{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bcc75b5",
   "metadata": {},
   "source": [
    "# CPR appropriation baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85dd79fb",
   "metadata": {},
   "source": [
    "This notebook contains actual Harvest trainings for the DQN baseline described in the original paper. The environment in use is a custom implementation of Harvest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e249de4b",
   "metadata": {},
   "source": [
    "## Pre-requisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9adda13",
   "metadata": {},
   "source": [
    "The cells down below install and import the necessary libraries to successfully run the notebook examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ff4506b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "05407869",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -r ../init/requirements.txt\n",
    "!pip install ../src/gym_cpr_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ae40e389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import ray\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "from src import rllib\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5713dd1",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a59b685",
   "metadata": {},
   "source": [
    "The cell down below defines common variables to be used throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "624d28a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_agents = 11\n",
    "grid_width = 39 \n",
    "grid_height = 19\n",
    "max_episodes = 4000\n",
    "num_workers = 4\n",
    "seed = 42\n",
    "rllib_log_dir = \"../rllib_logs/\"\n",
    "wandb_api_key = open(\"../wandb_api_key_file\", \"r\").read().strip()\n",
    "wandb_project = \"cpr-appropriation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f4d4a8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 18:23:10,966\tINFO services.py:1245 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8266\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '192.168.1.110',\n",
       " 'raylet_ip_address': '192.168.1.110',\n",
       " 'redis_address': '192.168.1.110:12604',\n",
       " 'object_store_address': '/tmp/ray/session_2021-08-25_18-23-08_968429_19542/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2021-08-25_18-23-08_968429_19542/sockets/raylet',\n",
       " 'webui_url': '127.0.0.1:8266',\n",
       " 'session_dir': '/tmp/ray/session_2021-08-25_18-23-08_968429_19542',\n",
       " 'metrics_export_port': 64055,\n",
       " 'node_id': 'ea256894445029047db96235f0d0eb2f93609cc726b4ef31c45bc2b1'}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.shutdown()\n",
    "ray.init(local_mode=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca89d8a6",
   "metadata": {},
   "source": [
    "## Random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce51190",
   "metadata": {},
   "source": [
    "This section shows a simple set of random agents sifting through the environment, as a way to show the general Gym workflow and the how rendering works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9ad4eaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\n",
    "    'gym_cpr_grid:CPRGridEnv-v0', \n",
    "    n_agents=n_agents, \n",
    "    grid_width=grid_width, \n",
    "    grid_height=grid_height\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efd9c9b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "observations = env.reset()\n",
    "fig, ax, img = env.plot(env.render('rgb_array'))\n",
    "for _ in range(env._max_episode_steps):\n",
    "    display.display(plt.gcf())\n",
    "    action_dict = {h: env.action_space.sample() for h in range(env.n_agents)}\n",
    "    print(action_dict)\n",
    "    observations, rewards, dones, infos = env.step(action_dict)\n",
    "    print(infos)\n",
    "    display.clear_output(wait=True)\n",
    "    img.set_data(env.render(mode='rgb_array'))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acc3151",
   "metadata": {},
   "source": [
    "## DQN baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a37844",
   "metadata": {},
   "source": [
    "This section deals with various DQN baselines, with different combinations of tagging and gifting abilities. The DQN algorithm itself is implemented in the RLlib library and accessible through the `rllib.dqn_baseline` function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48dc01f",
   "metadata": {},
   "source": [
    "### W/O tagging & W/O gifting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f47451",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_analysis = rllib.dqn_baseline(\n",
    "    n_agents,\n",
    "    grid_width,\n",
    "    grid_height,\n",
    "    wandb_project,\n",
    "    wandb_api_key,\n",
    "    rllib_log_dir,\n",
    "    max_episodes,\n",
    "    tagging_ability=False,\n",
    "    gifting_mechanism=None,\n",
    "    num_workers=4,\n",
    "    jupyter=True,\n",
    "    seed=seed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db0def0",
   "metadata": {},
   "source": [
    "### W/ tagging & W/O gifting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a547dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 18:24:56,212\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2021-08-25 18:24:58,137\tWARNING util.py:163 -- The `start_trial` operation took 2.346 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 9.2/16.0 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 5.0/16 CPUs, 0/0 GPUs, 0.0/4.34 GiB heap, 0.0/2.17 GiB objects\n",
      "Result logdir: /Users/jobs/Github/cpr-appropriation/rllib_logs/DQN_2021-08-25_18-24-55\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+--------------------------------------------+----------+-------+\n",
      "| Trial name                                 | status   | loc   |\n",
      "|--------------------------------------------+----------+-------|\n",
      "| DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000 | RUNNING  |       |\n",
      "+--------------------------------------------+----------+-------+\n",
      "\n",
      "\n",
      "Result for DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000:\n",
      "  agent_timesteps_total: 1056\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-25_18-24-58\n",
      "  done: false\n",
      "  episode_len_mean: .nan\n",
      "  episode_media: {}\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 0\n",
      "  experiment_id: d7c9d60e82b747cb85777bd6138148e5\n",
      "  hostname: wadaboa-work.local\n",
      "  info:\n",
      "    last_target_update_ts: 1056\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_lr: 0.0005\n",
      "          grad_gnorm: 0.1944553107023239\n",
      "          max_q: 0.046440064907073975\n",
      "          mean_q: 0.007184128742665052\n",
      "          mean_td_error: -0.10907012969255447\n",
      "          min_q: -0.0375279076397419\n",
      "        model: {}\n",
      "        td_error: \"[-3.4671295e-02 -1.1137752e-03 -1.2598817e-02 -2.1417394e-02\\n -2.8860126e-02\\\n",
      "          \\ -1.7635424e-02  2.3793634e-02 -6.5443300e-02\\n -1.0210067e+00  6.4535998e-04\\\n",
      "          \\ -1.0484681e+00 -4.8530735e-03\\n  2.1730267e-02 -1.0925251e-02 -2.5383942e-04\\\n",
      "          \\ -2.1100003e-02\\n  1.4859214e-03  8.9790486e-03 -1.0288293e-02  2.5922962e-02\\n\\\n",
      "          \\ -2.4306489e-02 -4.6604939e-02 -3.5619259e-02 -1.7053999e-02\\n -1.8114984e-02\\\n",
      "          \\  1.1477752e-02  5.0183721e-03 -3.7030548e-02\\n -2.7621815e-02 -1.0346178e+00\\\n",
      "          \\ -5.0337397e-02  6.4536370e-04]\"\n",
      "    num_agent_steps_sampled: 1056\n",
      "    num_agent_steps_trained: 32\n",
      "    num_steps_sampled: 1056\n",
      "    num_steps_trained: 32\n",
      "    num_target_updates: 1\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.1.110\n",
      "  num_healthy_workers: 4\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 19.733333333333334\n",
      "    ram_util_percent: 57.73333333333333\n",
      "  pid: 19542\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "  time_since_restore: 1.8994710445404053\n",
      "  time_this_iter_s: 1.8994710445404053\n",
      "  time_total_s: 1.8994710445404053\n",
      "  timers:\n",
      "    learn_throughput: 6516.056\n",
      "    learn_time_ms: 4.911\n",
      "    update_time_ms: 7.946\n",
      "  timestamp: 1629908698\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1056\n",
      "  training_iteration: 1\n",
      "  trial_id: fbba6_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: wadaboa (use `wandb login --relogin` to force relogin)\n",
      "wandb: WARNING Tried to auto resume run with id c7685_00000 but id fbba6_00000 is set.\n",
      "wandb: Tracking run with wandb version 0.12.0\n",
      "wandb: Syncing run DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000\n",
      "wandb:  View project at https://wandb.ai/wadaboa/cpr-appropriation\n",
      "wandb:  View run at https://wandb.ai/wadaboa/cpr-appropriation/runs/fbba6_00000\n",
      "wandb: Run data is saved locally in /Users/jobs/Github/cpr-appropriation/notebooks/wandb/run-20210825_182501-fbba6_00000\n",
      "wandb: Run `wandb offline` to turn off syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 9.8/16.0 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 5.0/16 CPUs, 0/0 GPUs, 0.0/4.34 GiB heap, 0.0/2.17 GiB objects\n",
      "Result logdir: /Users/jobs/Github/cpr-appropriation/rllib_logs/DQN_2021-08-25_18-24-55\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+--------------------------------------------+----------+---------------------+------------+\n",
      "| Trial name                                 | status   | loc                 |   episodes |\n",
      "|--------------------------------------------+----------+---------------------+------------|\n",
      "| DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000 | RUNNING  | 192.168.1.110:19542 |          0 |\n",
      "+--------------------------------------------+----------+---------------------+------------+\n",
      "\n",
      "\n",
      "Result for DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000:\n",
      "  agent_timesteps_total: 3168\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-25_18-25-03\n",
      "  done: false\n",
      "  episode_len_mean: .nan\n",
      "  episode_media: {}\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 0\n",
      "  experiment_id: d7c9d60e82b747cb85777bd6138148e5\n",
      "  hostname: wadaboa-work.local\n",
      "  info:\n",
      "    last_target_update_ts: 3168\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_lr: 0.0005\n",
      "          grad_gnorm: 0.017535103484988213\n",
      "          max_q: 0.19290012121200562\n",
      "          mean_q: 0.10400830954313278\n",
      "          mean_td_error: -0.06603261828422546\n",
      "          min_q: 0.04194323346018791\n",
      "        model: {}\n",
      "        td_error: \"[ 0.01245355 -0.00215006  0.01970013 -0.01929181 -0.01259591 -0.00412944\\n\\\n",
      "          \\ -0.01325224  0.01137912 -0.00746321  0.02387189 -0.03113896 -0.04368253\\n\\\n",
      "          \\  0.0017232  -0.07664321  0.03934948 -1.0416336  -0.02408051 -0.05008227\\n\\\n",
      "          \\  0.02334162 -0.01790862  0.00465917 -0.00487684  0.00749709  0.02804676\\n\\\n",
      "          \\  0.05417721 -0.0463566   0.01404414  0.00594139 -0.06988709  0.02749689\\n\\\n",
      "          \\ -0.9583231   0.03677075]\"\n",
      "    num_agent_steps_sampled: 3168\n",
      "    num_agent_steps_trained: 416\n",
      "    num_steps_sampled: 3168\n",
      "    num_steps_trained: 416\n",
      "    num_target_updates: 5\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 192.168.1.110\n",
      "  num_healthy_workers: 4\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.73333333333333\n",
      "    ram_util_percent: 60.6\n",
      "  pid: 19542\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "  time_since_restore: 7.480698108673096\n",
      "  time_this_iter_s: 3.2559359073638916\n",
      "  time_total_s: 7.480698108673096\n",
      "  timers:\n",
      "    learn_throughput: 5878.183\n",
      "    learn_time_ms: 5.444\n",
      "    update_time_ms: 106.587\n",
      "  timestamp: 1629908703\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3168\n",
      "  training_iteration: 3\n",
      "  trial_id: fbba6_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.9/16.0 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 5.0/16 CPUs, 0/0 GPUs, 0.0/4.34 GiB heap, 0.0/2.17 GiB objects (0.0/1.0 CPU_group_2_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_1_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_3_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_0_e8771a036fed53221c42d3b57c64506b, 0.0/5.0 CPU_group_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_4_e8771a036fed53221c42d3b57c64506b)\n",
      "Result logdir: /Users/jobs/Github/cpr-appropriation/rllib_logs/DQN_2021-08-25_18-24-55\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+--------------------------------------------+----------+---------------------+------------+\n",
      "| Trial name                                 | status   | loc                 |   episodes |\n",
      "|--------------------------------------------+----------+---------------------+------------|\n",
      "| DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000 | RUNNING  | 192.168.1.110:19542 |          0 |\n",
      "+--------------------------------------------+----------+---------------------+------------+\n",
      "\n",
      "\n",
      "Result for DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000:\n",
      "  agent_timesteps_total: 6336\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-25_18-25-11\n",
      "  done: false\n",
      "  episode_len_mean: .nan\n",
      "  episode_media: {}\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 0\n",
      "  experiment_id: d7c9d60e82b747cb85777bd6138148e5\n",
      "  hostname: wadaboa-work.local\n",
      "  info:\n",
      "    last_target_update_ts: 6336\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_lr: 0.0005\n",
      "          grad_gnorm: 0.016332734376192093\n",
      "          max_q: 0.5718539357185364\n",
      "          mean_q: 0.3347823917865753\n",
      "          mean_td_error: -0.04653463140130043\n",
      "          min_q: 0.12951992452144623\n",
      "        model: {}\n",
      "        td_error: \"[-0.00616714 -0.06175767 -0.04644904  0.04679304  0.02012354  0.07758498\\n\\\n",
      "          \\  0.11330181 -0.01167136 -0.02359489 -0.01386198  0.02826467 -0.00873107\\n\\\n",
      "          \\ -0.03852484  0.12234335  0.11231813 -0.01338679 -0.10627216  0.08222872\\n\\\n",
      "          \\  0.15107277  0.0671974  -0.07606745 -0.10714164  0.03382534 -1.0095326\\n\\\n",
      "          \\  0.00486627 -0.07885602  0.01695848  0.16092613 -0.90467525 -0.12312797\\n\\\n",
      "          \\  0.05808321  0.04482174]\"\n",
      "    num_agent_steps_sampled: 6336\n",
      "    num_agent_steps_trained: 992\n",
      "    num_steps_sampled: 6336\n",
      "    num_steps_trained: 992\n",
      "    num_target_updates: 11\n",
      "  iterations_since_restore: 6\n",
      "  node_ip: 192.168.1.110\n",
      "  num_healthy_workers: 4\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 6.325\n",
      "    ram_util_percent: 61.475\n",
      "  pid: 19542\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "  time_since_restore: 14.971964120864868\n",
      "  time_this_iter_s: 2.6459901332855225\n",
      "  time_total_s: 14.971964120864868\n",
      "  timers:\n",
      "    learn_throughput: 6267.493\n",
      "    learn_time_ms: 5.106\n",
      "    update_time_ms: 8.889\n",
      "  timestamp: 1629908711\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6336\n",
      "  training_iteration: 6\n",
      "  trial_id: fbba6_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.9/16.0 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 5.0/16 CPUs, 0/0 GPUs, 0.0/4.34 GiB heap, 0.0/2.17 GiB objects (0.0/1.0 CPU_group_2_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_1_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_3_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_0_e8771a036fed53221c42d3b57c64506b, 0.0/5.0 CPU_group_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_4_e8771a036fed53221c42d3b57c64506b)\n",
      "Result logdir: /Users/jobs/Github/cpr-appropriation/rllib_logs/DQN_2021-08-25_18-24-55\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+--------------------------------------------+----------+---------------------+------------+\n",
      "| Trial name                                 | status   | loc                 |   episodes |\n",
      "|--------------------------------------------+----------+---------------------+------------|\n",
      "| DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000 | RUNNING  | 192.168.1.110:19542 |          0 |\n",
      "+--------------------------------------------+----------+---------------------+------------+\n",
      "\n",
      "\n",
      "Result for DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000:\n",
      "  agent_timesteps_total: 8448\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-25_18-25-16\n",
      "  done: false\n",
      "  episode_len_mean: .nan\n",
      "  episode_media: {}\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 0\n",
      "  experiment_id: d7c9d60e82b747cb85777bd6138148e5\n",
      "  hostname: wadaboa-work.local\n",
      "  info:\n",
      "    last_target_update_ts: 8448\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_lr: 0.0005\n",
      "          grad_gnorm: 0.006986998021602631\n",
      "          max_q: 0.7400813698768616\n",
      "          mean_q: 0.5137251615524292\n",
      "          mean_td_error: 0.019439470022916794\n",
      "          min_q: 0.1839182823896408\n",
      "        model: {}\n",
      "        td_error: \"[ 1.9935310e-02  6.3431859e-03  7.9246640e-02  3.3635139e-02\\n -1.3950229e-02\\\n",
      "          \\  5.7462394e-02  3.4642100e-02  1.1185360e-01\\n  1.0091662e-03 -6.8918169e-03\\\n",
      "          \\  1.5654087e-02 -7.0534274e-02\\n  2.3831606e-02  3.5241246e-04  3.3945441e-02\\\n",
      "          \\  1.2432027e-01\\n  6.1363548e-02 -2.2606608e-01  2.4188071e-02  2.2856891e-02\\n\\\n",
      "          \\  2.4259090e-05 -4.5595378e-02 -3.2847345e-02  3.0862778e-02\\n -5.1756978e-02\\\n",
      "          \\  1.6528958e-01  2.0299882e-01 -1.6610205e-02\\n -5.6143016e-02 -3.4943223e-03\\\n",
      "          \\  7.3280513e-02  2.2856861e-02]\"\n",
      "    num_agent_steps_sampled: 8448\n",
      "    num_agent_steps_trained: 1376\n",
      "    num_steps_sampled: 8448\n",
      "    num_steps_trained: 1376\n",
      "    num_target_updates: 15\n",
      "  iterations_since_restore: 8\n",
      "  node_ip: 192.168.1.110\n",
      "  num_healthy_workers: 4\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 5.0\n",
      "    ram_util_percent: 61.72500000000001\n",
      "  pid: 19542\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "  time_since_restore: 20.29347062110901\n",
      "  time_this_iter_s: 2.625992774963379\n",
      "  time_total_s: 20.29347062110901\n",
      "  timers:\n",
      "    learn_throughput: 5975.59\n",
      "    learn_time_ms: 5.355\n",
      "    update_time_ms: 9.138\n",
      "  timestamp: 1629908716\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8448\n",
      "  training_iteration: 8\n",
      "  trial_id: fbba6_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 9.9/16.0 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 5.0/16 CPUs, 0/0 GPUs, 0.0/4.34 GiB heap, 0.0/2.17 GiB objects (0.0/1.0 CPU_group_3_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_1_e8771a036fed53221c42d3b57c64506b, 0.0/5.0 CPU_group_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_0_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_2_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_4_e8771a036fed53221c42d3b57c64506b)\n",
      "Result logdir: /Users/jobs/Github/cpr-appropriation/rllib_logs/DQN_2021-08-25_18-24-55\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+--------------------------------------------+----------+---------------------+------------+\n",
      "| Trial name                                 | status   | loc                 |   episodes |\n",
      "|--------------------------------------------+----------+---------------------+------------|\n",
      "| DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000 | RUNNING  | 192.168.1.110:19542 |          0 |\n",
      "+--------------------------------------------+----------+---------------------+------------+\n",
      "\n",
      "\n",
      "Result for DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000:\n",
      "  agent_timesteps_total: 10560\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-25_18-25-22\n",
      "  done: false\n",
      "  episode_len_mean: .nan\n",
      "  episode_media: {}\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 0\n",
      "  experiment_id: d7c9d60e82b747cb85777bd6138148e5\n",
      "  hostname: wadaboa-work.local\n",
      "  info:\n",
      "    last_target_update_ts: 10560\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_lr: 0.0005\n",
      "          grad_gnorm: 0.01228210050612688\n",
      "          max_q: 0.981564998626709\n",
      "          mean_q: 0.6756350994110107\n",
      "          mean_td_error: -0.03876485675573349\n",
      "          min_q: 0.3189713954925537\n",
      "        model: {}\n",
      "        td_error: \"[-1.77657992e-01 -4.70103323e-02  9.34889317e-02 -1.28414512e-01\\n\\\n",
      "          \\  7.55327940e-02 -1.17938876e-01 -1.91993117e-02 -5.13072014e-02\\n -3.04861307e-01\\\n",
      "          \\ -5.91247678e-02 -8.46970081e-02  8.56640339e-02\\n  1.73846841e-01 -7.85233080e-02\\\n",
      "          \\ -5.88768721e-03  5.15667200e-02\\n  8.06338489e-02  7.40101933e-02 -4.13278639e-02\\\n",
      "          \\  1.34529054e-01\\n  4.23942804e-02  7.69346952e-03 -5.49675226e-02  2.84556746e-02\\n\\\n",
      "          \\  6.66423440e-02 -6.68909252e-02  2.29207873e-02 -1.17021585e+00\\n -1.11442804e-03\\\n",
      "          \\  3.45733762e-02  3.04645896e-02  1.66246593e-01]\"\n",
      "    num_agent_steps_sampled: 10560\n",
      "    num_agent_steps_trained: 1760\n",
      "    num_steps_sampled: 10560\n",
      "    num_steps_trained: 1760\n",
      "    num_target_updates: 19\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 192.168.1.110\n",
      "  num_healthy_workers: 4\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 13.075\n",
      "    ram_util_percent: 61.925\n",
      "  pid: 19542\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "  time_since_restore: 25.6991605758667\n",
      "  time_this_iter_s: 2.722062826156616\n",
      "  time_total_s: 25.6991605758667\n",
      "  timers:\n",
      "    learn_throughput: 5496.154\n",
      "    learn_time_ms: 5.822\n",
      "    update_time_ms: 9.782\n",
      "  timestamp: 1629908722\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 10560\n",
      "  training_iteration: 10\n",
      "  trial_id: fbba6_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 10.0/16.0 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 5.0/16 CPUs, 0/0 GPUs, 0.0/4.34 GiB heap, 0.0/2.17 GiB objects (0.0/1.0 CPU_group_3_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_1_e8771a036fed53221c42d3b57c64506b, 0.0/5.0 CPU_group_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_0_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_2_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_4_e8771a036fed53221c42d3b57c64506b)\n",
      "Result logdir: /Users/jobs/Github/cpr-appropriation/rllib_logs/DQN_2021-08-25_18-24-55\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+--------------------------------------------+----------+---------------------+------------+\n",
      "| Trial name                                 | status   | loc                 |   episodes |\n",
      "|--------------------------------------------+----------+---------------------+------------|\n",
      "| DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000 | RUNNING  | 192.168.1.110:19542 |          0 |\n",
      "+--------------------------------------------+----------+---------------------+------------+\n",
      "\n",
      "\n",
      "Result for DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000:\n",
      "  agent_timesteps_total: 12672\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-25_18-25-27\n",
      "  done: false\n",
      "  episode_len_mean: .nan\n",
      "  episode_media: {}\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 0\n",
      "  experiment_id: d7c9d60e82b747cb85777bd6138148e5\n",
      "  hostname: wadaboa-work.local\n",
      "  info:\n",
      "    last_target_update_ts: 12672\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_lr: 0.0005\n",
      "          grad_gnorm: 0.014127573929727077\n",
      "          max_q: 1.2624818086624146\n",
      "          mean_q: 0.9818534255027771\n",
      "          mean_td_error: 0.0031889937818050385\n",
      "          min_q: 0.7218804359436035\n",
      "        model: {}\n",
      "        td_error: \"[ 0.24763846 -0.04202747  0.05032271  0.00306183 -0.00885129  0.01693273\\n\\\n",
      "          \\  0.08566713  0.05025566 -0.00576282  0.19989634  0.05452347  0.05449849\\n\\\n",
      "          \\  0.07516658  0.07958072 -0.18761861 -1.0700428   0.1911397   0.06928468\\n\\\n",
      "          \\  0.09292585  0.03549355  0.06662601  0.05766922  0.04209256 -0.10056031\\n\\\n",
      "          \\  0.06011981 -0.02411151 -0.05334073 -0.12665772  0.34074366 -0.15049285\\n\\\n",
      "          \\ -0.03415996  0.03203475]\"\n",
      "    num_agent_steps_sampled: 12672\n",
      "    num_agent_steps_trained: 2144\n",
      "    num_steps_sampled: 12672\n",
      "    num_steps_trained: 2144\n",
      "    num_target_updates: 23\n",
      "  iterations_since_restore: 12\n",
      "  node_ip: 192.168.1.110\n",
      "  num_healthy_workers: 4\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 14.35\n",
      "    ram_util_percent: 62.150000000000006\n",
      "  pid: 19542\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "  time_since_restore: 31.289265394210815\n",
      "  time_this_iter_s: 2.824967861175537\n",
      "  time_total_s: 31.289265394210815\n",
      "  timers:\n",
      "    learn_throughput: 5660.305\n",
      "    learn_time_ms: 5.653\n",
      "    update_time_ms: 9.994\n",
      "  timestamp: 1629908727\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 12672\n",
      "  training_iteration: 12\n",
      "  trial_id: fbba6_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 10.0/16.0 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 5.0/16 CPUs, 0/0 GPUs, 0.0/4.34 GiB heap, 0.0/2.17 GiB objects (0.0/1.0 CPU_group_0_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_2_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_4_e8771a036fed53221c42d3b57c64506b, 0.0/5.0 CPU_group_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_3_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_1_e8771a036fed53221c42d3b57c64506b)\n",
      "Result logdir: /Users/jobs/Github/cpr-appropriation/rllib_logs/DQN_2021-08-25_18-24-55\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+--------------------------------------------+----------+---------------------+------------+\n",
      "| Trial name                                 | status   | loc                 |   episodes |\n",
      "|--------------------------------------------+----------+---------------------+------------|\n",
      "| DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000 | RUNNING  | 192.168.1.110:19542 |          0 |\n",
      "+--------------------------------------------+----------+---------------------+------------+\n",
      "\n",
      "\n",
      "Result for DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000:\n",
      "  agent_timesteps_total: 14784\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-25_18-25-33\n",
      "  done: false\n",
      "  episode_len_mean: .nan\n",
      "  episode_media: {}\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 0\n",
      "  experiment_id: d7c9d60e82b747cb85777bd6138148e5\n",
      "  hostname: wadaboa-work.local\n",
      "  info:\n",
      "    last_target_update_ts: 14784\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_lr: 0.0005\n",
      "          grad_gnorm: 0.008185841143131256\n",
      "          max_q: 1.7125778198242188\n",
      "          mean_q: 1.3359230756759644\n",
      "          mean_td_error: -0.0031630434095859528\n",
      "          min_q: 0.5574040412902832\n",
      "        model: {}\n",
      "        td_error: \"[ 0.18324554 -0.03496921  0.07685554  0.00648034 -0.14894664 -0.1974988\\n\\\n",
      "          \\  0.06659365  0.07832968 -0.01005554 -0.1774627   0.12487018  0.0925225\\n\\\n",
      "          \\  0.1259023   0.05786967 -0.15110731  0.01629102  0.09193099 -0.12517524\\n\\\n",
      "          \\ -0.14394057  0.10978508 -0.07633615  0.04386306 -0.05902326 -0.10511315\\n\\\n",
      "          \\ -0.2911538   0.1039269  -0.01396954  0.01608217  0.08660376 -0.10314941\\n\\\n",
      "          \\  0.06921017  0.18632138]\"\n",
      "    num_agent_steps_sampled: 14784\n",
      "    num_agent_steps_trained: 2528\n",
      "    num_steps_sampled: 14784\n",
      "    num_steps_trained: 2528\n",
      "    num_target_updates: 27\n",
      "  iterations_since_restore: 14\n",
      "  node_ip: 192.168.1.110\n",
      "  num_healthy_workers: 4\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 6.1\n",
      "    ram_util_percent: 62.475\n",
      "  pid: 19542\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "  time_since_restore: 37.02479410171509\n",
      "  time_this_iter_s: 2.9314138889312744\n",
      "  time_total_s: 37.02479410171509\n",
      "  timers:\n",
      "    learn_throughput: 5335.565\n",
      "    learn_time_ms: 5.997\n",
      "    update_time_ms: 9.779\n",
      "  timestamp: 1629908733\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 14784\n",
      "  training_iteration: 14\n",
      "  trial_id: fbba6_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/wadaboa/cpr-appropriation/c7685_00000/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/wadaboa/cpr-appropriation/c7685_00000/file_stream\n",
      "NoneType: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 10.1/16.0 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 5.0/16 CPUs, 0/0 GPUs, 0.0/4.34 GiB heap, 0.0/2.17 GiB objects (0.0/1.0 CPU_group_0_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_2_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_4_e8771a036fed53221c42d3b57c64506b, 0.0/5.0 CPU_group_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_3_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_1_e8771a036fed53221c42d3b57c64506b)\n",
      "Result logdir: /Users/jobs/Github/cpr-appropriation/rllib_logs/DQN_2021-08-25_18-24-55\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+--------------------------------------------+----------+---------------------+------------+\n",
      "| Trial name                                 | status   | loc                 |   episodes |\n",
      "|--------------------------------------------+----------+---------------------+------------|\n",
      "| DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000 | RUNNING  | 192.168.1.110:19542 |          0 |\n",
      "+--------------------------------------------+----------+---------------------+------------+\n",
      "\n",
      "\n",
      "Result for DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000:\n",
      "  agent_timesteps_total: 16896\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-25_18-25-39\n",
      "  done: false\n",
      "  episode_len_mean: .nan\n",
      "  episode_media: {}\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 0\n",
      "  experiment_id: d7c9d60e82b747cb85777bd6138148e5\n",
      "  hostname: wadaboa-work.local\n",
      "  info:\n",
      "    last_target_update_ts: 16896\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_lr: 0.0005\n",
      "          grad_gnorm: 0.02254657819867134\n",
      "          max_q: 2.393805503845215\n",
      "          mean_q: 1.6954619884490967\n",
      "          mean_td_error: 0.0043494850397109985\n",
      "          min_q: 1.0291246175765991\n",
      "        model: {}\n",
      "        td_error: \"[ 2.64869690e-01  1.29236698e-01 -5.14627695e-02  6.20012283e-02\\n\\\n",
      "          \\  3.28514576e-02 -2.02947140e-01  2.30156660e-01  1.37982249e-01\\n  2.35737085e-01\\\n",
      "          \\ -8.40824842e-02  1.00129366e-01 -9.84632969e-03\\n -1.01853967e-01 -8.58924508e-01\\\n",
      "          \\  5.43718338e-02  1.03631496e-01\\n  4.14334536e-02  1.35029316e-01  8.44717026e-04\\\n",
      "          \\  1.31936431e-01\\n -2.35390663e-02  4.86419201e-02  1.31921768e-02  1.20464325e-01\\n\\\n",
      "          \\  1.56205893e-02  4.08963799e-01 -8.82553458e-01  6.74488544e-02\\n  2.55550265e-01\\\n",
      "          \\  1.50702238e-01  2.54476070e-03 -3.88947368e-01]\"\n",
      "    num_agent_steps_sampled: 16896\n",
      "    num_agent_steps_trained: 2912\n",
      "    num_steps_sampled: 16896\n",
      "    num_steps_trained: 2912\n",
      "    num_target_updates: 31\n",
      "  iterations_since_restore: 16\n",
      "  node_ip: 192.168.1.110\n",
      "  num_healthy_workers: 4\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 4.55\n",
      "    ram_util_percent: 62.775000000000006\n",
      "  pid: 19542\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "  time_since_restore: 43.296104192733765\n",
      "  time_this_iter_s: 3.2179410457611084\n",
      "  time_total_s: 43.296104192733765\n",
      "  timers:\n",
      "    learn_throughput: 5731.587\n",
      "    learn_time_ms: 5.583\n",
      "    update_time_ms: 9.806\n",
      "  timestamp: 1629908739\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 16896\n",
      "  training_iteration: 16\n",
      "  trial_id: fbba6_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 10.1/16.0 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 5.0/16 CPUs, 0/0 GPUs, 0.0/4.34 GiB heap, 0.0/2.17 GiB objects (0.0/5.0 CPU_group_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_0_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_3_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_2_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_4_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_1_e8771a036fed53221c42d3b57c64506b)\n",
      "Result logdir: /Users/jobs/Github/cpr-appropriation/rllib_logs/DQN_2021-08-25_18-24-55\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+--------------------------------------------+----------+---------------------+------------+\n",
      "| Trial name                                 | status   | loc                 |   episodes |\n",
      "|--------------------------------------------+----------+---------------------+------------|\n",
      "| DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000 | RUNNING  | 192.168.1.110:19542 |          0 |\n",
      "+--------------------------------------------+----------+---------------------+------------+\n",
      "\n",
      "\n",
      "Result for DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000:\n",
      "  agent_timesteps_total: 19008\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-25_18-25-46\n",
      "  done: false\n",
      "  episode_len_mean: .nan\n",
      "  episode_media: {}\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 0\n",
      "  experiment_id: d7c9d60e82b747cb85777bd6138148e5\n",
      "  hostname: wadaboa-work.local\n",
      "  info:\n",
      "    last_target_update_ts: 19008\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_lr: 0.0005\n",
      "          grad_gnorm: 0.025413760915398598\n",
      "          max_q: 2.976944923400879\n",
      "          mean_q: 1.8723026514053345\n",
      "          mean_td_error: 0.024651531130075455\n",
      "          min_q: 1.2347344160079956\n",
      "        model: {}\n",
      "        td_error: \"[ 0.15245724  0.08089328  0.08838439  0.07955992 -0.01685047  0.2856381\\n\\\n",
      "          \\  0.11558521  0.4067527   0.18800712  0.09603715  0.03706753  0.1208142\\n\\\n",
      "          \\  0.35372353  0.07338488  0.07790589  0.10996962  0.00495648  0.2025274\\n\\\n",
      "          \\ -0.01040018 -0.12025666  0.03627872  0.07160151  0.05761647  0.04544461\\n\\\n",
      "          \\ -1.1209403  -0.9996947   0.14476371  0.09443951  0.10508895  0.08782506\\n\\\n",
      "          \\  0.00665843 -0.06639028]\"\n",
      "    num_agent_steps_sampled: 19008\n",
      "    num_agent_steps_trained: 3296\n",
      "    num_steps_sampled: 19008\n",
      "    num_steps_trained: 3296\n",
      "    num_target_updates: 35\n",
      "  iterations_since_restore: 18\n",
      "  node_ip: 192.168.1.110\n",
      "  num_healthy_workers: 4\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 10.32\n",
      "    ram_util_percent: 63.08\n",
      "  pid: 19542\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "  time_since_restore: 49.979339838027954\n",
      "  time_this_iter_s: 3.3373677730560303\n",
      "  time_total_s: 49.979339838027954\n",
      "  timers:\n",
      "    learn_throughput: 5816.662\n",
      "    learn_time_ms: 5.501\n",
      "    update_time_ms: 9.46\n",
      "  timestamp: 1629908746\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 19008\n",
      "  training_iteration: 18\n",
      "  trial_id: fbba6_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.9/16.0 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 5.0/16 CPUs, 0/0 GPUs, 0.0/4.34 GiB heap, 0.0/2.17 GiB objects (0.0/1.0 CPU_group_3_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_2_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_0_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_4_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_1_e8771a036fed53221c42d3b57c64506b, 0.0/5.0 CPU_group_e8771a036fed53221c42d3b57c64506b)\n",
      "Result logdir: /Users/jobs/Github/cpr-appropriation/rllib_logs/DQN_2021-08-25_18-24-55\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+--------------------------------------------+----------+---------------------+------------+\n",
      "| Trial name                                 | status   | loc                 |   episodes |\n",
      "|--------------------------------------------+----------+---------------------+------------|\n",
      "| DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000 | RUNNING  | 192.168.1.110:19542 |          0 |\n",
      "+--------------------------------------------+----------+---------------------+------------+\n",
      "\n",
      "\n",
      "Result for DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000:\n",
      "  agent_timesteps_total: 21120\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-25_18-25-53\n",
      "  done: false\n",
      "  episode_len_mean: .nan\n",
      "  episode_media: {}\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 0\n",
      "  experiment_id: d7c9d60e82b747cb85777bd6138148e5\n",
      "  hostname: wadaboa-work.local\n",
      "  info:\n",
      "    last_target_update_ts: 21120\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_lr: 0.0005\n",
      "          grad_gnorm: 0.06958254426717758\n",
      "          max_q: 3.124500274658203\n",
      "          mean_q: 2.268242120742798\n",
      "          mean_td_error: 0.16937240958213806\n",
      "          min_q: 1.4781111478805542\n",
      "        model: {}\n",
      "        td_error: \"[ 0.1305958   0.09899974  0.47348475  0.03262818  0.2893101   0.00065279\\n\\\n",
      "          \\  0.06860876  0.16932034 -0.00474048  0.22752142  0.13701439  0.35040665\\n\\\n",
      "          \\  0.37575293  0.19065881  0.11344099  0.20727253  0.00065279  0.52416813\\n\\\n",
      "          \\  0.20370746 -0.20619583  0.04934955  0.08869994  0.37715387  0.22786331\\n\\\n",
      "          \\  0.2188251  -0.05417323  0.01653075  0.29038477  0.16831994  0.3724556\\n\\\n",
      "          \\  0.26745033  0.01379704]\"\n",
      "    num_agent_steps_sampled: 21120\n",
      "    num_agent_steps_trained: 3680\n",
      "    num_steps_sampled: 21120\n",
      "    num_steps_trained: 3680\n",
      "    num_target_updates: 39\n",
      "  iterations_since_restore: 20\n",
      "  node_ip: 192.168.1.110\n",
      "  num_healthy_workers: 4\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 15.62\n",
      "    ram_util_percent: 62.7\n",
      "  pid: 19542\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "  time_since_restore: 56.9101357460022\n",
      "  time_this_iter_s: 3.5806777477264404\n",
      "  time_total_s: 56.9101357460022\n",
      "  timers:\n",
      "    learn_throughput: 5790.463\n",
      "    learn_time_ms: 5.526\n",
      "    update_time_ms: 9.582\n",
      "  timestamp: 1629908753\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 21120\n",
      "  training_iteration: 20\n",
      "  trial_id: fbba6_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 18:25:57,063\tWARNING ray_trial_executor.py:709 -- Over the last 60 seconds, the Tune event loop has been backlogged processing new results. Consider increasing your period of result reporting to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 9.9/16.0 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 5.0/16 CPUs, 0/0 GPUs, 0.0/4.34 GiB heap, 0.0/2.17 GiB objects (0.0/1.0 CPU_group_3_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_2_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_0_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_4_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_1_e8771a036fed53221c42d3b57c64506b, 0.0/5.0 CPU_group_e8771a036fed53221c42d3b57c64506b)\n",
      "Result logdir: /Users/jobs/Github/cpr-appropriation/rllib_logs/DQN_2021-08-25_18-24-55\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+--------------------------------------------+----------+---------------------+------------+\n",
      "| Trial name                                 | status   | loc                 |   episodes |\n",
      "|--------------------------------------------+----------+---------------------+------------|\n",
      "| DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000 | RUNNING  | 192.168.1.110:19542 |          0 |\n",
      "+--------------------------------------------+----------+---------------------+------------+\n",
      "\n",
      "\n",
      "Result for DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000:\n",
      "  agent_timesteps_total: 23232\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-25_18-26-00\n",
      "  done: false\n",
      "  episode_len_mean: .nan\n",
      "  episode_media: {}\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 0\n",
      "  experiment_id: d7c9d60e82b747cb85777bd6138148e5\n",
      "  hostname: wadaboa-work.local\n",
      "  info:\n",
      "    last_target_update_ts: 23232\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_lr: 0.0005\n",
      "          grad_gnorm: 0.03270445764064789\n",
      "          max_q: 3.1699728965759277\n",
      "          mean_q: 2.291604518890381\n",
      "          mean_td_error: -0.07924751192331314\n",
      "          min_q: 1.5263798236846924\n",
      "        model: {}\n",
      "        td_error: \"[-0.01799071  0.04466057  0.08321977  0.0429368  -0.02813435 -1.0942383\\n\\\n",
      "          \\ -0.00376344 -0.10650039  0.09796512 -0.00998187 -0.02808952 -0.09837461\\n\\\n",
      "          \\ -0.20584345 -0.0042119   0.0078795  -1.0394739   0.07081008 -0.04688382\\n\\\n",
      "          \\ -0.02690196 -0.05246568 -0.01167321  0.02382755  0.1771028   0.02622271\\n\\\n",
      "          \\ -0.07325792  0.04604101 -0.00311601  0.02599347 -0.13794315 -0.0023098\\n\\\n",
      "          \\ -0.20196533  0.01053953]\"\n",
      "    num_agent_steps_sampled: 23232\n",
      "    num_agent_steps_trained: 4064\n",
      "    num_steps_sampled: 23232\n",
      "    num_steps_trained: 4064\n",
      "    num_target_updates: 43\n",
      "  iterations_since_restore: 22\n",
      "  node_ip: 192.168.1.110\n",
      "  num_healthy_workers: 4\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 0.0\n",
      "    ram_util_percent: 61.975\n",
      "  pid: 19542\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "  time_since_restore: 63.50437688827515\n",
      "  time_this_iter_s: 3.291996955871582\n",
      "  time_total_s: 63.50437688827515\n",
      "  timers:\n",
      "    learn_throughput: 5770.497\n",
      "    learn_time_ms: 5.545\n",
      "    update_time_ms: 9.239\n",
      "  timestamp: 1629908760\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 23232\n",
      "  training_iteration: 22\n",
      "  trial_id: fbba6_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/wadaboa/cpr-appropriation/c7685_00000/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/wadaboa/cpr-appropriation/c7685_00000/file_stream\n",
      "NoneType: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 10.0/16.0 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 5.0/16 CPUs, 0/0 GPUs, 0.0/4.34 GiB heap, 0.0/2.17 GiB objects (0.0/1.0 CPU_group_4_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_0_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_3_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_2_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_1_e8771a036fed53221c42d3b57c64506b, 0.0/5.0 CPU_group_e8771a036fed53221c42d3b57c64506b)\n",
      "Result logdir: /Users/jobs/Github/cpr-appropriation/rllib_logs/DQN_2021-08-25_18-24-55\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+--------------------------------------------+----------+---------------------+------------+\n",
      "| Trial name                                 | status   | loc                 |   episodes |\n",
      "|--------------------------------------------+----------+---------------------+------------|\n",
      "| DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000 | RUNNING  | 192.168.1.110:19542 |          0 |\n",
      "+--------------------------------------------+----------+---------------------+------------+\n",
      "\n",
      "\n",
      "Result for DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000:\n",
      "  agent_timesteps_total: 25344\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-25_18-26-07\n",
      "  done: false\n",
      "  episode_len_mean: .nan\n",
      "  episode_media: {}\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 0\n",
      "  experiment_id: d7c9d60e82b747cb85777bd6138148e5\n",
      "  hostname: wadaboa-work.local\n",
      "  info:\n",
      "    last_target_update_ts: 25344\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_lr: 0.0005\n",
      "          grad_gnorm: 0.029574932530522346\n",
      "          max_q: 3.8933305740356445\n",
      "          mean_q: 2.682668924331665\n",
      "          mean_td_error: 0.039072923362255096\n",
      "          min_q: 1.3151081800460815\n",
      "        model: {}\n",
      "        td_error: \"[ 0.06669092  0.06409454  0.21193063  0.02996695 -0.08420777 -0.00465965\\n\\\n",
      "          \\  0.47516418  0.02946424 -0.1648475   0.03114295  0.08113861  0.04633307\\n\\\n",
      "          \\  0.03329563  0.21557331  0.17725205 -0.718765   -0.41049743  0.10971141\\n\\\n",
      "          \\ -0.1422522   0.11041284  0.31905854 -0.02061319  0.04760623 -0.0453496\\n\\\n",
      "          \\  0.10757732  0.02625251  0.1526761   0.05889893  0.06860018  0.0698173\\n\\\n",
      "          \\  0.18652916  0.12233829]\"\n",
      "    num_agent_steps_sampled: 25344\n",
      "    num_agent_steps_trained: 4448\n",
      "    num_steps_sampled: 25344\n",
      "    num_steps_trained: 4448\n",
      "    num_target_updates: 47\n",
      "  iterations_since_restore: 24\n",
      "  node_ip: 192.168.1.110\n",
      "  num_healthy_workers: 4\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 17.32\n",
      "    ram_util_percent: 62.279999999999994\n",
      "  pid: 19542\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "  time_since_restore: 70.62609219551086\n",
      "  time_this_iter_s: 3.6681861877441406\n",
      "  time_total_s: 70.62609219551086\n",
      "  timers:\n",
      "    learn_throughput: 5905.261\n",
      "    learn_time_ms: 5.419\n",
      "    update_time_ms: 9.308\n",
      "  timestamp: 1629908767\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 25344\n",
      "  training_iteration: 24\n",
      "  trial_id: fbba6_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 10.0/16.0 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 5.0/16 CPUs, 0/0 GPUs, 0.0/4.34 GiB heap, 0.0/2.17 GiB objects (0.0/1.0 CPU_group_3_e8771a036fed53221c42d3b57c64506b, 0.0/5.0 CPU_group_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_1_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_0_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_2_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_4_e8771a036fed53221c42d3b57c64506b)\n",
      "Result logdir: /Users/jobs/Github/cpr-appropriation/rllib_logs/DQN_2021-08-25_18-24-55\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+--------------------------------------------+----------+---------------------+------------+\n",
      "| Trial name                                 | status   | loc                 |   episodes |\n",
      "|--------------------------------------------+----------+---------------------+------------|\n",
      "| DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000 | RUNNING  | 192.168.1.110:19542 |          0 |\n",
      "+--------------------------------------------+----------+---------------------+------------+\n",
      "\n",
      "\n",
      "Result for DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000:\n",
      "  agent_timesteps_total: 27456\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-25_18-26-15\n",
      "  done: false\n",
      "  episode_len_mean: .nan\n",
      "  episode_media: {}\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 0\n",
      "  experiment_id: d7c9d60e82b747cb85777bd6138148e5\n",
      "  hostname: wadaboa-work.local\n",
      "  info:\n",
      "    last_target_update_ts: 27456\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_lr: 0.0005\n",
      "          grad_gnorm: 0.08621887862682343\n",
      "          max_q: 4.392380714416504\n",
      "          mean_q: 3.2539143562316895\n",
      "          mean_td_error: 0.15228323638439178\n",
      "          min_q: 1.4019050598144531\n",
      "        model: {}\n",
      "        td_error: \"[-0.13509607  0.3436923   0.07070661  0.05883336 -0.03227472  0.89172053\\n\\\n",
      "          \\  0.18180895  0.1312027  -0.29929543  0.26053667 -0.3614986   0.331074\\n\\\n",
      "          \\  0.41234064  0.20790148  0.12840605 -0.02013075  0.01521301  0.33929563\\n\\\n",
      "          \\  0.12466764 -0.05775166  0.6630442   0.14393854  0.09620476  0.05279064\\n\\\n",
      "          \\  0.3335054   0.10400057 -0.14260483  0.17010403  0.16033578  0.12058401\\n\\\n",
      "          \\  0.21551347  0.36429477]\"\n",
      "    num_agent_steps_sampled: 27456\n",
      "    num_agent_steps_trained: 4832\n",
      "    num_steps_sampled: 27456\n",
      "    num_steps_trained: 4832\n",
      "    num_target_updates: 51\n",
      "  iterations_since_restore: 26\n",
      "  node_ip: 192.168.1.110\n",
      "  num_healthy_workers: 4\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.883333333333336\n",
      "    ram_util_percent: 62.63333333333333\n",
      "  pid: 19542\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "  time_since_restore: 78.49761056900024\n",
      "  time_this_iter_s: 3.9881882667541504\n",
      "  time_total_s: 78.49761056900024\n",
      "  timers:\n",
      "    learn_throughput: 6097.702\n",
      "    learn_time_ms: 5.248\n",
      "    update_time_ms: 8.878\n",
      "  timestamp: 1629908775\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 27456\n",
      "  training_iteration: 26\n",
      "  trial_id: fbba6_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 10.2/16.0 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 5.0/16 CPUs, 0/0 GPUs, 0.0/4.34 GiB heap, 0.0/2.17 GiB objects (0.0/1.0 CPU_group_3_e8771a036fed53221c42d3b57c64506b, 0.0/5.0 CPU_group_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_1_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_0_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_2_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_4_e8771a036fed53221c42d3b57c64506b)\n",
      "Result logdir: /Users/jobs/Github/cpr-appropriation/rllib_logs/DQN_2021-08-25_18-24-55\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+--------------------------------------------+----------+---------------------+------------+\n",
      "| Trial name                                 | status   | loc                 |   episodes |\n",
      "|--------------------------------------------+----------+---------------------+------------|\n",
      "| DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000 | RUNNING  | 192.168.1.110:19542 |          0 |\n",
      "+--------------------------------------------+----------+---------------------+------------+\n",
      "\n",
      "\n",
      "Result for DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000:\n",
      "  agent_timesteps_total: 29568\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-25_18-26-23\n",
      "  done: false\n",
      "  episode_len_mean: .nan\n",
      "  episode_media: {}\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 0\n",
      "  experiment_id: d7c9d60e82b747cb85777bd6138148e5\n",
      "  hostname: wadaboa-work.local\n",
      "  info:\n",
      "    last_target_update_ts: 29568\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_lr: 0.0005\n",
      "          grad_gnorm: 0.0704987570643425\n",
      "          max_q: 4.9316277503967285\n",
      "          mean_q: 3.298262119293213\n",
      "          mean_td_error: 0.1374889314174652\n",
      "          min_q: 1.6014505624771118\n",
      "        model: {}\n",
      "        td_error: \"[ 0.11328244  0.5028665   0.09706163  0.15501738  0.17293882  0.28179646\\n\\\n",
      "          \\ -0.16675568  0.10833764  0.11703587 -0.1814239   0.08772349  0.27861214\\n\\\n",
      "          \\  0.13133883  0.06370664  0.12660527  0.00147915  0.27552032  0.19994402\\n\\\n",
      "          \\  0.09512889  0.29103327  0.18587518  0.141577    0.18587518  0.2612059\\n\\\n",
      "          \\  0.03834677 -0.02512383  0.11951876  0.15630889  0.10013056  0.12174845\\n\\\n",
      "          \\  0.06870842  0.29422498]\"\n",
      "    num_agent_steps_sampled: 29568\n",
      "    num_agent_steps_trained: 5216\n",
      "    num_steps_sampled: 29568\n",
      "    num_steps_trained: 5216\n",
      "    num_target_updates: 55\n",
      "  iterations_since_restore: 28\n",
      "  node_ip: 192.168.1.110\n",
      "  num_healthy_workers: 4\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 13.280000000000001\n",
      "    ram_util_percent: 63.85999999999999\n",
      "  pid: 19542\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "  time_since_restore: 86.64695763587952\n",
      "  time_this_iter_s: 4.028094053268433\n",
      "  time_total_s: 86.64695763587952\n",
      "  timers:\n",
      "    learn_throughput: 6220.321\n",
      "    learn_time_ms: 5.144\n",
      "    update_time_ms: 8.712\n",
      "  timestamp: 1629908783\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 29568\n",
      "  training_iteration: 28\n",
      "  trial_id: fbba6_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 10.2/16.0 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 5.0/16 CPUs, 0/0 GPUs, 0.0/4.34 GiB heap, 0.0/2.17 GiB objects (0.0/1.0 CPU_group_4_e8771a036fed53221c42d3b57c64506b, 0.0/5.0 CPU_group_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_2_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_1_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_3_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_0_e8771a036fed53221c42d3b57c64506b)\n",
      "Result logdir: /Users/jobs/Github/cpr-appropriation/rllib_logs/DQN_2021-08-25_18-24-55\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+--------------------------------------------+----------+---------------------+------------+\n",
      "| Trial name                                 | status   | loc                 |   episodes |\n",
      "|--------------------------------------------+----------+---------------------+------------|\n",
      "| DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000 | RUNNING  | 192.168.1.110:19542 |          0 |\n",
      "+--------------------------------------------+----------+---------------------+------------+\n",
      "\n",
      "\n",
      "Result for DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000:\n",
      "  agent_timesteps_total: 31680\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-25_18-26-31\n",
      "  done: false\n",
      "  episode_len_mean: .nan\n",
      "  episode_media: {}\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 0\n",
      "  experiment_id: d7c9d60e82b747cb85777bd6138148e5\n",
      "  hostname: wadaboa-work.local\n",
      "  info:\n",
      "    last_target_update_ts: 31680\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_lr: 0.0005\n",
      "          grad_gnorm: 0.06190107390284538\n",
      "          max_q: 5.796097278594971\n",
      "          mean_q: 4.015655040740967\n",
      "          mean_td_error: 0.09453541785478592\n",
      "          min_q: 2.4244863986968994\n",
      "        model: {}\n",
      "        td_error: \"[ 1.35250092e-02  3.04255962e-01  2.36273527e-01  2.02355385e-02\\n\\\n",
      "          \\  9.19291973e-02  8.27571392e-01 -1.04923248e-02  3.02989006e-01\\n  1.01034641e-01\\\n",
      "          \\  4.36306000e-04 -1.50573254e-02  1.32316351e-01\\n -4.16307449e-02 -1.26226902e-01\\\n",
      "          \\  5.31585217e-02  3.34557295e-01\\n  4.33109760e-01  8.51292610e-02 -2.22749710e-02\\\n",
      "          \\  4.28584576e-01\\n  7.46123791e-02 -2.99813747e-01 -7.49511719e-02  8.52298737e-03\\n\\\n",
      "          \\  5.40361404e-02  3.99425030e-02  4.48648930e-01 -1.50370598e-02\\n -4.13503647e-02\\\n",
      "          \\ -2.68568516e-01 -1.70439959e-01  1.20107174e-01]\"\n",
      "    num_agent_steps_sampled: 31680\n",
      "    num_agent_steps_trained: 5600\n",
      "    num_steps_sampled: 31680\n",
      "    num_steps_trained: 5600\n",
      "    num_target_updates: 59\n",
      "  iterations_since_restore: 30\n",
      "  node_ip: 192.168.1.110\n",
      "  num_healthy_workers: 4\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 13.059999999999999\n",
      "    ram_util_percent: 63.96\n",
      "  pid: 19542\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "  time_since_restore: 94.27192735671997\n",
      "  time_this_iter_s: 3.724984645843506\n",
      "  time_total_s: 94.27192735671997\n",
      "  timers:\n",
      "    learn_throughput: 6354.134\n",
      "    learn_time_ms: 5.036\n",
      "    update_time_ms: 8.428\n",
      "  timestamp: 1629908791\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 31680\n",
      "  training_iteration: 30\n",
      "  trial_id: fbba6_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/wadaboa/cpr-appropriation/c7685_00000/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/wadaboa/cpr-appropriation/c7685_00000/file_stream\n",
      "NoneType: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 10.3/16.0 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 5.0/16 CPUs, 0/0 GPUs, 0.0/4.34 GiB heap, 0.0/2.17 GiB objects (0.0/1.0 CPU_group_4_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_3_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_2_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_1_e8771a036fed53221c42d3b57c64506b, 0.0/5.0 CPU_group_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_0_e8771a036fed53221c42d3b57c64506b)\n",
      "Result logdir: /Users/jobs/Github/cpr-appropriation/rllib_logs/DQN_2021-08-25_18-24-55\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+--------------------------------------------+----------+---------------------+------------+\n",
      "| Trial name                                 | status   | loc                 |   episodes |\n",
      "|--------------------------------------------+----------+---------------------+------------|\n",
      "| DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000 | RUNNING  | 192.168.1.110:19542 |          0 |\n",
      "+--------------------------------------------+----------+---------------------+------------+\n",
      "\n",
      "\n",
      "Result for DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000:\n",
      "  agent_timesteps_total: 33792\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-25_18-26-39\n",
      "  done: false\n",
      "  episode_len_mean: .nan\n",
      "  episode_media: {}\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 0\n",
      "  experiment_id: d7c9d60e82b747cb85777bd6138148e5\n",
      "  hostname: wadaboa-work.local\n",
      "  info:\n",
      "    last_target_update_ts: 33792\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_lr: 0.0005\n",
      "          grad_gnorm: 0.056626126170158386\n",
      "          max_q: 5.095829963684082\n",
      "          mean_q: 3.625394105911255\n",
      "          mean_td_error: 0.09042351692914963\n",
      "          min_q: 1.9916924238204956\n",
      "        model: {}\n",
      "        td_error: \"[ 0.12356162  0.03252602  0.16465497 -0.21178794  0.07312465  0.27569008\\n\\\n",
      "          \\ -0.24264538  0.12569737  0.08207011  0.05910468 -0.19984818  0.310179\\n\\\n",
      "          \\  0.4060297   0.24511409  0.11311007  0.12695074  0.18819523  0.0267911\\n\\\n",
      "          \\  0.28621006  0.14993024 -0.19111848  0.01028967  0.06175065  0.12990665\\n\\\n",
      "          \\  0.14959908  0.23401904  0.11250639 -0.03524733  0.15452051  0.18327951\\n\\\n",
      "          \\ -0.20278001  0.15216875]\"\n",
      "    num_agent_steps_sampled: 33792\n",
      "    num_agent_steps_trained: 5984\n",
      "    num_steps_sampled: 33792\n",
      "    num_steps_trained: 5984\n",
      "    num_target_updates: 63\n",
      "  iterations_since_restore: 32\n",
      "  node_ip: 192.168.1.110\n",
      "  num_healthy_workers: 4\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 6.659999999999999\n",
      "    ram_util_percent: 64.32000000000001\n",
      "  pid: 19542\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "  time_since_restore: 101.96416640281677\n",
      "  time_this_iter_s: 3.8894801139831543\n",
      "  time_total_s: 101.96416640281677\n",
      "  timers:\n",
      "    learn_throughput: 6628.822\n",
      "    learn_time_ms: 4.827\n",
      "    update_time_ms: 8.322\n",
      "  timestamp: 1629908799\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 33792\n",
      "  training_iteration: 32\n",
      "  trial_id: fbba6_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 10.2/16.0 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 5.0/16 CPUs, 0/0 GPUs, 0.0/4.34 GiB heap, 0.0/2.17 GiB objects (0.0/1.0 CPU_group_4_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_3_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_2_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_1_e8771a036fed53221c42d3b57c64506b, 0.0/5.0 CPU_group_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_0_e8771a036fed53221c42d3b57c64506b)\n",
      "Result logdir: /Users/jobs/Github/cpr-appropriation/rllib_logs/DQN_2021-08-25_18-24-55\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+--------------------------------------------+----------+---------------------+------------+\n",
      "| Trial name                                 | status   | loc                 |   episodes |\n",
      "|--------------------------------------------+----------+---------------------+------------|\n",
      "| DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000 | RUNNING  | 192.168.1.110:19542 |          0 |\n",
      "+--------------------------------------------+----------+---------------------+------------+\n",
      "\n",
      "\n",
      "Result for DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000:\n",
      "  agent_timesteps_total: 35904\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-25_18-26-46\n",
      "  done: false\n",
      "  episode_len_mean: .nan\n",
      "  episode_media: {}\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 0\n",
      "  experiment_id: d7c9d60e82b747cb85777bd6138148e5\n",
      "  hostname: wadaboa-work.local\n",
      "  info:\n",
      "    last_target_update_ts: 35904\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_lr: 0.0005\n",
      "          grad_gnorm: 0.04598112031817436\n",
      "          max_q: 6.029916286468506\n",
      "          mean_q: 3.9160234928131104\n",
      "          mean_td_error: 0.024680979549884796\n",
      "          min_q: 1.8416892290115356\n",
      "        model: {}\n",
      "        td_error: \"[ 0.24699044 -0.10758758 -0.01122093  0.3625598   0.5083518   0.21958876\\n\\\n",
      "          \\ -0.29616284 -0.11938643 -0.0062778   0.23567915  0.1560545   0.02244401\\n\\\n",
      "          \\  1.019578   -0.187783    0.10171986 -0.01696301 -0.05831861 -0.06602383\\n\\\n",
      "          \\  0.00916886 -0.1874764  -0.31291676 -0.2261858  -0.01418853 -0.38656032\\n\\\n",
      "          \\ -0.06635785 -0.04640734 -0.11860943 -0.06813097 -0.09863043 -0.05701375\\n\\\n",
      "          \\  0.03424859  0.3256092 ]\"\n",
      "    num_agent_steps_sampled: 35904\n",
      "    num_agent_steps_trained: 6368\n",
      "    num_steps_sampled: 35904\n",
      "    num_steps_trained: 6368\n",
      "    num_target_updates: 67\n",
      "  iterations_since_restore: 34\n",
      "  node_ip: 192.168.1.110\n",
      "  num_healthy_workers: 4\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 9.62\n",
      "    ram_util_percent: 63.7\n",
      "  pid: 19542\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "  time_since_restore: 109.62900471687317\n",
      "  time_this_iter_s: 3.7682900428771973\n",
      "  time_total_s: 109.62900471687317\n",
      "  timers:\n",
      "    learn_throughput: 6604.488\n",
      "    learn_time_ms: 4.845\n",
      "    update_time_ms: 8.499\n",
      "  timestamp: 1629908806\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 35904\n",
      "  training_iteration: 34\n",
      "  trial_id: fbba6_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 10.3/16.0 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 5.0/16 CPUs, 0/0 GPUs, 0.0/4.34 GiB heap, 0.0/2.17 GiB objects (0.0/5.0 CPU_group_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_2_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_3_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_1_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_4_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_0_e8771a036fed53221c42d3b57c64506b)\n",
      "Result logdir: /Users/jobs/Github/cpr-appropriation/rllib_logs/DQN_2021-08-25_18-24-55\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+--------------------------------------------+----------+---------------------+------------+\n",
      "| Trial name                                 | status   | loc                 |   episodes |\n",
      "|--------------------------------------------+----------+---------------------+------------|\n",
      "| DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000 | RUNNING  | 192.168.1.110:19542 |          0 |\n",
      "+--------------------------------------------+----------+---------------------+------------+\n",
      "\n",
      "\n",
      "Result for DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000:\n",
      "  agent_timesteps_total: 38016\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-25_18-26-54\n",
      "  done: false\n",
      "  episode_len_mean: .nan\n",
      "  episode_media: {}\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 0\n",
      "  experiment_id: d7c9d60e82b747cb85777bd6138148e5\n",
      "  hostname: wadaboa-work.local\n",
      "  info:\n",
      "    last_target_update_ts: 38016\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_lr: 0.0005\n",
      "          grad_gnorm: 0.03429684415459633\n",
      "          max_q: 5.551584243774414\n",
      "          mean_q: 3.8296334743499756\n",
      "          mean_td_error: -0.005710512399673462\n",
      "          min_q: 1.5377411842346191\n",
      "        model: {}\n",
      "        td_error: \"[-0.21160603  0.10182548  0.40591097  0.13048959  0.26090932 -0.03086329\\n\\\n",
      "          \\ -0.151999    0.16159439 -0.00336647 -0.50171757  0.40309668 -0.10394788\\n\\\n",
      "          \\ -0.99332666  0.06645656  0.02407813  0.09737206  0.0605607  -0.06416941\\n\\\n",
      "          \\ -0.1349833   0.07926846  0.04298735  0.18253684  0.02048802  0.16443253\\n\\\n",
      "          \\ -0.08153534 -0.06734538  0.05591893 -0.06548381 -0.0303669   0.15559745\\n\\\n",
      "          \\  0.04419994 -0.19974875]\"\n",
      "    num_agent_steps_sampled: 38016\n",
      "    num_agent_steps_trained: 6752\n",
      "    num_steps_sampled: 38016\n",
      "    num_steps_trained: 6752\n",
      "    num_target_updates: 71\n",
      "  iterations_since_restore: 36\n",
      "  node_ip: 192.168.1.110\n",
      "  num_healthy_workers: 4\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 19.216666666666665\n",
      "    ram_util_percent: 64.16666666666667\n",
      "  pid: 19542\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "  time_since_restore: 116.94386982917786\n",
      "  time_this_iter_s: 3.571971893310547\n",
      "  time_total_s: 116.94386982917786\n",
      "  timers:\n",
      "    learn_throughput: 6363.623\n",
      "    learn_time_ms: 5.029\n",
      "    update_time_ms: 8.725\n",
      "  timestamp: 1629908814\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 38016\n",
      "  training_iteration: 36\n",
      "  trial_id: fbba6_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 18:26:57,671\tWARNING ray_trial_executor.py:709 -- Over the last 60 seconds, the Tune event loop has been backlogged processing new results. Consider increasing your period of result reporting to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 10.4/16.0 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 5.0/16 CPUs, 0/0 GPUs, 0.0/4.34 GiB heap, 0.0/2.17 GiB objects (0.0/1.0 CPU_group_3_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_2_e8771a036fed53221c42d3b57c64506b, 0.0/5.0 CPU_group_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_0_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_4_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_1_e8771a036fed53221c42d3b57c64506b)\n",
      "Result logdir: /Users/jobs/Github/cpr-appropriation/rllib_logs/DQN_2021-08-25_18-24-55\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+--------------------------------------------+----------+---------------------+------------+\n",
      "| Trial name                                 | status   | loc                 |   episodes |\n",
      "|--------------------------------------------+----------+---------------------+------------|\n",
      "| DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000 | RUNNING  | 192.168.1.110:19542 |          0 |\n",
      "+--------------------------------------------+----------+---------------------+------------+\n",
      "\n",
      "\n",
      "Result for DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000:\n",
      "  agent_timesteps_total: 40128\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-25_18-27-01\n",
      "  done: false\n",
      "  episode_len_mean: .nan\n",
      "  episode_media: {}\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 0\n",
      "  experiment_id: d7c9d60e82b747cb85777bd6138148e5\n",
      "  hostname: wadaboa-work.local\n",
      "  info:\n",
      "    last_target_update_ts: 40128\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_lr: 0.0005\n",
      "          grad_gnorm: 0.03564537316560745\n",
      "          max_q: 5.736888408660889\n",
      "          mean_q: 4.047093868255615\n",
      "          mean_td_error: 0.010831385850906372\n",
      "          min_q: 2.2527856826782227\n",
      "        model: {}\n",
      "        td_error: \"[ 0.261724    0.06264448 -0.8220992   0.05600262 -0.11791706  0.14949656\\n\\\n",
      "          \\  0.07432318 -0.0175724   0.09678984  0.17832613 -0.6945791  -0.09660959\\n\\\n",
      "          \\  0.06925774 -0.02387404  0.04611015  0.0412724   0.03909445 -0.22276449\\n\\\n",
      "          \\ -0.03377581 -0.01091886  0.3203702   0.20688629  0.7958603   0.4147892\\n\\\n",
      "          \\  0.24602437 -0.10874844  0.15807629  0.07902384 -0.66813207  0.05930781\\n\\\n",
      "          \\ -0.21698833  0.02520394]\"\n",
      "    num_agent_steps_sampled: 40128\n",
      "    num_agent_steps_trained: 7136\n",
      "    num_steps_sampled: 40128\n",
      "    num_steps_trained: 7136\n",
      "    num_target_updates: 75\n",
      "  iterations_since_restore: 38\n",
      "  node_ip: 192.168.1.110\n",
      "  num_healthy_workers: 4\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.633333333333336\n",
      "    ram_util_percent: 64.66666666666667\n",
      "  pid: 19542\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "  time_since_restore: 123.95046281814575\n",
      "  time_this_iter_s: 3.564903974533081\n",
      "  time_total_s: 123.95046281814575\n",
      "  timers:\n",
      "    learn_throughput: 6556.866\n",
      "    learn_time_ms: 4.88\n",
      "    update_time_ms: 8.544\n",
      "  timestamp: 1629908821\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 40128\n",
      "  training_iteration: 38\n",
      "  trial_id: fbba6_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/wadaboa/cpr-appropriation/c7685_00000/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/wadaboa/cpr-appropriation/c7685_00000/file_stream\n",
      "NoneType: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 10.4/16.0 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 5.0/16 CPUs, 0/0 GPUs, 0.0/4.34 GiB heap, 0.0/2.17 GiB objects (0.0/1.0 CPU_group_3_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_2_e8771a036fed53221c42d3b57c64506b, 0.0/5.0 CPU_group_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_0_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_4_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_1_e8771a036fed53221c42d3b57c64506b)\n",
      "Result logdir: /Users/jobs/Github/cpr-appropriation/rllib_logs/DQN_2021-08-25_18-24-55\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+--------------------------------------------+----------+---------------------+------------+\n",
      "| Trial name                                 | status   | loc                 |   episodes |\n",
      "|--------------------------------------------+----------+---------------------+------------|\n",
      "| DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000 | RUNNING  | 192.168.1.110:19542 |          0 |\n",
      "+--------------------------------------------+----------+---------------------+------------+\n",
      "\n",
      "\n",
      "Result for DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000:\n",
      "  agent_timesteps_total: 42240\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-25_18-27-08\n",
      "  done: false\n",
      "  episode_len_mean: .nan\n",
      "  episode_media: {}\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 0\n",
      "  experiment_id: d7c9d60e82b747cb85777bd6138148e5\n",
      "  hostname: wadaboa-work.local\n",
      "  info:\n",
      "    last_target_update_ts: 42240\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_lr: 0.0005\n",
      "          grad_gnorm: 0.03920012712478638\n",
      "          max_q: 6.607676029205322\n",
      "          mean_q: 4.29514217376709\n",
      "          mean_td_error: 0.05925743281841278\n",
      "          min_q: 2.480858564376831\n",
      "        model: {}\n",
      "        td_error: \"[ 0.04839087 -0.01052332  0.17535257  0.0759964   0.11274719 -0.01135349\\n\\\n",
      "          \\  0.01139998  0.04962063  0.08388329  0.03860712 -0.20760846 -0.07951736\\n\\\n",
      "          \\ -0.00271058  0.37299013  0.15310287  0.02598381 -0.01605129  0.497756\\n\\\n",
      "          \\  0.09456301  0.02216291  0.08691788 -0.00367332  0.09538436  0.07269669\\n\\\n",
      "          \\ -0.03981781 -0.00209713 -0.10013485 -0.07098818  0.13114548  0.10677028\\n\\\n",
      "          \\  0.11529875  0.06994343]\"\n",
      "    num_agent_steps_sampled: 42240\n",
      "    num_agent_steps_trained: 7520\n",
      "    num_steps_sampled: 42240\n",
      "    num_steps_trained: 7520\n",
      "    num_target_updates: 79\n",
      "  iterations_since_restore: 40\n",
      "  node_ip: 192.168.1.110\n",
      "  num_healthy_workers: 4\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.48\n",
      "    ram_util_percent: 65.04\n",
      "  pid: 19542\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "  time_since_restore: 131.3633098602295\n",
      "  time_this_iter_s: 3.8337631225585938\n",
      "  time_total_s: 131.3633098602295\n",
      "  timers:\n",
      "    learn_throughput: 6611.45\n",
      "    learn_time_ms: 4.84\n",
      "    update_time_ms: 28.194\n",
      "  timestamp: 1629908828\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 42240\n",
      "  training_iteration: 40\n",
      "  trial_id: fbba6_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 10.4/16.0 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 5.0/16 CPUs, 0/0 GPUs, 0.0/4.34 GiB heap, 0.0/2.17 GiB objects (0.0/1.0 CPU_group_4_e8771a036fed53221c42d3b57c64506b, 0.0/5.0 CPU_group_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_0_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_2_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_1_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_3_e8771a036fed53221c42d3b57c64506b)\n",
      "Result logdir: /Users/jobs/Github/cpr-appropriation/rllib_logs/DQN_2021-08-25_18-24-55\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+--------------------------------------------+----------+---------------------+------------+\n",
      "| Trial name                                 | status   | loc                 |   episodes |\n",
      "|--------------------------------------------+----------+---------------------+------------|\n",
      "| DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000 | RUNNING  | 192.168.1.110:19542 |          0 |\n",
      "+--------------------------------------------+----------+---------------------+------------+\n",
      "\n",
      "\n",
      "Result for DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000:\n",
      "  agent_timesteps_total: 44352\n",
      "  custom_metrics:\n",
      "    efficiency_max: 14.113454545454545\n",
      "    efficiency_mean: 12.149250000000002\n",
      "    efficiency_min: 9.667545454545454\n",
      "    equality_max: 0.8014564330750137\n",
      "    equality_mean: 0.7843113128085738\n",
      "    equality_min: 0.7537295725673683\n",
      "    peace_max: 413.36109090909093\n",
      "    peace_mean: 397.76486363636366\n",
      "    peace_min: 385.05518181818184\n",
      "    sustainability_max: 240.71902484348544\n",
      "    sustainability_mean: 237.58475215400577\n",
      "    sustainability_min: 233.5863895068592\n",
      "  date: 2021-08-25_18-27-16\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 308.0\n",
      "  episode_reward_mean: 270.75\n",
      "  episode_reward_min: 230.0\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 4\n",
      "  experiment_id: d7c9d60e82b747cb85777bd6138148e5\n",
      "  hostname: wadaboa-work.local\n",
      "  info:\n",
      "    last_target_update_ts: 44352\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_lr: 0.0005\n",
      "          grad_gnorm: 0.053097423166036606\n",
      "          max_q: 5.826778411865234\n",
      "          mean_q: 4.442168712615967\n",
      "          mean_td_error: -0.03795153647661209\n",
      "          min_q: 2.8065290451049805\n",
      "        model: {}\n",
      "        td_error: \"[-0.7580385   0.02941465 -0.6209426  -0.08438873 -0.6862302  -0.00799751\\n\\\n",
      "          \\ -0.5423937  -0.0527873  -0.01376605 -0.03930664  0.02475762  0.27336287\\n\\\n",
      "          \\ -0.49843645  0.21036673  0.03126383 -0.13427496 -0.05569124  0.25718522\\n\\\n",
      "          \\ -0.07624769 -0.01087904  0.4154868  -0.13620496 -0.01815891 -0.02736664\\n\\\n",
      "          \\  0.03982258 -0.08511734  0.00438261  0.03640294  0.14434576  0.8222866\\n\\\n",
      "          \\  0.45810914 -0.11340809]\"\n",
      "    num_agent_steps_sampled: 44352\n",
      "    num_agent_steps_trained: 7904\n",
      "    num_steps_sampled: 44352\n",
      "    num_steps_trained: 7904\n",
      "    num_target_updates: 83\n",
      "  iterations_since_restore: 42\n",
      "  node_ip: 192.168.1.110\n",
      "  num_healthy_workers: 4\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 10.040000000000001\n",
      "    ram_util_percent: 65.1\n",
      "  pid: 19542\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.21398427819591329\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 25.216117781855544\n",
      "    mean_inference_ms: 1.5377956410229383\n",
      "    mean_raw_obs_processing_ms: 4.6629880890028685\n",
      "  time_since_restore: 138.72006058692932\n",
      "  time_this_iter_s: 3.4429986476898193\n",
      "  time_total_s: 138.72006058692932\n",
      "  timers:\n",
      "    learn_throughput: 6561.931\n",
      "    learn_time_ms: 4.877\n",
      "    update_time_ms: 8.447\n",
      "  timestamp: 1629908836\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 44352\n",
      "  training_iteration: 42\n",
      "  trial_id: fbba6_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 10.4/16.0 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 5.0/16 CPUs, 0/0 GPUs, 0.0/4.34 GiB heap, 0.0/2.17 GiB objects (0.0/1.0 CPU_group_0_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_4_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_2_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_1_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_3_e8771a036fed53221c42d3b57c64506b, 0.0/5.0 CPU_group_e8771a036fed53221c42d3b57c64506b)\n",
      "Result logdir: /Users/jobs/Github/cpr-appropriation/rllib_logs/DQN_2021-08-25_18-24-55\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+--------------------------------------------+----------+---------------------+------------+---------+----------+---------+---------+\n",
      "| Trial name                                 | status   | loc                 |   episodes |       U |        E |       S |       P |\n",
      "|--------------------------------------------+----------+---------------------+------------+---------+----------+---------+---------|\n",
      "| DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000 | RUNNING  | 192.168.1.110:19542 |          4 | 12.1493 | 0.784311 | 237.585 | 397.765 |\n",
      "+--------------------------------------------+----------+---------------------+------------+---------+----------+---------+---------+\n",
      "\n",
      "\n",
      "Result for DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000:\n",
      "  agent_timesteps_total: 46464\n",
      "  custom_metrics:\n",
      "    efficiency_max: 14.113454545454545\n",
      "    efficiency_mean: 12.149250000000002\n",
      "    efficiency_min: 9.667545454545454\n",
      "    equality_max: 0.8014564330750137\n",
      "    equality_mean: 0.7843113128085738\n",
      "    equality_min: 0.7537295725673683\n",
      "    peace_max: 413.36109090909093\n",
      "    peace_mean: 397.76486363636366\n",
      "    peace_min: 385.05518181818184\n",
      "    sustainability_max: 240.71902484348544\n",
      "    sustainability_mean: 237.58475215400577\n",
      "    sustainability_min: 233.5863895068592\n",
      "  date: 2021-08-25_18-27-21\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 308.0\n",
      "  episode_reward_mean: 270.75\n",
      "  episode_reward_min: 230.0\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 4\n",
      "  experiment_id: d7c9d60e82b747cb85777bd6138148e5\n",
      "  hostname: wadaboa-work.local\n",
      "  info:\n",
      "    last_target_update_ts: 46464\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_lr: 0.0005\n",
      "          grad_gnorm: 0.05522799864411354\n",
      "          max_q: 6.249037265777588\n",
      "          mean_q: 4.456928253173828\n",
      "          mean_td_error: 0.012332983314990997\n",
      "          min_q: 2.1941211223602295\n",
      "        model: {}\n",
      "        td_error: \"[ 0.12353992  0.7536001  -0.0179348   0.04312277  0.48282862  0.14974594\\n\\\n",
      "          \\  0.36607265 -0.01814795  0.12932014 -0.19702578  0.08726168 -0.79242325\\n\\\n",
      "          \\ -0.6896329   0.00108552  0.08625603 -0.30672503  0.07418036 -0.08378291\\n\\\n",
      "          \\  0.09274769 -0.01433849 -0.32031012  0.32826185 -0.08841753  0.00798082\\n\\\n",
      "          \\  0.11569738 -0.6250982   0.08625603 -0.7344103   0.12724733  0.12879038\\n\\\n",
      "          \\  1.0277834   0.07112408]\"\n",
      "    num_agent_steps_sampled: 46464\n",
      "    num_agent_steps_trained: 8288\n",
      "    num_steps_sampled: 46464\n",
      "    num_steps_trained: 8288\n",
      "    num_target_updates: 87\n",
      "  iterations_since_restore: 44\n",
      "  node_ip: 192.168.1.110\n",
      "  num_healthy_workers: 4\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 12.024999999999999\n",
      "    ram_util_percent: 65.2\n",
      "  pid: 19542\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.21398427819591329\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 25.216117781855544\n",
      "    mean_inference_ms: 1.5377956410229383\n",
      "    mean_raw_obs_processing_ms: 4.6629880890028685\n",
      "  time_since_restore: 143.69877123832703\n",
      "  time_this_iter_s: 2.6272037029266357\n",
      "  time_total_s: 143.69877123832703\n",
      "  timers:\n",
      "    learn_throughput: 6408.93\n",
      "    learn_time_ms: 4.993\n",
      "    update_time_ms: 8.447\n",
      "  timestamp: 1629908841\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 46464\n",
      "  training_iteration: 44\n",
      "  trial_id: fbba6_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 10.3/16.0 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 5.0/16 CPUs, 0/0 GPUs, 0.0/4.34 GiB heap, 0.0/2.17 GiB objects (0.0/1.0 CPU_group_0_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_4_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_2_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_1_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_3_e8771a036fed53221c42d3b57c64506b, 0.0/5.0 CPU_group_e8771a036fed53221c42d3b57c64506b)\n",
      "Result logdir: /Users/jobs/Github/cpr-appropriation/rllib_logs/DQN_2021-08-25_18-24-55\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+--------------------------------------------+----------+---------------------+------------+---------+----------+---------+---------+\n",
      "| Trial name                                 | status   | loc                 |   episodes |       U |        E |       S |       P |\n",
      "|--------------------------------------------+----------+---------------------+------------+---------+----------+---------+---------|\n",
      "| DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000 | RUNNING  | 192.168.1.110:19542 |          4 | 12.1493 | 0.784311 | 237.585 | 397.765 |\n",
      "+--------------------------------------------+----------+---------------------+------------+---------+----------+---------+---------+\n",
      "\n",
      "\n",
      "Result for DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000:\n",
      "  agent_timesteps_total: 48576\n",
      "  custom_metrics:\n",
      "    efficiency_max: 14.113454545454545\n",
      "    efficiency_mean: 12.149250000000002\n",
      "    efficiency_min: 9.667545454545454\n",
      "    equality_max: 0.8014564330750137\n",
      "    equality_mean: 0.7843113128085738\n",
      "    equality_min: 0.7537295725673683\n",
      "    peace_max: 413.36109090909093\n",
      "    peace_mean: 397.76486363636366\n",
      "    peace_min: 385.05518181818184\n",
      "    sustainability_max: 240.71902484348544\n",
      "    sustainability_mean: 237.58475215400577\n",
      "    sustainability_min: 233.5863895068592\n",
      "  date: 2021-08-25_18-27-27\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 308.0\n",
      "  episode_reward_mean: 270.75\n",
      "  episode_reward_min: 230.0\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 4\n",
      "  experiment_id: d7c9d60e82b747cb85777bd6138148e5\n",
      "  hostname: wadaboa-work.local\n",
      "  info:\n",
      "    last_target_update_ts: 48576\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_lr: 0.0005\n",
      "          grad_gnorm: 0.04911111295223236\n",
      "          max_q: 6.47182035446167\n",
      "          mean_q: 4.548064708709717\n",
      "          mean_td_error: -0.053860895335674286\n",
      "          min_q: 2.180297613143921\n",
      "        model: {}\n",
      "        td_error: \"[-0.0064733   0.00313568 -0.0166626  -0.03998518 -0.02304935  0.20653582\\n\\\n",
      "          \\ -0.08938122 -0.31667995 -0.25534678  0.06048107  0.4165659   0.19493961\\n\\\n",
      "          \\  0.19144297  0.02914071 -0.09813213 -0.12489271  0.14621115 -0.10514879\\n\\\n",
      "          \\ -0.2062025   0.26754856 -0.01395655 -0.11436033 -0.6817274   0.0931325\\n\\\n",
      "          \\ -0.7029915  -0.08753991  0.28474617 -0.13795137  0.11857367 -0.5324688\\n\\\n",
      "          \\ -0.1842432   0.00119114]\"\n",
      "    num_agent_steps_sampled: 48576\n",
      "    num_agent_steps_trained: 8672\n",
      "    num_steps_sampled: 48576\n",
      "    num_steps_trained: 8672\n",
      "    num_target_updates: 91\n",
      "  iterations_since_restore: 46\n",
      "  node_ip: 192.168.1.110\n",
      "  num_healthy_workers: 4\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 10.424999999999999\n",
      "    ram_util_percent: 65.15\n",
      "  pid: 19542\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.21398427819591329\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 25.216117781855544\n",
      "    mean_inference_ms: 1.5377956410229383\n",
      "    mean_raw_obs_processing_ms: 4.6629880890028685\n",
      "  time_since_restore: 148.80114912986755\n",
      "  time_this_iter_s: 2.5317118167877197\n",
      "  time_total_s: 148.80114912986755\n",
      "  timers:\n",
      "    learn_throughput: 6559.846\n",
      "    learn_time_ms: 4.878\n",
      "    update_time_ms: 8.514\n",
      "  timestamp: 1629908847\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 48576\n",
      "  training_iteration: 46\n",
      "  trial_id: fbba6_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 10.3/16.0 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 5.0/16 CPUs, 0/0 GPUs, 0.0/4.34 GiB heap, 0.0/2.17 GiB objects (0.0/1.0 CPU_group_1_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_3_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_2_e8771a036fed53221c42d3b57c64506b, 0.0/5.0 CPU_group_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_4_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_0_e8771a036fed53221c42d3b57c64506b)\n",
      "Result logdir: /Users/jobs/Github/cpr-appropriation/rllib_logs/DQN_2021-08-25_18-24-55\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+--------------------------------------------+----------+---------------------+------------+---------+----------+---------+---------+\n",
      "| Trial name                                 | status   | loc                 |   episodes |       U |        E |       S |       P |\n",
      "|--------------------------------------------+----------+---------------------+------------+---------+----------+---------+---------|\n",
      "| DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000 | RUNNING  | 192.168.1.110:19542 |          4 | 12.1493 | 0.784311 | 237.585 | 397.765 |\n",
      "+--------------------------------------------+----------+---------------------+------------+---------+----------+---------+---------+\n",
      "\n",
      "\n",
      "Result for DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000:\n",
      "  agent_timesteps_total: 50688\n",
      "  custom_metrics:\n",
      "    efficiency_max: 14.113454545454545\n",
      "    efficiency_mean: 12.149250000000002\n",
      "    efficiency_min: 9.667545454545454\n",
      "    equality_max: 0.8014564330750137\n",
      "    equality_mean: 0.7843113128085738\n",
      "    equality_min: 0.7537295725673683\n",
      "    peace_max: 413.36109090909093\n",
      "    peace_mean: 397.76486363636366\n",
      "    peace_min: 385.05518181818184\n",
      "    sustainability_max: 240.71902484348544\n",
      "    sustainability_mean: 237.58475215400577\n",
      "    sustainability_min: 233.5863895068592\n",
      "  date: 2021-08-25_18-27-34\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 308.0\n",
      "  episode_reward_mean: 270.75\n",
      "  episode_reward_min: 230.0\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 4\n",
      "  experiment_id: d7c9d60e82b747cb85777bd6138148e5\n",
      "  hostname: wadaboa-work.local\n",
      "  info:\n",
      "    last_target_update_ts: 50688\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_lr: 0.0005\n",
      "          grad_gnorm: 0.07229096442461014\n",
      "          max_q: 7.157270908355713\n",
      "          mean_q: 5.10531759262085\n",
      "          mean_td_error: 0.09261689335107803\n",
      "          min_q: 2.9209561347961426\n",
      "        model: {}\n",
      "        td_error: \"[-0.11401796  0.25992298 -0.02366352 -0.27626848  0.3450265   0.31798625\\n\\\n",
      "          \\  0.19093752  0.45714712  0.13243008  0.1533885   0.04120922  0.14388847\\n\\\n",
      "          \\  0.33798456  0.2722745   0.00410724  0.18505955  0.17762041  0.6299467\\n\\\n",
      "          \\  0.18106174 -1.0486898   0.08556461  1.1888094  -0.08106971 -0.29606676\\n\\\n",
      "          \\ -0.0331502   0.14646292 -0.31655812  0.11482     0.14431    -0.06498361\\n\\\n",
      "          \\ -0.6588259   0.3670764 ]\"\n",
      "    num_agent_steps_sampled: 50688\n",
      "    num_agent_steps_trained: 9056\n",
      "    num_steps_sampled: 50688\n",
      "    num_steps_trained: 9056\n",
      "    num_target_updates: 95\n",
      "  iterations_since_restore: 48\n",
      "  node_ip: 192.168.1.110\n",
      "  num_healthy_workers: 4\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 4.175\n",
      "    ram_util_percent: 64.375\n",
      "  pid: 19542\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.21398427819591329\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 25.216117781855544\n",
      "    mean_inference_ms: 1.5377956410229383\n",
      "    mean_raw_obs_processing_ms: 4.6629880890028685\n",
      "  time_since_restore: 154.2950201034546\n",
      "  time_this_iter_s: 2.8322110176086426\n",
      "  time_total_s: 154.2950201034546\n",
      "  timers:\n",
      "    learn_throughput: 5993.843\n",
      "    learn_time_ms: 5.339\n",
      "    update_time_ms: 9.022\n",
      "  timestamp: 1629908854\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 50688\n",
      "  training_iteration: 48\n",
      "  trial_id: fbba6_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/wadaboa/cpr-appropriation/c7685_00000/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/wadaboa/cpr-appropriation/c7685_00000/file_stream\n",
      "NoneType: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 10.4/16.0 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 5.0/16 CPUs, 0/0 GPUs, 0.0/4.34 GiB heap, 0.0/2.17 GiB objects (0.0/1.0 CPU_group_1_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_3_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_2_e8771a036fed53221c42d3b57c64506b, 0.0/5.0 CPU_group_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_4_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_0_e8771a036fed53221c42d3b57c64506b)\n",
      "Result logdir: /Users/jobs/Github/cpr-appropriation/rllib_logs/DQN_2021-08-25_18-24-55\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+--------------------------------------------+----------+---------------------+------------+---------+----------+---------+---------+\n",
      "| Trial name                                 | status   | loc                 |   episodes |       U |        E |       S |       P |\n",
      "|--------------------------------------------+----------+---------------------+------------+---------+----------+---------+---------|\n",
      "| DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000 | RUNNING  | 192.168.1.110:19542 |          4 | 12.1493 | 0.784311 | 237.585 | 397.765 |\n",
      "+--------------------------------------------+----------+---------------------+------------+---------+----------+---------+---------+\n",
      "\n",
      "\n",
      "Result for DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000:\n",
      "  agent_timesteps_total: 52800\n",
      "  custom_metrics:\n",
      "    efficiency_max: 14.113454545454545\n",
      "    efficiency_mean: 12.149250000000002\n",
      "    efficiency_min: 9.667545454545454\n",
      "    equality_max: 0.8014564330750137\n",
      "    equality_mean: 0.7843113128085738\n",
      "    equality_min: 0.7537295725673683\n",
      "    peace_max: 413.36109090909093\n",
      "    peace_mean: 397.76486363636366\n",
      "    peace_min: 385.05518181818184\n",
      "    sustainability_max: 240.71902484348544\n",
      "    sustainability_mean: 237.58475215400577\n",
      "    sustainability_min: 233.5863895068592\n",
      "  date: 2021-08-25_18-27-40\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 308.0\n",
      "  episode_reward_mean: 270.75\n",
      "  episode_reward_min: 230.0\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 4\n",
      "  experiment_id: d7c9d60e82b747cb85777bd6138148e5\n",
      "  hostname: wadaboa-work.local\n",
      "  info:\n",
      "    last_target_update_ts: 52800\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_lr: 0.0005\n",
      "          grad_gnorm: 0.08094267547130585\n",
      "          max_q: 8.30867862701416\n",
      "          mean_q: 5.996456623077393\n",
      "          mean_td_error: 0.11233033984899521\n",
      "          min_q: 3.3759119510650635\n",
      "        model: {}\n",
      "        td_error: \"[-0.03944016  0.05952978 -0.10396624  0.07981396 -0.3235464  -0.05918074\\n\\\n",
      "          \\  0.06420755 -0.0672946   0.04769683  0.4242742   0.07309103  0.01327944\\n\\\n",
      "          \\  0.06481409  0.16648674  0.06786156  0.7710366   0.5760069   0.47023058\\n\\\n",
      "          \\  0.07666636  0.45365858 -0.10844994 -0.11558819  0.43283176  0.02138329\\n\\\n",
      "          \\ -0.12226629 -0.10359645  0.3934083   0.41782904 -0.09496546 -0.06687832\\n\\\n",
      "          \\  0.0590992   0.06653786]\"\n",
      "    num_agent_steps_sampled: 52800\n",
      "    num_agent_steps_trained: 9440\n",
      "    num_steps_sampled: 52800\n",
      "    num_steps_trained: 9440\n",
      "    num_target_updates: 99\n",
      "  iterations_since_restore: 50\n",
      "  node_ip: 192.168.1.110\n",
      "  num_healthy_workers: 4\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 20.78\n",
      "    ram_util_percent: 64.6\n",
      "  pid: 19542\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.21398427819591329\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 25.216117781855544\n",
      "    mean_inference_ms: 1.5377956410229383\n",
      "    mean_raw_obs_processing_ms: 4.6629880890028685\n",
      "  time_since_restore: 160.03170919418335\n",
      "  time_this_iter_s: 2.955981969833374\n",
      "  time_total_s: 160.03170919418335\n",
      "  timers:\n",
      "    learn_throughput: 6331.861\n",
      "    learn_time_ms: 5.054\n",
      "    update_time_ms: 8.768\n",
      "  timestamp: 1629908860\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 52800\n",
      "  training_iteration: 50\n",
      "  trial_id: fbba6_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 10.4/16.0 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 5.0/16 CPUs, 0/0 GPUs, 0.0/4.34 GiB heap, 0.0/2.17 GiB objects (0.0/1.0 CPU_group_3_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_1_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_4_e8771a036fed53221c42d3b57c64506b, 0.0/5.0 CPU_group_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_0_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_2_e8771a036fed53221c42d3b57c64506b)\n",
      "Result logdir: /Users/jobs/Github/cpr-appropriation/rllib_logs/DQN_2021-08-25_18-24-55\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+--------------------------------------------+----------+---------------------+------------+---------+----------+---------+---------+\n",
      "| Trial name                                 | status   | loc                 |   episodes |       U |        E |       S |       P |\n",
      "|--------------------------------------------+----------+---------------------+------------+---------+----------+---------+---------|\n",
      "| DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000 | RUNNING  | 192.168.1.110:19542 |          4 | 12.1493 | 0.784311 | 237.585 | 397.765 |\n",
      "+--------------------------------------------+----------+---------------------+------------+---------+----------+---------+---------+\n",
      "\n",
      "\n",
      "Result for DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000:\n",
      "  agent_timesteps_total: 54912\n",
      "  custom_metrics:\n",
      "    efficiency_max: 14.113454545454545\n",
      "    efficiency_mean: 12.149250000000002\n",
      "    efficiency_min: 9.667545454545454\n",
      "    equality_max: 0.8014564330750137\n",
      "    equality_mean: 0.7843113128085738\n",
      "    equality_min: 0.7537295725673683\n",
      "    peace_max: 413.36109090909093\n",
      "    peace_mean: 397.76486363636366\n",
      "    peace_min: 385.05518181818184\n",
      "    sustainability_max: 240.71902484348544\n",
      "    sustainability_mean: 237.58475215400577\n",
      "    sustainability_min: 233.5863895068592\n",
      "  date: 2021-08-25_18-27-47\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 308.0\n",
      "  episode_reward_mean: 270.75\n",
      "  episode_reward_min: 230.0\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 4\n",
      "  experiment_id: d7c9d60e82b747cb85777bd6138148e5\n",
      "  hostname: wadaboa-work.local\n",
      "  info:\n",
      "    last_target_update_ts: 54912\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_lr: 0.0005\n",
      "          grad_gnorm: 0.06828629970550537\n",
      "          max_q: 8.39697551727295\n",
      "          mean_q: 6.260633945465088\n",
      "          mean_td_error: 0.0887267217040062\n",
      "          min_q: 3.5013179779052734\n",
      "        model: {}\n",
      "        td_error: \"[-0.4225073   0.09831095 -0.05672026  0.00938797  0.05624485  0.04857588\\n\\\n",
      "          \\  0.26898575  0.07855558 -0.36355305  0.39228344  0.07148647  0.33720064\\n\\\n",
      "          \\  0.10951757  0.12947655 -0.00086641 -0.0367527   0.04984474  0.03513813\\n\\\n",
      "          \\ -0.13364363  0.61511326  0.32614756  0.2999103   0.3062153  -0.42513466\\n\\\n",
      "          \\ -0.20878744  0.06719351  0.10546303 -0.03620338  0.15573406  0.5648837\\n\\\n",
      "          \\  0.27718925  0.12056541]\"\n",
      "    num_agent_steps_sampled: 54912\n",
      "    num_agent_steps_trained: 9824\n",
      "    num_steps_sampled: 54912\n",
      "    num_steps_trained: 9824\n",
      "    num_target_updates: 103\n",
      "  iterations_since_restore: 52\n",
      "  node_ip: 192.168.1.110\n",
      "  num_healthy_workers: 4\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 9.78\n",
      "    ram_util_percent: 64.78\n",
      "  pid: 19542\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.21398427819591329\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 25.216117781855544\n",
      "    mean_inference_ms: 1.5377956410229383\n",
      "    mean_raw_obs_processing_ms: 4.6629880890028685\n",
      "  time_since_restore: 165.89444732666016\n",
      "  time_this_iter_s: 2.9397799968719482\n",
      "  time_total_s: 165.89444732666016\n",
      "  timers:\n",
      "    learn_throughput: 6276.931\n",
      "    learn_time_ms: 5.098\n",
      "    update_time_ms: 8.686\n",
      "  timestamp: 1629908867\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 54912\n",
      "  training_iteration: 52\n",
      "  trial_id: fbba6_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 10.4/16.0 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 5.0/16 CPUs, 0/0 GPUs, 0.0/4.34 GiB heap, 0.0/2.17 GiB objects (0.0/1.0 CPU_group_3_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_1_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_4_e8771a036fed53221c42d3b57c64506b, 0.0/5.0 CPU_group_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_0_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_2_e8771a036fed53221c42d3b57c64506b)\n",
      "Result logdir: /Users/jobs/Github/cpr-appropriation/rllib_logs/DQN_2021-08-25_18-24-55\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+--------------------------------------------+----------+---------------------+------------+---------+----------+---------+---------+\n",
      "| Trial name                                 | status   | loc                 |   episodes |       U |        E |       S |       P |\n",
      "|--------------------------------------------+----------+---------------------+------------+---------+----------+---------+---------|\n",
      "| DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000 | RUNNING  | 192.168.1.110:19542 |          4 | 12.1493 | 0.784311 | 237.585 | 397.765 |\n",
      "+--------------------------------------------+----------+---------------------+------------+---------+----------+---------+---------+\n",
      "\n",
      "\n",
      "Result for DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000:\n",
      "  agent_timesteps_total: 57024\n",
      "  custom_metrics:\n",
      "    efficiency_max: 14.113454545454545\n",
      "    efficiency_mean: 12.149250000000002\n",
      "    efficiency_min: 9.667545454545454\n",
      "    equality_max: 0.8014564330750137\n",
      "    equality_mean: 0.7843113128085738\n",
      "    equality_min: 0.7537295725673683\n",
      "    peace_max: 413.36109090909093\n",
      "    peace_mean: 397.76486363636366\n",
      "    peace_min: 385.05518181818184\n",
      "    sustainability_max: 240.71902484348544\n",
      "    sustainability_mean: 237.58475215400577\n",
      "    sustainability_min: 233.5863895068592\n",
      "  date: 2021-08-25_18-27-54\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 308.0\n",
      "  episode_reward_mean: 270.75\n",
      "  episode_reward_min: 230.0\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 4\n",
      "  experiment_id: d7c9d60e82b747cb85777bd6138148e5\n",
      "  hostname: wadaboa-work.local\n",
      "  info:\n",
      "    last_target_update_ts: 57024\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_lr: 0.0005\n",
      "          grad_gnorm: 0.053153105080127716\n",
      "          max_q: 8.73456859588623\n",
      "          mean_q: 6.465262413024902\n",
      "          mean_td_error: -0.020482823252677917\n",
      "          min_q: 3.808089256286621\n",
      "        model: {}\n",
      "        td_error: \"[ 0.10123301  0.3418169   0.4646814  -0.0495677   0.14405203  0.02940559\\n\\\n",
      "          \\ -0.2618971  -0.7265935   0.17754602 -0.29108238 -0.9139962   0.5064869\\n\\\n",
      "          \\ -0.05074596 -0.19715929 -0.11093473 -0.25388527  0.11975718 -0.00249481\\n\\\n",
      "          \\ -0.36896992 -0.01691246 -0.05041313  0.199996    0.08414102 -0.20729685\\n\\\n",
      "          \\  0.19583035  0.7358899   0.10252714  0.09016371 -0.06781483  0.14142418\\n\\\n",
      "          \\ -0.4188137  -0.10182381]\"\n",
      "    num_agent_steps_sampled: 57024\n",
      "    num_agent_steps_trained: 10208\n",
      "    num_steps_sampled: 57024\n",
      "    num_steps_trained: 10208\n",
      "    num_target_updates: 107\n",
      "  iterations_since_restore: 54\n",
      "  node_ip: 192.168.1.110\n",
      "  num_healthy_workers: 4\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 17.52\n",
      "    ram_util_percent: 65.11999999999999\n",
      "  pid: 19542\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.21398427819591329\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 25.216117781855544\n",
      "    mean_inference_ms: 1.5377956410229383\n",
      "    mean_raw_obs_processing_ms: 4.6629880890028685\n",
      "  time_since_restore: 171.94594717025757\n",
      "  time_this_iter_s: 3.037418842315674\n",
      "  time_total_s: 171.94594717025757\n",
      "  timers:\n",
      "    learn_throughput: 5970.991\n",
      "    learn_time_ms: 5.359\n",
      "    update_time_ms: 8.823\n",
      "  timestamp: 1629908874\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 57024\n",
      "  training_iteration: 54\n",
      "  trial_id: fbba6_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 18:27:58,347\tWARNING ray_trial_executor.py:709 -- Over the last 60 seconds, the Tune event loop has been backlogged processing new results. Consider increasing your period of result reporting to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 10.5/16.0 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 5.0/16 CPUs, 0/0 GPUs, 0.0/4.34 GiB heap, 0.0/2.17 GiB objects (0.0/1.0 CPU_group_4_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_2_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_1_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_0_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_3_e8771a036fed53221c42d3b57c64506b, 0.0/5.0 CPU_group_e8771a036fed53221c42d3b57c64506b)\n",
      "Result logdir: /Users/jobs/Github/cpr-appropriation/rllib_logs/DQN_2021-08-25_18-24-55\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+--------------------------------------------+----------+---------------------+------------+---------+----------+---------+---------+\n",
      "| Trial name                                 | status   | loc                 |   episodes |       U |        E |       S |       P |\n",
      "|--------------------------------------------+----------+---------------------+------------+---------+----------+---------+---------|\n",
      "| DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000 | RUNNING  | 192.168.1.110:19542 |          4 | 12.1493 | 0.784311 | 237.585 | 397.765 |\n",
      "+--------------------------------------------+----------+---------------------+------------+---------+----------+---------+---------+\n",
      "\n",
      "\n",
      "Result for DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000:\n",
      "  agent_timesteps_total: 59136\n",
      "  custom_metrics:\n",
      "    efficiency_max: 14.113454545454545\n",
      "    efficiency_mean: 12.149250000000002\n",
      "    efficiency_min: 9.667545454545454\n",
      "    equality_max: 0.8014564330750137\n",
      "    equality_mean: 0.7843113128085738\n",
      "    equality_min: 0.7537295725673683\n",
      "    peace_max: 413.36109090909093\n",
      "    peace_mean: 397.76486363636366\n",
      "    peace_min: 385.05518181818184\n",
      "    sustainability_max: 240.71902484348544\n",
      "    sustainability_mean: 237.58475215400577\n",
      "    sustainability_min: 233.5863895068592\n",
      "  date: 2021-08-25_18-28-02\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 308.0\n",
      "  episode_reward_mean: 270.75\n",
      "  episode_reward_min: 230.0\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 4\n",
      "  experiment_id: d7c9d60e82b747cb85777bd6138148e5\n",
      "  hostname: wadaboa-work.local\n",
      "  info:\n",
      "    last_target_update_ts: 59136\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_lr: 0.0005\n",
      "          grad_gnorm: 0.04000116139650345\n",
      "          max_q: 10.112065315246582\n",
      "          mean_q: 6.887290954589844\n",
      "          mean_td_error: -0.031093835830688477\n",
      "          min_q: 3.942087411880493\n",
      "        model: {}\n",
      "        td_error: \"[ 0.05852222 -0.13534927  0.10242796  0.01268005  0.08731413  0.02907658\\n\\\n",
      "          \\  0.3393774   0.37807178  0.08278894 -0.00796556 -0.07862425 -0.34057808\\n\\\n",
      "          \\ -0.06614304  0.38366604 -0.04829168 -0.3757205  -0.15302563 -0.00931931\\n\\\n",
      "          \\  0.0838356  -0.21362114  0.1702404  -0.29956532 -0.03606129 -0.10915279\\n\\\n",
      "          \\ -0.9332013  -0.09766197  0.13317966 -0.02571678 -0.35825443  0.13228464\\n\\\n",
      "          \\ -0.00122452  0.3010087 ]\"\n",
      "    num_agent_steps_sampled: 59136\n",
      "    num_agent_steps_trained: 10592\n",
      "    num_steps_sampled: 59136\n",
      "    num_steps_trained: 10592\n",
      "    num_target_updates: 111\n",
      "  iterations_since_restore: 56\n",
      "  node_ip: 192.168.1.110\n",
      "  num_healthy_workers: 4\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 13.771428571428572\n",
      "    ram_util_percent: 65.54285714285716\n",
      "  pid: 19542\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.21398427819591329\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 25.216117781855544\n",
      "    mean_inference_ms: 1.5377956410229383\n",
      "    mean_raw_obs_processing_ms: 4.6629880890028685\n",
      "  time_since_restore: 179.41103315353394\n",
      "  time_this_iter_s: 4.086851119995117\n",
      "  time_total_s: 179.41103315353394\n",
      "  timers:\n",
      "    learn_throughput: 5683.628\n",
      "    learn_time_ms: 5.63\n",
      "    update_time_ms: 9.45\n",
      "  timestamp: 1629908882\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 59136\n",
      "  training_iteration: 56\n",
      "  trial_id: fbba6_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/wadaboa/cpr-appropriation/c7685_00000/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/wadaboa/cpr-appropriation/c7685_00000/file_stream\n",
      "NoneType: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 10.5/16.0 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 5.0/16 CPUs, 0/0 GPUs, 0.0/4.34 GiB heap, 0.0/2.17 GiB objects (0.0/1.0 CPU_group_2_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_3_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_1_e8771a036fed53221c42d3b57c64506b, 0.0/5.0 CPU_group_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_4_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_0_e8771a036fed53221c42d3b57c64506b)\n",
      "Result logdir: /Users/jobs/Github/cpr-appropriation/rllib_logs/DQN_2021-08-25_18-24-55\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+--------------------------------------------+----------+---------------------+------------+---------+----------+---------+---------+\n",
      "| Trial name                                 | status   | loc                 |   episodes |       U |        E |       S |       P |\n",
      "|--------------------------------------------+----------+---------------------+------------+---------+----------+---------+---------|\n",
      "| DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000 | RUNNING  | 192.168.1.110:19542 |          4 | 12.1493 | 0.784311 | 237.585 | 397.765 |\n",
      "+--------------------------------------------+----------+---------------------+------------+---------+----------+---------+---------+\n",
      "\n",
      "\n",
      "Result for DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000:\n",
      "  agent_timesteps_total: 61248\n",
      "  custom_metrics:\n",
      "    efficiency_max: 14.113454545454545\n",
      "    efficiency_mean: 12.149250000000002\n",
      "    efficiency_min: 9.667545454545454\n",
      "    equality_max: 0.8014564330750137\n",
      "    equality_mean: 0.7843113128085738\n",
      "    equality_min: 0.7537295725673683\n",
      "    peace_max: 413.36109090909093\n",
      "    peace_mean: 397.76486363636366\n",
      "    peace_min: 385.05518181818184\n",
      "    sustainability_max: 240.71902484348544\n",
      "    sustainability_mean: 237.58475215400577\n",
      "    sustainability_min: 233.5863895068592\n",
      "  date: 2021-08-25_18-28-12\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 308.0\n",
      "  episode_reward_mean: 270.75\n",
      "  episode_reward_min: 230.0\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 4\n",
      "  experiment_id: d7c9d60e82b747cb85777bd6138148e5\n",
      "  hostname: wadaboa-work.local\n",
      "  info:\n",
      "    last_target_update_ts: 61248\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_lr: 0.0005\n",
      "          grad_gnorm: 0.09367815405130386\n",
      "          max_q: 10.35258674621582\n",
      "          mean_q: 7.82531213760376\n",
      "          mean_td_error: 0.07786343991756439\n",
      "          min_q: 5.015626430511475\n",
      "        model: {}\n",
      "        td_error: \"[ 1.0206437  -0.50739145 -0.41880894  0.20266819 -0.02915001  0.4655714\\n\\\n",
      "          \\  0.14061737  0.96252155 -0.12362909 -0.88537455 -0.12362909  0.589838\\n\\\n",
      "          \\ -0.21268177 -0.02056217  0.69255495 -0.20777893  0.04468536  0.15047169\\n\\\n",
      "          \\  0.07319784 -0.22837067 -0.24982452 -0.13565922  0.47382307  0.12904501\\n\\\n",
      "          \\  0.17234755  0.8391676  -0.4039507   1.486598   -0.22652626 -1.2224274\\n\\\n",
      "          \\  0.12854433 -0.08490086]\"\n",
      "    num_agent_steps_sampled: 61248\n",
      "    num_agent_steps_trained: 10976\n",
      "    num_steps_sampled: 61248\n",
      "    num_steps_trained: 10976\n",
      "    num_target_updates: 115\n",
      "  iterations_since_restore: 58\n",
      "  node_ip: 192.168.1.110\n",
      "  num_healthy_workers: 4\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 18.271428571428572\n",
      "    ram_util_percent: 65.82857142857142\n",
      "  pid: 19542\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.21398427819591329\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 25.216117781855544\n",
      "    mean_inference_ms: 1.5377956410229383\n",
      "    mean_raw_obs_processing_ms: 4.6629880890028685\n",
      "  time_since_restore: 187.83127331733704\n",
      "  time_this_iter_s: 4.14150595664978\n",
      "  time_total_s: 187.83127331733704\n",
      "  timers:\n",
      "    learn_throughput: 5654.963\n",
      "    learn_time_ms: 5.659\n",
      "    update_time_ms: 9.447\n",
      "  timestamp: 1629908892\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 61248\n",
      "  training_iteration: 58\n",
      "  trial_id: fbba6_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 10.5/16.0 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 5.0/16 CPUs, 0/0 GPUs, 0.0/4.34 GiB heap, 0.0/2.17 GiB objects (0.0/1.0 CPU_group_2_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_3_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_1_e8771a036fed53221c42d3b57c64506b, 0.0/5.0 CPU_group_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_4_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_0_e8771a036fed53221c42d3b57c64506b)\n",
      "Result logdir: /Users/jobs/Github/cpr-appropriation/rllib_logs/DQN_2021-08-25_18-24-55\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+--------------------------------------------+----------+---------------------+------------+---------+----------+---------+---------+\n",
      "| Trial name                                 | status   | loc                 |   episodes |       U |        E |       S |       P |\n",
      "|--------------------------------------------+----------+---------------------+------------+---------+----------+---------+---------|\n",
      "| DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000 | RUNNING  | 192.168.1.110:19542 |          4 | 12.1493 | 0.784311 | 237.585 | 397.765 |\n",
      "+--------------------------------------------+----------+---------------------+------------+---------+----------+---------+---------+\n",
      "\n",
      "\n",
      "Result for DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000:\n",
      "  agent_timesteps_total: 63360\n",
      "  custom_metrics:\n",
      "    efficiency_max: 14.113454545454545\n",
      "    efficiency_mean: 12.149250000000002\n",
      "    efficiency_min: 9.667545454545454\n",
      "    equality_max: 0.8014564330750137\n",
      "    equality_mean: 0.7843113128085738\n",
      "    equality_min: 0.7537295725673683\n",
      "    peace_max: 413.36109090909093\n",
      "    peace_mean: 397.76486363636366\n",
      "    peace_min: 385.05518181818184\n",
      "    sustainability_max: 240.71902484348544\n",
      "    sustainability_mean: 237.58475215400577\n",
      "    sustainability_min: 233.5863895068592\n",
      "  date: 2021-08-25_18-28-21\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 308.0\n",
      "  episode_reward_mean: 270.75\n",
      "  episode_reward_min: 230.0\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 4\n",
      "  experiment_id: d7c9d60e82b747cb85777bd6138148e5\n",
      "  hostname: wadaboa-work.local\n",
      "  info:\n",
      "    last_target_update_ts: 63360\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_lr: 0.0005\n",
      "          grad_gnorm: 0.06647098064422607\n",
      "          max_q: 11.469524383544922\n",
      "          mean_q: 7.63248348236084\n",
      "          mean_td_error: -0.028212130069732666\n",
      "          min_q: 5.015789031982422\n",
      "        model: {}\n",
      "        td_error: \"[-1.5473104e+00  1.8856335e-01  5.9280872e-02  2.6343203e-01\\n  1.6458511e-01\\\n",
      "          \\ -8.8400841e-03  8.5642815e-02  2.4311972e-01\\n -1.4191151e-02 -2.2111416e-01\\\n",
      "          \\ -1.2645721e-03 -3.5547256e-02\\n  1.9264460e-01  1.9750500e-01  5.4844856e-02\\\n",
      "          \\ -3.5769939e-02\\n  6.5208340e-01  4.0032387e-02 -1.0660124e-01 -4.0757942e-01\\n\\\n",
      "          \\ -3.7659883e-01 -3.2931614e-01 -7.3272657e-01  1.9979334e-01\\n -4.4942856e-02\\\n",
      "          \\  1.9287395e-01  4.6041965e-01  4.9898815e-01\\n -7.2619057e-01 -1.3394451e-01\\\n",
      "          \\  1.6518593e-01  1.6015434e-01]\"\n",
      "    num_agent_steps_sampled: 63360\n",
      "    num_agent_steps_trained: 11360\n",
      "    num_steps_sampled: 63360\n",
      "    num_steps_trained: 11360\n",
      "    num_target_updates: 119\n",
      "  iterations_since_restore: 60\n",
      "  node_ip: 192.168.1.110\n",
      "  num_healthy_workers: 4\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 12.214285714285714\n",
      "    ram_util_percent: 65.50000000000001\n",
      "  pid: 19542\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.21398427819591329\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 25.216117781855544\n",
      "    mean_inference_ms: 1.5377956410229383\n",
      "    mean_raw_obs_processing_ms: 4.6629880890028685\n",
      "  time_since_restore: 196.64575266838074\n",
      "  time_this_iter_s: 4.35951828956604\n",
      "  time_total_s: 196.64575266838074\n",
      "  timers:\n",
      "    learn_throughput: 5828.508\n",
      "    learn_time_ms: 5.49\n",
      "    update_time_ms: 9.407\n",
      "  timestamp: 1629908901\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 63360\n",
      "  training_iteration: 60\n",
      "  trial_id: fbba6_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 10.5/16.0 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 5.0/16 CPUs, 0/0 GPUs, 0.0/4.34 GiB heap, 0.0/2.17 GiB objects (0.0/5.0 CPU_group_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_0_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_2_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_3_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_4_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_1_e8771a036fed53221c42d3b57c64506b)\n",
      "Result logdir: /Users/jobs/Github/cpr-appropriation/rllib_logs/DQN_2021-08-25_18-24-55\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+--------------------------------------------+----------+---------------------+------------+---------+----------+---------+---------+\n",
      "| Trial name                                 | status   | loc                 |   episodes |       U |        E |       S |       P |\n",
      "|--------------------------------------------+----------+---------------------+------------+---------+----------+---------+---------|\n",
      "| DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000 | RUNNING  | 192.168.1.110:19542 |          4 | 12.1493 | 0.784311 | 237.585 | 397.765 |\n",
      "+--------------------------------------------+----------+---------------------+------------+---------+----------+---------+---------+\n",
      "\n",
      "\n",
      "Result for DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000:\n",
      "  agent_timesteps_total: 65472\n",
      "  custom_metrics:\n",
      "    efficiency_max: 14.113454545454545\n",
      "    efficiency_mean: 12.149250000000002\n",
      "    efficiency_min: 9.667545454545454\n",
      "    equality_max: 0.8014564330750137\n",
      "    equality_mean: 0.7843113128085738\n",
      "    equality_min: 0.7537295725673683\n",
      "    peace_max: 413.36109090909093\n",
      "    peace_mean: 397.76486363636366\n",
      "    peace_min: 385.05518181818184\n",
      "    sustainability_max: 240.71902484348544\n",
      "    sustainability_mean: 237.58475215400577\n",
      "    sustainability_min: 233.5863895068592\n",
      "  date: 2021-08-25_18-28-31\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 308.0\n",
      "  episode_reward_mean: 270.75\n",
      "  episode_reward_min: 230.0\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 4\n",
      "  experiment_id: d7c9d60e82b747cb85777bd6138148e5\n",
      "  hostname: wadaboa-work.local\n",
      "  info:\n",
      "    last_target_update_ts: 65472\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_lr: 0.0005\n",
      "          grad_gnorm: 0.07585969567298889\n",
      "          max_q: 10.82002067565918\n",
      "          mean_q: 7.473562240600586\n",
      "          mean_td_error: 0.2079625427722931\n",
      "          min_q: 4.449249744415283\n",
      "        model: {}\n",
      "        td_error: \"[-1.07424736e-01  2.08416462e-01  2.91815758e-01 -2.99077988e-01\\n\\\n",
      "          \\  6.97652149e+00  5.60607910e-02  6.48913383e-02  4.02135849e-02\\n -1.34758472e-01\\\n",
      "          \\  6.38479710e-01 -9.29676056e-01 -1.53038025e-01\\n -3.36066246e-01  1.06005192e-01\\\n",
      "          \\ -1.68126583e-01  9.45495605e-01\\n  3.56855392e-02 -5.45978546e-03 -9.13615227e-02\\\n",
      "          \\  1.56885147e-01\\n -1.37877464e-02  2.31524944e-01  5.07555962e-01 -2.04005241e-01\\n\\\n",
      "          \\ -1.83705807e-01  2.65446663e-01 -1.98309422e-01  1.02789879e-01\\n -6.68454170e-01\\\n",
      "          \\ -2.97451019e-01 -3.64079475e-02 -1.45875931e-01]\"\n",
      "    num_agent_steps_sampled: 65472\n",
      "    num_agent_steps_trained: 11744\n",
      "    num_steps_sampled: 65472\n",
      "    num_steps_trained: 11744\n",
      "    num_target_updates: 123\n",
      "  iterations_since_restore: 62\n",
      "  node_ip: 192.168.1.110\n",
      "  num_healthy_workers: 4\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 11.099999999999998\n",
      "    ram_util_percent: 65.39999999999999\n",
      "  pid: 19542\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.21398427819591329\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 25.216117781855544\n",
      "    mean_inference_ms: 1.5377956410229383\n",
      "    mean_raw_obs_processing_ms: 4.6629880890028685\n",
      "  time_since_restore: 205.69451379776\n",
      "  time_this_iter_s: 4.640399217605591\n",
      "  time_total_s: 205.69451379776\n",
      "  timers:\n",
      "    learn_throughput: 5797.366\n",
      "    learn_time_ms: 5.52\n",
      "    update_time_ms: 9.287\n",
      "  timestamp: 1629908911\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 65472\n",
      "  training_iteration: 62\n",
      "  trial_id: fbba6_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/wadaboa/cpr-appropriation/c7685_00000/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/wadaboa/cpr-appropriation/c7685_00000/file_stream\n",
      "NoneType: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 10.5/16.0 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 5.0/16 CPUs, 0/0 GPUs, 0.0/4.34 GiB heap, 0.0/2.17 GiB objects (0.0/1.0 CPU_group_3_e8771a036fed53221c42d3b57c64506b, 0.0/5.0 CPU_group_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_1_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_2_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_0_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_4_e8771a036fed53221c42d3b57c64506b)\n",
      "Result logdir: /Users/jobs/Github/cpr-appropriation/rllib_logs/DQN_2021-08-25_18-24-55\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+--------------------------------------------+----------+---------------------+------------+---------+----------+---------+---------+\n",
      "| Trial name                                 | status   | loc                 |   episodes |       U |        E |       S |       P |\n",
      "|--------------------------------------------+----------+---------------------+------------+---------+----------+---------+---------|\n",
      "| DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000 | RUNNING  | 192.168.1.110:19542 |          4 | 12.1493 | 0.784311 | 237.585 | 397.765 |\n",
      "+--------------------------------------------+----------+---------------------+------------+---------+----------+---------+---------+\n",
      "\n",
      "\n",
      "Result for DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000:\n",
      "  agent_timesteps_total: 67584\n",
      "  custom_metrics:\n",
      "    efficiency_max: 14.113454545454545\n",
      "    efficiency_mean: 12.149250000000002\n",
      "    efficiency_min: 9.667545454545454\n",
      "    equality_max: 0.8014564330750137\n",
      "    equality_mean: 0.7843113128085738\n",
      "    equality_min: 0.7537295725673683\n",
      "    peace_max: 413.36109090909093\n",
      "    peace_mean: 397.76486363636366\n",
      "    peace_min: 385.05518181818184\n",
      "    sustainability_max: 240.71902484348544\n",
      "    sustainability_mean: 237.58475215400577\n",
      "    sustainability_min: 233.5863895068592\n",
      "  date: 2021-08-25_18-28-41\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 308.0\n",
      "  episode_reward_mean: 270.75\n",
      "  episode_reward_min: 230.0\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 4\n",
      "  experiment_id: d7c9d60e82b747cb85777bd6138148e5\n",
      "  hostname: wadaboa-work.local\n",
      "  info:\n",
      "    last_target_update_ts: 67584\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_lr: 0.0005\n",
      "          grad_gnorm: 0.08843914419412613\n",
      "          max_q: 12.61108684539795\n",
      "          mean_q: 8.93011474609375\n",
      "          mean_td_error: -0.061099499464035034\n",
      "          min_q: 5.983036041259766\n",
      "        model: {}\n",
      "        td_error: \"[ 0.0747776   0.13745403  0.08276701 -0.1596508  -0.05471992 -1.244792\\n\\\n",
      "          \\  0.12719536 -0.7859411  -0.02249146 -0.03107452 -0.37295532 -0.2637415\\n\\\n",
      "          \\  0.06406975  1.1667919   0.02953243  0.3324108   0.19303846  0.09865856\\n\\\n",
      "          \\  0.04353905  0.13232851  0.06869316 -0.5622549   0.05864716 -0.11750793\\n\\\n",
      "          \\  0.0551796  -0.23346996  0.05511475 -0.11596918 -0.39539146 -0.30598736\\n\\\n",
      "          \\  0.05243397 -0.06186867]\"\n",
      "    num_agent_steps_sampled: 67584\n",
      "    num_agent_steps_trained: 12128\n",
      "    num_steps_sampled: 67584\n",
      "    num_steps_trained: 12128\n",
      "    num_target_updates: 127\n",
      "  iterations_since_restore: 64\n",
      "  node_ip: 192.168.1.110\n",
      "  num_healthy_workers: 4\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 14.950000000000003\n",
      "    ram_util_percent: 65.71666666666667\n",
      "  pid: 19542\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.21398427819591329\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 25.216117781855544\n",
      "    mean_inference_ms: 1.5377956410229383\n",
      "    mean_raw_obs_processing_ms: 4.6629880890028685\n",
      "  time_since_restore: 213.96305465698242\n",
      "  time_this_iter_s: 4.044502019882202\n",
      "  time_total_s: 213.96305465698242\n",
      "  timers:\n",
      "    learn_throughput: 5957.977\n",
      "    learn_time_ms: 5.371\n",
      "    update_time_ms: 9.09\n",
      "  timestamp: 1629908921\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 67584\n",
      "  training_iteration: 64\n",
      "  trial_id: fbba6_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 10.6/16.0 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 5.0/16 CPUs, 0/0 GPUs, 0.0/4.34 GiB heap, 0.0/2.17 GiB objects (0.0/1.0 CPU_group_1_e8771a036fed53221c42d3b57c64506b, 0.0/5.0 CPU_group_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_2_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_4_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_3_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_0_e8771a036fed53221c42d3b57c64506b)\n",
      "Result logdir: /Users/jobs/Github/cpr-appropriation/rllib_logs/DQN_2021-08-25_18-24-55\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+--------------------------------------------+----------+---------------------+------------+---------+----------+---------+---------+\n",
      "| Trial name                                 | status   | loc                 |   episodes |       U |        E |       S |       P |\n",
      "|--------------------------------------------+----------+---------------------+------------+---------+----------+---------+---------|\n",
      "| DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000 | RUNNING  | 192.168.1.110:19542 |          4 | 12.1493 | 0.784311 | 237.585 | 397.765 |\n",
      "+--------------------------------------------+----------+---------------------+------------+---------+----------+---------+---------+\n",
      "\n",
      "\n",
      "Result for DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000:\n",
      "  agent_timesteps_total: 69696\n",
      "  custom_metrics:\n",
      "    efficiency_max: 14.113454545454545\n",
      "    efficiency_mean: 12.149250000000002\n",
      "    efficiency_min: 9.667545454545454\n",
      "    equality_max: 0.8014564330750137\n",
      "    equality_mean: 0.7843113128085738\n",
      "    equality_min: 0.7537295725673683\n",
      "    peace_max: 413.36109090909093\n",
      "    peace_mean: 397.76486363636366\n",
      "    peace_min: 385.05518181818184\n",
      "    sustainability_max: 240.71902484348544\n",
      "    sustainability_mean: 237.58475215400577\n",
      "    sustainability_min: 233.5863895068592\n",
      "  date: 2021-08-25_18-28-50\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 308.0\n",
      "  episode_reward_mean: 270.75\n",
      "  episode_reward_min: 230.0\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 4\n",
      "  experiment_id: d7c9d60e82b747cb85777bd6138148e5\n",
      "  hostname: wadaboa-work.local\n",
      "  info:\n",
      "    last_target_update_ts: 69696\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_lr: 0.0005\n",
      "          grad_gnorm: 0.06200317665934563\n",
      "          max_q: 11.99581527709961\n",
      "          mean_q: 8.407721519470215\n",
      "          mean_td_error: -0.042635008692741394\n",
      "          min_q: 4.373549938201904\n",
      "        model: {}\n",
      "        td_error: \"[-0.21549892  0.6055517   0.041399   -0.05997753  0.00470448 -0.9419756\\n\\\n",
      "          \\ -0.1226778  -0.01952648 -0.15015316 -0.11073303  0.2837534   0.05289936\\n\\\n",
      "          \\  0.24948788 -0.21700859 -0.86541605  0.13169384  0.11810207  0.01445103\\n\\\n",
      "          \\ -0.21753025  0.02353907  0.18216228 -0.1503706  -0.05911875 -0.46750355\\n\\\n",
      "          \\  0.6256237  -1.5411816   0.0878377   0.64322186  0.29453373 -0.08071613\\n\\\n",
      "          \\  0.21417665  0.28192997]\"\n",
      "    num_agent_steps_sampled: 69696\n",
      "    num_agent_steps_trained: 12512\n",
      "    num_steps_sampled: 69696\n",
      "    num_steps_trained: 12512\n",
      "    num_target_updates: 131\n",
      "  iterations_since_restore: 66\n",
      "  node_ip: 192.168.1.110\n",
      "  num_healthy_workers: 4\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 14.77142857142857\n",
      "    ram_util_percent: 65.92857142857143\n",
      "  pid: 19542\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.21398427819591329\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 25.216117781855544\n",
      "    mean_inference_ms: 1.5377956410229383\n",
      "    mean_raw_obs_processing_ms: 4.6629880890028685\n",
      "  time_since_restore: 222.00087642669678\n",
      "  time_this_iter_s: 3.952529191970825\n",
      "  time_total_s: 222.00087642669678\n",
      "  timers:\n",
      "    learn_throughput: 6313.068\n",
      "    learn_time_ms: 5.069\n",
      "    update_time_ms: 8.682\n",
      "  timestamp: 1629908930\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 69696\n",
      "  training_iteration: 66\n",
      "  trial_id: fbba6_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 18:28:59,235\tWARNING ray_trial_executor.py:709 -- Over the last 60 seconds, the Tune event loop has been backlogged processing new results. Consider increasing your period of result reporting to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 10.5/16.0 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 5.0/16 CPUs, 0/0 GPUs, 0.0/4.34 GiB heap, 0.0/2.17 GiB objects (0.0/1.0 CPU_group_1_e8771a036fed53221c42d3b57c64506b, 0.0/5.0 CPU_group_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_2_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_4_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_3_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_0_e8771a036fed53221c42d3b57c64506b)\n",
      "Result logdir: /Users/jobs/Github/cpr-appropriation/rllib_logs/DQN_2021-08-25_18-24-55\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+--------------------------------------------+----------+---------------------+------------+---------+----------+---------+---------+\n",
      "| Trial name                                 | status   | loc                 |   episodes |       U |        E |       S |       P |\n",
      "|--------------------------------------------+----------+---------------------+------------+---------+----------+---------+---------|\n",
      "| DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000 | RUNNING  | 192.168.1.110:19542 |          4 | 12.1493 | 0.784311 | 237.585 | 397.765 |\n",
      "+--------------------------------------------+----------+---------------------+------------+---------+----------+---------+---------+\n",
      "\n",
      "\n",
      "Result for DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000:\n",
      "  agent_timesteps_total: 71808\n",
      "  custom_metrics:\n",
      "    efficiency_max: 14.113454545454545\n",
      "    efficiency_mean: 12.149250000000002\n",
      "    efficiency_min: 9.667545454545454\n",
      "    equality_max: 0.8014564330750137\n",
      "    equality_mean: 0.7843113128085738\n",
      "    equality_min: 0.7537295725673683\n",
      "    peace_max: 413.36109090909093\n",
      "    peace_mean: 397.76486363636366\n",
      "    peace_min: 385.05518181818184\n",
      "    sustainability_max: 240.71902484348544\n",
      "    sustainability_mean: 237.58475215400577\n",
      "    sustainability_min: 233.5863895068592\n",
      "  date: 2021-08-25_18-28-59\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 308.0\n",
      "  episode_reward_mean: 270.75\n",
      "  episode_reward_min: 230.0\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 4\n",
      "  experiment_id: d7c9d60e82b747cb85777bd6138148e5\n",
      "  hostname: wadaboa-work.local\n",
      "  info:\n",
      "    last_target_update_ts: 71808\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_lr: 0.0005\n",
      "          grad_gnorm: 0.09185178577899933\n",
      "          max_q: 13.449151039123535\n",
      "          mean_q: 8.919370651245117\n",
      "          mean_td_error: 0.07635815441608429\n",
      "          min_q: 5.9970550537109375\n",
      "        model: {}\n",
      "        td_error: \"[ 0.71350765  0.01286697  0.8015213  -0.18881226 -0.3335848   0.23949718\\n\\\n",
      "          \\  0.08790445  0.05664253  0.01578712  0.7611623   0.08989906  0.01463032\\n\\\n",
      "          \\ -0.1165905  -0.6279392   0.06796837  0.44270134  0.03594112  0.28213453\\n\\\n",
      "          \\ -0.0199337  -0.30969524  0.14626503  0.07277632 -0.14110756  0.04992723\\n\\\n",
      "          \\  0.13269043  0.09117985  0.06355858  0.09457493  0.0251255   0.06259346\\n\\\n",
      "          \\ -0.00114441 -0.17858696]\"\n",
      "    num_agent_steps_sampled: 71808\n",
      "    num_agent_steps_trained: 12896\n",
      "    num_steps_sampled: 71808\n",
      "    num_steps_trained: 12896\n",
      "    num_target_updates: 135\n",
      "  iterations_since_restore: 68\n",
      "  node_ip: 192.168.1.110\n",
      "  num_healthy_workers: 4\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.01666666666667\n",
      "    ram_util_percent: 65.71666666666667\n",
      "  pid: 19542\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.21398427819591329\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 25.216117781855544\n",
      "    mean_inference_ms: 1.5377956410229383\n",
      "    mean_raw_obs_processing_ms: 4.6629880890028685\n",
      "  time_since_restore: 230.13284349441528\n",
      "  time_this_iter_s: 4.065195083618164\n",
      "  time_total_s: 230.13284349441528\n",
      "  timers:\n",
      "    learn_throughput: 6208.955\n",
      "    learn_time_ms: 5.154\n",
      "    update_time_ms: 8.634\n",
      "  timestamp: 1629908939\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 71808\n",
      "  training_iteration: 68\n",
      "  trial_id: fbba6_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 10.6/16.0 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 5.0/16 CPUs, 0/0 GPUs, 0.0/4.34 GiB heap, 0.0/2.17 GiB objects (0.0/1.0 CPU_group_2_e8771a036fed53221c42d3b57c64506b, 0.0/5.0 CPU_group_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_1_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_0_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_4_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_3_e8771a036fed53221c42d3b57c64506b)\n",
      "Result logdir: /Users/jobs/Github/cpr-appropriation/rllib_logs/DQN_2021-08-25_18-24-55\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+--------------------------------------------+----------+---------------------+------------+---------+----------+---------+---------+\n",
      "| Trial name                                 | status   | loc                 |   episodes |       U |        E |       S |       P |\n",
      "|--------------------------------------------+----------+---------------------+------------+---------+----------+---------+---------|\n",
      "| DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000 | RUNNING  | 192.168.1.110:19542 |          4 | 12.1493 | 0.784311 | 237.585 | 397.765 |\n",
      "+--------------------------------------------+----------+---------------------+------------+---------+----------+---------+---------+\n",
      "\n",
      "\n",
      "Result for DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000:\n",
      "  agent_timesteps_total: 73920\n",
      "  custom_metrics:\n",
      "    efficiency_max: 14.113454545454545\n",
      "    efficiency_mean: 12.149250000000002\n",
      "    efficiency_min: 9.667545454545454\n",
      "    equality_max: 0.8014564330750137\n",
      "    equality_mean: 0.7843113128085738\n",
      "    equality_min: 0.7537295725673683\n",
      "    peace_max: 413.36109090909093\n",
      "    peace_mean: 397.76486363636366\n",
      "    peace_min: 385.05518181818184\n",
      "    sustainability_max: 240.71902484348544\n",
      "    sustainability_mean: 237.58475215400577\n",
      "    sustainability_min: 233.5863895068592\n",
      "  date: 2021-08-25_18-29-08\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 308.0\n",
      "  episode_reward_mean: 270.75\n",
      "  episode_reward_min: 230.0\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 4\n",
      "  experiment_id: d7c9d60e82b747cb85777bd6138148e5\n",
      "  hostname: wadaboa-work.local\n",
      "  info:\n",
      "    last_target_update_ts: 73920\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_lr: 0.0005\n",
      "          grad_gnorm: 0.08406532555818558\n",
      "          max_q: 11.377540588378906\n",
      "          mean_q: 8.244070053100586\n",
      "          mean_td_error: -0.0805928111076355\n",
      "          min_q: 6.014036655426025\n",
      "        model: {}\n",
      "        td_error: \"[-0.10807896 -0.5521183  -0.05451679 -0.1658268  -0.09801674  0.05796623\\n\\\n",
      "          \\  0.04160213  0.02843046  0.01204205 -0.2545271   0.06004047  0.6359234\\n\\\n",
      "          \\ -0.81921005  0.90463305 -0.19427443 -0.2548113  -0.6648574   0.3794918\\n\\\n",
      "          \\ -0.3056841   0.06770325 -0.10328245 -0.10085392 -0.6056018  -0.11166906\\n\\\n",
      "          \\ -0.53132915 -0.12038612 -0.25120687 -0.03454876  0.48588848 -0.06279087\\n\\\n",
      "          \\  0.18245697 -0.04155731]\"\n",
      "    num_agent_steps_sampled: 73920\n",
      "    num_agent_steps_trained: 13280\n",
      "    num_steps_sampled: 73920\n",
      "    num_steps_trained: 13280\n",
      "    num_target_updates: 139\n",
      "  iterations_since_restore: 70\n",
      "  node_ip: 192.168.1.110\n",
      "  num_healthy_workers: 4\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 26.983333333333334\n",
      "    ram_util_percent: 65.89999999999999\n",
      "  pid: 19542\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.21398427819591329\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 25.216117781855544\n",
      "    mean_inference_ms: 1.5377956410229383\n",
      "    mean_raw_obs_processing_ms: 4.6629880890028685\n",
      "  time_since_restore: 238.21998476982117\n",
      "  time_this_iter_s: 4.053047180175781\n",
      "  time_total_s: 238.21998476982117\n",
      "  timers:\n",
      "    learn_throughput: 6232.944\n",
      "    learn_time_ms: 5.134\n",
      "    update_time_ms: 8.709\n",
      "  timestamp: 1629908948\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 73920\n",
      "  training_iteration: 70\n",
      "  trial_id: fbba6_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/wadaboa/cpr-appropriation/c7685_00000/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/wadaboa/cpr-appropriation/c7685_00000/file_stream\n",
      "NoneType: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 10.5/16.0 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 5.0/16 CPUs, 0/0 GPUs, 0.0/4.34 GiB heap, 0.0/2.17 GiB objects (0.0/5.0 CPU_group_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_4_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_1_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_2_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_0_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_3_e8771a036fed53221c42d3b57c64506b)\n",
      "Result logdir: /Users/jobs/Github/cpr-appropriation/rllib_logs/DQN_2021-08-25_18-24-55\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+--------------------------------------------+----------+---------------------+------------+---------+----------+---------+---------+\n",
      "| Trial name                                 | status   | loc                 |   episodes |       U |        E |       S |       P |\n",
      "|--------------------------------------------+----------+---------------------+------------+---------+----------+---------+---------|\n",
      "| DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000 | RUNNING  | 192.168.1.110:19542 |          4 | 12.1493 | 0.784311 | 237.585 | 397.765 |\n",
      "+--------------------------------------------+----------+---------------------+------------+---------+----------+---------+---------+\n",
      "\n",
      "\n",
      "Result for DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000:\n",
      "  agent_timesteps_total: 76032\n",
      "  custom_metrics:\n",
      "    efficiency_max: 14.113454545454545\n",
      "    efficiency_mean: 12.149250000000002\n",
      "    efficiency_min: 9.667545454545454\n",
      "    equality_max: 0.8014564330750137\n",
      "    equality_mean: 0.7843113128085738\n",
      "    equality_min: 0.7537295725673683\n",
      "    peace_max: 413.36109090909093\n",
      "    peace_mean: 397.76486363636366\n",
      "    peace_min: 385.05518181818184\n",
      "    sustainability_max: 240.71902484348544\n",
      "    sustainability_mean: 237.58475215400577\n",
      "    sustainability_min: 233.5863895068592\n",
      "  date: 2021-08-25_18-29-16\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 308.0\n",
      "  episode_reward_mean: 270.75\n",
      "  episode_reward_min: 230.0\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 4\n",
      "  experiment_id: d7c9d60e82b747cb85777bd6138148e5\n",
      "  hostname: wadaboa-work.local\n",
      "  info:\n",
      "    last_target_update_ts: 76032\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_lr: 0.0005\n",
      "          grad_gnorm: 0.10688992589712143\n",
      "          max_q: 12.532028198242188\n",
      "          mean_q: 9.629942893981934\n",
      "          mean_td_error: 0.04972304403781891\n",
      "          min_q: 6.463363170623779\n",
      "        model: {}\n",
      "        td_error: \"[ 0.5101023  -0.0254612  -0.04397821  0.26264477  0.8820009   0.30024624\\n\\\n",
      "          \\  0.03698015 -0.24960232  0.21374702 -0.729846    0.13304424  0.0792675\\n\\\n",
      "          \\ -0.5420542  -0.18328524 -0.09465504  0.08183002 -0.20630455 -0.25352097\\n\\\n",
      "          \\  1.0345659   0.11776161  0.1043663   0.3726759  -0.10967636 -0.09706783\\n\\\n",
      "          \\ -0.06301594 -0.35084724  0.04211521  0.06236124  0.0907979   0.22678852\\n\\\n",
      "          \\ -0.3139534   0.30311012]\"\n",
      "    num_agent_steps_sampled: 76032\n",
      "    num_agent_steps_trained: 13664\n",
      "    num_steps_sampled: 76032\n",
      "    num_steps_trained: 13664\n",
      "    num_target_updates: 143\n",
      "  iterations_since_restore: 72\n",
      "  node_ip: 192.168.1.110\n",
      "  num_healthy_workers: 4\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.428571428571427\n",
      "    ram_util_percent: 65.6\n",
      "  pid: 19542\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.21398427819591329\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 25.216117781855544\n",
      "    mean_inference_ms: 1.5377956410229383\n",
      "    mean_raw_obs_processing_ms: 4.6629880890028685\n",
      "  time_since_restore: 246.1639528274536\n",
      "  time_this_iter_s: 3.997058153152466\n",
      "  time_total_s: 246.1639528274536\n",
      "  timers:\n",
      "    learn_throughput: 6260.827\n",
      "    learn_time_ms: 5.111\n",
      "    update_time_ms: 8.649\n",
      "  timestamp: 1629908956\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 76032\n",
      "  training_iteration: 72\n",
      "  trial_id: fbba6_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 10.6/16.0 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 5.0/16 CPUs, 0/0 GPUs, 0.0/4.34 GiB heap, 0.0/2.17 GiB objects (0.0/5.0 CPU_group_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_4_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_1_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_2_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_0_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_3_e8771a036fed53221c42d3b57c64506b)\n",
      "Result logdir: /Users/jobs/Github/cpr-appropriation/rllib_logs/DQN_2021-08-25_18-24-55\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+--------------------------------------------+----------+---------------------+------------+---------+----------+---------+---------+\n",
      "| Trial name                                 | status   | loc                 |   episodes |       U |        E |       S |       P |\n",
      "|--------------------------------------------+----------+---------------------+------------+---------+----------+---------+---------|\n",
      "| DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000 | RUNNING  | 192.168.1.110:19542 |          4 | 12.1493 | 0.784311 | 237.585 | 397.765 |\n",
      "+--------------------------------------------+----------+---------------------+------------+---------+----------+---------+---------+\n",
      "\n",
      "\n",
      "Result for DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000:\n",
      "  agent_timesteps_total: 78144\n",
      "  custom_metrics:\n",
      "    efficiency_max: 14.113454545454545\n",
      "    efficiency_mean: 12.149250000000002\n",
      "    efficiency_min: 9.667545454545454\n",
      "    equality_max: 0.8014564330750137\n",
      "    equality_mean: 0.7843113128085738\n",
      "    equality_min: 0.7537295725673683\n",
      "    peace_max: 413.36109090909093\n",
      "    peace_mean: 397.76486363636366\n",
      "    peace_min: 385.05518181818184\n",
      "    sustainability_max: 240.71902484348544\n",
      "    sustainability_mean: 237.58475215400577\n",
      "    sustainability_min: 233.5863895068592\n",
      "  date: 2021-08-25_18-29-26\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 308.0\n",
      "  episode_reward_mean: 270.75\n",
      "  episode_reward_min: 230.0\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 4\n",
      "  experiment_id: d7c9d60e82b747cb85777bd6138148e5\n",
      "  hostname: wadaboa-work.local\n",
      "  info:\n",
      "    last_target_update_ts: 78144\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_lr: 0.0005\n",
      "          grad_gnorm: 0.07955240458250046\n",
      "          max_q: 15.022932052612305\n",
      "          mean_q: 10.134115219116211\n",
      "          mean_td_error: 0.01241426169872284\n",
      "          min_q: 6.846157073974609\n",
      "        model: {}\n",
      "        td_error: \"[ 0.3085575   0.25216007  0.26152802  0.7738104  -0.11493587 -0.14271736\\n\\\n",
      "          \\  0.6590748  -0.06467819  0.22048378 -0.05865955  0.23591137  0.26794243\\n\\\n",
      "          \\ -0.40284824 -0.42447853 -0.0713644   0.01075172 -0.64142084  0.01618099\\n\\\n",
      "          \\ -0.08537674 -0.16692543  0.04381657 -0.6432495   0.5635586  -0.65201473\\n\\\n",
      "          \\ -0.26432037  0.1571579  -0.15088367  0.0840559  -0.21897697 -0.0525341\\n\\\n",
      "          \\  0.29707623  0.40057468]\"\n",
      "    num_agent_steps_sampled: 78144\n",
      "    num_agent_steps_trained: 14048\n",
      "    num_steps_sampled: 78144\n",
      "    num_steps_trained: 14048\n",
      "    num_target_updates: 147\n",
      "  iterations_since_restore: 74\n",
      "  node_ip: 192.168.1.110\n",
      "  num_healthy_workers: 4\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 11.471428571428573\n",
      "    ram_util_percent: 66.14285714285715\n",
      "  pid: 19542\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.21398427819591329\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 25.216117781855544\n",
      "    mean_inference_ms: 1.5377956410229383\n",
      "    mean_raw_obs_processing_ms: 4.6629880890028685\n",
      "  time_since_restore: 254.65198183059692\n",
      "  time_this_iter_s: 4.310745000839233\n",
      "  time_total_s: 254.65198183059692\n",
      "  timers:\n",
      "    learn_throughput: 6367.941\n",
      "    learn_time_ms: 5.025\n",
      "    update_time_ms: 8.624\n",
      "  timestamp: 1629908966\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 78144\n",
      "  training_iteration: 74\n",
      "  trial_id: fbba6_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 10.6/16.0 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 5.0/16 CPUs, 0/0 GPUs, 0.0/4.34 GiB heap, 0.0/2.17 GiB objects (0.0/1.0 CPU_group_4_e8771a036fed53221c42d3b57c64506b, 0.0/5.0 CPU_group_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_1_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_0_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_2_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_3_e8771a036fed53221c42d3b57c64506b)\n",
      "Result logdir: /Users/jobs/Github/cpr-appropriation/rllib_logs/DQN_2021-08-25_18-24-55\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+--------------------------------------------+----------+---------------------+------------+---------+----------+---------+---------+\n",
      "| Trial name                                 | status   | loc                 |   episodes |       U |        E |       S |       P |\n",
      "|--------------------------------------------+----------+---------------------+------------+---------+----------+---------+---------|\n",
      "| DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000 | RUNNING  | 192.168.1.110:19542 |          4 | 12.1493 | 0.784311 | 237.585 | 397.765 |\n",
      "+--------------------------------------------+----------+---------------------+------------+---------+----------+---------+---------+\n",
      "\n",
      "\n",
      "Result for DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000:\n",
      "  agent_timesteps_total: 80256\n",
      "  custom_metrics:\n",
      "    efficiency_max: 14.113454545454545\n",
      "    efficiency_mean: 12.149250000000002\n",
      "    efficiency_min: 9.667545454545454\n",
      "    equality_max: 0.8014564330750137\n",
      "    equality_mean: 0.7843113128085738\n",
      "    equality_min: 0.7537295725673683\n",
      "    peace_max: 413.36109090909093\n",
      "    peace_mean: 397.76486363636366\n",
      "    peace_min: 385.05518181818184\n",
      "    sustainability_max: 240.71902484348544\n",
      "    sustainability_mean: 237.58475215400577\n",
      "    sustainability_min: 233.5863895068592\n",
      "  date: 2021-08-25_18-29-35\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 308.0\n",
      "  episode_reward_mean: 270.75\n",
      "  episode_reward_min: 230.0\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 4\n",
      "  experiment_id: d7c9d60e82b747cb85777bd6138148e5\n",
      "  hostname: wadaboa-work.local\n",
      "  info:\n",
      "    last_target_update_ts: 80256\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_lr: 0.0005\n",
      "          grad_gnorm: 0.27180859446525574\n",
      "          max_q: 14.455888748168945\n",
      "          mean_q: 10.604389190673828\n",
      "          mean_td_error: 0.1947394609451294\n",
      "          min_q: 7.001914978027344\n",
      "        model: {}\n",
      "        td_error: \"[ 0.07517672  0.22087002  0.21704006 -0.04745579 -0.01225185  0.2630272\\n\\\n",
      "          \\  0.02976894  0.17493916  0.32182407  0.33516216 -0.58139324  0.10664272\\n\\\n",
      "          \\  0.3010397   0.03300095  0.14554596 -0.07282734  0.31117868  0.41461658\\n\\\n",
      "          \\  0.0055933   0.20262909  0.44336605  0.25330448  0.9857998   0.371562\\n\\\n",
      "          \\  0.31083488  0.55611706  0.28700447  0.33842182  0.2598114  -0.39150143\\n\\\n",
      "          \\  0.06379604  0.3090191 ]\"\n",
      "    num_agent_steps_sampled: 80256\n",
      "    num_agent_steps_trained: 14432\n",
      "    num_steps_sampled: 80256\n",
      "    num_steps_trained: 14432\n",
      "    num_target_updates: 151\n",
      "  iterations_since_restore: 76\n",
      "  node_ip: 192.168.1.110\n",
      "  num_healthy_workers: 4\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 8.733333333333333\n",
      "    ram_util_percent: 66.3\n",
      "  pid: 19542\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.21398427819591329\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 25.216117781855544\n",
      "    mean_inference_ms: 1.5377956410229383\n",
      "    mean_raw_obs_processing_ms: 4.6629880890028685\n",
      "  time_since_restore: 263.1364061832428\n",
      "  time_this_iter_s: 4.182408332824707\n",
      "  time_total_s: 263.1364061832428\n",
      "  timers:\n",
      "    learn_throughput: 6409.236\n",
      "    learn_time_ms: 4.993\n",
      "    update_time_ms: 8.667\n",
      "  timestamp: 1629908975\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 80256\n",
      "  training_iteration: 76\n",
      "  trial_id: fbba6_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/wadaboa/cpr-appropriation/c7685_00000/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/wadaboa/cpr-appropriation/c7685_00000/file_stream\n",
      "NoneType: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 10.7/16.0 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 5.0/16 CPUs, 0/0 GPUs, 0.0/4.34 GiB heap, 0.0/2.17 GiB objects (0.0/1.0 CPU_group_1_e8771a036fed53221c42d3b57c64506b, 0.0/5.0 CPU_group_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_2_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_0_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_4_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_3_e8771a036fed53221c42d3b57c64506b)\n",
      "Result logdir: /Users/jobs/Github/cpr-appropriation/rllib_logs/DQN_2021-08-25_18-24-55\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+--------------------------------------------+----------+---------------------+------------+---------+----------+---------+---------+\n",
      "| Trial name                                 | status   | loc                 |   episodes |       U |        E |       S |       P |\n",
      "|--------------------------------------------+----------+---------------------+------------+---------+----------+---------+---------|\n",
      "| DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000 | RUNNING  | 192.168.1.110:19542 |          4 | 12.1493 | 0.784311 | 237.585 | 397.765 |\n",
      "+--------------------------------------------+----------+---------------------+------------+---------+----------+---------+---------+\n",
      "\n",
      "\n",
      "Result for DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000:\n",
      "  agent_timesteps_total: 82368\n",
      "  custom_metrics:\n",
      "    efficiency_max: 14.113454545454545\n",
      "    efficiency_mean: 12.149250000000002\n",
      "    efficiency_min: 9.667545454545454\n",
      "    equality_max: 0.8014564330750137\n",
      "    equality_mean: 0.7843113128085738\n",
      "    equality_min: 0.7537295725673683\n",
      "    peace_max: 413.36109090909093\n",
      "    peace_mean: 397.76486363636366\n",
      "    peace_min: 385.05518181818184\n",
      "    sustainability_max: 240.71902484348544\n",
      "    sustainability_mean: 237.58475215400577\n",
      "    sustainability_min: 233.5863895068592\n",
      "  date: 2021-08-25_18-29-44\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 308.0\n",
      "  episode_reward_mean: 270.75\n",
      "  episode_reward_min: 230.0\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 4\n",
      "  experiment_id: d7c9d60e82b747cb85777bd6138148e5\n",
      "  hostname: wadaboa-work.local\n",
      "  info:\n",
      "    last_target_update_ts: 82368\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_lr: 0.0005\n",
      "          grad_gnorm: 0.2382231056690216\n",
      "          max_q: 14.43946647644043\n",
      "          mean_q: 11.213516235351562\n",
      "          mean_td_error: 0.159255713224411\n",
      "          min_q: 8.402993202209473\n",
      "        model: {}\n",
      "        td_error: \"[-0.38173008  0.9614544   0.26612377  0.23637676  0.83920574  0.23502064\\n\\\n",
      "          \\  0.10643196  0.6258087   0.46204758  0.31617546 -0.6754389  -0.1829052\\n\\\n",
      "          \\  0.22414684  0.25391865  0.11570072 -0.75386524  0.31225204  0.08190346\\n\\\n",
      "          \\ -0.4955368   0.93975353  0.15869904  0.70906925  0.18941212  0.09793282\\n\\\n",
      "          \\  0.1726656  -0.7557554  -0.30346107  0.31030178  0.74869156 -0.06044388\\n\\\n",
      "          \\ -0.01287174  0.35509872]\"\n",
      "    num_agent_steps_sampled: 82368\n",
      "    num_agent_steps_trained: 14816\n",
      "    num_steps_sampled: 82368\n",
      "    num_steps_trained: 14816\n",
      "    num_target_updates: 155\n",
      "  iterations_since_restore: 78\n",
      "  node_ip: 192.168.1.110\n",
      "  num_healthy_workers: 4\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 9.75\n",
      "    ram_util_percent: 66.48333333333333\n",
      "  pid: 19542\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.21398427819591329\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 25.216117781855544\n",
      "    mean_inference_ms: 1.5377956410229383\n",
      "    mean_raw_obs_processing_ms: 4.6629880890028685\n",
      "  time_since_restore: 271.3611636161804\n",
      "  time_this_iter_s: 4.1087806224823\n",
      "  time_total_s: 271.3611636161804\n",
      "  timers:\n",
      "    learn_throughput: 6228.75\n",
      "    learn_time_ms: 5.137\n",
      "    update_time_ms: 8.651\n",
      "  timestamp: 1629908984\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 82368\n",
      "  training_iteration: 78\n",
      "  trial_id: fbba6_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 10.7/16.0 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 5.0/16 CPUs, 0/0 GPUs, 0.0/4.34 GiB heap, 0.0/2.17 GiB objects (0.0/1.0 CPU_group_1_e8771a036fed53221c42d3b57c64506b, 0.0/5.0 CPU_group_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_2_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_0_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_4_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_3_e8771a036fed53221c42d3b57c64506b)\n",
      "Result logdir: /Users/jobs/Github/cpr-appropriation/rllib_logs/DQN_2021-08-25_18-24-55\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+--------------------------------------------+----------+---------------------+------------+---------+----------+---------+---------+\n",
      "| Trial name                                 | status   | loc                 |   episodes |       U |        E |       S |       P |\n",
      "|--------------------------------------------+----------+---------------------+------------+---------+----------+---------+---------|\n",
      "| DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000 | RUNNING  | 192.168.1.110:19542 |          4 | 12.1493 | 0.784311 | 237.585 | 397.765 |\n",
      "+--------------------------------------------+----------+---------------------+------------+---------+----------+---------+---------+\n",
      "\n",
      "\n",
      "Result for DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000:\n",
      "  agent_timesteps_total: 84480\n",
      "  custom_metrics:\n",
      "    efficiency_max: 14.113454545454545\n",
      "    efficiency_mean: 12.149250000000002\n",
      "    efficiency_min: 9.667545454545454\n",
      "    equality_max: 0.8014564330750137\n",
      "    equality_mean: 0.7843113128085738\n",
      "    equality_min: 0.7537295725673683\n",
      "    peace_max: 413.36109090909093\n",
      "    peace_mean: 397.76486363636366\n",
      "    peace_min: 385.05518181818184\n",
      "    sustainability_max: 240.71902484348544\n",
      "    sustainability_mean: 237.58475215400577\n",
      "    sustainability_min: 233.5863895068592\n",
      "  date: 2021-08-25_18-29-54\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 308.0\n",
      "  episode_reward_mean: 270.75\n",
      "  episode_reward_min: 230.0\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 4\n",
      "  experiment_id: d7c9d60e82b747cb85777bd6138148e5\n",
      "  hostname: wadaboa-work.local\n",
      "  info:\n",
      "    last_target_update_ts: 84480\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_lr: 0.0005\n",
      "          grad_gnorm: 0.12235268205404282\n",
      "          max_q: 17.08325958251953\n",
      "          mean_q: 12.337541580200195\n",
      "          mean_td_error: 0.015275701880455017\n",
      "          min_q: 7.582381725311279\n",
      "        model: {}\n",
      "        td_error: \"[ 0.13574791 -0.23703289  1.3531837   0.17986298  0.10817623  0.12576103\\n\\\n",
      "          \\ -0.06350136  1.2072067   0.0872221   0.01967716 -0.88634014  0.35681438\\n\\\n",
      "          \\  0.9516239  -0.13633919 -0.00596237 -0.528285   -0.73521614 -0.2769928\\n\\\n",
      "          \\  0.4475975  -0.41069126  0.00796413  0.26424026 -0.37856483 -0.75263023\\n\\\n",
      "          \\  0.0537014  -0.02569962  0.38469362 -0.15346909 -0.17295837 -0.36009693\\n\\\n",
      "          \\ -0.11342812  0.04255772]\"\n",
      "    num_agent_steps_sampled: 84480\n",
      "    num_agent_steps_trained: 15200\n",
      "    num_steps_sampled: 84480\n",
      "    num_steps_trained: 15200\n",
      "    num_target_updates: 159\n",
      "  iterations_since_restore: 80\n",
      "  node_ip: 192.168.1.110\n",
      "  num_healthy_workers: 4\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 11.149999999999999\n",
      "    ram_util_percent: 66.66666666666666\n",
      "  pid: 19542\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.21398427819591329\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 25.216117781855544\n",
      "    mean_inference_ms: 1.5377956410229383\n",
      "    mean_raw_obs_processing_ms: 4.6629880890028685\n",
      "  time_since_restore: 279.9495096206665\n",
      "  time_this_iter_s: 4.281152963638306\n",
      "  time_total_s: 279.9495096206665\n",
      "  timers:\n",
      "    learn_throughput: 6056.948\n",
      "    learn_time_ms: 5.283\n",
      "    update_time_ms: 8.645\n",
      "  timestamp: 1629908994\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 84480\n",
      "  training_iteration: 80\n",
      "  trial_id: fbba6_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 18:30:03,575\tWARNING ray_trial_executor.py:709 -- Over the last 60 seconds, the Tune event loop has been backlogged processing new results. Consider increasing your period of result reporting to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 10.6/16.0 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 5.0/16 CPUs, 0/0 GPUs, 0.0/4.34 GiB heap, 0.0/2.17 GiB objects (0.0/1.0 CPU_group_1_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_4_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_3_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_0_e8771a036fed53221c42d3b57c64506b, 0.0/5.0 CPU_group_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_2_e8771a036fed53221c42d3b57c64506b)\n",
      "Result logdir: /Users/jobs/Github/cpr-appropriation/rllib_logs/DQN_2021-08-25_18-24-55\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+--------------------------------------------+----------+---------------------+------------+---------+----------+---------+---------+\n",
      "| Trial name                                 | status   | loc                 |   episodes |       U |        E |       S |       P |\n",
      "|--------------------------------------------+----------+---------------------+------------+---------+----------+---------+---------|\n",
      "| DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000 | RUNNING  | 192.168.1.110:19542 |          4 | 12.1493 | 0.784311 | 237.585 | 397.765 |\n",
      "+--------------------------------------------+----------+---------------------+------------+---------+----------+---------+---------+\n",
      "\n",
      "\n",
      "Result for DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000:\n",
      "  agent_timesteps_total: 86592\n",
      "  custom_metrics:\n",
      "    efficiency_max: 14.113454545454545\n",
      "    efficiency_mean: 12.149250000000002\n",
      "    efficiency_min: 9.667545454545454\n",
      "    equality_max: 0.8014564330750137\n",
      "    equality_mean: 0.7843113128085738\n",
      "    equality_min: 0.7537295725673683\n",
      "    peace_max: 413.36109090909093\n",
      "    peace_mean: 397.76486363636366\n",
      "    peace_min: 385.05518181818184\n",
      "    sustainability_max: 240.71902484348544\n",
      "    sustainability_mean: 237.58475215400577\n",
      "    sustainability_min: 233.5863895068592\n",
      "  date: 2021-08-25_18-30-03\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 308.0\n",
      "  episode_reward_mean: 270.75\n",
      "  episode_reward_min: 230.0\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 4\n",
      "  experiment_id: d7c9d60e82b747cb85777bd6138148e5\n",
      "  hostname: wadaboa-work.local\n",
      "  info:\n",
      "    last_target_update_ts: 86592\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_lr: 0.0005\n",
      "          grad_gnorm: 0.09886514395475388\n",
      "          max_q: 17.0942325592041\n",
      "          mean_q: 12.476045608520508\n",
      "          mean_td_error: 0.3674018085002899\n",
      "          min_q: 7.13882303237915\n",
      "        model: {}\n",
      "        td_error: \"[ 7.97843933e-02  3.90071869e-02 -1.21468544e-01  2.99702644e-01\\n\\\n",
      "          \\  2.31513977e-01  3.54385376e-02 -6.19029999e-03  3.08073044e-01\\n  2.80001640e-01\\\n",
      "          \\ -2.68802643e-01 -8.43658447e-02  9.01203156e-02\\n  1.03170395e-01 -1.89780235e-01\\\n",
      "          \\ -1.75618172e-01 -3.13529968e-01\\n -6.92200661e-01  1.53347969e-01  3.60420227e-01\\\n",
      "          \\  8.36610794e-02\\n -1.12808514e+00  4.46455956e-01  1.29153805e+01 -1.68564796e-01\\n\\\n",
      "          \\ -7.56149292e-02  4.11777496e-02 -1.35154724e-02 -1.88236237e-02\\n  2.82508850e-01\\\n",
      "          \\ -1.69844627e-01  3.87411118e-02 -6.05242729e-01]\"\n",
      "    num_agent_steps_sampled: 86592\n",
      "    num_agent_steps_trained: 15584\n",
      "    num_steps_sampled: 86592\n",
      "    num_steps_trained: 15584\n",
      "    num_target_updates: 163\n",
      "  iterations_since_restore: 82\n",
      "  node_ip: 192.168.1.110\n",
      "  num_healthy_workers: 4\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 13.742857142857142\n",
      "    ram_util_percent: 66.32857142857142\n",
      "  pid: 19542\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.21398427819591329\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 25.216117781855544\n",
      "    mean_inference_ms: 1.5377956410229383\n",
      "    mean_raw_obs_processing_ms: 4.6629880890028685\n",
      "  time_since_restore: 288.46127676963806\n",
      "  time_this_iter_s: 4.183560132980347\n",
      "  time_total_s: 288.46127676963806\n",
      "  timers:\n",
      "    learn_throughput: 6416.682\n",
      "    learn_time_ms: 4.987\n",
      "    update_time_ms: 8.587\n",
      "  timestamp: 1629909003\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 86592\n",
      "  training_iteration: 82\n",
      "  trial_id: fbba6_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/wadaboa/cpr-appropriation/c7685_00000/file_stream\n",
      "NoneType: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 10.8/16.0 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 5.0/16 CPUs, 0/0 GPUs, 0.0/4.34 GiB heap, 0.0/2.17 GiB objects (0.0/1.0 CPU_group_3_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_2_e8771a036fed53221c42d3b57c64506b, 0.0/5.0 CPU_group_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_1_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_4_e8771a036fed53221c42d3b57c64506b, 0.0/1.0 CPU_group_0_e8771a036fed53221c42d3b57c64506b)\n",
      "Result logdir: /Users/jobs/Github/cpr-appropriation/rllib_logs/DQN_2021-08-25_18-24-55\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+--------------------------------------------+----------+---------------------+------------+---------+----------+---------+---------+\n",
      "| Trial name                                 | status   | loc                 |   episodes |       U |        E |       S |       P |\n",
      "|--------------------------------------------+----------+---------------------+------------+---------+----------+---------+---------|\n",
      "| DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000 | RUNNING  | 192.168.1.110:19542 |          4 | 12.1493 | 0.784311 | 237.585 | 397.765 |\n",
      "+--------------------------------------------+----------+---------------------+------------+---------+----------+---------+---------+\n",
      "\n",
      "\n",
      "Result for DQN_gym_cpr_grid:CPRGridEnv-v0_fbba6_00000:\n",
      "  agent_timesteps_total: 88704\n",
      "  custom_metrics:\n",
      "    efficiency_max: 19.891272727272728\n",
      "    efficiency_mean: 14.770113636363636\n",
      "    efficiency_min: 9.667545454545454\n",
      "    equality_max: 0.8154082327786716\n",
      "    equality_mean: 0.7845050329109144\n",
      "    equality_min: 0.7493008908260312\n",
      "    peace_max: 413.36109090909093\n",
      "    peace_mean: 387.4713863636364\n",
      "    peace_min: 373.6723636363636\n",
      "    sustainability_max: 240.71902484348544\n",
      "    sustainability_mean: 224.91859217479032\n",
      "    sustainability_min: 201.29325641458445\n",
      "  date: 2021-08-25_18-30-11\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 376.0\n",
      "  episode_reward_mean: 298.75\n",
      "  episode_reward_min: 230.0\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 8\n",
      "  experiment_id: d7c9d60e82b747cb85777bd6138148e5\n",
      "  hostname: wadaboa-work.local\n",
      "  info:\n",
      "    last_target_update_ts: 88704\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_lr: 0.0005\n",
      "          grad_gnorm: 0.09567313641309738\n",
      "          max_q: 16.24693489074707\n",
      "          mean_q: 12.279951095581055\n",
      "          mean_td_error: -0.0315777063369751\n",
      "          min_q: 8.545063018798828\n",
      "        model: {}\n",
      "        td_error: \"[ 0.25381565 -0.16773987  0.27223873  0.6897125  -0.0837574   0.14920044\\n\\\n",
      "          \\ -0.19181347 -0.11029434  0.10122967 -0.69927883 -0.59199524 -0.41418743\\n\\\n",
      "          \\  0.6891384   0.01087761  0.24738598  0.01198673 -0.41495514  0.07735634\\n\\\n",
      "          \\ -0.01493263 -0.06844044 -0.6981411  -0.18906212 -0.0045557   0.11765003\\n\\\n",
      "          \\ -0.08694267  0.09705544  0.43549347 -0.12197208  0.10071659  0.1360836\\n\\\n",
      "          \\ -0.26585007 -0.27650928]\"\n",
      "    num_agent_steps_sampled: 88704\n",
      "    num_agent_steps_trained: 15968\n",
      "    num_steps_sampled: 88704\n",
      "    num_steps_trained: 15968\n",
      "    num_target_updates: 167\n",
      "  iterations_since_restore: 84\n",
      "  node_ip: 192.168.1.110\n",
      "  num_healthy_workers: 4\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.78\n",
      "    ram_util_percent: 67.72\n",
      "  pid: 19542\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.21380997170335925\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 26.415770822566817\n",
      "    mean_inference_ms: 1.5314111905572951\n",
      "    mean_raw_obs_processing_ms: 4.682110363644326\n",
      "  time_since_restore: 295.62068700790405\n",
      "  time_this_iter_s: 2.920525074005127\n",
      "  time_total_s: 295.62068700790405\n",
      "  timers:\n",
      "    learn_throughput: 6257.324\n",
      "    learn_time_ms: 5.114\n",
      "    update_time_ms: 8.626\n",
      "  timestamp: 1629909011\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 88704\n",
      "  training_iteration: 84\n",
      "  trial_id: fbba6_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/wadaboa/cpr-appropriation/c7685_00000/file_stream\n",
      "NoneType: None\n",
      "2021-08-25 18:30:12,267\tWARNING util.py:163 -- The `process_trial_result` operation took 0.527 s, which may be a performance bottleneck.\n",
      "2021-08-25 18:30:12,268\tWARNING util.py:163 -- Processing trial results took 0.528 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2021-08-25 18:30:12,269\tWARNING util.py:163 -- The `process_trial` operation took 0.557 s, which may be a performance bottleneck.\n",
      "2021-08-25 18:30:15,358\tWARNING util.py:163 -- The `process_trial_result` operation took 0.509 s, which may be a performance bottleneck.\n",
      "2021-08-25 18:30:15,359\tWARNING util.py:163 -- Processing trial results took 0.510 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2021-08-25 18:30:15,359\tWARNING util.py:163 -- The `process_trial` operation took 0.537 s, which may be a performance bottleneck.\n"
     ]
    }
   ],
   "source": [
    "experiment_analysis = rllib.dqn_baseline(\n",
    "    n_agents,\n",
    "    grid_width,\n",
    "    grid_height,\n",
    "    wandb_project,\n",
    "    wandb_api_key,\n",
    "    rllib_log_dir,\n",
    "    max_episodes,\n",
    "    tagging_ability=True,\n",
    "    gifting_mechanism=None,\n",
    "    num_workers=num_workers,\n",
    "    jupyter=False,\n",
    "    seed=seed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eac3aea",
   "metadata": {},
   "source": [
    "### W/O tagging & W/ gifting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1caa0ad7",
   "metadata": {},
   "source": [
    "#### Zero sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44c3bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_analysis = rllib.dqn_baseline(\n",
    "    n_agents,\n",
    "    grid_width,\n",
    "    grid_height,\n",
    "    wandb_project,\n",
    "    wandb_api_key,\n",
    "    rllib_log_dir,\n",
    "    max_episodes,\n",
    "    tagging_ability=False,\n",
    "    gifting_mechanism=0,\n",
    "    num_workers=num_workers,\n",
    "    jupyter=True,\n",
    "    seed=seed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c78584",
   "metadata": {},
   "source": [
    "#### Fixed budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1744213b",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_analysis = rllib.dqn_baseline(\n",
    "    n_agents,\n",
    "    grid_width,\n",
    "    grid_height,\n",
    "    wandb_project,\n",
    "    wandb_api_key,\n",
    "    rllib_log_dir,\n",
    "    max_episodes,\n",
    "    tagging_ability=False,\n",
    "    gifting_mechanism=1,\n",
    "    num_workers=num_workers,\n",
    "    jupyter=True,\n",
    "    seed=seed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5644ef8c",
   "metadata": {},
   "source": [
    "#### Replenishable budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20703058",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_analysis = rllib.dqn_baseline(\n",
    "    n_agents,\n",
    "    grid_width,\n",
    "    grid_height,\n",
    "    wandb_project,\n",
    "    wandb_api_key,\n",
    "    rllib_log_dir,\n",
    "    max_episodes,\n",
    "    tagging_ability=False,\n",
    "    gifting_mechanism=2,\n",
    "    num_workers=num_workers,\n",
    "    jupyter=True,\n",
    "    seed=seed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b7f908",
   "metadata": {},
   "source": [
    "### W/ tagging & W/ gifting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33610043",
   "metadata": {},
   "source": [
    "#### Zero sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e48213",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_analysis = rllib.dqn_baseline(\n",
    "    n_agents,\n",
    "    grid_width,\n",
    "    grid_height,\n",
    "    wandb_project,\n",
    "    wandb_api_key,\n",
    "    rllib_log_dir,\n",
    "    max_episodes,\n",
    "    tagging_ability=True,\n",
    "    gifting_mechanism=0,\n",
    "    num_workers=num_workers,\n",
    "    jupyter=True,\n",
    "    seed=seed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70d5005",
   "metadata": {},
   "source": [
    "#### Fixed budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd20f6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_analysis = rllib.dqn_baseline(\n",
    "    n_agents,\n",
    "    grid_width,\n",
    "    grid_height,\n",
    "    wandb_project,\n",
    "    wandb_api_key,\n",
    "    rllib_log_dir,\n",
    "    max_episodes,\n",
    "    tagging_ability=True,\n",
    "    gifting_mechanism=1,\n",
    "    num_workers=num_workers,\n",
    "    jupyter=True,\n",
    "    seed=seed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e684032",
   "metadata": {},
   "source": [
    "#### Replenishable budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76590b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_analysis = rllib.dqn_baseline(\n",
    "    n_agents,\n",
    "    grid_width,\n",
    "    grid_height,\n",
    "    wandb_project,\n",
    "    wandb_api_key,\n",
    "    rllib_log_dir,\n",
    "    max_episodes,\n",
    "    tagging_ability=True,\n",
    "    gifting_mechanism=2,\n",
    "    num_workers=num_workers,\n",
    "    jupyter=True,\n",
    "    seed=seed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87639c65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a1d7f10e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 17:50:49.357 | DEBUG    | src.policies:execute_episode:290 - Early stopping, all agents done\n",
      "2021-08-25 17:50:49.397 | INFO     | src.policies:train:120 - Episode infos: {'efficiency': 129.8181818181818, 'equality': 0.8641456582676297, 'sustainability': 598.2819134881199, 'peace': 607.6363636363636}\n",
      "2021-08-25 17:50:49.398 | INFO     | src.policies:train:125 - Mean episode return: 129.8181818181818\n",
      "2021-08-25 17:50:49.399 | INFO     | src.policies:train:126 - Last 100 episodes mean return: 137.83471074380162\n",
      "2021-08-25 17:50:49.399 | WARNING  | src.policies:train:136 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:51:00.224 | INFO     | src.policies:train:162 - Total loss: 0.9999077320098877\n",
      "2021-08-25 17:51:00.225 | INFO     | src.policies:train:167 - Epoch infos: {'efficiency': 129.8181818181818, 'equality': 0.8641456582676297, 'sustainability': 598.2819134881199, 'peace': 607.6363636363636}\n",
      "2021-08-25 17:51:00.277 | INFO     | src.policies:train:106 - Epoch 12 / 4000\n",
      "2021-08-25 17:51:00.277 | INFO     | src.policies:train:113 - Episode 12\n",
      "2021-08-25 17:52:06.962 | DEBUG    | src.policies:execute_episode:290 - Early stopping, all agents done\n",
      "2021-08-25 17:52:07.053 | INFO     | src.policies:train:120 - Episode infos: {'efficiency': 136.1818181818182, 'equality': 0.8669741473520156, 'sustainability': 581.8295645076818, 'peace': 612.0909090909091}\n",
      "2021-08-25 17:52:07.054 | INFO     | src.policies:train:125 - Mean episode return: 136.1818181818182\n",
      "2021-08-25 17:52:07.055 | INFO     | src.policies:train:126 - Last 100 episodes mean return: 137.69696969696966\n",
      "2021-08-25 17:52:07.056 | WARNING  | src.policies:train:136 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:52:19.124 | INFO     | src.policies:train:162 - Total loss: 0.9999077320098877\n",
      "2021-08-25 17:52:19.125 | INFO     | src.policies:train:167 - Epoch infos: {'efficiency': 136.1818181818182, 'equality': 0.8669741473520156, 'sustainability': 581.8295645076818, 'peace': 612.0909090909091}\n",
      "2021-08-25 17:52:19.187 | INFO     | src.policies:train:106 - Epoch 13 / 4000\n",
      "2021-08-25 17:52:19.188 | INFO     | src.policies:train:113 - Episode 13\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/pp/wfj1kcws58g7pxksj9k8zdhw0000gn/T/ipykernel_19542/2156572196.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrpo_baseline_nn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMLP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1260\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_softmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrpo_policy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRPOPolicy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrpo_policy_nn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrpo_baseline_nn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl_target\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m trpo_policy.train(\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;36m4000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;36m4000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Github/cpr-appropriation/notebooks/../src/policies.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, steps_per_epoch, policy_lr, baseline_lr, discount, save_every, checkpoints_path, enable_wandb, wandb_config, max_episodes, std_returns, episodes_mean_return, render_every)\u001b[0m\n\u001b[1;32m    116\u001b[0m                     \u001b[0mepisode_infos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                     \u001b[0mepisode_mean_return\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m                 ) = self.execute_episode(render=(current_episode % render_every == 0))\n\u001b[0m\u001b[1;32m    119\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisode_infos\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Episode infos: {episode_infos}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Github/cpr-appropriation/notebooks/../src/policies.py\u001b[0m in \u001b[0;36mexecute_episode\u001b[0;34m(self, render)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0;31m# Perform a step in the environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m             \u001b[0mnew_observations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;31m# Update rendering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Github/cpr-appropriation/venv/lib/python3.9/site-packages/gym_cpr_grid/cpr_grid.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action_dict)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;31m# Respawn resources\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_respawn_resources\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobservations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Github/cpr-appropriation/venv/lib/python3.9/site-packages/gym_cpr_grid/cpr_grid.py\u001b[0m in \u001b[0;36m_respawn_resources\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid_height\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGridCell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEMPTY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m                 \u001b[0mball\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extract_ball\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m                 \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mball\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mball\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGridCell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRESOURCE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m                 \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_respawn_probability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Github/cpr-appropriation/venv/lib/python3.9/site-packages/gym_cpr_grid/cpr_grid.py\u001b[0m in \u001b[0;36m_extract_ball\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \"\"\"\n\u001b[1;32m    587\u001b[0m         \u001b[0;31m# Pad the 2D grid so as not have indexing errors in ball extraction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         padded_grid, x_pad_width, y_pad_width = self._pad_grid(\n\u001b[0m\u001b[1;32m    589\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Github/cpr-appropriation/venv/lib/python3.9/site-packages/gym_cpr_grid/cpr_grid.py\u001b[0m in \u001b[0;36m_pad_grid\u001b[0;34m(self, grid, x, y, xl, yl, pad_value)\u001b[0m\n\u001b[1;32m    507\u001b[0m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0myl\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mheight\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m         )\n\u001b[0;32m--> 509\u001b[0;31m         padded_grid = np.pad(\n\u001b[0m\u001b[1;32m    510\u001b[0m             \u001b[0mgrid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m             \u001b[0mpad_width\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_pad_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_pad_width\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mpad\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/Github/cpr-appropriation/venv/lib/python3.9/site-packages/numpy/lib/arraypad.py\u001b[0m in \u001b[0;36mpad\u001b[0;34m(array, pad_width, mode, **kwargs)\u001b[0m\n\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[0;31m# Broadcast to shape (array.ndim, 2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 743\u001b[0;31m     \u001b[0mpad_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_as_pairs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    744\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Github/cpr-appropriation/venv/lib/python3.9/site-packages/numpy/lib/arraypad.py\u001b[0m in \u001b[0;36m_as_pairs\u001b[0;34m(x, ndim, as_index)\u001b[0m\n\u001b[1;32m    487\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mas_index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mround_\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/Github/cpr-appropriation/venv/lib/python3.9/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mround_\u001b[0;34m(a, decimals, out)\u001b[0m\n\u001b[1;32m   3737\u001b[0m     \u001b[0maround\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mequivalent\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0msee\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3738\u001b[0m     \"\"\"\n\u001b[0;32m-> 3739\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0maround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecimals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecimals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36maround\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/Github/cpr-appropriation/venv/lib/python3.9/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36maround\u001b[0;34m(a, decimals, out)\u001b[0m\n\u001b[1;32m   3312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3313\u001b[0m     \"\"\"\n\u001b[0;32m-> 3314\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'round'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecimals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecimals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Github/cpr-appropriation/venv/lib/python3.9/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src import models, policies\n",
    "trpo_policy_nn = models.MLP(1260, [32, 32], 9)\n",
    "trpo_baseline_nn = models.MLP(1260, [32, 32], 1, log_softmax=False)\n",
    "trpo_policy = policies.TRPOPolicy(env, trpo_policy_nn, trpo_baseline_nn, beta=1.0, kl_target=0.01)\n",
    "trpo_policy.train(\n",
    "    4000,\n",
    "    4000,\n",
    "    enable_wandb=False,\n",
    "    render_every=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd4d4fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
