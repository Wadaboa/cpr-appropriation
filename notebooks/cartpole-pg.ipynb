{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7a1479f",
   "metadata": {},
   "source": [
    "# Cartpole tests with policy gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be42462",
   "metadata": {},
   "source": [
    "This notebook contains a simple test for each implemented policy gradient method. In order to test if they function properly, we rely on the [Cartpole](https://gym.openai.com/envs/CartPole-v0/) environment, provided out-of-the-box in OpenAI Gym. As stated in Gym's documentation, the problem is considered \"solved\" if the agent is able to obtain a mean return of 195 in the last 100 episodes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14860860",
   "metadata": {},
   "source": [
    "## Pre-requisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5ccae8",
   "metadata": {},
   "source": [
    "The cells down below install and import the necessary libraries to successfully run the notebook examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dce2ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48a7fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -r ../init/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e221fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import base64\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import gym\n",
    "from gym import wrappers\n",
    "from IPython.display import HTML\n",
    "\n",
    "from src import models, policies\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a94d40",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1749819c",
   "metadata": {},
   "source": [
    "The cell down below defines the environment, along with common variables to be used throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff50867",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e9ec22",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_space_size = 4\n",
    "action_space_size = 2\n",
    "hidden_sizes = [32, 32]\n",
    "epochs = 800\n",
    "steps_per_epoch = 200\n",
    "minibatch_size = 100\n",
    "episodes_mean_return = 100\n",
    "wandb_config = {\n",
    "    \"api_key\": open(\"../wandb_api_key_file\", \"r\").read().strip(),\n",
    "    \"project\": \"cpr-appropriation\",\n",
    "    \"entity\": \"wadaboa\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246b0b49",
   "metadata": {},
   "source": [
    "## VPG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29665cb2",
   "metadata": {},
   "source": [
    "This section deals with training a Cartpole agent using our custom Vanilla Policy Gradient implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d831219c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vpg_policy_nn = models.MLP(observation_space_size, hidden_sizes, action_space_size)\n",
    "vpg_baseline_nn = models.MLP(observation_space_size, hidden_sizes, 1, log_softmax=False)\n",
    "vpg_policy = policies.VPGPolicy(env, vpg_policy_nn, baseline_nn=vpg_baseline_nn)\n",
    "vpg_policy.train(\n",
    "    epochs,\n",
    "    steps_per_epoch,\n",
    "    minibatch_size,\n",
    "    enable_wandb=True,\n",
    "    wandb_config={**wandb_config, \"group\": \"VPG\"},\n",
    "    episodes_mean_return=episodes_mean_return\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503ea7aa",
   "metadata": {},
   "source": [
    "## TRPO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5756d0",
   "metadata": {},
   "source": [
    "This section deals with training a Cartpole agent using our custom Trust Region Policy Optimization implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdddef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 1.0\n",
    "kl_target = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f959403",
   "metadata": {},
   "outputs": [],
   "source": [
    "trpo_policy_nn = models.MLP(observation_space_size, hidden_sizes, action_space_size)\n",
    "trpo_baseline_nn = models.MLP(observation_space_size, hidden_sizes, 1, log_softmax=False)\n",
    "trpo_policy = policies.TRPOPolicy(env, trpo_policy_nn, trpo_baseline_nn, beta=beta, kl_target=kl_target)\n",
    "trpo_policy.train(\n",
    "    epochs,\n",
    "    steps_per_epoch,\n",
    "    minibatch_size,\n",
    "    enable_wandb=True,\n",
    "    wandb_config={**wandb_config, \"group\": \"TRPO\"},\n",
    "    episodes_mean_return=episodes_mean_return\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34632f1f",
   "metadata": {},
   "source": [
    "## PPO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc40880f",
   "metadata": {},
   "source": [
    "This section deals with training a Cartpole agent using our custom Proximal Policy Optimization implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51783ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.5\n",
    "beta = 0.01\n",
    "eps = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e1efc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_policy_nn = models.MLP(observation_space_size, hidden_sizes, action_space_size)\n",
    "ppo_baseline_nn = models.MLP(observation_space_size, hidden_sizes, 1, log_softmax=False)\n",
    "ppo_policy = policies.PPOPolicy(env, ppo_policy_nn, ppo_baseline_nn, alpha=alpha, beta=beta, eps=eps)\n",
    "ppo_policy.train(\n",
    "    epochs,\n",
    "    steps_per_epoch,\n",
    "    minibatch_size,\n",
    "    enable_wandb=False,\n",
    "    save_every=200,\n",
    "    checkpoints_path=\"../checkpoints\",\n",
    "    wandb_config={**wandb_config, \"group\": \"PPO\"},\n",
    "    episodes_mean_return=episodes_mean_return\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b7a769",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d691d4",
   "metadata": {},
   "source": [
    "In this section we are evaluating one of the trained models on the Cartpole environment and visualizing results through Gym Monitor videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879ff2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = ppo_policy\n",
    "checkpoint = \"\"\n",
    "policy.load(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21be29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy.policy_nn.eval()\n",
    "policy.baseline_nn.eval()\n",
    "env = wrappers.Monitor(env, \"../gym-results\", force=True)\n",
    "observation = env.reset()\n",
    "for _ in range(1000):\n",
    "    probs = policy.policy_nn(torch.tensor(observation, dtype=torch.float32))\n",
    "    action = probs.argmax().item()\n",
    "    observation, _, done, _= env.step(action)\n",
    "    if done:\n",
    "        break\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcf345d",
   "metadata": {},
   "outputs": [],
   "source": [
    "video = io.open('../gym-results/openaigym.video.%s.video000000.mp4' % env.file_infix, 'r+b').read()\n",
    "encoded = base64.b64encode(video)\n",
    "HTML(\n",
    "    data='''\n",
    "        <video width=\"360\" height=\"auto\" alt=\"test\" controls>\n",
    "            <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "        </video>\n",
    "    '''.format(encoded.decode('ascii'))\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
