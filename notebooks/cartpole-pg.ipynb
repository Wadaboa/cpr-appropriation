{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7a1479f",
   "metadata": {},
   "source": [
    "# Cartpole tests with policy gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6cb259",
   "metadata": {},
   "source": [
    "This notebook contains a simple test for each implemented policy gradient method. In order to test if they function properly, we rely on the [Cartpole](https://gym.openai.com/envs/CartPole-v0/) environment, provided out-of-the-box in OpenAI Gym. As stated in Gym's documentation, the problem is considered \"solved\" if the agent is able to obtain a mean return of 200 in the last 100 episodes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14860860",
   "metadata": {},
   "source": [
    "## Pre-requisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9175b8ef",
   "metadata": {},
   "source": [
    "The cells down below install and import the necessary libraries to successfully run the notebook examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b55335e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f48a7fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -r ../init/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45e221fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "from src import models, policies\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a94d40",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c2b5da",
   "metadata": {},
   "source": [
    "The cell down below defines the environment, along with common variables to be used throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9161ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81e9ec22",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_space_size = 4\n",
    "action_space_size = 2\n",
    "hidden_sizes = [32, 32]\n",
    "epochs = 800\n",
    "steps_per_epoch = 200\n",
    "episodes_mean_reward = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246b0b49",
   "metadata": {},
   "source": [
    "## VPG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541d0707",
   "metadata": {},
   "source": [
    "This section deals with training a Cartpole agent using our custom Vanilla Policy Gradient implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d831219c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:14.849 | INFO     | src.policies:train:103 - Epoch 1 / 800\n",
      "2021-08-25 10:46:14.850 | INFO     | src.policies:train:109 - Episode 1\n",
      "2021-08-25 10:46:14.864 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:14.865 | INFO     | src.policies:train:121 - Mean episode return: 47.0\n",
      "2021-08-25 10:46:14.865 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 47.0\n",
      "2021-08-25 10:46:14.866 | INFO     | src.policies:train:109 - Episode 2\n",
      "2021-08-25 10:46:14.872 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:14.873 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:14.873 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.0\n",
      "2021-08-25 10:46:14.874 | INFO     | src.policies:train:109 - Episode 3\n",
      "2021-08-25 10:46:14.882 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:14.882 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 10:46:14.883 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.0\n",
      "2021-08-25 10:46:14.884 | INFO     | src.policies:train:109 - Episode 4\n",
      "2021-08-25 10:46:14.898 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:14.899 | INFO     | src.policies:train:121 - Mean episode return: 41.0\n",
      "2021-08-25 10:46:14.899 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.5\n",
      "2021-08-25 10:46:14.900 | INFO     | src.policies:train:109 - Episode 5\n",
      "2021-08-25 10:46:14.906 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:14.907 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:14.907 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.8\n",
      "2021-08-25 10:46:14.908 | INFO     | src.policies:train:109 - Episode 6\n",
      "2021-08-25 10:46:14.919 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:14.920 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 10:46:14.920 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.833333333333332\n",
      "2021-08-25 10:46:14.921 | INFO     | src.policies:train:109 - Episode 7\n",
      "2021-08-25 10:46:14.929 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:14.930 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:14.931 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.571428571428573\n",
      "2021-08-25 10:46:14.931 | INFO     | src.policies:train:109 - Episode 8\n",
      "2021-08-25 10:46:14.937 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:14.938 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:14.938 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.75\n",
      "2021-08-25 10:46:14.939 | INFO     | src.policies:train:109 - Episode 9\n",
      "2021-08-25 10:46:14.947 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:14.949 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 10:46:14.949 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.666666666666668\n",
      "2021-08-25 10:46:14.950 | WARNING  | src.policies:train:131 - The actual batch size is 222, instead of 200\n",
      "2021-08-25 10:46:14.955 | INFO     | src.policies:train:157 - Total loss: 237.690673828125\n",
      "2021-08-25 10:46:14.956 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:14.958 | INFO     | src.policies:train:103 - Epoch 2 / 800\n",
      "2021-08-25 10:46:14.959 | INFO     | src.policies:train:109 - Episode 10\n",
      "2021-08-25 10:46:14.965 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:14.966 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 10:46:14.967 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.9\n",
      "2021-08-25 10:46:14.967 | INFO     | src.policies:train:109 - Episode 11\n",
      "2021-08-25 10:46:14.975 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:14.976 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 10:46:14.976 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.545454545454547\n",
      "2021-08-25 10:46:14.977 | INFO     | src.policies:train:109 - Episode 12\n",
      "2021-08-25 10:46:14.983 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:14.984 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:14.985 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.916666666666668\n",
      "2021-08-25 10:46:14.986 | INFO     | src.policies:train:109 - Episode 13\n",
      "2021-08-25 10:46:14.991 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:14.992 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 10:46:14.993 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.923076923076923\n",
      "2021-08-25 10:46:14.994 | INFO     | src.policies:train:109 - Episode 14\n",
      "2021-08-25 10:46:15.001 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.002 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 10:46:15.003 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.785714285714285\n",
      "2021-08-25 10:46:15.004 | INFO     | src.policies:train:109 - Episode 15\n",
      "2021-08-25 10:46:15.022 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.023 | INFO     | src.policies:train:121 - Mean episode return: 58.0\n",
      "2021-08-25 10:46:15.024 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.2\n",
      "2021-08-25 10:46:15.024 | INFO     | src.policies:train:109 - Episode 16\n",
      "2021-08-25 10:46:15.039 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.039 | INFO     | src.policies:train:121 - Mean episode return: 41.0\n",
      "2021-08-25 10:46:15.040 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.25\n",
      "2021-08-25 10:46:15.041 | INFO     | src.policies:train:109 - Episode 17\n",
      "2021-08-25 10:46:15.051 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.052 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 10:46:15.053 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.529411764705884\n",
      "2021-08-25 10:46:15.054 | WARNING  | src.policies:train:131 - The actual batch size is 212, instead of 200\n",
      "2021-08-25 10:46:15.058 | INFO     | src.policies:train:157 - Total loss: 289.9859924316406\n",
      "2021-08-25 10:46:15.059 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:15.061 | INFO     | src.policies:train:103 - Epoch 3 / 800\n",
      "2021-08-25 10:46:15.062 | INFO     | src.policies:train:109 - Episode 18\n",
      "2021-08-25 10:46:15.075 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.076 | INFO     | src.policies:train:121 - Mean episode return: 39.0\n",
      "2021-08-25 10:46:15.076 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.27777777777778\n",
      "2021-08-25 10:46:15.077 | INFO     | src.policies:train:109 - Episode 19\n",
      "2021-08-25 10:46:15.083 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.084 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:15.085 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.526315789473685\n",
      "2021-08-25 10:46:15.085 | INFO     | src.policies:train:109 - Episode 20\n",
      "2021-08-25 10:46:15.097 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.097 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 10:46:15.098 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.9\n",
      "2021-08-25 10:46:15.099 | INFO     | src.policies:train:109 - Episode 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:15.106 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.107 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:15.108 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.523809523809526\n",
      "2021-08-25 10:46:15.109 | INFO     | src.policies:train:109 - Episode 22\n",
      "2021-08-25 10:46:15.117 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.118 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 10:46:15.119 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.318181818181817\n",
      "2021-08-25 10:46:15.119 | INFO     | src.policies:train:109 - Episode 23\n",
      "2021-08-25 10:46:15.130 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.131 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 10:46:15.132 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.652173913043477\n",
      "2021-08-25 10:46:15.133 | INFO     | src.policies:train:109 - Episode 24\n",
      "2021-08-25 10:46:15.139 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.140 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:15.140 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.208333333333332\n",
      "2021-08-25 10:46:15.141 | INFO     | src.policies:train:109 - Episode 25\n",
      "2021-08-25 10:46:15.149 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.150 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 10:46:15.151 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.04\n",
      "2021-08-25 10:46:15.152 | INFO     | src.policies:train:109 - Episode 26\n",
      "2021-08-25 10:46:15.160 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.161 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 10:46:15.162 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.96153846153846\n",
      "2021-08-25 10:46:15.162 | WARNING  | src.policies:train:131 - The actual batch size is 215, instead of 200\n",
      "2021-08-25 10:46:15.167 | INFO     | src.policies:train:157 - Total loss: 190.10704040527344\n",
      "2021-08-25 10:46:15.168 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:15.170 | INFO     | src.policies:train:103 - Epoch 4 / 800\n",
      "2021-08-25 10:46:15.171 | INFO     | src.policies:train:109 - Episode 27\n",
      "2021-08-25 10:46:15.181 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.182 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 10:46:15.182 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.14814814814815\n",
      "2021-08-25 10:46:15.183 | INFO     | src.policies:train:109 - Episode 28\n",
      "2021-08-25 10:46:15.190 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.191 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:15.192 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.75\n",
      "2021-08-25 10:46:15.192 | INFO     | src.policies:train:109 - Episode 29\n",
      "2021-08-25 10:46:15.198 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.199 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:15.200 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.379310344827587\n",
      "2021-08-25 10:46:15.200 | INFO     | src.policies:train:109 - Episode 30\n",
      "2021-08-25 10:46:15.208 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.209 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:15.209 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.166666666666668\n",
      "2021-08-25 10:46:15.210 | INFO     | src.policies:train:109 - Episode 31\n",
      "2021-08-25 10:46:15.226 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.227 | INFO     | src.policies:train:121 - Mean episode return: 51.0\n",
      "2021-08-25 10:46:15.227 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.032258064516128\n",
      "2021-08-25 10:46:15.228 | INFO     | src.policies:train:109 - Episode 32\n",
      "2021-08-25 10:46:15.237 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.238 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 10:46:15.238 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.96875\n",
      "2021-08-25 10:46:15.239 | INFO     | src.policies:train:109 - Episode 33\n",
      "2021-08-25 10:46:15.245 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.246 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:15.246 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.666666666666668\n",
      "2021-08-25 10:46:15.247 | INFO     | src.policies:train:109 - Episode 34\n",
      "2021-08-25 10:46:15.256 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.257 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 10:46:15.257 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.58823529411765\n",
      "2021-08-25 10:46:15.258 | INFO     | src.policies:train:109 - Episode 35\n",
      "2021-08-25 10:46:15.272 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.273 | INFO     | src.policies:train:121 - Mean episode return: 44.0\n",
      "2021-08-25 10:46:15.274 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.142857142857142\n",
      "2021-08-25 10:46:15.275 | WARNING  | src.policies:train:131 - The actual batch size is 231, instead of 200\n",
      "2021-08-25 10:46:15.279 | INFO     | src.policies:train:157 - Total loss: 252.9373016357422\n",
      "2021-08-25 10:46:15.280 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:15.282 | INFO     | src.policies:train:103 - Epoch 5 / 800\n",
      "2021-08-25 10:46:15.283 | INFO     | src.policies:train:109 - Episode 36\n",
      "2021-08-25 10:46:15.289 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.290 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:15.291 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.86111111111111\n",
      "2021-08-25 10:46:15.292 | INFO     | src.policies:train:109 - Episode 37\n",
      "2021-08-25 10:46:15.297 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.298 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:15.298 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.54054054054054\n",
      "2021-08-25 10:46:15.299 | INFO     | src.policies:train:109 - Episode 38\n",
      "2021-08-25 10:46:15.308 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.309 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 10:46:15.310 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.55263157894737\n",
      "2021-08-25 10:46:15.310 | INFO     | src.policies:train:109 - Episode 39\n",
      "2021-08-25 10:46:15.321 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.322 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 10:46:15.323 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.743589743589745\n",
      "2021-08-25 10:46:15.324 | INFO     | src.policies:train:109 - Episode 40\n",
      "2021-08-25 10:46:15.341 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.342 | INFO     | src.policies:train:121 - Mean episode return: 56.0\n",
      "2021-08-25 10:46:15.342 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.525\n",
      "2021-08-25 10:46:15.343 | INFO     | src.policies:train:109 - Episode 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:15.353 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.354 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 10:46:15.354 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.4390243902439\n",
      "2021-08-25 10:46:15.355 | INFO     | src.policies:train:109 - Episode 42\n",
      "2021-08-25 10:46:15.360 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.361 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:15.362 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.11904761904762\n",
      "2021-08-25 10:46:15.363 | INFO     | src.policies:train:109 - Episode 43\n",
      "2021-08-25 10:46:15.372 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.373 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 10:46:15.373 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.046511627906977\n",
      "2021-08-25 10:46:15.374 | INFO     | src.policies:train:109 - Episode 44\n",
      "2021-08-25 10:46:15.381 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.382 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:15.382 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.886363636363637\n",
      "2021-08-25 10:46:15.383 | WARNING  | src.policies:train:131 - The actual batch size is 215, instead of 200\n",
      "2021-08-25 10:46:15.388 | INFO     | src.policies:train:157 - Total loss: 240.8024444580078\n",
      "2021-08-25 10:46:15.389 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:15.391 | INFO     | src.policies:train:103 - Epoch 6 / 800\n",
      "2021-08-25 10:46:15.392 | INFO     | src.policies:train:109 - Episode 45\n",
      "2021-08-25 10:46:15.397 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.398 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:15.399 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.622222222222224\n",
      "2021-08-25 10:46:15.400 | INFO     | src.policies:train:109 - Episode 46\n",
      "2021-08-25 10:46:15.407 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.408 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 10:46:15.409 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.52173913043478\n",
      "2021-08-25 10:46:15.409 | INFO     | src.policies:train:109 - Episode 47\n",
      "2021-08-25 10:46:15.419 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.419 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 10:46:15.420 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.595744680851062\n",
      "2021-08-25 10:46:15.421 | INFO     | src.policies:train:109 - Episode 48\n",
      "2021-08-25 10:46:15.429 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.430 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 10:46:15.431 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.520833333333332\n",
      "2021-08-25 10:46:15.431 | INFO     | src.policies:train:109 - Episode 49\n",
      "2021-08-25 10:46:15.439 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.440 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 10:46:15.440 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.448979591836736\n",
      "2021-08-25 10:46:15.441 | INFO     | src.policies:train:109 - Episode 50\n",
      "2021-08-25 10:46:15.451 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.452 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 10:46:15.453 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.46\n",
      "2021-08-25 10:46:15.453 | INFO     | src.policies:train:109 - Episode 51\n",
      "2021-08-25 10:46:15.461 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.462 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:15.463 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.352941176470587\n",
      "2021-08-25 10:46:15.463 | INFO     | src.policies:train:109 - Episode 52\n",
      "2021-08-25 10:46:15.470 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.471 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 10:46:15.472 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.21153846153846\n",
      "2021-08-25 10:46:15.472 | INFO     | src.policies:train:109 - Episode 53\n",
      "2021-08-25 10:46:15.479 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.480 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:15.481 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.09433962264151\n",
      "2021-08-25 10:46:15.482 | INFO     | src.policies:train:109 - Episode 54\n",
      "2021-08-25 10:46:15.495 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.496 | INFO     | src.policies:train:121 - Mean episode return: 39.0\n",
      "2021-08-25 10:46:15.496 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.37037037037037\n",
      "2021-08-25 10:46:15.497 | WARNING  | src.policies:train:131 - The actual batch size is 221, instead of 200\n",
      "2021-08-25 10:46:15.503 | INFO     | src.policies:train:157 - Total loss: 158.08831787109375\n",
      "2021-08-25 10:46:15.503 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:15.506 | INFO     | src.policies:train:103 - Epoch 7 / 800\n",
      "2021-08-25 10:46:15.507 | INFO     | src.policies:train:109 - Episode 55\n",
      "2021-08-25 10:46:15.522 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.523 | INFO     | src.policies:train:121 - Mean episode return: 53.0\n",
      "2021-08-25 10:46:15.524 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.89090909090909\n",
      "2021-08-25 10:46:15.525 | INFO     | src.policies:train:109 - Episode 56\n",
      "2021-08-25 10:46:15.535 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.536 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 10:46:15.537 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.0\n",
      "2021-08-25 10:46:15.538 | INFO     | src.policies:train:109 - Episode 57\n",
      "2021-08-25 10:46:15.545 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.546 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:15.546 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.87719298245614\n",
      "2021-08-25 10:46:15.547 | INFO     | src.policies:train:109 - Episode 58\n",
      "2021-08-25 10:46:15.558 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.559 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 10:46:15.560 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.0\n",
      "2021-08-25 10:46:15.560 | INFO     | src.policies:train:109 - Episode 59\n",
      "2021-08-25 10:46:15.567 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.568 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:15.569 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.796610169491526\n",
      "2021-08-25 10:46:15.569 | INFO     | src.policies:train:109 - Episode 60\n",
      "2021-08-25 10:46:15.575 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.576 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:15.577 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.616666666666667\n",
      "2021-08-25 10:46:15.577 | INFO     | src.policies:train:109 - Episode 61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:15.585 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.586 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 10:46:15.586 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.557377049180328\n",
      "2021-08-25 10:46:15.587 | INFO     | src.policies:train:109 - Episode 62\n",
      "2021-08-25 10:46:15.598 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.599 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 10:46:15.600 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.70967741935484\n",
      "2021-08-25 10:46:15.600 | WARNING  | src.policies:train:131 - The actual batch size is 216, instead of 200\n",
      "2021-08-25 10:46:15.605 | INFO     | src.policies:train:157 - Total loss: 259.30316162109375\n",
      "2021-08-25 10:46:15.606 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:15.608 | INFO     | src.policies:train:103 - Epoch 8 / 800\n",
      "2021-08-25 10:46:15.609 | INFO     | src.policies:train:109 - Episode 63\n",
      "2021-08-25 10:46:15.623 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.624 | INFO     | src.policies:train:121 - Mean episode return: 45.0\n",
      "2021-08-25 10:46:15.624 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.03174603174603\n",
      "2021-08-25 10:46:15.625 | INFO     | src.policies:train:109 - Episode 64\n",
      "2021-08-25 10:46:15.633 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.634 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 10:46:15.634 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.90625\n",
      "2021-08-25 10:46:15.635 | INFO     | src.policies:train:109 - Episode 65\n",
      "2021-08-25 10:46:15.642 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.643 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:15.644 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.8\n",
      "2021-08-25 10:46:15.644 | INFO     | src.policies:train:109 - Episode 66\n",
      "2021-08-25 10:46:15.651 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.652 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 10:46:15.653 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.681818181818183\n",
      "2021-08-25 10:46:15.654 | INFO     | src.policies:train:109 - Episode 67\n",
      "2021-08-25 10:46:15.661 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.661 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:15.662 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.597014925373134\n",
      "2021-08-25 10:46:15.663 | INFO     | src.policies:train:109 - Episode 68\n",
      "2021-08-25 10:46:15.671 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.672 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 10:46:15.673 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.529411764705884\n",
      "2021-08-25 10:46:15.674 | INFO     | src.policies:train:109 - Episode 69\n",
      "2021-08-25 10:46:15.682 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.683 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 10:46:15.684 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.507246376811594\n",
      "2021-08-25 10:46:15.685 | INFO     | src.policies:train:109 - Episode 70\n",
      "2021-08-25 10:46:15.692 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.692 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:15.693 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.385714285714286\n",
      "2021-08-25 10:46:15.694 | INFO     | src.policies:train:109 - Episode 71\n",
      "2021-08-25 10:46:15.701 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.702 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 10:46:15.702 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.281690140845072\n",
      "2021-08-25 10:46:15.703 | INFO     | src.policies:train:109 - Episode 72\n",
      "2021-08-25 10:46:15.710 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.711 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:15.711 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.125\n",
      "2021-08-25 10:46:15.712 | WARNING  | src.policies:train:131 - The actual batch size is 205, instead of 200\n",
      "2021-08-25 10:46:15.717 | INFO     | src.policies:train:157 - Total loss: 161.19863891601562\n",
      "2021-08-25 10:46:15.717 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:15.719 | INFO     | src.policies:train:103 - Epoch 9 / 800\n",
      "2021-08-25 10:46:15.720 | INFO     | src.policies:train:109 - Episode 73\n",
      "2021-08-25 10:46:15.726 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.727 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:15.728 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.013698630136986\n",
      "2021-08-25 10:46:15.729 | INFO     | src.policies:train:109 - Episode 74\n",
      "2021-08-25 10:46:15.736 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.737 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:15.738 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.945945945945947\n",
      "2021-08-25 10:46:15.738 | INFO     | src.policies:train:109 - Episode 75\n",
      "2021-08-25 10:46:15.746 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.747 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:15.747 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.8\n",
      "2021-08-25 10:46:15.748 | INFO     | src.policies:train:109 - Episode 76\n",
      "2021-08-25 10:46:15.754 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.755 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 10:46:15.755 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.63157894736842\n",
      "2021-08-25 10:46:15.756 | INFO     | src.policies:train:109 - Episode 77\n",
      "2021-08-25 10:46:15.764 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.765 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:15.765 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.558441558441558\n",
      "2021-08-25 10:46:15.766 | INFO     | src.policies:train:109 - Episode 78\n",
      "2021-08-25 10:46:15.775 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.776 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 10:46:15.777 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.53846153846154\n",
      "2021-08-25 10:46:15.777 | INFO     | src.policies:train:109 - Episode 79\n",
      "2021-08-25 10:46:15.783 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.784 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:15.785 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.39240506329114\n",
      "2021-08-25 10:46:15.786 | INFO     | src.policies:train:109 - Episode 80\n",
      "2021-08-25 10:46:15.791 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.792 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 10:46:15.793 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.225\n",
      "2021-08-25 10:46:15.794 | INFO     | src.policies:train:109 - Episode 81\n",
      "2021-08-25 10:46:15.800 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:15.801 | INFO     | src.policies:train:121 - Mean episode return: 9.0\n",
      "2021-08-25 10:46:15.802 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.049382716049383\n",
      "2021-08-25 10:46:15.803 | INFO     | src.policies:train:109 - Episode 82\n",
      "2021-08-25 10:46:15.812 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.813 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:15.814 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.951219512195124\n",
      "2021-08-25 10:46:15.815 | INFO     | src.policies:train:109 - Episode 83\n",
      "2021-08-25 10:46:15.834 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.835 | INFO     | src.policies:train:121 - Mean episode return: 48.0\n",
      "2021-08-25 10:46:15.836 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.253012048192772\n",
      "2021-08-25 10:46:15.837 | INFO     | src.policies:train:109 - Episode 84\n",
      "2021-08-25 10:46:15.843 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.845 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:15.845 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.11904761904762\n",
      "2021-08-25 10:46:15.846 | WARNING  | src.policies:train:131 - The actual batch size is 205, instead of 200\n",
      "2021-08-25 10:46:15.854 | INFO     | src.policies:train:157 - Total loss: 157.7776641845703\n",
      "2021-08-25 10:46:15.854 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:15.857 | INFO     | src.policies:train:103 - Epoch 10 / 800\n",
      "2021-08-25 10:46:15.858 | INFO     | src.policies:train:109 - Episode 85\n",
      "2021-08-25 10:46:15.867 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.868 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 10:46:15.869 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.094117647058823\n",
      "2021-08-25 10:46:15.870 | INFO     | src.policies:train:109 - Episode 86\n",
      "2021-08-25 10:46:15.878 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.879 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 10:46:15.880 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.023255813953487\n",
      "2021-08-25 10:46:15.881 | INFO     | src.policies:train:109 - Episode 87\n",
      "2021-08-25 10:46:15.892 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.893 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 10:46:15.894 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.011494252873565\n",
      "2021-08-25 10:46:15.895 | INFO     | src.policies:train:109 - Episode 88\n",
      "2021-08-25 10:46:15.906 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.908 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 10:46:15.908 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.03409090909091\n",
      "2021-08-25 10:46:15.909 | INFO     | src.policies:train:109 - Episode 89\n",
      "2021-08-25 10:46:15.924 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.925 | INFO     | src.policies:train:121 - Mean episode return: 39.0\n",
      "2021-08-25 10:46:15.926 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.213483146067414\n",
      "2021-08-25 10:46:15.927 | INFO     | src.policies:train:109 - Episode 90\n",
      "2021-08-25 10:46:15.934 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.935 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:15.936 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.1\n",
      "2021-08-25 10:46:15.937 | INFO     | src.policies:train:109 - Episode 91\n",
      "2021-08-25 10:46:15.949 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.950 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 10:46:15.951 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.10989010989011\n",
      "2021-08-25 10:46:15.952 | INFO     | src.policies:train:109 - Episode 92\n",
      "2021-08-25 10:46:15.962 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.963 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 10:46:15.964 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.108695652173914\n",
      "2021-08-25 10:46:15.964 | INFO     | src.policies:train:109 - Episode 93\n",
      "2021-08-25 10:46:15.973 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:15.974 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 10:46:15.974 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.086021505376344\n",
      "2021-08-25 10:46:15.975 | WARNING  | src.policies:train:131 - The actual batch size is 205, instead of 200\n",
      "2021-08-25 10:46:15.980 | INFO     | src.policies:train:157 - Total loss: 162.17678833007812\n",
      "2021-08-25 10:46:15.980 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:15.983 | INFO     | src.policies:train:103 - Epoch 11 / 800\n",
      "2021-08-25 10:46:15.984 | INFO     | src.policies:train:109 - Episode 94\n",
      "2021-08-25 10:46:16.009 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.011 | INFO     | src.policies:train:121 - Mean episode return: 84.0\n",
      "2021-08-25 10:46:16.011 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.73404255319149\n",
      "2021-08-25 10:46:16.012 | INFO     | src.policies:train:109 - Episode 95\n",
      "2021-08-25 10:46:16.020 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.021 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:16.021 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.68421052631579\n",
      "2021-08-25 10:46:16.022 | INFO     | src.policies:train:109 - Episode 96\n",
      "2021-08-25 10:46:16.028 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.029 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:16.030 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.5625\n",
      "2021-08-25 10:46:16.031 | INFO     | src.policies:train:109 - Episode 97\n",
      "2021-08-25 10:46:16.037 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.038 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:16.038 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.463917525773194\n",
      "2021-08-25 10:46:16.039 | INFO     | src.policies:train:109 - Episode 98\n",
      "2021-08-25 10:46:16.048 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.049 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 10:46:16.050 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.459183673469386\n",
      "2021-08-25 10:46:16.050 | INFO     | src.policies:train:109 - Episode 99\n",
      "2021-08-25 10:46:16.072 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.073 | INFO     | src.policies:train:121 - Mean episode return: 67.0\n",
      "2021-08-25 10:46:16.073 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.8989898989899\n",
      "2021-08-25 10:46:16.074 | WARNING  | src.policies:train:131 - The actual batch size is 219, instead of 200\n",
      "2021-08-25 10:46:16.079 | INFO     | src.policies:train:157 - Total loss: 574.1613159179688\n",
      "2021-08-25 10:46:16.079 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:16.082 | INFO     | src.policies:train:103 - Epoch 12 / 800\n",
      "2021-08-25 10:46:16.083 | INFO     | src.policies:train:109 - Episode 100\n",
      "2021-08-25 10:46:16.089 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:16.090 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 10:46:16.091 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.83\n",
      "2021-08-25 10:46:16.091 | INFO     | src.policies:train:109 - Episode 101\n",
      "2021-08-25 10:46:16.099 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.099 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:16.100 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.54\n",
      "2021-08-25 10:46:16.101 | INFO     | src.policies:train:109 - Episode 102\n",
      "2021-08-25 10:46:16.108 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.109 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 10:46:16.110 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.58\n",
      "2021-08-25 10:46:16.111 | INFO     | src.policies:train:109 - Episode 103\n",
      "2021-08-25 10:46:16.116 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.116 | INFO     | src.policies:train:121 - Mean episode return: 9.0\n",
      "2021-08-25 10:46:16.117 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.46\n",
      "2021-08-25 10:46:16.118 | INFO     | src.policies:train:109 - Episode 104\n",
      "2021-08-25 10:46:16.123 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.124 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 10:46:16.124 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.16\n",
      "2021-08-25 10:46:16.125 | INFO     | src.policies:train:109 - Episode 105\n",
      "2021-08-25 10:46:16.139 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.140 | INFO     | src.policies:train:121 - Mean episode return: 38.0\n",
      "2021-08-25 10:46:16.141 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.42\n",
      "2021-08-25 10:46:16.141 | INFO     | src.policies:train:109 - Episode 106\n",
      "2021-08-25 10:46:16.155 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.156 | INFO     | src.policies:train:121 - Mean episode return: 42.0\n",
      "2021-08-25 10:46:16.157 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.51\n",
      "2021-08-25 10:46:16.158 | INFO     | src.policies:train:109 - Episode 107\n",
      "2021-08-25 10:46:16.167 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.168 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 10:46:16.169 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.56\n",
      "2021-08-25 10:46:16.169 | INFO     | src.policies:train:109 - Episode 108\n",
      "2021-08-25 10:46:16.177 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.178 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:16.178 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.62\n",
      "2021-08-25 10:46:16.179 | INFO     | src.policies:train:109 - Episode 109\n",
      "2021-08-25 10:46:16.187 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.188 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:16.188 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.56\n",
      "2021-08-25 10:46:16.189 | WARNING  | src.policies:train:131 - The actual batch size is 212, instead of 200\n",
      "2021-08-25 10:46:16.194 | INFO     | src.policies:train:157 - Total loss: 183.18310546875\n",
      "2021-08-25 10:46:16.195 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:16.197 | INFO     | src.policies:train:103 - Epoch 13 / 800\n",
      "2021-08-25 10:46:16.198 | INFO     | src.policies:train:109 - Episode 110\n",
      "2021-08-25 10:46:16.205 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.206 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:16.206 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.57\n",
      "2021-08-25 10:46:16.207 | INFO     | src.policies:train:109 - Episode 111\n",
      "2021-08-25 10:46:16.215 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.215 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:16.216 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.55\n",
      "2021-08-25 10:46:16.217 | INFO     | src.policies:train:109 - Episode 112\n",
      "2021-08-25 10:46:16.223 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.224 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:16.225 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.51\n",
      "2021-08-25 10:46:16.225 | INFO     | src.policies:train:109 - Episode 113\n",
      "2021-08-25 10:46:16.233 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.234 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:16.235 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.59\n",
      "2021-08-25 10:46:16.235 | INFO     | src.policies:train:109 - Episode 114\n",
      "2021-08-25 10:46:16.241 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.242 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:16.243 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.52\n",
      "2021-08-25 10:46:16.243 | INFO     | src.policies:train:109 - Episode 115\n",
      "2021-08-25 10:46:16.254 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.255 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 10:46:16.256 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.25\n",
      "2021-08-25 10:46:16.256 | INFO     | src.policies:train:109 - Episode 116\n",
      "2021-08-25 10:46:16.264 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.265 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:16.265 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.02\n",
      "2021-08-25 10:46:16.266 | INFO     | src.policies:train:109 - Episode 117\n",
      "2021-08-25 10:46:16.273 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.274 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:16.274 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.85\n",
      "2021-08-25 10:46:16.275 | INFO     | src.policies:train:109 - Episode 118\n",
      "2021-08-25 10:46:16.286 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.287 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 10:46:16.287 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.75\n",
      "2021-08-25 10:46:16.288 | INFO     | src.policies:train:109 - Episode 119\n",
      "2021-08-25 10:46:16.299 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.300 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 10:46:16.301 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.95\n",
      "2021-08-25 10:46:16.301 | WARNING  | src.policies:train:131 - The actual batch size is 202, instead of 200\n",
      "2021-08-25 10:46:16.306 | INFO     | src.policies:train:157 - Total loss: 142.91876220703125\n",
      "2021-08-25 10:46:16.307 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:16.310 | INFO     | src.policies:train:103 - Epoch 14 / 800\n",
      "2021-08-25 10:46:16.311 | INFO     | src.policies:train:109 - Episode 120\n",
      "2021-08-25 10:46:16.317 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.318 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:16.318 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:16.319 | INFO     | src.policies:train:109 - Episode 121\n",
      "2021-08-25 10:46:16.326 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.327 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:16.327 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.72\n",
      "2021-08-25 10:46:16.328 | INFO     | src.policies:train:109 - Episode 122\n",
      "2021-08-25 10:46:16.346 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.347 | INFO     | src.policies:train:121 - Mean episode return: 56.0\n",
      "2021-08-25 10:46:16.348 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.07\n",
      "2021-08-25 10:46:16.349 | INFO     | src.policies:train:109 - Episode 123\n",
      "2021-08-25 10:46:16.358 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.359 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 10:46:16.359 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.98\n",
      "2021-08-25 10:46:16.360 | INFO     | src.policies:train:109 - Episode 124\n",
      "2021-08-25 10:46:16.366 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.367 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:16.368 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.95\n",
      "2021-08-25 10:46:16.369 | INFO     | src.policies:train:109 - Episode 125\n",
      "2021-08-25 10:46:16.375 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.376 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:16.377 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.89\n",
      "2021-08-25 10:46:16.378 | INFO     | src.policies:train:109 - Episode 126\n",
      "2021-08-25 10:46:16.384 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.385 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:16.386 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.82\n",
      "2021-08-25 10:46:16.387 | INFO     | src.policies:train:109 - Episode 127\n",
      "2021-08-25 10:46:16.395 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.396 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:16.396 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.71\n",
      "2021-08-25 10:46:16.397 | INFO     | src.policies:train:109 - Episode 128\n",
      "2021-08-25 10:46:16.403 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.404 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:16.405 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.69\n",
      "2021-08-25 10:46:16.406 | INFO     | src.policies:train:109 - Episode 129\n",
      "2021-08-25 10:46:16.411 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.412 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:16.413 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.67\n",
      "2021-08-25 10:46:16.414 | INFO     | src.policies:train:109 - Episode 130\n",
      "2021-08-25 10:46:16.423 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.424 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 10:46:16.425 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.73\n",
      "2021-08-25 10:46:16.426 | WARNING  | src.policies:train:131 - The actual batch size is 218, instead of 200\n",
      "2021-08-25 10:46:16.431 | INFO     | src.policies:train:157 - Total loss: 204.10595703125\n",
      "2021-08-25 10:46:16.432 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:16.434 | INFO     | src.policies:train:103 - Epoch 15 / 800\n",
      "2021-08-25 10:46:16.435 | INFO     | src.policies:train:109 - Episode 131\n",
      "2021-08-25 10:46:16.440 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.441 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:16.442 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.35\n",
      "2021-08-25 10:46:16.443 | INFO     | src.policies:train:109 - Episode 132\n",
      "2021-08-25 10:46:16.450 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.451 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:16.451 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.27\n",
      "2021-08-25 10:46:16.452 | INFO     | src.policies:train:109 - Episode 133\n",
      "2021-08-25 10:46:16.475 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.476 | INFO     | src.policies:train:121 - Mean episode return: 71.0\n",
      "2021-08-25 10:46:16.476 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.83\n",
      "2021-08-25 10:46:16.477 | INFO     | src.policies:train:109 - Episode 134\n",
      "2021-08-25 10:46:16.483 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.484 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:16.485 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.75\n",
      "2021-08-25 10:46:16.486 | INFO     | src.policies:train:109 - Episode 135\n",
      "2021-08-25 10:46:16.493 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.494 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:16.495 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.49\n",
      "2021-08-25 10:46:16.496 | INFO     | src.policies:train:109 - Episode 136\n",
      "2021-08-25 10:46:16.501 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.502 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 10:46:16.503 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.44\n",
      "2021-08-25 10:46:16.504 | INFO     | src.policies:train:109 - Episode 137\n",
      "2021-08-25 10:46:16.516 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.517 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 10:46:16.518 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.63\n",
      "2021-08-25 10:46:16.518 | INFO     | src.policies:train:109 - Episode 138\n",
      "2021-08-25 10:46:16.525 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.526 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:16.527 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.51\n",
      "2021-08-25 10:46:16.528 | INFO     | src.policies:train:109 - Episode 139\n",
      "2021-08-25 10:46:16.535 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.536 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:16.536 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.34\n",
      "2021-08-25 10:46:16.537 | WARNING  | src.policies:train:131 - The actual batch size is 201, instead of 200\n",
      "2021-08-25 10:46:16.542 | INFO     | src.policies:train:157 - Total loss: 324.3236999511719\n",
      "2021-08-25 10:46:16.542 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:16.545 | INFO     | src.policies:train:103 - Epoch 16 / 800\n",
      "2021-08-25 10:46:16.546 | INFO     | src.policies:train:109 - Episode 140\n",
      "2021-08-25 10:46:16.552 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.553 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:16.554 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.93\n",
      "2021-08-25 10:46:16.554 | INFO     | src.policies:train:109 - Episode 141\n",
      "2021-08-25 10:46:16.560 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.561 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:16.562 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.84\n",
      "2021-08-25 10:46:16.563 | INFO     | src.policies:train:109 - Episode 142\n",
      "2021-08-25 10:46:16.568 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.569 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 10:46:16.570 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.83\n",
      "2021-08-25 10:46:16.571 | INFO     | src.policies:train:109 - Episode 143\n",
      "2021-08-25 10:46:16.578 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.579 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:16.579 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.77\n",
      "2021-08-25 10:46:16.580 | INFO     | src.policies:train:109 - Episode 144\n",
      "2021-08-25 10:46:16.588 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.589 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 10:46:16.590 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.8\n",
      "2021-08-25 10:46:16.591 | INFO     | src.policies:train:109 - Episode 145\n",
      "2021-08-25 10:46:16.607 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.608 | INFO     | src.policies:train:121 - Mean episode return: 49.0\n",
      "2021-08-25 10:46:16.609 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.16\n",
      "2021-08-25 10:46:16.610 | INFO     | src.policies:train:109 - Episode 146\n",
      "2021-08-25 10:46:16.615 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.616 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 10:46:16.616 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.06\n",
      "2021-08-25 10:46:16.617 | INFO     | src.policies:train:109 - Episode 147\n",
      "2021-08-25 10:46:16.622 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.622 | INFO     | src.policies:train:121 - Mean episode return: 9.0\n",
      "2021-08-25 10:46:16.623 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.87\n",
      "2021-08-25 10:46:16.624 | INFO     | src.policies:train:109 - Episode 148\n",
      "2021-08-25 10:46:16.630 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.631 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:16.632 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.79\n",
      "2021-08-25 10:46:16.632 | INFO     | src.policies:train:109 - Episode 149\n",
      "2021-08-25 10:46:16.640 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.641 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:16.641 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.77\n",
      "2021-08-25 10:46:16.642 | INFO     | src.policies:train:109 - Episode 150\n",
      "2021-08-25 10:46:16.655 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.656 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 10:46:16.657 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.89\n",
      "2021-08-25 10:46:16.657 | WARNING  | src.policies:train:131 - The actual batch size is 213, instead of 200\n",
      "2021-08-25 10:46:16.662 | INFO     | src.policies:train:157 - Total loss: 196.06324768066406\n",
      "2021-08-25 10:46:16.663 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:16.666 | INFO     | src.policies:train:103 - Epoch 17 / 800\n",
      "2021-08-25 10:46:16.667 | INFO     | src.policies:train:109 - Episode 151\n",
      "2021-08-25 10:46:16.676 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.677 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 10:46:16.677 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.96\n",
      "2021-08-25 10:46:16.678 | INFO     | src.policies:train:109 - Episode 152\n",
      "2021-08-25 10:46:16.685 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.686 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:16.687 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.93\n",
      "2021-08-25 10:46:16.688 | INFO     | src.policies:train:109 - Episode 153\n",
      "2021-08-25 10:46:16.696 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.697 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:16.697 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.93\n",
      "2021-08-25 10:46:16.698 | INFO     | src.policies:train:109 - Episode 154\n",
      "2021-08-25 10:46:16.705 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.706 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:16.707 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.69\n",
      "2021-08-25 10:46:16.707 | INFO     | src.policies:train:109 - Episode 155\n",
      "2021-08-25 10:46:16.719 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.720 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 10:46:16.720 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.49\n",
      "2021-08-25 10:46:16.721 | INFO     | src.policies:train:109 - Episode 156\n",
      "2021-08-25 10:46:16.727 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.729 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 10:46:16.729 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.29\n",
      "2021-08-25 10:46:16.730 | INFO     | src.policies:train:109 - Episode 157\n",
      "2021-08-25 10:46:16.735 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.736 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:16.737 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.23\n",
      "2021-08-25 10:46:16.737 | INFO     | src.policies:train:109 - Episode 158\n",
      "2021-08-25 10:46:16.747 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.748 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 10:46:16.749 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.17\n",
      "2021-08-25 10:46:16.749 | INFO     | src.policies:train:109 - Episode 159\n",
      "2021-08-25 10:46:16.756 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.757 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:16.757 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.18\n",
      "2021-08-25 10:46:16.758 | INFO     | src.policies:train:109 - Episode 160\n",
      "2021-08-25 10:46:16.768 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.769 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 10:46:16.769 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.31\n",
      "2021-08-25 10:46:16.770 | INFO     | src.policies:train:109 - Episode 161\n",
      "2021-08-25 10:46:16.779 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.779 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 10:46:16.780 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.32\n",
      "2021-08-25 10:46:16.781 | WARNING  | src.policies:train:131 - The actual batch size is 218, instead of 200\n",
      "2021-08-25 10:46:16.786 | INFO     | src.policies:train:157 - Total loss: 135.75978088378906\n",
      "2021-08-25 10:46:16.787 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:16.790 | INFO     | src.policies:train:103 - Epoch 18 / 800\n",
      "2021-08-25 10:46:16.791 | INFO     | src.policies:train:109 - Episode 162\n",
      "2021-08-25 10:46:16.798 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:16.799 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 10:46:16.800 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.18\n",
      "2021-08-25 10:46:16.800 | INFO     | src.policies:train:109 - Episode 163\n",
      "2021-08-25 10:46:16.812 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.813 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 10:46:16.814 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.05\n",
      "2021-08-25 10:46:16.814 | INFO     | src.policies:train:109 - Episode 164\n",
      "2021-08-25 10:46:16.822 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.823 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 10:46:16.824 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.09\n",
      "2021-08-25 10:46:16.825 | INFO     | src.policies:train:109 - Episode 165\n",
      "2021-08-25 10:46:16.831 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.832 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:16.833 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.04\n",
      "2021-08-25 10:46:16.833 | INFO     | src.policies:train:109 - Episode 166\n",
      "2021-08-25 10:46:16.838 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.839 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 10:46:16.839 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 20.97\n",
      "2021-08-25 10:46:16.840 | INFO     | src.policies:train:109 - Episode 167\n",
      "2021-08-25 10:46:16.855 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.856 | INFO     | src.policies:train:121 - Mean episode return: 46.0\n",
      "2021-08-25 10:46:16.856 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.24\n",
      "2021-08-25 10:46:16.857 | INFO     | src.policies:train:109 - Episode 168\n",
      "2021-08-25 10:46:16.863 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.864 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 10:46:16.864 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.15\n",
      "2021-08-25 10:46:16.865 | INFO     | src.policies:train:109 - Episode 169\n",
      "2021-08-25 10:46:16.875 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.876 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 10:46:16.876 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.17\n",
      "2021-08-25 10:46:16.877 | INFO     | src.policies:train:109 - Episode 170\n",
      "2021-08-25 10:46:16.884 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.885 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:16.886 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.19\n",
      "2021-08-25 10:46:16.887 | INFO     | src.policies:train:109 - Episode 171\n",
      "2021-08-25 10:46:16.898 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.899 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 10:46:16.900 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.35\n",
      "2021-08-25 10:46:16.901 | WARNING  | src.policies:train:131 - The actual batch size is 229, instead of 200\n",
      "2021-08-25 10:46:16.906 | INFO     | src.policies:train:157 - Total loss: 201.30911254882812\n",
      "2021-08-25 10:46:16.907 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:16.909 | INFO     | src.policies:train:103 - Epoch 19 / 800\n",
      "2021-08-25 10:46:16.910 | INFO     | src.policies:train:109 - Episode 172\n",
      "2021-08-25 10:46:16.923 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.924 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 10:46:16.925 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.62\n",
      "2021-08-25 10:46:16.925 | INFO     | src.policies:train:109 - Episode 173\n",
      "2021-08-25 10:46:16.935 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.936 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 10:46:16.936 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.68\n",
      "2021-08-25 10:46:16.937 | INFO     | src.policies:train:109 - Episode 174\n",
      "2021-08-25 10:46:16.947 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.948 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 10:46:16.949 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.73\n",
      "2021-08-25 10:46:16.949 | INFO     | src.policies:train:109 - Episode 175\n",
      "2021-08-25 10:46:16.960 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.961 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 10:46:16.961 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.85\n",
      "2021-08-25 10:46:16.962 | INFO     | src.policies:train:109 - Episode 176\n",
      "2021-08-25 10:46:16.979 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.980 | INFO     | src.policies:train:121 - Mean episode return: 50.0\n",
      "2021-08-25 10:46:16.981 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.24\n",
      "2021-08-25 10:46:16.981 | INFO     | src.policies:train:109 - Episode 177\n",
      "2021-08-25 10:46:16.991 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:16.992 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 10:46:16.992 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.29\n",
      "2021-08-25 10:46:16.993 | INFO     | src.policies:train:109 - Episode 178\n",
      "2021-08-25 10:46:17.002 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.003 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 10:46:17.004 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.3\n",
      "2021-08-25 10:46:17.005 | WARNING  | src.policies:train:131 - The actual batch size is 207, instead of 200\n",
      "2021-08-25 10:46:17.010 | INFO     | src.policies:train:157 - Total loss: 255.16720581054688\n",
      "2021-08-25 10:46:17.011 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:17.013 | INFO     | src.policies:train:103 - Epoch 20 / 800\n",
      "2021-08-25 10:46:17.014 | INFO     | src.policies:train:109 - Episode 179\n",
      "2021-08-25 10:46:17.019 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.020 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:17.021 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.31\n",
      "2021-08-25 10:46:17.022 | INFO     | src.policies:train:109 - Episode 180\n",
      "2021-08-25 10:46:17.030 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.031 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 10:46:17.032 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.42\n",
      "2021-08-25 10:46:17.033 | INFO     | src.policies:train:109 - Episode 181\n",
      "2021-08-25 10:46:17.040 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.041 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:17.042 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.51\n",
      "2021-08-25 10:46:17.043 | INFO     | src.policies:train:109 - Episode 182\n",
      "2021-08-25 10:46:17.050 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.051 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:17.052 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:17.052 | INFO     | src.policies:train:109 - Episode 183\n",
      "2021-08-25 10:46:17.068 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.069 | INFO     | src.policies:train:121 - Mean episode return: 46.0\n",
      "2021-08-25 10:46:17.069 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.5\n",
      "2021-08-25 10:46:17.070 | INFO     | src.policies:train:109 - Episode 184\n",
      "2021-08-25 10:46:17.079 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.079 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:17.080 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.57\n",
      "2021-08-25 10:46:17.081 | INFO     | src.policies:train:109 - Episode 185\n",
      "2021-08-25 10:46:17.091 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.092 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 10:46:17.093 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.64\n",
      "2021-08-25 10:46:17.094 | INFO     | src.policies:train:109 - Episode 186\n",
      "2021-08-25 10:46:17.105 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.106 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 10:46:17.107 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.8\n",
      "2021-08-25 10:46:17.108 | INFO     | src.policies:train:109 - Episode 187\n",
      "2021-08-25 10:46:17.116 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.117 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 10:46:17.118 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.81\n",
      "2021-08-25 10:46:17.119 | WARNING  | src.policies:train:131 - The actual batch size is 217, instead of 200\n",
      "2021-08-25 10:46:17.124 | INFO     | src.policies:train:157 - Total loss: 198.2537841796875\n",
      "2021-08-25 10:46:17.124 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:17.127 | INFO     | src.policies:train:103 - Epoch 21 / 800\n",
      "2021-08-25 10:46:17.128 | INFO     | src.policies:train:109 - Episode 188\n",
      "2021-08-25 10:46:17.133 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.134 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:17.135 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.7\n",
      "2021-08-25 10:46:17.136 | INFO     | src.policies:train:109 - Episode 189\n",
      "2021-08-25 10:46:17.146 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.147 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 10:46:17.147 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.6\n",
      "2021-08-25 10:46:17.148 | INFO     | src.policies:train:109 - Episode 190\n",
      "2021-08-25 10:46:17.155 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.156 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:17.157 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.65\n",
      "2021-08-25 10:46:17.158 | INFO     | src.policies:train:109 - Episode 191\n",
      "2021-08-25 10:46:17.164 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.164 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:17.165 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.54\n",
      "2021-08-25 10:46:17.166 | INFO     | src.policies:train:109 - Episode 192\n",
      "2021-08-25 10:46:17.178 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.179 | INFO     | src.policies:train:121 - Mean episode return: 38.0\n",
      "2021-08-25 10:46:17.180 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.69\n",
      "2021-08-25 10:46:17.181 | INFO     | src.policies:train:109 - Episode 193\n",
      "2021-08-25 10:46:17.187 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.188 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:17.189 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.61\n",
      "2021-08-25 10:46:17.190 | INFO     | src.policies:train:109 - Episode 194\n",
      "2021-08-25 10:46:17.197 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.198 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:17.199 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.96\n",
      "2021-08-25 10:46:17.200 | INFO     | src.policies:train:109 - Episode 195\n",
      "2021-08-25 10:46:17.212 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.213 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 10:46:17.214 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.1\n",
      "2021-08-25 10:46:17.214 | INFO     | src.policies:train:109 - Episode 196\n",
      "2021-08-25 10:46:17.228 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.229 | INFO     | src.policies:train:121 - Mean episode return: 39.0\n",
      "2021-08-25 10:46:17.230 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.37\n",
      "2021-08-25 10:46:17.230 | WARNING  | src.policies:train:131 - The actual batch size is 216, instead of 200\n",
      "2021-08-25 10:46:17.236 | INFO     | src.policies:train:157 - Total loss: 201.90602111816406\n",
      "2021-08-25 10:46:17.236 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:17.238 | INFO     | src.policies:train:103 - Epoch 22 / 800\n",
      "2021-08-25 10:46:17.239 | INFO     | src.policies:train:109 - Episode 197\n",
      "2021-08-25 10:46:17.250 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.251 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 10:46:17.252 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.55\n",
      "2021-08-25 10:46:17.253 | INFO     | src.policies:train:109 - Episode 198\n",
      "2021-08-25 10:46:17.260 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.261 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:17.261 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.48\n",
      "2021-08-25 10:46:17.262 | INFO     | src.policies:train:109 - Episode 199\n",
      "2021-08-25 10:46:17.268 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.269 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:17.270 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.93\n",
      "2021-08-25 10:46:17.271 | INFO     | src.policies:train:109 - Episode 200\n",
      "2021-08-25 10:46:17.282 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.283 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 10:46:17.283 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.08\n",
      "2021-08-25 10:46:17.284 | INFO     | src.policies:train:109 - Episode 201\n",
      "2021-08-25 10:46:17.292 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.292 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:17.293 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.06\n",
      "2021-08-25 10:46:17.294 | INFO     | src.policies:train:109 - Episode 202\n",
      "2021-08-25 10:46:17.300 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.301 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:17.302 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.03\n",
      "2021-08-25 10:46:17.303 | INFO     | src.policies:train:109 - Episode 203\n",
      "2021-08-25 10:46:17.310 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.311 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:17.312 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.09\n",
      "2021-08-25 10:46:17.312 | INFO     | src.policies:train:109 - Episode 204\n",
      "2021-08-25 10:46:17.318 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.320 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:17.320 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.12\n",
      "2021-08-25 10:46:17.321 | INFO     | src.policies:train:109 - Episode 205\n",
      "2021-08-25 10:46:17.331 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.332 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 10:46:17.332 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.0\n",
      "2021-08-25 10:46:17.333 | INFO     | src.policies:train:109 - Episode 206\n",
      "2021-08-25 10:46:17.344 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.345 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 10:46:17.345 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.87\n",
      "2021-08-25 10:46:17.346 | WARNING  | src.policies:train:131 - The actual batch size is 206, instead of 200\n",
      "2021-08-25 10:46:17.351 | INFO     | src.policies:train:157 - Total loss: 147.72520446777344\n",
      "2021-08-25 10:46:17.352 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:17.354 | INFO     | src.policies:train:103 - Epoch 23 / 800\n",
      "2021-08-25 10:46:17.355 | INFO     | src.policies:train:109 - Episode 207\n",
      "2021-08-25 10:46:17.366 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.367 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 10:46:17.368 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.96\n",
      "2021-08-25 10:46:17.368 | INFO     | src.policies:train:109 - Episode 208\n",
      "2021-08-25 10:46:17.375 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.376 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:17.377 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.93\n",
      "2021-08-25 10:46:17.377 | INFO     | src.policies:train:109 - Episode 209\n",
      "2021-08-25 10:46:17.384 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.385 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:17.386 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.9\n",
      "2021-08-25 10:46:17.387 | INFO     | src.policies:train:109 - Episode 210\n",
      "2021-08-25 10:46:17.393 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.394 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:17.395 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.85\n",
      "2021-08-25 10:46:17.395 | INFO     | src.policies:train:109 - Episode 211\n",
      "2021-08-25 10:46:17.403 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.404 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:17.404 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.85\n",
      "2021-08-25 10:46:17.405 | INFO     | src.policies:train:109 - Episode 212\n",
      "2021-08-25 10:46:17.415 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.416 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 10:46:17.416 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.94\n",
      "2021-08-25 10:46:17.417 | INFO     | src.policies:train:109 - Episode 213\n",
      "2021-08-25 10:46:17.423 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.424 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:17.425 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.88\n",
      "2021-08-25 10:46:17.425 | INFO     | src.policies:train:109 - Episode 214\n",
      "2021-08-25 10:46:17.434 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.435 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:17.436 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.94\n",
      "2021-08-25 10:46:17.436 | INFO     | src.policies:train:109 - Episode 215\n",
      "2021-08-25 10:46:17.447 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.449 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 10:46:17.449 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.97\n",
      "2021-08-25 10:46:17.450 | INFO     | src.policies:train:109 - Episode 216\n",
      "2021-08-25 10:46:17.458 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.459 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:17.460 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.98\n",
      "2021-08-25 10:46:17.460 | INFO     | src.policies:train:109 - Episode 217\n",
      "2021-08-25 10:46:17.467 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.468 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:17.468 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.97\n",
      "2021-08-25 10:46:17.469 | WARNING  | src.policies:train:131 - The actual batch size is 211, instead of 200\n",
      "2021-08-25 10:46:17.475 | INFO     | src.policies:train:157 - Total loss: 133.8562469482422\n",
      "2021-08-25 10:46:17.475 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:17.478 | INFO     | src.policies:train:103 - Epoch 24 / 800\n",
      "2021-08-25 10:46:17.479 | INFO     | src.policies:train:109 - Episode 218\n",
      "2021-08-25 10:46:17.486 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.487 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 10:46:17.488 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.88\n",
      "2021-08-25 10:46:17.489 | INFO     | src.policies:train:109 - Episode 219\n",
      "2021-08-25 10:46:17.495 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.496 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 10:46:17.497 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.67\n",
      "2021-08-25 10:46:17.497 | INFO     | src.policies:train:109 - Episode 220\n",
      "2021-08-25 10:46:17.506 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.507 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 10:46:17.508 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.73\n",
      "2021-08-25 10:46:17.509 | INFO     | src.policies:train:109 - Episode 221\n",
      "2021-08-25 10:46:17.519 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.520 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 10:46:17.520 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.85\n",
      "2021-08-25 10:46:17.521 | INFO     | src.policies:train:109 - Episode 222\n",
      "2021-08-25 10:46:17.531 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.532 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 10:46:17.533 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.56\n",
      "2021-08-25 10:46:17.534 | INFO     | src.policies:train:109 - Episode 223\n",
      "2021-08-25 10:46:17.541 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.541 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:17.542 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.46\n",
      "2021-08-25 10:46:17.543 | INFO     | src.policies:train:109 - Episode 224\n",
      "2021-08-25 10:46:17.550 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:17.551 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:17.552 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.48\n",
      "2021-08-25 10:46:17.552 | INFO     | src.policies:train:109 - Episode 225\n",
      "2021-08-25 10:46:17.561 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.561 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 10:46:17.562 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.54\n",
      "2021-08-25 10:46:17.563 | INFO     | src.policies:train:109 - Episode 226\n",
      "2021-08-25 10:46:17.573 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.574 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 10:46:17.574 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.63\n",
      "2021-08-25 10:46:17.575 | INFO     | src.policies:train:109 - Episode 227\n",
      "2021-08-25 10:46:17.582 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.583 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:17.583 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.6\n",
      "2021-08-25 10:46:17.584 | INFO     | src.policies:train:109 - Episode 228\n",
      "2021-08-25 10:46:17.593 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.594 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 10:46:17.595 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.69\n",
      "2021-08-25 10:46:17.595 | WARNING  | src.policies:train:131 - The actual batch size is 215, instead of 200\n",
      "2021-08-25 10:46:17.601 | INFO     | src.policies:train:157 - Total loss: 116.8504867553711\n",
      "2021-08-25 10:46:17.601 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:17.604 | INFO     | src.policies:train:103 - Epoch 25 / 800\n",
      "2021-08-25 10:46:17.605 | INFO     | src.policies:train:109 - Episode 229\n",
      "2021-08-25 10:46:17.614 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.615 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 10:46:17.616 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.82\n",
      "2021-08-25 10:46:17.617 | INFO     | src.policies:train:109 - Episode 230\n",
      "2021-08-25 10:46:17.624 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.625 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:17.625 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.73\n",
      "2021-08-25 10:46:17.626 | INFO     | src.policies:train:109 - Episode 231\n",
      "2021-08-25 10:46:17.636 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.637 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 10:46:17.637 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.84\n",
      "2021-08-25 10:46:17.638 | INFO     | src.policies:train:109 - Episode 232\n",
      "2021-08-25 10:46:17.659 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.660 | INFO     | src.policies:train:121 - Mean episode return: 67.0\n",
      "2021-08-25 10:46:17.661 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.36\n",
      "2021-08-25 10:46:17.661 | INFO     | src.policies:train:109 - Episode 233\n",
      "2021-08-25 10:46:17.671 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.672 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 10:46:17.673 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.88\n",
      "2021-08-25 10:46:17.674 | INFO     | src.policies:train:109 - Episode 234\n",
      "2021-08-25 10:46:17.681 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.682 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:17.683 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.93\n",
      "2021-08-25 10:46:17.684 | INFO     | src.policies:train:109 - Episode 235\n",
      "2021-08-25 10:46:17.695 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.696 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 10:46:17.697 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.07\n",
      "2021-08-25 10:46:17.698 | WARNING  | src.policies:train:131 - The actual batch size is 205, instead of 200\n",
      "2021-08-25 10:46:17.703 | INFO     | src.policies:train:157 - Total loss: 320.7884826660156\n",
      "2021-08-25 10:46:17.704 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:17.706 | INFO     | src.policies:train:103 - Epoch 26 / 800\n",
      "2021-08-25 10:46:17.707 | INFO     | src.policies:train:109 - Episode 236\n",
      "2021-08-25 10:46:17.717 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.718 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 10:46:17.719 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.25\n",
      "2021-08-25 10:46:17.719 | INFO     | src.policies:train:109 - Episode 237\n",
      "2021-08-25 10:46:17.731 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.732 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 10:46:17.732 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.24\n",
      "2021-08-25 10:46:17.733 | INFO     | src.policies:train:109 - Episode 238\n",
      "2021-08-25 10:46:17.741 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.742 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 10:46:17.743 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.31\n",
      "2021-08-25 10:46:17.743 | INFO     | src.policies:train:109 - Episode 239\n",
      "2021-08-25 10:46:17.750 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.751 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:17.752 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.29\n",
      "2021-08-25 10:46:17.752 | INFO     | src.policies:train:109 - Episode 240\n",
      "2021-08-25 10:46:17.758 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.759 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 10:46:17.759 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.25\n",
      "2021-08-25 10:46:17.760 | INFO     | src.policies:train:109 - Episode 241\n",
      "2021-08-25 10:46:17.768 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.769 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:17.770 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.3\n",
      "2021-08-25 10:46:17.771 | INFO     | src.policies:train:109 - Episode 242\n",
      "2021-08-25 10:46:17.782 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.783 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 10:46:17.784 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.53\n",
      "2021-08-25 10:46:17.784 | INFO     | src.policies:train:109 - Episode 243\n",
      "2021-08-25 10:46:17.795 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.796 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 10:46:17.797 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.65\n",
      "2021-08-25 10:46:17.798 | INFO     | src.policies:train:109 - Episode 244\n",
      "2021-08-25 10:46:17.804 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.805 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:17.806 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:17.807 | INFO     | src.policies:train:109 - Episode 245\n",
      "2021-08-25 10:46:17.819 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.819 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 10:46:17.820 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.41\n",
      "2021-08-25 10:46:17.821 | WARNING  | src.policies:train:131 - The actual batch size is 229, instead of 200\n",
      "2021-08-25 10:46:17.827 | INFO     | src.policies:train:157 - Total loss: 169.75656127929688\n",
      "2021-08-25 10:46:17.827 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:17.830 | INFO     | src.policies:train:103 - Epoch 27 / 800\n",
      "2021-08-25 10:46:17.831 | INFO     | src.policies:train:109 - Episode 246\n",
      "2021-08-25 10:46:17.836 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.837 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 10:46:17.837 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.42\n",
      "2021-08-25 10:46:17.838 | INFO     | src.policies:train:109 - Episode 247\n",
      "2021-08-25 10:46:17.848 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.849 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 10:46:17.849 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.58\n",
      "2021-08-25 10:46:17.850 | INFO     | src.policies:train:109 - Episode 248\n",
      "2021-08-25 10:46:17.865 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.866 | INFO     | src.policies:train:121 - Mean episode return: 45.0\n",
      "2021-08-25 10:46:17.867 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.9\n",
      "2021-08-25 10:46:17.868 | INFO     | src.policies:train:109 - Episode 249\n",
      "2021-08-25 10:46:17.876 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.876 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:17.877 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.89\n",
      "2021-08-25 10:46:17.878 | INFO     | src.policies:train:109 - Episode 250\n",
      "2021-08-25 10:46:17.885 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.886 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:17.886 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.66\n",
      "2021-08-25 10:46:17.887 | INFO     | src.policies:train:109 - Episode 251\n",
      "2021-08-25 10:46:17.895 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.896 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:17.897 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.59\n",
      "2021-08-25 10:46:17.898 | INFO     | src.policies:train:109 - Episode 252\n",
      "2021-08-25 10:46:17.905 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.906 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:17.907 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.61\n",
      "2021-08-25 10:46:17.908 | INFO     | src.policies:train:109 - Episode 253\n",
      "2021-08-25 10:46:17.915 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.916 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:17.917 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.59\n",
      "2021-08-25 10:46:17.918 | INFO     | src.policies:train:109 - Episode 254\n",
      "2021-08-25 10:46:17.926 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.927 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:17.928 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.58\n",
      "2021-08-25 10:46:17.929 | INFO     | src.policies:train:109 - Episode 255\n",
      "2021-08-25 10:46:17.938 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.939 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:17.940 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.38\n",
      "2021-08-25 10:46:17.941 | INFO     | src.policies:train:109 - Episode 256\n",
      "2021-08-25 10:46:17.958 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.959 | INFO     | src.policies:train:121 - Mean episode return: 48.0\n",
      "2021-08-25 10:46:17.960 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.75\n",
      "2021-08-25 10:46:17.961 | WARNING  | src.policies:train:131 - The actual batch size is 239, instead of 200\n",
      "2021-08-25 10:46:17.969 | INFO     | src.policies:train:157 - Total loss: 210.55455017089844\n",
      "2021-08-25 10:46:17.970 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:17.973 | INFO     | src.policies:train:103 - Epoch 28 / 800\n",
      "2021-08-25 10:46:17.974 | INFO     | src.policies:train:109 - Episode 257\n",
      "2021-08-25 10:46:17.980 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.982 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:17.982 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.78\n",
      "2021-08-25 10:46:17.983 | INFO     | src.policies:train:109 - Episode 258\n",
      "2021-08-25 10:46:17.992 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:17.993 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 10:46:17.994 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.69\n",
      "2021-08-25 10:46:17.995 | INFO     | src.policies:train:109 - Episode 259\n",
      "2021-08-25 10:46:18.006 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:18.007 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 10:46:18.008 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.78\n",
      "2021-08-25 10:46:18.009 | INFO     | src.policies:train:109 - Episode 260\n",
      "2021-08-25 10:46:18.026 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:18.027 | INFO     | src.policies:train:121 - Mean episode return: 45.0\n",
      "2021-08-25 10:46:18.028 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.96\n",
      "2021-08-25 10:46:18.030 | INFO     | src.policies:train:109 - Episode 261\n",
      "2021-08-25 10:46:18.046 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:18.047 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 10:46:18.048 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.14\n",
      "2021-08-25 10:46:18.049 | INFO     | src.policies:train:109 - Episode 262\n",
      "2021-08-25 10:46:18.063 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:18.064 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 10:46:18.065 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.31\n",
      "2021-08-25 10:46:18.066 | INFO     | src.policies:train:109 - Episode 263\n",
      "2021-08-25 10:46:18.083 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:18.084 | INFO     | src.policies:train:121 - Mean episode return: 45.0\n",
      "2021-08-25 10:46:18.085 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.44\n",
      "2021-08-25 10:46:18.086 | WARNING  | src.policies:train:131 - The actual batch size is 222, instead of 200\n",
      "2021-08-25 10:46:18.093 | INFO     | src.policies:train:157 - Total loss: 290.9825744628906\n",
      "2021-08-25 10:46:18.093 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:18.097 | INFO     | src.policies:train:103 - Epoch 29 / 800\n",
      "2021-08-25 10:46:18.098 | INFO     | src.policies:train:109 - Episode 264\n",
      "2021-08-25 10:46:18.106 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:18.107 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:18.107 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.44\n",
      "2021-08-25 10:46:18.108 | INFO     | src.policies:train:109 - Episode 265\n",
      "2021-08-25 10:46:18.113 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:18.114 | INFO     | src.policies:train:121 - Mean episode return: 9.0\n",
      "2021-08-25 10:46:18.115 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.4\n",
      "2021-08-25 10:46:18.116 | INFO     | src.policies:train:109 - Episode 266\n",
      "2021-08-25 10:46:18.125 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:18.126 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 10:46:18.126 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.55\n",
      "2021-08-25 10:46:18.127 | INFO     | src.policies:train:109 - Episode 267\n",
      "2021-08-25 10:46:18.137 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:18.138 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 10:46:18.139 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.37\n",
      "2021-08-25 10:46:18.140 | INFO     | src.policies:train:109 - Episode 268\n",
      "2021-08-25 10:46:18.148 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:18.149 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:18.150 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.39\n",
      "2021-08-25 10:46:18.151 | INFO     | src.policies:train:109 - Episode 269\n",
      "2021-08-25 10:46:18.169 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:18.170 | INFO     | src.policies:train:121 - Mean episode return: 51.0\n",
      "2021-08-25 10:46:18.171 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.65\n",
      "2021-08-25 10:46:18.172 | INFO     | src.policies:train:109 - Episode 270\n",
      "2021-08-25 10:46:18.181 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:18.182 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:18.183 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.66\n",
      "2021-08-25 10:46:18.184 | INFO     | src.policies:train:109 - Episode 271\n",
      "2021-08-25 10:46:18.199 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:18.200 | INFO     | src.policies:train:121 - Mean episode return: 39.0\n",
      "2021-08-25 10:46:18.200 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.72\n",
      "2021-08-25 10:46:18.201 | WARNING  | src.policies:train:131 - The actual batch size is 205, instead of 200\n",
      "2021-08-25 10:46:18.208 | INFO     | src.policies:train:157 - Total loss: 244.6920166015625\n",
      "2021-08-25 10:46:18.209 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:18.212 | INFO     | src.policies:train:103 - Epoch 30 / 800\n",
      "2021-08-25 10:46:18.213 | INFO     | src.policies:train:109 - Episode 272\n",
      "2021-08-25 10:46:18.219 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:18.220 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:18.221 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.45\n",
      "2021-08-25 10:46:18.222 | INFO     | src.policies:train:109 - Episode 273\n",
      "2021-08-25 10:46:18.233 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:18.234 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 10:46:18.234 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.47\n",
      "2021-08-25 10:46:18.235 | INFO     | src.policies:train:109 - Episode 274\n",
      "2021-08-25 10:46:18.244 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:18.245 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 10:46:18.246 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.43\n",
      "2021-08-25 10:46:18.247 | INFO     | src.policies:train:109 - Episode 275\n",
      "2021-08-25 10:46:18.257 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:18.258 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 10:46:18.259 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.4\n",
      "2021-08-25 10:46:18.260 | INFO     | src.policies:train:109 - Episode 276\n",
      "2021-08-25 10:46:18.272 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:18.273 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 10:46:18.273 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.17\n",
      "2021-08-25 10:46:18.274 | INFO     | src.policies:train:109 - Episode 277\n",
      "2021-08-25 10:46:18.281 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:18.282 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:18.283 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.07\n",
      "2021-08-25 10:46:18.284 | INFO     | src.policies:train:109 - Episode 278\n",
      "2021-08-25 10:46:18.296 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:18.297 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 10:46:18.298 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.13\n",
      "2021-08-25 10:46:18.299 | INFO     | src.policies:train:109 - Episode 279\n",
      "2021-08-25 10:46:18.308 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:18.309 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 10:46:18.310 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.2\n",
      "2021-08-25 10:46:18.311 | INFO     | src.policies:train:109 - Episode 280\n",
      "2021-08-25 10:46:18.319 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:18.320 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 10:46:18.321 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.2\n",
      "2021-08-25 10:46:18.322 | INFO     | src.policies:train:109 - Episode 281\n",
      "2021-08-25 10:46:18.340 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:18.341 | INFO     | src.policies:train:121 - Mean episode return: 56.0\n",
      "2021-08-25 10:46:18.342 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.58\n",
      "2021-08-25 10:46:18.343 | WARNING  | src.policies:train:131 - The actual batch size is 245, instead of 200\n",
      "2021-08-25 10:46:18.349 | INFO     | src.policies:train:157 - Total loss: 219.20494079589844\n",
      "2021-08-25 10:46:18.350 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:18.353 | INFO     | src.policies:train:103 - Epoch 31 / 800\n",
      "2021-08-25 10:46:18.354 | INFO     | src.policies:train:109 - Episode 282\n",
      "2021-08-25 10:46:18.379 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:18.380 | INFO     | src.policies:train:121 - Mean episode return: 79.0\n",
      "2021-08-25 10:46:18.381 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.21\n",
      "2021-08-25 10:46:18.382 | INFO     | src.policies:train:109 - Episode 283\n",
      "2021-08-25 10:46:18.394 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:18.395 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 10:46:18.395 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.02\n",
      "2021-08-25 10:46:18.396 | INFO     | src.policies:train:109 - Episode 284\n",
      "2021-08-25 10:46:18.410 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:18.411 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 10:46:18.412 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.2\n",
      "2021-08-25 10:46:18.413 | INFO     | src.policies:train:109 - Episode 285\n",
      "2021-08-25 10:46:18.423 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:18.424 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:18.425 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.11\n",
      "2021-08-25 10:46:18.426 | INFO     | src.policies:train:109 - Episode 286\n",
      "2021-08-25 10:46:18.441 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:18.442 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 10:46:18.443 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.18\n",
      "2021-08-25 10:46:18.444 | WARNING  | src.policies:train:131 - The actual batch size is 202, instead of 200\n",
      "2021-08-25 10:46:18.451 | INFO     | src.policies:train:157 - Total loss: 466.3680419921875\n",
      "2021-08-25 10:46:18.451 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:18.455 | INFO     | src.policies:train:103 - Epoch 32 / 800\n",
      "2021-08-25 10:46:18.456 | INFO     | src.policies:train:109 - Episode 287\n",
      "2021-08-25 10:46:18.464 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:18.465 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 10:46:18.466 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.15\n",
      "2021-08-25 10:46:18.467 | INFO     | src.policies:train:109 - Episode 288\n",
      "2021-08-25 10:46:18.480 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:18.481 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 10:46:18.481 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.29\n",
      "2021-08-25 10:46:18.482 | INFO     | src.policies:train:109 - Episode 289\n",
      "2021-08-25 10:46:18.491 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:18.493 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:18.493 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.16\n",
      "2021-08-25 10:46:18.494 | INFO     | src.policies:train:109 - Episode 290\n",
      "2021-08-25 10:46:18.514 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:18.515 | INFO     | src.policies:train:121 - Mean episode return: 51.0\n",
      "2021-08-25 10:46:18.516 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.49\n",
      "2021-08-25 10:46:18.517 | INFO     | src.policies:train:109 - Episode 291\n",
      "2021-08-25 10:46:18.524 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:18.525 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:18.526 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.5\n",
      "2021-08-25 10:46:18.527 | INFO     | src.policies:train:109 - Episode 292\n",
      "2021-08-25 10:46:18.534 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:18.535 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:18.536 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.26\n",
      "2021-08-25 10:46:18.536 | INFO     | src.policies:train:109 - Episode 293\n",
      "2021-08-25 10:46:18.543 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:18.543 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:18.544 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.28\n",
      "2021-08-25 10:46:18.545 | INFO     | src.policies:train:109 - Episode 294\n",
      "2021-08-25 10:46:18.556 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:18.557 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 10:46:18.558 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.36\n",
      "2021-08-25 10:46:18.559 | INFO     | src.policies:train:109 - Episode 295\n",
      "2021-08-25 10:46:18.568 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:18.569 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 10:46:18.570 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.2\n",
      "2021-08-25 10:46:18.571 | WARNING  | src.policies:train:131 - The actual batch size is 202, instead of 200\n",
      "2021-08-25 10:46:18.577 | INFO     | src.policies:train:157 - Total loss: 200.3050079345703\n",
      "2021-08-25 10:46:18.578 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:18.581 | INFO     | src.policies:train:103 - Epoch 33 / 800\n",
      "2021-08-25 10:46:18.582 | INFO     | src.policies:train:109 - Episode 296\n",
      "2021-08-25 10:46:18.598 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:18.599 | INFO     | src.policies:train:121 - Mean episode return: 44.0\n",
      "2021-08-25 10:46:18.599 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.25\n",
      "2021-08-25 10:46:18.600 | INFO     | src.policies:train:109 - Episode 297\n",
      "2021-08-25 10:46:18.613 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:18.615 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 10:46:18.616 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.2\n",
      "2021-08-25 10:46:18.617 | INFO     | src.policies:train:109 - Episode 298\n",
      "2021-08-25 10:46:18.626 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:18.628 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 10:46:18.629 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.21\n",
      "2021-08-25 10:46:18.630 | INFO     | src.policies:train:109 - Episode 299\n",
      "2021-08-25 10:46:18.650 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:18.652 | INFO     | src.policies:train:121 - Mean episode return: 55.0\n",
      "2021-08-25 10:46:18.652 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.64\n",
      "2021-08-25 10:46:18.653 | INFO     | src.policies:train:109 - Episode 300\n",
      "2021-08-25 10:46:18.671 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:18.672 | INFO     | src.policies:train:121 - Mean episode return: 41.0\n",
      "2021-08-25 10:46:18.672 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.73\n",
      "2021-08-25 10:46:18.673 | INFO     | src.policies:train:109 - Episode 301\n",
      "2021-08-25 10:46:18.694 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:18.695 | INFO     | src.policies:train:121 - Mean episode return: 54.0\n",
      "2021-08-25 10:46:18.696 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.11\n",
      "2021-08-25 10:46:18.697 | WARNING  | src.policies:train:131 - The actual batch size is 238, instead of 200\n",
      "2021-08-25 10:46:18.703 | INFO     | src.policies:train:157 - Total loss: 386.4969787597656\n",
      "2021-08-25 10:46:18.704 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:18.707 | INFO     | src.policies:train:103 - Epoch 34 / 800\n",
      "2021-08-25 10:46:18.708 | INFO     | src.policies:train:109 - Episode 302\n",
      "2021-08-25 10:46:18.718 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:18.719 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 10:46:18.720 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.21\n",
      "2021-08-25 10:46:18.721 | INFO     | src.policies:train:109 - Episode 303\n",
      "2021-08-25 10:46:18.730 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:18.731 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:18.732 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.22\n",
      "2021-08-25 10:46:18.733 | INFO     | src.policies:train:109 - Episode 304\n",
      "2021-08-25 10:46:18.746 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:18.747 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 10:46:18.747 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.41\n",
      "2021-08-25 10:46:18.748 | INFO     | src.policies:train:109 - Episode 305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:18.755 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:18.756 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:18.757 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.27\n",
      "2021-08-25 10:46:18.758 | INFO     | src.policies:train:109 - Episode 306\n",
      "2021-08-25 10:46:18.769 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:18.771 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 10:46:18.771 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.3\n",
      "2021-08-25 10:46:18.773 | INFO     | src.policies:train:109 - Episode 307\n",
      "2021-08-25 10:46:18.780 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:18.781 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 10:46:18.782 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.08\n",
      "2021-08-25 10:46:18.783 | INFO     | src.policies:train:109 - Episode 308\n",
      "2021-08-25 10:46:18.790 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:18.791 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 10:46:18.791 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.04\n",
      "2021-08-25 10:46:18.792 | INFO     | src.policies:train:109 - Episode 309\n",
      "2021-08-25 10:46:18.800 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:18.801 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:18.802 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.04\n",
      "2021-08-25 10:46:18.803 | INFO     | src.policies:train:109 - Episode 310\n",
      "2021-08-25 10:46:18.825 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:18.826 | INFO     | src.policies:train:121 - Mean episode return: 61.0\n",
      "2021-08-25 10:46:18.827 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.52\n",
      "2021-08-25 10:46:18.828 | WARNING  | src.policies:train:131 - The actual batch size is 215, instead of 200\n",
      "2021-08-25 10:46:18.834 | INFO     | src.policies:train:157 - Total loss: 269.3795166015625\n",
      "2021-08-25 10:46:18.835 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:18.838 | INFO     | src.policies:train:103 - Epoch 35 / 800\n",
      "2021-08-25 10:46:18.839 | INFO     | src.policies:train:109 - Episode 311\n",
      "2021-08-25 10:46:18.850 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:18.851 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 10:46:18.852 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.66\n",
      "2021-08-25 10:46:18.853 | INFO     | src.policies:train:109 - Episode 312\n",
      "2021-08-25 10:46:18.863 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:18.864 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 10:46:18.864 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.68\n",
      "2021-08-25 10:46:18.865 | INFO     | src.policies:train:109 - Episode 313\n",
      "2021-08-25 10:46:18.875 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:18.876 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:18.877 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.74\n",
      "2021-08-25 10:46:18.878 | INFO     | src.policies:train:109 - Episode 314\n",
      "2021-08-25 10:46:18.893 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:18.894 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 10:46:18.895 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.95\n",
      "2021-08-25 10:46:18.896 | INFO     | src.policies:train:109 - Episode 315\n",
      "2021-08-25 10:46:18.912 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:18.913 | INFO     | src.policies:train:121 - Mean episode return: 45.0\n",
      "2021-08-25 10:46:18.914 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.06\n",
      "2021-08-25 10:46:18.915 | INFO     | src.policies:train:109 - Episode 316\n",
      "2021-08-25 10:46:18.938 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:18.939 | INFO     | src.policies:train:121 - Mean episode return: 66.0\n",
      "2021-08-25 10:46:18.939 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.53\n",
      "2021-08-25 10:46:18.940 | WARNING  | src.policies:train:131 - The actual batch size is 224, instead of 200\n",
      "2021-08-25 10:46:18.946 | INFO     | src.policies:train:157 - Total loss: 380.66937255859375\n",
      "2021-08-25 10:46:18.947 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:18.950 | INFO     | src.policies:train:103 - Epoch 36 / 800\n",
      "2021-08-25 10:46:18.951 | INFO     | src.policies:train:109 - Episode 317\n",
      "2021-08-25 10:46:18.956 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:18.956 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 10:46:18.957 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.52\n",
      "2021-08-25 10:46:18.958 | INFO     | src.policies:train:109 - Episode 318\n",
      "2021-08-25 10:46:18.967 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:18.969 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 10:46:18.970 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.55\n",
      "2021-08-25 10:46:18.970 | INFO     | src.policies:train:109 - Episode 319\n",
      "2021-08-25 10:46:18.979 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:18.980 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:18.981 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.6\n",
      "2021-08-25 10:46:18.982 | INFO     | src.policies:train:109 - Episode 320\n",
      "2021-08-25 10:46:18.995 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:18.996 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 10:46:18.997 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.7\n",
      "2021-08-25 10:46:18.997 | INFO     | src.policies:train:109 - Episode 321\n",
      "2021-08-25 10:46:19.007 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.008 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:19.009 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.59\n",
      "2021-08-25 10:46:19.010 | INFO     | src.policies:train:109 - Episode 322\n",
      "2021-08-25 10:46:19.017 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.018 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:19.019 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.45\n",
      "2021-08-25 10:46:19.020 | INFO     | src.policies:train:109 - Episode 323\n",
      "2021-08-25 10:46:19.028 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.029 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:19.030 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.43\n",
      "2021-08-25 10:46:19.031 | INFO     | src.policies:train:109 - Episode 324\n",
      "2021-08-25 10:46:19.044 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.045 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 10:46:19.046 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.57\n",
      "2021-08-25 10:46:19.047 | INFO     | src.policies:train:109 - Episode 325\n",
      "2021-08-25 10:46:19.061 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.062 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:19.063 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.66\n",
      "2021-08-25 10:46:19.063 | INFO     | src.policies:train:109 - Episode 326\n",
      "2021-08-25 10:46:19.073 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.074 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 10:46:19.075 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.58\n",
      "2021-08-25 10:46:19.076 | INFO     | src.policies:train:109 - Episode 327\n",
      "2021-08-25 10:46:19.084 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.085 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:19.085 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.56\n",
      "2021-08-25 10:46:19.086 | WARNING  | src.policies:train:131 - The actual batch size is 209, instead of 200\n",
      "2021-08-25 10:46:19.094 | INFO     | src.policies:train:157 - Total loss: 123.33795928955078\n",
      "2021-08-25 10:46:19.095 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:19.098 | INFO     | src.policies:train:103 - Epoch 37 / 800\n",
      "2021-08-25 10:46:19.099 | INFO     | src.policies:train:109 - Episode 328\n",
      "2021-08-25 10:46:19.108 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.109 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 10:46:19.109 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.56\n",
      "2021-08-25 10:46:19.110 | INFO     | src.policies:train:109 - Episode 329\n",
      "2021-08-25 10:46:19.121 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.122 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 10:46:19.123 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.56\n",
      "2021-08-25 10:46:19.124 | INFO     | src.policies:train:109 - Episode 330\n",
      "2021-08-25 10:46:19.132 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.133 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:19.134 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.55\n",
      "2021-08-25 10:46:19.135 | INFO     | src.policies:train:109 - Episode 331\n",
      "2021-08-25 10:46:19.147 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.148 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 10:46:19.149 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.61\n",
      "2021-08-25 10:46:19.150 | INFO     | src.policies:train:109 - Episode 332\n",
      "2021-08-25 10:46:19.155 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.156 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 10:46:19.157 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.04\n",
      "2021-08-25 10:46:19.158 | INFO     | src.policies:train:109 - Episode 333\n",
      "2021-08-25 10:46:19.167 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.168 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 10:46:19.169 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.04\n",
      "2021-08-25 10:46:19.170 | INFO     | src.policies:train:109 - Episode 334\n",
      "2021-08-25 10:46:19.184 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.185 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 10:46:19.186 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.18\n",
      "2021-08-25 10:46:19.186 | INFO     | src.policies:train:109 - Episode 335\n",
      "2021-08-25 10:46:19.222 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.223 | INFO     | src.policies:train:121 - Mean episode return: 110.0\n",
      "2021-08-25 10:46:19.224 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.96\n",
      "2021-08-25 10:46:19.225 | WARNING  | src.policies:train:131 - The actual batch size is 266, instead of 200\n",
      "2021-08-25 10:46:19.230 | INFO     | src.policies:train:157 - Total loss: 546.7362670898438\n",
      "2021-08-25 10:46:19.231 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:19.234 | INFO     | src.policies:train:103 - Epoch 38 / 800\n",
      "2021-08-25 10:46:19.234 | INFO     | src.policies:train:109 - Episode 336\n",
      "2021-08-25 10:46:19.242 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.243 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 10:46:19.244 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.89\n",
      "2021-08-25 10:46:19.245 | INFO     | src.policies:train:109 - Episode 337\n",
      "2021-08-25 10:46:19.259 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.260 | INFO     | src.policies:train:121 - Mean episode return: 41.0\n",
      "2021-08-25 10:46:19.261 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.99\n",
      "2021-08-25 10:46:19.262 | INFO     | src.policies:train:109 - Episode 338\n",
      "2021-08-25 10:46:19.271 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.272 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 10:46:19.273 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.01\n",
      "2021-08-25 10:46:19.274 | INFO     | src.policies:train:109 - Episode 339\n",
      "2021-08-25 10:46:19.298 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.299 | INFO     | src.policies:train:121 - Mean episode return: 75.0\n",
      "2021-08-25 10:46:19.300 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.63\n",
      "2021-08-25 10:46:19.300 | INFO     | src.policies:train:109 - Episode 340\n",
      "2021-08-25 10:46:19.307 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.307 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 10:46:19.308 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.63\n",
      "2021-08-25 10:46:19.309 | INFO     | src.policies:train:109 - Episode 341\n",
      "2021-08-25 10:46:19.317 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.317 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:19.318 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.63\n",
      "2021-08-25 10:46:19.319 | INFO     | src.policies:train:109 - Episode 342\n",
      "2021-08-25 10:46:19.330 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.331 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 10:46:19.332 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.59\n",
      "2021-08-25 10:46:19.333 | WARNING  | src.policies:train:131 - The actual batch size is 218, instead of 200\n",
      "2021-08-25 10:46:19.338 | INFO     | src.policies:train:157 - Total loss: 383.4916076660156\n",
      "2021-08-25 10:46:19.338 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:19.341 | INFO     | src.policies:train:103 - Epoch 39 / 800\n",
      "2021-08-25 10:46:19.341 | INFO     | src.policies:train:109 - Episode 343\n",
      "2021-08-25 10:46:19.349 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.350 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:19.350 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.49\n",
      "2021-08-25 10:46:19.351 | INFO     | src.policies:train:109 - Episode 344\n",
      "2021-08-25 10:46:19.362 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.363 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 10:46:19.364 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.65\n",
      "2021-08-25 10:46:19.364 | INFO     | src.policies:train:109 - Episode 345\n",
      "2021-08-25 10:46:19.388 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:19.389 | INFO     | src.policies:train:121 - Mean episode return: 71.0\n",
      "2021-08-25 10:46:19.390 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.04\n",
      "2021-08-25 10:46:19.391 | INFO     | src.policies:train:109 - Episode 346\n",
      "2021-08-25 10:46:19.400 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.401 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 10:46:19.401 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.15\n",
      "2021-08-25 10:46:19.402 | INFO     | src.policies:train:109 - Episode 347\n",
      "2021-08-25 10:46:19.408 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.409 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:19.410 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.02\n",
      "2021-08-25 10:46:19.411 | INFO     | src.policies:train:109 - Episode 348\n",
      "2021-08-25 10:46:19.420 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.421 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 10:46:19.422 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.81\n",
      "2021-08-25 10:46:19.423 | INFO     | src.policies:train:109 - Episode 349\n",
      "2021-08-25 10:46:19.432 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.433 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:19.434 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.82\n",
      "2021-08-25 10:46:19.434 | INFO     | src.policies:train:109 - Episode 350\n",
      "2021-08-25 10:46:19.442 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.443 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:19.444 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.86\n",
      "2021-08-25 10:46:19.445 | WARNING  | src.policies:train:131 - The actual batch size is 214, instead of 200\n",
      "2021-08-25 10:46:19.451 | INFO     | src.policies:train:157 - Total loss: 315.5530090332031\n",
      "2021-08-25 10:46:19.452 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:19.454 | INFO     | src.policies:train:103 - Epoch 40 / 800\n",
      "2021-08-25 10:46:19.455 | INFO     | src.policies:train:109 - Episode 351\n",
      "2021-08-25 10:46:19.463 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.464 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:19.464 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.85\n",
      "2021-08-25 10:46:19.465 | INFO     | src.policies:train:109 - Episode 352\n",
      "2021-08-25 10:46:19.472 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.473 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:19.474 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.83\n",
      "2021-08-25 10:46:19.475 | INFO     | src.policies:train:109 - Episode 353\n",
      "2021-08-25 10:46:19.495 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.496 | INFO     | src.policies:train:121 - Mean episode return: 64.0\n",
      "2021-08-25 10:46:19.497 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.31\n",
      "2021-08-25 10:46:19.498 | INFO     | src.policies:train:109 - Episode 354\n",
      "2021-08-25 10:46:19.517 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.518 | INFO     | src.policies:train:121 - Mean episode return: 56.0\n",
      "2021-08-25 10:46:19.519 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.73\n",
      "2021-08-25 10:46:19.519 | INFO     | src.policies:train:109 - Episode 355\n",
      "2021-08-25 10:46:19.531 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.533 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 10:46:19.534 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.89\n",
      "2021-08-25 10:46:19.534 | INFO     | src.policies:train:109 - Episode 356\n",
      "2021-08-25 10:46:19.540 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.541 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 10:46:19.542 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.51\n",
      "2021-08-25 10:46:19.543 | INFO     | src.policies:train:109 - Episode 357\n",
      "2021-08-25 10:46:19.553 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.554 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 10:46:19.555 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.62\n",
      "2021-08-25 10:46:19.556 | WARNING  | src.policies:train:131 - The actual batch size is 217, instead of 200\n",
      "2021-08-25 10:46:19.561 | INFO     | src.policies:train:157 - Total loss: 374.6017150878906\n",
      "2021-08-25 10:46:19.561 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:19.564 | INFO     | src.policies:train:103 - Epoch 41 / 800\n",
      "2021-08-25 10:46:19.565 | INFO     | src.policies:train:109 - Episode 358\n",
      "2021-08-25 10:46:19.576 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.577 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 10:46:19.577 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.77\n",
      "2021-08-25 10:46:19.578 | INFO     | src.policies:train:109 - Episode 359\n",
      "2021-08-25 10:46:19.585 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.586 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:19.587 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.68\n",
      "2021-08-25 10:46:19.588 | INFO     | src.policies:train:109 - Episode 360\n",
      "2021-08-25 10:46:19.594 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.595 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:19.596 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.35\n",
      "2021-08-25 10:46:19.597 | INFO     | src.policies:train:109 - Episode 361\n",
      "2021-08-25 10:46:19.606 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.607 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 10:46:19.607 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.15\n",
      "2021-08-25 10:46:19.608 | INFO     | src.policies:train:109 - Episode 362\n",
      "2021-08-25 10:46:19.616 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.617 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:19.618 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.96\n",
      "2021-08-25 10:46:19.618 | INFO     | src.policies:train:109 - Episode 363\n",
      "2021-08-25 10:46:19.634 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.635 | INFO     | src.policies:train:121 - Mean episode return: 42.0\n",
      "2021-08-25 10:46:19.636 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.93\n",
      "2021-08-25 10:46:19.636 | INFO     | src.policies:train:109 - Episode 364\n",
      "2021-08-25 10:46:19.643 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.644 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:19.645 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.86\n",
      "2021-08-25 10:46:19.646 | INFO     | src.policies:train:109 - Episode 365\n",
      "2021-08-25 10:46:19.653 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.654 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:19.654 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:19.655 | INFO     | src.policies:train:109 - Episode 366\n",
      "2021-08-25 10:46:19.666 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.667 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 10:46:19.667 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.91\n",
      "2021-08-25 10:46:19.668 | INFO     | src.policies:train:109 - Episode 367\n",
      "2021-08-25 10:46:19.679 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.680 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 10:46:19.681 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.89\n",
      "2021-08-25 10:46:19.682 | WARNING  | src.policies:train:131 - The actual batch size is 217, instead of 200\n",
      "2021-08-25 10:46:19.688 | INFO     | src.policies:train:157 - Total loss: 165.20335388183594\n",
      "2021-08-25 10:46:19.689 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:19.691 | INFO     | src.policies:train:103 - Epoch 42 / 800\n",
      "2021-08-25 10:46:19.692 | INFO     | src.policies:train:109 - Episode 368\n",
      "2021-08-25 10:46:19.698 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.699 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:19.700 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.9\n",
      "2021-08-25 10:46:19.701 | INFO     | src.policies:train:109 - Episode 369\n",
      "2021-08-25 10:46:19.710 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.711 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 10:46:19.712 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.62\n",
      "2021-08-25 10:46:19.712 | INFO     | src.policies:train:109 - Episode 370\n",
      "2021-08-25 10:46:19.725 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.726 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 10:46:19.726 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.76\n",
      "2021-08-25 10:46:19.727 | INFO     | src.policies:train:109 - Episode 371\n",
      "2021-08-25 10:46:19.738 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.739 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 10:46:19.740 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.65\n",
      "2021-08-25 10:46:19.741 | INFO     | src.policies:train:109 - Episode 372\n",
      "2021-08-25 10:46:19.756 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.757 | INFO     | src.policies:train:121 - Mean episode return: 42.0\n",
      "2021-08-25 10:46:19.758 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.94\n",
      "2021-08-25 10:46:19.759 | INFO     | src.policies:train:109 - Episode 373\n",
      "2021-08-25 10:46:19.777 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.778 | INFO     | src.policies:train:121 - Mean episode return: 53.0\n",
      "2021-08-25 10:46:19.779 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.23\n",
      "2021-08-25 10:46:19.780 | INFO     | src.policies:train:109 - Episode 374\n",
      "2021-08-25 10:46:19.791 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.792 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 10:46:19.792 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.25\n",
      "2021-08-25 10:46:19.793 | WARNING  | src.policies:train:131 - The actual batch size is 215, instead of 200\n",
      "2021-08-25 10:46:19.798 | INFO     | src.policies:train:157 - Total loss: 274.4790344238281\n",
      "2021-08-25 10:46:19.799 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:19.801 | INFO     | src.policies:train:103 - Epoch 43 / 800\n",
      "2021-08-25 10:46:19.802 | INFO     | src.policies:train:109 - Episode 375\n",
      "2021-08-25 10:46:19.808 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.809 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:19.810 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.17\n",
      "2021-08-25 10:46:19.811 | INFO     | src.policies:train:109 - Episode 376\n",
      "2021-08-25 10:46:19.816 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.817 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 10:46:19.818 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.01\n",
      "2021-08-25 10:46:19.819 | INFO     | src.policies:train:109 - Episode 377\n",
      "2021-08-25 10:46:19.829 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.830 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 10:46:19.831 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.13\n",
      "2021-08-25 10:46:19.832 | INFO     | src.policies:train:109 - Episode 378\n",
      "2021-08-25 10:46:19.840 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.841 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 10:46:19.842 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.01\n",
      "2021-08-25 10:46:19.842 | INFO     | src.policies:train:109 - Episode 379\n",
      "2021-08-25 10:46:19.852 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.853 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 10:46:19.854 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.05\n",
      "2021-08-25 10:46:19.855 | INFO     | src.policies:train:109 - Episode 380\n",
      "2021-08-25 10:46:19.862 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.863 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:19.864 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.99\n",
      "2021-08-25 10:46:19.865 | INFO     | src.policies:train:109 - Episode 381\n",
      "2021-08-25 10:46:19.877 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.878 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 10:46:19.879 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.76\n",
      "2021-08-25 10:46:19.879 | INFO     | src.policies:train:109 - Episode 382\n",
      "2021-08-25 10:46:19.889 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.890 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 10:46:19.891 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.18\n",
      "2021-08-25 10:46:19.892 | INFO     | src.policies:train:109 - Episode 383\n",
      "2021-08-25 10:46:19.903 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.904 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 10:46:19.905 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.19\n",
      "2021-08-25 10:46:19.906 | INFO     | src.policies:train:109 - Episode 384\n",
      "2021-08-25 10:46:19.917 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.918 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 10:46:19.918 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.06\n",
      "2021-08-25 10:46:19.919 | WARNING  | src.policies:train:131 - The actual batch size is 212, instead of 200\n",
      "2021-08-25 10:46:19.925 | INFO     | src.policies:train:157 - Total loss: 134.19271850585938\n",
      "2021-08-25 10:46:19.926 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:19.928 | INFO     | src.policies:train:103 - Epoch 44 / 800\n",
      "2021-08-25 10:46:19.929 | INFO     | src.policies:train:109 - Episode 385\n",
      "2021-08-25 10:46:19.936 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.937 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:19.938 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.04\n",
      "2021-08-25 10:46:19.938 | INFO     | src.policies:train:109 - Episode 386\n",
      "2021-08-25 10:46:19.945 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.946 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:19.947 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.76\n",
      "2021-08-25 10:46:19.948 | INFO     | src.policies:train:109 - Episode 387\n",
      "2021-08-25 10:46:19.956 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.957 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:19.957 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.71\n",
      "2021-08-25 10:46:19.958 | INFO     | src.policies:train:109 - Episode 388\n",
      "2021-08-25 10:46:19.971 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.972 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 10:46:19.973 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.8\n",
      "2021-08-25 10:46:19.974 | INFO     | src.policies:train:109 - Episode 389\n",
      "2021-08-25 10:46:19.984 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.985 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 10:46:19.986 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.88\n",
      "2021-08-25 10:46:19.987 | INFO     | src.policies:train:109 - Episode 390\n",
      "2021-08-25 10:46:19.996 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:19.997 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 10:46:19.998 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.58\n",
      "2021-08-25 10:46:19.999 | INFO     | src.policies:train:109 - Episode 391\n",
      "2021-08-25 10:46:20.007 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:20.009 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 10:46:20.009 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.65\n",
      "2021-08-25 10:46:20.010 | INFO     | src.policies:train:109 - Episode 392\n",
      "2021-08-25 10:46:20.022 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:20.023 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 10:46:20.024 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.82\n",
      "2021-08-25 10:46:20.025 | INFO     | src.policies:train:109 - Episode 393\n",
      "2021-08-25 10:46:20.043 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:20.044 | INFO     | src.policies:train:121 - Mean episode return: 50.0\n",
      "2021-08-25 10:46:20.045 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.17\n",
      "2021-08-25 10:46:20.046 | WARNING  | src.policies:train:131 - The actual batch size is 228, instead of 200\n",
      "2021-08-25 10:46:20.052 | INFO     | src.policies:train:157 - Total loss: 217.2826690673828\n",
      "2021-08-25 10:46:20.052 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:20.055 | INFO     | src.policies:train:103 - Epoch 45 / 800\n",
      "2021-08-25 10:46:20.056 | INFO     | src.policies:train:109 - Episode 394\n",
      "2021-08-25 10:46:20.061 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:20.062 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:20.063 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.02\n",
      "2021-08-25 10:46:20.064 | INFO     | src.policies:train:109 - Episode 395\n",
      "2021-08-25 10:46:20.075 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:20.076 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 10:46:20.077 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.14\n",
      "2021-08-25 10:46:20.078 | INFO     | src.policies:train:109 - Episode 396\n",
      "2021-08-25 10:46:20.084 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:20.085 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:20.086 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.82\n",
      "2021-08-25 10:46:20.087 | INFO     | src.policies:train:109 - Episode 397\n",
      "2021-08-25 10:46:20.095 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:20.096 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 10:46:20.097 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.72\n",
      "2021-08-25 10:46:20.098 | INFO     | src.policies:train:109 - Episode 398\n",
      "2021-08-25 10:46:20.110 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:20.111 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 10:46:20.112 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.85\n",
      "2021-08-25 10:46:20.113 | INFO     | src.policies:train:109 - Episode 399\n",
      "2021-08-25 10:46:20.122 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:20.123 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 10:46:20.124 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.51\n",
      "2021-08-25 10:46:20.125 | INFO     | src.policies:train:109 - Episode 400\n",
      "2021-08-25 10:46:20.141 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:20.142 | INFO     | src.policies:train:121 - Mean episode return: 44.0\n",
      "2021-08-25 10:46:20.143 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.54\n",
      "2021-08-25 10:46:20.144 | INFO     | src.policies:train:109 - Episode 401\n",
      "2021-08-25 10:46:20.156 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:20.157 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 10:46:20.158 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.3\n",
      "2021-08-25 10:46:20.159 | INFO     | src.policies:train:109 - Episode 402\n",
      "2021-08-25 10:46:20.178 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:20.179 | INFO     | src.policies:train:121 - Mean episode return: 54.0\n",
      "2021-08-25 10:46:20.179 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.6\n",
      "2021-08-25 10:46:20.180 | WARNING  | src.policies:train:131 - The actual batch size is 249, instead of 200\n",
      "2021-08-25 10:46:20.186 | INFO     | src.policies:train:157 - Total loss: 260.00628662109375\n",
      "2021-08-25 10:46:20.187 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:20.190 | INFO     | src.policies:train:103 - Epoch 46 / 800\n",
      "2021-08-25 10:46:20.191 | INFO     | src.policies:train:109 - Episode 403\n",
      "2021-08-25 10:46:20.196 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:20.198 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:20.198 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.56\n",
      "2021-08-25 10:46:20.199 | INFO     | src.policies:train:109 - Episode 404\n",
      "2021-08-25 10:46:20.205 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:20.206 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:20.207 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.36\n",
      "2021-08-25 10:46:20.208 | INFO     | src.policies:train:109 - Episode 405\n",
      "2021-08-25 10:46:20.216 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:20.217 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:20.218 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.43\n",
      "2021-08-25 10:46:20.219 | INFO     | src.policies:train:109 - Episode 406\n",
      "2021-08-25 10:46:20.226 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:20.227 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:20.227 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.25\n",
      "2021-08-25 10:46:20.228 | INFO     | src.policies:train:109 - Episode 407\n",
      "2021-08-25 10:46:20.235 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:20.236 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:20.236 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.27\n",
      "2021-08-25 10:46:20.237 | INFO     | src.policies:train:109 - Episode 408\n",
      "2021-08-25 10:46:20.255 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:20.256 | INFO     | src.policies:train:121 - Mean episode return: 50.0\n",
      "2021-08-25 10:46:20.257 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.66\n",
      "2021-08-25 10:46:20.258 | INFO     | src.policies:train:109 - Episode 409\n",
      "2021-08-25 10:46:20.267 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:20.268 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 10:46:20.269 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.73\n",
      "2021-08-25 10:46:20.270 | INFO     | src.policies:train:109 - Episode 410\n",
      "2021-08-25 10:46:20.294 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:20.295 | INFO     | src.policies:train:121 - Mean episode return: 74.0\n",
      "2021-08-25 10:46:20.296 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.86\n",
      "2021-08-25 10:46:20.296 | WARNING  | src.policies:train:131 - The actual batch size is 217, instead of 200\n",
      "2021-08-25 10:46:20.302 | INFO     | src.policies:train:157 - Total loss: 381.3619384765625\n",
      "2021-08-25 10:46:20.303 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:20.305 | INFO     | src.policies:train:103 - Epoch 47 / 800\n",
      "2021-08-25 10:46:20.306 | INFO     | src.policies:train:109 - Episode 411\n",
      "2021-08-25 10:46:20.318 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:20.319 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 10:46:20.320 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.86\n",
      "2021-08-25 10:46:20.320 | INFO     | src.policies:train:109 - Episode 412\n",
      "2021-08-25 10:46:20.334 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:20.335 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 10:46:20.336 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.98\n",
      "2021-08-25 10:46:20.337 | INFO     | src.policies:train:109 - Episode 413\n",
      "2021-08-25 10:46:20.347 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:20.348 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 10:46:20.348 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.04\n",
      "2021-08-25 10:46:20.349 | INFO     | src.policies:train:109 - Episode 414\n",
      "2021-08-25 10:46:20.361 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:20.362 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 10:46:20.362 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.92\n",
      "2021-08-25 10:46:20.363 | INFO     | src.policies:train:109 - Episode 415\n",
      "2021-08-25 10:46:20.371 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:20.372 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:20.372 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.62\n",
      "2021-08-25 10:46:20.373 | INFO     | src.policies:train:109 - Episode 416\n",
      "2021-08-25 10:46:20.383 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:20.384 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 10:46:20.385 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.2\n",
      "2021-08-25 10:46:20.386 | INFO     | src.policies:train:109 - Episode 417\n",
      "2021-08-25 10:46:20.405 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:20.406 | INFO     | src.policies:train:121 - Mean episode return: 56.0\n",
      "2021-08-25 10:46:20.407 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.65\n",
      "2021-08-25 10:46:20.408 | WARNING  | src.policies:train:131 - The actual batch size is 214, instead of 200\n",
      "2021-08-25 10:46:20.413 | INFO     | src.policies:train:157 - Total loss: 267.6886291503906\n",
      "2021-08-25 10:46:20.414 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:20.417 | INFO     | src.policies:train:103 - Epoch 48 / 800\n",
      "2021-08-25 10:46:20.418 | INFO     | src.policies:train:109 - Episode 418\n",
      "2021-08-25 10:46:20.424 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:20.425 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:20.426 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.58\n",
      "2021-08-25 10:46:20.427 | INFO     | src.policies:train:109 - Episode 419\n",
      "2021-08-25 10:46:20.437 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:20.438 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 10:46:20.439 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.66\n",
      "2021-08-25 10:46:20.440 | INFO     | src.policies:train:109 - Episode 420\n",
      "2021-08-25 10:46:20.451 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:20.453 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 10:46:20.453 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.64\n",
      "2021-08-25 10:46:20.454 | INFO     | src.policies:train:109 - Episode 421\n",
      "2021-08-25 10:46:20.463 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:20.464 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 10:46:20.465 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.72\n",
      "2021-08-25 10:46:20.466 | INFO     | src.policies:train:109 - Episode 422\n",
      "2021-08-25 10:46:20.475 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:20.476 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:20.476 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.78\n",
      "2021-08-25 10:46:20.477 | INFO     | src.policies:train:109 - Episode 423\n",
      "2021-08-25 10:46:20.487 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:20.488 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 10:46:20.488 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.88\n",
      "2021-08-25 10:46:20.489 | INFO     | src.policies:train:109 - Episode 424\n",
      "2021-08-25 10:46:20.499 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:20.500 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 10:46:20.500 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.8\n",
      "2021-08-25 10:46:20.501 | INFO     | src.policies:train:109 - Episode 425\n",
      "2021-08-25 10:46:20.508 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:20.510 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:20.510 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.64\n",
      "2021-08-25 10:46:20.511 | INFO     | src.policies:train:109 - Episode 426\n",
      "2021-08-25 10:46:20.521 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:20.522 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 10:46:20.523 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:20.524 | INFO     | src.policies:train:109 - Episode 427\n",
      "2021-08-25 10:46:20.536 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:20.537 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 10:46:20.537 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.88\n",
      "2021-08-25 10:46:20.538 | WARNING  | src.policies:train:131 - The actual batch size is 221, instead of 200\n",
      "2021-08-25 10:46:20.544 | INFO     | src.policies:train:157 - Total loss: 129.65711975097656\n",
      "2021-08-25 10:46:20.544 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:20.547 | INFO     | src.policies:train:103 - Epoch 49 / 800\n",
      "2021-08-25 10:46:20.548 | INFO     | src.policies:train:109 - Episode 428\n",
      "2021-08-25 10:46:20.565 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:20.566 | INFO     | src.policies:train:121 - Mean episode return: 51.0\n",
      "2021-08-25 10:46:20.567 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.18\n",
      "2021-08-25 10:46:20.568 | INFO     | src.policies:train:109 - Episode 429\n",
      "2021-08-25 10:46:20.576 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:20.577 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:20.578 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.12\n",
      "2021-08-25 10:46:20.578 | INFO     | src.policies:train:109 - Episode 430\n",
      "2021-08-25 10:46:20.587 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:20.588 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 10:46:20.589 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.18\n",
      "2021-08-25 10:46:20.590 | INFO     | src.policies:train:109 - Episode 431\n",
      "2021-08-25 10:46:20.602 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:20.603 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 10:46:20.604 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.22\n",
      "2021-08-25 10:46:20.605 | INFO     | src.policies:train:109 - Episode 432\n",
      "2021-08-25 10:46:20.615 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:20.616 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 10:46:20.616 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.33\n",
      "2021-08-25 10:46:20.617 | INFO     | src.policies:train:109 - Episode 433\n",
      "2021-08-25 10:46:20.625 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:20.627 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 10:46:20.627 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.27\n",
      "2021-08-25 10:46:20.628 | INFO     | src.policies:train:109 - Episode 434\n",
      "2021-08-25 10:46:20.636 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:20.637 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:20.637 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.1\n",
      "2021-08-25 10:46:20.638 | INFO     | src.policies:train:109 - Episode 435\n",
      "2021-08-25 10:46:20.648 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:20.649 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 10:46:20.650 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.24\n",
      "2021-08-25 10:46:20.651 | WARNING  | src.policies:train:131 - The actual batch size is 202, instead of 200\n",
      "2021-08-25 10:46:20.656 | INFO     | src.policies:train:157 - Total loss: 210.42666625976562\n",
      "2021-08-25 10:46:20.656 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:20.659 | INFO     | src.policies:train:103 - Epoch 50 / 800\n",
      "2021-08-25 10:46:20.660 | INFO     | src.policies:train:109 - Episode 436\n",
      "2021-08-25 10:46:20.668 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:20.670 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 10:46:20.670 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.26\n",
      "2021-08-25 10:46:20.671 | INFO     | src.policies:train:109 - Episode 437\n",
      "2021-08-25 10:46:20.685 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:20.686 | INFO     | src.policies:train:121 - Mean episode return: 38.0\n",
      "2021-08-25 10:46:20.687 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.23\n",
      "2021-08-25 10:46:20.688 | INFO     | src.policies:train:109 - Episode 438\n",
      "2021-08-25 10:46:20.698 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:20.699 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 10:46:20.700 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.25\n",
      "2021-08-25 10:46:20.700 | INFO     | src.policies:train:109 - Episode 439\n",
      "2021-08-25 10:46:20.709 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:20.710 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:20.710 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.66\n",
      "2021-08-25 10:46:20.711 | INFO     | src.policies:train:109 - Episode 440\n",
      "2021-08-25 10:46:20.730 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:20.731 | INFO     | src.policies:train:121 - Mean episode return: 57.0\n",
      "2021-08-25 10:46:20.732 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.12\n",
      "2021-08-25 10:46:20.733 | INFO     | src.policies:train:109 - Episode 441\n",
      "2021-08-25 10:46:20.741 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:20.742 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:20.743 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.12\n",
      "2021-08-25 10:46:20.743 | INFO     | src.policies:train:109 - Episode 442\n",
      "2021-08-25 10:46:20.752 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:20.753 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:20.754 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.0\n",
      "2021-08-25 10:46:20.755 | INFO     | src.policies:train:109 - Episode 443\n",
      "2021-08-25 10:46:20.760 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:20.761 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:20.762 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.94\n",
      "2021-08-25 10:46:20.763 | WARNING  | src.policies:train:131 - The actual batch size is 206, instead of 200\n",
      "2021-08-25 10:46:20.768 | INFO     | src.policies:train:157 - Total loss: 249.61227416992188\n",
      "2021-08-25 10:46:20.769 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:20.772 | INFO     | src.policies:train:103 - Epoch 51 / 800\n",
      "2021-08-25 10:46:20.773 | INFO     | src.policies:train:109 - Episode 444\n",
      "2021-08-25 10:46:20.787 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:20.788 | INFO     | src.policies:train:121 - Mean episode return: 42.0\n",
      "2021-08-25 10:46:20.789 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.06\n",
      "2021-08-25 10:46:20.790 | INFO     | src.policies:train:109 - Episode 445\n",
      "2021-08-25 10:46:20.810 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:20.811 | INFO     | src.policies:train:121 - Mean episode return: 60.0\n",
      "2021-08-25 10:46:20.812 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.95\n",
      "2021-08-25 10:46:20.813 | INFO     | src.policies:train:109 - Episode 446\n",
      "2021-08-25 10:46:20.824 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:20.825 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:20.825 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.0\n",
      "2021-08-25 10:46:20.826 | INFO     | src.policies:train:109 - Episode 447\n",
      "2021-08-25 10:46:20.833 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:20.834 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:20.835 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.0\n",
      "2021-08-25 10:46:20.836 | INFO     | src.policies:train:109 - Episode 448\n",
      "2021-08-25 10:46:20.844 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:20.845 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:20.846 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.95\n",
      "2021-08-25 10:46:20.846 | INFO     | src.policies:train:109 - Episode 449\n",
      "2021-08-25 10:46:20.857 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:20.858 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 10:46:20.859 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.01\n",
      "2021-08-25 10:46:20.859 | INFO     | src.policies:train:109 - Episode 450\n",
      "2021-08-25 10:46:20.866 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:20.867 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:20.868 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.96\n",
      "2021-08-25 10:46:20.869 | INFO     | src.policies:train:109 - Episode 451\n",
      "2021-08-25 10:46:20.886 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:20.888 | INFO     | src.policies:train:121 - Mean episode return: 53.0\n",
      "2021-08-25 10:46:20.888 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.31\n",
      "2021-08-25 10:46:20.889 | WARNING  | src.policies:train:131 - The actual batch size is 251, instead of 200\n",
      "2021-08-25 10:46:20.894 | INFO     | src.policies:train:157 - Total loss: 334.3957214355469\n",
      "2021-08-25 10:46:20.895 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:20.897 | INFO     | src.policies:train:103 - Epoch 52 / 800\n",
      "2021-08-25 10:46:20.898 | INFO     | src.policies:train:109 - Episode 452\n",
      "2021-08-25 10:46:20.904 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:20.905 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:20.906 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.31\n",
      "2021-08-25 10:46:20.907 | INFO     | src.policies:train:109 - Episode 453\n",
      "2021-08-25 10:46:20.915 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:20.916 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 10:46:20.917 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.84\n",
      "2021-08-25 10:46:20.917 | INFO     | src.policies:train:109 - Episode 454\n",
      "2021-08-25 10:46:20.930 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:20.931 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 10:46:20.932 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.63\n",
      "2021-08-25 10:46:20.933 | INFO     | src.policies:train:109 - Episode 455\n",
      "2021-08-25 10:46:20.938 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:20.939 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 10:46:20.940 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.45\n",
      "2021-08-25 10:46:20.941 | INFO     | src.policies:train:109 - Episode 456\n",
      "2021-08-25 10:46:20.953 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:20.954 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 10:46:20.955 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.68\n",
      "2021-08-25 10:46:20.956 | INFO     | src.policies:train:109 - Episode 457\n",
      "2021-08-25 10:46:20.975 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:20.976 | INFO     | src.policies:train:121 - Mean episode return: 57.0\n",
      "2021-08-25 10:46:20.977 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.99\n",
      "2021-08-25 10:46:20.978 | INFO     | src.policies:train:109 - Episode 458\n",
      "2021-08-25 10:46:20.989 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:20.990 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 10:46:20.991 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.95\n",
      "2021-08-25 10:46:20.991 | INFO     | src.policies:train:109 - Episode 459\n",
      "2021-08-25 10:46:20.999 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:21.000 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:21.001 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.99\n",
      "2021-08-25 10:46:21.002 | WARNING  | src.policies:train:131 - The actual batch size is 213, instead of 200\n",
      "2021-08-25 10:46:21.007 | INFO     | src.policies:train:157 - Total loss: 257.9471740722656\n",
      "2021-08-25 10:46:21.008 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:21.011 | INFO     | src.policies:train:103 - Epoch 53 / 800\n",
      "2021-08-25 10:46:21.012 | INFO     | src.policies:train:109 - Episode 460\n",
      "2021-08-25 10:46:21.021 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:21.022 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 10:46:21.023 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.12\n",
      "2021-08-25 10:46:21.024 | INFO     | src.policies:train:109 - Episode 461\n",
      "2021-08-25 10:46:21.042 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:21.043 | INFO     | src.policies:train:121 - Mean episode return: 51.0\n",
      "2021-08-25 10:46:21.044 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.43\n",
      "2021-08-25 10:46:21.044 | INFO     | src.policies:train:109 - Episode 462\n",
      "2021-08-25 10:46:21.057 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:21.058 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 10:46:21.059 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.56\n",
      "2021-08-25 10:46:21.060 | INFO     | src.policies:train:109 - Episode 463\n",
      "2021-08-25 10:46:21.086 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:21.087 | INFO     | src.policies:train:121 - Mean episode return: 77.0\n",
      "2021-08-25 10:46:21.088 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.91\n",
      "2021-08-25 10:46:21.089 | INFO     | src.policies:train:109 - Episode 464\n",
      "2021-08-25 10:46:21.101 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:21.102 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 10:46:21.103 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.04\n",
      "2021-08-25 10:46:21.103 | WARNING  | src.policies:train:131 - The actual batch size is 211, instead of 200\n",
      "2021-08-25 10:46:21.109 | INFO     | src.policies:train:157 - Total loss: 453.7941589355469\n",
      "2021-08-25 10:46:21.109 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:21.112 | INFO     | src.policies:train:103 - Epoch 54 / 800\n",
      "2021-08-25 10:46:21.113 | INFO     | src.policies:train:109 - Episode 465\n",
      "2021-08-25 10:46:21.119 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:21.120 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:21.121 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.05\n",
      "2021-08-25 10:46:21.122 | INFO     | src.policies:train:109 - Episode 466\n",
      "2021-08-25 10:46:21.127 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:21.128 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 10:46:21.129 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.89\n",
      "2021-08-25 10:46:21.130 | INFO     | src.policies:train:109 - Episode 467\n",
      "2021-08-25 10:46:21.140 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:21.142 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 10:46:21.142 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.8\n",
      "2021-08-25 10:46:21.143 | INFO     | src.policies:train:109 - Episode 468\n",
      "2021-08-25 10:46:21.151 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:21.152 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:21.153 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.8\n",
      "2021-08-25 10:46:21.154 | INFO     | src.policies:train:109 - Episode 469\n",
      "2021-08-25 10:46:21.165 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:21.166 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 10:46:21.167 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.84\n",
      "2021-08-25 10:46:21.168 | INFO     | src.policies:train:109 - Episode 470\n",
      "2021-08-25 10:46:21.181 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:21.182 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 10:46:21.182 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.81\n",
      "2021-08-25 10:46:21.183 | INFO     | src.policies:train:109 - Episode 471\n",
      "2021-08-25 10:46:21.193 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:21.194 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:21.195 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.71\n",
      "2021-08-25 10:46:21.195 | INFO     | src.policies:train:109 - Episode 472\n",
      "2021-08-25 10:46:21.204 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:21.205 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:21.206 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.48\n",
      "2021-08-25 10:46:21.207 | INFO     | src.policies:train:109 - Episode 473\n",
      "2021-08-25 10:46:21.225 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:21.226 | INFO     | src.policies:train:121 - Mean episode return: 53.0\n",
      "2021-08-25 10:46:21.227 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.48\n",
      "2021-08-25 10:46:21.228 | WARNING  | src.policies:train:131 - The actual batch size is 202, instead of 200\n",
      "2021-08-25 10:46:21.234 | INFO     | src.policies:train:157 - Total loss: 202.8717498779297\n",
      "2021-08-25 10:46:21.234 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:21.237 | INFO     | src.policies:train:103 - Epoch 55 / 800\n",
      "2021-08-25 10:46:21.238 | INFO     | src.policies:train:109 - Episode 474\n",
      "2021-08-25 10:46:21.244 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:21.245 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:21.246 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.39\n",
      "2021-08-25 10:46:21.247 | INFO     | src.policies:train:109 - Episode 475\n",
      "2021-08-25 10:46:21.254 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:21.255 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:21.255 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.39\n",
      "2021-08-25 10:46:21.256 | INFO     | src.policies:train:109 - Episode 476\n",
      "2021-08-25 10:46:21.262 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:21.263 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 10:46:21.264 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.38\n",
      "2021-08-25 10:46:21.264 | INFO     | src.policies:train:109 - Episode 477\n",
      "2021-08-25 10:46:21.271 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:21.272 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:21.273 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.25\n",
      "2021-08-25 10:46:21.273 | INFO     | src.policies:train:109 - Episode 478\n",
      "2021-08-25 10:46:21.283 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:21.284 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 10:46:21.285 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.33\n",
      "2021-08-25 10:46:21.286 | INFO     | src.policies:train:109 - Episode 479\n",
      "2021-08-25 10:46:21.303 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:21.304 | INFO     | src.policies:train:121 - Mean episode return: 42.0\n",
      "2021-08-25 10:46:21.305 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.51\n",
      "2021-08-25 10:46:21.306 | INFO     | src.policies:train:109 - Episode 480\n",
      "2021-08-25 10:46:21.314 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:21.315 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:21.316 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.54\n",
      "2021-08-25 10:46:21.317 | INFO     | src.policies:train:109 - Episode 481\n",
      "2021-08-25 10:46:21.330 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:21.331 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 10:46:21.332 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.54\n",
      "2021-08-25 10:46:21.333 | INFO     | src.policies:train:109 - Episode 482\n",
      "2021-08-25 10:46:21.340 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:21.341 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:21.342 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.51\n",
      "2021-08-25 10:46:21.343 | INFO     | src.policies:train:109 - Episode 483\n",
      "2021-08-25 10:46:21.351 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:21.352 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:21.352 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.38\n",
      "2021-08-25 10:46:21.357 | INFO     | src.policies:train:157 - Total loss: 151.23385620117188\n",
      "2021-08-25 10:46:21.358 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:21.360 | INFO     | src.policies:train:103 - Epoch 56 / 800\n",
      "2021-08-25 10:46:21.361 | INFO     | src.policies:train:109 - Episode 484\n",
      "2021-08-25 10:46:21.371 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:21.372 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 10:46:21.372 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.37\n",
      "2021-08-25 10:46:21.373 | INFO     | src.policies:train:109 - Episode 485\n",
      "2021-08-25 10:46:21.386 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:21.387 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 10:46:21.388 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.51\n",
      "2021-08-25 10:46:21.388 | INFO     | src.policies:train:109 - Episode 486\n",
      "2021-08-25 10:46:21.406 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:21.407 | INFO     | src.policies:train:121 - Mean episode return: 52.0\n",
      "2021-08-25 10:46:21.408 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.91\n",
      "2021-08-25 10:46:21.409 | INFO     | src.policies:train:109 - Episode 487\n",
      "2021-08-25 10:46:21.422 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:21.423 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 10:46:21.424 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.11\n",
      "2021-08-25 10:46:21.425 | INFO     | src.policies:train:109 - Episode 488\n",
      "2021-08-25 10:46:21.439 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:21.440 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 10:46:21.441 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.1\n",
      "2021-08-25 10:46:21.442 | INFO     | src.policies:train:109 - Episode 489\n",
      "2021-08-25 10:46:21.449 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:21.450 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:21.451 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.98\n",
      "2021-08-25 10:46:21.452 | INFO     | src.policies:train:109 - Episode 490\n",
      "2021-08-25 10:46:21.462 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:21.463 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 10:46:21.464 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.0\n",
      "2021-08-25 10:46:21.464 | WARNING  | src.policies:train:131 - The actual batch size is 212, instead of 200\n",
      "2021-08-25 10:46:21.470 | INFO     | src.policies:train:157 - Total loss: 256.6473083496094\n",
      "2021-08-25 10:46:21.470 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:21.473 | INFO     | src.policies:train:103 - Epoch 57 / 800\n",
      "2021-08-25 10:46:21.474 | INFO     | src.policies:train:109 - Episode 491\n",
      "2021-08-25 10:46:21.483 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:21.484 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 10:46:21.485 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.01\n",
      "2021-08-25 10:46:21.486 | INFO     | src.policies:train:109 - Episode 492\n",
      "2021-08-25 10:46:21.494 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:21.495 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:21.496 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.89\n",
      "2021-08-25 10:46:21.496 | INFO     | src.policies:train:109 - Episode 493\n",
      "2021-08-25 10:46:21.507 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:21.508 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 10:46:21.509 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.65\n",
      "2021-08-25 10:46:21.510 | INFO     | src.policies:train:109 - Episode 494\n",
      "2021-08-25 10:46:21.516 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:21.517 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:21.518 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.66\n",
      "2021-08-25 10:46:21.519 | INFO     | src.policies:train:109 - Episode 495\n",
      "2021-08-25 10:46:21.528 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:21.530 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 10:46:21.531 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.61\n",
      "2021-08-25 10:46:21.532 | INFO     | src.policies:train:109 - Episode 496\n",
      "2021-08-25 10:46:21.539 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:21.540 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 10:46:21.540 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.6\n",
      "2021-08-25 10:46:21.541 | INFO     | src.policies:train:109 - Episode 497\n",
      "2021-08-25 10:46:21.551 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:21.552 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 10:46:21.553 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.67\n",
      "2021-08-25 10:46:21.553 | INFO     | src.policies:train:109 - Episode 498\n",
      "2021-08-25 10:46:21.564 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:21.565 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 10:46:21.565 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.61\n",
      "2021-08-25 10:46:21.566 | INFO     | src.policies:train:109 - Episode 499\n",
      "2021-08-25 10:46:21.582 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:21.583 | INFO     | src.policies:train:121 - Mean episode return: 39.0\n",
      "2021-08-25 10:46:21.584 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.79\n",
      "2021-08-25 10:46:21.585 | WARNING  | src.policies:train:131 - The actual batch size is 202, instead of 200\n",
      "2021-08-25 10:46:21.590 | INFO     | src.policies:train:157 - Total loss: 146.47915649414062\n",
      "2021-08-25 10:46:21.591 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:21.593 | INFO     | src.policies:train:103 - Epoch 58 / 800\n",
      "2021-08-25 10:46:21.594 | INFO     | src.policies:train:109 - Episode 500\n",
      "2021-08-25 10:46:21.610 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:21.611 | INFO     | src.policies:train:121 - Mean episode return: 50.0\n",
      "2021-08-25 10:46:21.612 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.85\n",
      "2021-08-25 10:46:21.613 | INFO     | src.policies:train:109 - Episode 501\n",
      "2021-08-25 10:46:21.636 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:21.637 | INFO     | src.policies:train:121 - Mean episode return: 66.0\n",
      "2021-08-25 10:46:21.638 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.21\n",
      "2021-08-25 10:46:21.639 | INFO     | src.policies:train:109 - Episode 502\n",
      "2021-08-25 10:46:21.650 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:21.651 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 10:46:21.651 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.94\n",
      "2021-08-25 10:46:21.652 | INFO     | src.policies:train:109 - Episode 503\n",
      "2021-08-25 10:46:21.658 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:21.659 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 10:46:21.660 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.93\n",
      "2021-08-25 10:46:21.660 | INFO     | src.policies:train:109 - Episode 504\n",
      "2021-08-25 10:46:21.676 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:21.677 | INFO     | src.policies:train:121 - Mean episode return: 39.0\n",
      "2021-08-25 10:46:21.677 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.19\n",
      "2021-08-25 10:46:21.678 | INFO     | src.policies:train:109 - Episode 505\n",
      "2021-08-25 10:46:21.685 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:21.686 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:21.687 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.13\n",
      "2021-08-25 10:46:21.688 | WARNING  | src.policies:train:131 - The actual batch size is 206, instead of 200\n",
      "2021-08-25 10:46:21.693 | INFO     | src.policies:train:157 - Total loss: 386.8840637207031\n",
      "2021-08-25 10:46:21.693 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:21.696 | INFO     | src.policies:train:103 - Epoch 59 / 800\n",
      "2021-08-25 10:46:21.697 | INFO     | src.policies:train:109 - Episode 506\n",
      "2021-08-25 10:46:21.703 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:21.704 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:21.705 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.14\n",
      "2021-08-25 10:46:21.706 | INFO     | src.policies:train:109 - Episode 507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:21.721 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:21.723 | INFO     | src.policies:train:121 - Mean episode return: 44.0\n",
      "2021-08-25 10:46:21.723 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.45\n",
      "2021-08-25 10:46:21.724 | INFO     | src.policies:train:109 - Episode 508\n",
      "2021-08-25 10:46:21.736 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:21.737 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 10:46:21.738 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.24\n",
      "2021-08-25 10:46:21.739 | INFO     | src.policies:train:109 - Episode 509\n",
      "2021-08-25 10:46:21.747 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:21.748 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 10:46:21.748 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.19\n",
      "2021-08-25 10:46:21.749 | INFO     | src.policies:train:109 - Episode 510\n",
      "2021-08-25 10:46:21.756 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:21.757 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:21.758 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.59\n",
      "2021-08-25 10:46:21.758 | INFO     | src.policies:train:109 - Episode 511\n",
      "2021-08-25 10:46:21.766 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:21.767 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 10:46:21.768 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.44\n",
      "2021-08-25 10:46:21.769 | INFO     | src.policies:train:109 - Episode 512\n",
      "2021-08-25 10:46:21.783 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:21.784 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 10:46:21.784 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.49\n",
      "2021-08-25 10:46:21.785 | INFO     | src.policies:train:109 - Episode 513\n",
      "2021-08-25 10:46:21.793 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:21.794 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:21.794 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.38\n",
      "2021-08-25 10:46:21.795 | INFO     | src.policies:train:109 - Episode 514\n",
      "2021-08-25 10:46:21.802 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:21.803 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:21.804 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.23\n",
      "2021-08-25 10:46:21.804 | WARNING  | src.policies:train:131 - The actual batch size is 202, instead of 200\n",
      "2021-08-25 10:46:21.810 | INFO     | src.policies:train:157 - Total loss: 186.92361450195312\n",
      "2021-08-25 10:46:21.811 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:21.813 | INFO     | src.policies:train:103 - Epoch 60 / 800\n",
      "2021-08-25 10:46:21.815 | INFO     | src.policies:train:109 - Episode 515\n",
      "2021-08-25 10:46:21.820 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:21.821 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:21.822 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.22\n",
      "2021-08-25 10:46:21.823 | INFO     | src.policies:train:109 - Episode 516\n",
      "2021-08-25 10:46:21.837 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:21.838 | INFO     | src.policies:train:121 - Mean episode return: 38.0\n",
      "2021-08-25 10:46:21.839 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.36\n",
      "2021-08-25 10:46:21.840 | INFO     | src.policies:train:109 - Episode 517\n",
      "2021-08-25 10:46:21.850 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:21.851 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 10:46:21.852 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.02\n",
      "2021-08-25 10:46:21.853 | INFO     | src.policies:train:109 - Episode 518\n",
      "2021-08-25 10:46:21.870 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:21.871 | INFO     | src.policies:train:121 - Mean episode return: 50.0\n",
      "2021-08-25 10:46:21.872 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.36\n",
      "2021-08-25 10:46:21.873 | INFO     | src.policies:train:109 - Episode 519\n",
      "2021-08-25 10:46:21.886 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:21.887 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 10:46:21.888 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.47\n",
      "2021-08-25 10:46:21.889 | INFO     | src.policies:train:109 - Episode 520\n",
      "2021-08-25 10:46:21.902 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:21.903 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 10:46:21.904 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.51\n",
      "2021-08-25 10:46:21.905 | INFO     | src.policies:train:109 - Episode 521\n",
      "2021-08-25 10:46:21.916 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:21.917 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 10:46:21.918 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.6\n",
      "2021-08-25 10:46:21.919 | WARNING  | src.policies:train:131 - The actual batch size is 223, instead of 200\n",
      "2021-08-25 10:46:21.924 | INFO     | src.policies:train:157 - Total loss: 255.98707580566406\n",
      "2021-08-25 10:46:21.925 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:21.928 | INFO     | src.policies:train:103 - Epoch 61 / 800\n",
      "2021-08-25 10:46:21.929 | INFO     | src.policies:train:109 - Episode 522\n",
      "2021-08-25 10:46:21.940 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:21.942 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 10:46:21.942 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.73\n",
      "2021-08-25 10:46:21.943 | INFO     | src.policies:train:109 - Episode 523\n",
      "2021-08-25 10:46:21.950 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:21.951 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:21.952 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.64\n",
      "2021-08-25 10:46:21.953 | INFO     | src.policies:train:109 - Episode 524\n",
      "2021-08-25 10:46:21.966 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:21.968 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 10:46:21.968 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.8\n",
      "2021-08-25 10:46:21.969 | INFO     | src.policies:train:109 - Episode 525\n",
      "2021-08-25 10:46:21.975 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:21.976 | INFO     | src.policies:train:121 - Mean episode return: 9.0\n",
      "2021-08-25 10:46:21.977 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.75\n",
      "2021-08-25 10:46:21.978 | INFO     | src.policies:train:109 - Episode 526\n",
      "2021-08-25 10:46:21.983 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:21.984 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 10:46:21.984 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.61\n",
      "2021-08-25 10:46:21.985 | INFO     | src.policies:train:109 - Episode 527\n",
      "2021-08-25 10:46:21.991 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:21.992 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:21.993 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.41\n",
      "2021-08-25 10:46:21.994 | INFO     | src.policies:train:109 - Episode 528\n",
      "2021-08-25 10:46:22.001 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.002 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 10:46:22.003 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.07\n",
      "2021-08-25 10:46:22.004 | INFO     | src.policies:train:109 - Episode 529\n",
      "2021-08-25 10:46:22.014 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.015 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 10:46:22.016 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.12\n",
      "2021-08-25 10:46:22.017 | INFO     | src.policies:train:109 - Episode 530\n",
      "2021-08-25 10:46:22.027 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.028 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 10:46:22.028 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.17\n",
      "2021-08-25 10:46:22.029 | INFO     | src.policies:train:109 - Episode 531\n",
      "2021-08-25 10:46:22.040 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.041 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 10:46:22.042 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.11\n",
      "2021-08-25 10:46:22.043 | WARNING  | src.policies:train:131 - The actual batch size is 205, instead of 200\n",
      "2021-08-25 10:46:22.049 | INFO     | src.policies:train:157 - Total loss: 143.09194946289062\n",
      "2021-08-25 10:46:22.050 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:22.052 | INFO     | src.policies:train:103 - Epoch 62 / 800\n",
      "2021-08-25 10:46:22.053 | INFO     | src.policies:train:109 - Episode 532\n",
      "2021-08-25 10:46:22.059 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.060 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:22.060 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.03\n",
      "2021-08-25 10:46:22.061 | INFO     | src.policies:train:109 - Episode 533\n",
      "2021-08-25 10:46:22.066 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.067 | INFO     | src.policies:train:121 - Mean episode return: 9.0\n",
      "2021-08-25 10:46:22.068 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.95\n",
      "2021-08-25 10:46:22.069 | INFO     | src.policies:train:109 - Episode 534\n",
      "2021-08-25 10:46:22.083 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.084 | INFO     | src.policies:train:121 - Mean episode return: 39.0\n",
      "2021-08-25 10:46:22.085 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.18\n",
      "2021-08-25 10:46:22.086 | INFO     | src.policies:train:109 - Episode 535\n",
      "2021-08-25 10:46:22.093 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.094 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:22.095 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.06\n",
      "2021-08-25 10:46:22.096 | INFO     | src.policies:train:109 - Episode 536\n",
      "2021-08-25 10:46:22.102 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.103 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:22.103 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.95\n",
      "2021-08-25 10:46:22.104 | INFO     | src.policies:train:109 - Episode 537\n",
      "2021-08-25 10:46:22.111 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.112 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:22.113 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.72\n",
      "2021-08-25 10:46:22.113 | INFO     | src.policies:train:109 - Episode 538\n",
      "2021-08-25 10:46:22.121 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.122 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:22.123 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.64\n",
      "2021-08-25 10:46:22.124 | INFO     | src.policies:train:109 - Episode 539\n",
      "2021-08-25 10:46:22.130 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.131 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 10:46:22.131 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.59\n",
      "2021-08-25 10:46:22.132 | INFO     | src.policies:train:109 - Episode 540\n",
      "2021-08-25 10:46:22.146 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.147 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 10:46:22.148 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.38\n",
      "2021-08-25 10:46:22.148 | INFO     | src.policies:train:109 - Episode 541\n",
      "2021-08-25 10:46:22.160 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.161 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 10:46:22.162 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.52\n",
      "2021-08-25 10:46:22.162 | INFO     | src.policies:train:109 - Episode 542\n",
      "2021-08-25 10:46:22.169 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.170 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 10:46:22.171 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.45\n",
      "2021-08-25 10:46:22.171 | WARNING  | src.policies:train:131 - The actual batch size is 206, instead of 200\n",
      "2021-08-25 10:46:22.177 | INFO     | src.policies:train:157 - Total loss: 149.89682006835938\n",
      "2021-08-25 10:46:22.178 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:22.180 | INFO     | src.policies:train:103 - Epoch 63 / 800\n",
      "2021-08-25 10:46:22.181 | INFO     | src.policies:train:109 - Episode 543\n",
      "2021-08-25 10:46:22.195 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.196 | INFO     | src.policies:train:121 - Mean episode return: 42.0\n",
      "2021-08-25 10:46:22.197 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.75\n",
      "2021-08-25 10:46:22.198 | INFO     | src.policies:train:109 - Episode 544\n",
      "2021-08-25 10:46:22.205 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.207 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:22.208 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.49\n",
      "2021-08-25 10:46:22.208 | INFO     | src.policies:train:109 - Episode 545\n",
      "2021-08-25 10:46:22.224 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.225 | INFO     | src.policies:train:121 - Mean episode return: 42.0\n",
      "2021-08-25 10:46:22.225 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.31\n",
      "2021-08-25 10:46:22.226 | INFO     | src.policies:train:109 - Episode 546\n",
      "2021-08-25 10:46:22.234 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.235 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:22.236 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.19\n",
      "2021-08-25 10:46:22.237 | INFO     | src.policies:train:109 - Episode 547\n",
      "2021-08-25 10:46:22.245 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.246 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 10:46:22.247 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.27\n",
      "2021-08-25 10:46:22.248 | INFO     | src.policies:train:109 - Episode 548\n",
      "2021-08-25 10:46:22.259 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:22.260 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 10:46:22.260 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.35\n",
      "2021-08-25 10:46:22.261 | INFO     | src.policies:train:109 - Episode 549\n",
      "2021-08-25 10:46:22.271 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.272 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 10:46:22.273 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.33\n",
      "2021-08-25 10:46:22.274 | INFO     | src.policies:train:109 - Episode 550\n",
      "2021-08-25 10:46:22.280 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.281 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:22.282 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.32\n",
      "2021-08-25 10:46:22.283 | INFO     | src.policies:train:109 - Episode 551\n",
      "2021-08-25 10:46:22.296 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.297 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 10:46:22.298 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.14\n",
      "2021-08-25 10:46:22.298 | WARNING  | src.policies:train:131 - The actual batch size is 232, instead of 200\n",
      "2021-08-25 10:46:22.304 | INFO     | src.policies:train:157 - Total loss: 202.77867126464844\n",
      "2021-08-25 10:46:22.305 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:22.308 | INFO     | src.policies:train:103 - Epoch 64 / 800\n",
      "2021-08-25 10:46:22.309 | INFO     | src.policies:train:109 - Episode 552\n",
      "2021-08-25 10:46:22.318 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.319 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 10:46:22.319 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.22\n",
      "2021-08-25 10:46:22.320 | INFO     | src.policies:train:109 - Episode 553\n",
      "2021-08-25 10:46:22.333 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.334 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 10:46:22.335 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.38\n",
      "2021-08-25 10:46:22.336 | INFO     | src.policies:train:109 - Episode 554\n",
      "2021-08-25 10:46:22.342 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.343 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:22.344 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.15\n",
      "2021-08-25 10:46:22.345 | INFO     | src.policies:train:109 - Episode 555\n",
      "2021-08-25 10:46:22.360 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.361 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 10:46:22.361 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.44\n",
      "2021-08-25 10:46:22.362 | INFO     | src.policies:train:109 - Episode 556\n",
      "2021-08-25 10:46:22.377 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.378 | INFO     | src.policies:train:121 - Mean episode return: 39.0\n",
      "2021-08-25 10:46:22.379 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.5\n",
      "2021-08-25 10:46:22.380 | INFO     | src.policies:train:109 - Episode 557\n",
      "2021-08-25 10:46:22.386 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.387 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 10:46:22.388 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.04\n",
      "2021-08-25 10:46:22.389 | INFO     | src.policies:train:109 - Episode 558\n",
      "2021-08-25 10:46:22.397 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.398 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:22.399 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.95\n",
      "2021-08-25 10:46:22.400 | INFO     | src.policies:train:109 - Episode 559\n",
      "2021-08-25 10:46:22.408 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.409 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:22.410 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.93\n",
      "2021-08-25 10:46:22.410 | INFO     | src.policies:train:109 - Episode 560\n",
      "2021-08-25 10:46:22.424 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.425 | INFO     | src.policies:train:121 - Mean episode return: 39.0\n",
      "2021-08-25 10:46:22.426 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.07\n",
      "2021-08-25 10:46:22.427 | WARNING  | src.policies:train:131 - The actual batch size is 231, instead of 200\n",
      "2021-08-25 10:46:22.433 | INFO     | src.policies:train:157 - Total loss: 205.8730010986328\n",
      "2021-08-25 10:46:22.433 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:22.436 | INFO     | src.policies:train:103 - Epoch 65 / 800\n",
      "2021-08-25 10:46:22.437 | INFO     | src.policies:train:109 - Episode 561\n",
      "2021-08-25 10:46:22.449 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.450 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 10:46:22.451 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.89\n",
      "2021-08-25 10:46:22.452 | INFO     | src.policies:train:109 - Episode 562\n",
      "2021-08-25 10:46:22.459 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.459 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:22.460 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.73\n",
      "2021-08-25 10:46:22.461 | INFO     | src.policies:train:109 - Episode 563\n",
      "2021-08-25 10:46:22.472 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.473 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 10:46:22.474 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.23\n",
      "2021-08-25 10:46:22.474 | INFO     | src.policies:train:109 - Episode 564\n",
      "2021-08-25 10:46:22.484 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.485 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 10:46:22.486 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.19\n",
      "2021-08-25 10:46:22.486 | INFO     | src.policies:train:109 - Episode 565\n",
      "2021-08-25 10:46:22.496 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.498 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 10:46:22.498 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.27\n",
      "2021-08-25 10:46:22.499 | INFO     | src.policies:train:109 - Episode 566\n",
      "2021-08-25 10:46:22.507 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.508 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:22.508 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.31\n",
      "2021-08-25 10:46:22.509 | INFO     | src.policies:train:109 - Episode 567\n",
      "2021-08-25 10:46:22.520 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.521 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 10:46:22.521 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.37\n",
      "2021-08-25 10:46:22.522 | INFO     | src.policies:train:109 - Episode 568\n",
      "2021-08-25 10:46:22.530 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.531 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 10:46:22.532 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:22.533 | INFO     | src.policies:train:109 - Episode 569\n",
      "2021-08-25 10:46:22.541 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.542 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:22.543 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.32\n",
      "2021-08-25 10:46:22.544 | INFO     | src.policies:train:109 - Episode 570\n",
      "2021-08-25 10:46:22.552 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.553 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:22.554 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.2\n",
      "2021-08-25 10:46:22.555 | WARNING  | src.policies:train:131 - The actual batch size is 211, instead of 200\n",
      "2021-08-25 10:46:22.560 | INFO     | src.policies:train:157 - Total loss: 114.65805053710938\n",
      "2021-08-25 10:46:22.561 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:22.564 | INFO     | src.policies:train:103 - Epoch 66 / 800\n",
      "2021-08-25 10:46:22.565 | INFO     | src.policies:train:109 - Episode 571\n",
      "2021-08-25 10:46:22.572 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.573 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:22.574 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.2\n",
      "2021-08-25 10:46:22.575 | INFO     | src.policies:train:109 - Episode 572\n",
      "2021-08-25 10:46:22.583 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.584 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:22.585 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.19\n",
      "2021-08-25 10:46:22.586 | INFO     | src.policies:train:109 - Episode 573\n",
      "2021-08-25 10:46:22.598 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.599 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 10:46:22.600 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.0\n",
      "2021-08-25 10:46:22.601 | INFO     | src.policies:train:109 - Episode 574\n",
      "2021-08-25 10:46:22.609 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.610 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:22.611 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.05\n",
      "2021-08-25 10:46:22.612 | INFO     | src.policies:train:109 - Episode 575\n",
      "2021-08-25 10:46:22.632 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.633 | INFO     | src.policies:train:121 - Mean episode return: 58.0\n",
      "2021-08-25 10:46:22.633 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.49\n",
      "2021-08-25 10:46:22.634 | INFO     | src.policies:train:109 - Episode 576\n",
      "2021-08-25 10:46:22.646 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.647 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 10:46:22.648 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.7\n",
      "2021-08-25 10:46:22.649 | INFO     | src.policies:train:109 - Episode 577\n",
      "2021-08-25 10:46:22.660 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.661 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 10:46:22.662 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.85\n",
      "2021-08-25 10:46:22.663 | WARNING  | src.policies:train:131 - The actual batch size is 204, instead of 200\n",
      "2021-08-25 10:46:22.668 | INFO     | src.policies:train:157 - Total loss: 255.2542266845703\n",
      "2021-08-25 10:46:22.669 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:22.672 | INFO     | src.policies:train:103 - Epoch 67 / 800\n",
      "2021-08-25 10:46:22.673 | INFO     | src.policies:train:109 - Episode 578\n",
      "2021-08-25 10:46:22.683 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.684 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 10:46:22.685 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.9\n",
      "2021-08-25 10:46:22.685 | INFO     | src.policies:train:109 - Episode 579\n",
      "2021-08-25 10:46:22.694 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.695 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:22.695 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.64\n",
      "2021-08-25 10:46:22.696 | INFO     | src.policies:train:109 - Episode 580\n",
      "2021-08-25 10:46:22.704 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.705 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:22.706 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.65\n",
      "2021-08-25 10:46:22.707 | INFO     | src.policies:train:109 - Episode 581\n",
      "2021-08-25 10:46:22.716 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.717 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 10:46:22.718 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.54\n",
      "2021-08-25 10:46:22.719 | INFO     | src.policies:train:109 - Episode 582\n",
      "2021-08-25 10:46:22.725 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.726 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 10:46:22.727 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.47\n",
      "2021-08-25 10:46:22.727 | INFO     | src.policies:train:109 - Episode 583\n",
      "2021-08-25 10:46:22.734 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.735 | INFO     | src.policies:train:121 - Mean episode return: 9.0\n",
      "2021-08-25 10:46:22.736 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.41\n",
      "2021-08-25 10:46:22.736 | INFO     | src.policies:train:109 - Episode 584\n",
      "2021-08-25 10:46:22.743 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.744 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:22.745 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.33\n",
      "2021-08-25 10:46:22.746 | INFO     | src.policies:train:109 - Episode 585\n",
      "2021-08-25 10:46:22.757 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.758 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 10:46:22.759 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.29\n",
      "2021-08-25 10:46:22.760 | INFO     | src.policies:train:109 - Episode 586\n",
      "2021-08-25 10:46:22.768 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.769 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 10:46:22.770 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.94\n",
      "2021-08-25 10:46:22.771 | INFO     | src.policies:train:109 - Episode 587\n",
      "2021-08-25 10:46:22.783 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.784 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 10:46:22.785 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.94\n",
      "2021-08-25 10:46:22.786 | WARNING  | src.policies:train:131 - The actual batch size is 201, instead of 200\n",
      "2021-08-25 10:46:22.792 | INFO     | src.policies:train:157 - Total loss: 124.0302734375\n",
      "2021-08-25 10:46:22.793 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:22.796 | INFO     | src.policies:train:103 - Epoch 68 / 800\n",
      "2021-08-25 10:46:22.796 | INFO     | src.policies:train:109 - Episode 588\n",
      "2021-08-25 10:46:22.832 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.833 | INFO     | src.policies:train:121 - Mean episode return: 115.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:22.834 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.73\n",
      "2021-08-25 10:46:22.835 | INFO     | src.policies:train:109 - Episode 589\n",
      "2021-08-25 10:46:22.843 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.844 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:22.845 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.79\n",
      "2021-08-25 10:46:22.846 | INFO     | src.policies:train:109 - Episode 590\n",
      "2021-08-25 10:46:22.853 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.854 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:22.854 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.68\n",
      "2021-08-25 10:46:22.855 | INFO     | src.policies:train:109 - Episode 591\n",
      "2021-08-25 10:46:22.867 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.868 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 10:46:22.868 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.73\n",
      "2021-08-25 10:46:22.869 | INFO     | src.policies:train:109 - Episode 592\n",
      "2021-08-25 10:46:22.876 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.877 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:22.877 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.68\n",
      "2021-08-25 10:46:22.878 | INFO     | src.policies:train:109 - Episode 593\n",
      "2021-08-25 10:46:22.891 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.892 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 10:46:22.893 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.77\n",
      "2021-08-25 10:46:22.894 | WARNING  | src.policies:train:131 - The actual batch size is 221, instead of 200\n",
      "2021-08-25 10:46:22.899 | INFO     | src.policies:train:157 - Total loss: 630.2520751953125\n",
      "2021-08-25 10:46:22.899 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:22.902 | INFO     | src.policies:train:103 - Epoch 69 / 800\n",
      "2021-08-25 10:46:22.903 | INFO     | src.policies:train:109 - Episode 594\n",
      "2021-08-25 10:46:22.920 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.921 | INFO     | src.policies:train:121 - Mean episode return: 46.0\n",
      "2021-08-25 10:46:22.922 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.1\n",
      "2021-08-25 10:46:22.923 | INFO     | src.policies:train:109 - Episode 595\n",
      "2021-08-25 10:46:22.933 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.934 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 10:46:22.935 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.09\n",
      "2021-08-25 10:46:22.935 | INFO     | src.policies:train:109 - Episode 596\n",
      "2021-08-25 10:46:22.943 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.944 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:22.945 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.14\n",
      "2021-08-25 10:46:22.946 | INFO     | src.policies:train:109 - Episode 597\n",
      "2021-08-25 10:46:22.951 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.952 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 10:46:22.953 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.0\n",
      "2021-08-25 10:46:22.954 | INFO     | src.policies:train:109 - Episode 598\n",
      "2021-08-25 10:46:22.964 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.965 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 10:46:22.965 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.0\n",
      "2021-08-25 10:46:22.966 | INFO     | src.policies:train:109 - Episode 599\n",
      "2021-08-25 10:46:22.973 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.974 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:22.975 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.74\n",
      "2021-08-25 10:46:22.975 | INFO     | src.policies:train:109 - Episode 600\n",
      "2021-08-25 10:46:22.982 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.983 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:22.984 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.38\n",
      "2021-08-25 10:46:22.985 | INFO     | src.policies:train:109 - Episode 601\n",
      "2021-08-25 10:46:22.994 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:22.995 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 10:46:22.995 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.93\n",
      "2021-08-25 10:46:22.996 | INFO     | src.policies:train:109 - Episode 602\n",
      "2021-08-25 10:46:23.017 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:23.018 | INFO     | src.policies:train:121 - Mean episode return: 65.0\n",
      "2021-08-25 10:46:23.019 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.31\n",
      "2021-08-25 10:46:23.020 | WARNING  | src.policies:train:131 - The actual batch size is 232, instead of 200\n",
      "2021-08-25 10:46:23.027 | INFO     | src.policies:train:157 - Total loss: 281.35955810546875\n",
      "2021-08-25 10:46:23.027 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:23.030 | INFO     | src.policies:train:103 - Epoch 70 / 800\n",
      "2021-08-25 10:46:23.031 | INFO     | src.policies:train:109 - Episode 603\n",
      "2021-08-25 10:46:23.041 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:23.042 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 10:46:23.043 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.46\n",
      "2021-08-25 10:46:23.044 | INFO     | src.policies:train:109 - Episode 604\n",
      "2021-08-25 10:46:23.051 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:23.052 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:23.052 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.2\n",
      "2021-08-25 10:46:23.053 | INFO     | src.policies:train:109 - Episode 605\n",
      "2021-08-25 10:46:23.066 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:23.067 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 10:46:23.068 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.41\n",
      "2021-08-25 10:46:23.068 | INFO     | src.policies:train:109 - Episode 606\n",
      "2021-08-25 10:46:23.079 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:23.080 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 10:46:23.081 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.52\n",
      "2021-08-25 10:46:23.082 | INFO     | src.policies:train:109 - Episode 607\n",
      "2021-08-25 10:46:23.090 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:23.091 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:23.092 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.23\n",
      "2021-08-25 10:46:23.093 | INFO     | src.policies:train:109 - Episode 608\n",
      "2021-08-25 10:46:23.105 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:23.106 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 10:46:23.107 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.25\n",
      "2021-08-25 10:46:23.107 | INFO     | src.policies:train:109 - Episode 609\n",
      "2021-08-25 10:46:23.118 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:23.119 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 10:46:23.120 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.34\n",
      "2021-08-25 10:46:23.120 | INFO     | src.policies:train:109 - Episode 610\n",
      "2021-08-25 10:46:23.131 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:23.132 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 10:46:23.133 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.43\n",
      "2021-08-25 10:46:23.134 | INFO     | src.policies:train:109 - Episode 611\n",
      "2021-08-25 10:46:23.147 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:23.148 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 10:46:23.148 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.58\n",
      "2021-08-25 10:46:23.149 | WARNING  | src.policies:train:131 - The actual batch size is 226, instead of 200\n",
      "2021-08-25 10:46:23.155 | INFO     | src.policies:train:157 - Total loss: 155.15640258789062\n",
      "2021-08-25 10:46:23.155 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:23.158 | INFO     | src.policies:train:103 - Epoch 71 / 800\n",
      "2021-08-25 10:46:23.159 | INFO     | src.policies:train:109 - Episode 612\n",
      "2021-08-25 10:46:23.171 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:23.172 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 10:46:23.173 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.53\n",
      "2021-08-25 10:46:23.174 | INFO     | src.policies:train:109 - Episode 613\n",
      "2021-08-25 10:46:23.196 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:23.197 | INFO     | src.policies:train:121 - Mean episode return: 64.0\n",
      "2021-08-25 10:46:23.198 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.04\n",
      "2021-08-25 10:46:23.198 | INFO     | src.policies:train:109 - Episode 614\n",
      "2021-08-25 10:46:23.206 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:23.207 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:23.208 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.06\n",
      "2021-08-25 10:46:23.209 | INFO     | src.policies:train:109 - Episode 615\n",
      "2021-08-25 10:46:23.219 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:23.220 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 10:46:23.221 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.18\n",
      "2021-08-25 10:46:23.222 | INFO     | src.policies:train:109 - Episode 616\n",
      "2021-08-25 10:46:23.233 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:23.234 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 10:46:23.234 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.02\n",
      "2021-08-25 10:46:23.235 | INFO     | src.policies:train:109 - Episode 617\n",
      "2021-08-25 10:46:23.244 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:23.245 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:23.246 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.99\n",
      "2021-08-25 10:46:23.246 | INFO     | src.policies:train:109 - Episode 618\n",
      "2021-08-25 10:46:23.269 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:23.270 | INFO     | src.policies:train:121 - Mean episode return: 67.0\n",
      "2021-08-25 10:46:23.271 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.16\n",
      "2021-08-25 10:46:23.271 | WARNING  | src.policies:train:131 - The actual batch size is 248, instead of 200\n",
      "2021-08-25 10:46:23.277 | INFO     | src.policies:train:157 - Total loss: 384.1354675292969\n",
      "2021-08-25 10:46:23.277 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:23.280 | INFO     | src.policies:train:103 - Epoch 72 / 800\n",
      "2021-08-25 10:46:23.281 | INFO     | src.policies:train:109 - Episode 619\n",
      "2021-08-25 10:46:23.291 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:23.292 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 10:46:23.292 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.06\n",
      "2021-08-25 10:46:23.293 | INFO     | src.policies:train:109 - Episode 620\n",
      "2021-08-25 10:46:23.301 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:23.302 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:23.303 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.92\n",
      "2021-08-25 10:46:23.303 | INFO     | src.policies:train:109 - Episode 621\n",
      "2021-08-25 10:46:23.318 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:23.319 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 10:46:23.319 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.97\n",
      "2021-08-25 10:46:23.320 | INFO     | src.policies:train:109 - Episode 622\n",
      "2021-08-25 10:46:23.331 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:23.332 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 10:46:23.332 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.9\n",
      "2021-08-25 10:46:23.333 | INFO     | src.policies:train:109 - Episode 623\n",
      "2021-08-25 10:46:23.346 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:23.347 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 10:46:23.348 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.12\n",
      "2021-08-25 10:46:23.349 | INFO     | src.policies:train:109 - Episode 624\n",
      "2021-08-25 10:46:23.368 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:23.369 | INFO     | src.policies:train:121 - Mean episode return: 55.0\n",
      "2021-08-25 10:46:23.370 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.31\n",
      "2021-08-25 10:46:23.370 | INFO     | src.policies:train:109 - Episode 625\n",
      "2021-08-25 10:46:23.378 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:23.379 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 10:46:23.380 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.39\n",
      "2021-08-25 10:46:23.380 | WARNING  | src.policies:train:131 - The actual batch size is 212, instead of 200\n",
      "2021-08-25 10:46:23.386 | INFO     | src.policies:train:157 - Total loss: 246.99513244628906\n",
      "2021-08-25 10:46:23.387 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:23.389 | INFO     | src.policies:train:103 - Epoch 73 / 800\n",
      "2021-08-25 10:46:23.390 | INFO     | src.policies:train:109 - Episode 626\n",
      "2021-08-25 10:46:23.398 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:23.398 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:23.399 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.47\n",
      "2021-08-25 10:46:23.400 | INFO     | src.policies:train:109 - Episode 627\n",
      "2021-08-25 10:46:23.411 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:23.412 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 10:46:23.413 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.59\n",
      "2021-08-25 10:46:23.414 | INFO     | src.policies:train:109 - Episode 628\n",
      "2021-08-25 10:46:23.451 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:23.452 | INFO     | src.policies:train:121 - Mean episode return: 115.0\n",
      "2021-08-25 10:46:23.452 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.57\n",
      "2021-08-25 10:46:23.453 | INFO     | src.policies:train:109 - Episode 629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:23.466 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:23.467 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 10:46:23.468 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.69\n",
      "2021-08-25 10:46:23.469 | INFO     | src.policies:train:109 - Episode 630\n",
      "2021-08-25 10:46:23.479 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:23.480 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 10:46:23.480 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.65\n",
      "2021-08-25 10:46:23.481 | WARNING  | src.policies:train:131 - The actual batch size is 213, instead of 200\n",
      "2021-08-25 10:46:23.487 | INFO     | src.policies:train:157 - Total loss: 642.825439453125\n",
      "2021-08-25 10:46:23.488 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:23.490 | INFO     | src.policies:train:103 - Epoch 74 / 800\n",
      "2021-08-25 10:46:23.491 | INFO     | src.policies:train:109 - Episode 631\n",
      "2021-08-25 10:46:23.502 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:23.503 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 10:46:23.504 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.69\n",
      "2021-08-25 10:46:23.505 | INFO     | src.policies:train:109 - Episode 632\n",
      "2021-08-25 10:46:23.524 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:23.525 | INFO     | src.policies:train:121 - Mean episode return: 54.0\n",
      "2021-08-25 10:46:23.525 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.1\n",
      "2021-08-25 10:46:23.526 | INFO     | src.policies:train:109 - Episode 633\n",
      "2021-08-25 10:46:23.535 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:23.536 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 10:46:23.537 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.18\n",
      "2021-08-25 10:46:23.538 | INFO     | src.policies:train:109 - Episode 634\n",
      "2021-08-25 10:46:23.544 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:23.545 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:23.545 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.91\n",
      "2021-08-25 10:46:23.546 | INFO     | src.policies:train:109 - Episode 635\n",
      "2021-08-25 10:46:23.559 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:23.560 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 10:46:23.560 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.1\n",
      "2021-08-25 10:46:23.561 | INFO     | src.policies:train:109 - Episode 636\n",
      "2021-08-25 10:46:23.569 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:23.570 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:23.570 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.11\n",
      "2021-08-25 10:46:23.571 | INFO     | src.policies:train:109 - Episode 637\n",
      "2021-08-25 10:46:23.578 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:23.579 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:23.580 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.12\n",
      "2021-08-25 10:46:23.581 | INFO     | src.policies:train:109 - Episode 638\n",
      "2021-08-25 10:46:23.595 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:23.596 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 10:46:23.596 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.33\n",
      "2021-08-25 10:46:23.597 | WARNING  | src.policies:train:131 - The actual batch size is 212, instead of 200\n",
      "2021-08-25 10:46:23.603 | INFO     | src.policies:train:157 - Total loss: 230.71580505371094\n",
      "2021-08-25 10:46:23.603 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:23.606 | INFO     | src.policies:train:103 - Epoch 75 / 800\n",
      "2021-08-25 10:46:23.607 | INFO     | src.policies:train:109 - Episode 639\n",
      "2021-08-25 10:46:23.615 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:23.616 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:23.617 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.41\n",
      "2021-08-25 10:46:23.618 | INFO     | src.policies:train:109 - Episode 640\n",
      "2021-08-25 10:46:23.624 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:23.625 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:23.626 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.18\n",
      "2021-08-25 10:46:23.626 | INFO     | src.policies:train:109 - Episode 641\n",
      "2021-08-25 10:46:23.636 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:23.637 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 10:46:23.638 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.08\n",
      "2021-08-25 10:46:23.638 | INFO     | src.policies:train:109 - Episode 642\n",
      "2021-08-25 10:46:23.649 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:23.650 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 10:46:23.651 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.23\n",
      "2021-08-25 10:46:23.652 | INFO     | src.policies:train:109 - Episode 643\n",
      "2021-08-25 10:46:23.665 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:23.666 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 10:46:23.667 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.21\n",
      "2021-08-25 10:46:23.667 | INFO     | src.policies:train:109 - Episode 644\n",
      "2021-08-25 10:46:23.679 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:23.680 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 10:46:23.680 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.32\n",
      "2021-08-25 10:46:23.681 | INFO     | src.policies:train:109 - Episode 645\n",
      "2021-08-25 10:46:23.688 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:23.689 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:23.690 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.02\n",
      "2021-08-25 10:46:23.691 | INFO     | src.policies:train:109 - Episode 646\n",
      "2021-08-25 10:46:23.697 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:23.698 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:23.699 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.0\n",
      "2021-08-25 10:46:23.700 | INFO     | src.policies:train:109 - Episode 647\n",
      "2021-08-25 10:46:23.710 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:23.712 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 10:46:23.712 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.06\n",
      "2021-08-25 10:46:23.713 | INFO     | src.policies:train:109 - Episode 648\n",
      "2021-08-25 10:46:23.730 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:23.731 | INFO     | src.policies:train:121 - Mean episode return: 49.0\n",
      "2021-08-25 10:46:23.732 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.28\n",
      "2021-08-25 10:46:23.733 | WARNING  | src.policies:train:131 - The actual batch size is 247, instead of 200\n",
      "2021-08-25 10:46:23.739 | INFO     | src.policies:train:157 - Total loss: 189.33494567871094\n",
      "2021-08-25 10:46:23.739 | INFO     | src.policies:train:161 - Epoch infos: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:23.742 | INFO     | src.policies:train:103 - Epoch 76 / 800\n",
      "2021-08-25 10:46:23.743 | INFO     | src.policies:train:109 - Episode 649\n",
      "2021-08-25 10:46:23.758 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:23.759 | INFO     | src.policies:train:121 - Mean episode return: 46.0\n",
      "2021-08-25 10:46:23.760 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.51\n",
      "2021-08-25 10:46:23.761 | INFO     | src.policies:train:109 - Episode 650\n",
      "2021-08-25 10:46:23.767 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:23.768 | INFO     | src.policies:train:121 - Mean episode return: 9.0\n",
      "2021-08-25 10:46:23.769 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.48\n",
      "2021-08-25 10:46:23.770 | INFO     | src.policies:train:109 - Episode 651\n",
      "2021-08-25 10:46:23.778 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:23.779 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 10:46:23.780 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.35\n",
      "2021-08-25 10:46:23.781 | INFO     | src.policies:train:109 - Episode 652\n",
      "2021-08-25 10:46:23.790 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:23.791 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 10:46:23.792 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.34\n",
      "2021-08-25 10:46:23.793 | INFO     | src.policies:train:109 - Episode 653\n",
      "2021-08-25 10:46:23.808 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:23.809 | INFO     | src.policies:train:121 - Mean episode return: 41.0\n",
      "2021-08-25 10:46:23.810 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.42\n",
      "2021-08-25 10:46:23.811 | INFO     | src.policies:train:109 - Episode 654\n",
      "2021-08-25 10:46:23.818 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:23.818 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:23.819 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.44\n",
      "2021-08-25 10:46:23.820 | INFO     | src.policies:train:109 - Episode 655\n",
      "2021-08-25 10:46:23.835 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:23.836 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 10:46:23.836 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.44\n",
      "2021-08-25 10:46:23.837 | INFO     | src.policies:train:109 - Episode 656\n",
      "2021-08-25 10:46:23.849 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:23.850 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 10:46:23.851 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.36\n",
      "2021-08-25 10:46:23.852 | WARNING  | src.policies:train:131 - The actual batch size is 224, instead of 200\n",
      "2021-08-25 10:46:23.857 | INFO     | src.policies:train:157 - Total loss: 227.4898223876953\n",
      "2021-08-25 10:46:23.857 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:23.860 | INFO     | src.policies:train:103 - Epoch 77 / 800\n",
      "2021-08-25 10:46:23.861 | INFO     | src.policies:train:109 - Episode 657\n",
      "2021-08-25 10:46:23.869 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:23.870 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:23.871 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.44\n",
      "2021-08-25 10:46:23.872 | INFO     | src.policies:train:109 - Episode 658\n",
      "2021-08-25 10:46:23.881 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:23.882 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 10:46:23.882 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.47\n",
      "2021-08-25 10:46:23.883 | INFO     | src.policies:train:109 - Episode 659\n",
      "2021-08-25 10:46:23.892 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:23.893 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 10:46:23.894 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.51\n",
      "2021-08-25 10:46:23.895 | INFO     | src.policies:train:109 - Episode 660\n",
      "2021-08-25 10:46:23.903 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:23.904 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:23.905 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.31\n",
      "2021-08-25 10:46:23.906 | INFO     | src.policies:train:109 - Episode 661\n",
      "2021-08-25 10:46:23.924 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:23.925 | INFO     | src.policies:train:121 - Mean episode return: 53.0\n",
      "2021-08-25 10:46:23.926 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.51\n",
      "2021-08-25 10:46:23.927 | INFO     | src.policies:train:109 - Episode 662\n",
      "2021-08-25 10:46:23.940 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:23.942 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 10:46:23.942 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.71\n",
      "2021-08-25 10:46:23.943 | INFO     | src.policies:train:109 - Episode 663\n",
      "2021-08-25 10:46:23.955 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:23.956 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 10:46:23.957 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.71\n",
      "2021-08-25 10:46:23.957 | INFO     | src.policies:train:109 - Episode 664\n",
      "2021-08-25 10:46:23.964 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:23.965 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:23.966 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.62\n",
      "2021-08-25 10:46:23.966 | WARNING  | src.policies:train:131 - The actual batch size is 209, instead of 200\n",
      "2021-08-25 10:46:23.972 | INFO     | src.policies:train:157 - Total loss: 201.39486694335938\n",
      "2021-08-25 10:46:23.973 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:23.975 | INFO     | src.policies:train:103 - Epoch 78 / 800\n",
      "2021-08-25 10:46:23.976 | INFO     | src.policies:train:109 - Episode 665\n",
      "2021-08-25 10:46:23.984 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:23.985 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 10:46:23.986 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.6\n",
      "2021-08-25 10:46:23.987 | INFO     | src.policies:train:109 - Episode 666\n",
      "2021-08-25 10:46:23.993 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:23.994 | INFO     | src.policies:train:121 - Mean episode return: 9.0\n",
      "2021-08-25 10:46:23.995 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.55\n",
      "2021-08-25 10:46:23.995 | INFO     | src.policies:train:109 - Episode 667\n",
      "2021-08-25 10:46:24.004 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:24.005 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 10:46:24.005 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.53\n",
      "2021-08-25 10:46:24.006 | INFO     | src.policies:train:109 - Episode 668\n",
      "2021-08-25 10:46:24.013 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:24.014 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 10:46:24.015 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.46\n",
      "2021-08-25 10:46:24.015 | INFO     | src.policies:train:109 - Episode 669\n",
      "2021-08-25 10:46:24.023 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:24.024 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:24.025 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.46\n",
      "2021-08-25 10:46:24.026 | INFO     | src.policies:train:109 - Episode 670\n",
      "2021-08-25 10:46:24.033 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:24.034 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:24.035 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.43\n",
      "2021-08-25 10:46:24.036 | INFO     | src.policies:train:109 - Episode 671\n",
      "2021-08-25 10:46:24.044 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:24.045 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 10:46:24.046 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.45\n",
      "2021-08-25 10:46:24.047 | INFO     | src.policies:train:109 - Episode 672\n",
      "2021-08-25 10:46:24.053 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:24.054 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:24.055 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.39\n",
      "2021-08-25 10:46:24.056 | INFO     | src.policies:train:109 - Episode 673\n",
      "2021-08-25 10:46:24.062 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:24.063 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 10:46:24.064 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.16\n",
      "2021-08-25 10:46:24.064 | INFO     | src.policies:train:109 - Episode 674\n",
      "2021-08-25 10:46:24.077 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:24.078 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 10:46:24.078 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.3\n",
      "2021-08-25 10:46:24.079 | INFO     | src.policies:train:109 - Episode 675\n",
      "2021-08-25 10:46:24.109 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:24.111 | INFO     | src.policies:train:121 - Mean episode return: 89.0\n",
      "2021-08-25 10:46:24.111 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.61\n",
      "2021-08-25 10:46:24.112 | WARNING  | src.policies:train:131 - The actual batch size is 258, instead of 200\n",
      "2021-08-25 10:46:24.118 | INFO     | src.policies:train:157 - Total loss: 347.5101318359375\n",
      "2021-08-25 10:46:24.118 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:24.121 | INFO     | src.policies:train:103 - Epoch 79 / 800\n",
      "2021-08-25 10:46:24.122 | INFO     | src.policies:train:109 - Episode 676\n",
      "2021-08-25 10:46:24.135 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:24.136 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 10:46:24.137 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.7\n",
      "2021-08-25 10:46:24.138 | INFO     | src.policies:train:109 - Episode 677\n",
      "2021-08-25 10:46:24.153 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:24.154 | INFO     | src.policies:train:121 - Mean episode return: 41.0\n",
      "2021-08-25 10:46:24.155 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.84\n",
      "2021-08-25 10:46:24.155 | INFO     | src.policies:train:109 - Episode 678\n",
      "2021-08-25 10:46:24.163 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:24.164 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:24.164 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.7\n",
      "2021-08-25 10:46:24.165 | INFO     | src.policies:train:109 - Episode 679\n",
      "2021-08-25 10:46:24.176 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:24.177 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 10:46:24.177 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.79\n",
      "2021-08-25 10:46:24.178 | INFO     | src.policies:train:109 - Episode 680\n",
      "2021-08-25 10:46:24.186 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:24.188 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 10:46:24.188 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.77\n",
      "2021-08-25 10:46:24.189 | INFO     | src.policies:train:109 - Episode 681\n",
      "2021-08-25 10:46:24.203 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:24.204 | INFO     | src.policies:train:121 - Mean episode return: 38.0\n",
      "2021-08-25 10:46:24.205 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.93\n",
      "2021-08-25 10:46:24.206 | INFO     | src.policies:train:109 - Episode 682\n",
      "2021-08-25 10:46:24.213 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:24.214 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:24.214 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.95\n",
      "2021-08-25 10:46:24.215 | INFO     | src.policies:train:109 - Episode 683\n",
      "2021-08-25 10:46:24.225 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:24.226 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 10:46:24.227 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.12\n",
      "2021-08-25 10:46:24.228 | WARNING  | src.policies:train:131 - The actual batch size is 216, instead of 200\n",
      "2021-08-25 10:46:24.233 | INFO     | src.policies:train:157 - Total loss: 196.88511657714844\n",
      "2021-08-25 10:46:24.234 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:24.237 | INFO     | src.policies:train:103 - Epoch 80 / 800\n",
      "2021-08-25 10:46:24.238 | INFO     | src.policies:train:109 - Episode 684\n",
      "2021-08-25 10:46:24.250 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:24.252 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 10:46:24.252 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.32\n",
      "2021-08-25 10:46:24.253 | INFO     | src.policies:train:109 - Episode 685\n",
      "2021-08-25 10:46:24.260 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:24.261 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:24.262 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.18\n",
      "2021-08-25 10:46:24.263 | INFO     | src.policies:train:109 - Episode 686\n",
      "2021-08-25 10:46:24.272 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:24.273 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 10:46:24.274 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.23\n",
      "2021-08-25 10:46:24.275 | INFO     | src.policies:train:109 - Episode 687\n",
      "2021-08-25 10:46:24.288 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:24.289 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 10:46:24.290 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.23\n",
      "2021-08-25 10:46:24.291 | INFO     | src.policies:train:109 - Episode 688\n",
      "2021-08-25 10:46:24.300 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:24.301 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 10:46:24.302 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.3\n",
      "2021-08-25 10:46:24.302 | INFO     | src.policies:train:109 - Episode 689\n",
      "2021-08-25 10:46:24.313 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:24.314 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 10:46:24.314 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.35\n",
      "2021-08-25 10:46:24.315 | INFO     | src.policies:train:109 - Episode 690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:24.333 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:24.334 | INFO     | src.policies:train:121 - Mean episode return: 51.0\n",
      "2021-08-25 10:46:24.334 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.74\n",
      "2021-08-25 10:46:24.335 | WARNING  | src.policies:train:131 - The actual batch size is 201, instead of 200\n",
      "2021-08-25 10:46:24.340 | INFO     | src.policies:train:157 - Total loss: 217.71441650390625\n",
      "2021-08-25 10:46:24.341 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:24.344 | INFO     | src.policies:train:103 - Epoch 81 / 800\n",
      "2021-08-25 10:46:24.345 | INFO     | src.policies:train:109 - Episode 691\n",
      "2021-08-25 10:46:24.362 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:24.363 | INFO     | src.policies:train:121 - Mean episode return: 50.0\n",
      "2021-08-25 10:46:24.364 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.97\n",
      "2021-08-25 10:46:24.365 | INFO     | src.policies:train:109 - Episode 692\n",
      "2021-08-25 10:46:24.374 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:24.375 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 10:46:24.376 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.03\n",
      "2021-08-25 10:46:24.376 | INFO     | src.policies:train:109 - Episode 693\n",
      "2021-08-25 10:46:24.398 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:24.399 | INFO     | src.policies:train:121 - Mean episode return: 62.0\n",
      "2021-08-25 10:46:24.399 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.3\n",
      "2021-08-25 10:46:24.400 | INFO     | src.policies:train:109 - Episode 694\n",
      "2021-08-25 10:46:24.407 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:24.408 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 10:46:24.409 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.94\n",
      "2021-08-25 10:46:24.410 | INFO     | src.policies:train:109 - Episode 695\n",
      "2021-08-25 10:46:24.417 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:24.417 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:24.418 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.84\n",
      "2021-08-25 10:46:24.419 | INFO     | src.policies:train:109 - Episode 696\n",
      "2021-08-25 10:46:24.429 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:24.430 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 10:46:24.431 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.9\n",
      "2021-08-25 10:46:24.432 | INFO     | src.policies:train:109 - Episode 697\n",
      "2021-08-25 10:46:24.453 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:24.454 | INFO     | src.policies:train:121 - Mean episode return: 65.0\n",
      "2021-08-25 10:46:24.454 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.45\n",
      "2021-08-25 10:46:24.455 | WARNING  | src.policies:train:131 - The actual batch size is 242, instead of 200\n",
      "2021-08-25 10:46:24.460 | INFO     | src.policies:train:157 - Total loss: 392.1664733886719\n",
      "2021-08-25 10:46:24.461 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:24.464 | INFO     | src.policies:train:103 - Epoch 82 / 800\n",
      "2021-08-25 10:46:24.465 | INFO     | src.policies:train:109 - Episode 698\n",
      "2021-08-25 10:46:24.472 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:24.473 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:24.474 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.4\n",
      "2021-08-25 10:46:24.475 | INFO     | src.policies:train:109 - Episode 699\n",
      "2021-08-25 10:46:24.483 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:24.484 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:24.485 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.46\n",
      "2021-08-25 10:46:24.486 | INFO     | src.policies:train:109 - Episode 700\n",
      "2021-08-25 10:46:24.494 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:24.495 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:24.496 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.51\n",
      "2021-08-25 10:46:24.497 | INFO     | src.policies:train:109 - Episode 701\n",
      "2021-08-25 10:46:24.507 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:24.508 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 10:46:24.508 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.52\n",
      "2021-08-25 10:46:24.509 | INFO     | src.policies:train:109 - Episode 702\n",
      "2021-08-25 10:46:24.516 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:24.517 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:24.518 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.02\n",
      "2021-08-25 10:46:24.518 | INFO     | src.policies:train:109 - Episode 703\n",
      "2021-08-25 10:46:24.536 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:24.537 | INFO     | src.policies:train:121 - Mean episode return: 53.0\n",
      "2021-08-25 10:46:24.538 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.29\n",
      "2021-08-25 10:46:24.538 | INFO     | src.policies:train:109 - Episode 704\n",
      "2021-08-25 10:46:24.544 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:24.545 | INFO     | src.policies:train:121 - Mean episode return: 9.0\n",
      "2021-08-25 10:46:24.546 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.25\n",
      "2021-08-25 10:46:24.546 | INFO     | src.policies:train:109 - Episode 705\n",
      "2021-08-25 10:46:24.567 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:24.568 | INFO     | src.policies:train:121 - Mean episode return: 58.0\n",
      "2021-08-25 10:46:24.568 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.49\n",
      "2021-08-25 10:46:24.569 | WARNING  | src.policies:train:131 - The actual batch size is 214, instead of 200\n",
      "2021-08-25 10:46:24.575 | INFO     | src.policies:train:157 - Total loss: 272.22857666015625\n",
      "2021-08-25 10:46:24.576 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:24.578 | INFO     | src.policies:train:103 - Epoch 83 / 800\n",
      "2021-08-25 10:46:24.579 | INFO     | src.policies:train:109 - Episode 706\n",
      "2021-08-25 10:46:24.584 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:24.586 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:24.586 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.36\n",
      "2021-08-25 10:46:24.587 | INFO     | src.policies:train:109 - Episode 707\n",
      "2021-08-25 10:46:24.595 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:24.597 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:24.597 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.4\n",
      "2021-08-25 10:46:24.598 | INFO     | src.policies:train:109 - Episode 708\n",
      "2021-08-25 10:46:24.605 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:24.606 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 10:46:24.607 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.26\n",
      "2021-08-25 10:46:24.608 | INFO     | src.policies:train:109 - Episode 709\n",
      "2021-08-25 10:46:24.628 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:24.629 | INFO     | src.policies:train:121 - Mean episode return: 57.0\n",
      "2021-08-25 10:46:24.630 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:24.630 | INFO     | src.policies:train:109 - Episode 710\n",
      "2021-08-25 10:46:24.647 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:24.648 | INFO     | src.policies:train:121 - Mean episode return: 47.0\n",
      "2021-08-25 10:46:24.648 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.81\n",
      "2021-08-25 10:46:24.649 | INFO     | src.policies:train:109 - Episode 711\n",
      "2021-08-25 10:46:24.656 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:24.657 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:24.658 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.62\n",
      "2021-08-25 10:46:24.659 | INFO     | src.policies:train:109 - Episode 712\n",
      "2021-08-25 10:46:24.666 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:24.667 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:24.668 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.43\n",
      "2021-08-25 10:46:24.669 | INFO     | src.policies:train:109 - Episode 713\n",
      "2021-08-25 10:46:24.675 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:24.676 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:24.677 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.91\n",
      "2021-08-25 10:46:24.678 | INFO     | src.policies:train:109 - Episode 714\n",
      "2021-08-25 10:46:24.688 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:24.688 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 10:46:24.689 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.99\n",
      "2021-08-25 10:46:24.690 | WARNING  | src.policies:train:131 - The actual batch size is 217, instead of 200\n",
      "2021-08-25 10:46:24.695 | INFO     | src.policies:train:157 - Total loss: 235.03822326660156\n",
      "2021-08-25 10:46:24.696 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:24.699 | INFO     | src.policies:train:103 - Epoch 84 / 800\n",
      "2021-08-25 10:46:24.700 | INFO     | src.policies:train:109 - Episode 715\n",
      "2021-08-25 10:46:24.705 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:24.706 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:24.707 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.85\n",
      "2021-08-25 10:46:24.708 | INFO     | src.policies:train:109 - Episode 716\n",
      "2021-08-25 10:46:24.738 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:24.739 | INFO     | src.policies:train:121 - Mean episode return: 95.0\n",
      "2021-08-25 10:46:24.740 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.58\n",
      "2021-08-25 10:46:24.741 | INFO     | src.policies:train:109 - Episode 717\n",
      "2021-08-25 10:46:24.751 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:24.752 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 10:46:24.752 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.61\n",
      "2021-08-25 10:46:24.753 | INFO     | src.policies:train:109 - Episode 718\n",
      "2021-08-25 10:46:24.759 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:24.760 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:24.761 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.06\n",
      "2021-08-25 10:46:24.762 | INFO     | src.policies:train:109 - Episode 719\n",
      "2021-08-25 10:46:24.770 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:24.771 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 10:46:24.772 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.98\n",
      "2021-08-25 10:46:24.772 | INFO     | src.policies:train:109 - Episode 720\n",
      "2021-08-25 10:46:24.784 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:24.785 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 10:46:24.785 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.09\n",
      "2021-08-25 10:46:24.786 | INFO     | src.policies:train:109 - Episode 721\n",
      "2021-08-25 10:46:24.804 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:24.805 | INFO     | src.policies:train:121 - Mean episode return: 49.0\n",
      "2021-08-25 10:46:24.806 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.21\n",
      "2021-08-25 10:46:24.807 | WARNING  | src.policies:train:131 - The actual batch size is 236, instead of 200\n",
      "2021-08-25 10:46:24.812 | INFO     | src.policies:train:157 - Total loss: 470.323974609375\n",
      "2021-08-25 10:46:24.813 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:24.815 | INFO     | src.policies:train:103 - Epoch 85 / 800\n",
      "2021-08-25 10:46:24.816 | INFO     | src.policies:train:109 - Episode 722\n",
      "2021-08-25 10:46:24.832 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:24.833 | INFO     | src.policies:train:121 - Mean episode return: 45.0\n",
      "2021-08-25 10:46:24.833 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.41\n",
      "2021-08-25 10:46:24.834 | INFO     | src.policies:train:109 - Episode 723\n",
      "2021-08-25 10:46:24.842 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:24.843 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:24.843 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.22\n",
      "2021-08-25 10:46:24.844 | INFO     | src.policies:train:109 - Episode 724\n",
      "2021-08-25 10:46:24.854 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:24.855 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 10:46:24.856 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.92\n",
      "2021-08-25 10:46:24.856 | INFO     | src.policies:train:109 - Episode 725\n",
      "2021-08-25 10:46:24.867 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:24.868 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 10:46:24.869 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.02\n",
      "2021-08-25 10:46:24.870 | INFO     | src.policies:train:109 - Episode 726\n",
      "2021-08-25 10:46:24.877 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:24.878 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:24.878 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.97\n",
      "2021-08-25 10:46:24.879 | INFO     | src.policies:train:109 - Episode 727\n",
      "2021-08-25 10:46:24.891 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:24.892 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 10:46:24.893 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.05\n",
      "2021-08-25 10:46:24.894 | INFO     | src.policies:train:109 - Episode 728\n",
      "2021-08-25 10:46:24.903 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:24.904 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 10:46:24.905 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.1\n",
      "2021-08-25 10:46:24.905 | INFO     | src.policies:train:109 - Episode 729\n",
      "2021-08-25 10:46:24.913 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:24.914 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:24.915 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.9\n",
      "2021-08-25 10:46:24.916 | INFO     | src.policies:train:109 - Episode 730\n",
      "2021-08-25 10:46:24.931 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:24.932 | INFO     | src.policies:train:121 - Mean episode return: 44.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:24.933 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.13\n",
      "2021-08-25 10:46:24.933 | WARNING  | src.policies:train:131 - The actual batch size is 237, instead of 200\n",
      "2021-08-25 10:46:24.939 | INFO     | src.policies:train:157 - Total loss: 187.53970336914062\n",
      "2021-08-25 10:46:24.940 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:24.943 | INFO     | src.policies:train:103 - Epoch 86 / 800\n",
      "2021-08-25 10:46:24.944 | INFO     | src.policies:train:109 - Episode 731\n",
      "2021-08-25 10:46:24.951 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:24.952 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 10:46:24.953 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.98\n",
      "2021-08-25 10:46:24.954 | INFO     | src.policies:train:109 - Episode 732\n",
      "2021-08-25 10:46:24.961 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:24.962 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:24.963 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.6\n",
      "2021-08-25 10:46:24.964 | INFO     | src.policies:train:109 - Episode 733\n",
      "2021-08-25 10:46:24.973 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:24.974 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 10:46:24.975 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.64\n",
      "2021-08-25 10:46:24.976 | INFO     | src.policies:train:109 - Episode 734\n",
      "2021-08-25 10:46:24.987 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:24.989 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 10:46:24.990 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.75\n",
      "2021-08-25 10:46:24.991 | INFO     | src.policies:train:109 - Episode 735\n",
      "2021-08-25 10:46:25.001 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:25.003 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 10:46:25.004 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.66\n",
      "2021-08-25 10:46:25.004 | INFO     | src.policies:train:109 - Episode 736\n",
      "2021-08-25 10:46:25.014 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:25.015 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:25.016 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.69\n",
      "2021-08-25 10:46:25.017 | INFO     | src.policies:train:109 - Episode 737\n",
      "2021-08-25 10:46:25.024 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:25.025 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 10:46:25.026 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.64\n",
      "2021-08-25 10:46:25.027 | INFO     | src.policies:train:109 - Episode 738\n",
      "2021-08-25 10:46:25.035 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:25.036 | INFO     | src.policies:train:121 - Mean episode return: 9.0\n",
      "2021-08-25 10:46:25.037 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.36\n",
      "2021-08-25 10:46:25.038 | INFO     | src.policies:train:109 - Episode 739\n",
      "2021-08-25 10:46:25.049 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:25.050 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 10:46:25.051 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.39\n",
      "2021-08-25 10:46:25.052 | INFO     | src.policies:train:109 - Episode 740\n",
      "2021-08-25 10:46:25.065 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:25.066 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 10:46:25.067 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.53\n",
      "2021-08-25 10:46:25.068 | INFO     | src.policies:train:109 - Episode 741\n",
      "2021-08-25 10:46:25.091 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:25.092 | INFO     | src.policies:train:121 - Mean episode return: 59.0\n",
      "2021-08-25 10:46:25.093 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.9\n",
      "2021-08-25 10:46:25.094 | WARNING  | src.policies:train:131 - The actual batch size is 243, instead of 200\n",
      "2021-08-25 10:46:25.102 | INFO     | src.policies:train:157 - Total loss: 178.36172485351562\n",
      "2021-08-25 10:46:25.103 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:25.107 | INFO     | src.policies:train:103 - Epoch 87 / 800\n",
      "2021-08-25 10:46:25.108 | INFO     | src.policies:train:109 - Episode 742\n",
      "2021-08-25 10:46:25.115 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:25.116 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:25.117 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.78\n",
      "2021-08-25 10:46:25.118 | INFO     | src.policies:train:109 - Episode 743\n",
      "2021-08-25 10:46:25.127 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:25.128 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:25.129 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.51\n",
      "2021-08-25 10:46:25.130 | INFO     | src.policies:train:109 - Episode 744\n",
      "2021-08-25 10:46:25.143 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:25.145 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 10:46:25.145 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.53\n",
      "2021-08-25 10:46:25.146 | INFO     | src.policies:train:109 - Episode 745\n",
      "2021-08-25 10:46:25.153 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:25.155 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:25.155 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.53\n",
      "2021-08-25 10:46:25.156 | INFO     | src.policies:train:109 - Episode 746\n",
      "2021-08-25 10:46:25.165 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:25.166 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 10:46:25.167 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.6\n",
      "2021-08-25 10:46:25.168 | INFO     | src.policies:train:109 - Episode 747\n",
      "2021-08-25 10:46:25.199 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:25.200 | INFO     | src.policies:train:121 - Mean episode return: 93.0\n",
      "2021-08-25 10:46:25.201 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.27\n",
      "2021-08-25 10:46:25.202 | INFO     | src.policies:train:109 - Episode 748\n",
      "2021-08-25 10:46:25.214 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:25.215 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 10:46:25.216 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.09\n",
      "2021-08-25 10:46:25.217 | WARNING  | src.policies:train:131 - The actual batch size is 212, instead of 200\n",
      "2021-08-25 10:46:25.223 | INFO     | src.policies:train:157 - Total loss: 432.9328308105469\n",
      "2021-08-25 10:46:25.223 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:25.226 | INFO     | src.policies:train:103 - Epoch 88 / 800\n",
      "2021-08-25 10:46:25.227 | INFO     | src.policies:train:109 - Episode 749\n",
      "2021-08-25 10:46:25.238 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:25.239 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 10:46:25.240 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.9\n",
      "2021-08-25 10:46:25.241 | INFO     | src.policies:train:109 - Episode 750\n",
      "2021-08-25 10:46:25.248 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:25.249 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:25.250 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.93\n",
      "2021-08-25 10:46:25.250 | INFO     | src.policies:train:109 - Episode 751\n",
      "2021-08-25 10:46:25.273 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:25.274 | INFO     | src.policies:train:121 - Mean episode return: 64.0\n",
      "2021-08-25 10:46:25.275 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.35\n",
      "2021-08-25 10:46:25.276 | INFO     | src.policies:train:109 - Episode 752\n",
      "2021-08-25 10:46:25.292 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:25.293 | INFO     | src.policies:train:121 - Mean episode return: 45.0\n",
      "2021-08-25 10:46:25.294 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.59\n",
      "2021-08-25 10:46:25.295 | INFO     | src.policies:train:109 - Episode 753\n",
      "2021-08-25 10:46:25.313 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:25.315 | INFO     | src.policies:train:121 - Mean episode return: 48.0\n",
      "2021-08-25 10:46:25.315 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.66\n",
      "2021-08-25 10:46:25.316 | INFO     | src.policies:train:109 - Episode 754\n",
      "2021-08-25 10:46:25.323 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:25.324 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:25.325 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.66\n",
      "2021-08-25 10:46:25.326 | WARNING  | src.policies:train:131 - The actual batch size is 210, instead of 200\n",
      "2021-08-25 10:46:25.331 | INFO     | src.policies:train:157 - Total loss: 343.01739501953125\n",
      "2021-08-25 10:46:25.332 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:25.334 | INFO     | src.policies:train:103 - Epoch 89 / 800\n",
      "2021-08-25 10:46:25.335 | INFO     | src.policies:train:109 - Episode 755\n",
      "2021-08-25 10:46:25.345 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:25.346 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 10:46:25.346 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.49\n",
      "2021-08-25 10:46:25.347 | INFO     | src.policies:train:109 - Episode 756\n",
      "2021-08-25 10:46:25.358 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:25.359 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 10:46:25.360 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.4\n",
      "2021-08-25 10:46:25.361 | INFO     | src.policies:train:109 - Episode 757\n",
      "2021-08-25 10:46:25.370 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:25.371 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:25.371 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.39\n",
      "2021-08-25 10:46:25.372 | INFO     | src.policies:train:109 - Episode 758\n",
      "2021-08-25 10:46:25.382 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:25.383 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 10:46:25.383 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.4\n",
      "2021-08-25 10:46:25.384 | INFO     | src.policies:train:109 - Episode 759\n",
      "2021-08-25 10:46:25.391 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:25.392 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:25.392 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.32\n",
      "2021-08-25 10:46:25.393 | INFO     | src.policies:train:109 - Episode 760\n",
      "2021-08-25 10:46:25.401 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:25.403 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 10:46:25.404 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.3\n",
      "2021-08-25 10:46:25.404 | INFO     | src.policies:train:109 - Episode 761\n",
      "2021-08-25 10:46:25.417 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:25.418 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 10:46:25.419 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.08\n",
      "2021-08-25 10:46:25.419 | INFO     | src.policies:train:109 - Episode 762\n",
      "2021-08-25 10:46:25.433 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:25.434 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 10:46:25.434 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.04\n",
      "2021-08-25 10:46:25.435 | INFO     | src.policies:train:109 - Episode 763\n",
      "2021-08-25 10:46:25.444 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:25.445 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 10:46:25.445 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.94\n",
      "2021-08-25 10:46:25.446 | INFO     | src.policies:train:109 - Episode 764\n",
      "2021-08-25 10:46:25.458 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:25.459 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 10:46:25.460 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.06\n",
      "2021-08-25 10:46:25.461 | WARNING  | src.policies:train:131 - The actual batch size is 220, instead of 200\n",
      "2021-08-25 10:46:25.467 | INFO     | src.policies:train:157 - Total loss: 106.04664611816406\n",
      "2021-08-25 10:46:25.467 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:25.470 | INFO     | src.policies:train:103 - Epoch 90 / 800\n",
      "2021-08-25 10:46:25.471 | INFO     | src.policies:train:109 - Episode 765\n",
      "2021-08-25 10:46:25.490 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:25.492 | INFO     | src.policies:train:121 - Mean episode return: 55.0\n",
      "2021-08-25 10:46:25.493 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.41\n",
      "2021-08-25 10:46:25.493 | INFO     | src.policies:train:109 - Episode 766\n",
      "2021-08-25 10:46:25.508 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:25.510 | INFO     | src.policies:train:121 - Mean episode return: 42.0\n",
      "2021-08-25 10:46:25.510 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.74\n",
      "2021-08-25 10:46:25.511 | INFO     | src.policies:train:109 - Episode 767\n",
      "2021-08-25 10:46:25.519 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:25.520 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:25.520 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.68\n",
      "2021-08-25 10:46:25.521 | INFO     | src.policies:train:109 - Episode 768\n",
      "2021-08-25 10:46:25.537 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:25.538 | INFO     | src.policies:train:121 - Mean episode return: 39.0\n",
      "2021-08-25 10:46:25.539 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.97\n",
      "2021-08-25 10:46:25.539 | INFO     | src.policies:train:109 - Episode 769\n",
      "2021-08-25 10:46:25.551 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:25.553 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 10:46:25.553 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.05\n",
      "2021-08-25 10:46:25.554 | INFO     | src.policies:train:109 - Episode 770\n",
      "2021-08-25 10:46:25.562 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:25.563 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:25.564 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:25.565 | INFO     | src.policies:train:109 - Episode 771\n",
      "2021-08-25 10:46:25.572 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:25.573 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:25.574 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.0\n",
      "2021-08-25 10:46:25.574 | WARNING  | src.policies:train:131 - The actual batch size is 208, instead of 200\n",
      "2021-08-25 10:46:25.580 | INFO     | src.policies:train:157 - Total loss: 247.47854614257812\n",
      "2021-08-25 10:46:25.580 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:25.583 | INFO     | src.policies:train:103 - Epoch 91 / 800\n",
      "2021-08-25 10:46:25.584 | INFO     | src.policies:train:109 - Episode 772\n",
      "2021-08-25 10:46:25.596 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:25.598 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 10:46:25.598 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.2\n",
      "2021-08-25 10:46:25.599 | INFO     | src.policies:train:109 - Episode 773\n",
      "2021-08-25 10:46:25.608 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:25.609 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:25.610 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.28\n",
      "2021-08-25 10:46:25.611 | INFO     | src.policies:train:109 - Episode 774\n",
      "2021-08-25 10:46:25.625 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:25.626 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 10:46:25.626 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.31\n",
      "2021-08-25 10:46:25.627 | INFO     | src.policies:train:109 - Episode 775\n",
      "2021-08-25 10:46:25.643 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:25.644 | INFO     | src.policies:train:121 - Mean episode return: 41.0\n",
      "2021-08-25 10:46:25.645 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.83\n",
      "2021-08-25 10:46:25.646 | INFO     | src.policies:train:109 - Episode 776\n",
      "2021-08-25 10:46:25.660 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:25.661 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 10:46:25.662 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.77\n",
      "2021-08-25 10:46:25.662 | INFO     | src.policies:train:109 - Episode 777\n",
      "2021-08-25 10:46:25.676 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:25.677 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 10:46:25.678 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.68\n",
      "2021-08-25 10:46:25.678 | INFO     | src.policies:train:109 - Episode 778\n",
      "2021-08-25 10:46:25.688 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:25.689 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 10:46:25.690 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.72\n",
      "2021-08-25 10:46:25.691 | WARNING  | src.policies:train:131 - The actual batch size is 213, instead of 200\n",
      "2021-08-25 10:46:25.696 | INFO     | src.policies:train:157 - Total loss: 186.4495849609375\n",
      "2021-08-25 10:46:25.697 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:25.699 | INFO     | src.policies:train:103 - Epoch 92 / 800\n",
      "2021-08-25 10:46:25.700 | INFO     | src.policies:train:109 - Episode 779\n",
      "2021-08-25 10:46:25.706 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:25.707 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 10:46:25.708 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.58\n",
      "2021-08-25 10:46:25.709 | INFO     | src.policies:train:109 - Episode 780\n",
      "2021-08-25 10:46:25.715 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:25.716 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:25.717 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.54\n",
      "2021-08-25 10:46:25.718 | INFO     | src.policies:train:109 - Episode 781\n",
      "2021-08-25 10:46:25.741 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:25.743 | INFO     | src.policies:train:121 - Mean episode return: 68.0\n",
      "2021-08-25 10:46:25.744 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.84\n",
      "2021-08-25 10:46:25.744 | INFO     | src.policies:train:109 - Episode 782\n",
      "2021-08-25 10:46:25.755 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:25.757 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 10:46:25.757 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.96\n",
      "2021-08-25 10:46:25.758 | INFO     | src.policies:train:109 - Episode 783\n",
      "2021-08-25 10:46:25.766 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:25.767 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:25.768 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.84\n",
      "2021-08-25 10:46:25.769 | INFO     | src.policies:train:109 - Episode 784\n",
      "2021-08-25 10:46:25.790 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:25.792 | INFO     | src.policies:train:121 - Mean episode return: 58.0\n",
      "2021-08-25 10:46:25.792 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.07\n",
      "2021-08-25 10:46:25.793 | INFO     | src.policies:train:109 - Episode 785\n",
      "2021-08-25 10:46:25.812 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:25.814 | INFO     | src.policies:train:121 - Mean episode return: 51.0\n",
      "2021-08-25 10:46:25.814 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.45\n",
      "2021-08-25 10:46:25.815 | WARNING  | src.policies:train:131 - The actual batch size is 240, instead of 200\n",
      "2021-08-25 10:46:25.820 | INFO     | src.policies:train:157 - Total loss: 377.58282470703125\n",
      "2021-08-25 10:46:25.821 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:25.824 | INFO     | src.policies:train:103 - Epoch 93 / 800\n",
      "2021-08-25 10:46:25.825 | INFO     | src.policies:train:109 - Episode 786\n",
      "2021-08-25 10:46:25.832 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:25.833 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 10:46:25.834 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.4\n",
      "2021-08-25 10:46:25.835 | INFO     | src.policies:train:109 - Episode 787\n",
      "2021-08-25 10:46:25.852 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:25.853 | INFO     | src.policies:train:121 - Mean episode return: 46.0\n",
      "2021-08-25 10:46:25.854 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.51\n",
      "2021-08-25 10:46:25.855 | INFO     | src.policies:train:109 - Episode 788\n",
      "2021-08-25 10:46:25.876 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:25.877 | INFO     | src.policies:train:121 - Mean episode return: 59.0\n",
      "2021-08-25 10:46:25.877 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.88\n",
      "2021-08-25 10:46:25.878 | INFO     | src.policies:train:109 - Episode 789\n",
      "2021-08-25 10:46:25.889 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:25.890 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 10:46:25.891 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.9\n",
      "2021-08-25 10:46:25.892 | INFO     | src.policies:train:109 - Episode 790\n",
      "2021-08-25 10:46:25.902 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:25.903 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:25.903 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.61\n",
      "2021-08-25 10:46:25.904 | INFO     | src.policies:train:109 - Episode 791\n",
      "2021-08-25 10:46:25.914 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:25.914 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 10:46:25.915 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.31\n",
      "2021-08-25 10:46:25.916 | INFO     | src.policies:train:109 - Episode 792\n",
      "2021-08-25 10:46:25.933 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:25.934 | INFO     | src.policies:train:121 - Mean episode return: 44.0\n",
      "2021-08-25 10:46:25.934 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.55\n",
      "2021-08-25 10:46:25.935 | WARNING  | src.policies:train:131 - The actual batch size is 233, instead of 200\n",
      "2021-08-25 10:46:25.941 | INFO     | src.policies:train:157 - Total loss: 272.3721008300781\n",
      "2021-08-25 10:46:25.941 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:25.944 | INFO     | src.policies:train:103 - Epoch 94 / 800\n",
      "2021-08-25 10:46:25.945 | INFO     | src.policies:train:109 - Episode 793\n",
      "2021-08-25 10:46:25.957 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:25.958 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 10:46:25.959 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.23\n",
      "2021-08-25 10:46:25.960 | INFO     | src.policies:train:109 - Episode 794\n",
      "2021-08-25 10:46:25.974 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:25.975 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 10:46:25.975 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.48\n",
      "2021-08-25 10:46:25.976 | INFO     | src.policies:train:109 - Episode 795\n",
      "2021-08-25 10:46:25.990 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:25.992 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 10:46:25.992 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.71\n",
      "2021-08-25 10:46:25.993 | INFO     | src.policies:train:109 - Episode 796\n",
      "2021-08-25 10:46:26.001 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:26.002 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:26.002 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.65\n",
      "2021-08-25 10:46:26.003 | INFO     | src.policies:train:109 - Episode 797\n",
      "2021-08-25 10:46:26.017 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:26.018 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 10:46:26.019 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.34\n",
      "2021-08-25 10:46:26.020 | INFO     | src.policies:train:109 - Episode 798\n",
      "2021-08-25 10:46:26.046 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:26.047 | INFO     | src.policies:train:121 - Mean episode return: 73.0\n",
      "2021-08-25 10:46:26.048 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.88\n",
      "2021-08-25 10:46:26.049 | WARNING  | src.policies:train:131 - The actual batch size is 224, instead of 200\n",
      "2021-08-25 10:46:26.054 | INFO     | src.policies:train:157 - Total loss: 327.6075744628906\n",
      "2021-08-25 10:46:26.055 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:26.057 | INFO     | src.policies:train:103 - Epoch 95 / 800\n",
      "2021-08-25 10:46:26.058 | INFO     | src.policies:train:109 - Episode 799\n",
      "2021-08-25 10:46:26.065 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:26.066 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 10:46:26.067 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.86\n",
      "2021-08-25 10:46:26.068 | INFO     | src.policies:train:109 - Episode 800\n",
      "2021-08-25 10:46:26.086 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:26.087 | INFO     | src.policies:train:121 - Mean episode return: 47.0\n",
      "2021-08-25 10:46:26.087 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.14\n",
      "2021-08-25 10:46:26.088 | INFO     | src.policies:train:109 - Episode 801\n",
      "2021-08-25 10:46:26.101 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:26.102 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 10:46:26.103 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.22\n",
      "2021-08-25 10:46:26.104 | INFO     | src.policies:train:109 - Episode 802\n",
      "2021-08-25 10:46:26.111 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:26.112 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:26.113 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.19\n",
      "2021-08-25 10:46:26.113 | INFO     | src.policies:train:109 - Episode 803\n",
      "2021-08-25 10:46:26.134 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:26.135 | INFO     | src.policies:train:121 - Mean episode return: 61.0\n",
      "2021-08-25 10:46:26.135 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.27\n",
      "2021-08-25 10:46:26.136 | INFO     | src.policies:train:109 - Episode 804\n",
      "2021-08-25 10:46:26.148 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:26.149 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 10:46:26.149 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.43\n",
      "2021-08-25 10:46:26.150 | INFO     | src.policies:train:109 - Episode 805\n",
      "2021-08-25 10:46:26.163 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:26.164 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 10:46:26.165 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.16\n",
      "2021-08-25 10:46:26.166 | WARNING  | src.policies:train:131 - The actual batch size is 223, instead of 200\n",
      "2021-08-25 10:46:26.172 | INFO     | src.policies:train:157 - Total loss: 271.5240783691406\n",
      "2021-08-25 10:46:26.172 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:26.175 | INFO     | src.policies:train:103 - Epoch 96 / 800\n",
      "2021-08-25 10:46:26.176 | INFO     | src.policies:train:109 - Episode 806\n",
      "2021-08-25 10:46:26.186 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:26.187 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 10:46:26.188 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.32\n",
      "2021-08-25 10:46:26.189 | INFO     | src.policies:train:109 - Episode 807\n",
      "2021-08-25 10:46:26.196 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:26.197 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 10:46:26.197 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.24\n",
      "2021-08-25 10:46:26.198 | INFO     | src.policies:train:109 - Episode 808\n",
      "2021-08-25 10:46:26.214 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:26.215 | INFO     | src.policies:train:121 - Mean episode return: 43.0\n",
      "2021-08-25 10:46:26.216 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.5\n",
      "2021-08-25 10:46:26.217 | INFO     | src.policies:train:109 - Episode 809\n",
      "2021-08-25 10:46:26.228 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:26.229 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 10:46:26.230 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.22\n",
      "2021-08-25 10:46:26.231 | INFO     | src.policies:train:109 - Episode 810\n",
      "2021-08-25 10:46:26.243 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:26.244 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 10:46:26.245 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.06\n",
      "2021-08-25 10:46:26.246 | INFO     | src.policies:train:109 - Episode 811\n",
      "2021-08-25 10:46:26.254 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:26.255 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:26.256 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.12\n",
      "2021-08-25 10:46:26.257 | INFO     | src.policies:train:109 - Episode 812\n",
      "2021-08-25 10:46:26.267 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:26.268 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 10:46:26.269 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.21\n",
      "2021-08-25 10:46:26.270 | INFO     | src.policies:train:109 - Episode 813\n",
      "2021-08-25 10:46:26.276 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:26.277 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 10:46:26.278 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.19\n",
      "2021-08-25 10:46:26.279 | INFO     | src.policies:train:109 - Episode 814\n",
      "2021-08-25 10:46:26.285 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:26.286 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 10:46:26.287 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.07\n",
      "2021-08-25 10:46:26.287 | WARNING  | src.policies:train:131 - The actual batch size is 208, instead of 200\n",
      "2021-08-25 10:46:26.293 | INFO     | src.policies:train:157 - Total loss: 147.86692810058594\n",
      "2021-08-25 10:46:26.294 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:26.296 | INFO     | src.policies:train:103 - Epoch 97 / 800\n",
      "2021-08-25 10:46:26.297 | INFO     | src.policies:train:109 - Episode 815\n",
      "2021-08-25 10:46:26.315 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:26.316 | INFO     | src.policies:train:121 - Mean episode return: 48.0\n",
      "2021-08-25 10:46:26.317 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.43\n",
      "2021-08-25 10:46:26.317 | INFO     | src.policies:train:109 - Episode 816\n",
      "2021-08-25 10:46:26.327 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:26.328 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 10:46:26.329 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.69\n",
      "2021-08-25 10:46:26.329 | INFO     | src.policies:train:109 - Episode 817\n",
      "2021-08-25 10:46:26.336 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:26.337 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 10:46:26.337 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.57\n",
      "2021-08-25 10:46:26.338 | INFO     | src.policies:train:109 - Episode 818\n",
      "2021-08-25 10:46:26.345 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:26.346 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:26.347 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.61\n",
      "2021-08-25 10:46:26.348 | INFO     | src.policies:train:109 - Episode 819\n",
      "2021-08-25 10:46:26.355 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:26.356 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:26.357 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.58\n",
      "2021-08-25 10:46:26.358 | INFO     | src.policies:train:109 - Episode 820\n",
      "2021-08-25 10:46:26.376 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:26.377 | INFO     | src.policies:train:121 - Mean episode return: 52.0\n",
      "2021-08-25 10:46:26.378 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.81\n",
      "2021-08-25 10:46:26.379 | INFO     | src.policies:train:109 - Episode 821\n",
      "2021-08-25 10:46:26.390 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:26.391 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 10:46:26.392 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.56\n",
      "2021-08-25 10:46:26.393 | INFO     | src.policies:train:109 - Episode 822\n",
      "2021-08-25 10:46:26.405 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:26.405 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 10:46:26.406 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.42\n",
      "2021-08-25 10:46:26.407 | WARNING  | src.policies:train:131 - The actual batch size is 216, instead of 200\n",
      "2021-08-25 10:46:26.413 | INFO     | src.policies:train:157 - Total loss: 218.7757568359375\n",
      "2021-08-25 10:46:26.413 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:26.416 | INFO     | src.policies:train:103 - Epoch 98 / 800\n",
      "2021-08-25 10:46:26.417 | INFO     | src.policies:train:109 - Episode 823\n",
      "2021-08-25 10:46:26.425 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:26.426 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 10:46:26.427 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.48\n",
      "2021-08-25 10:46:26.428 | INFO     | src.policies:train:109 - Episode 824\n",
      "2021-08-25 10:46:26.434 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:26.435 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 10:46:26.436 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.33\n",
      "2021-08-25 10:46:26.437 | INFO     | src.policies:train:109 - Episode 825\n",
      "2021-08-25 10:46:26.456 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:26.457 | INFO     | src.policies:train:121 - Mean episode return: 53.0\n",
      "2021-08-25 10:46:26.458 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.59\n",
      "2021-08-25 10:46:26.459 | INFO     | src.policies:train:109 - Episode 826\n",
      "2021-08-25 10:46:26.471 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:26.472 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 10:46:26.473 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.77\n",
      "2021-08-25 10:46:26.473 | INFO     | src.policies:train:109 - Episode 827\n",
      "2021-08-25 10:46:26.481 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:26.482 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:26.482 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.61\n",
      "2021-08-25 10:46:26.483 | INFO     | src.policies:train:109 - Episode 828\n",
      "2021-08-25 10:46:26.491 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:26.492 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 10:46:26.493 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.58\n",
      "2021-08-25 10:46:26.494 | INFO     | src.policies:train:109 - Episode 829\n",
      "2021-08-25 10:46:26.503 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:26.504 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 10:46:26.504 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.62\n",
      "2021-08-25 10:46:26.505 | INFO     | src.policies:train:109 - Episode 830\n",
      "2021-08-25 10:46:26.518 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:26.519 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 10:46:26.520 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:26.521 | INFO     | src.policies:train:109 - Episode 831\n",
      "2021-08-25 10:46:26.528 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:26.529 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:26.530 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.46\n",
      "2021-08-25 10:46:26.531 | WARNING  | src.policies:train:131 - The actual batch size is 213, instead of 200\n",
      "2021-08-25 10:46:26.537 | INFO     | src.policies:train:157 - Total loss: 168.76844787597656\n",
      "2021-08-25 10:46:26.538 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:26.541 | INFO     | src.policies:train:103 - Epoch 99 / 800\n",
      "2021-08-25 10:46:26.542 | INFO     | src.policies:train:109 - Episode 832\n",
      "2021-08-25 10:46:26.550 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:26.552 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:26.553 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.48\n",
      "2021-08-25 10:46:26.553 | INFO     | src.policies:train:109 - Episode 833\n",
      "2021-08-25 10:46:26.571 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:26.572 | INFO     | src.policies:train:121 - Mean episode return: 47.0\n",
      "2021-08-25 10:46:26.573 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.74\n",
      "2021-08-25 10:46:26.574 | INFO     | src.policies:train:109 - Episode 834\n",
      "2021-08-25 10:46:26.583 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:26.584 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 10:46:26.585 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.71\n",
      "2021-08-25 10:46:26.586 | INFO     | src.policies:train:109 - Episode 835\n",
      "2021-08-25 10:46:26.596 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:26.597 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:26.598 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.68\n",
      "2021-08-25 10:46:26.599 | INFO     | src.policies:train:109 - Episode 836\n",
      "2021-08-25 10:46:26.618 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:26.619 | INFO     | src.policies:train:121 - Mean episode return: 49.0\n",
      "2021-08-25 10:46:26.620 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.01\n",
      "2021-08-25 10:46:26.621 | INFO     | src.policies:train:109 - Episode 837\n",
      "2021-08-25 10:46:26.635 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:26.636 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 10:46:26.637 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.23\n",
      "2021-08-25 10:46:26.637 | INFO     | src.policies:train:109 - Episode 838\n",
      "2021-08-25 10:46:26.645 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:26.646 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:26.647 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.26\n",
      "2021-08-25 10:46:26.648 | INFO     | src.policies:train:109 - Episode 839\n",
      "2021-08-25 10:46:26.661 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:26.663 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 10:46:26.664 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.34\n",
      "2021-08-25 10:46:26.665 | WARNING  | src.policies:train:131 - The actual batch size is 228, instead of 200\n",
      "2021-08-25 10:46:26.673 | INFO     | src.policies:train:157 - Total loss: 206.0898895263672\n",
      "2021-08-25 10:46:26.674 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:26.677 | INFO     | src.policies:train:103 - Epoch 100 / 800\n",
      "2021-08-25 10:46:26.678 | INFO     | src.policies:train:109 - Episode 840\n",
      "2021-08-25 10:46:26.693 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:26.695 | INFO     | src.policies:train:121 - Mean episode return: 39.0\n",
      "2021-08-25 10:46:26.696 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.46\n",
      "2021-08-25 10:46:26.696 | INFO     | src.policies:train:109 - Episode 841\n",
      "2021-08-25 10:46:26.704 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:26.705 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:26.706 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.03\n",
      "2021-08-25 10:46:26.707 | INFO     | src.policies:train:109 - Episode 842\n",
      "2021-08-25 10:46:26.727 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:26.728 | INFO     | src.policies:train:121 - Mean episode return: 53.0\n",
      "2021-08-25 10:46:26.729 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.42\n",
      "2021-08-25 10:46:26.730 | INFO     | src.policies:train:109 - Episode 843\n",
      "2021-08-25 10:46:26.753 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:26.754 | INFO     | src.policies:train:121 - Mean episode return: 62.0\n",
      "2021-08-25 10:46:26.754 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.91\n",
      "2021-08-25 10:46:26.755 | INFO     | src.policies:train:109 - Episode 844\n",
      "2021-08-25 10:46:26.764 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:26.765 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:26.766 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.81\n",
      "2021-08-25 10:46:26.766 | INFO     | src.policies:train:109 - Episode 845\n",
      "2021-08-25 10:46:26.786 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:26.787 | INFO     | src.policies:train:121 - Mean episode return: 50.0\n",
      "2021-08-25 10:46:26.788 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.19\n",
      "2021-08-25 10:46:26.789 | WARNING  | src.policies:train:131 - The actual batch size is 239, instead of 200\n",
      "2021-08-25 10:46:26.795 | INFO     | src.policies:train:157 - Total loss: 343.21514892578125\n",
      "2021-08-25 10:46:26.795 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:26.798 | INFO     | src.policies:train:103 - Epoch 101 / 800\n",
      "2021-08-25 10:46:26.800 | INFO     | src.policies:train:109 - Episode 846\n",
      "2021-08-25 10:46:26.808 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:26.809 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:26.810 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.18\n",
      "2021-08-25 10:46:26.811 | INFO     | src.policies:train:109 - Episode 847\n",
      "2021-08-25 10:46:26.826 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:26.827 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 10:46:26.828 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.62\n",
      "2021-08-25 10:46:26.829 | INFO     | src.policies:train:109 - Episode 848\n",
      "2021-08-25 10:46:26.842 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:26.843 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 10:46:26.843 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.6\n",
      "2021-08-25 10:46:26.844 | INFO     | src.policies:train:109 - Episode 849\n",
      "2021-08-25 10:46:26.853 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:26.854 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:26.855 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.48\n",
      "2021-08-25 10:46:26.856 | INFO     | src.policies:train:109 - Episode 850\n",
      "2021-08-25 10:46:26.864 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:26.865 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:26.866 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.53\n",
      "2021-08-25 10:46:26.866 | INFO     | src.policies:train:109 - Episode 851\n",
      "2021-08-25 10:46:26.877 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:26.878 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 10:46:26.879 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.16\n",
      "2021-08-25 10:46:26.880 | INFO     | src.policies:train:109 - Episode 852\n",
      "2021-08-25 10:46:26.891 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:26.892 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 10:46:26.893 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.96\n",
      "2021-08-25 10:46:26.894 | INFO     | src.policies:train:109 - Episode 853\n",
      "2021-08-25 10:46:26.909 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:26.910 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 10:46:26.911 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.77\n",
      "2021-08-25 10:46:26.912 | INFO     | src.policies:train:109 - Episode 854\n",
      "2021-08-25 10:46:26.929 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:26.930 | INFO     | src.policies:train:121 - Mean episode return: 44.0\n",
      "2021-08-25 10:46:26.931 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.07\n",
      "2021-08-25 10:46:26.932 | WARNING  | src.policies:train:131 - The actual batch size is 242, instead of 200\n",
      "2021-08-25 10:46:26.939 | INFO     | src.policies:train:157 - Total loss: 154.72549438476562\n",
      "2021-08-25 10:46:26.940 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:26.942 | INFO     | src.policies:train:103 - Epoch 102 / 800\n",
      "2021-08-25 10:46:26.943 | INFO     | src.policies:train:109 - Episode 855\n",
      "2021-08-25 10:46:26.951 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:26.952 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:26.953 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.98\n",
      "2021-08-25 10:46:26.954 | INFO     | src.policies:train:109 - Episode 856\n",
      "2021-08-25 10:46:26.966 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:26.967 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 10:46:26.968 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.0\n",
      "2021-08-25 10:46:26.968 | INFO     | src.policies:train:109 - Episode 857\n",
      "2021-08-25 10:46:27.010 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:27.011 | INFO     | src.policies:train:121 - Mean episode return: 125.0\n",
      "2021-08-25 10:46:27.012 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.07\n",
      "2021-08-25 10:46:27.013 | INFO     | src.policies:train:109 - Episode 858\n",
      "2021-08-25 10:46:27.020 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:27.021 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:27.022 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.97\n",
      "2021-08-25 10:46:27.023 | INFO     | src.policies:train:109 - Episode 859\n",
      "2021-08-25 10:46:27.038 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:27.039 | INFO     | src.policies:train:121 - Mean episode return: 42.0\n",
      "2021-08-25 10:46:27.040 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.27\n",
      "2021-08-25 10:46:27.041 | WARNING  | src.policies:train:131 - The actual batch size is 218, instead of 200\n",
      "2021-08-25 10:46:27.047 | INFO     | src.policies:train:157 - Total loss: 667.0829467773438\n",
      "2021-08-25 10:46:27.048 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:27.050 | INFO     | src.policies:train:103 - Epoch 103 / 800\n",
      "2021-08-25 10:46:27.051 | INFO     | src.policies:train:109 - Episode 860\n",
      "2021-08-25 10:46:27.058 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:27.059 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:27.060 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.23\n",
      "2021-08-25 10:46:27.060 | INFO     | src.policies:train:109 - Episode 861\n",
      "2021-08-25 10:46:27.076 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:27.077 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 10:46:27.078 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.25\n",
      "2021-08-25 10:46:27.079 | INFO     | src.policies:train:109 - Episode 862\n",
      "2021-08-25 10:46:27.090 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:27.091 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 10:46:27.092 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.15\n",
      "2021-08-25 10:46:27.093 | INFO     | src.policies:train:109 - Episode 863\n",
      "2021-08-25 10:46:27.104 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:27.105 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 10:46:27.106 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.24\n",
      "2021-08-25 10:46:27.106 | INFO     | src.policies:train:109 - Episode 864\n",
      "2021-08-25 10:46:27.123 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:27.124 | INFO     | src.policies:train:121 - Mean episode return: 41.0\n",
      "2021-08-25 10:46:27.125 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.39\n",
      "2021-08-25 10:46:27.126 | INFO     | src.policies:train:109 - Episode 865\n",
      "2021-08-25 10:46:27.136 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:27.137 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:27.138 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.03\n",
      "2021-08-25 10:46:27.139 | INFO     | src.policies:train:109 - Episode 866\n",
      "2021-08-25 10:46:27.146 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:27.147 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:27.147 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.73\n",
      "2021-08-25 10:46:27.148 | INFO     | src.policies:train:109 - Episode 867\n",
      "2021-08-25 10:46:27.166 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:27.167 | INFO     | src.policies:train:121 - Mean episode return: 44.0\n",
      "2021-08-25 10:46:27.167 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.02\n",
      "2021-08-25 10:46:27.168 | WARNING  | src.policies:train:131 - The actual batch size is 209, instead of 200\n",
      "2021-08-25 10:46:27.175 | INFO     | src.policies:train:157 - Total loss: 171.31581115722656\n",
      "2021-08-25 10:46:27.175 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:27.178 | INFO     | src.policies:train:103 - Epoch 104 / 800\n",
      "2021-08-25 10:46:27.179 | INFO     | src.policies:train:109 - Episode 868\n",
      "2021-08-25 10:46:27.189 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:27.191 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 10:46:27.191 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.89\n",
      "2021-08-25 10:46:27.192 | INFO     | src.policies:train:109 - Episode 869\n",
      "2021-08-25 10:46:27.205 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:27.206 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 10:46:27.206 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.95\n",
      "2021-08-25 10:46:27.207 | INFO     | src.policies:train:109 - Episode 870\n",
      "2021-08-25 10:46:27.214 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:27.215 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 10:46:27.216 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.89\n",
      "2021-08-25 10:46:27.217 | INFO     | src.policies:train:109 - Episode 871\n",
      "2021-08-25 10:46:27.224 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:27.225 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:27.226 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.89\n",
      "2021-08-25 10:46:27.226 | INFO     | src.policies:train:109 - Episode 872\n",
      "2021-08-25 10:46:27.244 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:27.245 | INFO     | src.policies:train:121 - Mean episode return: 47.0\n",
      "2021-08-25 10:46:27.246 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.04\n",
      "2021-08-25 10:46:27.247 | INFO     | src.policies:train:109 - Episode 873\n",
      "2021-08-25 10:46:27.264 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:27.265 | INFO     | src.policies:train:121 - Mean episode return: 43.0\n",
      "2021-08-25 10:46:27.266 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.28\n",
      "2021-08-25 10:46:27.267 | INFO     | src.policies:train:109 - Episode 874\n",
      "2021-08-25 10:46:27.276 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:27.277 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:27.277 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.12\n",
      "2021-08-25 10:46:27.278 | INFO     | src.policies:train:109 - Episode 875\n",
      "2021-08-25 10:46:27.293 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:27.294 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 10:46:27.295 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.06\n",
      "2021-08-25 10:46:27.296 | WARNING  | src.policies:train:131 - The actual batch size is 227, instead of 200\n",
      "2021-08-25 10:46:27.302 | INFO     | src.policies:train:157 - Total loss: 195.89971923828125\n",
      "2021-08-25 10:46:27.302 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:27.305 | INFO     | src.policies:train:103 - Epoch 105 / 800\n",
      "2021-08-25 10:46:27.306 | INFO     | src.policies:train:109 - Episode 876\n",
      "2021-08-25 10:46:27.329 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:27.331 | INFO     | src.policies:train:121 - Mean episode return: 66.0\n",
      "2021-08-25 10:46:27.331 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.38\n",
      "2021-08-25 10:46:27.332 | INFO     | src.policies:train:109 - Episode 877\n",
      "2021-08-25 10:46:27.354 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:27.355 | INFO     | src.policies:train:121 - Mean episode return: 57.0\n",
      "2021-08-25 10:46:27.356 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.63\n",
      "2021-08-25 10:46:27.357 | INFO     | src.policies:train:109 - Episode 878\n",
      "2021-08-25 10:46:27.367 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:27.368 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:27.370 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.57\n",
      "2021-08-25 10:46:27.371 | INFO     | src.policies:train:109 - Episode 879\n",
      "2021-08-25 10:46:27.380 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:27.382 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 10:46:27.383 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.63\n",
      "2021-08-25 10:46:27.384 | INFO     | src.policies:train:109 - Episode 880\n",
      "2021-08-25 10:46:27.396 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:27.398 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 10:46:27.399 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.72\n",
      "2021-08-25 10:46:27.399 | INFO     | src.policies:train:109 - Episode 881\n",
      "2021-08-25 10:46:27.419 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:27.420 | INFO     | src.policies:train:121 - Mean episode return: 47.0\n",
      "2021-08-25 10:46:27.421 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.51\n",
      "2021-08-25 10:46:27.422 | WARNING  | src.policies:train:131 - The actual batch size is 223, instead of 200\n",
      "2021-08-25 10:46:27.430 | INFO     | src.policies:train:157 - Total loss: 352.9066162109375\n",
      "2021-08-25 10:46:27.431 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:27.434 | INFO     | src.policies:train:103 - Epoch 106 / 800\n",
      "2021-08-25 10:46:27.435 | INFO     | src.policies:train:109 - Episode 882\n",
      "2021-08-25 10:46:27.463 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:27.465 | INFO     | src.policies:train:121 - Mean episode return: 76.0\n",
      "2021-08-25 10:46:27.465 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.02\n",
      "2021-08-25 10:46:27.466 | INFO     | src.policies:train:109 - Episode 883\n",
      "2021-08-25 10:46:27.479 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:27.481 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 10:46:27.482 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.11\n",
      "2021-08-25 10:46:27.483 | INFO     | src.policies:train:109 - Episode 884\n",
      "2021-08-25 10:46:27.500 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:27.501 | INFO     | src.policies:train:121 - Mean episode return: 38.0\n",
      "2021-08-25 10:46:27.502 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.91\n",
      "2021-08-25 10:46:27.504 | INFO     | src.policies:train:109 - Episode 885\n",
      "2021-08-25 10:46:27.522 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:27.523 | INFO     | src.policies:train:121 - Mean episode return: 42.0\n",
      "2021-08-25 10:46:27.524 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.82\n",
      "2021-08-25 10:46:27.525 | INFO     | src.policies:train:109 - Episode 886\n",
      "2021-08-25 10:46:27.535 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:27.537 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:27.537 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.79\n",
      "2021-08-25 10:46:27.538 | INFO     | src.policies:train:109 - Episode 887\n",
      "2021-08-25 10:46:27.546 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:27.548 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:27.549 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.45\n",
      "2021-08-25 10:46:27.550 | WARNING  | src.policies:train:131 - The actual batch size is 205, instead of 200\n",
      "2021-08-25 10:46:27.557 | INFO     | src.policies:train:157 - Total loss: 345.60662841796875\n",
      "2021-08-25 10:46:27.558 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:27.560 | INFO     | src.policies:train:103 - Epoch 107 / 800\n",
      "2021-08-25 10:46:27.561 | INFO     | src.policies:train:109 - Episode 888\n",
      "2021-08-25 10:46:27.578 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:27.579 | INFO     | src.policies:train:121 - Mean episode return: 44.0\n",
      "2021-08-25 10:46:27.580 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.3\n",
      "2021-08-25 10:46:27.581 | INFO     | src.policies:train:109 - Episode 889\n",
      "2021-08-25 10:46:27.591 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:27.593 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:27.594 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.24\n",
      "2021-08-25 10:46:27.595 | INFO     | src.policies:train:109 - Episode 890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:27.604 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:27.605 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:27.606 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.17\n",
      "2021-08-25 10:46:27.607 | INFO     | src.policies:train:109 - Episode 891\n",
      "2021-08-25 10:46:27.633 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:27.635 | INFO     | src.policies:train:121 - Mean episode return: 60.0\n",
      "2021-08-25 10:46:27.636 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.57\n",
      "2021-08-25 10:46:27.637 | INFO     | src.policies:train:109 - Episode 892\n",
      "2021-08-25 10:46:27.645 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:27.646 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 10:46:27.647 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.23\n",
      "2021-08-25 10:46:27.649 | INFO     | src.policies:train:109 - Episode 893\n",
      "2021-08-25 10:46:27.663 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:27.665 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 10:46:27.666 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.25\n",
      "2021-08-25 10:46:27.668 | INFO     | src.policies:train:109 - Episode 894\n",
      "2021-08-25 10:46:27.677 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:27.679 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:27.680 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.04\n",
      "2021-08-25 10:46:27.681 | INFO     | src.policies:train:109 - Episode 895\n",
      "2021-08-25 10:46:27.695 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:27.697 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 10:46:27.697 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.99\n",
      "2021-08-25 10:46:27.698 | WARNING  | src.policies:train:131 - The actual batch size is 225, instead of 200\n",
      "2021-08-25 10:46:27.706 | INFO     | src.policies:train:157 - Total loss: 229.7721405029297\n",
      "2021-08-25 10:46:27.706 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:27.710 | INFO     | src.policies:train:103 - Epoch 108 / 800\n",
      "2021-08-25 10:46:27.712 | INFO     | src.policies:train:109 - Episode 896\n",
      "2021-08-25 10:46:27.725 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:27.727 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 10:46:27.728 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.18\n",
      "2021-08-25 10:46:27.729 | INFO     | src.policies:train:109 - Episode 897\n",
      "2021-08-25 10:46:27.740 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:27.741 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 10:46:27.742 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.01\n",
      "2021-08-25 10:46:27.743 | INFO     | src.policies:train:109 - Episode 898\n",
      "2021-08-25 10:46:27.758 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:27.760 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 10:46:27.761 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.62\n",
      "2021-08-25 10:46:27.761 | INFO     | src.policies:train:109 - Episode 899\n",
      "2021-08-25 10:46:27.804 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:27.805 | INFO     | src.policies:train:121 - Mean episode return: 117.0\n",
      "2021-08-25 10:46:27.806 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.62\n",
      "2021-08-25 10:46:27.807 | WARNING  | src.policies:train:131 - The actual batch size is 203, instead of 200\n",
      "2021-08-25 10:46:27.811 | INFO     | src.policies:train:157 - Total loss: 632.1939086914062\n",
      "2021-08-25 10:46:27.812 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:27.815 | INFO     | src.policies:train:103 - Epoch 109 / 800\n",
      "2021-08-25 10:46:27.816 | INFO     | src.policies:train:109 - Episode 900\n",
      "2021-08-25 10:46:27.827 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:27.829 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 10:46:27.830 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.43\n",
      "2021-08-25 10:46:27.831 | INFO     | src.policies:train:109 - Episode 901\n",
      "2021-08-25 10:46:27.842 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:27.843 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:27.844 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.31\n",
      "2021-08-25 10:46:27.845 | INFO     | src.policies:train:109 - Episode 902\n",
      "2021-08-25 10:46:27.863 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:27.864 | INFO     | src.policies:train:121 - Mean episode return: 44.0\n",
      "2021-08-25 10:46:27.866 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.63\n",
      "2021-08-25 10:46:27.867 | INFO     | src.policies:train:109 - Episode 903\n",
      "2021-08-25 10:46:27.882 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:27.884 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 10:46:27.884 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.34\n",
      "2021-08-25 10:46:27.886 | INFO     | src.policies:train:109 - Episode 904\n",
      "2021-08-25 10:46:27.898 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:27.900 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 10:46:27.900 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.33\n",
      "2021-08-25 10:46:27.901 | INFO     | src.policies:train:109 - Episode 905\n",
      "2021-08-25 10:46:27.916 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:27.917 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 10:46:27.918 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.3\n",
      "2021-08-25 10:46:27.919 | INFO     | src.policies:train:109 - Episode 906\n",
      "2021-08-25 10:46:27.939 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:27.940 | INFO     | src.policies:train:121 - Mean episode return: 50.0\n",
      "2021-08-25 10:46:27.941 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.51\n",
      "2021-08-25 10:46:27.942 | WARNING  | src.policies:train:131 - The actual batch size is 224, instead of 200\n",
      "2021-08-25 10:46:27.950 | INFO     | src.policies:train:157 - Total loss: 193.22581481933594\n",
      "2021-08-25 10:46:27.952 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:27.955 | INFO     | src.policies:train:103 - Epoch 110 / 800\n",
      "2021-08-25 10:46:27.956 | INFO     | src.policies:train:109 - Episode 907\n",
      "2021-08-25 10:46:27.971 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:27.973 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 10:46:27.974 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.76\n",
      "2021-08-25 10:46:27.974 | INFO     | src.policies:train:109 - Episode 908\n",
      "2021-08-25 10:46:27.988 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:27.989 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 10:46:27.990 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.65\n",
      "2021-08-25 10:46:27.991 | INFO     | src.policies:train:109 - Episode 909\n",
      "2021-08-25 10:46:28.004 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:28.005 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:28.006 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.6\n",
      "2021-08-25 10:46:28.007 | INFO     | src.policies:train:109 - Episode 910\n",
      "2021-08-25 10:46:28.022 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:28.023 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 10:46:28.025 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.58\n",
      "2021-08-25 10:46:28.026 | INFO     | src.policies:train:109 - Episode 911\n",
      "2021-08-25 10:46:28.048 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:28.049 | INFO     | src.policies:train:121 - Mean episode return: 54.0\n",
      "2021-08-25 10:46:28.050 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.93\n",
      "2021-08-25 10:46:28.050 | INFO     | src.policies:train:109 - Episode 912\n",
      "2021-08-25 10:46:28.071 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:28.072 | INFO     | src.policies:train:121 - Mean episode return: 49.0\n",
      "2021-08-25 10:46:28.073 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.17\n",
      "2021-08-25 10:46:28.074 | WARNING  | src.policies:train:131 - The actual batch size is 224, instead of 200\n",
      "2021-08-25 10:46:28.081 | INFO     | src.policies:train:157 - Total loss: 246.82798767089844\n",
      "2021-08-25 10:46:28.081 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:28.085 | INFO     | src.policies:train:103 - Epoch 111 / 800\n",
      "2021-08-25 10:46:28.086 | INFO     | src.policies:train:109 - Episode 913\n",
      "2021-08-25 10:46:28.101 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:28.103 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 10:46:28.104 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.42\n",
      "2021-08-25 10:46:28.105 | INFO     | src.policies:train:109 - Episode 914\n",
      "2021-08-25 10:46:28.117 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:28.118 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 10:46:28.119 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.53\n",
      "2021-08-25 10:46:28.120 | INFO     | src.policies:train:109 - Episode 915\n",
      "2021-08-25 10:46:28.133 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:28.135 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 10:46:28.135 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.33\n",
      "2021-08-25 10:46:28.136 | INFO     | src.policies:train:109 - Episode 916\n",
      "2021-08-25 10:46:28.147 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:28.148 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:28.149 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.31\n",
      "2021-08-25 10:46:28.150 | INFO     | src.policies:train:109 - Episode 917\n",
      "2021-08-25 10:46:28.160 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:28.161 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:28.162 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.34\n",
      "2021-08-25 10:46:28.163 | INFO     | src.policies:train:109 - Episode 918\n",
      "2021-08-25 10:46:28.172 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:28.174 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:28.174 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.32\n",
      "2021-08-25 10:46:28.175 | INFO     | src.policies:train:109 - Episode 919\n",
      "2021-08-25 10:46:28.185 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:28.186 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:28.186 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.34\n",
      "2021-08-25 10:46:28.187 | INFO     | src.policies:train:109 - Episode 920\n",
      "2021-08-25 10:46:28.197 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:28.198 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:28.199 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.97\n",
      "2021-08-25 10:46:28.200 | INFO     | src.policies:train:109 - Episode 921\n",
      "2021-08-25 10:46:28.214 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:28.215 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 10:46:28.216 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.0\n",
      "2021-08-25 10:46:28.217 | INFO     | src.policies:train:109 - Episode 922\n",
      "2021-08-25 10:46:28.240 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:28.241 | INFO     | src.policies:train:121 - Mean episode return: 57.0\n",
      "2021-08-25 10:46:28.242 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.26\n",
      "2021-08-25 10:46:28.243 | WARNING  | src.policies:train:131 - The actual batch size is 246, instead of 200\n",
      "2021-08-25 10:46:28.252 | INFO     | src.policies:train:157 - Total loss: 168.24024963378906\n",
      "2021-08-25 10:46:28.253 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:28.257 | INFO     | src.policies:train:103 - Epoch 112 / 800\n",
      "2021-08-25 10:46:28.258 | INFO     | src.policies:train:109 - Episode 923\n",
      "2021-08-25 10:46:28.275 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:28.277 | INFO     | src.policies:train:121 - Mean episode return: 47.0\n",
      "2021-08-25 10:46:28.277 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.51\n",
      "2021-08-25 10:46:28.278 | INFO     | src.policies:train:109 - Episode 924\n",
      "2021-08-25 10:46:28.291 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:28.292 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 10:46:28.293 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.71\n",
      "2021-08-25 10:46:28.294 | INFO     | src.policies:train:109 - Episode 925\n",
      "2021-08-25 10:46:28.312 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:28.313 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 10:46:28.314 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.55\n",
      "2021-08-25 10:46:28.315 | INFO     | src.policies:train:109 - Episode 926\n",
      "2021-08-25 10:46:28.325 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:28.326 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:28.327 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.4\n",
      "2021-08-25 10:46:28.328 | INFO     | src.policies:train:109 - Episode 927\n",
      "2021-08-25 10:46:28.347 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:28.348 | INFO     | src.policies:train:121 - Mean episode return: 42.0\n",
      "2021-08-25 10:46:28.349 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.67\n",
      "2021-08-25 10:46:28.350 | INFO     | src.policies:train:109 - Episode 928\n",
      "2021-08-25 10:46:28.361 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:28.362 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 10:46:28.363 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.7\n",
      "2021-08-25 10:46:28.364 | INFO     | src.policies:train:109 - Episode 929\n",
      "2021-08-25 10:46:28.376 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:28.377 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 10:46:28.378 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.67\n",
      "2021-08-25 10:46:28.379 | WARNING  | src.policies:train:131 - The actual batch size is 209, instead of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:28.386 | INFO     | src.policies:train:157 - Total loss: 187.78887939453125\n",
      "2021-08-25 10:46:28.387 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:28.390 | INFO     | src.policies:train:103 - Epoch 113 / 800\n",
      "2021-08-25 10:46:28.392 | INFO     | src.policies:train:109 - Episode 930\n",
      "2021-08-25 10:46:28.408 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:28.409 | INFO     | src.policies:train:121 - Mean episode return: 39.0\n",
      "2021-08-25 10:46:28.410 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.75\n",
      "2021-08-25 10:46:28.411 | INFO     | src.policies:train:109 - Episode 931\n",
      "2021-08-25 10:46:28.430 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:28.431 | INFO     | src.policies:train:121 - Mean episode return: 43.0\n",
      "2021-08-25 10:46:28.432 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.04\n",
      "2021-08-25 10:46:28.433 | INFO     | src.policies:train:109 - Episode 932\n",
      "2021-08-25 10:46:28.442 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:28.443 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:28.445 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.01\n",
      "2021-08-25 10:46:28.446 | INFO     | src.policies:train:109 - Episode 933\n",
      "2021-08-25 10:46:28.477 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:28.478 | INFO     | src.policies:train:121 - Mean episode return: 82.0\n",
      "2021-08-25 10:46:28.479 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.36\n",
      "2021-08-25 10:46:28.480 | INFO     | src.policies:train:109 - Episode 934\n",
      "2021-08-25 10:46:28.489 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:28.491 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:28.491 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.31\n",
      "2021-08-25 10:46:28.493 | INFO     | src.policies:train:109 - Episode 935\n",
      "2021-08-25 10:46:28.507 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:28.508 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 10:46:28.509 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.44\n",
      "2021-08-25 10:46:28.510 | WARNING  | src.policies:train:131 - The actual batch size is 226, instead of 200\n",
      "2021-08-25 10:46:28.516 | INFO     | src.policies:train:157 - Total loss: 361.0471496582031\n",
      "2021-08-25 10:46:28.516 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:28.520 | INFO     | src.policies:train:103 - Epoch 114 / 800\n",
      "2021-08-25 10:46:28.521 | INFO     | src.policies:train:109 - Episode 936\n",
      "2021-08-25 10:46:28.532 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:28.534 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 10:46:28.535 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.23\n",
      "2021-08-25 10:46:28.536 | INFO     | src.policies:train:109 - Episode 937\n",
      "2021-08-25 10:46:28.547 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:28.548 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 10:46:28.549 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.12\n",
      "2021-08-25 10:46:28.550 | INFO     | src.policies:train:109 - Episode 938\n",
      "2021-08-25 10:46:28.558 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:28.559 | INFO     | src.policies:train:121 - Mean episode return: 9.0\n",
      "2021-08-25 10:46:28.560 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.09\n",
      "2021-08-25 10:46:28.561 | INFO     | src.policies:train:109 - Episode 939\n",
      "2021-08-25 10:46:28.578 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:28.579 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 10:46:28.580 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.15\n",
      "2021-08-25 10:46:28.581 | INFO     | src.policies:train:109 - Episode 940\n",
      "2021-08-25 10:46:28.598 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:28.599 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 10:46:28.600 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.09\n",
      "2021-08-25 10:46:28.601 | INFO     | src.policies:train:109 - Episode 941\n",
      "2021-08-25 10:46:28.622 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:28.624 | INFO     | src.policies:train:121 - Mean episode return: 53.0\n",
      "2021-08-25 10:46:28.625 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.46\n",
      "2021-08-25 10:46:28.626 | INFO     | src.policies:train:109 - Episode 942\n",
      "2021-08-25 10:46:28.646 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:28.647 | INFO     | src.policies:train:121 - Mean episode return: 43.0\n",
      "2021-08-25 10:46:28.648 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.36\n",
      "2021-08-25 10:46:28.649 | WARNING  | src.policies:train:131 - The actual batch size is 224, instead of 200\n",
      "2021-08-25 10:46:28.656 | INFO     | src.policies:train:157 - Total loss: 211.1699981689453\n",
      "2021-08-25 10:46:28.657 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:28.660 | INFO     | src.policies:train:103 - Epoch 115 / 800\n",
      "2021-08-25 10:46:28.661 | INFO     | src.policies:train:109 - Episode 943\n",
      "2021-08-25 10:46:28.670 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:28.671 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:28.673 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.92\n",
      "2021-08-25 10:46:28.674 | INFO     | src.policies:train:109 - Episode 944\n",
      "2021-08-25 10:46:28.692 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:28.693 | INFO     | src.policies:train:121 - Mean episode return: 42.0\n",
      "2021-08-25 10:46:28.694 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.15\n",
      "2021-08-25 10:46:28.695 | INFO     | src.policies:train:109 - Episode 945\n",
      "2021-08-25 10:46:28.704 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:28.705 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:28.706 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.77\n",
      "2021-08-25 10:46:28.707 | INFO     | src.policies:train:109 - Episode 946\n",
      "2021-08-25 10:46:28.726 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:28.727 | INFO     | src.policies:train:121 - Mean episode return: 39.0\n",
      "2021-08-25 10:46:28.728 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.97\n",
      "2021-08-25 10:46:28.729 | INFO     | src.policies:train:109 - Episode 947\n",
      "2021-08-25 10:46:28.738 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:28.740 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:28.740 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.73\n",
      "2021-08-25 10:46:28.741 | INFO     | src.policies:train:109 - Episode 948\n",
      "2021-08-25 10:46:28.748 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:28.750 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:28.751 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.56\n",
      "2021-08-25 10:46:28.751 | INFO     | src.policies:train:109 - Episode 949\n",
      "2021-08-25 10:46:28.766 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:28.767 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 10:46:28.768 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:28.768 | INFO     | src.policies:train:109 - Episode 950\n",
      "2021-08-25 10:46:28.781 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:28.783 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 10:46:28.783 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.85\n",
      "2021-08-25 10:46:28.784 | INFO     | src.policies:train:109 - Episode 951\n",
      "2021-08-25 10:46:28.793 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:28.794 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:28.795 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.76\n",
      "2021-08-25 10:46:28.795 | WARNING  | src.policies:train:131 - The actual batch size is 215, instead of 200\n",
      "2021-08-25 10:46:28.801 | INFO     | src.policies:train:157 - Total loss: 137.84075927734375\n",
      "2021-08-25 10:46:28.802 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:28.805 | INFO     | src.policies:train:103 - Epoch 116 / 800\n",
      "2021-08-25 10:46:28.806 | INFO     | src.policies:train:109 - Episode 952\n",
      "2021-08-25 10:46:28.817 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:28.818 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 10:46:28.818 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.78\n",
      "2021-08-25 10:46:28.819 | INFO     | src.policies:train:109 - Episode 953\n",
      "2021-08-25 10:46:28.828 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:28.829 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:28.829 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.63\n",
      "2021-08-25 10:46:28.830 | INFO     | src.policies:train:109 - Episode 954\n",
      "2021-08-25 10:46:28.839 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:28.840 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:28.840 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.35\n",
      "2021-08-25 10:46:28.841 | INFO     | src.policies:train:109 - Episode 955\n",
      "2021-08-25 10:46:28.889 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:28.891 | INFO     | src.policies:train:121 - Mean episode return: 140.0\n",
      "2021-08-25 10:46:28.891 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.61\n",
      "2021-08-25 10:46:28.892 | INFO     | src.policies:train:109 - Episode 956\n",
      "2021-08-25 10:46:28.905 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:28.906 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 10:46:28.907 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.67\n",
      "2021-08-25 10:46:28.909 | WARNING  | src.policies:train:131 - The actual batch size is 227, instead of 200\n",
      "2021-08-25 10:46:28.914 | INFO     | src.policies:train:157 - Total loss: 702.1510009765625\n",
      "2021-08-25 10:46:28.915 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:28.918 | INFO     | src.policies:train:103 - Epoch 117 / 800\n",
      "2021-08-25 10:46:28.919 | INFO     | src.policies:train:109 - Episode 957\n",
      "2021-08-25 10:46:28.925 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:28.926 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:28.927 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.55\n",
      "2021-08-25 10:46:28.928 | INFO     | src.policies:train:109 - Episode 958\n",
      "2021-08-25 10:46:28.955 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:28.956 | INFO     | src.policies:train:121 - Mean episode return: 71.0\n",
      "2021-08-25 10:46:28.956 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.13\n",
      "2021-08-25 10:46:28.957 | INFO     | src.policies:train:109 - Episode 959\n",
      "2021-08-25 10:46:28.977 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:28.978 | INFO     | src.policies:train:121 - Mean episode return: 51.0\n",
      "2021-08-25 10:46:28.979 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.22\n",
      "2021-08-25 10:46:28.980 | INFO     | src.policies:train:109 - Episode 960\n",
      "2021-08-25 10:46:29.015 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:29.016 | INFO     | src.policies:train:121 - Mean episode return: 96.0\n",
      "2021-08-25 10:46:29.016 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.05\n",
      "2021-08-25 10:46:29.017 | WARNING  | src.policies:train:131 - The actual batch size is 231, instead of 200\n",
      "2021-08-25 10:46:29.023 | INFO     | src.policies:train:157 - Total loss: 567.8045654296875\n",
      "2021-08-25 10:46:29.023 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:29.026 | INFO     | src.policies:train:103 - Epoch 118 / 800\n",
      "2021-08-25 10:46:29.027 | INFO     | src.policies:train:109 - Episode 961\n",
      "2021-08-25 10:46:29.039 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:29.040 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 10:46:29.041 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.01\n",
      "2021-08-25 10:46:29.042 | INFO     | src.policies:train:109 - Episode 962\n",
      "2021-08-25 10:46:29.057 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:29.058 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 10:46:29.059 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.14\n",
      "2021-08-25 10:46:29.060 | INFO     | src.policies:train:109 - Episode 963\n",
      "2021-08-25 10:46:29.070 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:29.071 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:29.071 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.06\n",
      "2021-08-25 10:46:29.073 | INFO     | src.policies:train:109 - Episode 964\n",
      "2021-08-25 10:46:29.086 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:29.087 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 10:46:29.088 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.94\n",
      "2021-08-25 10:46:29.089 | INFO     | src.policies:train:109 - Episode 965\n",
      "2021-08-25 10:46:29.104 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:29.105 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 10:46:29.106 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.09\n",
      "2021-08-25 10:46:29.107 | INFO     | src.policies:train:109 - Episode 966\n",
      "2021-08-25 10:46:29.118 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:29.119 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 10:46:29.120 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.2\n",
      "2021-08-25 10:46:29.121 | INFO     | src.policies:train:109 - Episode 967\n",
      "2021-08-25 10:46:29.137 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:29.138 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 10:46:29.139 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.13\n",
      "2021-08-25 10:46:29.140 | WARNING  | src.policies:train:131 - The actual batch size is 204, instead of 200\n",
      "2021-08-25 10:46:29.146 | INFO     | src.policies:train:157 - Total loss: 134.5924835205078\n",
      "2021-08-25 10:46:29.147 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:29.150 | INFO     | src.policies:train:103 - Epoch 119 / 800\n",
      "2021-08-25 10:46:29.151 | INFO     | src.policies:train:109 - Episode 968\n",
      "2021-08-25 10:46:29.164 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:29.165 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:29.165 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.2\n",
      "2021-08-25 10:46:29.166 | INFO     | src.policies:train:109 - Episode 969\n",
      "2021-08-25 10:46:29.177 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:29.178 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 10:46:29.179 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.1\n",
      "2021-08-25 10:46:29.180 | INFO     | src.policies:train:109 - Episode 970\n",
      "2021-08-25 10:46:29.189 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:29.191 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:29.191 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.19\n",
      "2021-08-25 10:46:29.192 | INFO     | src.policies:train:109 - Episode 971\n",
      "2021-08-25 10:46:29.204 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:29.205 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 10:46:29.206 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.32\n",
      "2021-08-25 10:46:29.207 | INFO     | src.policies:train:109 - Episode 972\n",
      "2021-08-25 10:46:29.223 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:29.224 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 10:46:29.225 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.25\n",
      "2021-08-25 10:46:29.226 | INFO     | src.policies:train:109 - Episode 973\n",
      "2021-08-25 10:46:29.245 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:29.246 | INFO     | src.policies:train:121 - Mean episode return: 45.0\n",
      "2021-08-25 10:46:29.247 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.27\n",
      "2021-08-25 10:46:29.248 | INFO     | src.policies:train:109 - Episode 974\n",
      "2021-08-25 10:46:29.263 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:29.264 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 10:46:29.266 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.45\n",
      "2021-08-25 10:46:29.267 | WARNING  | src.policies:train:131 - The actual batch size is 224, instead of 200\n",
      "2021-08-25 10:46:29.277 | INFO     | src.policies:train:157 - Total loss: 171.49954223632812\n",
      "2021-08-25 10:46:29.277 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:29.281 | INFO     | src.policies:train:103 - Epoch 120 / 800\n",
      "2021-08-25 10:46:29.282 | INFO     | src.policies:train:109 - Episode 975\n",
      "2021-08-25 10:46:29.297 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:29.298 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 10:46:29.299 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.47\n",
      "2021-08-25 10:46:29.300 | INFO     | src.policies:train:109 - Episode 976\n",
      "2021-08-25 10:46:29.311 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:29.312 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 10:46:29.313 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.05\n",
      "2021-08-25 10:46:29.314 | INFO     | src.policies:train:109 - Episode 977\n",
      "2021-08-25 10:46:29.330 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:29.331 | INFO     | src.policies:train:121 - Mean episode return: 38.0\n",
      "2021-08-25 10:46:29.332 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.86\n",
      "2021-08-25 10:46:29.333 | INFO     | src.policies:train:109 - Episode 978\n",
      "2021-08-25 10:46:29.340 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:29.341 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:29.342 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.85\n",
      "2021-08-25 10:46:29.343 | INFO     | src.policies:train:109 - Episode 979\n",
      "2021-08-25 10:46:29.351 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:29.352 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:29.353 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.82\n",
      "2021-08-25 10:46:29.354 | INFO     | src.policies:train:109 - Episode 980\n",
      "2021-08-25 10:46:29.365 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:29.366 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 10:46:29.367 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.85\n",
      "2021-08-25 10:46:29.367 | INFO     | src.policies:train:109 - Episode 981\n",
      "2021-08-25 10:46:29.375 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:29.376 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:29.376 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.5\n",
      "2021-08-25 10:46:29.377 | INFO     | src.policies:train:109 - Episode 982\n",
      "2021-08-25 10:46:29.403 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:29.404 | INFO     | src.policies:train:121 - Mean episode return: 71.0\n",
      "2021-08-25 10:46:29.404 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.45\n",
      "2021-08-25 10:46:29.405 | WARNING  | src.policies:train:131 - The actual batch size is 234, instead of 200\n",
      "2021-08-25 10:46:29.411 | INFO     | src.policies:train:157 - Total loss: 247.14559936523438\n",
      "2021-08-25 10:46:29.412 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:29.415 | INFO     | src.policies:train:103 - Epoch 121 / 800\n",
      "2021-08-25 10:46:29.416 | INFO     | src.policies:train:109 - Episode 983\n",
      "2021-08-25 10:46:29.422 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:29.423 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:29.424 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.35\n",
      "2021-08-25 10:46:29.425 | INFO     | src.policies:train:109 - Episode 984\n",
      "2021-08-25 10:46:29.437 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:29.438 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 10:46:29.438 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.25\n",
      "2021-08-25 10:46:29.439 | INFO     | src.policies:train:109 - Episode 985\n",
      "2021-08-25 10:46:29.463 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:29.465 | INFO     | src.policies:train:121 - Mean episode return: 63.0\n",
      "2021-08-25 10:46:29.465 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.46\n",
      "2021-08-25 10:46:29.466 | INFO     | src.policies:train:109 - Episode 986\n",
      "2021-08-25 10:46:29.477 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:29.478 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 10:46:29.479 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.55\n",
      "2021-08-25 10:46:29.480 | INFO     | src.policies:train:109 - Episode 987\n",
      "2021-08-25 10:46:29.486 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:29.487 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 10:46:29.488 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.54\n",
      "2021-08-25 10:46:29.489 | INFO     | src.policies:train:109 - Episode 988\n",
      "2021-08-25 10:46:29.505 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:29.507 | INFO     | src.policies:train:121 - Mean episode return: 41.0\n",
      "2021-08-25 10:46:29.507 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.51\n",
      "2021-08-25 10:46:29.508 | INFO     | src.policies:train:109 - Episode 989\n",
      "2021-08-25 10:46:29.521 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:29.522 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 10:46:29.523 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.61\n",
      "2021-08-25 10:46:29.524 | WARNING  | src.policies:train:131 - The actual batch size is 208, instead of 200\n",
      "2021-08-25 10:46:29.529 | INFO     | src.policies:train:157 - Total loss: 220.91995239257812\n",
      "2021-08-25 10:46:29.530 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:29.533 | INFO     | src.policies:train:103 - Epoch 122 / 800\n",
      "2021-08-25 10:46:29.534 | INFO     | src.policies:train:109 - Episode 990\n",
      "2021-08-25 10:46:29.551 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:29.552 | INFO     | src.policies:train:121 - Mean episode return: 44.0\n",
      "2021-08-25 10:46:29.553 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.9\n",
      "2021-08-25 10:46:29.554 | INFO     | src.policies:train:109 - Episode 991\n",
      "2021-08-25 10:46:29.563 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:29.564 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 10:46:29.565 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.5\n",
      "2021-08-25 10:46:29.566 | INFO     | src.policies:train:109 - Episode 992\n",
      "2021-08-25 10:46:29.583 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:29.584 | INFO     | src.policies:train:121 - Mean episode return: 43.0\n",
      "2021-08-25 10:46:29.585 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.83\n",
      "2021-08-25 10:46:29.586 | INFO     | src.policies:train:109 - Episode 993\n",
      "2021-08-25 10:46:29.600 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:29.601 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 10:46:29.602 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.82\n",
      "2021-08-25 10:46:29.603 | INFO     | src.policies:train:109 - Episode 994\n",
      "2021-08-25 10:46:29.615 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:29.616 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 10:46:29.617 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.93\n",
      "2021-08-25 10:46:29.618 | INFO     | src.policies:train:109 - Episode 995\n",
      "2021-08-25 10:46:29.637 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:29.638 | INFO     | src.policies:train:121 - Mean episode return: 48.0\n",
      "2021-08-25 10:46:29.639 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.1\n",
      "2021-08-25 10:46:29.640 | WARNING  | src.policies:train:131 - The actual batch size is 211, instead of 200\n",
      "2021-08-25 10:46:29.645 | INFO     | src.policies:train:157 - Total loss: 198.6011505126953\n",
      "2021-08-25 10:46:29.646 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:29.649 | INFO     | src.policies:train:103 - Epoch 123 / 800\n",
      "2021-08-25 10:46:29.651 | INFO     | src.policies:train:109 - Episode 996\n",
      "2021-08-25 10:46:29.656 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:29.657 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 10:46:29.658 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.86\n",
      "2021-08-25 10:46:29.659 | INFO     | src.policies:train:109 - Episode 997\n",
      "2021-08-25 10:46:29.675 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:29.676 | INFO     | src.policies:train:121 - Mean episode return: 38.0\n",
      "2021-08-25 10:46:29.677 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.07\n",
      "2021-08-25 10:46:29.678 | INFO     | src.policies:train:109 - Episode 998\n",
      "2021-08-25 10:46:29.691 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:29.692 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 10:46:29.693 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.05\n",
      "2021-08-25 10:46:29.694 | INFO     | src.policies:train:109 - Episode 999\n",
      "2021-08-25 10:46:29.711 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:29.712 | INFO     | src.policies:train:121 - Mean episode return: 42.0\n",
      "2021-08-25 10:46:29.713 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.3\n",
      "2021-08-25 10:46:29.714 | INFO     | src.policies:train:109 - Episode 1000\n",
      "2021-08-25 10:46:29.725 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:29.726 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 10:46:29.727 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.27\n",
      "2021-08-25 10:46:29.727 | INFO     | src.policies:train:109 - Episode 1001\n",
      "2021-08-25 10:46:29.736 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:29.737 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:29.738 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.24\n",
      "2021-08-25 10:46:29.739 | INFO     | src.policies:train:109 - Episode 1002\n",
      "2021-08-25 10:46:29.751 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:29.752 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 10:46:29.753 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.08\n",
      "2021-08-25 10:46:29.754 | INFO     | src.policies:train:109 - Episode 1003\n",
      "2021-08-25 10:46:29.766 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:29.767 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 10:46:29.767 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.03\n",
      "2021-08-25 10:46:29.768 | WARNING  | src.policies:train:131 - The actual batch size is 218, instead of 200\n",
      "2021-08-25 10:46:29.774 | INFO     | src.policies:train:157 - Total loss: 135.8285675048828\n",
      "2021-08-25 10:46:29.775 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:29.778 | INFO     | src.policies:train:103 - Epoch 124 / 800\n",
      "2021-08-25 10:46:29.779 | INFO     | src.policies:train:109 - Episode 1004\n",
      "2021-08-25 10:46:29.797 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:29.798 | INFO     | src.policies:train:121 - Mean episode return: 53.0\n",
      "2021-08-25 10:46:29.799 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.32\n",
      "2021-08-25 10:46:29.800 | INFO     | src.policies:train:109 - Episode 1005\n",
      "2021-08-25 10:46:29.810 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:29.811 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 10:46:29.812 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.26\n",
      "2021-08-25 10:46:29.813 | INFO     | src.policies:train:109 - Episode 1006\n",
      "2021-08-25 10:46:29.829 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:29.830 | INFO     | src.policies:train:121 - Mean episode return: 39.0\n",
      "2021-08-25 10:46:29.831 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.15\n",
      "2021-08-25 10:46:29.832 | INFO     | src.policies:train:109 - Episode 1007\n",
      "2021-08-25 10:46:29.848 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:29.849 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 10:46:29.849 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.16\n",
      "2021-08-25 10:46:29.850 | INFO     | src.policies:train:109 - Episode 1008\n",
      "2021-08-25 10:46:29.862 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:29.863 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 10:46:29.864 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:29.865 | INFO     | src.policies:train:109 - Episode 1009\n",
      "2021-08-25 10:46:29.873 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:29.874 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:29.875 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.02\n",
      "2021-08-25 10:46:29.876 | INFO     | src.policies:train:109 - Episode 1010\n",
      "2021-08-25 10:46:29.884 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:29.885 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:29.886 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.89\n",
      "2021-08-25 10:46:29.887 | WARNING  | src.policies:train:131 - The actual batch size is 209, instead of 200\n",
      "2021-08-25 10:46:29.893 | INFO     | src.policies:train:157 - Total loss: 180.14476013183594\n",
      "2021-08-25 10:46:29.893 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:29.896 | INFO     | src.policies:train:103 - Epoch 125 / 800\n",
      "2021-08-25 10:46:29.897 | INFO     | src.policies:train:109 - Episode 1011\n",
      "2021-08-25 10:46:29.903 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:29.904 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:29.905 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.47\n",
      "2021-08-25 10:46:29.906 | INFO     | src.policies:train:109 - Episode 1012\n",
      "2021-08-25 10:46:29.916 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:29.917 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:29.918 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.17\n",
      "2021-08-25 10:46:29.919 | INFO     | src.policies:train:109 - Episode 1013\n",
      "2021-08-25 10:46:29.933 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:29.934 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 10:46:29.935 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.18\n",
      "2021-08-25 10:46:29.936 | INFO     | src.policies:train:109 - Episode 1014\n",
      "2021-08-25 10:46:29.947 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:29.949 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 10:46:29.950 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.22\n",
      "2021-08-25 10:46:29.951 | INFO     | src.policies:train:109 - Episode 1015\n",
      "2021-08-25 10:46:29.961 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:29.962 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 10:46:29.963 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.18\n",
      "2021-08-25 10:46:29.964 | INFO     | src.policies:train:109 - Episode 1016\n",
      "2021-08-25 10:46:29.977 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:29.978 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 10:46:29.979 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.27\n",
      "2021-08-25 10:46:29.979 | INFO     | src.policies:train:109 - Episode 1017\n",
      "2021-08-25 10:46:29.987 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:29.988 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:29.988 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.27\n",
      "2021-08-25 10:46:29.989 | INFO     | src.policies:train:109 - Episode 1018\n",
      "2021-08-25 10:46:30.008 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:30.009 | INFO     | src.policies:train:121 - Mean episode return: 47.0\n",
      "2021-08-25 10:46:30.010 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.6\n",
      "2021-08-25 10:46:30.011 | WARNING  | src.policies:train:131 - The actual batch size is 205, instead of 200\n",
      "2021-08-25 10:46:30.017 | INFO     | src.policies:train:157 - Total loss: 136.1945037841797\n",
      "2021-08-25 10:46:30.017 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:30.020 | INFO     | src.policies:train:103 - Epoch 126 / 800\n",
      "2021-08-25 10:46:30.021 | INFO     | src.policies:train:109 - Episode 1019\n",
      "2021-08-25 10:46:30.048 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:30.050 | INFO     | src.policies:train:121 - Mean episode return: 77.0\n",
      "2021-08-25 10:46:30.051 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.21\n",
      "2021-08-25 10:46:30.051 | INFO     | src.policies:train:109 - Episode 1020\n",
      "2021-08-25 10:46:30.058 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:30.059 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 10:46:30.060 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.17\n",
      "2021-08-25 10:46:30.060 | INFO     | src.policies:train:109 - Episode 1021\n",
      "2021-08-25 10:46:30.078 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:30.079 | INFO     | src.policies:train:121 - Mean episode return: 43.0\n",
      "2021-08-25 10:46:30.080 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.33\n",
      "2021-08-25 10:46:30.080 | INFO     | src.policies:train:109 - Episode 1022\n",
      "2021-08-25 10:46:30.100 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:30.102 | INFO     | src.policies:train:121 - Mean episode return: 51.0\n",
      "2021-08-25 10:46:30.103 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.27\n",
      "2021-08-25 10:46:30.103 | INFO     | src.policies:train:109 - Episode 1023\n",
      "2021-08-25 10:46:30.114 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:30.115 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 10:46:30.116 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.03\n",
      "2021-08-25 10:46:30.117 | WARNING  | src.policies:train:131 - The actual batch size is 205, instead of 200\n",
      "2021-08-25 10:46:30.122 | INFO     | src.policies:train:157 - Total loss: 353.9353332519531\n",
      "2021-08-25 10:46:30.123 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:30.126 | INFO     | src.policies:train:103 - Epoch 127 / 800\n",
      "2021-08-25 10:46:30.127 | INFO     | src.policies:train:109 - Episode 1024\n",
      "2021-08-25 10:46:30.138 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:30.139 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 10:46:30.140 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.99\n",
      "2021-08-25 10:46:30.140 | INFO     | src.policies:train:109 - Episode 1025\n",
      "2021-08-25 10:46:30.156 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:30.157 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 10:46:30.158 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.98\n",
      "2021-08-25 10:46:30.159 | INFO     | src.policies:train:109 - Episode 1026\n",
      "2021-08-25 10:46:30.174 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:30.175 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 10:46:30.176 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.17\n",
      "2021-08-25 10:46:30.177 | INFO     | src.policies:train:109 - Episode 1027\n",
      "2021-08-25 10:46:30.189 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:30.190 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 10:46:30.191 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.01\n",
      "2021-08-25 10:46:30.192 | INFO     | src.policies:train:109 - Episode 1028\n",
      "2021-08-25 10:46:30.216 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:30.217 | INFO     | src.policies:train:121 - Mean episode return: 67.0\n",
      "2021-08-25 10:46:30.217 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.48\n",
      "2021-08-25 10:46:30.218 | INFO     | src.policies:train:109 - Episode 1029\n",
      "2021-08-25 10:46:30.227 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:30.229 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:30.229 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.5\n",
      "2021-08-25 10:46:30.230 | WARNING  | src.policies:train:131 - The actual batch size is 209, instead of 200\n",
      "2021-08-25 10:46:30.236 | INFO     | src.policies:train:157 - Total loss: 231.87820434570312\n",
      "2021-08-25 10:46:30.236 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:30.239 | INFO     | src.policies:train:103 - Epoch 128 / 800\n",
      "2021-08-25 10:46:30.240 | INFO     | src.policies:train:109 - Episode 1030\n",
      "2021-08-25 10:46:30.248 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:30.249 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:30.250 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.3\n",
      "2021-08-25 10:46:30.251 | INFO     | src.policies:train:109 - Episode 1031\n",
      "2021-08-25 10:46:30.262 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:30.263 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 10:46:30.264 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.12\n",
      "2021-08-25 10:46:30.265 | INFO     | src.policies:train:109 - Episode 1032\n",
      "2021-08-25 10:46:30.271 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:30.272 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 10:46:30.273 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.07\n",
      "2021-08-25 10:46:30.274 | INFO     | src.policies:train:109 - Episode 1033\n",
      "2021-08-25 10:46:30.289 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:30.290 | INFO     | src.policies:train:121 - Mean episode return: 39.0\n",
      "2021-08-25 10:46:30.291 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.64\n",
      "2021-08-25 10:46:30.292 | INFO     | src.policies:train:109 - Episode 1034\n",
      "2021-08-25 10:46:30.312 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:30.313 | INFO     | src.policies:train:121 - Mean episode return: 53.0\n",
      "2021-08-25 10:46:30.313 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.02\n",
      "2021-08-25 10:46:30.314 | INFO     | src.policies:train:109 - Episode 1035\n",
      "2021-08-25 10:46:30.340 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:30.342 | INFO     | src.policies:train:121 - Mean episode return: 73.0\n",
      "2021-08-25 10:46:30.342 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.43\n",
      "2021-08-25 10:46:30.343 | WARNING  | src.policies:train:131 - The actual batch size is 219, instead of 200\n",
      "2021-08-25 10:46:30.349 | INFO     | src.policies:train:157 - Total loss: 307.0819091796875\n",
      "2021-08-25 10:46:30.349 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:30.352 | INFO     | src.policies:train:103 - Epoch 129 / 800\n",
      "2021-08-25 10:46:30.353 | INFO     | src.policies:train:109 - Episode 1036\n",
      "2021-08-25 10:46:30.376 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:30.377 | INFO     | src.policies:train:121 - Mean episode return: 65.0\n",
      "2021-08-25 10:46:30.378 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.8\n",
      "2021-08-25 10:46:30.379 | INFO     | src.policies:train:109 - Episode 1037\n",
      "2021-08-25 10:46:30.387 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:30.389 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:30.389 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.74\n",
      "2021-08-25 10:46:30.390 | INFO     | src.policies:train:109 - Episode 1038\n",
      "2021-08-25 10:46:30.410 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:30.411 | INFO     | src.policies:train:121 - Mean episode return: 53.0\n",
      "2021-08-25 10:46:30.412 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.18\n",
      "2021-08-25 10:46:30.413 | INFO     | src.policies:train:109 - Episode 1039\n",
      "2021-08-25 10:46:30.423 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:30.424 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 10:46:30.425 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.03\n",
      "2021-08-25 10:46:30.426 | INFO     | src.policies:train:109 - Episode 1040\n",
      "2021-08-25 10:46:30.438 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:30.439 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 10:46:30.440 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.96\n",
      "2021-08-25 10:46:30.441 | INFO     | src.policies:train:109 - Episode 1041\n",
      "2021-08-25 10:46:30.453 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:30.454 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 10:46:30.455 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.68\n",
      "2021-08-25 10:46:30.456 | WARNING  | src.policies:train:131 - The actual batch size is 206, instead of 200\n",
      "2021-08-25 10:46:30.461 | INFO     | src.policies:train:157 - Total loss: 251.02920532226562\n",
      "2021-08-25 10:46:30.462 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:30.465 | INFO     | src.policies:train:103 - Epoch 130 / 800\n",
      "2021-08-25 10:46:30.466 | INFO     | src.policies:train:109 - Episode 1042\n",
      "2021-08-25 10:46:30.475 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:30.477 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 10:46:30.477 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.47\n",
      "2021-08-25 10:46:30.478 | INFO     | src.policies:train:109 - Episode 1043\n",
      "2021-08-25 10:46:30.488 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:30.489 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 10:46:30.490 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.49\n",
      "2021-08-25 10:46:30.491 | INFO     | src.policies:train:109 - Episode 1044\n",
      "2021-08-25 10:46:30.505 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:30.506 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 10:46:30.507 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.4\n",
      "2021-08-25 10:46:30.508 | INFO     | src.policies:train:109 - Episode 1045\n",
      "2021-08-25 10:46:30.519 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:30.520 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 10:46:30.521 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.52\n",
      "2021-08-25 10:46:30.522 | INFO     | src.policies:train:109 - Episode 1046\n",
      "2021-08-25 10:46:30.537 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:30.538 | INFO     | src.policies:train:121 - Mean episode return: 38.0\n",
      "2021-08-25 10:46:30.538 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.51\n",
      "2021-08-25 10:46:30.539 | INFO     | src.policies:train:109 - Episode 1047\n",
      "2021-08-25 10:46:30.564 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:30.565 | INFO     | src.policies:train:121 - Mean episode return: 65.0\n",
      "2021-08-25 10:46:30.566 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:30.567 | WARNING  | src.policies:train:131 - The actual batch size is 202, instead of 200\n",
      "2021-08-25 10:46:30.573 | INFO     | src.policies:train:157 - Total loss: 217.85464477539062\n",
      "2021-08-25 10:46:30.574 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:30.576 | INFO     | src.policies:train:103 - Epoch 131 / 800\n",
      "2021-08-25 10:46:30.577 | INFO     | src.policies:train:109 - Episode 1048\n",
      "2021-08-25 10:46:30.597 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:30.598 | INFO     | src.policies:train:121 - Mean episode return: 54.0\n",
      "2021-08-25 10:46:30.599 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.45\n",
      "2021-08-25 10:46:30.600 | INFO     | src.policies:train:109 - Episode 1049\n",
      "2021-08-25 10:46:30.621 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:30.622 | INFO     | src.policies:train:121 - Mean episode return: 55.0\n",
      "2021-08-25 10:46:30.623 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.65\n",
      "2021-08-25 10:46:30.624 | INFO     | src.policies:train:109 - Episode 1050\n",
      "2021-08-25 10:46:30.650 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:30.651 | INFO     | src.policies:train:121 - Mean episode return: 70.0\n",
      "2021-08-25 10:46:30.652 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.09\n",
      "2021-08-25 10:46:30.653 | INFO     | src.policies:train:109 - Episode 1051\n",
      "2021-08-25 10:46:30.663 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:30.664 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 10:46:30.665 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.14\n",
      "2021-08-25 10:46:30.666 | WARNING  | src.policies:train:131 - The actual batch size is 202, instead of 200\n",
      "2021-08-25 10:46:30.671 | INFO     | src.policies:train:157 - Total loss: 365.0368347167969\n",
      "2021-08-25 10:46:30.672 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:30.674 | INFO     | src.policies:train:103 - Epoch 132 / 800\n",
      "2021-08-25 10:46:30.675 | INFO     | src.policies:train:109 - Episode 1052\n",
      "2021-08-25 10:46:30.684 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:30.685 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 10:46:30.686 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.08\n",
      "2021-08-25 10:46:30.687 | INFO     | src.policies:train:109 - Episode 1053\n",
      "2021-08-25 10:46:30.698 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:30.699 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 10:46:30.700 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.19\n",
      "2021-08-25 10:46:30.701 | INFO     | src.policies:train:109 - Episode 1054\n",
      "2021-08-25 10:46:30.709 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:30.710 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:30.711 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.18\n",
      "2021-08-25 10:46:30.712 | INFO     | src.policies:train:109 - Episode 1055\n",
      "2021-08-25 10:46:30.731 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:30.732 | INFO     | src.policies:train:121 - Mean episode return: 51.0\n",
      "2021-08-25 10:46:30.733 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.29\n",
      "2021-08-25 10:46:30.734 | INFO     | src.policies:train:109 - Episode 1056\n",
      "2021-08-25 10:46:30.750 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:30.751 | INFO     | src.policies:train:121 - Mean episode return: 42.0\n",
      "2021-08-25 10:46:30.752 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.41\n",
      "2021-08-25 10:46:30.753 | INFO     | src.policies:train:109 - Episode 1057\n",
      "2021-08-25 10:46:30.768 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:30.769 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 10:46:30.770 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.63\n",
      "2021-08-25 10:46:30.771 | INFO     | src.policies:train:109 - Episode 1058\n",
      "2021-08-25 10:46:30.782 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:30.783 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 10:46:30.784 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.16\n",
      "2021-08-25 10:46:30.785 | WARNING  | src.policies:train:131 - The actual batch size is 213, instead of 200\n",
      "2021-08-25 10:46:30.791 | INFO     | src.policies:train:157 - Total loss: 162.72938537597656\n",
      "2021-08-25 10:46:30.792 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:30.794 | INFO     | src.policies:train:103 - Epoch 133 / 800\n",
      "2021-08-25 10:46:30.795 | INFO     | src.policies:train:109 - Episode 1059\n",
      "2021-08-25 10:46:30.819 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:30.821 | INFO     | src.policies:train:121 - Mean episode return: 68.0\n",
      "2021-08-25 10:46:30.821 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.33\n",
      "2021-08-25 10:46:30.823 | INFO     | src.policies:train:109 - Episode 1060\n",
      "2021-08-25 10:46:30.834 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:30.835 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 10:46:30.836 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.62\n",
      "2021-08-25 10:46:30.837 | INFO     | src.policies:train:109 - Episode 1061\n",
      "2021-08-25 10:46:30.860 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:30.861 | INFO     | src.policies:train:121 - Mean episode return: 64.0\n",
      "2021-08-25 10:46:30.862 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.97\n",
      "2021-08-25 10:46:30.863 | INFO     | src.policies:train:109 - Episode 1062\n",
      "2021-08-25 10:46:30.883 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:30.884 | INFO     | src.policies:train:121 - Mean episode return: 51.0\n",
      "2021-08-25 10:46:30.885 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.14\n",
      "2021-08-25 10:46:30.886 | WARNING  | src.policies:train:131 - The actual batch size is 208, instead of 200\n",
      "2021-08-25 10:46:30.891 | INFO     | src.policies:train:157 - Total loss: 373.5333251953125\n",
      "2021-08-25 10:46:30.892 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:30.895 | INFO     | src.policies:train:103 - Epoch 134 / 800\n",
      "2021-08-25 10:46:30.895 | INFO     | src.policies:train:109 - Episode 1063\n",
      "2021-08-25 10:46:30.904 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:30.905 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 10:46:30.906 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.16\n",
      "2021-08-25 10:46:30.907 | INFO     | src.policies:train:109 - Episode 1064\n",
      "2021-08-25 10:46:30.924 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:30.926 | INFO     | src.policies:train:121 - Mean episode return: 46.0\n",
      "2021-08-25 10:46:30.926 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.33\n",
      "2021-08-25 10:46:30.927 | INFO     | src.policies:train:109 - Episode 1065\n",
      "2021-08-25 10:46:30.937 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:30.938 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:30.939 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.15\n",
      "2021-08-25 10:46:30.940 | INFO     | src.policies:train:109 - Episode 1066\n",
      "2021-08-25 10:46:30.951 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:30.952 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:30.953 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.16\n",
      "2021-08-25 10:46:30.954 | INFO     | src.policies:train:109 - Episode 1067\n",
      "2021-08-25 10:46:30.960 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:30.961 | INFO     | src.policies:train:121 - Mean episode return: 9.0\n",
      "2021-08-25 10:46:30.961 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.88\n",
      "2021-08-25 10:46:30.962 | INFO     | src.policies:train:109 - Episode 1068\n",
      "2021-08-25 10:46:30.969 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:30.970 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 10:46:30.971 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.66\n",
      "2021-08-25 10:46:30.972 | INFO     | src.policies:train:109 - Episode 1069\n",
      "2021-08-25 10:46:30.999 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:31.000 | INFO     | src.policies:train:121 - Mean episode return: 74.0\n",
      "2021-08-25 10:46:31.000 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.17\n",
      "2021-08-25 10:46:31.007 | INFO     | src.policies:train:157 - Total loss: 266.4598083496094\n",
      "2021-08-25 10:46:31.008 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:31.010 | INFO     | src.policies:train:103 - Epoch 135 / 800\n",
      "2021-08-25 10:46:31.011 | INFO     | src.policies:train:109 - Episode 1070\n",
      "2021-08-25 10:46:31.023 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:31.024 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 10:46:31.025 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.25\n",
      "2021-08-25 10:46:31.026 | INFO     | src.policies:train:109 - Episode 1071\n",
      "2021-08-25 10:46:31.050 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:31.051 | INFO     | src.policies:train:121 - Mean episode return: 64.0\n",
      "2021-08-25 10:46:31.052 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.62\n",
      "2021-08-25 10:46:31.053 | INFO     | src.policies:train:109 - Episode 1072\n",
      "2021-08-25 10:46:31.065 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:31.066 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 10:46:31.066 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.48\n",
      "2021-08-25 10:46:31.067 | INFO     | src.policies:train:109 - Episode 1073\n",
      "2021-08-25 10:46:31.103 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:31.105 | INFO     | src.policies:train:121 - Mean episode return: 100.0\n",
      "2021-08-25 10:46:31.105 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.03\n",
      "2021-08-25 10:46:31.106 | WARNING  | src.policies:train:131 - The actual batch size is 217, instead of 200\n",
      "2021-08-25 10:46:31.111 | INFO     | src.policies:train:157 - Total loss: 482.77496337890625\n",
      "2021-08-25 10:46:31.112 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:31.115 | INFO     | src.policies:train:103 - Epoch 136 / 800\n",
      "2021-08-25 10:46:31.116 | INFO     | src.policies:train:109 - Episode 1074\n",
      "2021-08-25 10:46:31.145 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:31.146 | INFO     | src.policies:train:121 - Mean episode return: 83.0\n",
      "2021-08-25 10:46:31.147 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.49\n",
      "2021-08-25 10:46:31.148 | INFO     | src.policies:train:109 - Episode 1075\n",
      "2021-08-25 10:46:31.155 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:31.156 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 10:46:31.157 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.23\n",
      "2021-08-25 10:46:31.158 | INFO     | src.policies:train:109 - Episode 1076\n",
      "2021-08-25 10:46:31.171 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:31.172 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 10:46:31.173 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.32\n",
      "2021-08-25 10:46:31.174 | INFO     | src.policies:train:109 - Episode 1077\n",
      "2021-08-25 10:46:31.182 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:31.183 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 10:46:31.184 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.11\n",
      "2021-08-25 10:46:31.185 | INFO     | src.policies:train:109 - Episode 1078\n",
      "2021-08-25 10:46:31.204 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:31.206 | INFO     | src.policies:train:121 - Mean episode return: 49.0\n",
      "2021-08-25 10:46:31.206 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.47\n",
      "2021-08-25 10:46:31.207 | INFO     | src.policies:train:109 - Episode 1079\n",
      "2021-08-25 10:46:31.226 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:31.227 | INFO     | src.policies:train:121 - Mean episode return: 47.0\n",
      "2021-08-25 10:46:31.228 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.8\n",
      "2021-08-25 10:46:31.229 | WARNING  | src.policies:train:131 - The actual batch size is 240, instead of 200\n",
      "2021-08-25 10:46:31.235 | INFO     | src.policies:train:157 - Total loss: 338.81268310546875\n",
      "2021-08-25 10:46:31.236 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:31.239 | INFO     | src.policies:train:103 - Epoch 137 / 800\n",
      "2021-08-25 10:46:31.240 | INFO     | src.policies:train:109 - Episode 1080\n",
      "2021-08-25 10:46:31.246 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:31.247 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:31.248 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.69\n",
      "2021-08-25 10:46:31.249 | INFO     | src.policies:train:109 - Episode 1081\n",
      "2021-08-25 10:46:31.257 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:31.258 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:31.259 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.72\n",
      "2021-08-25 10:46:31.260 | INFO     | src.policies:train:109 - Episode 1082\n",
      "2021-08-25 10:46:31.268 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:31.270 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 10:46:31.270 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.18\n",
      "2021-08-25 10:46:31.271 | INFO     | src.policies:train:109 - Episode 1083\n",
      "2021-08-25 10:46:31.281 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:31.282 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 10:46:31.283 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.28\n",
      "2021-08-25 10:46:31.284 | INFO     | src.policies:train:109 - Episode 1084\n",
      "2021-08-25 10:46:31.293 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:31.294 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 10:46:31.295 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.2\n",
      "2021-08-25 10:46:31.296 | INFO     | src.policies:train:109 - Episode 1085\n",
      "2021-08-25 10:46:31.306 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:31.307 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 10:46:31.307 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.79\n",
      "2021-08-25 10:46:31.308 | INFO     | src.policies:train:109 - Episode 1086\n",
      "2021-08-25 10:46:31.315 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:31.316 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:31.317 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.67\n",
      "2021-08-25 10:46:31.318 | INFO     | src.policies:train:109 - Episode 1087\n",
      "2021-08-25 10:46:31.329 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:31.331 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 10:46:31.331 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.87\n",
      "2021-08-25 10:46:31.332 | INFO     | src.policies:train:109 - Episode 1088\n",
      "2021-08-25 10:46:31.343 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:31.344 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 10:46:31.344 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.69\n",
      "2021-08-25 10:46:31.345 | INFO     | src.policies:train:109 - Episode 1089\n",
      "2021-08-25 10:46:31.359 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:31.360 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 10:46:31.361 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.7\n",
      "2021-08-25 10:46:31.362 | WARNING  | src.policies:train:131 - The actual batch size is 206, instead of 200\n",
      "2021-08-25 10:46:31.368 | INFO     | src.policies:train:157 - Total loss: 63.762325286865234\n",
      "2021-08-25 10:46:31.369 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:31.372 | INFO     | src.policies:train:103 - Epoch 138 / 800\n",
      "2021-08-25 10:46:31.373 | INFO     | src.policies:train:109 - Episode 1090\n",
      "2021-08-25 10:46:31.381 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:31.382 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:31.382 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.45\n",
      "2021-08-25 10:46:31.383 | INFO     | src.policies:train:109 - Episode 1091\n",
      "2021-08-25 10:46:31.399 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:31.400 | INFO     | src.policies:train:121 - Mean episode return: 39.0\n",
      "2021-08-25 10:46:31.401 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.64\n",
      "2021-08-25 10:46:31.402 | INFO     | src.policies:train:109 - Episode 1092\n",
      "2021-08-25 10:46:31.417 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:31.418 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 10:46:31.419 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.57\n",
      "2021-08-25 10:46:31.420 | INFO     | src.policies:train:109 - Episode 1093\n",
      "2021-08-25 10:46:31.442 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:31.443 | INFO     | src.policies:train:121 - Mean episode return: 55.0\n",
      "2021-08-25 10:46:31.444 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.81\n",
      "2021-08-25 10:46:31.445 | INFO     | src.policies:train:109 - Episode 1094\n",
      "2021-08-25 10:46:31.458 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:31.459 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 10:46:31.460 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.84\n",
      "2021-08-25 10:46:31.460 | INFO     | src.policies:train:109 - Episode 1095\n",
      "2021-08-25 10:46:31.475 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:31.476 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 10:46:31.476 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.69\n",
      "2021-08-25 10:46:31.477 | WARNING  | src.policies:train:131 - The actual batch size is 210, instead of 200\n",
      "2021-08-25 10:46:31.483 | INFO     | src.policies:train:157 - Total loss: 176.7556915283203\n",
      "2021-08-25 10:46:31.484 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:31.486 | INFO     | src.policies:train:103 - Epoch 139 / 800\n",
      "2021-08-25 10:46:31.488 | INFO     | src.policies:train:109 - Episode 1096\n",
      "2021-08-25 10:46:31.495 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:31.496 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:31.497 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.73\n",
      "2021-08-25 10:46:31.497 | INFO     | src.policies:train:109 - Episode 1097\n",
      "2021-08-25 10:46:31.530 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:31.531 | INFO     | src.policies:train:121 - Mean episode return: 88.0\n",
      "2021-08-25 10:46:31.532 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.23\n",
      "2021-08-25 10:46:31.533 | INFO     | src.policies:train:109 - Episode 1098\n",
      "2021-08-25 10:46:31.540 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:31.541 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:31.542 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.05\n",
      "2021-08-25 10:46:31.543 | INFO     | src.policies:train:109 - Episode 1099\n",
      "2021-08-25 10:46:31.555 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:31.556 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 10:46:31.557 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.93\n",
      "2021-08-25 10:46:31.558 | INFO     | src.policies:train:109 - Episode 1100\n",
      "2021-08-25 10:46:31.567 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:31.568 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:31.569 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.87\n",
      "2021-08-25 10:46:31.569 | INFO     | src.policies:train:109 - Episode 1101\n",
      "2021-08-25 10:46:31.579 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:31.580 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 10:46:31.581 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.93\n",
      "2021-08-25 10:46:31.582 | INFO     | src.policies:train:109 - Episode 1102\n",
      "2021-08-25 10:46:31.605 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:31.606 | INFO     | src.policies:train:121 - Mean episode return: 63.0\n",
      "2021-08-25 10:46:31.607 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.28\n",
      "2021-08-25 10:46:31.608 | WARNING  | src.policies:train:131 - The actual batch size is 250, instead of 200\n",
      "2021-08-25 10:46:31.613 | INFO     | src.policies:train:157 - Total loss: 343.9054870605469\n",
      "2021-08-25 10:46:31.614 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:31.617 | INFO     | src.policies:train:103 - Epoch 140 / 800\n",
      "2021-08-25 10:46:31.618 | INFO     | src.policies:train:109 - Episode 1103\n",
      "2021-08-25 10:46:31.623 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:31.624 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 10:46:31.625 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.11\n",
      "2021-08-25 10:46:31.626 | INFO     | src.policies:train:109 - Episode 1104\n",
      "2021-08-25 10:46:31.638 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:31.639 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 10:46:31.640 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.88\n",
      "2021-08-25 10:46:31.641 | INFO     | src.policies:train:109 - Episode 1105\n",
      "2021-08-25 10:46:31.647 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:31.648 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 10:46:31.649 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.76\n",
      "2021-08-25 10:46:31.650 | INFO     | src.policies:train:109 - Episode 1106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:31.659 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:31.660 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:31.660 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.51\n",
      "2021-08-25 10:46:31.661 | INFO     | src.policies:train:109 - Episode 1107\n",
      "2021-08-25 10:46:31.671 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:31.672 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 10:46:31.673 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.34\n",
      "2021-08-25 10:46:31.674 | INFO     | src.policies:train:109 - Episode 1108\n",
      "2021-08-25 10:46:31.693 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:31.694 | INFO     | src.policies:train:121 - Mean episode return: 48.0\n",
      "2021-08-25 10:46:31.694 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.58\n",
      "2021-08-25 10:46:31.695 | INFO     | src.policies:train:109 - Episode 1109\n",
      "2021-08-25 10:46:31.703 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:31.704 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:31.705 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.56\n",
      "2021-08-25 10:46:31.706 | INFO     | src.policies:train:109 - Episode 1110\n",
      "2021-08-25 10:46:31.729 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:31.730 | INFO     | src.policies:train:121 - Mean episode return: 60.0\n",
      "2021-08-25 10:46:31.731 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.0\n",
      "2021-08-25 10:46:31.732 | WARNING  | src.policies:train:131 - The actual batch size is 208, instead of 200\n",
      "2021-08-25 10:46:31.737 | INFO     | src.policies:train:157 - Total loss: 189.9737548828125\n",
      "2021-08-25 10:46:31.738 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:31.741 | INFO     | src.policies:train:103 - Epoch 141 / 800\n",
      "2021-08-25 10:46:31.742 | INFO     | src.policies:train:109 - Episode 1111\n",
      "2021-08-25 10:46:31.752 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:31.753 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 10:46:31.754 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.14\n",
      "2021-08-25 10:46:31.755 | INFO     | src.policies:train:109 - Episode 1112\n",
      "2021-08-25 10:46:31.762 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:31.763 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:31.764 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.07\n",
      "2021-08-25 10:46:31.764 | INFO     | src.policies:train:109 - Episode 1113\n",
      "2021-08-25 10:46:31.774 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:31.775 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:31.776 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.89\n",
      "2021-08-25 10:46:31.777 | INFO     | src.policies:train:109 - Episode 1114\n",
      "2021-08-25 10:46:31.791 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:31.793 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 10:46:31.793 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.99\n",
      "2021-08-25 10:46:31.794 | INFO     | src.policies:train:109 - Episode 1115\n",
      "2021-08-25 10:46:31.803 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:31.804 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 10:46:31.805 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.92\n",
      "2021-08-25 10:46:31.806 | INFO     | src.policies:train:109 - Episode 1116\n",
      "2021-08-25 10:46:31.829 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:31.830 | INFO     | src.policies:train:121 - Mean episode return: 57.0\n",
      "2021-08-25 10:46:31.831 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.21\n",
      "2021-08-25 10:46:31.832 | INFO     | src.policies:train:109 - Episode 1117\n",
      "2021-08-25 10:46:31.841 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:31.842 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 10:46:31.843 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.28\n",
      "2021-08-25 10:46:31.844 | INFO     | src.policies:train:109 - Episode 1118\n",
      "2021-08-25 10:46:31.855 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:31.856 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 10:46:31.857 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.03\n",
      "2021-08-25 10:46:31.858 | WARNING  | src.policies:train:131 - The actual batch size is 208, instead of 200\n",
      "2021-08-25 10:46:31.864 | INFO     | src.policies:train:157 - Total loss: 141.5926055908203\n",
      "2021-08-25 10:46:31.864 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:31.867 | INFO     | src.policies:train:103 - Epoch 142 / 800\n",
      "2021-08-25 10:46:31.868 | INFO     | src.policies:train:109 - Episode 1119\n",
      "2021-08-25 10:46:31.880 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:31.881 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 10:46:31.882 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.56\n",
      "2021-08-25 10:46:31.883 | INFO     | src.policies:train:109 - Episode 1120\n",
      "2021-08-25 10:46:31.896 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:31.897 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 10:46:31.898 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.75\n",
      "2021-08-25 10:46:31.898 | INFO     | src.policies:train:109 - Episode 1121\n",
      "2021-08-25 10:46:31.908 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:31.909 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:31.910 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.5\n",
      "2021-08-25 10:46:31.911 | INFO     | src.policies:train:109 - Episode 1122\n",
      "2021-08-25 10:46:31.930 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:31.931 | INFO     | src.policies:train:121 - Mean episode return: 51.0\n",
      "2021-08-25 10:46:31.932 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.5\n",
      "2021-08-25 10:46:31.933 | INFO     | src.policies:train:109 - Episode 1123\n",
      "2021-08-25 10:46:31.941 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:31.942 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:31.943 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.41\n",
      "2021-08-25 10:46:31.944 | INFO     | src.policies:train:109 - Episode 1124\n",
      "2021-08-25 10:46:31.953 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:31.954 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 10:46:31.955 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.36\n",
      "2021-08-25 10:46:31.956 | INFO     | src.policies:train:109 - Episode 1125\n",
      "2021-08-25 10:46:31.978 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:31.979 | INFO     | src.policies:train:121 - Mean episode return: 58.0\n",
      "2021-08-25 10:46:31.980 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.58\n",
      "2021-08-25 10:46:31.981 | WARNING  | src.policies:train:131 - The actual batch size is 222, instead of 200\n",
      "2021-08-25 10:46:31.987 | INFO     | src.policies:train:157 - Total loss: 188.69541931152344\n",
      "2021-08-25 10:46:31.988 | INFO     | src.policies:train:161 - Epoch infos: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:31.991 | INFO     | src.policies:train:103 - Epoch 143 / 800\n",
      "2021-08-25 10:46:31.992 | INFO     | src.policies:train:109 - Episode 1126\n",
      "2021-08-25 10:46:31.999 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:32.001 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:32.001 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.39\n",
      "2021-08-25 10:46:32.002 | INFO     | src.policies:train:109 - Episode 1127\n",
      "2021-08-25 10:46:32.015 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:32.016 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 10:46:32.016 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.43\n",
      "2021-08-25 10:46:32.017 | INFO     | src.policies:train:109 - Episode 1128\n",
      "2021-08-25 10:46:32.032 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:32.033 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 10:46:32.034 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.13\n",
      "2021-08-25 10:46:32.035 | INFO     | src.policies:train:109 - Episode 1129\n",
      "2021-08-25 10:46:32.044 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:32.046 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 10:46:32.046 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.15\n",
      "2021-08-25 10:46:32.047 | INFO     | src.policies:train:109 - Episode 1130\n",
      "2021-08-25 10:46:32.060 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:32.061 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 10:46:32.062 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.24\n",
      "2021-08-25 10:46:32.063 | INFO     | src.policies:train:109 - Episode 1131\n",
      "2021-08-25 10:46:32.070 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:32.071 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 10:46:32.072 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.1\n",
      "2021-08-25 10:46:32.073 | INFO     | src.policies:train:109 - Episode 1132\n",
      "2021-08-25 10:46:32.082 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:32.083 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:32.083 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.19\n",
      "2021-08-25 10:46:32.084 | INFO     | src.policies:train:109 - Episode 1133\n",
      "2021-08-25 10:46:32.105 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:32.106 | INFO     | src.policies:train:121 - Mean episode return: 55.0\n",
      "2021-08-25 10:46:32.107 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.35\n",
      "2021-08-25 10:46:32.108 | WARNING  | src.policies:train:131 - The actual batch size is 217, instead of 200\n",
      "2021-08-25 10:46:32.115 | INFO     | src.policies:train:157 - Total loss: 144.1448974609375\n",
      "2021-08-25 10:46:32.115 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:32.118 | INFO     | src.policies:train:103 - Epoch 144 / 800\n",
      "2021-08-25 10:46:32.119 | INFO     | src.policies:train:109 - Episode 1134\n",
      "2021-08-25 10:46:32.140 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:32.142 | INFO     | src.policies:train:121 - Mean episode return: 62.0\n",
      "2021-08-25 10:46:32.142 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.44\n",
      "2021-08-25 10:46:32.143 | INFO     | src.policies:train:109 - Episode 1135\n",
      "2021-08-25 10:46:32.153 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:32.154 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:32.155 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.9\n",
      "2021-08-25 10:46:32.156 | INFO     | src.policies:train:109 - Episode 1136\n",
      "2021-08-25 10:46:32.163 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:32.164 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:32.165 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.38\n",
      "2021-08-25 10:46:32.166 | INFO     | src.policies:train:109 - Episode 1137\n",
      "2021-08-25 10:46:32.190 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:32.191 | INFO     | src.policies:train:121 - Mean episode return: 67.0\n",
      "2021-08-25 10:46:32.192 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.89\n",
      "2021-08-25 10:46:32.193 | INFO     | src.policies:train:109 - Episode 1138\n",
      "2021-08-25 10:46:32.203 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:32.204 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 10:46:32.205 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.56\n",
      "2021-08-25 10:46:32.205 | INFO     | src.policies:train:109 - Episode 1139\n",
      "2021-08-25 10:46:32.212 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:32.213 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:32.214 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.49\n",
      "2021-08-25 10:46:32.215 | INFO     | src.policies:train:109 - Episode 1140\n",
      "2021-08-25 10:46:32.225 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:32.226 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 10:46:32.227 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.46\n",
      "2021-08-25 10:46:32.228 | WARNING  | src.policies:train:131 - The actual batch size is 218, instead of 200\n",
      "2021-08-25 10:46:32.234 | INFO     | src.policies:train:157 - Total loss: 248.94566345214844\n",
      "2021-08-25 10:46:32.235 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:32.237 | INFO     | src.policies:train:103 - Epoch 145 / 800\n",
      "2021-08-25 10:46:32.238 | INFO     | src.policies:train:109 - Episode 1141\n",
      "2021-08-25 10:46:32.252 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:32.253 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 10:46:32.254 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.57\n",
      "2021-08-25 10:46:32.255 | INFO     | src.policies:train:109 - Episode 1142\n",
      "2021-08-25 10:46:32.264 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:32.265 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:32.266 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.53\n",
      "2021-08-25 10:46:32.267 | INFO     | src.policies:train:109 - Episode 1143\n",
      "2021-08-25 10:46:32.276 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:32.277 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:32.278 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.52\n",
      "2021-08-25 10:46:32.279 | INFO     | src.policies:train:109 - Episode 1144\n",
      "2021-08-25 10:46:32.296 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:32.297 | INFO     | src.policies:train:121 - Mean episode return: 42.0\n",
      "2021-08-25 10:46:32.297 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.61\n",
      "2021-08-25 10:46:32.298 | INFO     | src.policies:train:109 - Episode 1145\n",
      "2021-08-25 10:46:32.319 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:32.320 | INFO     | src.policies:train:121 - Mean episode return: 55.0\n",
      "2021-08-25 10:46:32.321 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.92\n",
      "2021-08-25 10:46:32.322 | INFO     | src.policies:train:109 - Episode 1146\n",
      "2021-08-25 10:46:32.328 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:32.329 | INFO     | src.policies:train:121 - Mean episode return: 9.0\n",
      "2021-08-25 10:46:32.330 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.63\n",
      "2021-08-25 10:46:32.331 | INFO     | src.policies:train:109 - Episode 1147\n",
      "2021-08-25 10:46:32.364 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:32.365 | INFO     | src.policies:train:121 - Mean episode return: 93.0\n",
      "2021-08-25 10:46:32.366 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.91\n",
      "2021-08-25 10:46:32.367 | WARNING  | src.policies:train:131 - The actual batch size is 272, instead of 200\n",
      "2021-08-25 10:46:32.373 | INFO     | src.policies:train:157 - Total loss: 337.5208740234375\n",
      "2021-08-25 10:46:32.374 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:32.376 | INFO     | src.policies:train:103 - Epoch 146 / 800\n",
      "2021-08-25 10:46:32.377 | INFO     | src.policies:train:109 - Episode 1148\n",
      "2021-08-25 10:46:32.385 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:32.386 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 10:46:32.387 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.54\n",
      "2021-08-25 10:46:32.388 | INFO     | src.policies:train:109 - Episode 1149\n",
      "2021-08-25 10:46:32.407 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:32.408 | INFO     | src.policies:train:121 - Mean episode return: 49.0\n",
      "2021-08-25 10:46:32.409 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.48\n",
      "2021-08-25 10:46:32.410 | INFO     | src.policies:train:109 - Episode 1150\n",
      "2021-08-25 10:46:32.417 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:32.418 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:32.419 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.91\n",
      "2021-08-25 10:46:32.420 | INFO     | src.policies:train:109 - Episode 1151\n",
      "2021-08-25 10:46:32.433 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:32.434 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 10:46:32.434 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.98\n",
      "2021-08-25 10:46:32.435 | INFO     | src.policies:train:109 - Episode 1152\n",
      "2021-08-25 10:46:32.449 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:32.450 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 10:46:32.451 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.11\n",
      "2021-08-25 10:46:32.452 | INFO     | src.policies:train:109 - Episode 1153\n",
      "2021-08-25 10:46:32.463 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:32.464 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 10:46:32.465 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.11\n",
      "2021-08-25 10:46:32.466 | INFO     | src.policies:train:109 - Episode 1154\n",
      "2021-08-25 10:46:32.484 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:32.485 | INFO     | src.policies:train:121 - Mean episode return: 46.0\n",
      "2021-08-25 10:46:32.486 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.42\n",
      "2021-08-25 10:46:32.487 | WARNING  | src.policies:train:131 - The actual batch size is 214, instead of 200\n",
      "2021-08-25 10:46:32.493 | INFO     | src.policies:train:157 - Total loss: 144.79356384277344\n",
      "2021-08-25 10:46:32.494 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:32.497 | INFO     | src.policies:train:103 - Epoch 147 / 800\n",
      "2021-08-25 10:46:32.498 | INFO     | src.policies:train:109 - Episode 1155\n",
      "2021-08-25 10:46:32.507 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:32.508 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 10:46:32.509 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.12\n",
      "2021-08-25 10:46:32.510 | INFO     | src.policies:train:109 - Episode 1156\n",
      "2021-08-25 10:46:32.518 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:32.519 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 10:46:32.520 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.87\n",
      "2021-08-25 10:46:32.521 | INFO     | src.policies:train:109 - Episode 1157\n",
      "2021-08-25 10:46:32.533 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:32.534 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 10:46:32.535 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.79\n",
      "2021-08-25 10:46:32.536 | INFO     | src.policies:train:109 - Episode 1158\n",
      "2021-08-25 10:46:32.545 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:32.546 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:32.546 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.74\n",
      "2021-08-25 10:46:32.547 | INFO     | src.policies:train:109 - Episode 1159\n",
      "2021-08-25 10:46:32.554 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:32.555 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:32.556 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.18\n",
      "2021-08-25 10:46:32.557 | INFO     | src.policies:train:109 - Episode 1160\n",
      "2021-08-25 10:46:32.566 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:32.567 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:32.568 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.11\n",
      "2021-08-25 10:46:32.569 | INFO     | src.policies:train:109 - Episode 1161\n",
      "2021-08-25 10:46:32.593 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:32.594 | INFO     | src.policies:train:121 - Mean episode return: 61.0\n",
      "2021-08-25 10:46:32.595 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.08\n",
      "2021-08-25 10:46:32.595 | INFO     | src.policies:train:109 - Episode 1162\n",
      "2021-08-25 10:46:32.604 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:32.605 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:32.606 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.76\n",
      "2021-08-25 10:46:32.607 | INFO     | src.policies:train:109 - Episode 1163\n",
      "2021-08-25 10:46:32.625 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:32.626 | INFO     | src.policies:train:121 - Mean episode return: 41.0\n",
      "2021-08-25 10:46:32.627 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.97\n",
      "2021-08-25 10:46:32.627 | WARNING  | src.policies:train:131 - The actual batch size is 235, instead of 200\n",
      "2021-08-25 10:46:32.634 | INFO     | src.policies:train:157 - Total loss: 143.73768615722656\n",
      "2021-08-25 10:46:32.635 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:32.637 | INFO     | src.policies:train:103 - Epoch 148 / 800\n",
      "2021-08-25 10:46:32.638 | INFO     | src.policies:train:109 - Episode 1164\n",
      "2021-08-25 10:46:32.647 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:32.648 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 10:46:32.649 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.72\n",
      "2021-08-25 10:46:32.650 | INFO     | src.policies:train:109 - Episode 1165\n",
      "2021-08-25 10:46:32.680 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:32.681 | INFO     | src.policies:train:121 - Mean episode return: 79.0\n",
      "2021-08-25 10:46:32.682 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:32.683 | INFO     | src.policies:train:109 - Episode 1166\n",
      "2021-08-25 10:46:32.710 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:32.711 | INFO     | src.policies:train:121 - Mean episode return: 72.0\n",
      "2021-08-25 10:46:32.712 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.83\n",
      "2021-08-25 10:46:32.713 | INFO     | src.policies:train:109 - Episode 1167\n",
      "2021-08-25 10:46:32.724 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:32.725 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 10:46:32.726 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.0\n",
      "2021-08-25 10:46:32.727 | INFO     | src.policies:train:109 - Episode 1168\n",
      "2021-08-25 10:46:32.744 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:32.746 | INFO     | src.policies:train:121 - Mean episode return: 44.0\n",
      "2021-08-25 10:46:32.747 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.33\n",
      "2021-08-25 10:46:32.748 | WARNING  | src.policies:train:131 - The actual batch size is 242, instead of 200\n",
      "2021-08-25 10:46:32.754 | INFO     | src.policies:train:157 - Total loss: 355.51605224609375\n",
      "2021-08-25 10:46:32.754 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:32.757 | INFO     | src.policies:train:103 - Epoch 149 / 800\n",
      "2021-08-25 10:46:32.758 | INFO     | src.policies:train:109 - Episode 1169\n",
      "2021-08-25 10:46:32.770 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:32.771 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 10:46:32.771 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.89\n",
      "2021-08-25 10:46:32.772 | INFO     | src.policies:train:109 - Episode 1170\n",
      "2021-08-25 10:46:32.780 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:32.781 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:32.782 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.77\n",
      "2021-08-25 10:46:32.783 | INFO     | src.policies:train:109 - Episode 1171\n",
      "2021-08-25 10:46:32.799 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:32.800 | INFO     | src.policies:train:121 - Mean episode return: 38.0\n",
      "2021-08-25 10:46:32.800 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.51\n",
      "2021-08-25 10:46:32.801 | INFO     | src.policies:train:109 - Episode 1172\n",
      "2021-08-25 10:46:32.837 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:32.838 | INFO     | src.policies:train:121 - Mean episode return: 99.0\n",
      "2021-08-25 10:46:32.838 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.24\n",
      "2021-08-25 10:46:32.839 | INFO     | src.policies:train:109 - Episode 1173\n",
      "2021-08-25 10:46:32.849 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:32.850 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:32.851 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.43\n",
      "2021-08-25 10:46:32.852 | WARNING  | src.policies:train:131 - The actual batch size is 201, instead of 200\n",
      "2021-08-25 10:46:32.857 | INFO     | src.policies:train:157 - Total loss: 381.1432800292969\n",
      "2021-08-25 10:46:32.858 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:32.860 | INFO     | src.policies:train:103 - Epoch 150 / 800\n",
      "2021-08-25 10:46:32.861 | INFO     | src.policies:train:109 - Episode 1174\n",
      "2021-08-25 10:46:32.873 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:32.874 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 10:46:32.875 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.91\n",
      "2021-08-25 10:46:32.876 | INFO     | src.policies:train:109 - Episode 1175\n",
      "2021-08-25 10:46:32.890 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:32.891 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 10:46:32.892 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.14\n",
      "2021-08-25 10:46:32.893 | INFO     | src.policies:train:109 - Episode 1176\n",
      "2021-08-25 10:46:32.905 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:32.906 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 10:46:32.906 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.07\n",
      "2021-08-25 10:46:32.907 | INFO     | src.policies:train:109 - Episode 1177\n",
      "2021-08-25 10:46:32.916 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:32.917 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:32.918 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.06\n",
      "2021-08-25 10:46:32.919 | INFO     | src.policies:train:109 - Episode 1178\n",
      "2021-08-25 10:46:32.929 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:32.930 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 10:46:32.931 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.78\n",
      "2021-08-25 10:46:32.932 | INFO     | src.policies:train:109 - Episode 1179\n",
      "2021-08-25 10:46:32.954 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:32.955 | INFO     | src.policies:train:121 - Mean episode return: 60.0\n",
      "2021-08-25 10:46:32.956 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.91\n",
      "2021-08-25 10:46:32.957 | INFO     | src.policies:train:109 - Episode 1180\n",
      "2021-08-25 10:46:32.964 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:32.965 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:32.966 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.89\n",
      "2021-08-25 10:46:32.971 | INFO     | src.policies:train:157 - Total loss: 155.2568359375\n",
      "2021-08-25 10:46:32.972 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:32.975 | INFO     | src.policies:train:103 - Epoch 151 / 800\n",
      "2021-08-25 10:46:32.976 | INFO     | src.policies:train:109 - Episode 1181\n",
      "2021-08-25 10:46:32.982 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:32.983 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:32.984 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.87\n",
      "2021-08-25 10:46:32.985 | INFO     | src.policies:train:109 - Episode 1182\n",
      "2021-08-25 10:46:32.994 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:32.995 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:32.995 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.86\n",
      "2021-08-25 10:46:32.996 | INFO     | src.policies:train:109 - Episode 1183\n",
      "2021-08-25 10:46:33.009 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:33.010 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 10:46:33.011 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.9\n",
      "2021-08-25 10:46:33.011 | INFO     | src.policies:train:109 - Episode 1184\n",
      "2021-08-25 10:46:33.022 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:33.023 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 10:46:33.024 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.94\n",
      "2021-08-25 10:46:33.025 | INFO     | src.policies:train:109 - Episode 1185\n",
      "2021-08-25 10:46:33.048 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:33.050 | INFO     | src.policies:train:121 - Mean episode return: 65.0\n",
      "2021-08-25 10:46:33.050 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:33.052 | INFO     | src.policies:train:109 - Episode 1186\n",
      "2021-08-25 10:46:33.059 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:33.060 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:33.061 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.38\n",
      "2021-08-25 10:46:33.062 | INFO     | src.policies:train:109 - Episode 1187\n",
      "2021-08-25 10:46:33.069 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:33.070 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 10:46:33.071 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.18\n",
      "2021-08-25 10:46:33.072 | INFO     | src.policies:train:109 - Episode 1188\n",
      "2021-08-25 10:46:33.079 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:33.080 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:33.081 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.08\n",
      "2021-08-25 10:46:33.082 | INFO     | src.policies:train:109 - Episode 1189\n",
      "2021-08-25 10:46:33.089 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:33.090 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 10:46:33.090 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.89\n",
      "2021-08-25 10:46:33.091 | INFO     | src.policies:train:109 - Episode 1190\n",
      "2021-08-25 10:46:33.104 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:33.105 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 10:46:33.106 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.01\n",
      "2021-08-25 10:46:33.107 | WARNING  | src.policies:train:131 - The actual batch size is 223, instead of 200\n",
      "2021-08-25 10:46:33.113 | INFO     | src.policies:train:157 - Total loss: 149.8354034423828\n",
      "2021-08-25 10:46:33.114 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:33.117 | INFO     | src.policies:train:103 - Epoch 152 / 800\n",
      "2021-08-25 10:46:33.118 | INFO     | src.policies:train:109 - Episode 1191\n",
      "2021-08-25 10:46:33.130 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:33.131 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 10:46:33.132 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.95\n",
      "2021-08-25 10:46:33.133 | INFO     | src.policies:train:109 - Episode 1192\n",
      "2021-08-25 10:46:33.140 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:33.141 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:33.142 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.73\n",
      "2021-08-25 10:46:33.143 | INFO     | src.policies:train:109 - Episode 1193\n",
      "2021-08-25 10:46:33.180 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:33.181 | INFO     | src.policies:train:121 - Mean episode return: 102.0\n",
      "2021-08-25 10:46:33.182 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.2\n",
      "2021-08-25 10:46:33.183 | INFO     | src.policies:train:109 - Episode 1194\n",
      "2021-08-25 10:46:33.193 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:33.194 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 10:46:33.195 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.13\n",
      "2021-08-25 10:46:33.196 | INFO     | src.policies:train:109 - Episode 1195\n",
      "2021-08-25 10:46:33.223 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:33.224 | INFO     | src.policies:train:121 - Mean episode return: 76.0\n",
      "2021-08-25 10:46:33.225 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.56\n",
      "2021-08-25 10:46:33.226 | WARNING  | src.policies:train:131 - The actual batch size is 246, instead of 200\n",
      "2021-08-25 10:46:33.231 | INFO     | src.policies:train:157 - Total loss: 443.46099853515625\n",
      "2021-08-25 10:46:33.232 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:33.235 | INFO     | src.policies:train:103 - Epoch 153 / 800\n",
      "2021-08-25 10:46:33.236 | INFO     | src.policies:train:109 - Episode 1196\n",
      "2021-08-25 10:46:33.247 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:33.248 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 10:46:33.249 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.7\n",
      "2021-08-25 10:46:33.250 | INFO     | src.policies:train:109 - Episode 1197\n",
      "2021-08-25 10:46:33.263 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:33.264 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 10:46:33.264 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.1\n",
      "2021-08-25 10:46:33.265 | INFO     | src.policies:train:109 - Episode 1198\n",
      "2021-08-25 10:46:33.276 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:33.277 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 10:46:33.278 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.2\n",
      "2021-08-25 10:46:33.279 | INFO     | src.policies:train:109 - Episode 1199\n",
      "2021-08-25 10:46:33.294 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:33.295 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 10:46:33.295 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.24\n",
      "2021-08-25 10:46:33.296 | INFO     | src.policies:train:109 - Episode 1200\n",
      "2021-08-25 10:46:33.306 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:33.307 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:33.308 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.24\n",
      "2021-08-25 10:46:33.309 | INFO     | src.policies:train:109 - Episode 1201\n",
      "2021-08-25 10:46:33.321 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:33.322 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 10:46:33.323 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.3\n",
      "2021-08-25 10:46:33.324 | INFO     | src.policies:train:109 - Episode 1202\n",
      "2021-08-25 10:46:33.335 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:33.336 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 10:46:33.337 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.9\n",
      "2021-08-25 10:46:33.337 | INFO     | src.policies:train:109 - Episode 1203\n",
      "2021-08-25 10:46:33.345 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:33.346 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:33.347 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.94\n",
      "2021-08-25 10:46:33.348 | INFO     | src.policies:train:109 - Episode 1204\n",
      "2021-08-25 10:46:33.360 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:33.361 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 10:46:33.362 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.93\n",
      "2021-08-25 10:46:33.363 | WARNING  | src.policies:train:131 - The actual batch size is 227, instead of 200\n",
      "2021-08-25 10:46:33.369 | INFO     | src.policies:train:157 - Total loss: 69.54623413085938\n",
      "2021-08-25 10:46:33.370 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:33.373 | INFO     | src.policies:train:103 - Epoch 154 / 800\n",
      "2021-08-25 10:46:33.374 | INFO     | src.policies:train:109 - Episode 1205\n",
      "2021-08-25 10:46:33.394 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:33.395 | INFO     | src.policies:train:121 - Mean episode return: 56.0\n",
      "2021-08-25 10:46:33.396 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.39\n",
      "2021-08-25 10:46:33.397 | INFO     | src.policies:train:109 - Episode 1206\n",
      "2021-08-25 10:46:33.411 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:33.412 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 10:46:33.413 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.6\n",
      "2021-08-25 10:46:33.414 | INFO     | src.policies:train:109 - Episode 1207\n",
      "2021-08-25 10:46:33.424 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:33.425 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 10:46:33.425 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.62\n",
      "2021-08-25 10:46:33.426 | INFO     | src.policies:train:109 - Episode 1208\n",
      "2021-08-25 10:46:33.439 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:33.440 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 10:46:33.440 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.41\n",
      "2021-08-25 10:46:33.441 | INFO     | src.policies:train:109 - Episode 1209\n",
      "2021-08-25 10:46:33.450 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:33.452 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:33.452 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.41\n",
      "2021-08-25 10:46:33.453 | INFO     | src.policies:train:109 - Episode 1210\n",
      "2021-08-25 10:46:33.462 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:33.463 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 10:46:33.464 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.01\n",
      "2021-08-25 10:46:33.465 | INFO     | src.policies:train:109 - Episode 1211\n",
      "2021-08-25 10:46:33.481 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:33.482 | INFO     | src.policies:train:121 - Mean episode return: 38.0\n",
      "2021-08-25 10:46:33.482 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.13\n",
      "2021-08-25 10:46:33.483 | WARNING  | src.policies:train:131 - The actual batch size is 214, instead of 200\n",
      "2021-08-25 10:46:33.489 | INFO     | src.policies:train:157 - Total loss: 135.11676025390625\n",
      "2021-08-25 10:46:33.490 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:33.493 | INFO     | src.policies:train:103 - Epoch 155 / 800\n",
      "2021-08-25 10:46:33.494 | INFO     | src.policies:train:109 - Episode 1212\n",
      "2021-08-25 10:46:33.508 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:33.509 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 10:46:33.510 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.38\n",
      "2021-08-25 10:46:33.511 | INFO     | src.policies:train:109 - Episode 1213\n",
      "2021-08-25 10:46:33.544 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:33.545 | INFO     | src.policies:train:121 - Mean episode return: 90.0\n",
      "2021-08-25 10:46:33.546 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.1\n",
      "2021-08-25 10:46:33.547 | INFO     | src.policies:train:109 - Episode 1214\n",
      "2021-08-25 10:46:33.577 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:33.579 | INFO     | src.policies:train:121 - Mean episode return: 86.0\n",
      "2021-08-25 10:46:33.579 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.6\n",
      "2021-08-25 10:46:33.580 | WARNING  | src.policies:train:131 - The actual batch size is 213, instead of 200\n",
      "2021-08-25 10:46:33.586 | INFO     | src.policies:train:157 - Total loss: 486.1581115722656\n",
      "2021-08-25 10:46:33.586 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:33.589 | INFO     | src.policies:train:103 - Epoch 156 / 800\n",
      "2021-08-25 10:46:33.590 | INFO     | src.policies:train:109 - Episode 1215\n",
      "2021-08-25 10:46:33.597 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:33.598 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:33.599 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.57\n",
      "2021-08-25 10:46:33.600 | INFO     | src.policies:train:109 - Episode 1216\n",
      "2021-08-25 10:46:33.607 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:33.609 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:33.609 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.14\n",
      "2021-08-25 10:46:33.610 | INFO     | src.policies:train:109 - Episode 1217\n",
      "2021-08-25 10:46:33.634 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:33.635 | INFO     | src.policies:train:121 - Mean episode return: 62.0\n",
      "2021-08-25 10:46:33.636 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.56\n",
      "2021-08-25 10:46:33.637 | INFO     | src.policies:train:109 - Episode 1218\n",
      "2021-08-25 10:46:33.644 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:33.645 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 10:46:33.646 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.45\n",
      "2021-08-25 10:46:33.647 | INFO     | src.policies:train:109 - Episode 1219\n",
      "2021-08-25 10:46:33.655 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:33.656 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:33.657 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.29\n",
      "2021-08-25 10:46:33.658 | INFO     | src.policies:train:109 - Episode 1220\n",
      "2021-08-25 10:46:33.674 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:33.675 | INFO     | src.policies:train:121 - Mean episode return: 39.0\n",
      "2021-08-25 10:46:33.676 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.38\n",
      "2021-08-25 10:46:33.677 | INFO     | src.policies:train:109 - Episode 1221\n",
      "2021-08-25 10:46:33.685 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:33.686 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:33.687 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.33\n",
      "2021-08-25 10:46:33.687 | INFO     | src.policies:train:109 - Episode 1222\n",
      "2021-08-25 10:46:33.698 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:33.699 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 10:46:33.700 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.04\n",
      "2021-08-25 10:46:33.701 | INFO     | src.policies:train:109 - Episode 1223\n",
      "2021-08-25 10:46:33.708 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:33.709 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:33.710 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.03\n",
      "2021-08-25 10:46:33.711 | WARNING  | src.policies:train:131 - The actual batch size is 202, instead of 200\n",
      "2021-08-25 10:46:33.717 | INFO     | src.policies:train:157 - Total loss: 151.6605224609375\n",
      "2021-08-25 10:46:33.718 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:33.720 | INFO     | src.policies:train:103 - Epoch 157 / 800\n",
      "2021-08-25 10:46:33.721 | INFO     | src.policies:train:109 - Episode 1224\n",
      "2021-08-25 10:46:33.728 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:33.729 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 10:46:33.730 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:33.731 | INFO     | src.policies:train:109 - Episode 1225\n",
      "2021-08-25 10:46:33.751 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:33.752 | INFO     | src.policies:train:121 - Mean episode return: 54.0\n",
      "2021-08-25 10:46:33.753 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.95\n",
      "2021-08-25 10:46:33.754 | INFO     | src.policies:train:109 - Episode 1226\n",
      "2021-08-25 10:46:33.789 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:33.790 | INFO     | src.policies:train:121 - Mean episode return: 99.0\n",
      "2021-08-25 10:46:33.791 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.78\n",
      "2021-08-25 10:46:33.792 | INFO     | src.policies:train:109 - Episode 1227\n",
      "2021-08-25 10:46:33.802 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:33.803 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:33.803 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.67\n",
      "2021-08-25 10:46:33.804 | INFO     | src.policies:train:109 - Episode 1228\n",
      "2021-08-25 10:46:33.827 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:33.828 | INFO     | src.policies:train:121 - Mean episode return: 60.0\n",
      "2021-08-25 10:46:33.829 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.9\n",
      "2021-08-25 10:46:33.830 | WARNING  | src.policies:train:131 - The actual batch size is 249, instead of 200\n",
      "2021-08-25 10:46:33.836 | INFO     | src.policies:train:157 - Total loss: 391.05322265625\n",
      "2021-08-25 10:46:33.837 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:33.839 | INFO     | src.policies:train:103 - Epoch 158 / 800\n",
      "2021-08-25 10:46:33.840 | INFO     | src.policies:train:109 - Episode 1229\n",
      "2021-08-25 10:46:33.850 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:33.851 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 10:46:33.852 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.91\n",
      "2021-08-25 10:46:33.853 | INFO     | src.policies:train:109 - Episode 1230\n",
      "2021-08-25 10:46:33.879 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:33.880 | INFO     | src.policies:train:121 - Mean episode return: 71.0\n",
      "2021-08-25 10:46:33.881 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.34\n",
      "2021-08-25 10:46:33.882 | INFO     | src.policies:train:109 - Episode 1231\n",
      "2021-08-25 10:46:33.894 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:33.895 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 10:46:33.896 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.5\n",
      "2021-08-25 10:46:33.897 | INFO     | src.policies:train:109 - Episode 1232\n",
      "2021-08-25 10:46:33.913 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:33.914 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 10:46:33.914 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.71\n",
      "2021-08-25 10:46:33.915 | INFO     | src.policies:train:109 - Episode 1233\n",
      "2021-08-25 10:46:33.933 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:33.934 | INFO     | src.policies:train:121 - Mean episode return: 46.0\n",
      "2021-08-25 10:46:33.935 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.62\n",
      "2021-08-25 10:46:33.936 | WARNING  | src.policies:train:131 - The actual batch size is 206, instead of 200\n",
      "2021-08-25 10:46:33.941 | INFO     | src.policies:train:157 - Total loss: 227.73521423339844\n",
      "2021-08-25 10:46:33.942 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:33.945 | INFO     | src.policies:train:103 - Epoch 159 / 800\n",
      "2021-08-25 10:46:33.946 | INFO     | src.policies:train:109 - Episode 1234\n",
      "2021-08-25 10:46:33.953 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:33.955 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:33.955 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.16\n",
      "2021-08-25 10:46:33.956 | INFO     | src.policies:train:109 - Episode 1235\n",
      "2021-08-25 10:46:33.976 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:33.977 | INFO     | src.policies:train:121 - Mean episode return: 56.0\n",
      "2021-08-25 10:46:33.978 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.53\n",
      "2021-08-25 10:46:33.979 | INFO     | src.policies:train:109 - Episode 1236\n",
      "2021-08-25 10:46:33.987 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:33.988 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:33.989 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.54\n",
      "2021-08-25 10:46:33.990 | INFO     | src.policies:train:109 - Episode 1237\n",
      "2021-08-25 10:46:34.006 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:34.007 | INFO     | src.policies:train:121 - Mean episode return: 41.0\n",
      "2021-08-25 10:46:34.008 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.28\n",
      "2021-08-25 10:46:34.009 | INFO     | src.policies:train:109 - Episode 1238\n",
      "2021-08-25 10:46:34.029 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:34.030 | INFO     | src.policies:train:121 - Mean episode return: 53.0\n",
      "2021-08-25 10:46:34.031 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.61\n",
      "2021-08-25 10:46:34.032 | INFO     | src.policies:train:109 - Episode 1239\n",
      "2021-08-25 10:46:34.040 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:34.041 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:34.042 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.63\n",
      "2021-08-25 10:46:34.043 | INFO     | src.policies:train:109 - Episode 1240\n",
      "2021-08-25 10:46:34.059 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:34.060 | INFO     | src.policies:train:121 - Mean episode return: 38.0\n",
      "2021-08-25 10:46:34.060 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.78\n",
      "2021-08-25 10:46:34.061 | WARNING  | src.policies:train:131 - The actual batch size is 234, instead of 200\n",
      "2021-08-25 10:46:34.067 | INFO     | src.policies:train:157 - Total loss: 168.3170928955078\n",
      "2021-08-25 10:46:34.068 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:34.071 | INFO     | src.policies:train:103 - Epoch 160 / 800\n",
      "2021-08-25 10:46:34.072 | INFO     | src.policies:train:109 - Episode 1241\n",
      "2021-08-25 10:46:34.086 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:34.087 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 10:46:34.088 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.78\n",
      "2021-08-25 10:46:34.089 | INFO     | src.policies:train:109 - Episode 1242\n",
      "2021-08-25 10:46:34.098 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:34.099 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:34.100 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.79\n",
      "2021-08-25 10:46:34.101 | INFO     | src.policies:train:109 - Episode 1243\n",
      "2021-08-25 10:46:34.109 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:34.110 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:34.111 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.74\n",
      "2021-08-25 10:46:34.111 | INFO     | src.policies:train:109 - Episode 1244\n",
      "2021-08-25 10:46:34.126 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:34.127 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 10:46:34.128 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.67\n",
      "2021-08-25 10:46:34.129 | INFO     | src.policies:train:109 - Episode 1245\n",
      "2021-08-25 10:46:34.139 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:34.140 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 10:46:34.141 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.33\n",
      "2021-08-25 10:46:34.142 | INFO     | src.policies:train:109 - Episode 1246\n",
      "2021-08-25 10:46:34.152 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:34.154 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 10:46:34.154 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.45\n",
      "2021-08-25 10:46:34.155 | INFO     | src.policies:train:109 - Episode 1247\n",
      "2021-08-25 10:46:34.167 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:34.168 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 10:46:34.169 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.8\n",
      "2021-08-25 10:46:34.170 | INFO     | src.policies:train:109 - Episode 1248\n",
      "2021-08-25 10:46:34.185 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:34.186 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 10:46:34.187 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.0\n",
      "2021-08-25 10:46:34.188 | WARNING  | src.policies:train:131 - The actual batch size is 211, instead of 200\n",
      "2021-08-25 10:46:34.194 | INFO     | src.policies:train:157 - Total loss: 80.82576751708984\n",
      "2021-08-25 10:46:34.195 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:34.198 | INFO     | src.policies:train:103 - Epoch 161 / 800\n",
      "2021-08-25 10:46:34.199 | INFO     | src.policies:train:109 - Episode 1249\n",
      "2021-08-25 10:46:34.243 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:34.244 | INFO     | src.policies:train:121 - Mean episode return: 128.0\n",
      "2021-08-25 10:46:34.245 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.79\n",
      "2021-08-25 10:46:34.246 | INFO     | src.policies:train:109 - Episode 1250\n",
      "2021-08-25 10:46:34.259 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:34.260 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 10:46:34.261 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.97\n",
      "2021-08-25 10:46:34.261 | INFO     | src.policies:train:109 - Episode 1251\n",
      "2021-08-25 10:46:34.277 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:34.278 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 10:46:34.279 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.02\n",
      "2021-08-25 10:46:34.280 | INFO     | src.policies:train:109 - Episode 1252\n",
      "2021-08-25 10:46:34.293 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:34.294 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 10:46:34.295 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.97\n",
      "2021-08-25 10:46:34.296 | WARNING  | src.policies:train:131 - The actual batch size is 223, instead of 200\n",
      "2021-08-25 10:46:34.301 | INFO     | src.policies:train:157 - Total loss: 509.5513000488281\n",
      "2021-08-25 10:46:34.302 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:34.305 | INFO     | src.policies:train:103 - Epoch 162 / 800\n",
      "2021-08-25 10:46:34.306 | INFO     | src.policies:train:109 - Episode 1253\n",
      "2021-08-25 10:46:34.323 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:34.324 | INFO     | src.policies:train:121 - Mean episode return: 49.0\n",
      "2021-08-25 10:46:34.325 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.21\n",
      "2021-08-25 10:46:34.326 | INFO     | src.policies:train:109 - Episode 1254\n",
      "2021-08-25 10:46:34.333 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:34.334 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 10:46:34.335 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.86\n",
      "2021-08-25 10:46:34.336 | INFO     | src.policies:train:109 - Episode 1255\n",
      "2021-08-25 10:46:34.343 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:34.344 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:34.345 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.79\n",
      "2021-08-25 10:46:34.346 | INFO     | src.policies:train:109 - Episode 1256\n",
      "2021-08-25 10:46:34.365 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:34.367 | INFO     | src.policies:train:121 - Mean episode return: 50.0\n",
      "2021-08-25 10:46:34.367 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.12\n",
      "2021-08-25 10:46:34.368 | INFO     | src.policies:train:109 - Episode 1257\n",
      "2021-08-25 10:46:34.386 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:34.387 | INFO     | src.policies:train:121 - Mean episode return: 45.0\n",
      "2021-08-25 10:46:34.388 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.3\n",
      "2021-08-25 10:46:34.389 | INFO     | src.policies:train:109 - Episode 1258\n",
      "2021-08-25 10:46:34.402 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:34.403 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 10:46:34.404 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.39\n",
      "2021-08-25 10:46:34.404 | INFO     | src.policies:train:109 - Episode 1259\n",
      "2021-08-25 10:46:34.413 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:34.414 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:34.415 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.46\n",
      "2021-08-25 10:46:34.416 | WARNING  | src.policies:train:131 - The actual batch size is 216, instead of 200\n",
      "2021-08-25 10:46:34.421 | INFO     | src.policies:train:157 - Total loss: 147.2707977294922\n",
      "2021-08-25 10:46:34.422 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:34.425 | INFO     | src.policies:train:103 - Epoch 163 / 800\n",
      "2021-08-25 10:46:34.426 | INFO     | src.policies:train:109 - Episode 1260\n",
      "2021-08-25 10:46:34.434 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:34.435 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 10:46:34.436 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.48\n",
      "2021-08-25 10:46:34.437 | INFO     | src.policies:train:109 - Episode 1261\n",
      "2021-08-25 10:46:34.448 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:34.449 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 10:46:34.450 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.1\n",
      "2021-08-25 10:46:34.451 | INFO     | src.policies:train:109 - Episode 1262\n",
      "2021-08-25 10:46:34.463 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:34.464 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 10:46:34.465 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.13\n",
      "2021-08-25 10:46:34.466 | INFO     | src.policies:train:109 - Episode 1263\n",
      "2021-08-25 10:46:34.472 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:34.473 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:34.474 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:34.475 | INFO     | src.policies:train:109 - Episode 1264\n",
      "2021-08-25 10:46:34.493 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:34.494 | INFO     | src.policies:train:121 - Mean episode return: 47.0\n",
      "2021-08-25 10:46:34.495 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.1\n",
      "2021-08-25 10:46:34.496 | INFO     | src.policies:train:109 - Episode 1265\n",
      "2021-08-25 10:46:34.516 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:34.517 | INFO     | src.policies:train:121 - Mean episode return: 52.0\n",
      "2021-08-25 10:46:34.518 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.83\n",
      "2021-08-25 10:46:34.519 | INFO     | src.policies:train:109 - Episode 1266\n",
      "2021-08-25 10:46:34.539 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:34.540 | INFO     | src.policies:train:121 - Mean episode return: 51.0\n",
      "2021-08-25 10:46:34.541 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.62\n",
      "2021-08-25 10:46:34.542 | WARNING  | src.policies:train:131 - The actual batch size is 227, instead of 200\n",
      "2021-08-25 10:46:34.548 | INFO     | src.policies:train:157 - Total loss: 156.1541290283203\n",
      "2021-08-25 10:46:34.549 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:34.552 | INFO     | src.policies:train:103 - Epoch 164 / 800\n",
      "2021-08-25 10:46:34.553 | INFO     | src.policies:train:109 - Episode 1267\n",
      "2021-08-25 10:46:34.574 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:34.575 | INFO     | src.policies:train:121 - Mean episode return: 61.0\n",
      "2021-08-25 10:46:34.576 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.97\n",
      "2021-08-25 10:46:34.577 | INFO     | src.policies:train:109 - Episode 1268\n",
      "2021-08-25 10:46:34.586 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:34.587 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 10:46:34.587 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.7\n",
      "2021-08-25 10:46:34.588 | INFO     | src.policies:train:109 - Episode 1269\n",
      "2021-08-25 10:46:34.598 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:34.599 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 10:46:34.600 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.6\n",
      "2021-08-25 10:46:34.601 | INFO     | src.policies:train:109 - Episode 1270\n",
      "2021-08-25 10:46:34.624 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:34.625 | INFO     | src.policies:train:121 - Mean episode return: 60.0\n",
      "2021-08-25 10:46:34.626 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.05\n",
      "2021-08-25 10:46:34.627 | INFO     | src.policies:train:109 - Episode 1271\n",
      "2021-08-25 10:46:34.643 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:34.644 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 10:46:34.645 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.03\n",
      "2021-08-25 10:46:34.646 | INFO     | src.policies:train:109 - Episode 1272\n",
      "2021-08-25 10:46:34.658 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:34.659 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 10:46:34.659 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.3\n",
      "2021-08-25 10:46:34.660 | WARNING  | src.policies:train:131 - The actual batch size is 220, instead of 200\n",
      "2021-08-25 10:46:34.666 | INFO     | src.policies:train:157 - Total loss: 188.23358154296875\n",
      "2021-08-25 10:46:34.667 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:34.670 | INFO     | src.policies:train:103 - Epoch 165 / 800\n",
      "2021-08-25 10:46:34.671 | INFO     | src.policies:train:109 - Episode 1273\n",
      "2021-08-25 10:46:34.681 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:34.683 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 10:46:34.683 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.37\n",
      "2021-08-25 10:46:34.684 | INFO     | src.policies:train:109 - Episode 1274\n",
      "2021-08-25 10:46:34.695 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:34.696 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 10:46:34.697 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.27\n",
      "2021-08-25 10:46:34.698 | INFO     | src.policies:train:109 - Episode 1275\n",
      "2021-08-25 10:46:34.714 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:34.715 | INFO     | src.policies:train:121 - Mean episode return: 41.0\n",
      "2021-08-25 10:46:34.716 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.34\n",
      "2021-08-25 10:46:34.716 | INFO     | src.policies:train:109 - Episode 1276\n",
      "2021-08-25 10:46:34.728 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:34.729 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 10:46:34.730 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.36\n",
      "2021-08-25 10:46:34.731 | INFO     | src.policies:train:109 - Episode 1277\n",
      "2021-08-25 10:46:34.742 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:34.743 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 10:46:34.744 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.44\n",
      "2021-08-25 10:46:34.745 | INFO     | src.policies:train:109 - Episode 1278\n",
      "2021-08-25 10:46:34.754 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:34.755 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:34.756 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.42\n",
      "2021-08-25 10:46:34.756 | INFO     | src.policies:train:109 - Episode 1279\n",
      "2021-08-25 10:46:34.763 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:34.764 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:34.765 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.94\n",
      "2021-08-25 10:46:34.766 | INFO     | src.policies:train:109 - Episode 1280\n",
      "2021-08-25 10:46:34.788 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:34.789 | INFO     | src.policies:train:121 - Mean episode return: 56.0\n",
      "2021-08-25 10:46:34.790 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.38\n",
      "2021-08-25 10:46:34.791 | WARNING  | src.policies:train:131 - The actual batch size is 227, instead of 200\n",
      "2021-08-25 10:46:34.797 | INFO     | src.policies:train:157 - Total loss: 114.34687805175781\n",
      "2021-08-25 10:46:34.797 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:34.800 | INFO     | src.policies:train:103 - Epoch 166 / 800\n",
      "2021-08-25 10:46:34.801 | INFO     | src.policies:train:109 - Episode 1281\n",
      "2021-08-25 10:46:34.809 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:34.810 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 10:46:34.811 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.42\n",
      "2021-08-25 10:46:34.812 | INFO     | src.policies:train:109 - Episode 1282\n",
      "2021-08-25 10:46:34.824 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:34.825 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 10:46:34.825 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.54\n",
      "2021-08-25 10:46:34.826 | INFO     | src.policies:train:109 - Episode 1283\n",
      "2021-08-25 10:46:34.837 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:34.838 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 10:46:34.839 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.49\n",
      "2021-08-25 10:46:34.840 | INFO     | src.policies:train:109 - Episode 1284\n",
      "2021-08-25 10:46:34.857 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:34.858 | INFO     | src.policies:train:121 - Mean episode return: 43.0\n",
      "2021-08-25 10:46:34.858 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.68\n",
      "2021-08-25 10:46:34.859 | INFO     | src.policies:train:109 - Episode 1285\n",
      "2021-08-25 10:46:34.871 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:34.872 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 10:46:34.873 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.26\n",
      "2021-08-25 10:46:34.873 | INFO     | src.policies:train:109 - Episode 1286\n",
      "2021-08-25 10:46:34.882 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:34.883 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 10:46:34.884 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.31\n",
      "2021-08-25 10:46:34.884 | INFO     | src.policies:train:109 - Episode 1287\n",
      "2021-08-25 10:46:34.904 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:34.905 | INFO     | src.policies:train:121 - Mean episode return: 49.0\n",
      "2021-08-25 10:46:34.906 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.69\n",
      "2021-08-25 10:46:34.906 | INFO     | src.policies:train:109 - Episode 1288\n",
      "2021-08-25 10:46:34.968 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:34.969 | INFO     | src.policies:train:121 - Mean episode return: 179.0\n",
      "2021-08-25 10:46:34.970 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.35\n",
      "2021-08-25 10:46:34.971 | WARNING  | src.policies:train:131 - The actual batch size is 378, instead of 200\n",
      "2021-08-25 10:46:34.977 | INFO     | src.policies:train:157 - Total loss: 515.5435180664062\n",
      "2021-08-25 10:46:34.978 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:34.981 | INFO     | src.policies:train:103 - Epoch 167 / 800\n",
      "2021-08-25 10:46:34.982 | INFO     | src.policies:train:109 - Episode 1289\n",
      "2021-08-25 10:46:34.995 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:34.997 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 10:46:34.998 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.59\n",
      "2021-08-25 10:46:34.998 | INFO     | src.policies:train:109 - Episode 1290\n",
      "2021-08-25 10:46:35.008 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:35.009 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 10:46:35.010 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.48\n",
      "2021-08-25 10:46:35.011 | INFO     | src.policies:train:109 - Episode 1291\n",
      "2021-08-25 10:46:35.030 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:35.031 | INFO     | src.policies:train:121 - Mean episode return: 48.0\n",
      "2021-08-25 10:46:35.032 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.63\n",
      "2021-08-25 10:46:35.032 | INFO     | src.policies:train:109 - Episode 1292\n",
      "2021-08-25 10:46:35.043 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:35.045 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:35.046 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.65\n",
      "2021-08-25 10:46:35.046 | INFO     | src.policies:train:109 - Episode 1293\n",
      "2021-08-25 10:46:35.061 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:35.062 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 10:46:35.063 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.95\n",
      "2021-08-25 10:46:35.064 | INFO     | src.policies:train:109 - Episode 1294\n",
      "2021-08-25 10:46:35.072 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:35.073 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:35.074 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.88\n",
      "2021-08-25 10:46:35.075 | INFO     | src.policies:train:109 - Episode 1295\n",
      "2021-08-25 10:46:35.084 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:35.085 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 10:46:35.086 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.29\n",
      "2021-08-25 10:46:35.087 | INFO     | src.policies:train:109 - Episode 1296\n",
      "2021-08-25 10:46:35.113 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:35.114 | INFO     | src.policies:train:121 - Mean episode return: 67.0\n",
      "2021-08-25 10:46:35.115 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.67\n",
      "2021-08-25 10:46:35.116 | WARNING  | src.policies:train:131 - The actual batch size is 249, instead of 200\n",
      "2021-08-25 10:46:35.124 | INFO     | src.policies:train:157 - Total loss: 158.91603088378906\n",
      "2021-08-25 10:46:35.125 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:35.129 | INFO     | src.policies:train:103 - Epoch 168 / 800\n",
      "2021-08-25 10:46:35.130 | INFO     | src.policies:train:109 - Episode 1297\n",
      "2021-08-25 10:46:35.139 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:35.141 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:35.141 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.58\n",
      "2021-08-25 10:46:35.143 | INFO     | src.policies:train:109 - Episode 1298\n",
      "2021-08-25 10:46:35.152 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:35.153 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:35.155 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.48\n",
      "2021-08-25 10:46:35.155 | INFO     | src.policies:train:109 - Episode 1299\n",
      "2021-08-25 10:46:35.186 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:35.187 | INFO     | src.policies:train:121 - Mean episode return: 75.0\n",
      "2021-08-25 10:46:35.188 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.89\n",
      "2021-08-25 10:46:35.189 | INFO     | src.policies:train:109 - Episode 1300\n",
      "2021-08-25 10:46:35.209 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:35.211 | INFO     | src.policies:train:121 - Mean episode return: 44.0\n",
      "2021-08-25 10:46:35.212 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.14\n",
      "2021-08-25 10:46:35.213 | INFO     | src.policies:train:109 - Episode 1301\n",
      "2021-08-25 10:46:35.223 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:35.224 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:35.225 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.03\n",
      "2021-08-25 10:46:35.226 | INFO     | src.policies:train:109 - Episode 1302\n",
      "2021-08-25 10:46:35.247 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:35.248 | INFO     | src.policies:train:121 - Mean episode return: 47.0\n",
      "2021-08-25 10:46:35.249 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.27\n",
      "2021-08-25 10:46:35.250 | WARNING  | src.policies:train:131 - The actual batch size is 215, instead of 200\n",
      "2021-08-25 10:46:35.255 | INFO     | src.policies:train:157 - Total loss: 227.83450317382812\n",
      "2021-08-25 10:46:35.256 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:35.259 | INFO     | src.policies:train:103 - Epoch 169 / 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:35.260 | INFO     | src.policies:train:109 - Episode 1303\n",
      "2021-08-25 10:46:35.266 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:35.267 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:35.268 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.25\n",
      "2021-08-25 10:46:35.269 | INFO     | src.policies:train:109 - Episode 1304\n",
      "2021-08-25 10:46:35.282 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:35.283 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 10:46:35.284 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.24\n",
      "2021-08-25 10:46:35.285 | INFO     | src.policies:train:109 - Episode 1305\n",
      "2021-08-25 10:46:35.295 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:35.296 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 10:46:35.297 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.89\n",
      "2021-08-25 10:46:35.298 | INFO     | src.policies:train:109 - Episode 1306\n",
      "2021-08-25 10:46:35.310 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:35.311 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 10:46:35.312 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.82\n",
      "2021-08-25 10:46:35.313 | INFO     | src.policies:train:109 - Episode 1307\n",
      "2021-08-25 10:46:35.320 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:35.321 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:35.322 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.72\n",
      "2021-08-25 10:46:35.323 | INFO     | src.policies:train:109 - Episode 1308\n",
      "2021-08-25 10:46:35.341 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:35.342 | INFO     | src.policies:train:121 - Mean episode return: 47.0\n",
      "2021-08-25 10:46:35.342 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.92\n",
      "2021-08-25 10:46:35.343 | INFO     | src.policies:train:109 - Episode 1309\n",
      "2021-08-25 10:46:35.355 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:35.356 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 10:46:35.357 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.03\n",
      "2021-08-25 10:46:35.358 | INFO     | src.policies:train:109 - Episode 1310\n",
      "2021-08-25 10:46:35.366 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:35.367 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:35.367 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.96\n",
      "2021-08-25 10:46:35.368 | INFO     | src.policies:train:109 - Episode 1311\n",
      "2021-08-25 10:46:35.380 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:35.381 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 10:46:35.382 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.85\n",
      "2021-08-25 10:46:35.383 | WARNING  | src.policies:train:131 - The actual batch size is 215, instead of 200\n",
      "2021-08-25 10:46:35.389 | INFO     | src.policies:train:157 - Total loss: 78.03144073486328\n",
      "2021-08-25 10:46:35.390 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:35.392 | INFO     | src.policies:train:103 - Epoch 170 / 800\n",
      "2021-08-25 10:46:35.393 | INFO     | src.policies:train:109 - Episode 1312\n",
      "2021-08-25 10:46:35.413 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:35.414 | INFO     | src.policies:train:121 - Mean episode return: 58.0\n",
      "2021-08-25 10:46:35.415 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.06\n",
      "2021-08-25 10:46:35.416 | INFO     | src.policies:train:109 - Episode 1313\n",
      "2021-08-25 10:46:35.424 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:35.425 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:35.425 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.31\n",
      "2021-08-25 10:46:35.426 | INFO     | src.policies:train:109 - Episode 1314\n",
      "2021-08-25 10:46:35.439 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:35.440 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 10:46:35.441 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.76\n",
      "2021-08-25 10:46:35.442 | INFO     | src.policies:train:109 - Episode 1315\n",
      "2021-08-25 10:46:35.452 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:35.453 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:35.453 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.8\n",
      "2021-08-25 10:46:35.454 | INFO     | src.policies:train:109 - Episode 1316\n",
      "2021-08-25 10:46:35.465 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:35.466 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 10:46:35.467 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.91\n",
      "2021-08-25 10:46:35.468 | INFO     | src.policies:train:109 - Episode 1317\n",
      "2021-08-25 10:46:35.475 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:35.476 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 10:46:35.476 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.4\n",
      "2021-08-25 10:46:35.477 | INFO     | src.policies:train:109 - Episode 1318\n",
      "2021-08-25 10:46:35.488 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:35.489 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 10:46:35.490 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.53\n",
      "2021-08-25 10:46:35.491 | INFO     | src.policies:train:109 - Episode 1319\n",
      "2021-08-25 10:46:35.512 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:35.513 | INFO     | src.policies:train:121 - Mean episode return: 54.0\n",
      "2021-08-25 10:46:35.513 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.93\n",
      "2021-08-25 10:46:35.514 | WARNING  | src.policies:train:131 - The actual batch size is 236, instead of 200\n",
      "2021-08-25 10:46:35.521 | INFO     | src.policies:train:157 - Total loss: 136.74884033203125\n",
      "2021-08-25 10:46:35.522 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:35.525 | INFO     | src.policies:train:103 - Epoch 171 / 800\n",
      "2021-08-25 10:46:35.526 | INFO     | src.policies:train:109 - Episode 1320\n",
      "2021-08-25 10:46:35.539 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:35.541 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 10:46:35.541 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.91\n",
      "2021-08-25 10:46:35.542 | INFO     | src.policies:train:109 - Episode 1321\n",
      "2021-08-25 10:46:35.550 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:35.551 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:35.552 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.9\n",
      "2021-08-25 10:46:35.553 | INFO     | src.policies:train:109 - Episode 1322\n",
      "2021-08-25 10:46:35.561 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:35.562 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 10:46:35.563 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.85\n",
      "2021-08-25 10:46:35.564 | INFO     | src.policies:train:109 - Episode 1323\n",
      "2021-08-25 10:46:35.571 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:35.573 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:35.573 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.86\n",
      "2021-08-25 10:46:35.574 | INFO     | src.policies:train:109 - Episode 1324\n",
      "2021-08-25 10:46:35.588 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:35.589 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 10:46:35.589 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.02\n",
      "2021-08-25 10:46:35.590 | INFO     | src.policies:train:109 - Episode 1325\n",
      "2021-08-25 10:46:35.600 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:35.601 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 10:46:35.602 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.68\n",
      "2021-08-25 10:46:35.603 | INFO     | src.policies:train:109 - Episode 1326\n",
      "2021-08-25 10:46:35.609 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:35.610 | INFO     | src.policies:train:121 - Mean episode return: 9.0\n",
      "2021-08-25 10:46:35.611 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.78\n",
      "2021-08-25 10:46:35.612 | INFO     | src.policies:train:109 - Episode 1327\n",
      "2021-08-25 10:46:35.620 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:35.621 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:35.622 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.75\n",
      "2021-08-25 10:46:35.623 | INFO     | src.policies:train:109 - Episode 1328\n",
      "2021-08-25 10:46:35.635 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:35.636 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 10:46:35.636 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.4\n",
      "2021-08-25 10:46:35.637 | INFO     | src.policies:train:109 - Episode 1329\n",
      "2021-08-25 10:46:35.643 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:35.644 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 10:46:35.645 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.28\n",
      "2021-08-25 10:46:35.646 | INFO     | src.policies:train:109 - Episode 1330\n",
      "2021-08-25 10:46:35.657 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:35.658 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 10:46:35.658 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.79\n",
      "2021-08-25 10:46:35.659 | WARNING  | src.policies:train:131 - The actual batch size is 215, instead of 200\n",
      "2021-08-25 10:46:35.665 | INFO     | src.policies:train:157 - Total loss: 58.860572814941406\n",
      "2021-08-25 10:46:35.666 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:35.669 | INFO     | src.policies:train:103 - Epoch 172 / 800\n",
      "2021-08-25 10:46:35.670 | INFO     | src.policies:train:109 - Episode 1331\n",
      "2021-08-25 10:46:35.687 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:35.688 | INFO     | src.policies:train:121 - Mean episode return: 44.0\n",
      "2021-08-25 10:46:35.689 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.96\n",
      "2021-08-25 10:46:35.690 | INFO     | src.policies:train:109 - Episode 1332\n",
      "2021-08-25 10:46:35.697 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:35.698 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:35.699 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.7\n",
      "2021-08-25 10:46:35.700 | INFO     | src.policies:train:109 - Episode 1333\n",
      "2021-08-25 10:46:35.708 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:35.709 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:35.710 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.38\n",
      "2021-08-25 10:46:35.711 | INFO     | src.policies:train:109 - Episode 1334\n",
      "2021-08-25 10:46:35.717 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:35.718 | INFO     | src.policies:train:121 - Mean episode return: 9.0\n",
      "2021-08-25 10:46:35.718 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.31\n",
      "2021-08-25 10:46:35.719 | INFO     | src.policies:train:109 - Episode 1335\n",
      "2021-08-25 10:46:35.755 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:35.756 | INFO     | src.policies:train:121 - Mean episode return: 102.0\n",
      "2021-08-25 10:46:35.757 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.77\n",
      "2021-08-25 10:46:35.758 | INFO     | src.policies:train:109 - Episode 1336\n",
      "2021-08-25 10:46:35.783 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:35.784 | INFO     | src.policies:train:121 - Mean episode return: 66.0\n",
      "2021-08-25 10:46:35.785 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.29\n",
      "2021-08-25 10:46:35.786 | WARNING  | src.policies:train:131 - The actual batch size is 249, instead of 200\n",
      "2021-08-25 10:46:35.791 | INFO     | src.policies:train:157 - Total loss: 367.8017578125\n",
      "2021-08-25 10:46:35.792 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:35.795 | INFO     | src.policies:train:103 - Epoch 173 / 800\n",
      "2021-08-25 10:46:35.796 | INFO     | src.policies:train:109 - Episode 1337\n",
      "2021-08-25 10:46:35.805 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:35.807 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:35.807 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.07\n",
      "2021-08-25 10:46:35.808 | INFO     | src.policies:train:109 - Episode 1338\n",
      "2021-08-25 10:46:35.817 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:35.818 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:35.818 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.7\n",
      "2021-08-25 10:46:35.819 | INFO     | src.policies:train:109 - Episode 1339\n",
      "2021-08-25 10:46:35.828 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:35.830 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:35.830 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.73\n",
      "2021-08-25 10:46:35.831 | INFO     | src.policies:train:109 - Episode 1340\n",
      "2021-08-25 10:46:35.843 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:35.844 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 10:46:35.845 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.62\n",
      "2021-08-25 10:46:35.846 | INFO     | src.policies:train:109 - Episode 1341\n",
      "2021-08-25 10:46:35.855 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:35.856 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:35.857 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.44\n",
      "2021-08-25 10:46:35.857 | INFO     | src.policies:train:109 - Episode 1342\n",
      "2021-08-25 10:46:35.865 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:35.866 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:35.867 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.4\n",
      "2021-08-25 10:46:35.868 | INFO     | src.policies:train:109 - Episode 1343\n",
      "2021-08-25 10:46:35.880 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:35.881 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 10:46:35.882 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:35.883 | INFO     | src.policies:train:109 - Episode 1344\n",
      "2021-08-25 10:46:35.893 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:35.894 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 10:46:35.895 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.4\n",
      "2021-08-25 10:46:35.896 | INFO     | src.policies:train:109 - Episode 1345\n",
      "2021-08-25 10:46:35.915 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:35.916 | INFO     | src.policies:train:121 - Mean episode return: 52.0\n",
      "2021-08-25 10:46:35.917 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.71\n",
      "2021-08-25 10:46:35.918 | WARNING  | src.policies:train:131 - The actual batch size is 215, instead of 200\n",
      "2021-08-25 10:46:35.924 | INFO     | src.policies:train:157 - Total loss: 97.375244140625\n",
      "2021-08-25 10:46:35.925 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:35.928 | INFO     | src.policies:train:103 - Epoch 174 / 800\n",
      "2021-08-25 10:46:35.929 | INFO     | src.policies:train:109 - Episode 1346\n",
      "2021-08-25 10:46:35.947 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:35.949 | INFO     | src.policies:train:121 - Mean episode return: 49.0\n",
      "2021-08-25 10:46:35.950 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.99\n",
      "2021-08-25 10:46:35.950 | INFO     | src.policies:train:109 - Episode 1347\n",
      "2021-08-25 10:46:35.958 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:35.959 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:35.960 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.83\n",
      "2021-08-25 10:46:35.961 | INFO     | src.policies:train:109 - Episode 1348\n",
      "2021-08-25 10:46:35.970 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:35.971 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:35.972 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.65\n",
      "2021-08-25 10:46:35.973 | INFO     | src.policies:train:109 - Episode 1349\n",
      "2021-08-25 10:46:35.979 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:35.980 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 10:46:35.981 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.47\n",
      "2021-08-25 10:46:35.982 | INFO     | src.policies:train:109 - Episode 1350\n",
      "2021-08-25 10:46:35.994 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:35.995 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 10:46:35.996 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.45\n",
      "2021-08-25 10:46:35.997 | INFO     | src.policies:train:109 - Episode 1351\n",
      "2021-08-25 10:46:36.011 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:36.012 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 10:46:36.013 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.46\n",
      "2021-08-25 10:46:36.014 | INFO     | src.policies:train:109 - Episode 1352\n",
      "2021-08-25 10:46:36.022 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:36.023 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:36.024 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.32\n",
      "2021-08-25 10:46:36.025 | INFO     | src.policies:train:109 - Episode 1353\n",
      "2021-08-25 10:46:36.035 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:36.036 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 10:46:36.037 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.05\n",
      "2021-08-25 10:46:36.038 | INFO     | src.policies:train:109 - Episode 1354\n",
      "2021-08-25 10:46:36.053 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:36.054 | INFO     | src.policies:train:121 - Mean episode return: 38.0\n",
      "2021-08-25 10:46:36.055 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.32\n",
      "2021-08-25 10:46:36.056 | WARNING  | src.policies:train:131 - The actual batch size is 230, instead of 200\n",
      "2021-08-25 10:46:36.062 | INFO     | src.policies:train:157 - Total loss: 88.56751251220703\n",
      "2021-08-25 10:46:36.063 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:36.066 | INFO     | src.policies:train:103 - Epoch 175 / 800\n",
      "2021-08-25 10:46:36.067 | INFO     | src.policies:train:109 - Episode 1355\n",
      "2021-08-25 10:46:36.074 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:36.075 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:36.076 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.34\n",
      "2021-08-25 10:46:36.077 | INFO     | src.policies:train:109 - Episode 1356\n",
      "2021-08-25 10:46:36.092 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:36.093 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 10:46:36.094 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.21\n",
      "2021-08-25 10:46:36.095 | INFO     | src.policies:train:109 - Episode 1357\n",
      "2021-08-25 10:46:36.126 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:36.127 | INFO     | src.policies:train:121 - Mean episode return: 91.0\n",
      "2021-08-25 10:46:36.128 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.67\n",
      "2021-08-25 10:46:36.129 | INFO     | src.policies:train:109 - Episode 1358\n",
      "2021-08-25 10:46:36.135 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:36.136 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 10:46:36.137 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.49\n",
      "2021-08-25 10:46:36.138 | INFO     | src.policies:train:109 - Episode 1359\n",
      "2021-08-25 10:46:36.145 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:36.146 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:36.147 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.44\n",
      "2021-08-25 10:46:36.148 | INFO     | src.policies:train:109 - Episode 1360\n",
      "2021-08-25 10:46:36.154 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:36.155 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 10:46:36.156 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.34\n",
      "2021-08-25 10:46:36.157 | INFO     | src.policies:train:109 - Episode 1361\n",
      "2021-08-25 10:46:36.164 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:36.165 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:36.166 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.26\n",
      "2021-08-25 10:46:36.167 | INFO     | src.policies:train:109 - Episode 1362\n",
      "2021-08-25 10:46:36.179 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:36.180 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 10:46:36.181 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.33\n",
      "2021-08-25 10:46:36.182 | WARNING  | src.policies:train:131 - The actual batch size is 222, instead of 200\n",
      "2021-08-25 10:46:36.188 | INFO     | src.policies:train:157 - Total loss: 237.3914031982422\n",
      "2021-08-25 10:46:36.189 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:36.192 | INFO     | src.policies:train:103 - Epoch 176 / 800\n",
      "2021-08-25 10:46:36.193 | INFO     | src.policies:train:109 - Episode 1363\n",
      "2021-08-25 10:46:36.205 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:36.206 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 10:46:36.207 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.54\n",
      "2021-08-25 10:46:36.208 | INFO     | src.policies:train:109 - Episode 1364\n",
      "2021-08-25 10:46:36.228 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:36.229 | INFO     | src.policies:train:121 - Mean episode return: 47.0\n",
      "2021-08-25 10:46:36.229 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.54\n",
      "2021-08-25 10:46:36.230 | INFO     | src.policies:train:109 - Episode 1365\n",
      "2021-08-25 10:46:36.244 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:36.245 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 10:46:36.245 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.31\n",
      "2021-08-25 10:46:36.246 | INFO     | src.policies:train:109 - Episode 1366\n",
      "2021-08-25 10:46:36.256 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:36.258 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:36.259 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.99\n",
      "2021-08-25 10:46:36.259 | INFO     | src.policies:train:109 - Episode 1367\n",
      "2021-08-25 10:46:36.286 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:36.288 | INFO     | src.policies:train:121 - Mean episode return: 74.0\n",
      "2021-08-25 10:46:36.288 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.12\n",
      "2021-08-25 10:46:36.289 | WARNING  | src.policies:train:131 - The actual batch size is 202, instead of 200\n",
      "2021-08-25 10:46:36.295 | INFO     | src.policies:train:157 - Total loss: 200.0775604248047\n",
      "2021-08-25 10:46:36.295 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:36.298 | INFO     | src.policies:train:103 - Epoch 177 / 800\n",
      "2021-08-25 10:46:36.299 | INFO     | src.policies:train:109 - Episode 1368\n",
      "2021-08-25 10:46:36.306 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:36.307 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:36.308 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.09\n",
      "2021-08-25 10:46:36.309 | INFO     | src.policies:train:109 - Episode 1369\n",
      "2021-08-25 10:46:36.324 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:36.325 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 10:46:36.325 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.29\n",
      "2021-08-25 10:46:36.327 | INFO     | src.policies:train:109 - Episode 1370\n",
      "2021-08-25 10:46:36.333 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:36.335 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:36.335 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.81\n",
      "2021-08-25 10:46:36.336 | INFO     | src.policies:train:109 - Episode 1371\n",
      "2021-08-25 10:46:36.344 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:36.345 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:36.346 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.58\n",
      "2021-08-25 10:46:36.347 | INFO     | src.policies:train:109 - Episode 1372\n",
      "2021-08-25 10:46:36.364 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:36.366 | INFO     | src.policies:train:121 - Mean episode return: 47.0\n",
      "2021-08-25 10:46:36.366 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.79\n",
      "2021-08-25 10:46:36.367 | INFO     | src.policies:train:109 - Episode 1373\n",
      "2021-08-25 10:46:36.384 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:36.385 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 10:46:36.385 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.93\n",
      "2021-08-25 10:46:36.386 | INFO     | src.policies:train:109 - Episode 1374\n",
      "2021-08-25 10:46:36.401 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:36.402 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 10:46:36.402 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.05\n",
      "2021-08-25 10:46:36.403 | INFO     | src.policies:train:109 - Episode 1375\n",
      "2021-08-25 10:46:36.414 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:36.415 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 10:46:36.416 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.85\n",
      "2021-08-25 10:46:36.417 | WARNING  | src.policies:train:131 - The actual batch size is 220, instead of 200\n",
      "2021-08-25 10:46:36.422 | INFO     | src.policies:train:157 - Total loss: 96.02438354492188\n",
      "2021-08-25 10:46:36.423 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:36.426 | INFO     | src.policies:train:103 - Epoch 178 / 800\n",
      "2021-08-25 10:46:36.427 | INFO     | src.policies:train:109 - Episode 1376\n",
      "2021-08-25 10:46:36.438 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:36.439 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 10:46:36.440 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.83\n",
      "2021-08-25 10:46:36.440 | INFO     | src.policies:train:109 - Episode 1377\n",
      "2021-08-25 10:46:36.455 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:36.457 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 10:46:36.457 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.93\n",
      "2021-08-25 10:46:36.458 | INFO     | src.policies:train:109 - Episode 1378\n",
      "2021-08-25 10:46:36.469 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:36.471 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 10:46:36.471 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.0\n",
      "2021-08-25 10:46:36.472 | INFO     | src.policies:train:109 - Episode 1379\n",
      "2021-08-25 10:46:36.481 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:36.482 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:36.483 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.04\n",
      "2021-08-25 10:46:36.484 | INFO     | src.policies:train:109 - Episode 1380\n",
      "2021-08-25 10:46:36.502 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:36.503 | INFO     | src.policies:train:121 - Mean episode return: 46.0\n",
      "2021-08-25 10:46:36.504 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.94\n",
      "2021-08-25 10:46:36.505 | INFO     | src.policies:train:109 - Episode 1381\n",
      "2021-08-25 10:46:36.515 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:36.517 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 10:46:36.517 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.02\n",
      "2021-08-25 10:46:36.518 | INFO     | src.policies:train:109 - Episode 1382\n",
      "2021-08-25 10:46:36.525 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:36.526 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:36.527 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.86\n",
      "2021-08-25 10:46:36.528 | INFO     | src.policies:train:109 - Episode 1383\n",
      "2021-08-25 10:46:36.543 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:36.544 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 10:46:36.545 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:36.546 | WARNING  | src.policies:train:131 - The actual batch size is 221, instead of 200\n",
      "2021-08-25 10:46:36.552 | INFO     | src.policies:train:157 - Total loss: 74.5862045288086\n",
      "2021-08-25 10:46:36.553 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:36.556 | INFO     | src.policies:train:103 - Epoch 179 / 800\n",
      "2021-08-25 10:46:36.557 | INFO     | src.policies:train:109 - Episode 1384\n",
      "2021-08-25 10:46:36.573 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:36.574 | INFO     | src.policies:train:121 - Mean episode return: 43.0\n",
      "2021-08-25 10:46:36.575 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.0\n",
      "2021-08-25 10:46:36.576 | INFO     | src.policies:train:109 - Episode 1385\n",
      "2021-08-25 10:46:36.587 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:36.588 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 10:46:36.589 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.01\n",
      "2021-08-25 10:46:36.590 | INFO     | src.policies:train:109 - Episode 1386\n",
      "2021-08-25 10:46:36.605 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:36.606 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 10:46:36.607 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.24\n",
      "2021-08-25 10:46:36.608 | INFO     | src.policies:train:109 - Episode 1387\n",
      "2021-08-25 10:46:36.624 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:36.625 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 10:46:36.626 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.11\n",
      "2021-08-25 10:46:36.627 | INFO     | src.policies:train:109 - Episode 1388\n",
      "2021-08-25 10:46:36.638 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:36.639 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 10:46:36.640 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.54\n",
      "2021-08-25 10:46:36.641 | INFO     | src.policies:train:109 - Episode 1389\n",
      "2021-08-25 10:46:36.651 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:36.652 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 10:46:36.653 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.42\n",
      "2021-08-25 10:46:36.654 | INFO     | src.policies:train:109 - Episode 1390\n",
      "2021-08-25 10:46:36.663 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:36.664 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 10:46:36.665 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.43\n",
      "2021-08-25 10:46:36.666 | WARNING  | src.policies:train:131 - The actual batch size is 209, instead of 200\n",
      "2021-08-25 10:46:36.672 | INFO     | src.policies:train:157 - Total loss: 77.87825775146484\n",
      "2021-08-25 10:46:36.673 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:36.675 | INFO     | src.policies:train:103 - Epoch 180 / 800\n",
      "2021-08-25 10:46:36.676 | INFO     | src.policies:train:109 - Episode 1391\n",
      "2021-08-25 10:46:36.691 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:36.692 | INFO     | src.policies:train:121 - Mean episode return: 39.0\n",
      "2021-08-25 10:46:36.693 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.34\n",
      "2021-08-25 10:46:36.694 | INFO     | src.policies:train:109 - Episode 1392\n",
      "2021-08-25 10:46:36.701 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:36.702 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:36.703 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.3\n",
      "2021-08-25 10:46:36.704 | INFO     | src.policies:train:109 - Episode 1393\n",
      "2021-08-25 10:46:36.720 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:36.721 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 10:46:36.722 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.32\n",
      "2021-08-25 10:46:36.723 | INFO     | src.policies:train:109 - Episode 1394\n",
      "2021-08-25 10:46:36.735 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:36.736 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 10:46:36.737 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.42\n",
      "2021-08-25 10:46:36.738 | INFO     | src.policies:train:109 - Episode 1395\n",
      "2021-08-25 10:46:36.749 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:36.750 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 10:46:36.751 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.48\n",
      "2021-08-25 10:46:36.752 | INFO     | src.policies:train:109 - Episode 1396\n",
      "2021-08-25 10:46:36.766 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:36.767 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 10:46:36.768 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.15\n",
      "2021-08-25 10:46:36.769 | INFO     | src.policies:train:109 - Episode 1397\n",
      "2021-08-25 10:46:36.784 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:36.785 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 10:46:36.786 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.32\n",
      "2021-08-25 10:46:36.786 | WARNING  | src.policies:train:131 - The actual batch size is 202, instead of 200\n",
      "2021-08-25 10:46:36.793 | INFO     | src.policies:train:157 - Total loss: 88.199462890625\n",
      "2021-08-25 10:46:36.794 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:36.796 | INFO     | src.policies:train:103 - Epoch 181 / 800\n",
      "2021-08-25 10:46:36.797 | INFO     | src.policies:train:109 - Episode 1398\n",
      "2021-08-25 10:46:36.806 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:36.807 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 10:46:36.808 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.38\n",
      "2021-08-25 10:46:36.809 | INFO     | src.policies:train:109 - Episode 1399\n",
      "2021-08-25 10:46:36.829 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:36.830 | INFO     | src.policies:train:121 - Mean episode return: 53.0\n",
      "2021-08-25 10:46:36.831 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.16\n",
      "2021-08-25 10:46:36.832 | INFO     | src.policies:train:109 - Episode 1400\n",
      "2021-08-25 10:46:36.852 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:36.853 | INFO     | src.policies:train:121 - Mean episode return: 51.0\n",
      "2021-08-25 10:46:36.854 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.23\n",
      "2021-08-25 10:46:36.855 | INFO     | src.policies:train:109 - Episode 1401\n",
      "2021-08-25 10:46:36.864 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:36.865 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 10:46:36.866 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.27\n",
      "2021-08-25 10:46:36.867 | INFO     | src.policies:train:109 - Episode 1402\n",
      "2021-08-25 10:46:36.893 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:36.894 | INFO     | src.policies:train:121 - Mean episode return: 70.0\n",
      "2021-08-25 10:46:36.895 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.5\n",
      "2021-08-25 10:46:36.896 | WARNING  | src.policies:train:131 - The actual batch size is 214, instead of 200\n",
      "2021-08-25 10:46:36.901 | INFO     | src.policies:train:157 - Total loss: 207.70303344726562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:36.902 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:36.905 | INFO     | src.policies:train:103 - Epoch 182 / 800\n",
      "2021-08-25 10:46:36.906 | INFO     | src.policies:train:109 - Episode 1403\n",
      "2021-08-25 10:46:36.935 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:36.936 | INFO     | src.policies:train:121 - Mean episode return: 80.0\n",
      "2021-08-25 10:46:36.937 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.18\n",
      "2021-08-25 10:46:36.938 | INFO     | src.policies:train:109 - Episode 1404\n",
      "2021-08-25 10:46:36.946 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:36.947 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 10:46:36.948 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.07\n",
      "2021-08-25 10:46:36.949 | INFO     | src.policies:train:109 - Episode 1405\n",
      "2021-08-25 10:46:36.974 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:36.975 | INFO     | src.policies:train:121 - Mean episode return: 64.0\n",
      "2021-08-25 10:46:36.975 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.5\n",
      "2021-08-25 10:46:36.976 | INFO     | src.policies:train:109 - Episode 1406\n",
      "2021-08-25 10:46:36.999 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:37.000 | INFO     | src.policies:train:121 - Mean episode return: 58.0\n",
      "2021-08-25 10:46:37.001 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.8\n",
      "2021-08-25 10:46:37.002 | WARNING  | src.policies:train:131 - The actual batch size is 219, instead of 200\n",
      "2021-08-25 10:46:37.009 | INFO     | src.policies:train:157 - Total loss: 306.3534240722656\n",
      "2021-08-25 10:46:37.010 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:37.012 | INFO     | src.policies:train:103 - Epoch 183 / 800\n",
      "2021-08-25 10:46:37.013 | INFO     | src.policies:train:109 - Episode 1407\n",
      "2021-08-25 10:46:37.020 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:37.021 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:37.022 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.81\n",
      "2021-08-25 10:46:37.023 | INFO     | src.policies:train:109 - Episode 1408\n",
      "2021-08-25 10:46:37.037 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:37.038 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 10:46:37.039 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.64\n",
      "2021-08-25 10:46:37.040 | INFO     | src.policies:train:109 - Episode 1409\n",
      "2021-08-25 10:46:37.053 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:37.054 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 10:46:37.054 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.68\n",
      "2021-08-25 10:46:37.055 | INFO     | src.policies:train:109 - Episode 1410\n",
      "2021-08-25 10:46:37.070 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:37.071 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 10:46:37.072 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.87\n",
      "2021-08-25 10:46:37.072 | INFO     | src.policies:train:109 - Episode 1411\n",
      "2021-08-25 10:46:37.080 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:37.081 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:37.082 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.75\n",
      "2021-08-25 10:46:37.083 | INFO     | src.policies:train:109 - Episode 1412\n",
      "2021-08-25 10:46:37.102 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:37.104 | INFO     | src.policies:train:121 - Mean episode return: 52.0\n",
      "2021-08-25 10:46:37.104 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.69\n",
      "2021-08-25 10:46:37.105 | INFO     | src.policies:train:109 - Episode 1413\n",
      "2021-08-25 10:46:37.115 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:37.116 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:37.117 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.73\n",
      "2021-08-25 10:46:37.118 | INFO     | src.policies:train:109 - Episode 1414\n",
      "2021-08-25 10:46:37.131 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:37.133 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 10:46:37.133 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.75\n",
      "2021-08-25 10:46:37.134 | WARNING  | src.policies:train:131 - The actual batch size is 225, instead of 200\n",
      "2021-08-25 10:46:37.140 | INFO     | src.policies:train:157 - Total loss: 87.71559143066406\n",
      "2021-08-25 10:46:37.141 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:37.144 | INFO     | src.policies:train:103 - Epoch 184 / 800\n",
      "2021-08-25 10:46:37.145 | INFO     | src.policies:train:109 - Episode 1415\n",
      "2021-08-25 10:46:37.153 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:37.154 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 10:46:37.155 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.74\n",
      "2021-08-25 10:46:37.156 | INFO     | src.policies:train:109 - Episode 1416\n",
      "2021-08-25 10:46:37.165 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:37.166 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 10:46:37.167 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.71\n",
      "2021-08-25 10:46:37.168 | INFO     | src.policies:train:109 - Episode 1417\n",
      "2021-08-25 10:46:37.178 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:37.179 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:37.179 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.78\n",
      "2021-08-25 10:46:37.180 | INFO     | src.policies:train:109 - Episode 1418\n",
      "2021-08-25 10:46:37.190 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:37.191 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:37.192 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.72\n",
      "2021-08-25 10:46:37.193 | INFO     | src.policies:train:109 - Episode 1419\n",
      "2021-08-25 10:46:37.217 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:37.218 | INFO     | src.policies:train:121 - Mean episode return: 59.0\n",
      "2021-08-25 10:46:37.218 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.77\n",
      "2021-08-25 10:46:37.219 | INFO     | src.policies:train:109 - Episode 1420\n",
      "2021-08-25 10:46:37.228 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:37.229 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:37.229 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.55\n",
      "2021-08-25 10:46:37.230 | INFO     | src.policies:train:109 - Episode 1421\n",
      "2021-08-25 10:46:37.238 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:37.239 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 10:46:37.239 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.54\n",
      "2021-08-25 10:46:37.240 | INFO     | src.policies:train:109 - Episode 1422\n",
      "2021-08-25 10:46:37.261 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:37.262 | INFO     | src.policies:train:121 - Mean episode return: 52.0\n",
      "2021-08-25 10:46:37.263 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.89\n",
      "2021-08-25 10:46:37.264 | WARNING  | src.policies:train:131 - The actual batch size is 212, instead of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:37.270 | INFO     | src.policies:train:157 - Total loss: 122.9393539428711\n",
      "2021-08-25 10:46:37.271 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:37.274 | INFO     | src.policies:train:103 - Epoch 185 / 800\n",
      "2021-08-25 10:46:37.275 | INFO     | src.policies:train:109 - Episode 1423\n",
      "2021-08-25 10:46:37.281 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:37.282 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 10:46:37.283 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.86\n",
      "2021-08-25 10:46:37.284 | INFO     | src.policies:train:109 - Episode 1424\n",
      "2021-08-25 10:46:37.293 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:37.294 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:37.295 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.71\n",
      "2021-08-25 10:46:37.295 | INFO     | src.policies:train:109 - Episode 1425\n",
      "2021-08-25 10:46:37.309 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:37.310 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 10:46:37.310 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.8\n",
      "2021-08-25 10:46:37.311 | INFO     | src.policies:train:109 - Episode 1426\n",
      "2021-08-25 10:46:37.331 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:37.332 | INFO     | src.policies:train:121 - Mean episode return: 52.0\n",
      "2021-08-25 10:46:37.333 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.23\n",
      "2021-08-25 10:46:37.334 | INFO     | src.policies:train:109 - Episode 1427\n",
      "2021-08-25 10:46:37.353 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:37.354 | INFO     | src.policies:train:121 - Mean episode return: 47.0\n",
      "2021-08-25 10:46:37.355 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.54\n",
      "2021-08-25 10:46:37.356 | INFO     | src.policies:train:109 - Episode 1428\n",
      "2021-08-25 10:46:37.367 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:37.369 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 10:46:37.369 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.56\n",
      "2021-08-25 10:46:37.370 | INFO     | src.policies:train:109 - Episode 1429\n",
      "2021-08-25 10:46:37.381 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:37.382 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 10:46:37.383 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.71\n",
      "2021-08-25 10:46:37.384 | WARNING  | src.policies:train:131 - The actual batch size is 209, instead of 200\n",
      "2021-08-25 10:46:37.390 | INFO     | src.policies:train:157 - Total loss: 95.90682983398438\n",
      "2021-08-25 10:46:37.391 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:37.394 | INFO     | src.policies:train:103 - Epoch 186 / 800\n",
      "2021-08-25 10:46:37.395 | INFO     | src.policies:train:109 - Episode 1430\n",
      "2021-08-25 10:46:37.426 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:37.428 | INFO     | src.policies:train:121 - Mean episode return: 93.0\n",
      "2021-08-25 10:46:37.428 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.42\n",
      "2021-08-25 10:46:37.429 | INFO     | src.policies:train:109 - Episode 1431\n",
      "2021-08-25 10:46:37.441 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:37.442 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 10:46:37.443 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.24\n",
      "2021-08-25 10:46:37.444 | INFO     | src.policies:train:109 - Episode 1432\n",
      "2021-08-25 10:46:37.461 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:37.462 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 10:46:37.463 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.5\n",
      "2021-08-25 10:46:37.464 | INFO     | src.policies:train:109 - Episode 1433\n",
      "2021-08-25 10:46:37.473 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:37.474 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 10:46:37.475 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.53\n",
      "2021-08-25 10:46:37.476 | INFO     | src.policies:train:109 - Episode 1434\n",
      "2021-08-25 10:46:37.502 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:37.503 | INFO     | src.policies:train:121 - Mean episode return: 68.0\n",
      "2021-08-25 10:46:37.504 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.12\n",
      "2021-08-25 10:46:37.505 | WARNING  | src.policies:train:131 - The actual batch size is 244, instead of 200\n",
      "2021-08-25 10:46:37.511 | INFO     | src.policies:train:157 - Total loss: 295.802978515625\n",
      "2021-08-25 10:46:37.512 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:37.514 | INFO     | src.policies:train:103 - Epoch 187 / 800\n",
      "2021-08-25 10:46:37.515 | INFO     | src.policies:train:109 - Episode 1435\n",
      "2021-08-25 10:46:37.524 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:37.525 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:37.526 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.29\n",
      "2021-08-25 10:46:37.526 | INFO     | src.policies:train:109 - Episode 1436\n",
      "2021-08-25 10:46:37.540 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:37.541 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 10:46:37.543 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.89\n",
      "2021-08-25 10:46:37.544 | INFO     | src.policies:train:109 - Episode 1437\n",
      "2021-08-25 10:46:37.563 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:37.564 | INFO     | src.policies:train:121 - Mean episode return: 44.0\n",
      "2021-08-25 10:46:37.565 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.14\n",
      "2021-08-25 10:46:37.566 | INFO     | src.policies:train:109 - Episode 1438\n",
      "2021-08-25 10:46:37.582 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:37.584 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 10:46:37.585 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.29\n",
      "2021-08-25 10:46:37.586 | INFO     | src.policies:train:109 - Episode 1439\n",
      "2021-08-25 10:46:37.596 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:37.597 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:37.598 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.25\n",
      "2021-08-25 10:46:37.599 | INFO     | src.policies:train:109 - Episode 1440\n",
      "2021-08-25 10:46:37.617 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:37.618 | INFO     | src.policies:train:121 - Mean episode return: 41.0\n",
      "2021-08-25 10:46:37.619 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.39\n",
      "2021-08-25 10:46:37.620 | INFO     | src.policies:train:109 - Episode 1441\n",
      "2021-08-25 10:46:37.646 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:37.648 | INFO     | src.policies:train:121 - Mean episode return: 58.0\n",
      "2021-08-25 10:46:37.649 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.79\n",
      "2021-08-25 10:46:37.650 | WARNING  | src.policies:train:131 - The actual batch size is 234, instead of 200\n",
      "2021-08-25 10:46:37.658 | INFO     | src.policies:train:157 - Total loss: 120.04643249511719\n",
      "2021-08-25 10:46:37.658 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:37.663 | INFO     | src.policies:train:103 - Epoch 188 / 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:37.664 | INFO     | src.policies:train:109 - Episode 1442\n",
      "2021-08-25 10:46:37.680 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:37.681 | INFO     | src.policies:train:121 - Mean episode return: 38.0\n",
      "2021-08-25 10:46:37.683 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.02\n",
      "2021-08-25 10:46:37.684 | INFO     | src.policies:train:109 - Episode 1443\n",
      "2021-08-25 10:46:37.711 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:37.713 | INFO     | src.policies:train:121 - Mean episode return: 70.0\n",
      "2021-08-25 10:46:37.714 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.43\n",
      "2021-08-25 10:46:37.715 | INFO     | src.policies:train:109 - Episode 1444\n",
      "2021-08-25 10:46:37.725 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:37.727 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:37.728 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.42\n",
      "2021-08-25 10:46:37.729 | INFO     | src.policies:train:109 - Episode 1445\n",
      "2021-08-25 10:46:37.738 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:37.739 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:37.740 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.03\n",
      "2021-08-25 10:46:37.741 | INFO     | src.policies:train:109 - Episode 1446\n",
      "2021-08-25 10:46:37.755 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:37.756 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 10:46:37.757 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.84\n",
      "2021-08-25 10:46:37.758 | INFO     | src.policies:train:109 - Episode 1447\n",
      "2021-08-25 10:46:37.770 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:37.771 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 10:46:37.771 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.96\n",
      "2021-08-25 10:46:37.772 | INFO     | src.policies:train:109 - Episode 1448\n",
      "2021-08-25 10:46:37.788 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:37.790 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 10:46:37.791 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.17\n",
      "2021-08-25 10:46:37.792 | WARNING  | src.policies:train:131 - The actual batch size is 234, instead of 200\n",
      "2021-08-25 10:46:37.799 | INFO     | src.policies:train:157 - Total loss: 142.80828857421875\n",
      "2021-08-25 10:46:37.800 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:37.803 | INFO     | src.policies:train:103 - Epoch 189 / 800\n",
      "2021-08-25 10:46:37.804 | INFO     | src.policies:train:109 - Episode 1449\n",
      "2021-08-25 10:46:37.814 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:37.815 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 10:46:37.816 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.27\n",
      "2021-08-25 10:46:37.817 | INFO     | src.policies:train:109 - Episode 1450\n",
      "2021-08-25 10:46:37.839 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:37.840 | INFO     | src.policies:train:121 - Mean episode return: 60.0\n",
      "2021-08-25 10:46:37.841 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.58\n",
      "2021-08-25 10:46:37.842 | INFO     | src.policies:train:109 - Episode 1451\n",
      "2021-08-25 10:46:37.856 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:37.857 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 10:46:37.858 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.49\n",
      "2021-08-25 10:46:37.859 | INFO     | src.policies:train:109 - Episode 1452\n",
      "2021-08-25 10:46:37.874 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:37.875 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 10:46:37.876 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.65\n",
      "2021-08-25 10:46:37.877 | INFO     | src.policies:train:109 - Episode 1453\n",
      "2021-08-25 10:46:37.894 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:37.895 | INFO     | src.policies:train:121 - Mean episode return: 42.0\n",
      "2021-08-25 10:46:37.896 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.85\n",
      "2021-08-25 10:46:37.897 | INFO     | src.policies:train:109 - Episode 1454\n",
      "2021-08-25 10:46:37.916 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:37.917 | INFO     | src.policies:train:121 - Mean episode return: 43.0\n",
      "2021-08-25 10:46:37.918 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.9\n",
      "2021-08-25 10:46:37.919 | WARNING  | src.policies:train:131 - The actual batch size is 223, instead of 200\n",
      "2021-08-25 10:46:37.926 | INFO     | src.policies:train:157 - Total loss: 119.24531555175781\n",
      "2021-08-25 10:46:37.927 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:37.931 | INFO     | src.policies:train:103 - Epoch 190 / 800\n",
      "2021-08-25 10:46:37.932 | INFO     | src.policies:train:109 - Episode 1455\n",
      "2021-08-25 10:46:37.956 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:37.957 | INFO     | src.policies:train:121 - Mean episode return: 64.0\n",
      "2021-08-25 10:46:37.958 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.38\n",
      "2021-08-25 10:46:37.959 | INFO     | src.policies:train:109 - Episode 1456\n",
      "2021-08-25 10:46:37.990 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:37.991 | INFO     | src.policies:train:121 - Mean episode return: 79.0\n",
      "2021-08-25 10:46:37.992 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.8\n",
      "2021-08-25 10:46:37.992 | INFO     | src.policies:train:109 - Episode 1457\n",
      "2021-08-25 10:46:38.024 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:38.025 | INFO     | src.policies:train:121 - Mean episode return: 81.0\n",
      "2021-08-25 10:46:38.026 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.7\n",
      "2021-08-25 10:46:38.027 | WARNING  | src.policies:train:131 - The actual batch size is 224, instead of 200\n",
      "2021-08-25 10:46:38.033 | INFO     | src.policies:train:157 - Total loss: 335.4512023925781\n",
      "2021-08-25 10:46:38.034 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:38.038 | INFO     | src.policies:train:103 - Epoch 191 / 800\n",
      "2021-08-25 10:46:38.039 | INFO     | src.policies:train:109 - Episode 1458\n",
      "2021-08-25 10:46:38.048 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:38.049 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:38.050 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.76\n",
      "2021-08-25 10:46:38.051 | INFO     | src.policies:train:109 - Episode 1459\n",
      "2021-08-25 10:46:38.070 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:38.071 | INFO     | src.policies:train:121 - Mean episode return: 44.0\n",
      "2021-08-25 10:46:38.072 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.06\n",
      "2021-08-25 10:46:38.074 | INFO     | src.policies:train:109 - Episode 1460\n",
      "2021-08-25 10:46:38.096 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:38.098 | INFO     | src.policies:train:121 - Mean episode return: 57.0\n",
      "2021-08-25 10:46:38.099 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.53\n",
      "2021-08-25 10:46:38.100 | INFO     | src.policies:train:109 - Episode 1461\n",
      "2021-08-25 10:46:38.109 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:38.111 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:38.112 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.53\n",
      "2021-08-25 10:46:38.113 | INFO     | src.policies:train:109 - Episode 1462\n",
      "2021-08-25 10:46:38.131 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:38.132 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 10:46:38.133 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.64\n",
      "2021-08-25 10:46:38.134 | INFO     | src.policies:train:109 - Episode 1463\n",
      "2021-08-25 10:46:38.167 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:38.168 | INFO     | src.policies:train:121 - Mean episode return: 92.0\n",
      "2021-08-25 10:46:38.169 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.23\n",
      "2021-08-25 10:46:38.170 | WARNING  | src.policies:train:131 - The actual batch size is 264, instead of 200\n",
      "2021-08-25 10:46:38.177 | INFO     | src.policies:train:157 - Total loss: 246.56785583496094\n",
      "2021-08-25 10:46:38.178 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:38.182 | INFO     | src.policies:train:103 - Epoch 192 / 800\n",
      "2021-08-25 10:46:38.183 | INFO     | src.policies:train:109 - Episode 1464\n",
      "2021-08-25 10:46:38.217 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:38.218 | INFO     | src.policies:train:121 - Mean episode return: 91.0\n",
      "2021-08-25 10:46:38.219 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.67\n",
      "2021-08-25 10:46:38.220 | INFO     | src.policies:train:109 - Episode 1465\n",
      "2021-08-25 10:46:38.229 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:38.230 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:38.230 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.54\n",
      "2021-08-25 10:46:38.231 | INFO     | src.policies:train:109 - Episode 1466\n",
      "2021-08-25 10:46:38.240 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:38.241 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:38.242 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.54\n",
      "2021-08-25 10:46:38.243 | INFO     | src.policies:train:109 - Episode 1467\n",
      "2021-08-25 10:46:38.257 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:38.258 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 10:46:38.259 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.04\n",
      "2021-08-25 10:46:38.260 | INFO     | src.policies:train:109 - Episode 1468\n",
      "2021-08-25 10:46:38.269 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:38.271 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:38.271 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.02\n",
      "2021-08-25 10:46:38.273 | INFO     | src.policies:train:109 - Episode 1469\n",
      "2021-08-25 10:46:38.286 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:38.287 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 10:46:38.288 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.85\n",
      "2021-08-25 10:46:38.289 | INFO     | src.policies:train:109 - Episode 1470\n",
      "2021-08-25 10:46:38.299 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:38.301 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:38.301 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.86\n",
      "2021-08-25 10:46:38.302 | INFO     | src.policies:train:109 - Episode 1471\n",
      "2021-08-25 10:46:38.318 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:38.320 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 10:46:38.321 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.05\n",
      "2021-08-25 10:46:38.322 | WARNING  | src.policies:train:131 - The actual batch size is 230, instead of 200\n",
      "2021-08-25 10:46:38.330 | INFO     | src.policies:train:157 - Total loss: 208.18679809570312\n",
      "2021-08-25 10:46:38.331 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:38.335 | INFO     | src.policies:train:103 - Epoch 193 / 800\n",
      "2021-08-25 10:46:38.336 | INFO     | src.policies:train:109 - Episode 1472\n",
      "2021-08-25 10:46:38.345 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:38.347 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:38.348 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.76\n",
      "2021-08-25 10:46:38.349 | INFO     | src.policies:train:109 - Episode 1473\n",
      "2021-08-25 10:46:38.375 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:38.376 | INFO     | src.policies:train:121 - Mean episode return: 63.0\n",
      "2021-08-25 10:46:38.377 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.99\n",
      "2021-08-25 10:46:38.378 | INFO     | src.policies:train:109 - Episode 1474\n",
      "2021-08-25 10:46:38.397 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:38.399 | INFO     | src.policies:train:121 - Mean episode return: 42.0\n",
      "2021-08-25 10:46:38.400 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.08\n",
      "2021-08-25 10:46:38.400 | INFO     | src.policies:train:109 - Episode 1475\n",
      "2021-08-25 10:46:38.410 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:38.411 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:38.412 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.0\n",
      "2021-08-25 10:46:38.413 | INFO     | src.policies:train:109 - Episode 1476\n",
      "2021-08-25 10:46:38.445 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:38.446 | INFO     | src.policies:train:121 - Mean episode return: 74.0\n",
      "2021-08-25 10:46:38.447 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.48\n",
      "2021-08-25 10:46:38.448 | WARNING  | src.policies:train:131 - The actual batch size is 210, instead of 200\n",
      "2021-08-25 10:46:38.454 | INFO     | src.policies:train:157 - Total loss: 220.22451782226562\n",
      "2021-08-25 10:46:38.455 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:38.458 | INFO     | src.policies:train:103 - Epoch 194 / 800\n",
      "2021-08-25 10:46:38.460 | INFO     | src.policies:train:109 - Episode 1477\n",
      "2021-08-25 10:46:38.467 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:38.469 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:38.469 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.29\n",
      "2021-08-25 10:46:38.470 | INFO     | src.policies:train:109 - Episode 1478\n",
      "2021-08-25 10:46:38.483 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:38.484 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 10:46:38.485 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.31\n",
      "2021-08-25 10:46:38.486 | INFO     | src.policies:train:109 - Episode 1479\n",
      "2021-08-25 10:46:38.497 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:38.498 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:38.499 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.33\n",
      "2021-08-25 10:46:38.500 | INFO     | src.policies:train:109 - Episode 1480\n",
      "2021-08-25 10:46:38.514 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:38.516 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 10:46:38.517 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:38.518 | INFO     | src.policies:train:109 - Episode 1481\n",
      "2021-08-25 10:46:38.530 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:38.532 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 10:46:38.533 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.12\n",
      "2021-08-25 10:46:38.534 | INFO     | src.policies:train:109 - Episode 1482\n",
      "2021-08-25 10:46:38.556 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:38.558 | INFO     | src.policies:train:121 - Mean episode return: 48.0\n",
      "2021-08-25 10:46:38.559 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.48\n",
      "2021-08-25 10:46:38.560 | INFO     | src.policies:train:109 - Episode 1483\n",
      "2021-08-25 10:46:38.569 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:38.570 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:38.571 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.26\n",
      "2021-08-25 10:46:38.573 | INFO     | src.policies:train:109 - Episode 1484\n",
      "2021-08-25 10:46:38.582 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:38.584 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:38.585 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.98\n",
      "2021-08-25 10:46:38.586 | INFO     | src.policies:train:109 - Episode 1485\n",
      "2021-08-25 10:46:38.601 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:38.602 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 10:46:38.603 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.05\n",
      "2021-08-25 10:46:38.604 | WARNING  | src.policies:train:131 - The actual batch size is 219, instead of 200\n",
      "2021-08-25 10:46:38.613 | INFO     | src.policies:train:157 - Total loss: 62.03734588623047\n",
      "2021-08-25 10:46:38.614 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:38.617 | INFO     | src.policies:train:103 - Epoch 195 / 800\n",
      "2021-08-25 10:46:38.619 | INFO     | src.policies:train:109 - Episode 1486\n",
      "2021-08-25 10:46:38.628 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:38.629 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:38.630 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.83\n",
      "2021-08-25 10:46:38.631 | INFO     | src.policies:train:109 - Episode 1487\n",
      "2021-08-25 10:46:38.652 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:38.653 | INFO     | src.policies:train:121 - Mean episode return: 46.0\n",
      "2021-08-25 10:46:38.654 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.93\n",
      "2021-08-25 10:46:38.655 | INFO     | src.policies:train:109 - Episode 1488\n",
      "2021-08-25 10:46:38.667 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:38.668 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 10:46:38.669 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.91\n",
      "2021-08-25 10:46:38.670 | INFO     | src.policies:train:109 - Episode 1489\n",
      "2021-08-25 10:46:38.683 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:38.684 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 10:46:38.686 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.89\n",
      "2021-08-25 10:46:38.687 | INFO     | src.policies:train:109 - Episode 1490\n",
      "2021-08-25 10:46:38.724 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:38.725 | INFO     | src.policies:train:121 - Mean episode return: 99.0\n",
      "2021-08-25 10:46:38.726 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.67\n",
      "2021-08-25 10:46:38.727 | WARNING  | src.policies:train:131 - The actual batch size is 204, instead of 200\n",
      "2021-08-25 10:46:38.734 | INFO     | src.policies:train:157 - Total loss: 288.6741943359375\n",
      "2021-08-25 10:46:38.735 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:38.739 | INFO     | src.policies:train:103 - Epoch 196 / 800\n",
      "2021-08-25 10:46:38.740 | INFO     | src.policies:train:109 - Episode 1491\n",
      "2021-08-25 10:46:38.763 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:38.765 | INFO     | src.policies:train:121 - Mean episode return: 56.0\n",
      "2021-08-25 10:46:38.766 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.84\n",
      "2021-08-25 10:46:38.767 | INFO     | src.policies:train:109 - Episode 1492\n",
      "2021-08-25 10:46:38.780 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:38.782 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 10:46:38.783 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.97\n",
      "2021-08-25 10:46:38.784 | INFO     | src.policies:train:109 - Episode 1493\n",
      "2021-08-25 10:46:38.808 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:38.810 | INFO     | src.policies:train:121 - Mean episode return: 58.0\n",
      "2021-08-25 10:46:38.810 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.21\n",
      "2021-08-25 10:46:38.812 | INFO     | src.policies:train:109 - Episode 1494\n",
      "2021-08-25 10:46:38.823 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:38.824 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:38.825 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.13\n",
      "2021-08-25 10:46:38.826 | INFO     | src.policies:train:109 - Episode 1495\n",
      "2021-08-25 10:46:38.848 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:38.849 | INFO     | src.policies:train:121 - Mean episode return: 48.0\n",
      "2021-08-25 10:46:38.850 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.38\n",
      "2021-08-25 10:46:38.852 | WARNING  | src.policies:train:131 - The actual batch size is 203, instead of 200\n",
      "2021-08-25 10:46:38.858 | INFO     | src.policies:train:157 - Total loss: 149.23507690429688\n",
      "2021-08-25 10:46:38.859 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:38.863 | INFO     | src.policies:train:103 - Epoch 197 / 800\n",
      "2021-08-25 10:46:38.864 | INFO     | src.policies:train:109 - Episode 1496\n",
      "2021-08-25 10:46:38.874 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:38.876 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:38.877 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.23\n",
      "2021-08-25 10:46:38.878 | INFO     | src.policies:train:109 - Episode 1497\n",
      "2021-08-25 10:46:38.888 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:38.889 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:38.890 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.01\n",
      "2021-08-25 10:46:38.891 | INFO     | src.policies:train:109 - Episode 1498\n",
      "2021-08-25 10:46:38.916 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:38.917 | INFO     | src.policies:train:121 - Mean episode return: 61.0\n",
      "2021-08-25 10:46:38.918 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.42\n",
      "2021-08-25 10:46:38.919 | INFO     | src.policies:train:109 - Episode 1499\n",
      "2021-08-25 10:46:38.935 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:38.937 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 10:46:38.938 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.2\n",
      "2021-08-25 10:46:38.940 | INFO     | src.policies:train:109 - Episode 1500\n",
      "2021-08-25 10:46:38.962 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:38.963 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 10:46:38.965 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.09\n",
      "2021-08-25 10:46:38.966 | INFO     | src.policies:train:109 - Episode 1501\n",
      "2021-08-25 10:46:38.974 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:38.975 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:38.976 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.03\n",
      "2021-08-25 10:46:38.976 | INFO     | src.policies:train:109 - Episode 1502\n",
      "2021-08-25 10:46:38.990 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:38.992 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 10:46:38.993 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.64\n",
      "2021-08-25 10:46:38.995 | WARNING  | src.policies:train:131 - The actual batch size is 210, instead of 200\n",
      "2021-08-25 10:46:39.002 | INFO     | src.policies:train:157 - Total loss: 97.57564544677734\n",
      "2021-08-25 10:46:39.003 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:39.006 | INFO     | src.policies:train:103 - Epoch 198 / 800\n",
      "2021-08-25 10:46:39.007 | INFO     | src.policies:train:109 - Episode 1503\n",
      "2021-08-25 10:46:39.031 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:39.032 | INFO     | src.policies:train:121 - Mean episode return: 58.0\n",
      "2021-08-25 10:46:39.032 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.42\n",
      "2021-08-25 10:46:39.033 | INFO     | src.policies:train:109 - Episode 1504\n",
      "2021-08-25 10:46:39.043 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:39.044 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:39.045 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.44\n",
      "2021-08-25 10:46:39.046 | INFO     | src.policies:train:109 - Episode 1505\n",
      "2021-08-25 10:46:39.081 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:39.082 | INFO     | src.policies:train:121 - Mean episode return: 93.0\n",
      "2021-08-25 10:46:39.083 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.73\n",
      "2021-08-25 10:46:39.084 | INFO     | src.policies:train:109 - Episode 1506\n",
      "2021-08-25 10:46:39.110 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:39.111 | INFO     | src.policies:train:121 - Mean episode return: 73.0\n",
      "2021-08-25 10:46:39.112 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.88\n",
      "2021-08-25 10:46:39.113 | WARNING  | src.policies:train:131 - The actual batch size is 243, instead of 200\n",
      "2021-08-25 10:46:39.119 | INFO     | src.policies:train:157 - Total loss: 339.05999755859375\n",
      "2021-08-25 10:46:39.120 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:39.123 | INFO     | src.policies:train:103 - Epoch 199 / 800\n",
      "2021-08-25 10:46:39.124 | INFO     | src.policies:train:109 - Episode 1507\n",
      "2021-08-25 10:46:39.131 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:39.132 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:39.133 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.89\n",
      "2021-08-25 10:46:39.134 | INFO     | src.policies:train:109 - Episode 1508\n",
      "2021-08-25 10:46:39.170 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:39.171 | INFO     | src.policies:train:121 - Mean episode return: 95.0\n",
      "2021-08-25 10:46:39.172 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.54\n",
      "2021-08-25 10:46:39.173 | INFO     | src.policies:train:109 - Episode 1509\n",
      "2021-08-25 10:46:39.186 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:39.187 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 10:46:39.188 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.51\n",
      "2021-08-25 10:46:39.189 | INFO     | src.policies:train:109 - Episode 1510\n",
      "2021-08-25 10:46:39.223 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:39.224 | INFO     | src.policies:train:121 - Mean episode return: 93.0\n",
      "2021-08-25 10:46:39.225 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.12\n",
      "2021-08-25 10:46:39.226 | WARNING  | src.policies:train:131 - The actual batch size is 230, instead of 200\n",
      "2021-08-25 10:46:39.231 | INFO     | src.policies:train:157 - Total loss: 381.20989990234375\n",
      "2021-08-25 10:46:39.232 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:39.235 | INFO     | src.policies:train:103 - Epoch 200 / 800\n",
      "2021-08-25 10:46:39.236 | INFO     | src.policies:train:109 - Episode 1511\n",
      "2021-08-25 10:46:39.257 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:39.258 | INFO     | src.policies:train:121 - Mean episode return: 53.0\n",
      "2021-08-25 10:46:39.259 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.5\n",
      "2021-08-25 10:46:39.260 | INFO     | src.policies:train:109 - Episode 1512\n",
      "2021-08-25 10:46:39.278 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:39.280 | INFO     | src.policies:train:121 - Mean episode return: 44.0\n",
      "2021-08-25 10:46:39.280 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.42\n",
      "2021-08-25 10:46:39.281 | INFO     | src.policies:train:109 - Episode 1513\n",
      "2021-08-25 10:46:39.290 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:39.291 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:39.292 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.37\n",
      "2021-08-25 10:46:39.293 | INFO     | src.policies:train:109 - Episode 1514\n",
      "2021-08-25 10:46:39.303 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:39.304 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 10:46:39.305 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.24\n",
      "2021-08-25 10:46:39.306 | INFO     | src.policies:train:109 - Episode 1515\n",
      "2021-08-25 10:46:39.328 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:39.329 | INFO     | src.policies:train:121 - Mean episode return: 52.0\n",
      "2021-08-25 10:46:39.330 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.59\n",
      "2021-08-25 10:46:39.331 | INFO     | src.policies:train:109 - Episode 1516\n",
      "2021-08-25 10:46:39.346 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:39.347 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 10:46:39.348 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.72\n",
      "2021-08-25 10:46:39.349 | WARNING  | src.policies:train:131 - The actual batch size is 218, instead of 200\n",
      "2021-08-25 10:46:39.355 | INFO     | src.policies:train:157 - Total loss: 107.73350524902344\n",
      "2021-08-25 10:46:39.356 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:39.358 | INFO     | src.policies:train:103 - Epoch 201 / 800\n",
      "2021-08-25 10:46:39.359 | INFO     | src.policies:train:109 - Episode 1517\n",
      "2021-08-25 10:46:39.366 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:39.368 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:39.368 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.68\n",
      "2021-08-25 10:46:39.369 | INFO     | src.policies:train:109 - Episode 1518\n",
      "2021-08-25 10:46:39.376 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:39.377 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 10:46:39.378 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:39.379 | INFO     | src.policies:train:109 - Episode 1519\n",
      "2021-08-25 10:46:39.389 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:39.390 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:39.391 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.21\n",
      "2021-08-25 10:46:39.392 | INFO     | src.policies:train:109 - Episode 1520\n",
      "2021-08-25 10:46:39.402 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:39.404 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 10:46:39.404 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.26\n",
      "2021-08-25 10:46:39.405 | INFO     | src.policies:train:109 - Episode 1521\n",
      "2021-08-25 10:46:39.426 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:39.428 | INFO     | src.policies:train:121 - Mean episode return: 51.0\n",
      "2021-08-25 10:46:39.428 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.66\n",
      "2021-08-25 10:46:39.429 | INFO     | src.policies:train:109 - Episode 1522\n",
      "2021-08-25 10:46:39.447 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:39.448 | INFO     | src.policies:train:121 - Mean episode return: 43.0\n",
      "2021-08-25 10:46:39.449 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.57\n",
      "2021-08-25 10:46:39.450 | INFO     | src.policies:train:109 - Episode 1523\n",
      "2021-08-25 10:46:39.456 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:39.458 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 10:46:39.458 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.57\n",
      "2021-08-25 10:46:39.459 | INFO     | src.policies:train:109 - Episode 1524\n",
      "2021-08-25 10:46:39.473 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:39.474 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 10:46:39.475 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.69\n",
      "2021-08-25 10:46:39.476 | INFO     | src.policies:train:109 - Episode 1525\n",
      "2021-08-25 10:46:39.489 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:39.490 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 10:46:39.491 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.69\n",
      "2021-08-25 10:46:39.491 | WARNING  | src.policies:train:131 - The actual batch size is 228, instead of 200\n",
      "2021-08-25 10:46:39.498 | INFO     | src.policies:train:157 - Total loss: 69.3198471069336\n",
      "2021-08-25 10:46:39.498 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:39.501 | INFO     | src.policies:train:103 - Epoch 202 / 800\n",
      "2021-08-25 10:46:39.502 | INFO     | src.policies:train:109 - Episode 1526\n",
      "2021-08-25 10:46:39.512 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:39.513 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 10:46:39.514 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.38\n",
      "2021-08-25 10:46:39.515 | INFO     | src.policies:train:109 - Episode 1527\n",
      "2021-08-25 10:46:39.523 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:39.524 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:39.525 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.09\n",
      "2021-08-25 10:46:39.526 | INFO     | src.policies:train:109 - Episode 1528\n",
      "2021-08-25 10:46:39.550 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:39.551 | INFO     | src.policies:train:121 - Mean episode return: 58.0\n",
      "2021-08-25 10:46:39.551 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.4\n",
      "2021-08-25 10:46:39.552 | INFO     | src.policies:train:109 - Episode 1529\n",
      "2021-08-25 10:46:39.563 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:39.565 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 10:46:39.566 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.38\n",
      "2021-08-25 10:46:39.568 | INFO     | src.policies:train:109 - Episode 1530\n",
      "2021-08-25 10:46:39.601 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:39.602 | INFO     | src.policies:train:121 - Mean episode return: 75.0\n",
      "2021-08-25 10:46:39.603 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.2\n",
      "2021-08-25 10:46:39.604 | INFO     | src.policies:train:109 - Episode 1531\n",
      "2021-08-25 10:46:39.640 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:39.641 | INFO     | src.policies:train:121 - Mean episode return: 99.0\n",
      "2021-08-25 10:46:39.642 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.93\n",
      "2021-08-25 10:46:39.643 | WARNING  | src.policies:train:131 - The actual batch size is 294, instead of 200\n",
      "2021-08-25 10:46:39.649 | INFO     | src.policies:train:157 - Total loss: 283.2779541015625\n",
      "2021-08-25 10:46:39.650 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:39.653 | INFO     | src.policies:train:103 - Epoch 203 / 800\n",
      "2021-08-25 10:46:39.654 | INFO     | src.policies:train:109 - Episode 1532\n",
      "2021-08-25 10:46:39.666 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:39.668 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 10:46:39.669 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.82\n",
      "2021-08-25 10:46:39.670 | INFO     | src.policies:train:109 - Episode 1533\n",
      "2021-08-25 10:46:39.682 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:39.683 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 10:46:39.684 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.9\n",
      "2021-08-25 10:46:39.685 | INFO     | src.policies:train:109 - Episode 1534\n",
      "2021-08-25 10:46:39.695 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:39.696 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:39.697 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.4\n",
      "2021-08-25 10:46:39.698 | INFO     | src.policies:train:109 - Episode 1535\n",
      "2021-08-25 10:46:39.713 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:39.715 | INFO     | src.policies:train:121 - Mean episode return: 38.0\n",
      "2021-08-25 10:46:39.716 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.59\n",
      "2021-08-25 10:46:39.717 | INFO     | src.policies:train:109 - Episode 1536\n",
      "2021-08-25 10:46:39.729 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:39.731 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 10:46:39.731 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.59\n",
      "2021-08-25 10:46:39.732 | INFO     | src.policies:train:109 - Episode 1537\n",
      "2021-08-25 10:46:39.745 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:39.746 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 10:46:39.747 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.44\n",
      "2021-08-25 10:46:39.748 | INFO     | src.policies:train:109 - Episode 1538\n",
      "2021-08-25 10:46:39.768 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:39.769 | INFO     | src.policies:train:121 - Mean episode return: 47.0\n",
      "2021-08-25 10:46:39.770 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.6\n",
      "2021-08-25 10:46:39.771 | WARNING  | src.policies:train:131 - The actual batch size is 212, instead of 200\n",
      "2021-08-25 10:46:39.777 | INFO     | src.policies:train:157 - Total loss: 72.46162414550781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:39.777 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:39.780 | INFO     | src.policies:train:103 - Epoch 204 / 800\n",
      "2021-08-25 10:46:39.781 | INFO     | src.policies:train:109 - Episode 1539\n",
      "2021-08-25 10:46:39.792 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:39.793 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 10:46:39.794 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.71\n",
      "2021-08-25 10:46:39.795 | INFO     | src.policies:train:109 - Episode 1540\n",
      "2021-08-25 10:46:39.839 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:39.840 | INFO     | src.policies:train:121 - Mean episode return: 122.0\n",
      "2021-08-25 10:46:39.841 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.52\n",
      "2021-08-25 10:46:39.842 | INFO     | src.policies:train:109 - Episode 1541\n",
      "2021-08-25 10:46:39.854 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:39.855 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 10:46:39.856 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.2\n",
      "2021-08-25 10:46:39.857 | INFO     | src.policies:train:109 - Episode 1542\n",
      "2021-08-25 10:46:39.866 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:39.868 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 10:46:39.869 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.02\n",
      "2021-08-25 10:46:39.869 | INFO     | src.policies:train:109 - Episode 1543\n",
      "2021-08-25 10:46:39.886 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:39.888 | INFO     | src.policies:train:121 - Mean episode return: 41.0\n",
      "2021-08-25 10:46:39.888 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.73\n",
      "2021-08-25 10:46:39.889 | WARNING  | src.policies:train:131 - The actual batch size is 235, instead of 200\n",
      "2021-08-25 10:46:39.895 | INFO     | src.policies:train:157 - Total loss: 343.5040588378906\n",
      "2021-08-25 10:46:39.895 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:39.899 | INFO     | src.policies:train:103 - Epoch 205 / 800\n",
      "2021-08-25 10:46:39.900 | INFO     | src.policies:train:109 - Episode 1544\n",
      "2021-08-25 10:46:39.905 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:39.906 | INFO     | src.policies:train:121 - Mean episode return: 9.0\n",
      "2021-08-25 10:46:39.907 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.63\n",
      "2021-08-25 10:46:39.908 | INFO     | src.policies:train:109 - Episode 1545\n",
      "2021-08-25 10:46:39.948 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:39.949 | INFO     | src.policies:train:121 - Mean episode return: 110.0\n",
      "2021-08-25 10:46:39.950 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.6\n",
      "2021-08-25 10:46:39.951 | INFO     | src.policies:train:109 - Episode 1546\n",
      "2021-08-25 10:46:39.976 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:39.977 | INFO     | src.policies:train:121 - Mean episode return: 66.0\n",
      "2021-08-25 10:46:39.978 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.96\n",
      "2021-08-25 10:46:39.978 | INFO     | src.policies:train:109 - Episode 1547\n",
      "2021-08-25 10:46:39.990 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:39.991 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 10:46:39.992 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.96\n",
      "2021-08-25 10:46:39.993 | WARNING  | src.policies:train:131 - The actual batch size is 209, instead of 200\n",
      "2021-08-25 10:46:39.999 | INFO     | src.policies:train:157 - Total loss: 328.2129211425781\n",
      "2021-08-25 10:46:40.000 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:40.003 | INFO     | src.policies:train:103 - Epoch 206 / 800\n",
      "2021-08-25 10:46:40.004 | INFO     | src.policies:train:109 - Episode 1548\n",
      "2021-08-25 10:46:40.014 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:40.015 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 10:46:40.016 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.79\n",
      "2021-08-25 10:46:40.017 | INFO     | src.policies:train:109 - Episode 1549\n",
      "2021-08-25 10:46:40.025 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:40.026 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:40.026 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.72\n",
      "2021-08-25 10:46:40.027 | INFO     | src.policies:train:109 - Episode 1550\n",
      "2021-08-25 10:46:40.047 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:40.048 | INFO     | src.policies:train:121 - Mean episode return: 47.0\n",
      "2021-08-25 10:46:40.048 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.59\n",
      "2021-08-25 10:46:40.050 | INFO     | src.policies:train:109 - Episode 1551\n",
      "2021-08-25 10:46:40.059 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:40.060 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 10:46:40.061 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.49\n",
      "2021-08-25 10:46:40.062 | INFO     | src.policies:train:109 - Episode 1552\n",
      "2021-08-25 10:46:40.076 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:40.077 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 10:46:40.078 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.49\n",
      "2021-08-25 10:46:40.079 | INFO     | src.policies:train:109 - Episode 1553\n",
      "2021-08-25 10:46:40.099 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:40.101 | INFO     | src.policies:train:121 - Mean episode return: 50.0\n",
      "2021-08-25 10:46:40.102 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.57\n",
      "2021-08-25 10:46:40.102 | INFO     | src.policies:train:109 - Episode 1554\n",
      "2021-08-25 10:46:40.117 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:40.118 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 10:46:40.119 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.48\n",
      "2021-08-25 10:46:40.120 | WARNING  | src.policies:train:131 - The actual batch size is 215, instead of 200\n",
      "2021-08-25 10:46:40.126 | INFO     | src.policies:train:157 - Total loss: 86.85428619384766\n",
      "2021-08-25 10:46:40.127 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:40.130 | INFO     | src.policies:train:103 - Epoch 207 / 800\n",
      "2021-08-25 10:46:40.132 | INFO     | src.policies:train:109 - Episode 1555\n",
      "2021-08-25 10:46:40.141 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:40.142 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 10:46:40.143 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.06\n",
      "2021-08-25 10:46:40.144 | INFO     | src.policies:train:109 - Episode 1556\n",
      "2021-08-25 10:46:40.152 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:40.154 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:40.154 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.41\n",
      "2021-08-25 10:46:40.155 | INFO     | src.policies:train:109 - Episode 1557\n",
      "2021-08-25 10:46:40.161 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:40.162 | INFO     | src.policies:train:121 - Mean episode return: 9.0\n",
      "2021-08-25 10:46:40.163 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.69\n",
      "2021-08-25 10:46:40.164 | INFO     | src.policies:train:109 - Episode 1558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:40.194 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:40.195 | INFO     | src.policies:train:121 - Mean episode return: 84.0\n",
      "2021-08-25 10:46:40.196 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.37\n",
      "2021-08-25 10:46:40.197 | INFO     | src.policies:train:109 - Episode 1559\n",
      "2021-08-25 10:46:40.210 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:40.211 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 10:46:40.212 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.26\n",
      "2021-08-25 10:46:40.213 | INFO     | src.policies:train:109 - Episode 1560\n",
      "2021-08-25 10:46:40.229 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:40.230 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 10:46:40.230 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.05\n",
      "2021-08-25 10:46:40.231 | INFO     | src.policies:train:109 - Episode 1561\n",
      "2021-08-25 10:46:40.245 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:40.246 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 10:46:40.246 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.21\n",
      "2021-08-25 10:46:40.247 | WARNING  | src.policies:train:131 - The actual batch size is 229, instead of 200\n",
      "2021-08-25 10:46:40.254 | INFO     | src.policies:train:157 - Total loss: 160.0940704345703\n",
      "2021-08-25 10:46:40.255 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:40.258 | INFO     | src.policies:train:103 - Epoch 208 / 800\n",
      "2021-08-25 10:46:40.259 | INFO     | src.policies:train:109 - Episode 1562\n",
      "2021-08-25 10:46:40.270 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:40.271 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 10:46:40.272 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.07\n",
      "2021-08-25 10:46:40.273 | INFO     | src.policies:train:109 - Episode 1563\n",
      "2021-08-25 10:46:40.297 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:40.298 | INFO     | src.policies:train:121 - Mean episode return: 65.0\n",
      "2021-08-25 10:46:40.299 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.8\n",
      "2021-08-25 10:46:40.300 | INFO     | src.policies:train:109 - Episode 1564\n",
      "2021-08-25 10:46:40.311 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:40.312 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 10:46:40.313 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.12\n",
      "2021-08-25 10:46:40.314 | INFO     | src.policies:train:109 - Episode 1565\n",
      "2021-08-25 10:46:40.322 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:40.323 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:40.324 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.12\n",
      "2021-08-25 10:46:40.325 | INFO     | src.policies:train:109 - Episode 1566\n",
      "2021-08-25 10:46:40.337 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:40.338 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 10:46:40.339 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.2\n",
      "2021-08-25 10:46:40.340 | INFO     | src.policies:train:109 - Episode 1567\n",
      "2021-08-25 10:46:40.347 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:40.348 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 10:46:40.349 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.07\n",
      "2021-08-25 10:46:40.350 | INFO     | src.policies:train:109 - Episode 1568\n",
      "2021-08-25 10:46:40.362 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:40.363 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 10:46:40.363 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.2\n",
      "2021-08-25 10:46:40.364 | INFO     | src.policies:train:109 - Episode 1569\n",
      "2021-08-25 10:46:40.390 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:40.391 | INFO     | src.policies:train:121 - Mean episode return: 68.0\n",
      "2021-08-25 10:46:40.392 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.65\n",
      "2021-08-25 10:46:40.393 | WARNING  | src.policies:train:131 - The actual batch size is 261, instead of 200\n",
      "2021-08-25 10:46:40.399 | INFO     | src.policies:train:157 - Total loss: 159.98028564453125\n",
      "2021-08-25 10:46:40.400 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:40.403 | INFO     | src.policies:train:103 - Epoch 209 / 800\n",
      "2021-08-25 10:46:40.404 | INFO     | src.policies:train:109 - Episode 1570\n",
      "2021-08-25 10:46:40.418 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:40.419 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 10:46:40.420 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.85\n",
      "2021-08-25 10:46:40.420 | INFO     | src.policies:train:109 - Episode 1571\n",
      "2021-08-25 10:46:40.427 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:40.428 | INFO     | src.policies:train:121 - Mean episode return: 8.0\n",
      "2021-08-25 10:46:40.429 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.61\n",
      "2021-08-25 10:46:40.430 | INFO     | src.policies:train:109 - Episode 1572\n",
      "2021-08-25 10:46:40.440 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:40.441 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 10:46:40.442 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.65\n",
      "2021-08-25 10:46:40.443 | INFO     | src.policies:train:109 - Episode 1573\n",
      "2021-08-25 10:46:40.461 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:40.462 | INFO     | src.policies:train:121 - Mean episode return: 42.0\n",
      "2021-08-25 10:46:40.463 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.44\n",
      "2021-08-25 10:46:40.464 | INFO     | src.policies:train:109 - Episode 1574\n",
      "2021-08-25 10:46:40.499 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:40.500 | INFO     | src.policies:train:121 - Mean episode return: 99.0\n",
      "2021-08-25 10:46:40.501 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.01\n",
      "2021-08-25 10:46:40.502 | WARNING  | src.policies:train:131 - The actual batch size is 204, instead of 200\n",
      "2021-08-25 10:46:40.509 | INFO     | src.policies:train:157 - Total loss: 273.21221923828125\n",
      "2021-08-25 10:46:40.509 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:40.513 | INFO     | src.policies:train:103 - Epoch 210 / 800\n",
      "2021-08-25 10:46:40.514 | INFO     | src.policies:train:109 - Episode 1575\n",
      "2021-08-25 10:46:40.529 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:40.531 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 10:46:40.532 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.25\n",
      "2021-08-25 10:46:40.533 | INFO     | src.policies:train:109 - Episode 1576\n",
      "2021-08-25 10:46:40.543 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:40.544 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:40.545 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.7\n",
      "2021-08-25 10:46:40.546 | INFO     | src.policies:train:109 - Episode 1577\n",
      "2021-08-25 10:46:40.573 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:40.574 | INFO     | src.policies:train:121 - Mean episode return: 70.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:40.575 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.25\n",
      "2021-08-25 10:46:40.576 | INFO     | src.policies:train:109 - Episode 1578\n",
      "2021-08-25 10:46:40.596 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:40.597 | INFO     | src.policies:train:121 - Mean episode return: 49.0\n",
      "2021-08-25 10:46:40.598 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.46\n",
      "2021-08-25 10:46:40.599 | INFO     | src.policies:train:109 - Episode 1579\n",
      "2021-08-25 10:46:40.614 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:40.615 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 10:46:40.616 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.63\n",
      "2021-08-25 10:46:40.617 | WARNING  | src.policies:train:131 - The actual batch size is 210, instead of 200\n",
      "2021-08-25 10:46:40.622 | INFO     | src.policies:train:157 - Total loss: 132.21112060546875\n",
      "2021-08-25 10:46:40.623 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:40.626 | INFO     | src.policies:train:103 - Epoch 211 / 800\n",
      "2021-08-25 10:46:40.627 | INFO     | src.policies:train:109 - Episode 1580\n",
      "2021-08-25 10:46:40.633 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:40.634 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 10:46:40.635 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.47\n",
      "2021-08-25 10:46:40.636 | INFO     | src.policies:train:109 - Episode 1581\n",
      "2021-08-25 10:46:40.657 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:40.658 | INFO     | src.policies:train:121 - Mean episode return: 53.0\n",
      "2021-08-25 10:46:40.659 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.77\n",
      "2021-08-25 10:46:40.660 | INFO     | src.policies:train:109 - Episode 1582\n",
      "2021-08-25 10:46:40.673 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:40.674 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 10:46:40.674 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.54\n",
      "2021-08-25 10:46:40.675 | INFO     | src.policies:train:109 - Episode 1583\n",
      "2021-08-25 10:46:40.689 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:40.690 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 10:46:40.691 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.72\n",
      "2021-08-25 10:46:40.692 | INFO     | src.policies:train:109 - Episode 1584\n",
      "2021-08-25 10:46:40.708 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:40.709 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 10:46:40.710 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.93\n",
      "2021-08-25 10:46:40.711 | INFO     | src.policies:train:109 - Episode 1585\n",
      "2021-08-25 10:46:40.724 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:40.725 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 10:46:40.726 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.92\n",
      "2021-08-25 10:46:40.727 | INFO     | src.policies:train:109 - Episode 1586\n",
      "2021-08-25 10:46:40.748 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:40.749 | INFO     | src.policies:train:121 - Mean episode return: 50.0\n",
      "2021-08-25 10:46:40.750 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.24\n",
      "2021-08-25 10:46:40.751 | WARNING  | src.policies:train:131 - The actual batch size is 237, instead of 200\n",
      "2021-08-25 10:46:40.757 | INFO     | src.policies:train:157 - Total loss: 92.20679473876953\n",
      "2021-08-25 10:46:40.758 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:40.761 | INFO     | src.policies:train:103 - Epoch 212 / 800\n",
      "2021-08-25 10:46:40.762 | INFO     | src.policies:train:109 - Episode 1587\n",
      "2021-08-25 10:46:40.787 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:40.789 | INFO     | src.policies:train:121 - Mean episode return: 68.0\n",
      "2021-08-25 10:46:40.789 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.46\n",
      "2021-08-25 10:46:40.791 | INFO     | src.policies:train:109 - Episode 1588\n",
      "2021-08-25 10:46:40.809 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:40.810 | INFO     | src.policies:train:121 - Mean episode return: 43.0\n",
      "2021-08-25 10:46:40.811 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.69\n",
      "2021-08-25 10:46:40.812 | INFO     | src.policies:train:109 - Episode 1589\n",
      "2021-08-25 10:46:40.822 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:40.824 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 10:46:40.825 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.68\n",
      "2021-08-25 10:46:40.826 | INFO     | src.policies:train:109 - Episode 1590\n",
      "2021-08-25 10:46:40.843 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:40.844 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 10:46:40.845 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.09\n",
      "2021-08-25 10:46:40.846 | INFO     | src.policies:train:109 - Episode 1591\n",
      "2021-08-25 10:46:40.868 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:40.869 | INFO     | src.policies:train:121 - Mean episode return: 57.0\n",
      "2021-08-25 10:46:40.870 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.1\n",
      "2021-08-25 10:46:40.871 | WARNING  | src.policies:train:131 - The actual batch size is 228, instead of 200\n",
      "2021-08-25 10:46:40.877 | INFO     | src.policies:train:157 - Total loss: 140.8994140625\n",
      "2021-08-25 10:46:40.878 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:40.881 | INFO     | src.policies:train:103 - Epoch 213 / 800\n",
      "2021-08-25 10:46:40.882 | INFO     | src.policies:train:109 - Episode 1592\n",
      "2021-08-25 10:46:40.893 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:40.895 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 10:46:40.895 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.11\n",
      "2021-08-25 10:46:40.896 | INFO     | src.policies:train:109 - Episode 1593\n",
      "2021-08-25 10:46:40.914 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:40.915 | INFO     | src.policies:train:121 - Mean episode return: 41.0\n",
      "2021-08-25 10:46:40.916 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.94\n",
      "2021-08-25 10:46:40.917 | INFO     | src.policies:train:109 - Episode 1594\n",
      "2021-08-25 10:46:40.933 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:40.934 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 10:46:40.935 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.13\n",
      "2021-08-25 10:46:40.936 | INFO     | src.policies:train:109 - Episode 1595\n",
      "2021-08-25 10:46:40.961 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:40.962 | INFO     | src.policies:train:121 - Mean episode return: 62.0\n",
      "2021-08-25 10:46:40.963 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.27\n",
      "2021-08-25 10:46:40.964 | INFO     | src.policies:train:109 - Episode 1596\n",
      "2021-08-25 10:46:40.971 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:40.973 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:40.973 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.22\n",
      "2021-08-25 10:46:40.974 | INFO     | src.policies:train:109 - Episode 1597\n",
      "2021-08-25 10:46:41.008 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:41.009 | INFO     | src.policies:train:121 - Mean episode return: 95.0\n",
      "2021-08-25 10:46:41.010 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.03\n",
      "2021-08-25 10:46:41.011 | WARNING  | src.policies:train:131 - The actual batch size is 273, instead of 200\n",
      "2021-08-25 10:46:41.017 | INFO     | src.policies:train:157 - Total loss: 208.55772399902344\n",
      "2021-08-25 10:46:41.018 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:41.021 | INFO     | src.policies:train:103 - Epoch 214 / 800\n",
      "2021-08-25 10:46:41.022 | INFO     | src.policies:train:109 - Episode 1598\n",
      "2021-08-25 10:46:41.045 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:41.046 | INFO     | src.policies:train:121 - Mean episode return: 58.0\n",
      "2021-08-25 10:46:41.047 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.0\n",
      "2021-08-25 10:46:41.048 | INFO     | src.policies:train:109 - Episode 1599\n",
      "2021-08-25 10:46:41.064 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:41.065 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 10:46:41.066 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.05\n",
      "2021-08-25 10:46:41.067 | INFO     | src.policies:train:109 - Episode 1600\n",
      "2021-08-25 10:46:41.095 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:41.097 | INFO     | src.policies:train:121 - Mean episode return: 76.0\n",
      "2021-08-25 10:46:41.097 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.41\n",
      "2021-08-25 10:46:41.098 | INFO     | src.policies:train:109 - Episode 1601\n",
      "2021-08-25 10:46:41.110 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:41.111 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 10:46:41.112 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.53\n",
      "2021-08-25 10:46:41.113 | INFO     | src.policies:train:109 - Episode 1602\n",
      "2021-08-25 10:46:41.126 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:41.127 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 10:46:41.128 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.51\n",
      "2021-08-25 10:46:41.129 | WARNING  | src.policies:train:131 - The actual batch size is 225, instead of 200\n",
      "2021-08-25 10:46:41.134 | INFO     | src.policies:train:157 - Total loss: 155.82843017578125\n",
      "2021-08-25 10:46:41.135 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:41.138 | INFO     | src.policies:train:103 - Epoch 215 / 800\n",
      "2021-08-25 10:46:41.139 | INFO     | src.policies:train:109 - Episode 1603\n",
      "2021-08-25 10:46:41.147 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:41.148 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:41.149 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.12\n",
      "2021-08-25 10:46:41.150 | INFO     | src.policies:train:109 - Episode 1604\n",
      "2021-08-25 10:46:41.165 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:41.166 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 10:46:41.167 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.27\n",
      "2021-08-25 10:46:41.168 | INFO     | src.policies:train:109 - Episode 1605\n",
      "2021-08-25 10:46:41.181 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:41.182 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 10:46:41.183 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.62\n",
      "2021-08-25 10:46:41.184 | INFO     | src.policies:train:109 - Episode 1606\n",
      "2021-08-25 10:46:41.198 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:41.199 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 10:46:41.200 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.19\n",
      "2021-08-25 10:46:41.201 | INFO     | src.policies:train:109 - Episode 1607\n",
      "2021-08-25 10:46:41.220 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:41.221 | INFO     | src.policies:train:121 - Mean episode return: 45.0\n",
      "2021-08-25 10:46:41.222 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.5\n",
      "2021-08-25 10:46:41.223 | INFO     | src.policies:train:109 - Episode 1608\n",
      "2021-08-25 10:46:41.231 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:41.232 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:41.232 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.67\n",
      "2021-08-25 10:46:41.233 | INFO     | src.policies:train:109 - Episode 1609\n",
      "2021-08-25 10:46:41.245 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:41.247 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 10:46:41.248 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.66\n",
      "2021-08-25 10:46:41.249 | INFO     | src.policies:train:109 - Episode 1610\n",
      "2021-08-25 10:46:41.259 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:41.260 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 10:46:41.261 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.94\n",
      "2021-08-25 10:46:41.262 | WARNING  | src.policies:train:131 - The actual batch size is 216, instead of 200\n",
      "2021-08-25 10:46:41.268 | INFO     | src.policies:train:157 - Total loss: 79.84635925292969\n",
      "2021-08-25 10:46:41.268 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:41.272 | INFO     | src.policies:train:103 - Epoch 216 / 800\n",
      "2021-08-25 10:46:41.273 | INFO     | src.policies:train:109 - Episode 1611\n",
      "2021-08-25 10:46:41.283 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:41.284 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 10:46:41.285 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.65\n",
      "2021-08-25 10:46:41.286 | INFO     | src.policies:train:109 - Episode 1612\n",
      "2021-08-25 10:46:41.302 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:41.304 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 10:46:41.304 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.61\n",
      "2021-08-25 10:46:41.305 | INFO     | src.policies:train:109 - Episode 1613\n",
      "2021-08-25 10:46:41.332 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:41.333 | INFO     | src.policies:train:121 - Mean episode return: 64.0\n",
      "2021-08-25 10:46:41.334 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.11\n",
      "2021-08-25 10:46:41.335 | INFO     | src.policies:train:109 - Episode 1614\n",
      "2021-08-25 10:46:41.351 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:41.352 | INFO     | src.policies:train:121 - Mean episode return: 38.0\n",
      "2021-08-25 10:46:41.353 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.29\n",
      "2021-08-25 10:46:41.354 | INFO     | src.policies:train:109 - Episode 1615\n",
      "2021-08-25 10:46:41.367 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:41.368 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 10:46:41.369 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.05\n",
      "2021-08-25 10:46:41.370 | INFO     | src.policies:train:109 - Episode 1616\n",
      "2021-08-25 10:46:41.378 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:41.379 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:41.380 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:41.381 | WARNING  | src.policies:train:131 - The actual batch size is 210, instead of 200\n",
      "2021-08-25 10:46:41.386 | INFO     | src.policies:train:157 - Total loss: 122.40425109863281\n",
      "2021-08-25 10:46:41.387 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:41.390 | INFO     | src.policies:train:103 - Epoch 217 / 800\n",
      "2021-08-25 10:46:41.391 | INFO     | src.policies:train:109 - Episode 1617\n",
      "2021-08-25 10:46:41.403 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:41.404 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 10:46:41.405 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.99\n",
      "2021-08-25 10:46:41.406 | INFO     | src.policies:train:109 - Episode 1618\n",
      "2021-08-25 10:46:41.427 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:41.428 | INFO     | src.policies:train:121 - Mean episode return: 51.0\n",
      "2021-08-25 10:46:41.429 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.39\n",
      "2021-08-25 10:46:41.430 | INFO     | src.policies:train:109 - Episode 1619\n",
      "2021-08-25 10:46:41.440 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:41.441 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 10:46:41.442 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.37\n",
      "2021-08-25 10:46:41.443 | INFO     | src.policies:train:109 - Episode 1620\n",
      "2021-08-25 10:46:41.459 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:41.461 | INFO     | src.policies:train:121 - Mean episode return: 39.0\n",
      "2021-08-25 10:46:41.461 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.56\n",
      "2021-08-25 10:46:41.462 | INFO     | src.policies:train:109 - Episode 1621\n",
      "2021-08-25 10:46:41.471 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:41.472 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:41.473 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.21\n",
      "2021-08-25 10:46:41.474 | INFO     | src.policies:train:109 - Episode 1622\n",
      "2021-08-25 10:46:41.489 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:41.490 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 10:46:41.491 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.13\n",
      "2021-08-25 10:46:41.492 | INFO     | src.policies:train:109 - Episode 1623\n",
      "2021-08-25 10:46:41.501 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:41.502 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:41.503 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.21\n",
      "2021-08-25 10:46:41.504 | WARNING  | src.policies:train:131 - The actual batch size is 204, instead of 200\n",
      "2021-08-25 10:46:41.510 | INFO     | src.policies:train:157 - Total loss: 73.33541107177734\n",
      "2021-08-25 10:46:41.511 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:41.514 | INFO     | src.policies:train:103 - Epoch 218 / 800\n",
      "2021-08-25 10:46:41.515 | INFO     | src.policies:train:109 - Episode 1624\n",
      "2021-08-25 10:46:41.538 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:41.539 | INFO     | src.policies:train:121 - Mean episode return: 64.0\n",
      "2021-08-25 10:46:41.540 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.55\n",
      "2021-08-25 10:46:41.540 | INFO     | src.policies:train:109 - Episode 1625\n",
      "2021-08-25 10:46:41.551 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:41.552 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:41.553 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.45\n",
      "2021-08-25 10:46:41.554 | INFO     | src.policies:train:109 - Episode 1626\n",
      "2021-08-25 10:46:41.561 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:41.562 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:41.563 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.37\n",
      "2021-08-25 10:46:41.564 | INFO     | src.policies:train:109 - Episode 1627\n",
      "2021-08-25 10:46:41.588 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:41.589 | INFO     | src.policies:train:121 - Mean episode return: 58.0\n",
      "2021-08-25 10:46:41.590 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.77\n",
      "2021-08-25 10:46:41.591 | INFO     | src.policies:train:109 - Episode 1628\n",
      "2021-08-25 10:46:41.602 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:41.603 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 10:46:41.604 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.43\n",
      "2021-08-25 10:46:41.605 | INFO     | src.policies:train:109 - Episode 1629\n",
      "2021-08-25 10:46:41.619 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:41.621 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 10:46:41.622 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.54\n",
      "2021-08-25 10:46:41.622 | WARNING  | src.policies:train:131 - The actual batch size is 212, instead of 200\n",
      "2021-08-25 10:46:41.628 | INFO     | src.policies:train:157 - Total loss: 152.19114685058594\n",
      "2021-08-25 10:46:41.629 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:41.632 | INFO     | src.policies:train:103 - Epoch 219 / 800\n",
      "2021-08-25 10:46:41.633 | INFO     | src.policies:train:109 - Episode 1630\n",
      "2021-08-25 10:46:41.646 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:41.647 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 10:46:41.648 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.1\n",
      "2021-08-25 10:46:41.649 | INFO     | src.policies:train:109 - Episode 1631\n",
      "2021-08-25 10:46:41.684 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:41.685 | INFO     | src.policies:train:121 - Mean episode return: 91.0\n",
      "2021-08-25 10:46:41.686 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.02\n",
      "2021-08-25 10:46:41.687 | INFO     | src.policies:train:109 - Episode 1632\n",
      "2021-08-25 10:46:41.705 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:41.707 | INFO     | src.policies:train:121 - Mean episode return: 45.0\n",
      "2021-08-25 10:46:41.707 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.18\n",
      "2021-08-25 10:46:41.708 | INFO     | src.policies:train:109 - Episode 1633\n",
      "2021-08-25 10:46:41.728 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:41.729 | INFO     | src.policies:train:121 - Mean episode return: 47.0\n",
      "2021-08-25 10:46:41.730 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.4\n",
      "2021-08-25 10:46:41.731 | WARNING  | src.policies:train:131 - The actual batch size is 214, instead of 200\n",
      "2021-08-25 10:46:41.737 | INFO     | src.policies:train:157 - Total loss: 234.9607696533203\n",
      "2021-08-25 10:46:41.737 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:41.740 | INFO     | src.policies:train:103 - Epoch 220 / 800\n",
      "2021-08-25 10:46:41.741 | INFO     | src.policies:train:109 - Episode 1634\n",
      "2021-08-25 10:46:41.764 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:41.765 | INFO     | src.policies:train:121 - Mean episode return: 60.0\n",
      "2021-08-25 10:46:41.766 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.82\n",
      "2021-08-25 10:46:41.766 | INFO     | src.policies:train:109 - Episode 1635\n",
      "2021-08-25 10:46:41.787 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:41.789 | INFO     | src.policies:train:121 - Mean episode return: 52.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:41.790 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.96\n",
      "2021-08-25 10:46:41.791 | INFO     | src.policies:train:109 - Episode 1636\n",
      "2021-08-25 10:46:41.804 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:41.805 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 10:46:41.806 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.97\n",
      "2021-08-25 10:46:41.807 | INFO     | src.policies:train:109 - Episode 1637\n",
      "2021-08-25 10:46:41.832 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:41.833 | INFO     | src.policies:train:121 - Mean episode return: 61.0\n",
      "2021-08-25 10:46:41.834 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.29\n",
      "2021-08-25 10:46:41.839 | INFO     | src.policies:train:157 - Total loss: 136.14698791503906\n",
      "2021-08-25 10:46:41.839 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:41.842 | INFO     | src.policies:train:103 - Epoch 221 / 800\n",
      "2021-08-25 10:46:41.843 | INFO     | src.policies:train:109 - Episode 1638\n",
      "2021-08-25 10:46:41.857 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:41.858 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 10:46:41.859 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.17\n",
      "2021-08-25 10:46:41.860 | INFO     | src.policies:train:109 - Episode 1639\n",
      "2021-08-25 10:46:41.874 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:41.875 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 10:46:41.876 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.22\n",
      "2021-08-25 10:46:41.877 | INFO     | src.policies:train:109 - Episode 1640\n",
      "2021-08-25 10:46:41.888 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:41.889 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 10:46:41.890 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.23\n",
      "2021-08-25 10:46:41.891 | INFO     | src.policies:train:109 - Episode 1641\n",
      "2021-08-25 10:46:41.904 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:41.906 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 10:46:41.907 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.28\n",
      "2021-08-25 10:46:41.907 | INFO     | src.policies:train:109 - Episode 1642\n",
      "2021-08-25 10:46:41.917 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:41.918 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:41.919 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.27\n",
      "2021-08-25 10:46:41.920 | INFO     | src.policies:train:109 - Episode 1643\n",
      "2021-08-25 10:46:41.927 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:41.929 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 10:46:41.930 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.97\n",
      "2021-08-25 10:46:41.931 | INFO     | src.policies:train:109 - Episode 1644\n",
      "2021-08-25 10:46:41.949 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:41.950 | INFO     | src.policies:train:121 - Mean episode return: 41.0\n",
      "2021-08-25 10:46:41.951 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.29\n",
      "2021-08-25 10:46:41.952 | INFO     | src.policies:train:109 - Episode 1645\n",
      "2021-08-25 10:46:41.969 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:41.970 | INFO     | src.policies:train:121 - Mean episode return: 38.0\n",
      "2021-08-25 10:46:41.971 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.57\n",
      "2021-08-25 10:46:41.972 | WARNING  | src.policies:train:131 - The actual batch size is 229, instead of 200\n",
      "2021-08-25 10:46:41.977 | INFO     | src.policies:train:157 - Total loss: 58.2230224609375\n",
      "2021-08-25 10:46:41.978 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:41.981 | INFO     | src.policies:train:103 - Epoch 222 / 800\n",
      "2021-08-25 10:46:41.982 | INFO     | src.policies:train:109 - Episode 1646\n",
      "2021-08-25 10:46:42.012 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:42.013 | INFO     | src.policies:train:121 - Mean episode return: 81.0\n",
      "2021-08-25 10:46:42.014 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.72\n",
      "2021-08-25 10:46:42.015 | INFO     | src.policies:train:109 - Episode 1647\n",
      "2021-08-25 10:46:42.027 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:42.028 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 10:46:42.029 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.77\n",
      "2021-08-25 10:46:42.031 | INFO     | src.policies:train:109 - Episode 1648\n",
      "2021-08-25 10:46:42.051 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:42.052 | INFO     | src.policies:train:121 - Mean episode return: 52.0\n",
      "2021-08-25 10:46:42.053 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.06\n",
      "2021-08-25 10:46:42.054 | INFO     | src.policies:train:109 - Episode 1649\n",
      "2021-08-25 10:46:42.071 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:42.072 | INFO     | src.policies:train:121 - Mean episode return: 42.0\n",
      "2021-08-25 10:46:42.073 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.35\n",
      "2021-08-25 10:46:42.074 | WARNING  | src.policies:train:131 - The actual batch size is 204, instead of 200\n",
      "2021-08-25 10:46:42.080 | INFO     | src.policies:train:157 - Total loss: 187.5543212890625\n",
      "2021-08-25 10:46:42.080 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:42.083 | INFO     | src.policies:train:103 - Epoch 223 / 800\n",
      "2021-08-25 10:46:42.084 | INFO     | src.policies:train:109 - Episode 1650\n",
      "2021-08-25 10:46:42.091 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:42.092 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 10:46:42.093 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.99\n",
      "2021-08-25 10:46:42.094 | INFO     | src.policies:train:109 - Episode 1651\n",
      "2021-08-25 10:46:42.104 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:42.105 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 10:46:42.106 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.06\n",
      "2021-08-25 10:46:42.107 | INFO     | src.policies:train:109 - Episode 1652\n",
      "2021-08-25 10:46:42.132 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:42.133 | INFO     | src.policies:train:121 - Mean episode return: 64.0\n",
      "2021-08-25 10:46:42.134 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.39\n",
      "2021-08-25 10:46:42.135 | INFO     | src.policies:train:109 - Episode 1653\n",
      "2021-08-25 10:46:42.159 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:42.160 | INFO     | src.policies:train:121 - Mean episode return: 53.0\n",
      "2021-08-25 10:46:42.161 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.42\n",
      "2021-08-25 10:46:42.163 | INFO     | src.policies:train:109 - Episode 1654\n",
      "2021-08-25 10:46:42.184 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:42.185 | INFO     | src.policies:train:121 - Mean episode return: 49.0\n",
      "2021-08-25 10:46:42.186 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.57\n",
      "2021-08-25 10:46:42.187 | WARNING  | src.policies:train:131 - The actual batch size is 201, instead of 200\n",
      "2021-08-25 10:46:42.193 | INFO     | src.policies:train:157 - Total loss: 150.2071990966797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:42.193 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:42.196 | INFO     | src.policies:train:103 - Epoch 224 / 800\n",
      "2021-08-25 10:46:42.197 | INFO     | src.policies:train:109 - Episode 1655\n",
      "2021-08-25 10:46:42.205 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:42.206 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:42.207 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.51\n",
      "2021-08-25 10:46:42.208 | INFO     | src.policies:train:109 - Episode 1656\n",
      "2021-08-25 10:46:42.221 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:42.222 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 10:46:42.223 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.64\n",
      "2021-08-25 10:46:42.224 | INFO     | src.policies:train:109 - Episode 1657\n",
      "2021-08-25 10:46:42.248 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:42.249 | INFO     | src.policies:train:121 - Mean episode return: 61.0\n",
      "2021-08-25 10:46:42.250 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.16\n",
      "2021-08-25 10:46:42.251 | INFO     | src.policies:train:109 - Episode 1658\n",
      "2021-08-25 10:46:42.259 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:42.260 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:42.261 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.47\n",
      "2021-08-25 10:46:42.262 | INFO     | src.policies:train:109 - Episode 1659\n",
      "2021-08-25 10:46:42.280 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:42.281 | INFO     | src.policies:train:121 - Mean episode return: 43.0\n",
      "2021-08-25 10:46:42.282 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.57\n",
      "2021-08-25 10:46:42.283 | INFO     | src.policies:train:109 - Episode 1660\n",
      "2021-08-25 10:46:42.292 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:42.293 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:42.293 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.36\n",
      "2021-08-25 10:46:42.294 | INFO     | src.policies:train:109 - Episode 1661\n",
      "2021-08-25 10:46:42.317 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:42.318 | INFO     | src.policies:train:121 - Mean episode return: 57.0\n",
      "2021-08-25 10:46:42.319 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.62\n",
      "2021-08-25 10:46:42.320 | WARNING  | src.policies:train:131 - The actual batch size is 234, instead of 200\n",
      "2021-08-25 10:46:42.326 | INFO     | src.policies:train:157 - Total loss: 120.88211822509766\n",
      "2021-08-25 10:46:42.327 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:42.330 | INFO     | src.policies:train:103 - Epoch 225 / 800\n",
      "2021-08-25 10:46:42.331 | INFO     | src.policies:train:109 - Episode 1662\n",
      "2021-08-25 10:46:42.342 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:42.343 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 10:46:42.344 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.63\n",
      "2021-08-25 10:46:42.345 | INFO     | src.policies:train:109 - Episode 1663\n",
      "2021-08-25 10:46:42.354 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:42.355 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:42.355 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.14\n",
      "2021-08-25 10:46:42.356 | INFO     | src.policies:train:109 - Episode 1664\n",
      "2021-08-25 10:46:42.365 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:42.366 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:42.366 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.06\n",
      "2021-08-25 10:46:42.367 | INFO     | src.policies:train:109 - Episode 1665\n",
      "2021-08-25 10:46:42.376 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:42.378 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 10:46:42.378 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.07\n",
      "2021-08-25 10:46:42.379 | INFO     | src.policies:train:109 - Episode 1666\n",
      "2021-08-25 10:46:42.427 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:42.428 | INFO     | src.policies:train:121 - Mean episode return: 128.0\n",
      "2021-08-25 10:46:42.429 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.08\n",
      "2021-08-25 10:46:42.430 | WARNING  | src.policies:train:131 - The actual batch size is 203, instead of 200\n",
      "2021-08-25 10:46:42.435 | INFO     | src.policies:train:157 - Total loss: 394.52349853515625\n",
      "2021-08-25 10:46:42.436 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:42.439 | INFO     | src.policies:train:103 - Epoch 226 / 800\n",
      "2021-08-25 10:46:42.440 | INFO     | src.policies:train:109 - Episode 1667\n",
      "2021-08-25 10:46:42.478 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:42.479 | INFO     | src.policies:train:121 - Mean episode return: 107.0\n",
      "2021-08-25 10:46:42.480 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.04\n",
      "2021-08-25 10:46:42.481 | INFO     | src.policies:train:109 - Episode 1668\n",
      "2021-08-25 10:46:42.490 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:42.491 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:42.492 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.95\n",
      "2021-08-25 10:46:42.493 | INFO     | src.policies:train:109 - Episode 1669\n",
      "2021-08-25 10:46:42.501 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:42.502 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:42.503 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.42\n",
      "2021-08-25 10:46:42.504 | INFO     | src.policies:train:109 - Episode 1670\n",
      "2021-08-25 10:46:42.512 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:42.513 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:42.514 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.24\n",
      "2021-08-25 10:46:42.515 | INFO     | src.policies:train:109 - Episode 1671\n",
      "2021-08-25 10:46:42.535 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:42.536 | INFO     | src.policies:train:121 - Mean episode return: 51.0\n",
      "2021-08-25 10:46:42.537 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.67\n",
      "2021-08-25 10:46:42.538 | WARNING  | src.policies:train:131 - The actual batch size is 204, instead of 200\n",
      "2021-08-25 10:46:42.544 | INFO     | src.policies:train:157 - Total loss: 269.501953125\n",
      "2021-08-25 10:46:42.545 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:42.548 | INFO     | src.policies:train:103 - Epoch 227 / 800\n",
      "2021-08-25 10:46:42.549 | INFO     | src.policies:train:109 - Episode 1672\n",
      "2021-08-25 10:46:42.559 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:42.560 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 10:46:42.561 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.66\n",
      "2021-08-25 10:46:42.562 | INFO     | src.policies:train:109 - Episode 1673\n",
      "2021-08-25 10:46:42.578 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:42.579 | INFO     | src.policies:train:121 - Mean episode return: 39.0\n",
      "2021-08-25 10:46:42.580 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.63\n",
      "2021-08-25 10:46:42.581 | INFO     | src.policies:train:109 - Episode 1674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:42.612 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:42.614 | INFO     | src.policies:train:121 - Mean episode return: 86.0\n",
      "2021-08-25 10:46:42.614 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.5\n",
      "2021-08-25 10:46:42.615 | INFO     | src.policies:train:109 - Episode 1675\n",
      "2021-08-25 10:46:42.625 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:42.626 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 10:46:42.627 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.34\n",
      "2021-08-25 10:46:42.628 | INFO     | src.policies:train:109 - Episode 1676\n",
      "2021-08-25 10:46:42.655 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:42.656 | INFO     | src.policies:train:121 - Mean episode return: 69.0\n",
      "2021-08-25 10:46:42.657 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.84\n",
      "2021-08-25 10:46:42.658 | WARNING  | src.policies:train:131 - The actual batch size is 236, instead of 200\n",
      "2021-08-25 10:46:42.664 | INFO     | src.policies:train:157 - Total loss: 181.57020568847656\n",
      "2021-08-25 10:46:42.665 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:42.667 | INFO     | src.policies:train:103 - Epoch 228 / 800\n",
      "2021-08-25 10:46:42.669 | INFO     | src.policies:train:109 - Episode 1677\n",
      "2021-08-25 10:46:42.691 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:42.693 | INFO     | src.policies:train:121 - Mean episode return: 61.0\n",
      "2021-08-25 10:46:42.693 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.75\n",
      "2021-08-25 10:46:42.694 | INFO     | src.policies:train:109 - Episode 1678\n",
      "2021-08-25 10:46:42.723 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:42.724 | INFO     | src.policies:train:121 - Mean episode return: 75.0\n",
      "2021-08-25 10:46:42.725 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.01\n",
      "2021-08-25 10:46:42.726 | INFO     | src.policies:train:109 - Episode 1679\n",
      "2021-08-25 10:46:42.737 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:42.738 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 10:46:42.739 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.89\n",
      "2021-08-25 10:46:42.740 | INFO     | src.policies:train:109 - Episode 1680\n",
      "2021-08-25 10:46:42.755 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:42.756 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 10:46:42.757 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.14\n",
      "2021-08-25 10:46:42.758 | INFO     | src.policies:train:109 - Episode 1681\n",
      "2021-08-25 10:46:42.765 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:42.766 | INFO     | src.policies:train:121 - Mean episode return: 9.0\n",
      "2021-08-25 10:46:42.767 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.7\n",
      "2021-08-25 10:46:42.768 | WARNING  | src.policies:train:131 - The actual batch size is 204, instead of 200\n",
      "2021-08-25 10:46:42.773 | INFO     | src.policies:train:157 - Total loss: 179.14724731445312\n",
      "2021-08-25 10:46:42.774 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:42.777 | INFO     | src.policies:train:103 - Epoch 229 / 800\n",
      "2021-08-25 10:46:42.778 | INFO     | src.policies:train:109 - Episode 1682\n",
      "2021-08-25 10:46:42.787 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:42.788 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 10:46:42.789 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.67\n",
      "2021-08-25 10:46:42.790 | INFO     | src.policies:train:109 - Episode 1683\n",
      "2021-08-25 10:46:42.815 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:42.817 | INFO     | src.policies:train:121 - Mean episode return: 67.0\n",
      "2021-08-25 10:46:42.817 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.02\n",
      "2021-08-25 10:46:42.818 | INFO     | src.policies:train:109 - Episode 1684\n",
      "2021-08-25 10:46:42.828 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:42.830 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:42.831 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.85\n",
      "2021-08-25 10:46:42.832 | INFO     | src.policies:train:109 - Episode 1685\n",
      "2021-08-25 10:46:42.844 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:42.845 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 10:46:42.846 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.84\n",
      "2021-08-25 10:46:42.848 | INFO     | src.policies:train:109 - Episode 1686\n",
      "2021-08-25 10:46:42.866 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:42.867 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 10:46:42.867 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.74\n",
      "2021-08-25 10:46:42.868 | INFO     | src.policies:train:109 - Episode 1687\n",
      "2021-08-25 10:46:42.887 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:42.888 | INFO     | src.policies:train:121 - Mean episode return: 41.0\n",
      "2021-08-25 10:46:42.888 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.47\n",
      "2021-08-25 10:46:42.889 | WARNING  | src.policies:train:131 - The actual batch size is 218, instead of 200\n",
      "2021-08-25 10:46:42.895 | INFO     | src.policies:train:157 - Total loss: 129.62197875976562\n",
      "2021-08-25 10:46:42.896 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:42.899 | INFO     | src.policies:train:103 - Epoch 230 / 800\n",
      "2021-08-25 10:46:42.900 | INFO     | src.policies:train:109 - Episode 1688\n",
      "2021-08-25 10:46:42.909 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:42.911 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 10:46:42.911 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.26\n",
      "2021-08-25 10:46:42.912 | INFO     | src.policies:train:109 - Episode 1689\n",
      "2021-08-25 10:46:42.920 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:42.921 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:42.922 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.18\n",
      "2021-08-25 10:46:42.923 | INFO     | src.policies:train:109 - Episode 1690\n",
      "2021-08-25 10:46:42.931 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:42.932 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:42.933 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.93\n",
      "2021-08-25 10:46:42.934 | INFO     | src.policies:train:109 - Episode 1691\n",
      "2021-08-25 10:46:42.946 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:42.947 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 10:46:42.948 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.65\n",
      "2021-08-25 10:46:42.949 | INFO     | src.policies:train:109 - Episode 1692\n",
      "2021-08-25 10:46:42.957 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:42.958 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 10:46:42.959 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.5\n",
      "2021-08-25 10:46:42.960 | INFO     | src.policies:train:109 - Episode 1693\n",
      "2021-08-25 10:46:42.971 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:42.972 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:42.973 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.27\n",
      "2021-08-25 10:46:42.974 | INFO     | src.policies:train:109 - Episode 1694\n",
      "2021-08-25 10:46:42.989 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:42.990 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 10:46:42.991 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.29\n",
      "2021-08-25 10:46:42.992 | INFO     | src.policies:train:109 - Episode 1695\n",
      "2021-08-25 10:46:43.005 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:43.006 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 10:46:43.007 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.95\n",
      "2021-08-25 10:46:43.007 | INFO     | src.policies:train:109 - Episode 1696\n",
      "2021-08-25 10:46:43.016 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:43.017 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:43.018 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.97\n",
      "2021-08-25 10:46:43.019 | INFO     | src.policies:train:109 - Episode 1697\n",
      "2021-08-25 10:46:43.027 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:43.028 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:43.029 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.17\n",
      "2021-08-25 10:46:43.030 | WARNING  | src.policies:train:131 - The actual batch size is 203, instead of 200\n",
      "2021-08-25 10:46:43.037 | INFO     | src.policies:train:157 - Total loss: 39.66604232788086\n",
      "2021-08-25 10:46:43.037 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:43.040 | INFO     | src.policies:train:103 - Epoch 231 / 800\n",
      "2021-08-25 10:46:43.041 | INFO     | src.policies:train:109 - Episode 1698\n",
      "2021-08-25 10:46:43.051 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:43.052 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 10:46:43.053 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.79\n",
      "2021-08-25 10:46:43.054 | INFO     | src.policies:train:109 - Episode 1699\n",
      "2021-08-25 10:46:43.060 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:43.061 | INFO     | src.policies:train:121 - Mean episode return: 9.0\n",
      "2021-08-25 10:46:43.062 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.52\n",
      "2021-08-25 10:46:43.063 | INFO     | src.policies:train:109 - Episode 1700\n",
      "2021-08-25 10:46:43.079 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:43.080 | INFO     | src.policies:train:121 - Mean episode return: 38.0\n",
      "2021-08-25 10:46:43.081 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.14\n",
      "2021-08-25 10:46:43.082 | INFO     | src.policies:train:109 - Episode 1701\n",
      "2021-08-25 10:46:43.099 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:43.100 | INFO     | src.policies:train:121 - Mean episode return: 42.0\n",
      "2021-08-25 10:46:43.101 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.3\n",
      "2021-08-25 10:46:43.102 | INFO     | src.policies:train:109 - Episode 1702\n",
      "2021-08-25 10:46:43.112 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:43.113 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:43.114 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.2\n",
      "2021-08-25 10:46:43.115 | INFO     | src.policies:train:109 - Episode 1703\n",
      "2021-08-25 10:46:43.134 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:43.136 | INFO     | src.policies:train:121 - Mean episode return: 47.0\n",
      "2021-08-25 10:46:43.136 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.48\n",
      "2021-08-25 10:46:43.137 | INFO     | src.policies:train:109 - Episode 1704\n",
      "2021-08-25 10:46:43.145 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:43.146 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 10:46:43.146 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.25\n",
      "2021-08-25 10:46:43.147 | INFO     | src.policies:train:109 - Episode 1705\n",
      "2021-08-25 10:46:43.158 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:43.159 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 10:46:43.160 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.17\n",
      "2021-08-25 10:46:43.161 | WARNING  | src.policies:train:131 - The actual batch size is 206, instead of 200\n",
      "2021-08-25 10:46:43.167 | INFO     | src.policies:train:157 - Total loss: 82.05677032470703\n",
      "2021-08-25 10:46:43.168 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:43.171 | INFO     | src.policies:train:103 - Epoch 232 / 800\n",
      "2021-08-25 10:46:43.172 | INFO     | src.policies:train:109 - Episode 1706\n",
      "2021-08-25 10:46:43.191 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:43.192 | INFO     | src.policies:train:121 - Mean episode return: 50.0\n",
      "2021-08-25 10:46:43.193 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.37\n",
      "2021-08-25 10:46:43.194 | INFO     | src.policies:train:109 - Episode 1707\n",
      "2021-08-25 10:46:43.206 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:43.207 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 10:46:43.208 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.18\n",
      "2021-08-25 10:46:43.209 | INFO     | src.policies:train:109 - Episode 1708\n",
      "2021-08-25 10:46:43.217 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:43.218 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:43.219 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.19\n",
      "2021-08-25 10:46:43.220 | INFO     | src.policies:train:109 - Episode 1709\n",
      "2021-08-25 10:46:43.237 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:43.239 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 10:46:43.239 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.29\n",
      "2021-08-25 10:46:43.240 | INFO     | src.policies:train:109 - Episode 1710\n",
      "2021-08-25 10:46:43.248 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:43.249 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:43.250 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.2\n",
      "2021-08-25 10:46:43.251 | INFO     | src.policies:train:109 - Episode 1711\n",
      "2021-08-25 10:46:43.265 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:43.266 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 10:46:43.267 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.25\n",
      "2021-08-25 10:46:43.268 | INFO     | src.policies:train:109 - Episode 1712\n",
      "2021-08-25 10:46:43.292 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:43.293 | INFO     | src.policies:train:121 - Mean episode return: 58.0\n",
      "2021-08-25 10:46:43.294 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.43\n",
      "2021-08-25 10:46:43.295 | WARNING  | src.policies:train:131 - The actual batch size is 225, instead of 200\n",
      "2021-08-25 10:46:43.301 | INFO     | src.policies:train:157 - Total loss: 102.3057861328125\n",
      "2021-08-25 10:46:43.301 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:43.304 | INFO     | src.policies:train:103 - Epoch 233 / 800\n",
      "2021-08-25 10:46:43.305 | INFO     | src.policies:train:109 - Episode 1713\n",
      "2021-08-25 10:46:43.312 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:43.313 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:43.314 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.92\n",
      "2021-08-25 10:46:43.315 | INFO     | src.policies:train:109 - Episode 1714\n",
      "2021-08-25 10:46:43.324 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:43.325 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 10:46:43.326 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.74\n",
      "2021-08-25 10:46:43.327 | INFO     | src.policies:train:109 - Episode 1715\n",
      "2021-08-25 10:46:43.365 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:43.366 | INFO     | src.policies:train:121 - Mean episode return: 100.0\n",
      "2021-08-25 10:46:43.367 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.46\n",
      "2021-08-25 10:46:43.367 | INFO     | src.policies:train:109 - Episode 1716\n",
      "2021-08-25 10:46:43.388 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:43.390 | INFO     | src.policies:train:121 - Mean episode return: 52.0\n",
      "2021-08-25 10:46:43.390 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.82\n",
      "2021-08-25 10:46:43.391 | INFO     | src.policies:train:109 - Episode 1717\n",
      "2021-08-25 10:46:43.402 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:43.403 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 10:46:43.404 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.77\n",
      "2021-08-25 10:46:43.405 | WARNING  | src.policies:train:131 - The actual batch size is 207, instead of 200\n",
      "2021-08-25 10:46:43.411 | INFO     | src.policies:train:157 - Total loss: 242.38111877441406\n",
      "2021-08-25 10:46:43.412 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:43.415 | INFO     | src.policies:train:103 - Epoch 234 / 800\n",
      "2021-08-25 10:46:43.416 | INFO     | src.policies:train:109 - Episode 1718\n",
      "2021-08-25 10:46:43.432 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:43.433 | INFO     | src.policies:train:121 - Mean episode return: 43.0\n",
      "2021-08-25 10:46:43.434 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.69\n",
      "2021-08-25 10:46:43.435 | INFO     | src.policies:train:109 - Episode 1719\n",
      "2021-08-25 10:46:43.443 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:43.445 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:43.445 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.68\n",
      "2021-08-25 10:46:43.446 | INFO     | src.policies:train:109 - Episode 1720\n",
      "2021-08-25 10:46:43.455 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:43.456 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:43.457 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.42\n",
      "2021-08-25 10:46:43.458 | INFO     | src.policies:train:109 - Episode 1721\n",
      "2021-08-25 10:46:43.466 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:43.467 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 10:46:43.469 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.43\n",
      "2021-08-25 10:46:43.469 | INFO     | src.policies:train:109 - Episode 1722\n",
      "2021-08-25 10:46:43.476 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:43.477 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 10:46:43.478 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.18\n",
      "2021-08-25 10:46:43.479 | INFO     | src.policies:train:109 - Episode 1723\n",
      "2021-08-25 10:46:43.487 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:43.488 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:43.489 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.15\n",
      "2021-08-25 10:46:43.490 | INFO     | src.policies:train:109 - Episode 1724\n",
      "2021-08-25 10:46:43.499 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:43.500 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:43.500 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.66\n",
      "2021-08-25 10:46:43.501 | INFO     | src.policies:train:109 - Episode 1725\n",
      "2021-08-25 10:46:43.511 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:43.513 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 10:46:43.513 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.67\n",
      "2021-08-25 10:46:43.514 | INFO     | src.policies:train:109 - Episode 1726\n",
      "2021-08-25 10:46:43.523 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:43.524 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:43.524 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.7\n",
      "2021-08-25 10:46:43.525 | INFO     | src.policies:train:109 - Episode 1727\n",
      "2021-08-25 10:46:43.534 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:43.535 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 10:46:43.536 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.29\n",
      "2021-08-25 10:46:43.537 | INFO     | src.policies:train:109 - Episode 1728\n",
      "2021-08-25 10:46:43.545 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:43.546 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:43.547 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.21\n",
      "2021-08-25 10:46:43.548 | INFO     | src.policies:train:109 - Episode 1729\n",
      "2021-08-25 10:46:43.557 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:43.558 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:43.559 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.03\n",
      "2021-08-25 10:46:43.560 | WARNING  | src.policies:train:131 - The actual batch size is 215, instead of 200\n",
      "2021-08-25 10:46:43.567 | INFO     | src.policies:train:157 - Total loss: 47.259586334228516\n",
      "2021-08-25 10:46:43.568 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:43.571 | INFO     | src.policies:train:103 - Epoch 235 / 800\n",
      "2021-08-25 10:46:43.573 | INFO     | src.policies:train:109 - Episode 1730\n",
      "2021-08-25 10:46:43.583 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:43.584 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 10:46:43.585 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.98\n",
      "2021-08-25 10:46:43.586 | INFO     | src.policies:train:109 - Episode 1731\n",
      "2021-08-25 10:46:43.601 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:43.602 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 10:46:43.603 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.38\n",
      "2021-08-25 10:46:43.603 | INFO     | src.policies:train:109 - Episode 1732\n",
      "2021-08-25 10:46:43.623 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:43.624 | INFO     | src.policies:train:121 - Mean episode return: 47.0\n",
      "2021-08-25 10:46:43.625 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.4\n",
      "2021-08-25 10:46:43.626 | INFO     | src.policies:train:109 - Episode 1733\n",
      "2021-08-25 10:46:43.635 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:43.637 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:43.637 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:43.638 | INFO     | src.policies:train:109 - Episode 1734\n",
      "2021-08-25 10:46:43.648 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:43.649 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:43.650 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.69\n",
      "2021-08-25 10:46:43.651 | INFO     | src.policies:train:109 - Episode 1735\n",
      "2021-08-25 10:46:43.665 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:43.666 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 10:46:43.667 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.45\n",
      "2021-08-25 10:46:43.668 | INFO     | src.policies:train:109 - Episode 1736\n",
      "2021-08-25 10:46:43.679 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:43.680 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:43.681 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.36\n",
      "2021-08-25 10:46:43.682 | INFO     | src.policies:train:109 - Episode 1737\n",
      "2021-08-25 10:46:43.689 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:43.690 | INFO     | src.policies:train:121 - Mean episode return: 9.0\n",
      "2021-08-25 10:46:43.691 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.84\n",
      "2021-08-25 10:46:43.692 | INFO     | src.policies:train:109 - Episode 1738\n",
      "2021-08-25 10:46:43.706 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:43.707 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 10:46:43.708 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.79\n",
      "2021-08-25 10:46:43.709 | WARNING  | src.policies:train:131 - The actual batch size is 225, instead of 200\n",
      "2021-08-25 10:46:43.715 | INFO     | src.policies:train:157 - Total loss: 100.79228973388672\n",
      "2021-08-25 10:46:43.716 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:43.718 | INFO     | src.policies:train:103 - Epoch 236 / 800\n",
      "2021-08-25 10:46:43.720 | INFO     | src.policies:train:109 - Episode 1739\n",
      "2021-08-25 10:46:43.736 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:43.737 | INFO     | src.policies:train:121 - Mean episode return: 43.0\n",
      "2021-08-25 10:46:43.738 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.91\n",
      "2021-08-25 10:46:43.739 | INFO     | src.policies:train:109 - Episode 1740\n",
      "2021-08-25 10:46:43.774 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:43.775 | INFO     | src.policies:train:121 - Mean episode return: 87.0\n",
      "2021-08-25 10:46:43.776 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.55\n",
      "2021-08-25 10:46:43.776 | INFO     | src.policies:train:109 - Episode 1741\n",
      "2021-08-25 10:46:43.786 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:43.787 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:43.788 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.42\n",
      "2021-08-25 10:46:43.789 | INFO     | src.policies:train:109 - Episode 1742\n",
      "2021-08-25 10:46:43.801 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:43.802 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 10:46:43.803 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.5\n",
      "2021-08-25 10:46:43.804 | INFO     | src.policies:train:109 - Episode 1743\n",
      "2021-08-25 10:46:43.817 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:43.818 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 10:46:43.819 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.66\n",
      "2021-08-25 10:46:43.820 | WARNING  | src.policies:train:131 - The actual batch size is 202, instead of 200\n",
      "2021-08-25 10:46:43.825 | INFO     | src.policies:train:157 - Total loss: 160.07362365722656\n",
      "2021-08-25 10:46:43.826 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:43.829 | INFO     | src.policies:train:103 - Epoch 237 / 800\n",
      "2021-08-25 10:46:43.830 | INFO     | src.policies:train:109 - Episode 1744\n",
      "2021-08-25 10:46:43.845 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:43.846 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 10:46:43.847 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.62\n",
      "2021-08-25 10:46:43.848 | INFO     | src.policies:train:109 - Episode 1745\n",
      "2021-08-25 10:46:43.855 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:43.856 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 10:46:43.857 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.34\n",
      "2021-08-25 10:46:43.858 | INFO     | src.policies:train:109 - Episode 1746\n",
      "2021-08-25 10:46:43.867 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:43.868 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:43.869 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.71\n",
      "2021-08-25 10:46:43.870 | INFO     | src.policies:train:109 - Episode 1747\n",
      "2021-08-25 10:46:43.877 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:43.878 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:43.879 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.54\n",
      "2021-08-25 10:46:43.880 | INFO     | src.policies:train:109 - Episode 1748\n",
      "2021-08-25 10:46:43.887 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:43.888 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 10:46:43.889 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.13\n",
      "2021-08-25 10:46:43.890 | INFO     | src.policies:train:109 - Episode 1749\n",
      "2021-08-25 10:46:43.902 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:43.903 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 10:46:43.904 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.99\n",
      "2021-08-25 10:46:43.905 | INFO     | src.policies:train:109 - Episode 1750\n",
      "2021-08-25 10:46:43.916 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:43.917 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 10:46:43.918 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.09\n",
      "2021-08-25 10:46:43.919 | INFO     | src.policies:train:109 - Episode 1751\n",
      "2021-08-25 10:46:43.928 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:43.929 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:43.930 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.01\n",
      "2021-08-25 10:46:43.931 | INFO     | src.policies:train:109 - Episode 1752\n",
      "2021-08-25 10:46:43.948 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:43.949 | INFO     | src.policies:train:121 - Mean episode return: 38.0\n",
      "2021-08-25 10:46:43.950 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.75\n",
      "2021-08-25 10:46:43.950 | INFO     | src.policies:train:109 - Episode 1753\n",
      "2021-08-25 10:46:43.960 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:43.961 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:43.962 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.38\n",
      "2021-08-25 10:46:43.964 | WARNING  | src.policies:train:131 - The actual batch size is 207, instead of 200\n",
      "2021-08-25 10:46:43.970 | INFO     | src.policies:train:157 - Total loss: 66.75067901611328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:43.971 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:43.974 | INFO     | src.policies:train:103 - Epoch 238 / 800\n",
      "2021-08-25 10:46:43.975 | INFO     | src.policies:train:109 - Episode 1754\n",
      "2021-08-25 10:46:43.999 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:44.000 | INFO     | src.policies:train:121 - Mean episode return: 65.0\n",
      "2021-08-25 10:46:44.001 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.54\n",
      "2021-08-25 10:46:44.002 | INFO     | src.policies:train:109 - Episode 1755\n",
      "2021-08-25 10:46:44.011 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:44.012 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:44.013 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.53\n",
      "2021-08-25 10:46:44.014 | INFO     | src.policies:train:109 - Episode 1756\n",
      "2021-08-25 10:46:44.040 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:44.041 | INFO     | src.policies:train:121 - Mean episode return: 67.0\n",
      "2021-08-25 10:46:44.042 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.93\n",
      "2021-08-25 10:46:44.042 | INFO     | src.policies:train:109 - Episode 1757\n",
      "2021-08-25 10:46:44.052 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:44.053 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 10:46:44.053 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.49\n",
      "2021-08-25 10:46:44.054 | INFO     | src.policies:train:109 - Episode 1758\n",
      "2021-08-25 10:46:44.068 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:44.069 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 10:46:44.070 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.67\n",
      "2021-08-25 10:46:44.071 | INFO     | src.policies:train:109 - Episode 1759\n",
      "2021-08-25 10:46:44.083 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:44.084 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 10:46:44.085 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.49\n",
      "2021-08-25 10:46:44.086 | WARNING  | src.policies:train:131 - The actual batch size is 222, instead of 200\n",
      "2021-08-25 10:46:44.092 | INFO     | src.policies:train:157 - Total loss: 112.2364501953125\n",
      "2021-08-25 10:46:44.093 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:44.096 | INFO     | src.policies:train:103 - Epoch 239 / 800\n",
      "2021-08-25 10:46:44.097 | INFO     | src.policies:train:109 - Episode 1760\n",
      "2021-08-25 10:46:44.116 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:44.117 | INFO     | src.policies:train:121 - Mean episode return: 50.0\n",
      "2021-08-25 10:46:44.118 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.84\n",
      "2021-08-25 10:46:44.119 | INFO     | src.policies:train:109 - Episode 1761\n",
      "2021-08-25 10:46:44.132 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:44.133 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 10:46:44.134 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.55\n",
      "2021-08-25 10:46:44.135 | INFO     | src.policies:train:109 - Episode 1762\n",
      "2021-08-25 10:46:44.152 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:44.153 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 10:46:44.154 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.64\n",
      "2021-08-25 10:46:44.154 | INFO     | src.policies:train:109 - Episode 1763\n",
      "2021-08-25 10:46:44.175 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:44.176 | INFO     | src.policies:train:121 - Mean episode return: 49.0\n",
      "2021-08-25 10:46:44.177 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.97\n",
      "2021-08-25 10:46:44.178 | INFO     | src.policies:train:109 - Episode 1764\n",
      "2021-08-25 10:46:44.191 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:44.192 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 10:46:44.193 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.12\n",
      "2021-08-25 10:46:44.194 | INFO     | src.policies:train:109 - Episode 1765\n",
      "2021-08-25 10:46:44.201 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:44.202 | INFO     | src.policies:train:121 - Mean episode return: 9.0\n",
      "2021-08-25 10:46:44.203 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.04\n",
      "2021-08-25 10:46:44.204 | WARNING  | src.policies:train:131 - The actual batch size is 202, instead of 200\n",
      "2021-08-25 10:46:44.209 | INFO     | src.policies:train:157 - Total loss: 89.75940704345703\n",
      "2021-08-25 10:46:44.210 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:44.213 | INFO     | src.policies:train:103 - Epoch 240 / 800\n",
      "2021-08-25 10:46:44.214 | INFO     | src.policies:train:109 - Episode 1766\n",
      "2021-08-25 10:46:44.220 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:44.221 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 10:46:44.222 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.86\n",
      "2021-08-25 10:46:44.223 | INFO     | src.policies:train:109 - Episode 1767\n",
      "2021-08-25 10:46:44.238 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:44.239 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 10:46:44.240 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.16\n",
      "2021-08-25 10:46:44.241 | INFO     | src.policies:train:109 - Episode 1768\n",
      "2021-08-25 10:46:44.254 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:44.255 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 10:46:44.256 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.29\n",
      "2021-08-25 10:46:44.257 | INFO     | src.policies:train:109 - Episode 1769\n",
      "2021-08-25 10:46:44.268 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:44.269 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 10:46:44.270 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.38\n",
      "2021-08-25 10:46:44.271 | INFO     | src.policies:train:109 - Episode 1770\n",
      "2021-08-25 10:46:44.282 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:44.283 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 10:46:44.284 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.43\n",
      "2021-08-25 10:46:44.285 | INFO     | src.policies:train:109 - Episode 1771\n",
      "2021-08-25 10:46:44.299 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:44.300 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 10:46:44.301 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.25\n",
      "2021-08-25 10:46:44.302 | INFO     | src.policies:train:109 - Episode 1772\n",
      "2021-08-25 10:46:44.317 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:44.318 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 10:46:44.319 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.36\n",
      "2021-08-25 10:46:44.320 | INFO     | src.policies:train:109 - Episode 1773\n",
      "2021-08-25 10:46:44.340 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:44.341 | INFO     | src.policies:train:121 - Mean episode return: 50.0\n",
      "2021-08-25 10:46:44.342 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.47\n",
      "2021-08-25 10:46:44.343 | WARNING  | src.policies:train:131 - The actual batch size is 235, instead of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:44.350 | INFO     | src.policies:train:157 - Total loss: 80.36029815673828\n",
      "2021-08-25 10:46:44.350 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:44.353 | INFO     | src.policies:train:103 - Epoch 241 / 800\n",
      "2021-08-25 10:46:44.355 | INFO     | src.policies:train:109 - Episode 1774\n",
      "2021-08-25 10:46:44.368 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:44.370 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 10:46:44.370 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.98\n",
      "2021-08-25 10:46:44.371 | INFO     | src.policies:train:109 - Episode 1775\n",
      "2021-08-25 10:46:44.402 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:44.403 | INFO     | src.policies:train:121 - Mean episode return: 76.0\n",
      "2021-08-25 10:46:44.404 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.53\n",
      "2021-08-25 10:46:44.405 | INFO     | src.policies:train:109 - Episode 1776\n",
      "2021-08-25 10:46:44.428 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:44.429 | INFO     | src.policies:train:121 - Mean episode return: 58.0\n",
      "2021-08-25 10:46:44.430 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.42\n",
      "2021-08-25 10:46:44.431 | INFO     | src.policies:train:109 - Episode 1777\n",
      "2021-08-25 10:46:44.446 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:44.447 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 10:46:44.448 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.14\n",
      "2021-08-25 10:46:44.449 | WARNING  | src.policies:train:131 - The actual batch size is 204, instead of 200\n",
      "2021-08-25 10:46:44.455 | INFO     | src.policies:train:157 - Total loss: 132.8013458251953\n",
      "2021-08-25 10:46:44.456 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:44.458 | INFO     | src.policies:train:103 - Epoch 242 / 800\n",
      "2021-08-25 10:46:44.459 | INFO     | src.policies:train:109 - Episode 1778\n",
      "2021-08-25 10:46:44.476 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:44.477 | INFO     | src.policies:train:121 - Mean episode return: 43.0\n",
      "2021-08-25 10:46:44.478 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.82\n",
      "2021-08-25 10:46:44.479 | INFO     | src.policies:train:109 - Episode 1779\n",
      "2021-08-25 10:46:44.500 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:44.501 | INFO     | src.policies:train:121 - Mean episode return: 51.0\n",
      "2021-08-25 10:46:44.502 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.1\n",
      "2021-08-25 10:46:44.503 | INFO     | src.policies:train:109 - Episode 1780\n",
      "2021-08-25 10:46:44.512 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:44.513 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:44.514 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.88\n",
      "2021-08-25 10:46:44.515 | INFO     | src.policies:train:109 - Episode 1781\n",
      "2021-08-25 10:46:44.523 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:44.524 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:44.525 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.93\n",
      "2021-08-25 10:46:44.526 | INFO     | src.policies:train:109 - Episode 1782\n",
      "2021-08-25 10:46:44.548 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:44.550 | INFO     | src.policies:train:121 - Mean episode return: 55.0\n",
      "2021-08-25 10:46:44.550 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.26\n",
      "2021-08-25 10:46:44.551 | INFO     | src.policies:train:109 - Episode 1783\n",
      "2021-08-25 10:46:44.594 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:44.595 | INFO     | src.policies:train:121 - Mean episode return: 121.0\n",
      "2021-08-25 10:46:44.596 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.8\n",
      "2021-08-25 10:46:44.596 | WARNING  | src.policies:train:131 - The actual batch size is 298, instead of 200\n",
      "2021-08-25 10:46:44.603 | INFO     | src.policies:train:157 - Total loss: 268.6238708496094\n",
      "2021-08-25 10:46:44.604 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:44.607 | INFO     | src.policies:train:103 - Epoch 243 / 800\n",
      "2021-08-25 10:46:44.608 | INFO     | src.policies:train:109 - Episode 1784\n",
      "2021-08-25 10:46:44.628 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:44.629 | INFO     | src.policies:train:121 - Mean episode return: 52.0\n",
      "2021-08-25 10:46:44.630 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.13\n",
      "2021-08-25 10:46:44.631 | INFO     | src.policies:train:109 - Episode 1785\n",
      "2021-08-25 10:46:44.639 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:44.640 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:44.641 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.98\n",
      "2021-08-25 10:46:44.642 | INFO     | src.policies:train:109 - Episode 1786\n",
      "2021-08-25 10:46:44.649 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:44.650 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 10:46:44.651 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.68\n",
      "2021-08-25 10:46:44.652 | INFO     | src.policies:train:109 - Episode 1787\n",
      "2021-08-25 10:46:44.675 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:44.676 | INFO     | src.policies:train:121 - Mean episode return: 62.0\n",
      "2021-08-25 10:46:44.677 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.89\n",
      "2021-08-25 10:46:44.678 | INFO     | src.policies:train:109 - Episode 1788\n",
      "2021-08-25 10:46:44.688 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:44.689 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 10:46:44.690 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.84\n",
      "2021-08-25 10:46:44.691 | INFO     | src.policies:train:109 - Episode 1789\n",
      "2021-08-25 10:46:44.707 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:44.709 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 10:46:44.709 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.08\n",
      "2021-08-25 10:46:44.710 | INFO     | src.policies:train:109 - Episode 1790\n",
      "2021-08-25 10:46:44.725 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:44.726 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 10:46:44.727 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.26\n",
      "2021-08-25 10:46:44.728 | WARNING  | src.policies:train:131 - The actual batch size is 224, instead of 200\n",
      "2021-08-25 10:46:44.733 | INFO     | src.policies:train:157 - Total loss: 136.17318725585938\n",
      "2021-08-25 10:46:44.734 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:44.737 | INFO     | src.policies:train:103 - Epoch 244 / 800\n",
      "2021-08-25 10:46:44.738 | INFO     | src.policies:train:109 - Episode 1791\n",
      "2021-08-25 10:46:44.753 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:44.754 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 10:46:44.755 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.33\n",
      "2021-08-25 10:46:44.756 | INFO     | src.policies:train:109 - Episode 1792\n",
      "2021-08-25 10:46:44.765 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:44.766 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 10:46:44.767 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:44.768 | INFO     | src.policies:train:109 - Episode 1793\n",
      "2021-08-25 10:46:44.799 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:44.800 | INFO     | src.policies:train:121 - Mean episode return: 82.0\n",
      "2021-08-25 10:46:44.800 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.03\n",
      "2021-08-25 10:46:44.801 | INFO     | src.policies:train:109 - Episode 1794\n",
      "2021-08-25 10:46:44.814 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:44.815 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 10:46:44.816 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.89\n",
      "2021-08-25 10:46:44.817 | INFO     | src.policies:train:109 - Episode 1795\n",
      "2021-08-25 10:46:44.829 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:44.830 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 10:46:44.830 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.88\n",
      "2021-08-25 10:46:44.831 | INFO     | src.policies:train:109 - Episode 1796\n",
      "2021-08-25 10:46:44.843 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:44.845 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 10:46:44.845 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.97\n",
      "2021-08-25 10:46:44.846 | WARNING  | src.policies:train:131 - The actual batch size is 210, instead of 200\n",
      "2021-08-25 10:46:44.852 | INFO     | src.policies:train:157 - Total loss: 142.2340545654297\n",
      "2021-08-25 10:46:44.853 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:44.856 | INFO     | src.policies:train:103 - Epoch 245 / 800\n",
      "2021-08-25 10:46:44.857 | INFO     | src.policies:train:109 - Episode 1797\n",
      "2021-08-25 10:46:44.864 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:44.866 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 10:46:44.867 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.99\n",
      "2021-08-25 10:46:44.867 | INFO     | src.policies:train:109 - Episode 1798\n",
      "2021-08-25 10:46:44.886 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:44.887 | INFO     | src.policies:train:121 - Mean episode return: 47.0\n",
      "2021-08-25 10:46:44.888 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.26\n",
      "2021-08-25 10:46:44.889 | INFO     | src.policies:train:109 - Episode 1799\n",
      "2021-08-25 10:46:44.910 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:44.911 | INFO     | src.policies:train:121 - Mean episode return: 53.0\n",
      "2021-08-25 10:46:44.912 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.7\n",
      "2021-08-25 10:46:44.913 | INFO     | src.policies:train:109 - Episode 1800\n",
      "2021-08-25 10:46:44.937 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:44.938 | INFO     | src.policies:train:121 - Mean episode return: 61.0\n",
      "2021-08-25 10:46:44.939 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.93\n",
      "2021-08-25 10:46:44.940 | INFO     | src.policies:train:109 - Episode 1801\n",
      "2021-08-25 10:46:44.951 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:44.952 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 10:46:44.953 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.72\n",
      "2021-08-25 10:46:44.954 | INFO     | src.policies:train:109 - Episode 1802\n",
      "2021-08-25 10:46:44.967 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:44.969 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 10:46:44.970 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.82\n",
      "2021-08-25 10:46:44.970 | WARNING  | src.policies:train:131 - The actual batch size is 228, instead of 200\n",
      "2021-08-25 10:46:44.976 | INFO     | src.policies:train:157 - Total loss: 77.08374786376953\n",
      "2021-08-25 10:46:44.977 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:44.980 | INFO     | src.policies:train:103 - Epoch 246 / 800\n",
      "2021-08-25 10:46:44.981 | INFO     | src.policies:train:109 - Episode 1803\n",
      "2021-08-25 10:46:44.989 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:44.990 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:44.991 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.51\n",
      "2021-08-25 10:46:44.992 | INFO     | src.policies:train:109 - Episode 1804\n",
      "2021-08-25 10:46:45.003 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:45.004 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 10:46:45.005 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.64\n",
      "2021-08-25 10:46:45.006 | INFO     | src.policies:train:109 - Episode 1805\n",
      "2021-08-25 10:46:45.019 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:45.020 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 10:46:45.021 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.72\n",
      "2021-08-25 10:46:45.022 | INFO     | src.policies:train:109 - Episode 1806\n",
      "2021-08-25 10:46:45.030 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:45.031 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:45.032 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.34\n",
      "2021-08-25 10:46:45.033 | INFO     | src.policies:train:109 - Episode 1807\n",
      "2021-08-25 10:46:45.049 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:45.050 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 10:46:45.051 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.43\n",
      "2021-08-25 10:46:45.052 | INFO     | src.policies:train:109 - Episode 1808\n",
      "2021-08-25 10:46:45.073 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:45.074 | INFO     | src.policies:train:121 - Mean episode return: 54.0\n",
      "2021-08-25 10:46:45.075 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.84\n",
      "2021-08-25 10:46:45.076 | INFO     | src.policies:train:109 - Episode 1809\n",
      "2021-08-25 10:46:45.094 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:45.095 | INFO     | src.policies:train:121 - Mean episode return: 45.0\n",
      "2021-08-25 10:46:45.096 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.92\n",
      "2021-08-25 10:46:45.097 | WARNING  | src.policies:train:131 - The actual batch size is 214, instead of 200\n",
      "2021-08-25 10:46:45.103 | INFO     | src.policies:train:157 - Total loss: 119.5362319946289\n",
      "2021-08-25 10:46:45.104 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:45.107 | INFO     | src.policies:train:103 - Epoch 247 / 800\n",
      "2021-08-25 10:46:45.108 | INFO     | src.policies:train:109 - Episode 1810\n",
      "2021-08-25 10:46:45.118 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:45.119 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 10:46:45.119 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.0\n",
      "2021-08-25 10:46:45.120 | INFO     | src.policies:train:109 - Episode 1811\n",
      "2021-08-25 10:46:45.128 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:45.129 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 10:46:45.130 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.82\n",
      "2021-08-25 10:46:45.131 | INFO     | src.policies:train:109 - Episode 1812\n",
      "2021-08-25 10:46:45.148 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:45.149 | INFO     | src.policies:train:121 - Mean episode return: 41.0\n",
      "2021-08-25 10:46:45.149 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.65\n",
      "2021-08-25 10:46:45.150 | INFO     | src.policies:train:109 - Episode 1813\n",
      "2021-08-25 10:46:45.174 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:45.175 | INFO     | src.policies:train:121 - Mean episode return: 61.0\n",
      "2021-08-25 10:46:45.176 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.13\n",
      "2021-08-25 10:46:45.177 | INFO     | src.policies:train:109 - Episode 1814\n",
      "2021-08-25 10:46:45.190 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:45.192 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 10:46:45.192 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.24\n",
      "2021-08-25 10:46:45.193 | INFO     | src.policies:train:109 - Episode 1815\n",
      "2021-08-25 10:46:45.207 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:45.209 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 10:46:45.209 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.55\n",
      "2021-08-25 10:46:45.210 | INFO     | src.policies:train:109 - Episode 1816\n",
      "2021-08-25 10:46:45.218 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:45.219 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:45.220 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.18\n",
      "2021-08-25 10:46:45.221 | WARNING  | src.policies:train:131 - The actual batch size is 210, instead of 200\n",
      "2021-08-25 10:46:45.227 | INFO     | src.policies:train:157 - Total loss: 61.84052276611328\n",
      "2021-08-25 10:46:45.228 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:45.231 | INFO     | src.policies:train:103 - Epoch 248 / 800\n",
      "2021-08-25 10:46:45.232 | INFO     | src.policies:train:109 - Episode 1817\n",
      "2021-08-25 10:46:45.241 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:45.242 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 10:46:45.243 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.17\n",
      "2021-08-25 10:46:45.244 | INFO     | src.policies:train:109 - Episode 1818\n",
      "2021-08-25 10:46:45.255 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:45.256 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 10:46:45.257 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.95\n",
      "2021-08-25 10:46:45.258 | INFO     | src.policies:train:109 - Episode 1819\n",
      "2021-08-25 10:46:45.270 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:45.271 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 10:46:45.272 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.07\n",
      "2021-08-25 10:46:45.273 | INFO     | src.policies:train:109 - Episode 1820\n",
      "2021-08-25 10:46:45.289 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:45.290 | INFO     | src.policies:train:121 - Mean episode return: 41.0\n",
      "2021-08-25 10:46:45.291 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.35\n",
      "2021-08-25 10:46:45.292 | INFO     | src.policies:train:109 - Episode 1821\n",
      "2021-08-25 10:46:45.322 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:45.323 | INFO     | src.policies:train:121 - Mean episode return: 75.0\n",
      "2021-08-25 10:46:45.324 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.93\n",
      "2021-08-25 10:46:45.325 | INFO     | src.policies:train:109 - Episode 1822\n",
      "2021-08-25 10:46:45.340 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:45.341 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 10:46:45.342 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.17\n",
      "2021-08-25 10:46:45.343 | WARNING  | src.policies:train:131 - The actual batch size is 220, instead of 200\n",
      "2021-08-25 10:46:45.350 | INFO     | src.policies:train:157 - Total loss: 89.93579864501953\n",
      "2021-08-25 10:46:45.350 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:45.353 | INFO     | src.policies:train:103 - Epoch 249 / 800\n",
      "2021-08-25 10:46:45.354 | INFO     | src.policies:train:109 - Episode 1823\n",
      "2021-08-25 10:46:45.360 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:45.361 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 10:46:45.362 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.11\n",
      "2021-08-25 10:46:45.362 | INFO     | src.policies:train:109 - Episode 1824\n",
      "2021-08-25 10:46:45.386 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:45.388 | INFO     | src.policies:train:121 - Mean episode return: 63.0\n",
      "2021-08-25 10:46:45.388 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.59\n",
      "2021-08-25 10:46:45.389 | INFO     | src.policies:train:109 - Episode 1825\n",
      "2021-08-25 10:46:45.409 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:45.410 | INFO     | src.policies:train:121 - Mean episode return: 49.0\n",
      "2021-08-25 10:46:45.411 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.88\n",
      "2021-08-25 10:46:45.412 | INFO     | src.policies:train:109 - Episode 1826\n",
      "2021-08-25 10:46:45.425 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:45.426 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 10:46:45.427 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.0\n",
      "2021-08-25 10:46:45.428 | INFO     | src.policies:train:109 - Episode 1827\n",
      "2021-08-25 10:46:45.456 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:45.457 | INFO     | src.policies:train:121 - Mean episode return: 72.0\n",
      "2021-08-25 10:46:45.458 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.55\n",
      "2021-08-25 10:46:45.459 | WARNING  | src.policies:train:131 - The actual batch size is 222, instead of 200\n",
      "2021-08-25 10:46:45.465 | INFO     | src.policies:train:157 - Total loss: 156.3899688720703\n",
      "2021-08-25 10:46:45.465 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:45.468 | INFO     | src.policies:train:103 - Epoch 250 / 800\n",
      "2021-08-25 10:46:45.469 | INFO     | src.policies:train:109 - Episode 1828\n",
      "2021-08-25 10:46:45.490 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:45.492 | INFO     | src.policies:train:121 - Mean episode return: 57.0\n",
      "2021-08-25 10:46:45.492 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.96\n",
      "2021-08-25 10:46:45.493 | INFO     | src.policies:train:109 - Episode 1829\n",
      "2021-08-25 10:46:45.517 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:45.518 | INFO     | src.policies:train:121 - Mean episode return: 60.0\n",
      "2021-08-25 10:46:45.518 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.4\n",
      "2021-08-25 10:46:45.519 | INFO     | src.policies:train:109 - Episode 1830\n",
      "2021-08-25 10:46:45.529 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:45.531 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:45.531 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.33\n",
      "2021-08-25 10:46:45.532 | INFO     | src.policies:train:109 - Episode 1831\n",
      "2021-08-25 10:46:45.556 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:45.557 | INFO     | src.policies:train:121 - Mean episode return: 59.0\n",
      "2021-08-25 10:46:45.558 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:45.559 | INFO     | src.policies:train:109 - Episode 1832\n",
      "2021-08-25 10:46:45.569 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:45.570 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:45.571 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.33\n",
      "2021-08-25 10:46:45.572 | WARNING  | src.policies:train:131 - The actual batch size is 214, instead of 200\n",
      "2021-08-25 10:46:45.578 | INFO     | src.policies:train:157 - Total loss: 101.92375183105469\n",
      "2021-08-25 10:46:45.579 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:45.582 | INFO     | src.policies:train:103 - Epoch 251 / 800\n",
      "2021-08-25 10:46:45.583 | INFO     | src.policies:train:109 - Episode 1833\n",
      "2021-08-25 10:46:45.604 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:45.606 | INFO     | src.policies:train:121 - Mean episode return: 57.0\n",
      "2021-08-25 10:46:45.607 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.72\n",
      "2021-08-25 10:46:45.608 | INFO     | src.policies:train:109 - Episode 1834\n",
      "2021-08-25 10:46:45.620 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:45.621 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 10:46:45.622 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.77\n",
      "2021-08-25 10:46:45.624 | INFO     | src.policies:train:109 - Episode 1835\n",
      "2021-08-25 10:46:45.635 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:45.636 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:45.637 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.68\n",
      "2021-08-25 10:46:45.638 | INFO     | src.policies:train:109 - Episode 1836\n",
      "2021-08-25 10:46:45.662 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:45.664 | INFO     | src.policies:train:121 - Mean episode return: 59.0\n",
      "2021-08-25 10:46:45.665 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.09\n",
      "2021-08-25 10:46:45.666 | INFO     | src.policies:train:109 - Episode 1837\n",
      "2021-08-25 10:46:45.686 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:45.687 | INFO     | src.policies:train:121 - Mean episode return: 43.0\n",
      "2021-08-25 10:46:45.688 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.43\n",
      "2021-08-25 10:46:45.689 | WARNING  | src.policies:train:131 - The actual batch size is 201, instead of 200\n",
      "2021-08-25 10:46:45.697 | INFO     | src.policies:train:157 - Total loss: 124.02889251708984\n",
      "2021-08-25 10:46:45.698 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:45.702 | INFO     | src.policies:train:103 - Epoch 252 / 800\n",
      "2021-08-25 10:46:45.704 | INFO     | src.policies:train:109 - Episode 1838\n",
      "2021-08-25 10:46:45.737 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:45.738 | INFO     | src.policies:train:121 - Mean episode return: 81.0\n",
      "2021-08-25 10:46:45.739 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.94\n",
      "2021-08-25 10:46:45.740 | INFO     | src.policies:train:109 - Episode 1839\n",
      "2021-08-25 10:46:45.749 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:45.751 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:45.752 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.64\n",
      "2021-08-25 10:46:45.753 | INFO     | src.policies:train:109 - Episode 1840\n",
      "2021-08-25 10:46:45.766 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:45.768 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 10:46:45.769 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.0\n",
      "2021-08-25 10:46:45.770 | INFO     | src.policies:train:109 - Episode 1841\n",
      "2021-08-25 10:46:45.781 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:45.783 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 10:46:45.783 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.03\n",
      "2021-08-25 10:46:45.784 | INFO     | src.policies:train:109 - Episode 1842\n",
      "2021-08-25 10:46:45.793 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:45.794 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:45.795 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.9\n",
      "2021-08-25 10:46:45.796 | INFO     | src.policies:train:109 - Episode 1843\n",
      "2021-08-25 10:46:45.807 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:45.808 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 10:46:45.809 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.86\n",
      "2021-08-25 10:46:45.810 | INFO     | src.policies:train:109 - Episode 1844\n",
      "2021-08-25 10:46:45.817 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:45.818 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 10:46:45.819 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.6\n",
      "2021-08-25 10:46:45.820 | INFO     | src.policies:train:109 - Episode 1845\n",
      "2021-08-25 10:46:45.850 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:45.851 | INFO     | src.policies:train:121 - Mean episode return: 79.0\n",
      "2021-08-25 10:46:45.852 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.29\n",
      "2021-08-25 10:46:45.853 | WARNING  | src.policies:train:131 - The actual batch size is 265, instead of 200\n",
      "2021-08-25 10:46:45.859 | INFO     | src.policies:train:157 - Total loss: 180.95501708984375\n",
      "2021-08-25 10:46:45.860 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:45.863 | INFO     | src.policies:train:103 - Epoch 253 / 800\n",
      "2021-08-25 10:46:45.864 | INFO     | src.policies:train:109 - Episode 1846\n",
      "2021-08-25 10:46:45.869 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:45.870 | INFO     | src.policies:train:121 - Mean episode return: 9.0\n",
      "2021-08-25 10:46:45.871 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.2\n",
      "2021-08-25 10:46:45.872 | INFO     | src.policies:train:109 - Episode 1847\n",
      "2021-08-25 10:46:45.879 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:45.880 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:45.881 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.21\n",
      "2021-08-25 10:46:45.881 | INFO     | src.policies:train:109 - Episode 1848\n",
      "2021-08-25 10:46:45.893 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:45.894 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 10:46:45.895 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.32\n",
      "2021-08-25 10:46:45.895 | INFO     | src.policies:train:109 - Episode 1849\n",
      "2021-08-25 10:46:45.926 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:45.927 | INFO     | src.policies:train:121 - Mean episode return: 85.0\n",
      "2021-08-25 10:46:45.928 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.89\n",
      "2021-08-25 10:46:45.929 | INFO     | src.policies:train:109 - Episode 1850\n",
      "2021-08-25 10:46:45.936 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:45.937 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:45.938 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.81\n",
      "2021-08-25 10:46:45.939 | INFO     | src.policies:train:109 - Episode 1851\n",
      "2021-08-25 10:46:45.949 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:45.950 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:45.951 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.81\n",
      "2021-08-25 10:46:45.952 | INFO     | src.policies:train:109 - Episode 1852\n",
      "2021-08-25 10:46:45.968 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:45.969 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 10:46:45.970 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.83\n",
      "2021-08-25 10:46:45.971 | INFO     | src.policies:train:109 - Episode 1853\n",
      "2021-08-25 10:46:45.982 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:45.983 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 10:46:45.984 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.88\n",
      "2021-08-25 10:46:45.985 | WARNING  | src.policies:train:131 - The actual batch size is 219, instead of 200\n",
      "2021-08-25 10:46:45.991 | INFO     | src.policies:train:157 - Total loss: 173.4159698486328\n",
      "2021-08-25 10:46:45.992 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:45.995 | INFO     | src.policies:train:103 - Epoch 254 / 800\n",
      "2021-08-25 10:46:45.996 | INFO     | src.policies:train:109 - Episode 1854\n",
      "2021-08-25 10:46:46.004 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:46.005 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:46.006 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.42\n",
      "2021-08-25 10:46:46.007 | INFO     | src.policies:train:109 - Episode 1855\n",
      "2021-08-25 10:46:46.024 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:46.025 | INFO     | src.policies:train:121 - Mean episode return: 39.0\n",
      "2021-08-25 10:46:46.026 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.66\n",
      "2021-08-25 10:46:46.027 | INFO     | src.policies:train:109 - Episode 1856\n",
      "2021-08-25 10:46:46.047 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:46.048 | INFO     | src.policies:train:121 - Mean episode return: 48.0\n",
      "2021-08-25 10:46:46.049 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.47\n",
      "2021-08-25 10:46:46.050 | INFO     | src.policies:train:109 - Episode 1857\n",
      "2021-08-25 10:46:46.064 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:46.065 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 10:46:46.066 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.63\n",
      "2021-08-25 10:46:46.066 | INFO     | src.policies:train:109 - Episode 1858\n",
      "2021-08-25 10:46:46.092 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:46.093 | INFO     | src.policies:train:121 - Mean episode return: 64.0\n",
      "2021-08-25 10:46:46.094 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.94\n",
      "2021-08-25 10:46:46.094 | WARNING  | src.policies:train:131 - The actual batch size is 203, instead of 200\n",
      "2021-08-25 10:46:46.100 | INFO     | src.policies:train:157 - Total loss: 79.08164978027344\n",
      "2021-08-25 10:46:46.101 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:46.104 | INFO     | src.policies:train:103 - Epoch 255 / 800\n",
      "2021-08-25 10:46:46.105 | INFO     | src.policies:train:109 - Episode 1859\n",
      "2021-08-25 10:46:46.112 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:46.113 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:46.114 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.83\n",
      "2021-08-25 10:46:46.115 | INFO     | src.policies:train:109 - Episode 1860\n",
      "2021-08-25 10:46:46.124 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:46.125 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:46.126 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.51\n",
      "2021-08-25 10:46:46.127 | INFO     | src.policies:train:109 - Episode 1861\n",
      "2021-08-25 10:46:46.135 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:46.136 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:46.137 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.36\n",
      "2021-08-25 10:46:46.138 | INFO     | src.policies:train:109 - Episode 1862\n",
      "2021-08-25 10:46:46.149 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:46.150 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 10:46:46.151 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.25\n",
      "2021-08-25 10:46:46.152 | INFO     | src.policies:train:109 - Episode 1863\n",
      "2021-08-25 10:46:46.162 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:46.163 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 10:46:46.164 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.97\n",
      "2021-08-25 10:46:46.164 | INFO     | src.policies:train:109 - Episode 1864\n",
      "2021-08-25 10:46:46.178 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:46.179 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 10:46:46.180 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.97\n",
      "2021-08-25 10:46:46.181 | INFO     | src.policies:train:109 - Episode 1865\n",
      "2021-08-25 10:46:46.190 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:46.191 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:46.192 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.04\n",
      "2021-08-25 10:46:46.193 | INFO     | src.policies:train:109 - Episode 1866\n",
      "2021-08-25 10:46:46.200 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:46.201 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 10:46:46.202 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.05\n",
      "2021-08-25 10:46:46.203 | INFO     | src.policies:train:109 - Episode 1867\n",
      "2021-08-25 10:46:46.235 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:46.237 | INFO     | src.policies:train:121 - Mean episode return: 91.0\n",
      "2021-08-25 10:46:46.237 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.59\n",
      "2021-08-25 10:46:46.238 | WARNING  | src.policies:train:131 - The actual batch size is 239, instead of 200\n",
      "2021-08-25 10:46:46.245 | INFO     | src.policies:train:157 - Total loss: 173.10694885253906\n",
      "2021-08-25 10:46:46.246 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:46.249 | INFO     | src.policies:train:103 - Epoch 256 / 800\n",
      "2021-08-25 10:46:46.250 | INFO     | src.policies:train:109 - Episode 1868\n",
      "2021-08-25 10:46:46.267 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:46.268 | INFO     | src.policies:train:121 - Mean episode return: 44.0\n",
      "2021-08-25 10:46:46.269 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.74\n",
      "2021-08-25 10:46:46.270 | INFO     | src.policies:train:109 - Episode 1869\n",
      "2021-08-25 10:46:46.280 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:46.281 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:46.281 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.69\n",
      "2021-08-25 10:46:46.282 | INFO     | src.policies:train:109 - Episode 1870\n",
      "2021-08-25 10:46:46.319 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:46.320 | INFO     | src.policies:train:121 - Mean episode return: 97.0\n",
      "2021-08-25 10:46:46.321 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:46.322 | INFO     | src.policies:train:109 - Episode 1871\n",
      "2021-08-25 10:46:46.336 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:46.338 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 10:46:46.338 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.45\n",
      "2021-08-25 10:46:46.339 | INFO     | src.policies:train:109 - Episode 1872\n",
      "2021-08-25 10:46:46.350 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:46.351 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 10:46:46.352 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.35\n",
      "2021-08-25 10:46:46.353 | WARNING  | src.policies:train:131 - The actual batch size is 214, instead of 200\n",
      "2021-08-25 10:46:46.359 | INFO     | src.policies:train:157 - Total loss: 225.27938842773438\n",
      "2021-08-25 10:46:46.359 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:46.362 | INFO     | src.policies:train:103 - Epoch 257 / 800\n",
      "2021-08-25 10:46:46.363 | INFO     | src.policies:train:109 - Episode 1873\n",
      "2021-08-25 10:46:46.370 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:46.372 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:46.373 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.99\n",
      "2021-08-25 10:46:46.373 | INFO     | src.policies:train:109 - Episode 1874\n",
      "2021-08-25 10:46:46.393 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:46.395 | INFO     | src.policies:train:121 - Mean episode return: 50.0\n",
      "2021-08-25 10:46:46.395 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.12\n",
      "2021-08-25 10:46:46.396 | INFO     | src.policies:train:109 - Episode 1875\n",
      "2021-08-25 10:46:46.408 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:46.409 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 10:46:46.410 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.61\n",
      "2021-08-25 10:46:46.411 | INFO     | src.policies:train:109 - Episode 1876\n",
      "2021-08-25 10:46:46.421 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:46.422 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 10:46:46.423 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.23\n",
      "2021-08-25 10:46:46.424 | INFO     | src.policies:train:109 - Episode 1877\n",
      "2021-08-25 10:46:46.439 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:46.440 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 10:46:46.441 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.23\n",
      "2021-08-25 10:46:46.442 | INFO     | src.policies:train:109 - Episode 1878\n",
      "2021-08-25 10:46:46.458 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:46.459 | INFO     | src.policies:train:121 - Mean episode return: 39.0\n",
      "2021-08-25 10:46:46.460 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.19\n",
      "2021-08-25 10:46:46.461 | INFO     | src.policies:train:109 - Episode 1879\n",
      "2021-08-25 10:46:46.481 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:46.482 | INFO     | src.policies:train:121 - Mean episode return: 48.0\n",
      "2021-08-25 10:46:46.483 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.16\n",
      "2021-08-25 10:46:46.484 | WARNING  | src.policies:train:131 - The actual batch size is 229, instead of 200\n",
      "2021-08-25 10:46:46.490 | INFO     | src.policies:train:157 - Total loss: 34.9087028503418\n",
      "2021-08-25 10:46:46.491 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:46.494 | INFO     | src.policies:train:103 - Epoch 258 / 800\n",
      "2021-08-25 10:46:46.495 | INFO     | src.policies:train:109 - Episode 1880\n",
      "2021-08-25 10:46:46.514 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:46.515 | INFO     | src.policies:train:121 - Mean episode return: 52.0\n",
      "2021-08-25 10:46:46.516 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.54\n",
      "2021-08-25 10:46:46.517 | INFO     | src.policies:train:109 - Episode 1881\n",
      "2021-08-25 10:46:46.528 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:46.529 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 10:46:46.530 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.63\n",
      "2021-08-25 10:46:46.531 | INFO     | src.policies:train:109 - Episode 1882\n",
      "2021-08-25 10:46:46.538 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:46.539 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 10:46:46.540 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.19\n",
      "2021-08-25 10:46:46.540 | INFO     | src.policies:train:109 - Episode 1883\n",
      "2021-08-25 10:46:46.552 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:46.554 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 10:46:46.554 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.22\n",
      "2021-08-25 10:46:46.555 | INFO     | src.policies:train:109 - Episode 1884\n",
      "2021-08-25 10:46:46.565 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:46.566 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:46.567 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.89\n",
      "2021-08-25 10:46:46.568 | INFO     | src.policies:train:109 - Episode 1885\n",
      "2021-08-25 10:46:46.589 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:46.590 | INFO     | src.policies:train:121 - Mean episode return: 54.0\n",
      "2021-08-25 10:46:46.591 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.29\n",
      "2021-08-25 10:46:46.592 | INFO     | src.policies:train:109 - Episode 1886\n",
      "2021-08-25 10:46:46.602 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:46.603 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 10:46:46.604 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.39\n",
      "2021-08-25 10:46:46.605 | WARNING  | src.policies:train:131 - The actual batch size is 203, instead of 200\n",
      "2021-08-25 10:46:46.611 | INFO     | src.policies:train:157 - Total loss: 58.074283599853516\n",
      "2021-08-25 10:46:46.611 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:46.614 | INFO     | src.policies:train:103 - Epoch 259 / 800\n",
      "2021-08-25 10:46:46.615 | INFO     | src.policies:train:109 - Episode 1887\n",
      "2021-08-25 10:46:46.629 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:46.630 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 10:46:46.631 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.1\n",
      "2021-08-25 10:46:46.632 | INFO     | src.policies:train:109 - Episode 1888\n",
      "2021-08-25 10:46:46.639 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:46.640 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 10:46:46.641 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.04\n",
      "2021-08-25 10:46:46.642 | INFO     | src.policies:train:109 - Episode 1889\n",
      "2021-08-25 10:46:46.651 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:46.652 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:46.653 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.86\n",
      "2021-08-25 10:46:46.654 | INFO     | src.policies:train:109 - Episode 1890\n",
      "2021-08-25 10:46:46.669 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:46.670 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 10:46:46.671 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.9\n",
      "2021-08-25 10:46:46.672 | INFO     | src.policies:train:109 - Episode 1891\n",
      "2021-08-25 10:46:46.681 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:46.683 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:46.684 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.7\n",
      "2021-08-25 10:46:46.685 | INFO     | src.policies:train:109 - Episode 1892\n",
      "2021-08-25 10:46:46.693 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:46.694 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:46.695 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.68\n",
      "2021-08-25 10:46:46.696 | INFO     | src.policies:train:109 - Episode 1893\n",
      "2021-08-25 10:46:46.703 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:46.704 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:46.705 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.01\n",
      "2021-08-25 10:46:46.706 | INFO     | src.policies:train:109 - Episode 1894\n",
      "2021-08-25 10:46:46.726 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:46.727 | INFO     | src.policies:train:121 - Mean episode return: 47.0\n",
      "2021-08-25 10:46:46.728 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.25\n",
      "2021-08-25 10:46:46.729 | INFO     | src.policies:train:109 - Episode 1895\n",
      "2021-08-25 10:46:46.746 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:46.747 | INFO     | src.policies:train:121 - Mean episode return: 39.0\n",
      "2021-08-25 10:46:46.747 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.37\n",
      "2021-08-25 10:46:46.748 | WARNING  | src.policies:train:131 - The actual batch size is 231, instead of 200\n",
      "2021-08-25 10:46:46.755 | INFO     | src.policies:train:157 - Total loss: 132.08680725097656\n",
      "2021-08-25 10:46:46.756 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:46.758 | INFO     | src.policies:train:103 - Epoch 260 / 800\n",
      "2021-08-25 10:46:46.759 | INFO     | src.policies:train:109 - Episode 1896\n",
      "2021-08-25 10:46:46.776 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:46.777 | INFO     | src.policies:train:121 - Mean episode return: 42.0\n",
      "2021-08-25 10:46:46.778 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.54\n",
      "2021-08-25 10:46:46.779 | INFO     | src.policies:train:109 - Episode 1897\n",
      "2021-08-25 10:46:46.814 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:46.815 | INFO     | src.policies:train:121 - Mean episode return: 92.0\n",
      "2021-08-25 10:46:46.816 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.29\n",
      "2021-08-25 10:46:46.817 | INFO     | src.policies:train:109 - Episode 1898\n",
      "2021-08-25 10:46:46.833 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:46.834 | INFO     | src.policies:train:121 - Mean episode return: 38.0\n",
      "2021-08-25 10:46:46.835 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.2\n",
      "2021-08-25 10:46:46.836 | INFO     | src.policies:train:109 - Episode 1899\n",
      "2021-08-25 10:46:46.862 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:46.864 | INFO     | src.policies:train:121 - Mean episode return: 69.0\n",
      "2021-08-25 10:46:46.864 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.36\n",
      "2021-08-25 10:46:46.865 | WARNING  | src.policies:train:131 - The actual batch size is 241, instead of 200\n",
      "2021-08-25 10:46:46.871 | INFO     | src.policies:train:157 - Total loss: 201.20632934570312\n",
      "2021-08-25 10:46:46.872 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:46.875 | INFO     | src.policies:train:103 - Epoch 261 / 800\n",
      "2021-08-25 10:46:46.876 | INFO     | src.policies:train:109 - Episode 1900\n",
      "2021-08-25 10:46:46.885 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:46.886 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:46.887 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.94\n",
      "2021-08-25 10:46:46.887 | INFO     | src.policies:train:109 - Episode 1901\n",
      "2021-08-25 10:46:46.895 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:46.896 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 10:46:46.897 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.84\n",
      "2021-08-25 10:46:46.897 | INFO     | src.policies:train:109 - Episode 1902\n",
      "2021-08-25 10:46:46.911 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:46.912 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 10:46:46.913 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.88\n",
      "2021-08-25 10:46:46.914 | INFO     | src.policies:train:109 - Episode 1903\n",
      "2021-08-25 10:46:46.933 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:46.935 | INFO     | src.policies:train:121 - Mean episode return: 49.0\n",
      "2021-08-25 10:46:46.936 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.21\n",
      "2021-08-25 10:46:46.937 | INFO     | src.policies:train:109 - Episode 1904\n",
      "2021-08-25 10:46:46.944 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:46.945 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:46.946 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.1\n",
      "2021-08-25 10:46:46.947 | INFO     | src.policies:train:109 - Episode 1905\n",
      "2021-08-25 10:46:46.969 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:46.970 | INFO     | src.policies:train:121 - Mean episode return: 53.0\n",
      "2021-08-25 10:46:46.971 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.35\n",
      "2021-08-25 10:46:46.972 | INFO     | src.policies:train:109 - Episode 1906\n",
      "2021-08-25 10:46:46.998 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:46.999 | INFO     | src.policies:train:121 - Mean episode return: 68.0\n",
      "2021-08-25 10:46:47.000 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.91\n",
      "2021-08-25 10:46:47.001 | WARNING  | src.policies:train:131 - The actual batch size is 246, instead of 200\n",
      "2021-08-25 10:46:47.008 | INFO     | src.policies:train:157 - Total loss: 167.46080017089844\n",
      "2021-08-25 10:46:47.009 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:47.013 | INFO     | src.policies:train:103 - Epoch 262 / 800\n",
      "2021-08-25 10:46:47.014 | INFO     | src.policies:train:109 - Episode 1907\n",
      "2021-08-25 10:46:47.023 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:47.024 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 10:46:47.025 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.76\n",
      "2021-08-25 10:46:47.026 | INFO     | src.policies:train:109 - Episode 1908\n",
      "2021-08-25 10:46:47.035 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:47.036 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:47.037 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.37\n",
      "2021-08-25 10:46:47.037 | INFO     | src.policies:train:109 - Episode 1909\n",
      "2021-08-25 10:46:47.053 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:47.054 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 10:46:47.055 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:47.056 | INFO     | src.policies:train:109 - Episode 1910\n",
      "2021-08-25 10:46:47.063 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:47.065 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:47.065 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.22\n",
      "2021-08-25 10:46:47.066 | INFO     | src.policies:train:109 - Episode 1911\n",
      "2021-08-25 10:46:47.103 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:47.104 | INFO     | src.policies:train:121 - Mean episode return: 101.0\n",
      "2021-08-25 10:46:47.105 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.12\n",
      "2021-08-25 10:46:47.106 | INFO     | src.policies:train:109 - Episode 1912\n",
      "2021-08-25 10:46:47.116 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:47.117 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:47.118 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.9\n",
      "2021-08-25 10:46:47.119 | WARNING  | src.policies:train:131 - The actual batch size is 205, instead of 200\n",
      "2021-08-25 10:46:47.125 | INFO     | src.policies:train:157 - Total loss: 191.06655883789062\n",
      "2021-08-25 10:46:47.126 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:47.129 | INFO     | src.policies:train:103 - Epoch 263 / 800\n",
      "2021-08-25 10:46:47.130 | INFO     | src.policies:train:109 - Episode 1913\n",
      "2021-08-25 10:46:47.138 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:47.139 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:47.139 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.44\n",
      "2021-08-25 10:46:47.140 | INFO     | src.policies:train:109 - Episode 1914\n",
      "2021-08-25 10:46:47.156 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:47.158 | INFO     | src.policies:train:121 - Mean episode return: 38.0\n",
      "2021-08-25 10:46:47.158 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.51\n",
      "2021-08-25 10:46:47.159 | INFO     | src.policies:train:109 - Episode 1915\n",
      "2021-08-25 10:46:47.170 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:47.171 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 10:46:47.172 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.41\n",
      "2021-08-25 10:46:47.173 | INFO     | src.policies:train:109 - Episode 1916\n",
      "2021-08-25 10:46:47.217 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:47.218 | INFO     | src.policies:train:121 - Mean episode return: 127.0\n",
      "2021-08-25 10:46:47.219 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.53\n",
      "2021-08-25 10:46:47.220 | WARNING  | src.policies:train:131 - The actual batch size is 201, instead of 200\n",
      "2021-08-25 10:46:47.225 | INFO     | src.policies:train:157 - Total loss: 348.1692810058594\n",
      "2021-08-25 10:46:47.226 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:47.229 | INFO     | src.policies:train:103 - Epoch 264 / 800\n",
      "2021-08-25 10:46:47.230 | INFO     | src.policies:train:109 - Episode 1917\n",
      "2021-08-25 10:46:47.244 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:47.245 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 10:46:47.247 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.65\n",
      "2021-08-25 10:46:47.247 | INFO     | src.policies:train:109 - Episode 1918\n",
      "2021-08-25 10:46:47.266 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:47.267 | INFO     | src.policies:train:121 - Mean episode return: 43.0\n",
      "2021-08-25 10:46:47.268 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.87\n",
      "2021-08-25 10:46:47.269 | INFO     | src.policies:train:109 - Episode 1919\n",
      "2021-08-25 10:46:47.276 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:47.278 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:47.278 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.72\n",
      "2021-08-25 10:46:47.279 | INFO     | src.policies:train:109 - Episode 1920\n",
      "2021-08-25 10:46:47.308 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:47.309 | INFO     | src.policies:train:121 - Mean episode return: 76.0\n",
      "2021-08-25 10:46:47.310 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.07\n",
      "2021-08-25 10:46:47.311 | INFO     | src.policies:train:109 - Episode 1921\n",
      "2021-08-25 10:46:47.318 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:47.320 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:47.320 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.45\n",
      "2021-08-25 10:46:47.321 | INFO     | src.policies:train:109 - Episode 1922\n",
      "2021-08-25 10:46:47.333 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:47.334 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 10:46:47.335 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.32\n",
      "2021-08-25 10:46:47.335 | INFO     | src.policies:train:109 - Episode 1923\n",
      "2021-08-25 10:46:47.351 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:47.352 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 10:46:47.353 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.58\n",
      "2021-08-25 10:46:47.354 | WARNING  | src.policies:train:131 - The actual batch size is 235, instead of 200\n",
      "2021-08-25 10:46:47.360 | INFO     | src.policies:train:157 - Total loss: 144.0293426513672\n",
      "2021-08-25 10:46:47.361 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:47.365 | INFO     | src.policies:train:103 - Epoch 265 / 800\n",
      "2021-08-25 10:46:47.366 | INFO     | src.policies:train:109 - Episode 1924\n",
      "2021-08-25 10:46:47.382 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:47.383 | INFO     | src.policies:train:121 - Mean episode return: 39.0\n",
      "2021-08-25 10:46:47.384 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.34\n",
      "2021-08-25 10:46:47.385 | INFO     | src.policies:train:109 - Episode 1925\n",
      "2021-08-25 10:46:47.394 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:47.395 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:47.396 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.99\n",
      "2021-08-25 10:46:47.396 | INFO     | src.policies:train:109 - Episode 1926\n",
      "2021-08-25 10:46:47.406 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:47.407 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 10:46:47.408 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.91\n",
      "2021-08-25 10:46:47.409 | INFO     | src.policies:train:109 - Episode 1927\n",
      "2021-08-25 10:46:47.426 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:47.428 | INFO     | src.policies:train:121 - Mean episode return: 41.0\n",
      "2021-08-25 10:46:47.428 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.6\n",
      "2021-08-25 10:46:47.429 | INFO     | src.policies:train:109 - Episode 1928\n",
      "2021-08-25 10:46:47.447 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:47.449 | INFO     | src.policies:train:121 - Mean episode return: 43.0\n",
      "2021-08-25 10:46:47.450 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.46\n",
      "2021-08-25 10:46:47.450 | INFO     | src.policies:train:109 - Episode 1929\n",
      "2021-08-25 10:46:47.462 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:47.463 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 10:46:47.464 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.12\n",
      "2021-08-25 10:46:47.465 | INFO     | src.policies:train:109 - Episode 1930\n",
      "2021-08-25 10:46:47.481 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:47.482 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 10:46:47.483 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.27\n",
      "2021-08-25 10:46:47.484 | WARNING  | src.policies:train:131 - The actual batch size is 217, instead of 200\n",
      "2021-08-25 10:46:47.491 | INFO     | src.policies:train:157 - Total loss: 64.1790542602539\n",
      "2021-08-25 10:46:47.492 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:47.495 | INFO     | src.policies:train:103 - Epoch 266 / 800\n",
      "2021-08-25 10:46:47.496 | INFO     | src.policies:train:109 - Episode 1931\n",
      "2021-08-25 10:46:47.508 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:47.509 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 10:46:47.509 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.98\n",
      "2021-08-25 10:46:47.510 | INFO     | src.policies:train:109 - Episode 1932\n",
      "2021-08-25 10:46:47.528 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:47.529 | INFO     | src.policies:train:121 - Mean episode return: 44.0\n",
      "2021-08-25 10:46:47.530 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.23\n",
      "2021-08-25 10:46:47.531 | INFO     | src.policies:train:109 - Episode 1933\n",
      "2021-08-25 10:46:47.551 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:47.552 | INFO     | src.policies:train:121 - Mean episode return: 51.0\n",
      "2021-08-25 10:46:47.553 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.17\n",
      "2021-08-25 10:46:47.554 | INFO     | src.policies:train:109 - Episode 1934\n",
      "2021-08-25 10:46:47.563 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:47.564 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:47.565 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.1\n",
      "2021-08-25 10:46:47.566 | INFO     | src.policies:train:109 - Episode 1935\n",
      "2021-08-25 10:46:47.589 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:47.590 | INFO     | src.policies:train:121 - Mean episode return: 56.0\n",
      "2021-08-25 10:46:47.591 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.47\n",
      "2021-08-25 10:46:47.592 | INFO     | src.policies:train:109 - Episode 1936\n",
      "2021-08-25 10:46:47.602 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:47.603 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 10:46:47.604 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.09\n",
      "2021-08-25 10:46:47.605 | WARNING  | src.policies:train:131 - The actual batch size is 218, instead of 200\n",
      "2021-08-25 10:46:47.611 | INFO     | src.policies:train:157 - Total loss: 93.8726577758789\n",
      "2021-08-25 10:46:47.612 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:47.615 | INFO     | src.policies:train:103 - Epoch 267 / 800\n",
      "2021-08-25 10:46:47.616 | INFO     | src.policies:train:109 - Episode 1937\n",
      "2021-08-25 10:46:47.639 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:47.640 | INFO     | src.policies:train:121 - Mean episode return: 61.0\n",
      "2021-08-25 10:46:47.640 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.27\n",
      "2021-08-25 10:46:47.641 | INFO     | src.policies:train:109 - Episode 1938\n",
      "2021-08-25 10:46:47.650 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:47.651 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 10:46:47.652 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.56\n",
      "2021-08-25 10:46:47.652 | INFO     | src.policies:train:109 - Episode 1939\n",
      "2021-08-25 10:46:47.674 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:47.676 | INFO     | src.policies:train:121 - Mean episode return: 54.0\n",
      "2021-08-25 10:46:47.676 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.97\n",
      "2021-08-25 10:46:47.677 | INFO     | src.policies:train:109 - Episode 1940\n",
      "2021-08-25 10:46:47.694 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:47.695 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 10:46:47.696 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.09\n",
      "2021-08-25 10:46:47.697 | INFO     | src.policies:train:109 - Episode 1941\n",
      "2021-08-25 10:46:47.704 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:47.705 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:47.706 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.0\n",
      "2021-08-25 10:46:47.707 | INFO     | src.policies:train:109 - Episode 1942\n",
      "2021-08-25 10:46:47.726 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:47.728 | INFO     | src.policies:train:121 - Mean episode return: 47.0\n",
      "2021-08-25 10:46:47.728 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.33\n",
      "2021-08-25 10:46:47.729 | WARNING  | src.policies:train:131 - The actual batch size is 219, instead of 200\n",
      "2021-08-25 10:46:47.736 | INFO     | src.policies:train:157 - Total loss: 130.741943359375\n",
      "2021-08-25 10:46:47.736 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:47.739 | INFO     | src.policies:train:103 - Epoch 268 / 800\n",
      "2021-08-25 10:46:47.740 | INFO     | src.policies:train:109 - Episode 1943\n",
      "2021-08-25 10:46:47.760 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:47.761 | INFO     | src.policies:train:121 - Mean episode return: 49.0\n",
      "2021-08-25 10:46:47.762 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.59\n",
      "2021-08-25 10:46:47.763 | INFO     | src.policies:train:109 - Episode 1944\n",
      "2021-08-25 10:46:47.793 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:47.794 | INFO     | src.policies:train:121 - Mean episode return: 80.0\n",
      "2021-08-25 10:46:47.795 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.28\n",
      "2021-08-25 10:46:47.796 | INFO     | src.policies:train:109 - Episode 1945\n",
      "2021-08-25 10:46:47.825 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:47.827 | INFO     | src.policies:train:121 - Mean episode return: 76.0\n",
      "2021-08-25 10:46:47.828 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.25\n",
      "2021-08-25 10:46:47.828 | WARNING  | src.policies:train:131 - The actual batch size is 205, instead of 200\n",
      "2021-08-25 10:46:47.834 | INFO     | src.policies:train:157 - Total loss: 238.54908752441406\n",
      "2021-08-25 10:46:47.835 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:47.838 | INFO     | src.policies:train:103 - Epoch 269 / 800\n",
      "2021-08-25 10:46:47.839 | INFO     | src.policies:train:109 - Episode 1946\n",
      "2021-08-25 10:46:47.847 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:47.848 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:47.849 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.31\n",
      "2021-08-25 10:46:47.850 | INFO     | src.policies:train:109 - Episode 1947\n",
      "2021-08-25 10:46:47.861 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:47.862 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 10:46:47.863 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.38\n",
      "2021-08-25 10:46:47.864 | INFO     | src.policies:train:109 - Episode 1948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:47.871 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:47.873 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 10:46:47.873 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.27\n",
      "2021-08-25 10:46:47.875 | INFO     | src.policies:train:109 - Episode 1949\n",
      "2021-08-25 10:46:47.882 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:47.883 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 10:46:47.884 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.53\n",
      "2021-08-25 10:46:47.885 | INFO     | src.policies:train:109 - Episode 1950\n",
      "2021-08-25 10:46:47.897 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:47.898 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 10:46:47.899 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.66\n",
      "2021-08-25 10:46:47.900 | INFO     | src.policies:train:109 - Episode 1951\n",
      "2021-08-25 10:46:47.918 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:47.919 | INFO     | src.policies:train:121 - Mean episode return: 42.0\n",
      "2021-08-25 10:46:47.920 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.92\n",
      "2021-08-25 10:46:47.921 | INFO     | src.policies:train:109 - Episode 1952\n",
      "2021-08-25 10:46:47.932 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:47.933 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 10:46:47.934 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.72\n",
      "2021-08-25 10:46:47.935 | INFO     | src.policies:train:109 - Episode 1953\n",
      "2021-08-25 10:46:47.949 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:47.950 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 10:46:47.951 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.84\n",
      "2021-08-25 10:46:47.952 | INFO     | src.policies:train:109 - Episode 1954\n",
      "2021-08-25 10:46:47.967 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:47.968 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 10:46:47.969 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.97\n",
      "2021-08-25 10:46:47.970 | WARNING  | src.policies:train:131 - The actual batch size is 210, instead of 200\n",
      "2021-08-25 10:46:47.977 | INFO     | src.policies:train:157 - Total loss: 31.25048828125\n",
      "2021-08-25 10:46:47.978 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:47.981 | INFO     | src.policies:train:103 - Epoch 270 / 800\n",
      "2021-08-25 10:46:47.982 | INFO     | src.policies:train:109 - Episode 1955\n",
      "2021-08-25 10:46:48.002 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:48.003 | INFO     | src.policies:train:121 - Mean episode return: 48.0\n",
      "2021-08-25 10:46:48.004 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.06\n",
      "2021-08-25 10:46:48.005 | INFO     | src.policies:train:109 - Episode 1956\n",
      "2021-08-25 10:46:48.021 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:48.022 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 10:46:48.023 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.92\n",
      "2021-08-25 10:46:48.024 | INFO     | src.policies:train:109 - Episode 1957\n",
      "2021-08-25 10:46:48.067 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:48.068 | INFO     | src.policies:train:121 - Mean episode return: 112.0\n",
      "2021-08-25 10:46:48.069 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.71\n",
      "2021-08-25 10:46:48.070 | INFO     | src.policies:train:109 - Episode 1958\n",
      "2021-08-25 10:46:48.088 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:48.089 | INFO     | src.policies:train:121 - Mean episode return: 41.0\n",
      "2021-08-25 10:46:48.090 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.48\n",
      "2021-08-25 10:46:48.091 | WARNING  | src.policies:train:131 - The actual batch size is 235, instead of 200\n",
      "2021-08-25 10:46:48.097 | INFO     | src.policies:train:157 - Total loss: 246.35028076171875\n",
      "2021-08-25 10:46:48.098 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:48.101 | INFO     | src.policies:train:103 - Epoch 271 / 800\n",
      "2021-08-25 10:46:48.102 | INFO     | src.policies:train:109 - Episode 1959\n",
      "2021-08-25 10:46:48.123 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:48.124 | INFO     | src.policies:train:121 - Mean episode return: 56.0\n",
      "2021-08-25 10:46:48.125 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.9\n",
      "2021-08-25 10:46:48.126 | INFO     | src.policies:train:109 - Episode 1960\n",
      "2021-08-25 10:46:48.154 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:48.155 | INFO     | src.policies:train:121 - Mean episode return: 72.0\n",
      "2021-08-25 10:46:48.156 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.44\n",
      "2021-08-25 10:46:48.157 | INFO     | src.policies:train:109 - Episode 1961\n",
      "2021-08-25 10:46:48.202 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:48.203 | INFO     | src.policies:train:121 - Mean episode return: 110.0\n",
      "2021-08-25 10:46:48.204 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.41\n",
      "2021-08-25 10:46:48.205 | WARNING  | src.policies:train:131 - The actual batch size is 238, instead of 200\n",
      "2021-08-25 10:46:48.212 | INFO     | src.policies:train:157 - Total loss: 366.5236511230469\n",
      "2021-08-25 10:46:48.213 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:48.217 | INFO     | src.policies:train:103 - Epoch 272 / 800\n",
      "2021-08-25 10:46:48.218 | INFO     | src.policies:train:109 - Episode 1962\n",
      "2021-08-25 10:46:48.234 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:48.235 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 10:46:48.236 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.5\n",
      "2021-08-25 10:46:48.237 | INFO     | src.policies:train:109 - Episode 1963\n",
      "2021-08-25 10:46:48.253 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:48.254 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 10:46:48.255 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.61\n",
      "2021-08-25 10:46:48.256 | INFO     | src.policies:train:109 - Episode 1964\n",
      "2021-08-25 10:46:48.278 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:48.280 | INFO     | src.policies:train:121 - Mean episode return: 47.0\n",
      "2021-08-25 10:46:48.281 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.78\n",
      "2021-08-25 10:46:48.282 | INFO     | src.policies:train:109 - Episode 1965\n",
      "2021-08-25 10:46:48.293 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:48.294 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:48.296 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.75\n",
      "2021-08-25 10:46:48.297 | INFO     | src.policies:train:109 - Episode 1966\n",
      "2021-08-25 10:46:48.364 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:48.365 | INFO     | src.policies:train:121 - Mean episode return: 189.0\n",
      "2021-08-25 10:46:48.366 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.53\n",
      "2021-08-25 10:46:48.367 | WARNING  | src.policies:train:131 - The actual batch size is 315, instead of 200\n",
      "2021-08-25 10:46:48.373 | INFO     | src.policies:train:157 - Total loss: 464.0005187988281\n",
      "2021-08-25 10:46:48.374 | INFO     | src.policies:train:161 - Epoch infos: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:48.378 | INFO     | src.policies:train:103 - Epoch 273 / 800\n",
      "2021-08-25 10:46:48.379 | INFO     | src.policies:train:109 - Episode 1967\n",
      "2021-08-25 10:46:48.385 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:48.386 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:48.387 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.75\n",
      "2021-08-25 10:46:48.388 | INFO     | src.policies:train:109 - Episode 1968\n",
      "2021-08-25 10:46:48.413 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:48.414 | INFO     | src.policies:train:121 - Mean episode return: 61.0\n",
      "2021-08-25 10:46:48.415 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.92\n",
      "2021-08-25 10:46:48.416 | INFO     | src.policies:train:109 - Episode 1969\n",
      "2021-08-25 10:46:48.448 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:48.449 | INFO     | src.policies:train:121 - Mean episode return: 79.0\n",
      "2021-08-25 10:46:48.450 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.52\n",
      "2021-08-25 10:46:48.451 | INFO     | src.policies:train:109 - Episode 1970\n",
      "2021-08-25 10:46:48.476 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:48.477 | INFO     | src.policies:train:121 - Mean episode return: 59.0\n",
      "2021-08-25 10:46:48.478 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.14\n",
      "2021-08-25 10:46:48.479 | WARNING  | src.policies:train:131 - The actual batch size is 212, instead of 200\n",
      "2021-08-25 10:46:48.486 | INFO     | src.policies:train:157 - Total loss: 156.19583129882812\n",
      "2021-08-25 10:46:48.487 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:48.491 | INFO     | src.policies:train:103 - Epoch 274 / 800\n",
      "2021-08-25 10:46:48.492 | INFO     | src.policies:train:109 - Episode 1971\n",
      "2021-08-25 10:46:48.502 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:48.503 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 10:46:48.504 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.99\n",
      "2021-08-25 10:46:48.505 | INFO     | src.policies:train:109 - Episode 1972\n",
      "2021-08-25 10:46:48.546 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:48.547 | INFO     | src.policies:train:121 - Mean episode return: 110.0\n",
      "2021-08-25 10:46:48.548 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.87\n",
      "2021-08-25 10:46:48.548 | INFO     | src.policies:train:109 - Episode 1973\n",
      "2021-08-25 10:46:48.566 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:48.567 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 10:46:48.568 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 40.1\n",
      "2021-08-25 10:46:48.569 | INFO     | src.policies:train:109 - Episode 1974\n",
      "2021-08-25 10:46:48.582 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:48.584 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 10:46:48.585 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.84\n",
      "2021-08-25 10:46:48.586 | INFO     | src.policies:train:109 - Episode 1975\n",
      "2021-08-25 10:46:48.602 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:48.603 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 10:46:48.604 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.92\n",
      "2021-08-25 10:46:48.605 | WARNING  | src.policies:train:131 - The actual batch size is 221, instead of 200\n",
      "2021-08-25 10:46:48.613 | INFO     | src.policies:train:157 - Total loss: 231.7730255126953\n",
      "2021-08-25 10:46:48.614 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:48.618 | INFO     | src.policies:train:103 - Epoch 275 / 800\n",
      "2021-08-25 10:46:48.619 | INFO     | src.policies:train:109 - Episode 1976\n",
      "2021-08-25 10:46:48.625 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:48.626 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 10:46:48.627 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.83\n",
      "2021-08-25 10:46:48.628 | INFO     | src.policies:train:109 - Episode 1977\n",
      "2021-08-25 10:46:48.656 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:48.658 | INFO     | src.policies:train:121 - Mean episode return: 71.0\n",
      "2021-08-25 10:46:48.658 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 40.21\n",
      "2021-08-25 10:46:48.659 | INFO     | src.policies:train:109 - Episode 1978\n",
      "2021-08-25 10:46:48.674 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:48.675 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 10:46:48.676 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 40.1\n",
      "2021-08-25 10:46:48.677 | INFO     | src.policies:train:109 - Episode 1979\n",
      "2021-08-25 10:46:48.697 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:48.698 | INFO     | src.policies:train:121 - Mean episode return: 43.0\n",
      "2021-08-25 10:46:48.700 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 40.05\n",
      "2021-08-25 10:46:48.701 | INFO     | src.policies:train:109 - Episode 1980\n",
      "2021-08-25 10:46:48.753 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:48.754 | INFO     | src.policies:train:121 - Mean episode return: 140.0\n",
      "2021-08-25 10:46:48.755 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 40.93\n",
      "2021-08-25 10:46:48.756 | WARNING  | src.policies:train:131 - The actual batch size is 293, instead of 200\n",
      "2021-08-25 10:46:48.764 | INFO     | src.policies:train:157 - Total loss: 303.9497985839844\n",
      "2021-08-25 10:46:48.765 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:48.769 | INFO     | src.policies:train:103 - Epoch 276 / 800\n",
      "2021-08-25 10:46:48.770 | INFO     | src.policies:train:109 - Episode 1981\n",
      "2021-08-25 10:46:48.779 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:48.780 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 10:46:48.781 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 40.87\n",
      "2021-08-25 10:46:48.782 | INFO     | src.policies:train:109 - Episode 1982\n",
      "2021-08-25 10:46:48.792 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:48.793 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:48.794 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 40.9\n",
      "2021-08-25 10:46:48.795 | INFO     | src.policies:train:109 - Episode 1983\n",
      "2021-08-25 10:46:48.806 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:48.807 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:48.808 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 40.81\n",
      "2021-08-25 10:46:48.809 | INFO     | src.policies:train:109 - Episode 1984\n",
      "2021-08-25 10:46:48.848 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:48.849 | INFO     | src.policies:train:121 - Mean episode return: 98.0\n",
      "2021-08-25 10:46:48.850 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 41.6\n",
      "2021-08-25 10:46:48.851 | INFO     | src.policies:train:109 - Episode 1985\n",
      "2021-08-25 10:46:48.871 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:48.873 | INFO     | src.policies:train:121 - Mean episode return: 48.0\n",
      "2021-08-25 10:46:48.874 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 41.54\n",
      "2021-08-25 10:46:48.874 | INFO     | src.policies:train:109 - Episode 1986\n",
      "2021-08-25 10:46:48.884 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:48.885 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 10:46:48.886 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 41.54\n",
      "2021-08-25 10:46:48.887 | WARNING  | src.policies:train:131 - The actual batch size is 212, instead of 200\n",
      "2021-08-25 10:46:48.894 | INFO     | src.policies:train:157 - Total loss: 175.09800720214844\n",
      "2021-08-25 10:46:48.895 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:48.899 | INFO     | src.policies:train:103 - Epoch 277 / 800\n",
      "2021-08-25 10:46:48.900 | INFO     | src.policies:train:109 - Episode 1987\n",
      "2021-08-25 10:46:48.923 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:48.925 | INFO     | src.policies:train:121 - Mean episode return: 62.0\n",
      "2021-08-25 10:46:48.926 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 41.83\n",
      "2021-08-25 10:46:48.926 | INFO     | src.policies:train:109 - Episode 1988\n",
      "2021-08-25 10:46:48.936 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:48.938 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:48.939 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 41.86\n",
      "2021-08-25 10:46:48.939 | INFO     | src.policies:train:109 - Episode 1989\n",
      "2021-08-25 10:46:48.956 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:48.958 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 10:46:48.959 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 42.02\n",
      "2021-08-25 10:46:48.959 | INFO     | src.policies:train:109 - Episode 1990\n",
      "2021-08-25 10:46:48.969 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:48.970 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:48.972 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 41.79\n",
      "2021-08-25 10:46:48.973 | INFO     | src.policies:train:109 - Episode 1991\n",
      "2021-08-25 10:46:48.984 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:48.985 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 10:46:48.986 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 41.8\n",
      "2021-08-25 10:46:48.987 | INFO     | src.policies:train:109 - Episode 1992\n",
      "2021-08-25 10:46:49.012 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:49.014 | INFO     | src.policies:train:121 - Mean episode return: 57.0\n",
      "2021-08-25 10:46:49.015 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 42.22\n",
      "2021-08-25 10:46:49.016 | INFO     | src.policies:train:109 - Episode 1993\n",
      "2021-08-25 10:46:49.024 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:49.025 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:49.026 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 42.19\n",
      "2021-08-25 10:46:49.027 | WARNING  | src.policies:train:131 - The actual batch size is 210, instead of 200\n",
      "2021-08-25 10:46:49.035 | INFO     | src.policies:train:157 - Total loss: 83.5954818725586\n",
      "2021-08-25 10:46:49.036 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:49.039 | INFO     | src.policies:train:103 - Epoch 278 / 800\n",
      "2021-08-25 10:46:49.040 | INFO     | src.policies:train:109 - Episode 1994\n",
      "2021-08-25 10:46:49.063 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:49.065 | INFO     | src.policies:train:121 - Mean episode return: 58.0\n",
      "2021-08-25 10:46:49.066 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 42.3\n",
      "2021-08-25 10:46:49.067 | INFO     | src.policies:train:109 - Episode 1995\n",
      "2021-08-25 10:46:49.091 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:49.092 | INFO     | src.policies:train:121 - Mean episode return: 52.0\n",
      "2021-08-25 10:46:49.093 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 42.43\n",
      "2021-08-25 10:46:49.094 | INFO     | src.policies:train:109 - Episode 1996\n",
      "2021-08-25 10:46:49.109 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:49.110 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 10:46:49.111 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 42.34\n",
      "2021-08-25 10:46:49.112 | INFO     | src.policies:train:109 - Episode 1997\n",
      "2021-08-25 10:46:49.166 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:49.167 | INFO     | src.policies:train:121 - Mean episode return: 148.0\n",
      "2021-08-25 10:46:49.168 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 42.9\n",
      "2021-08-25 10:46:49.169 | WARNING  | src.policies:train:131 - The actual batch size is 291, instead of 200\n",
      "2021-08-25 10:46:49.176 | INFO     | src.policies:train:157 - Total loss: 398.2484130859375\n",
      "2021-08-25 10:46:49.177 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:49.181 | INFO     | src.policies:train:103 - Epoch 279 / 800\n",
      "2021-08-25 10:46:49.182 | INFO     | src.policies:train:109 - Episode 1998\n",
      "2021-08-25 10:46:49.190 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:49.191 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:49.193 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 42.67\n",
      "2021-08-25 10:46:49.194 | INFO     | src.policies:train:109 - Episode 1999\n",
      "2021-08-25 10:46:49.207 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:49.208 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 10:46:49.208 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 42.24\n",
      "2021-08-25 10:46:49.210 | INFO     | src.policies:train:109 - Episode 2000\n",
      "2021-08-25 10:46:49.231 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:49.232 | INFO     | src.policies:train:121 - Mean episode return: 45.0\n",
      "2021-08-25 10:46:49.233 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 42.5\n",
      "2021-08-25 10:46:49.234 | INFO     | src.policies:train:109 - Episode 2001\n",
      "2021-08-25 10:46:49.257 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:49.259 | INFO     | src.policies:train:121 - Mean episode return: 57.0\n",
      "2021-08-25 10:46:49.259 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 42.96\n",
      "2021-08-25 10:46:49.261 | INFO     | src.policies:train:109 - Episode 2002\n",
      "2021-08-25 10:46:49.273 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:49.274 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:49.276 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 42.82\n",
      "2021-08-25 10:46:49.277 | INFO     | src.policies:train:109 - Episode 2003\n",
      "2021-08-25 10:46:49.287 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:49.289 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:49.289 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 42.48\n",
      "2021-08-25 10:46:49.291 | INFO     | src.policies:train:109 - Episode 2004\n",
      "2021-08-25 10:46:49.300 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:49.302 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:49.303 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 42.49\n",
      "2021-08-25 10:46:49.304 | INFO     | src.policies:train:109 - Episode 2005\n",
      "2021-08-25 10:46:49.328 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:49.329 | INFO     | src.policies:train:121 - Mean episode return: 56.0\n",
      "2021-08-25 10:46:49.331 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 42.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:49.332 | WARNING  | src.policies:train:131 - The actual batch size is 247, instead of 200\n",
      "2021-08-25 10:46:49.340 | INFO     | src.policies:train:157 - Total loss: 84.1073989868164\n",
      "2021-08-25 10:46:49.341 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:49.345 | INFO     | src.policies:train:103 - Epoch 280 / 800\n",
      "2021-08-25 10:46:49.346 | INFO     | src.policies:train:109 - Episode 2006\n",
      "2021-08-25 10:46:49.360 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:49.361 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 10:46:49.362 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 42.15\n",
      "2021-08-25 10:46:49.363 | INFO     | src.policies:train:109 - Episode 2007\n",
      "2021-08-25 10:46:49.373 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:49.374 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:49.375 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 42.13\n",
      "2021-08-25 10:46:49.376 | INFO     | src.policies:train:109 - Episode 2008\n",
      "2021-08-25 10:46:49.392 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:49.393 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 10:46:49.394 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 42.34\n",
      "2021-08-25 10:46:49.395 | INFO     | src.policies:train:109 - Episode 2009\n",
      "2021-08-25 10:46:49.413 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:49.414 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 10:46:49.415 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 42.37\n",
      "2021-08-25 10:46:49.416 | INFO     | src.policies:train:109 - Episode 2010\n",
      "2021-08-25 10:46:49.429 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:49.430 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 10:46:49.431 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 42.49\n",
      "2021-08-25 10:46:49.432 | INFO     | src.policies:train:109 - Episode 2011\n",
      "2021-08-25 10:46:49.457 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:49.458 | INFO     | src.policies:train:121 - Mean episode return: 60.0\n",
      "2021-08-25 10:46:49.459 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 42.08\n",
      "2021-08-25 10:46:49.460 | WARNING  | src.policies:train:131 - The actual batch size is 210, instead of 200\n",
      "2021-08-25 10:46:49.468 | INFO     | src.policies:train:157 - Total loss: 114.11276245117188\n",
      "2021-08-25 10:46:49.469 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:49.473 | INFO     | src.policies:train:103 - Epoch 281 / 800\n",
      "2021-08-25 10:46:49.474 | INFO     | src.policies:train:109 - Episode 2012\n",
      "2021-08-25 10:46:49.484 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:49.485 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:49.486 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 42.07\n",
      "2021-08-25 10:46:49.487 | INFO     | src.policies:train:109 - Episode 2013\n",
      "2021-08-25 10:46:49.514 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:49.516 | INFO     | src.policies:train:121 - Mean episode return: 61.0\n",
      "2021-08-25 10:46:49.516 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 42.53\n",
      "2021-08-25 10:46:49.517 | INFO     | src.policies:train:109 - Episode 2014\n",
      "2021-08-25 10:46:49.526 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:49.527 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 10:46:49.528 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 42.26\n",
      "2021-08-25 10:46:49.529 | INFO     | src.policies:train:109 - Episode 2015\n",
      "2021-08-25 10:46:49.559 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:49.560 | INFO     | src.policies:train:121 - Mean episode return: 75.0\n",
      "2021-08-25 10:46:49.561 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 42.8\n",
      "2021-08-25 10:46:49.562 | INFO     | src.policies:train:109 - Episode 2016\n",
      "2021-08-25 10:46:49.572 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:49.574 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:49.574 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 41.68\n",
      "2021-08-25 10:46:49.575 | INFO     | src.policies:train:109 - Episode 2017\n",
      "2021-08-25 10:46:49.606 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:49.608 | INFO     | src.policies:train:121 - Mean episode return: 75.0\n",
      "2021-08-25 10:46:49.608 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 42.1\n",
      "2021-08-25 10:46:49.609 | WARNING  | src.policies:train:131 - The actual batch size is 255, instead of 200\n",
      "2021-08-25 10:46:49.615 | INFO     | src.policies:train:157 - Total loss: 129.8926239013672\n",
      "2021-08-25 10:46:49.615 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:49.619 | INFO     | src.policies:train:103 - Epoch 282 / 800\n",
      "2021-08-25 10:46:49.620 | INFO     | src.policies:train:109 - Episode 2018\n",
      "2021-08-25 10:46:49.628 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:49.629 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:49.630 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 41.8\n",
      "2021-08-25 10:46:49.632 | INFO     | src.policies:train:109 - Episode 2019\n",
      "2021-08-25 10:46:49.649 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:49.650 | INFO     | src.policies:train:121 - Mean episode return: 41.0\n",
      "2021-08-25 10:46:49.651 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 42.08\n",
      "2021-08-25 10:46:49.652 | INFO     | src.policies:train:109 - Episode 2020\n",
      "2021-08-25 10:46:49.667 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:49.668 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 10:46:49.669 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 41.67\n",
      "2021-08-25 10:46:49.670 | INFO     | src.policies:train:109 - Episode 2021\n",
      "2021-08-25 10:46:49.678 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:49.679 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:49.680 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 41.69\n",
      "2021-08-25 10:46:49.681 | INFO     | src.policies:train:109 - Episode 2022\n",
      "2021-08-25 10:46:49.689 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:49.690 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:49.691 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 41.63\n",
      "2021-08-25 10:46:49.692 | INFO     | src.policies:train:109 - Episode 2023\n",
      "2021-08-25 10:46:49.703 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:49.704 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 10:46:49.705 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 41.51\n",
      "2021-08-25 10:46:49.706 | INFO     | src.policies:train:109 - Episode 2024\n",
      "2021-08-25 10:46:49.719 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:49.720 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 10:46:49.721 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 41.43\n",
      "2021-08-25 10:46:49.722 | INFO     | src.policies:train:109 - Episode 2025\n",
      "2021-08-25 10:46:49.732 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:49.733 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:49.734 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 41.48\n",
      "2021-08-25 10:46:49.735 | INFO     | src.policies:train:109 - Episode 2026\n",
      "2021-08-25 10:46:49.756 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:49.757 | INFO     | src.policies:train:121 - Mean episode return: 55.0\n",
      "2021-08-25 10:46:49.758 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 41.83\n",
      "2021-08-25 10:46:49.759 | WARNING  | src.policies:train:131 - The actual batch size is 248, instead of 200\n",
      "2021-08-25 10:46:49.765 | INFO     | src.policies:train:157 - Total loss: 58.39814376831055\n",
      "2021-08-25 10:46:49.766 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:49.769 | INFO     | src.policies:train:103 - Epoch 283 / 800\n",
      "2021-08-25 10:46:49.770 | INFO     | src.policies:train:109 - Episode 2027\n",
      "2021-08-25 10:46:49.776 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:49.777 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 10:46:49.778 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 41.52\n",
      "2021-08-25 10:46:49.779 | INFO     | src.policies:train:109 - Episode 2028\n",
      "2021-08-25 10:46:49.800 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:49.801 | INFO     | src.policies:train:121 - Mean episode return: 55.0\n",
      "2021-08-25 10:46:49.802 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 41.64\n",
      "2021-08-25 10:46:49.803 | INFO     | src.policies:train:109 - Episode 2029\n",
      "2021-08-25 10:46:49.816 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:49.817 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 10:46:49.818 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 41.65\n",
      "2021-08-25 10:46:49.819 | INFO     | src.policies:train:109 - Episode 2030\n",
      "2021-08-25 10:46:49.851 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:49.852 | INFO     | src.policies:train:121 - Mean episode return: 81.0\n",
      "2021-08-25 10:46:49.853 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 42.12\n",
      "2021-08-25 10:46:49.854 | INFO     | src.policies:train:109 - Episode 2031\n",
      "2021-08-25 10:46:49.860 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:49.861 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 10:46:49.862 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 41.92\n",
      "2021-08-25 10:46:49.863 | INFO     | src.policies:train:109 - Episode 2032\n",
      "2021-08-25 10:46:49.873 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:49.874 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:49.875 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 41.64\n",
      "2021-08-25 10:46:49.876 | INFO     | src.policies:train:109 - Episode 2033\n",
      "2021-08-25 10:46:49.896 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:49.897 | INFO     | src.policies:train:121 - Mean episode return: 48.0\n",
      "2021-08-25 10:46:49.898 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 41.61\n",
      "2021-08-25 10:46:49.899 | WARNING  | src.policies:train:131 - The actual batch size is 247, instead of 200\n",
      "2021-08-25 10:46:49.905 | INFO     | src.policies:train:157 - Total loss: 114.97244262695312\n",
      "2021-08-25 10:46:49.906 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:49.909 | INFO     | src.policies:train:103 - Epoch 284 / 800\n",
      "2021-08-25 10:46:49.910 | INFO     | src.policies:train:109 - Episode 2034\n",
      "2021-08-25 10:46:49.921 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:49.923 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 10:46:49.923 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 41.72\n",
      "2021-08-25 10:46:49.924 | INFO     | src.policies:train:109 - Episode 2035\n",
      "2021-08-25 10:46:49.932 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:49.933 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:49.934 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 41.29\n",
      "2021-08-25 10:46:49.935 | INFO     | src.policies:train:109 - Episode 2036\n",
      "2021-08-25 10:46:49.944 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:49.945 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:49.945 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 41.26\n",
      "2021-08-25 10:46:49.946 | INFO     | src.policies:train:109 - Episode 2037\n",
      "2021-08-25 10:46:49.955 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:49.957 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:49.957 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 40.8\n",
      "2021-08-25 10:46:49.958 | INFO     | src.policies:train:109 - Episode 2038\n",
      "2021-08-25 10:46:49.979 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:49.980 | INFO     | src.policies:train:121 - Mean episode return: 50.0\n",
      "2021-08-25 10:46:49.981 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 41.2\n",
      "2021-08-25 10:46:49.982 | INFO     | src.policies:train:109 - Episode 2039\n",
      "2021-08-25 10:46:50.018 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:50.019 | INFO     | src.policies:train:121 - Mean episode return: 98.0\n",
      "2021-08-25 10:46:50.020 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 41.64\n",
      "2021-08-25 10:46:50.021 | WARNING  | src.policies:train:131 - The actual batch size is 221, instead of 200\n",
      "2021-08-25 10:46:50.027 | INFO     | src.policies:train:157 - Total loss: 211.95567321777344\n",
      "2021-08-25 10:46:50.028 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:50.032 | INFO     | src.policies:train:103 - Epoch 285 / 800\n",
      "2021-08-25 10:46:50.033 | INFO     | src.policies:train:109 - Episode 2040\n",
      "2021-08-25 10:46:50.067 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:50.068 | INFO     | src.policies:train:121 - Mean episode return: 90.0\n",
      "2021-08-25 10:46:50.069 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 42.19\n",
      "2021-08-25 10:46:50.070 | INFO     | src.policies:train:109 - Episode 2041\n",
      "2021-08-25 10:46:50.076 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:50.078 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 10:46:50.078 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 42.18\n",
      "2021-08-25 10:46:50.079 | INFO     | src.policies:train:109 - Episode 2042\n",
      "2021-08-25 10:46:50.092 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:50.094 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:50.094 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 41.89\n",
      "2021-08-25 10:46:50.096 | INFO     | src.policies:train:109 - Episode 2043\n",
      "2021-08-25 10:46:50.114 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:50.116 | INFO     | src.policies:train:121 - Mean episode return: 39.0\n",
      "2021-08-25 10:46:50.117 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 41.79\n",
      "2021-08-25 10:46:50.117 | INFO     | src.policies:train:109 - Episode 2044\n",
      "2021-08-25 10:46:50.129 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:50.130 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 10:46:50.130 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 41.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:50.131 | INFO     | src.policies:train:109 - Episode 2045\n",
      "2021-08-25 10:46:50.172 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:50.173 | INFO     | src.policies:train:121 - Mean episode return: 113.0\n",
      "2021-08-25 10:46:50.174 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 41.58\n",
      "2021-08-25 10:46:50.174 | WARNING  | src.policies:train:131 - The actual batch size is 293, instead of 200\n",
      "2021-08-25 10:46:50.181 | INFO     | src.policies:train:157 - Total loss: 238.256103515625\n",
      "2021-08-25 10:46:50.182 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:50.185 | INFO     | src.policies:train:103 - Epoch 286 / 800\n",
      "2021-08-25 10:46:50.186 | INFO     | src.policies:train:109 - Episode 2046\n",
      "2021-08-25 10:46:50.193 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:50.195 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:50.195 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 41.58\n",
      "2021-08-25 10:46:50.196 | INFO     | src.policies:train:109 - Episode 2047\n",
      "2021-08-25 10:46:50.204 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:50.206 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:50.207 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 41.53\n",
      "2021-08-25 10:46:50.208 | INFO     | src.policies:train:109 - Episode 2048\n",
      "2021-08-25 10:46:50.221 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:50.222 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 10:46:50.223 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 41.68\n",
      "2021-08-25 10:46:50.224 | INFO     | src.policies:train:109 - Episode 2049\n",
      "2021-08-25 10:46:50.233 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:50.234 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:50.235 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 41.75\n",
      "2021-08-25 10:46:50.236 | INFO     | src.policies:train:109 - Episode 2050\n",
      "2021-08-25 10:46:50.285 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:50.286 | INFO     | src.policies:train:121 - Mean episode return: 136.0\n",
      "2021-08-25 10:46:50.287 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 42.85\n",
      "2021-08-25 10:46:50.288 | WARNING  | src.policies:train:131 - The actual batch size is 210, instead of 200\n",
      "2021-08-25 10:46:50.293 | INFO     | src.policies:train:157 - Total loss: 349.3189392089844\n",
      "2021-08-25 10:46:50.294 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:50.297 | INFO     | src.policies:train:103 - Epoch 287 / 800\n",
      "2021-08-25 10:46:50.298 | INFO     | src.policies:train:109 - Episode 2051\n",
      "2021-08-25 10:46:50.304 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:50.305 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:50.306 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 42.55\n",
      "2021-08-25 10:46:50.306 | INFO     | src.policies:train:109 - Episode 2052\n",
      "2021-08-25 10:46:50.314 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:50.315 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 10:46:50.316 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 42.46\n",
      "2021-08-25 10:46:50.317 | INFO     | src.policies:train:109 - Episode 2053\n",
      "2021-08-25 10:46:50.323 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:50.324 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 10:46:50.324 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 42.23\n",
      "2021-08-25 10:46:50.325 | INFO     | src.policies:train:109 - Episode 2054\n",
      "2021-08-25 10:46:50.343 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:50.344 | INFO     | src.policies:train:121 - Mean episode return: 44.0\n",
      "2021-08-25 10:46:50.345 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 42.35\n",
      "2021-08-25 10:46:50.346 | INFO     | src.policies:train:109 - Episode 2055\n",
      "2021-08-25 10:46:50.357 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:50.358 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 10:46:50.359 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 42.12\n",
      "2021-08-25 10:46:50.360 | INFO     | src.policies:train:109 - Episode 2056\n",
      "2021-08-25 10:46:50.394 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:50.395 | INFO     | src.policies:train:121 - Mean episode return: 90.0\n",
      "2021-08-25 10:46:50.396 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 42.68\n",
      "2021-08-25 10:46:50.397 | INFO     | src.policies:train:109 - Episode 2057\n",
      "2021-08-25 10:46:50.410 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:50.411 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 10:46:50.412 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 41.85\n",
      "2021-08-25 10:46:50.413 | WARNING  | src.policies:train:131 - The actual batch size is 221, instead of 200\n",
      "2021-08-25 10:46:50.419 | INFO     | src.policies:train:157 - Total loss: 174.9619598388672\n",
      "2021-08-25 10:46:50.420 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:50.422 | INFO     | src.policies:train:103 - Epoch 288 / 800\n",
      "2021-08-25 10:46:50.424 | INFO     | src.policies:train:109 - Episode 2058\n",
      "2021-08-25 10:46:50.436 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:50.437 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 10:46:50.438 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 41.76\n",
      "2021-08-25 10:46:50.439 | INFO     | src.policies:train:109 - Episode 2059\n",
      "2021-08-25 10:46:50.464 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:50.465 | INFO     | src.policies:train:121 - Mean episode return: 65.0\n",
      "2021-08-25 10:46:50.466 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 41.85\n",
      "2021-08-25 10:46:50.467 | INFO     | src.policies:train:109 - Episode 2060\n",
      "2021-08-25 10:46:50.485 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:50.486 | INFO     | src.policies:train:121 - Mean episode return: 44.0\n",
      "2021-08-25 10:46:50.487 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 41.57\n",
      "2021-08-25 10:46:50.488 | INFO     | src.policies:train:109 - Episode 2061\n",
      "2021-08-25 10:46:50.502 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:50.503 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 10:46:50.504 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 40.77\n",
      "2021-08-25 10:46:50.505 | INFO     | src.policies:train:109 - Episode 2062\n",
      "2021-08-25 10:46:50.522 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:50.523 | INFO     | src.policies:train:121 - Mean episode return: 42.0\n",
      "2021-08-25 10:46:50.524 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 40.85\n",
      "2021-08-25 10:46:50.525 | WARNING  | src.policies:train:131 - The actual batch size is 213, instead of 200\n",
      "2021-08-25 10:46:50.530 | INFO     | src.policies:train:157 - Total loss: 131.68875122070312\n",
      "2021-08-25 10:46:50.531 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:50.534 | INFO     | src.policies:train:103 - Epoch 289 / 800\n",
      "2021-08-25 10:46:50.535 | INFO     | src.policies:train:109 - Episode 2063\n",
      "2021-08-25 10:46:50.548 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:50.549 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:50.550 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 40.84\n",
      "2021-08-25 10:46:50.551 | INFO     | src.policies:train:109 - Episode 2064\n",
      "2021-08-25 10:46:50.569 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:50.570 | INFO     | src.policies:train:121 - Mean episode return: 45.0\n",
      "2021-08-25 10:46:50.571 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 40.82\n",
      "2021-08-25 10:46:50.572 | INFO     | src.policies:train:109 - Episode 2065\n",
      "2021-08-25 10:46:50.602 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:50.603 | INFO     | src.policies:train:121 - Mean episode return: 83.0\n",
      "2021-08-25 10:46:50.604 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 41.52\n",
      "2021-08-25 10:46:50.605 | INFO     | src.policies:train:109 - Episode 2066\n",
      "2021-08-25 10:46:50.649 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:50.650 | INFO     | src.policies:train:121 - Mean episode return: 118.0\n",
      "2021-08-25 10:46:50.651 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 40.81\n",
      "2021-08-25 10:46:50.652 | WARNING  | src.policies:train:131 - The actual batch size is 277, instead of 200\n",
      "2021-08-25 10:46:50.658 | INFO     | src.policies:train:157 - Total loss: 311.86944580078125\n",
      "2021-08-25 10:46:50.659 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:50.662 | INFO     | src.policies:train:103 - Epoch 290 / 800\n",
      "2021-08-25 10:46:50.663 | INFO     | src.policies:train:109 - Episode 2067\n",
      "2021-08-25 10:46:50.672 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:50.674 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 10:46:50.674 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 40.89\n",
      "2021-08-25 10:46:50.675 | INFO     | src.policies:train:109 - Episode 2068\n",
      "2021-08-25 10:46:50.692 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:50.694 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 10:46:50.694 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 40.68\n",
      "2021-08-25 10:46:50.695 | INFO     | src.policies:train:109 - Episode 2069\n",
      "2021-08-25 10:46:50.708 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:50.709 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 10:46:50.710 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 40.17\n",
      "2021-08-25 10:46:50.711 | INFO     | src.policies:train:109 - Episode 2070\n",
      "2021-08-25 10:46:50.723 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:50.724 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 10:46:50.725 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.86\n",
      "2021-08-25 10:46:50.726 | INFO     | src.policies:train:109 - Episode 2071\n",
      "2021-08-25 10:46:50.743 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:50.744 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 10:46:50.745 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 40.06\n",
      "2021-08-25 10:46:50.746 | INFO     | src.policies:train:109 - Episode 2072\n",
      "2021-08-25 10:46:50.789 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:50.790 | INFO     | src.policies:train:121 - Mean episode return: 119.0\n",
      "2021-08-25 10:46:50.791 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 40.15\n",
      "2021-08-25 10:46:50.792 | WARNING  | src.policies:train:131 - The actual batch size is 273, instead of 200\n",
      "2021-08-25 10:46:50.797 | INFO     | src.policies:train:157 - Total loss: 230.05384826660156\n",
      "2021-08-25 10:46:50.798 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:50.801 | INFO     | src.policies:train:103 - Epoch 291 / 800\n",
      "2021-08-25 10:46:50.802 | INFO     | src.policies:train:109 - Episode 2073\n",
      "2021-08-25 10:46:50.815 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:50.816 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 10:46:50.817 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 40.12\n",
      "2021-08-25 10:46:50.818 | INFO     | src.policies:train:109 - Episode 2074\n",
      "2021-08-25 10:46:50.832 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:50.834 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 10:46:50.834 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 40.2\n",
      "2021-08-25 10:46:50.835 | INFO     | src.policies:train:109 - Episode 2075\n",
      "2021-08-25 10:46:50.843 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:50.844 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:50.844 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.99\n",
      "2021-08-25 10:46:50.845 | INFO     | src.policies:train:109 - Episode 2076\n",
      "2021-08-25 10:46:50.858 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:50.859 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 10:46:50.860 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 40.14\n",
      "2021-08-25 10:46:50.861 | INFO     | src.policies:train:109 - Episode 2077\n",
      "2021-08-25 10:46:50.868 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:50.869 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:50.870 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.55\n",
      "2021-08-25 10:46:50.871 | INFO     | src.policies:train:109 - Episode 2078\n",
      "2021-08-25 10:46:50.888 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:50.889 | INFO     | src.policies:train:121 - Mean episode return: 42.0\n",
      "2021-08-25 10:46:50.890 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.69\n",
      "2021-08-25 10:46:50.891 | INFO     | src.policies:train:109 - Episode 2079\n",
      "2021-08-25 10:46:50.899 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:50.900 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:50.901 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.41\n",
      "2021-08-25 10:46:50.902 | INFO     | src.policies:train:109 - Episode 2080\n",
      "2021-08-25 10:46:50.919 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:50.920 | INFO     | src.policies:train:121 - Mean episode return: 39.0\n",
      "2021-08-25 10:46:50.921 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.4\n",
      "2021-08-25 10:46:50.922 | WARNING  | src.policies:train:131 - The actual batch size is 212, instead of 200\n",
      "2021-08-25 10:46:50.928 | INFO     | src.policies:train:157 - Total loss: 44.63640594482422\n",
      "2021-08-25 10:46:50.929 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:50.932 | INFO     | src.policies:train:103 - Epoch 292 / 800\n",
      "2021-08-25 10:46:50.933 | INFO     | src.policies:train:109 - Episode 2081\n",
      "2021-08-25 10:46:50.946 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:50.947 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 10:46:50.948 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.53\n",
      "2021-08-25 10:46:50.949 | INFO     | src.policies:train:109 - Episode 2082\n",
      "2021-08-25 10:46:50.956 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:50.957 | INFO     | src.policies:train:121 - Mean episode return: 9.0\n",
      "2021-08-25 10:46:50.958 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.48\n",
      "2021-08-25 10:46:50.959 | INFO     | src.policies:train:109 - Episode 2083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:50.968 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:50.969 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:50.970 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.51\n",
      "2021-08-25 10:46:50.971 | INFO     | src.policies:train:109 - Episode 2084\n",
      "2021-08-25 10:46:50.979 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:50.980 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:50.981 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.67\n",
      "2021-08-25 10:46:50.982 | INFO     | src.policies:train:109 - Episode 2085\n",
      "2021-08-25 10:46:50.990 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:50.991 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:50.992 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.34\n",
      "2021-08-25 10:46:50.993 | INFO     | src.policies:train:109 - Episode 2086\n",
      "2021-08-25 10:46:51.000 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:51.001 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:51.002 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.27\n",
      "2021-08-25 10:46:51.003 | INFO     | src.policies:train:109 - Episode 2087\n",
      "2021-08-25 10:46:51.015 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:51.016 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 10:46:51.017 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.9\n",
      "2021-08-25 10:46:51.018 | INFO     | src.policies:train:109 - Episode 2088\n",
      "2021-08-25 10:46:51.034 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:51.035 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 10:46:51.036 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.16\n",
      "2021-08-25 10:46:51.037 | INFO     | src.policies:train:109 - Episode 2089\n",
      "2021-08-25 10:46:51.048 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:51.049 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 10:46:51.050 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.04\n",
      "2021-08-25 10:46:51.051 | INFO     | src.policies:train:109 - Episode 2090\n",
      "2021-08-25 10:46:51.065 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:51.066 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 10:46:51.067 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.23\n",
      "2021-08-25 10:46:51.068 | WARNING  | src.policies:train:131 - The actual batch size is 219, instead of 200\n",
      "2021-08-25 10:46:51.074 | INFO     | src.policies:train:157 - Total loss: 108.68630981445312\n",
      "2021-08-25 10:46:51.075 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:51.078 | INFO     | src.policies:train:103 - Epoch 293 / 800\n",
      "2021-08-25 10:46:51.079 | INFO     | src.policies:train:109 - Episode 2091\n",
      "2021-08-25 10:46:51.096 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:51.098 | INFO     | src.policies:train:121 - Mean episode return: 44.0\n",
      "2021-08-25 10:46:51.098 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.5\n",
      "2021-08-25 10:46:51.099 | INFO     | src.policies:train:109 - Episode 2092\n",
      "2021-08-25 10:46:51.108 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:51.109 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 10:46:51.110 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.09\n",
      "2021-08-25 10:46:51.111 | INFO     | src.policies:train:109 - Episode 2093\n",
      "2021-08-25 10:46:51.141 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:51.142 | INFO     | src.policies:train:121 - Mean episode return: 78.0\n",
      "2021-08-25 10:46:51.143 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.75\n",
      "2021-08-25 10:46:51.144 | INFO     | src.policies:train:109 - Episode 2094\n",
      "2021-08-25 10:46:51.181 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:51.182 | INFO     | src.policies:train:121 - Mean episode return: 99.0\n",
      "2021-08-25 10:46:51.183 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.16\n",
      "2021-08-25 10:46:51.184 | WARNING  | src.policies:train:131 - The actual batch size is 237, instead of 200\n",
      "2021-08-25 10:46:51.190 | INFO     | src.policies:train:157 - Total loss: 249.6051025390625\n",
      "2021-08-25 10:46:51.191 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:51.193 | INFO     | src.policies:train:103 - Epoch 294 / 800\n",
      "2021-08-25 10:46:51.194 | INFO     | src.policies:train:109 - Episode 2095\n",
      "2021-08-25 10:46:51.202 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:51.203 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:51.204 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.79\n",
      "2021-08-25 10:46:51.205 | INFO     | src.policies:train:109 - Episode 2096\n",
      "2021-08-25 10:46:51.213 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:51.214 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:51.214 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.59\n",
      "2021-08-25 10:46:51.215 | INFO     | src.policies:train:109 - Episode 2097\n",
      "2021-08-25 10:46:51.225 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:51.226 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 10:46:51.227 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.31\n",
      "2021-08-25 10:46:51.228 | INFO     | src.policies:train:109 - Episode 2098\n",
      "2021-08-25 10:46:51.242 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:51.244 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 10:46:51.244 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.45\n",
      "2021-08-25 10:46:51.245 | INFO     | src.policies:train:109 - Episode 2099\n",
      "2021-08-25 10:46:51.253 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:51.254 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 10:46:51.255 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.32\n",
      "2021-08-25 10:46:51.256 | INFO     | src.policies:train:109 - Episode 2100\n",
      "2021-08-25 10:46:51.273 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:51.274 | INFO     | src.policies:train:121 - Mean episode return: 43.0\n",
      "2021-08-25 10:46:51.275 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.3\n",
      "2021-08-25 10:46:51.276 | INFO     | src.policies:train:109 - Episode 2101\n",
      "2021-08-25 10:46:51.298 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:51.299 | INFO     | src.policies:train:121 - Mean episode return: 57.0\n",
      "2021-08-25 10:46:51.300 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.3\n",
      "2021-08-25 10:46:51.301 | INFO     | src.policies:train:109 - Episode 2102\n",
      "2021-08-25 10:46:51.329 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:51.330 | INFO     | src.policies:train:121 - Mean episode return: 77.0\n",
      "2021-08-25 10:46:51.331 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.88\n",
      "2021-08-25 10:46:51.332 | WARNING  | src.policies:train:131 - The actual batch size is 267, instead of 200\n",
      "2021-08-25 10:46:51.339 | INFO     | src.policies:train:157 - Total loss: 154.51730346679688\n",
      "2021-08-25 10:46:51.339 | INFO     | src.policies:train:161 - Epoch infos: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:51.342 | INFO     | src.policies:train:103 - Epoch 295 / 800\n",
      "2021-08-25 10:46:51.343 | INFO     | src.policies:train:109 - Episode 2103\n",
      "2021-08-25 10:46:51.364 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:51.365 | INFO     | src.policies:train:121 - Mean episode return: 56.0\n",
      "2021-08-25 10:46:51.366 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.29\n",
      "2021-08-25 10:46:51.367 | INFO     | src.policies:train:109 - Episode 2104\n",
      "2021-08-25 10:46:51.377 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:51.378 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 10:46:51.379 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.32\n",
      "2021-08-25 10:46:51.380 | INFO     | src.policies:train:109 - Episode 2105\n",
      "2021-08-25 10:46:51.395 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:51.396 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 10:46:51.397 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.11\n",
      "2021-08-25 10:46:51.398 | INFO     | src.policies:train:109 - Episode 2106\n",
      "2021-08-25 10:46:51.408 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:51.409 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:51.410 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.99\n",
      "2021-08-25 10:46:51.411 | INFO     | src.policies:train:109 - Episode 2107\n",
      "2021-08-25 10:46:51.418 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:51.419 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 10:46:51.420 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.92\n",
      "2021-08-25 10:46:51.421 | INFO     | src.policies:train:109 - Episode 2108\n",
      "2021-08-25 10:46:51.438 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:51.439 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 10:46:51.440 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.96\n",
      "2021-08-25 10:46:51.441 | INFO     | src.policies:train:109 - Episode 2109\n",
      "2021-08-25 10:46:51.454 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:51.455 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 10:46:51.456 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.84\n",
      "2021-08-25 10:46:51.457 | WARNING  | src.policies:train:131 - The actual batch size is 206, instead of 200\n",
      "2021-08-25 10:46:51.463 | INFO     | src.policies:train:157 - Total loss: 63.60720443725586\n",
      "2021-08-25 10:46:51.464 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:51.466 | INFO     | src.policies:train:103 - Epoch 296 / 800\n",
      "2021-08-25 10:46:51.468 | INFO     | src.policies:train:109 - Episode 2110\n",
      "2021-08-25 10:46:51.489 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:51.490 | INFO     | src.policies:train:121 - Mean episode return: 56.0\n",
      "2021-08-25 10:46:51.491 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.15\n",
      "2021-08-25 10:46:51.492 | INFO     | src.policies:train:109 - Episode 2111\n",
      "2021-08-25 10:46:51.507 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:51.508 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 10:46:51.509 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.9\n",
      "2021-08-25 10:46:51.510 | INFO     | src.policies:train:109 - Episode 2112\n",
      "2021-08-25 10:46:51.520 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:51.521 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 10:46:51.522 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.93\n",
      "2021-08-25 10:46:51.523 | INFO     | src.policies:train:109 - Episode 2113\n",
      "2021-08-25 10:46:51.531 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:51.532 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:51.533 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.47\n",
      "2021-08-25 10:46:51.534 | INFO     | src.policies:train:109 - Episode 2114\n",
      "2021-08-25 10:46:51.569 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:51.571 | INFO     | src.policies:train:121 - Mean episode return: 95.0\n",
      "2021-08-25 10:46:51.571 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.31\n",
      "2021-08-25 10:46:51.572 | WARNING  | src.policies:train:131 - The actual batch size is 222, instead of 200\n",
      "2021-08-25 10:46:51.578 | INFO     | src.policies:train:157 - Total loss: 197.7423858642578\n",
      "2021-08-25 10:46:51.578 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:51.582 | INFO     | src.policies:train:103 - Epoch 297 / 800\n",
      "2021-08-25 10:46:51.583 | INFO     | src.policies:train:109 - Episode 2115\n",
      "2021-08-25 10:46:51.608 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:51.609 | INFO     | src.policies:train:121 - Mean episode return: 69.0\n",
      "2021-08-25 10:46:51.610 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.25\n",
      "2021-08-25 10:46:51.611 | INFO     | src.policies:train:109 - Episode 2116\n",
      "2021-08-25 10:46:51.625 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:51.626 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 10:46:51.627 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.38\n",
      "2021-08-25 10:46:51.628 | INFO     | src.policies:train:109 - Episode 2117\n",
      "2021-08-25 10:46:51.640 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:51.641 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 10:46:51.642 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.89\n",
      "2021-08-25 10:46:51.643 | INFO     | src.policies:train:109 - Episode 2118\n",
      "2021-08-25 10:46:51.697 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:51.698 | INFO     | src.policies:train:121 - Mean episode return: 153.0\n",
      "2021-08-25 10:46:51.699 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.29\n",
      "2021-08-25 10:46:51.700 | WARNING  | src.policies:train:131 - The actual batch size is 276, instead of 200\n",
      "2021-08-25 10:46:51.705 | INFO     | src.policies:train:157 - Total loss: 359.9305725097656\n",
      "2021-08-25 10:46:51.706 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:51.709 | INFO     | src.policies:train:103 - Epoch 298 / 800\n",
      "2021-08-25 10:46:51.711 | INFO     | src.policies:train:109 - Episode 2119\n",
      "2021-08-25 10:46:51.733 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:51.734 | INFO     | src.policies:train:121 - Mean episode return: 60.0\n",
      "2021-08-25 10:46:51.735 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.48\n",
      "2021-08-25 10:46:51.736 | INFO     | src.policies:train:109 - Episode 2120\n",
      "2021-08-25 10:46:51.747 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:51.748 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 10:46:51.749 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.34\n",
      "2021-08-25 10:46:51.750 | INFO     | src.policies:train:109 - Episode 2121\n",
      "2021-08-25 10:46:51.790 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:51.792 | INFO     | src.policies:train:121 - Mean episode return: 114.0\n",
      "2021-08-25 10:46:51.792 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.33\n",
      "2021-08-25 10:46:51.793 | INFO     | src.policies:train:109 - Episode 2122\n",
      "2021-08-25 10:46:51.801 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:51.802 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:51.803 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.32\n",
      "2021-08-25 10:46:51.804 | WARNING  | src.policies:train:131 - The actual batch size is 209, instead of 200\n",
      "2021-08-25 10:46:51.809 | INFO     | src.policies:train:157 - Total loss: 269.7599792480469\n",
      "2021-08-25 10:46:51.809 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:51.813 | INFO     | src.policies:train:103 - Epoch 299 / 800\n",
      "2021-08-25 10:46:51.814 | INFO     | src.policies:train:109 - Episode 2123\n",
      "2021-08-25 10:46:51.831 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:51.832 | INFO     | src.policies:train:121 - Mean episode return: 42.0\n",
      "2021-08-25 10:46:51.833 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.5\n",
      "2021-08-25 10:46:51.834 | INFO     | src.policies:train:109 - Episode 2124\n",
      "2021-08-25 10:46:51.841 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:51.842 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 10:46:51.843 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.31\n",
      "2021-08-25 10:46:51.844 | INFO     | src.policies:train:109 - Episode 2125\n",
      "2021-08-25 10:46:51.856 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:51.857 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 10:46:51.858 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.38\n",
      "2021-08-25 10:46:51.859 | INFO     | src.policies:train:109 - Episode 2126\n",
      "2021-08-25 10:46:51.885 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:51.886 | INFO     | src.policies:train:121 - Mean episode return: 70.0\n",
      "2021-08-25 10:46:51.887 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.53\n",
      "2021-08-25 10:46:51.888 | INFO     | src.policies:train:109 - Episode 2127\n",
      "2021-08-25 10:46:51.903 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:51.904 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 10:46:51.905 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.73\n",
      "2021-08-25 10:46:51.906 | INFO     | src.policies:train:109 - Episode 2128\n",
      "2021-08-25 10:46:51.959 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:51.960 | INFO     | src.policies:train:121 - Mean episode return: 147.0\n",
      "2021-08-25 10:46:51.961 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 40.65\n",
      "2021-08-25 10:46:51.962 | WARNING  | src.policies:train:131 - The actual batch size is 327, instead of 200\n",
      "2021-08-25 10:46:51.969 | INFO     | src.policies:train:157 - Total loss: 327.7034606933594\n",
      "2021-08-25 10:46:51.970 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:51.973 | INFO     | src.policies:train:103 - Epoch 300 / 800\n",
      "2021-08-25 10:46:51.974 | INFO     | src.policies:train:109 - Episode 2129\n",
      "2021-08-25 10:46:52.006 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:52.008 | INFO     | src.policies:train:121 - Mean episode return: 89.0\n",
      "2021-08-25 10:46:52.009 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 41.27\n",
      "2021-08-25 10:46:52.010 | INFO     | src.policies:train:109 - Episode 2130\n",
      "2021-08-25 10:46:52.037 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:52.038 | INFO     | src.policies:train:121 - Mean episode return: 68.0\n",
      "2021-08-25 10:46:52.039 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 41.14\n",
      "2021-08-25 10:46:52.040 | INFO     | src.policies:train:109 - Episode 2131\n",
      "2021-08-25 10:46:52.060 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:52.061 | INFO     | src.policies:train:121 - Mean episode return: 50.0\n",
      "2021-08-25 10:46:52.062 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 41.54\n",
      "2021-08-25 10:46:52.063 | WARNING  | src.policies:train:131 - The actual batch size is 207, instead of 200\n",
      "2021-08-25 10:46:52.068 | INFO     | src.policies:train:157 - Total loss: 190.8530731201172\n",
      "2021-08-25 10:46:52.069 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:52.072 | INFO     | src.policies:train:103 - Epoch 301 / 800\n",
      "2021-08-25 10:46:52.074 | INFO     | src.policies:train:109 - Episode 2132\n",
      "2021-08-25 10:46:52.090 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:52.091 | INFO     | src.policies:train:121 - Mean episode return: 42.0\n",
      "2021-08-25 10:46:52.092 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 41.8\n",
      "2021-08-25 10:46:52.093 | INFO     | src.policies:train:109 - Episode 2133\n",
      "2021-08-25 10:46:52.110 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:52.111 | INFO     | src.policies:train:121 - Mean episode return: 41.0\n",
      "2021-08-25 10:46:52.112 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 41.73\n",
      "2021-08-25 10:46:52.113 | INFO     | src.policies:train:109 - Episode 2134\n",
      "2021-08-25 10:46:52.130 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:52.131 | INFO     | src.policies:train:121 - Mean episode return: 44.0\n",
      "2021-08-25 10:46:52.132 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 41.9\n",
      "2021-08-25 10:46:52.133 | INFO     | src.policies:train:109 - Episode 2135\n",
      "2021-08-25 10:46:52.142 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:52.143 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 10:46:52.144 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 41.94\n",
      "2021-08-25 10:46:52.145 | INFO     | src.policies:train:109 - Episode 2136\n",
      "2021-08-25 10:46:52.159 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:52.161 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 10:46:52.161 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 42.1\n",
      "2021-08-25 10:46:52.163 | INFO     | src.policies:train:109 - Episode 2137\n",
      "2021-08-25 10:46:52.195 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:52.196 | INFO     | src.policies:train:121 - Mean episode return: 88.0\n",
      "2021-08-25 10:46:52.197 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 42.83\n",
      "2021-08-25 10:46:52.198 | WARNING  | src.policies:train:131 - The actual batch size is 266, instead of 200\n",
      "2021-08-25 10:46:52.204 | INFO     | src.policies:train:157 - Total loss: 233.779296875\n",
      "2021-08-25 10:46:52.204 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:52.207 | INFO     | src.policies:train:103 - Epoch 302 / 800\n",
      "2021-08-25 10:46:52.208 | INFO     | src.policies:train:109 - Episode 2138\n",
      "2021-08-25 10:46:52.225 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:52.226 | INFO     | src.policies:train:121 - Mean episode return: 43.0\n",
      "2021-08-25 10:46:52.227 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 42.76\n",
      "2021-08-25 10:46:52.228 | INFO     | src.policies:train:109 - Episode 2139\n",
      "2021-08-25 10:46:52.252 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:52.253 | INFO     | src.policies:train:121 - Mean episode return: 58.0\n",
      "2021-08-25 10:46:52.254 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 42.36\n",
      "2021-08-25 10:46:52.255 | INFO     | src.policies:train:109 - Episode 2140\n",
      "2021-08-25 10:46:52.284 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:52.285 | INFO     | src.policies:train:121 - Mean episode return: 76.0\n",
      "2021-08-25 10:46:52.286 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 42.22\n",
      "2021-08-25 10:46:52.287 | INFO     | src.policies:train:109 - Episode 2141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:52.295 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:52.296 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 10:46:52.297 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 42.26\n",
      "2021-08-25 10:46:52.298 | INFO     | src.policies:train:109 - Episode 2142\n",
      "2021-08-25 10:46:52.324 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:52.325 | INFO     | src.policies:train:121 - Mean episode return: 70.0\n",
      "2021-08-25 10:46:52.326 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 42.78\n",
      "2021-08-25 10:46:52.327 | WARNING  | src.policies:train:131 - The actual batch size is 262, instead of 200\n",
      "2021-08-25 10:46:52.333 | INFO     | src.policies:train:157 - Total loss: 171.0751953125\n",
      "2021-08-25 10:46:52.333 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:52.336 | INFO     | src.policies:train:103 - Epoch 303 / 800\n",
      "2021-08-25 10:46:52.338 | INFO     | src.policies:train:109 - Episode 2143\n",
      "2021-08-25 10:46:52.353 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:52.355 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 10:46:52.355 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 42.79\n",
      "2021-08-25 10:46:52.356 | INFO     | src.policies:train:109 - Episode 2144\n",
      "2021-08-25 10:46:52.366 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:52.367 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 10:46:52.368 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 42.75\n",
      "2021-08-25 10:46:52.369 | INFO     | src.policies:train:109 - Episode 2145\n",
      "2021-08-25 10:46:52.379 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:52.381 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 10:46:52.381 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 41.83\n",
      "2021-08-25 10:46:52.382 | INFO     | src.policies:train:109 - Episode 2146\n",
      "2021-08-25 10:46:52.394 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:52.395 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 10:46:52.396 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 41.92\n",
      "2021-08-25 10:46:52.397 | INFO     | src.policies:train:109 - Episode 2147\n",
      "2021-08-25 10:46:52.445 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:52.446 | INFO     | src.policies:train:121 - Mean episode return: 135.0\n",
      "2021-08-25 10:46:52.447 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 43.12\n",
      "2021-08-25 10:46:52.447 | WARNING  | src.policies:train:131 - The actual batch size is 238, instead of 200\n",
      "2021-08-25 10:46:52.453 | INFO     | src.policies:train:157 - Total loss: 356.5030822753906\n",
      "2021-08-25 10:46:52.454 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:52.457 | INFO     | src.policies:train:103 - Epoch 304 / 800\n",
      "2021-08-25 10:46:52.458 | INFO     | src.policies:train:109 - Episode 2148\n",
      "2021-08-25 10:46:52.487 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:52.488 | INFO     | src.policies:train:121 - Mean episode return: 83.0\n",
      "2021-08-25 10:46:52.489 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 43.69\n",
      "2021-08-25 10:46:52.490 | INFO     | src.policies:train:109 - Episode 2149\n",
      "2021-08-25 10:46:52.497 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:52.498 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 10:46:52.499 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 43.62\n",
      "2021-08-25 10:46:52.500 | INFO     | src.policies:train:109 - Episode 2150\n",
      "2021-08-25 10:46:52.529 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:52.530 | INFO     | src.policies:train:121 - Mean episode return: 80.0\n",
      "2021-08-25 10:46:52.531 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 43.06\n",
      "2021-08-25 10:46:52.532 | INFO     | src.policies:train:109 - Episode 2151\n",
      "2021-08-25 10:46:52.566 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:52.567 | INFO     | src.policies:train:121 - Mean episode return: 92.0\n",
      "2021-08-25 10:46:52.568 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 43.86\n",
      "2021-08-25 10:46:52.569 | WARNING  | src.policies:train:131 - The actual batch size is 266, instead of 200\n",
      "2021-08-25 10:46:52.574 | INFO     | src.policies:train:157 - Total loss: 344.47113037109375\n",
      "2021-08-25 10:46:52.575 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:52.578 | INFO     | src.policies:train:103 - Epoch 305 / 800\n",
      "2021-08-25 10:46:52.579 | INFO     | src.policies:train:109 - Episode 2152\n",
      "2021-08-25 10:46:52.588 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:52.589 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:52.590 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 43.94\n",
      "2021-08-25 10:46:52.591 | INFO     | src.policies:train:109 - Episode 2153\n",
      "2021-08-25 10:46:52.625 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:52.626 | INFO     | src.policies:train:121 - Mean episode return: 94.0\n",
      "2021-08-25 10:46:52.627 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 44.78\n",
      "2021-08-25 10:46:52.628 | INFO     | src.policies:train:109 - Episode 2154\n",
      "2021-08-25 10:46:52.646 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:52.647 | INFO     | src.policies:train:121 - Mean episode return: 45.0\n",
      "2021-08-25 10:46:52.648 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 44.79\n",
      "2021-08-25 10:46:52.649 | INFO     | src.policies:train:109 - Episode 2155\n",
      "2021-08-25 10:46:52.676 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:52.677 | INFO     | src.policies:train:121 - Mean episode return: 71.0\n",
      "2021-08-25 10:46:52.678 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 45.25\n",
      "2021-08-25 10:46:52.679 | WARNING  | src.policies:train:131 - The actual batch size is 229, instead of 200\n",
      "2021-08-25 10:46:52.685 | INFO     | src.policies:train:157 - Total loss: 206.22935485839844\n",
      "2021-08-25 10:46:52.685 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:52.688 | INFO     | src.policies:train:103 - Epoch 306 / 800\n",
      "2021-08-25 10:46:52.689 | INFO     | src.policies:train:109 - Episode 2156\n",
      "2021-08-25 10:46:52.698 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:52.699 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 10:46:52.700 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 44.54\n",
      "2021-08-25 10:46:52.701 | INFO     | src.policies:train:109 - Episode 2157\n",
      "2021-08-25 10:46:52.749 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:52.751 | INFO     | src.policies:train:121 - Mean episode return: 138.0\n",
      "2021-08-25 10:46:52.751 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 45.63\n",
      "2021-08-25 10:46:52.752 | INFO     | src.policies:train:109 - Episode 2158\n",
      "2021-08-25 10:46:52.782 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:52.783 | INFO     | src.policies:train:121 - Mean episode return: 74.0\n",
      "2021-08-25 10:46:52.784 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 46.05\n",
      "2021-08-25 10:46:52.785 | WARNING  | src.policies:train:131 - The actual batch size is 231, instead of 200\n",
      "2021-08-25 10:46:52.790 | INFO     | src.policies:train:157 - Total loss: 343.002197265625\n",
      "2021-08-25 10:46:52.791 | INFO     | src.policies:train:161 - Epoch infos: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:52.794 | INFO     | src.policies:train:103 - Epoch 307 / 800\n",
      "2021-08-25 10:46:52.795 | INFO     | src.policies:train:109 - Episode 2159\n",
      "2021-08-25 10:46:52.831 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:52.832 | INFO     | src.policies:train:121 - Mean episode return: 103.0\n",
      "2021-08-25 10:46:52.833 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 46.43\n",
      "2021-08-25 10:46:52.834 | INFO     | src.policies:train:109 - Episode 2160\n",
      "2021-08-25 10:46:52.845 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:52.846 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 10:46:52.846 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 46.23\n",
      "2021-08-25 10:46:52.847 | INFO     | src.policies:train:109 - Episode 2161\n",
      "2021-08-25 10:46:52.869 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:52.870 | INFO     | src.policies:train:121 - Mean episode return: 56.0\n",
      "2021-08-25 10:46:52.871 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 46.49\n",
      "2021-08-25 10:46:52.872 | INFO     | src.policies:train:109 - Episode 2162\n",
      "2021-08-25 10:46:52.880 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:52.882 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 10:46:52.882 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 46.21\n",
      "2021-08-25 10:46:52.884 | INFO     | src.policies:train:109 - Episode 2163\n",
      "2021-08-25 10:46:52.919 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:52.920 | INFO     | src.policies:train:121 - Mean episode return: 96.0\n",
      "2021-08-25 10:46:52.921 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 46.86\n",
      "2021-08-25 10:46:52.922 | WARNING  | src.policies:train:131 - The actual batch size is 293, instead of 200\n",
      "2021-08-25 10:46:52.928 | INFO     | src.policies:train:157 - Total loss: 276.15704345703125\n",
      "2021-08-25 10:46:52.928 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:52.931 | INFO     | src.policies:train:103 - Epoch 308 / 800\n",
      "2021-08-25 10:46:52.932 | INFO     | src.policies:train:109 - Episode 2164\n",
      "2021-08-25 10:46:52.950 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:52.952 | INFO     | src.policies:train:121 - Mean episode return: 49.0\n",
      "2021-08-25 10:46:52.953 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 46.9\n",
      "2021-08-25 10:46:52.954 | INFO     | src.policies:train:109 - Episode 2165\n",
      "2021-08-25 10:46:52.979 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:52.980 | INFO     | src.policies:train:121 - Mean episode return: 69.0\n",
      "2021-08-25 10:46:52.981 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 46.76\n",
      "2021-08-25 10:46:52.982 | INFO     | src.policies:train:109 - Episode 2166\n",
      "2021-08-25 10:46:53.013 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:53.014 | INFO     | src.policies:train:121 - Mean episode return: 82.0\n",
      "2021-08-25 10:46:53.015 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 46.4\n",
      "2021-08-25 10:46:53.020 | INFO     | src.policies:train:157 - Total loss: 210.4673614501953\n",
      "2021-08-25 10:46:53.020 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:53.023 | INFO     | src.policies:train:103 - Epoch 309 / 800\n",
      "2021-08-25 10:46:53.024 | INFO     | src.policies:train:109 - Episode 2167\n",
      "2021-08-25 10:46:53.035 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:53.037 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 10:46:53.037 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 46.43\n",
      "2021-08-25 10:46:53.038 | INFO     | src.policies:train:109 - Episode 2168\n",
      "2021-08-25 10:46:53.066 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:53.067 | INFO     | src.policies:train:121 - Mean episode return: 72.0\n",
      "2021-08-25 10:46:53.068 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 46.75\n",
      "2021-08-25 10:46:53.069 | INFO     | src.policies:train:109 - Episode 2169\n",
      "2021-08-25 10:46:53.079 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:53.080 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 10:46:53.081 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 46.68\n",
      "2021-08-25 10:46:53.082 | INFO     | src.policies:train:109 - Episode 2170\n",
      "2021-08-25 10:46:53.097 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:53.098 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 10:46:53.099 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 46.77\n",
      "2021-08-25 10:46:53.100 | INFO     | src.policies:train:109 - Episode 2171\n",
      "2021-08-25 10:46:53.117 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:53.118 | INFO     | src.policies:train:121 - Mean episode return: 43.0\n",
      "2021-08-25 10:46:53.119 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 46.83\n",
      "2021-08-25 10:46:53.120 | INFO     | src.policies:train:109 - Episode 2172\n",
      "2021-08-25 10:46:53.156 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:53.157 | INFO     | src.policies:train:121 - Mean episode return: 98.0\n",
      "2021-08-25 10:46:53.158 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 46.62\n",
      "2021-08-25 10:46:53.158 | WARNING  | src.policies:train:131 - The actual batch size is 295, instead of 200\n",
      "2021-08-25 10:46:53.165 | INFO     | src.policies:train:157 - Total loss: 206.02427673339844\n",
      "2021-08-25 10:46:53.166 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:53.168 | INFO     | src.policies:train:103 - Epoch 310 / 800\n",
      "2021-08-25 10:46:53.169 | INFO     | src.policies:train:109 - Episode 2173\n",
      "2021-08-25 10:46:53.187 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:53.188 | INFO     | src.policies:train:121 - Mean episode return: 45.0\n",
      "2021-08-25 10:46:53.189 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 46.73\n",
      "2021-08-25 10:46:53.190 | INFO     | src.policies:train:109 - Episode 2174\n",
      "2021-08-25 10:46:53.226 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:53.227 | INFO     | src.policies:train:121 - Mean episode return: 100.0\n",
      "2021-08-25 10:46:53.228 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 47.41\n",
      "2021-08-25 10:46:53.229 | INFO     | src.policies:train:109 - Episode 2175\n",
      "2021-08-25 10:46:53.284 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:53.285 | INFO     | src.policies:train:121 - Mean episode return: 149.0\n",
      "2021-08-25 10:46:53.285 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 48.78\n",
      "2021-08-25 10:46:53.286 | WARNING  | src.policies:train:131 - The actual batch size is 294, instead of 200\n",
      "2021-08-25 10:46:53.292 | INFO     | src.policies:train:157 - Total loss: 430.72344970703125\n",
      "2021-08-25 10:46:53.292 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:53.295 | INFO     | src.policies:train:103 - Epoch 311 / 800\n",
      "2021-08-25 10:46:53.296 | INFO     | src.policies:train:109 - Episode 2176\n",
      "2021-08-25 10:46:53.311 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:53.312 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 10:46:53.313 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 48.89\n",
      "2021-08-25 10:46:53.314 | INFO     | src.policies:train:109 - Episode 2177\n",
      "2021-08-25 10:46:53.347 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:53.348 | INFO     | src.policies:train:121 - Mean episode return: 90.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:53.349 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 49.67\n",
      "2021-08-25 10:46:53.350 | INFO     | src.policies:train:109 - Episode 2178\n",
      "2021-08-25 10:46:53.371 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:53.372 | INFO     | src.policies:train:121 - Mean episode return: 48.0\n",
      "2021-08-25 10:46:53.373 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 49.73\n",
      "2021-08-25 10:46:53.374 | INFO     | src.policies:train:109 - Episode 2179\n",
      "2021-08-25 10:46:53.385 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:53.387 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 10:46:53.387 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 49.84\n",
      "2021-08-25 10:46:53.388 | WARNING  | src.policies:train:131 - The actual batch size is 201, instead of 200\n",
      "2021-08-25 10:46:53.394 | INFO     | src.policies:train:157 - Total loss: 196.21240234375\n",
      "2021-08-25 10:46:53.394 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:53.397 | INFO     | src.policies:train:103 - Epoch 312 / 800\n",
      "2021-08-25 10:46:53.398 | INFO     | src.policies:train:109 - Episode 2180\n",
      "2021-08-25 10:46:53.429 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:53.430 | INFO     | src.policies:train:121 - Mean episode return: 88.0\n",
      "2021-08-25 10:46:53.431 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 50.33\n",
      "2021-08-25 10:46:53.432 | INFO     | src.policies:train:109 - Episode 2181\n",
      "2021-08-25 10:46:53.447 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:53.448 | INFO     | src.policies:train:121 - Mean episode return: 39.0\n",
      "2021-08-25 10:46:53.449 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 50.42\n",
      "2021-08-25 10:46:53.450 | INFO     | src.policies:train:109 - Episode 2182\n",
      "2021-08-25 10:46:53.470 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:53.471 | INFO     | src.policies:train:121 - Mean episode return: 50.0\n",
      "2021-08-25 10:46:53.472 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 50.83\n",
      "2021-08-25 10:46:53.473 | INFO     | src.policies:train:109 - Episode 2183\n",
      "2021-08-25 10:46:53.493 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:53.494 | INFO     | src.policies:train:121 - Mean episode return: 48.0\n",
      "2021-08-25 10:46:53.495 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 51.13\n",
      "2021-08-25 10:46:53.496 | WARNING  | src.policies:train:131 - The actual batch size is 225, instead of 200\n",
      "2021-08-25 10:46:53.501 | INFO     | src.policies:train:157 - Total loss: 126.27192687988281\n",
      "2021-08-25 10:46:53.502 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:53.505 | INFO     | src.policies:train:103 - Epoch 313 / 800\n",
      "2021-08-25 10:46:53.506 | INFO     | src.policies:train:109 - Episode 2184\n",
      "2021-08-25 10:46:53.550 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:53.551 | INFO     | src.policies:train:121 - Mean episode return: 126.0\n",
      "2021-08-25 10:46:53.552 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 52.25\n",
      "2021-08-25 10:46:53.553 | INFO     | src.policies:train:109 - Episode 2185\n",
      "2021-08-25 10:46:53.564 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:53.565 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 10:46:53.566 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 52.35\n",
      "2021-08-25 10:46:53.567 | INFO     | src.policies:train:109 - Episode 2186\n",
      "2021-08-25 10:46:53.601 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:53.602 | INFO     | src.policies:train:121 - Mean episode return: 89.0\n",
      "2021-08-25 10:46:53.603 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 53.11\n",
      "2021-08-25 10:46:53.604 | WARNING  | src.policies:train:131 - The actual batch size is 240, instead of 200\n",
      "2021-08-25 10:46:53.609 | INFO     | src.policies:train:157 - Total loss: 308.7666320800781\n",
      "2021-08-25 10:46:53.610 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:53.614 | INFO     | src.policies:train:103 - Epoch 314 / 800\n",
      "2021-08-25 10:46:53.615 | INFO     | src.policies:train:109 - Episode 2187\n",
      "2021-08-25 10:46:53.649 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:53.650 | INFO     | src.policies:train:121 - Mean episode return: 98.0\n",
      "2021-08-25 10:46:53.651 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 53.84\n",
      "2021-08-25 10:46:53.652 | INFO     | src.policies:train:109 - Episode 2188\n",
      "2021-08-25 10:46:53.709 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:53.710 | INFO     | src.policies:train:121 - Mean episode return: 162.0\n",
      "2021-08-25 10:46:53.711 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 55.06\n",
      "2021-08-25 10:46:53.712 | WARNING  | src.policies:train:131 - The actual batch size is 260, instead of 200\n",
      "2021-08-25 10:46:53.718 | INFO     | src.policies:train:157 - Total loss: 415.84857177734375\n",
      "2021-08-25 10:46:53.718 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:53.721 | INFO     | src.policies:train:103 - Epoch 315 / 800\n",
      "2021-08-25 10:46:53.722 | INFO     | src.policies:train:109 - Episode 2189\n",
      "2021-08-25 10:46:53.755 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:53.756 | INFO     | src.policies:train:121 - Mean episode return: 93.0\n",
      "2021-08-25 10:46:53.757 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 55.77\n",
      "2021-08-25 10:46:53.758 | INFO     | src.policies:train:109 - Episode 2190\n",
      "2021-08-25 10:46:53.795 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:53.796 | INFO     | src.policies:train:121 - Mean episode return: 106.0\n",
      "2021-08-25 10:46:53.797 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 56.5\n",
      "2021-08-25 10:46:53.798 | INFO     | src.policies:train:109 - Episode 2191\n",
      "2021-08-25 10:46:53.827 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:53.828 | INFO     | src.policies:train:121 - Mean episode return: 75.0\n",
      "2021-08-25 10:46:53.829 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 56.81\n",
      "2021-08-25 10:46:53.830 | WARNING  | src.policies:train:131 - The actual batch size is 274, instead of 200\n",
      "2021-08-25 10:46:53.835 | INFO     | src.policies:train:157 - Total loss: 289.8154602050781\n",
      "2021-08-25 10:46:53.836 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:53.839 | INFO     | src.policies:train:103 - Epoch 316 / 800\n",
      "2021-08-25 10:46:53.840 | INFO     | src.policies:train:109 - Episode 2192\n",
      "2021-08-25 10:46:53.853 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:53.854 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 10:46:53.855 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 56.97\n",
      "2021-08-25 10:46:53.856 | INFO     | src.policies:train:109 - Episode 2193\n",
      "2021-08-25 10:46:53.886 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:53.887 | INFO     | src.policies:train:121 - Mean episode return: 85.0\n",
      "2021-08-25 10:46:53.888 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 57.04\n",
      "2021-08-25 10:46:53.889 | INFO     | src.policies:train:109 - Episode 2194\n",
      "2021-08-25 10:46:53.946 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:53.947 | INFO     | src.policies:train:121 - Mean episode return: 165.0\n",
      "2021-08-25 10:46:53.947 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 57.7\n",
      "2021-08-25 10:46:53.948 | WARNING  | src.policies:train:131 - The actual batch size is 282, instead of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:53.954 | INFO     | src.policies:train:157 - Total loss: 389.82415771484375\n",
      "2021-08-25 10:46:53.955 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:53.958 | INFO     | src.policies:train:103 - Epoch 317 / 800\n",
      "2021-08-25 10:46:53.959 | INFO     | src.policies:train:109 - Episode 2195\n",
      "2021-08-25 10:46:53.991 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:53.993 | INFO     | src.policies:train:121 - Mean episode return: 95.0\n",
      "2021-08-25 10:46:53.994 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 58.5\n",
      "2021-08-25 10:46:53.994 | INFO     | src.policies:train:109 - Episode 2196\n",
      "2021-08-25 10:46:54.021 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:54.022 | INFO     | src.policies:train:121 - Mean episode return: 68.0\n",
      "2021-08-25 10:46:54.023 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 59.05\n",
      "2021-08-25 10:46:54.024 | INFO     | src.policies:train:109 - Episode 2197\n",
      "2021-08-25 10:46:54.055 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:54.057 | INFO     | src.policies:train:121 - Mean episode return: 84.0\n",
      "2021-08-25 10:46:54.057 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 59.69\n",
      "2021-08-25 10:46:54.058 | WARNING  | src.policies:train:131 - The actual batch size is 247, instead of 200\n",
      "2021-08-25 10:46:54.064 | INFO     | src.policies:train:157 - Total loss: 271.66607666015625\n",
      "2021-08-25 10:46:54.065 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:54.068 | INFO     | src.policies:train:103 - Epoch 318 / 800\n",
      "2021-08-25 10:46:54.069 | INFO     | src.policies:train:109 - Episode 2198\n",
      "2021-08-25 10:46:54.115 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:54.117 | INFO     | src.policies:train:121 - Mean episode return: 137.0\n",
      "2021-08-25 10:46:54.117 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 60.77\n",
      "2021-08-25 10:46:54.118 | INFO     | src.policies:train:109 - Episode 2199\n",
      "2021-08-25 10:46:54.179 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:54.180 | INFO     | src.policies:train:121 - Mean episode return: 179.0\n",
      "2021-08-25 10:46:54.181 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 62.43\n",
      "2021-08-25 10:46:54.182 | WARNING  | src.policies:train:131 - The actual batch size is 316, instead of 200\n",
      "2021-08-25 10:46:54.188 | INFO     | src.policies:train:157 - Total loss: 466.42242431640625\n",
      "2021-08-25 10:46:54.189 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:54.193 | INFO     | src.policies:train:103 - Epoch 319 / 800\n",
      "2021-08-25 10:46:54.194 | INFO     | src.policies:train:109 - Episode 2200\n",
      "2021-08-25 10:46:54.218 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:54.220 | INFO     | src.policies:train:121 - Mean episode return: 64.0\n",
      "2021-08-25 10:46:54.220 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 62.64\n",
      "2021-08-25 10:46:54.221 | INFO     | src.policies:train:109 - Episode 2201\n",
      "2021-08-25 10:46:54.261 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:54.262 | INFO     | src.policies:train:121 - Mean episode return: 105.0\n",
      "2021-08-25 10:46:54.263 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 63.12\n",
      "2021-08-25 10:46:54.264 | INFO     | src.policies:train:109 - Episode 2202\n",
      "2021-08-25 10:46:54.309 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:54.311 | INFO     | src.policies:train:121 - Mean episode return: 127.0\n",
      "2021-08-25 10:46:54.311 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 63.62\n",
      "2021-08-25 10:46:54.312 | WARNING  | src.policies:train:131 - The actual batch size is 296, instead of 200\n",
      "2021-08-25 10:46:54.318 | INFO     | src.policies:train:157 - Total loss: 305.478515625\n",
      "2021-08-25 10:46:54.319 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:54.322 | INFO     | src.policies:train:103 - Epoch 320 / 800\n",
      "2021-08-25 10:46:54.323 | INFO     | src.policies:train:109 - Episode 2203\n",
      "2021-08-25 10:46:54.365 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:54.366 | INFO     | src.policies:train:121 - Mean episode return: 116.0\n",
      "2021-08-25 10:46:54.367 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 64.22\n",
      "2021-08-25 10:46:54.368 | INFO     | src.policies:train:109 - Episode 2204\n",
      "2021-08-25 10:46:54.416 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:54.417 | INFO     | src.policies:train:121 - Mean episode return: 124.0\n",
      "2021-08-25 10:46:54.418 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 65.29\n",
      "2021-08-25 10:46:54.419 | WARNING  | src.policies:train:131 - The actual batch size is 240, instead of 200\n",
      "2021-08-25 10:46:54.425 | INFO     | src.policies:train:157 - Total loss: 359.8569641113281\n",
      "2021-08-25 10:46:54.426 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:54.429 | INFO     | src.policies:train:103 - Epoch 321 / 800\n",
      "2021-08-25 10:46:54.430 | INFO     | src.policies:train:109 - Episode 2205\n",
      "2021-08-25 10:46:54.499 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:54.501 | INFO     | src.policies:train:121 - Mean episode return: 197.0\n",
      "2021-08-25 10:46:54.502 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 66.91\n",
      "2021-08-25 10:46:54.502 | INFO     | src.policies:train:109 - Episode 2206\n",
      "2021-08-25 10:46:54.550 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:54.551 | INFO     | src.policies:train:121 - Mean episode return: 127.0\n",
      "2021-08-25 10:46:54.552 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 67.99\n",
      "2021-08-25 10:46:54.552 | WARNING  | src.policies:train:131 - The actual batch size is 324, instead of 200\n",
      "2021-08-25 10:46:54.559 | INFO     | src.policies:train:157 - Total loss: 495.4691467285156\n",
      "2021-08-25 10:46:54.560 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:54.563 | INFO     | src.policies:train:103 - Epoch 322 / 800\n",
      "2021-08-25 10:46:54.564 | INFO     | src.policies:train:109 - Episode 2207\n",
      "2021-08-25 10:46:54.599 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:54.600 | INFO     | src.policies:train:121 - Mean episode return: 101.0\n",
      "2021-08-25 10:46:54.601 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 68.89\n",
      "2021-08-25 10:46:54.602 | INFO     | src.policies:train:109 - Episode 2208\n",
      "2021-08-25 10:46:54.631 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:54.633 | INFO     | src.policies:train:121 - Mean episode return: 72.0\n",
      "2021-08-25 10:46:54.633 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 69.21\n",
      "2021-08-25 10:46:54.634 | INFO     | src.policies:train:109 - Episode 2209\n",
      "2021-08-25 10:46:54.646 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:54.648 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 10:46:54.649 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 69.19\n",
      "2021-08-25 10:46:54.649 | INFO     | src.policies:train:109 - Episode 2210\n",
      "2021-08-25 10:46:54.683 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:54.684 | INFO     | src.policies:train:121 - Mean episode return: 90.0\n",
      "2021-08-25 10:46:54.685 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 69.53\n",
      "2021-08-25 10:46:54.686 | WARNING  | src.policies:train:131 - The actual batch size is 289, instead of 200\n",
      "2021-08-25 10:46:54.692 | INFO     | src.policies:train:157 - Total loss: 232.98406982421875\n",
      "2021-08-25 10:46:54.693 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:54.697 | INFO     | src.policies:train:103 - Epoch 323 / 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:54.698 | INFO     | src.policies:train:109 - Episode 2211\n",
      "2021-08-25 10:46:54.737 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:54.738 | INFO     | src.policies:train:121 - Mean episode return: 110.0\n",
      "2021-08-25 10:46:54.739 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 70.28\n",
      "2021-08-25 10:46:54.740 | INFO     | src.policies:train:109 - Episode 2212\n",
      "2021-08-25 10:46:54.783 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:54.784 | INFO     | src.policies:train:121 - Mean episode return: 110.0\n",
      "2021-08-25 10:46:54.785 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 71.17\n",
      "2021-08-25 10:46:54.786 | WARNING  | src.policies:train:131 - The actual batch size is 220, instead of 200\n",
      "2021-08-25 10:46:54.792 | INFO     | src.policies:train:157 - Total loss: 297.5151062011719\n",
      "2021-08-25 10:46:54.793 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:54.795 | INFO     | src.policies:train:103 - Epoch 324 / 800\n",
      "2021-08-25 10:46:54.796 | INFO     | src.policies:train:109 - Episode 2213\n",
      "2021-08-25 10:46:54.836 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:54.837 | INFO     | src.policies:train:121 - Mean episode return: 114.0\n",
      "2021-08-25 10:46:54.838 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 72.16\n",
      "2021-08-25 10:46:54.839 | INFO     | src.policies:train:109 - Episode 2214\n",
      "2021-08-25 10:46:54.888 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:54.890 | INFO     | src.policies:train:121 - Mean episode return: 135.0\n",
      "2021-08-25 10:46:54.890 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 72.56\n",
      "2021-08-25 10:46:54.891 | WARNING  | src.policies:train:131 - The actual batch size is 249, instead of 200\n",
      "2021-08-25 10:46:54.897 | INFO     | src.policies:train:157 - Total loss: 322.9457092285156\n",
      "2021-08-25 10:46:54.897 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:54.900 | INFO     | src.policies:train:103 - Epoch 325 / 800\n",
      "2021-08-25 10:46:54.901 | INFO     | src.policies:train:109 - Episode 2215\n",
      "2021-08-25 10:46:54.925 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:54.926 | INFO     | src.policies:train:121 - Mean episode return: 65.0\n",
      "2021-08-25 10:46:54.927 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 72.52\n",
      "2021-08-25 10:46:54.928 | INFO     | src.policies:train:109 - Episode 2216\n",
      "2021-08-25 10:46:54.994 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:54.996 | INFO     | src.policies:train:121 - Mean episode return: 192.0\n",
      "2021-08-25 10:46:54.996 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 74.16\n",
      "2021-08-25 10:46:54.997 | WARNING  | src.policies:train:131 - The actual batch size is 257, instead of 200\n",
      "2021-08-25 10:46:55.003 | INFO     | src.policies:train:157 - Total loss: 423.929443359375\n",
      "2021-08-25 10:46:55.004 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:55.007 | INFO     | src.policies:train:103 - Epoch 326 / 800\n",
      "2021-08-25 10:46:55.008 | INFO     | src.policies:train:109 - Episode 2217\n",
      "2021-08-25 10:46:55.062 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:55.064 | INFO     | src.policies:train:121 - Mean episode return: 158.0\n",
      "2021-08-25 10:46:55.065 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 75.48\n",
      "2021-08-25 10:46:55.065 | INFO     | src.policies:train:109 - Episode 2218\n",
      "2021-08-25 10:46:55.114 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:55.115 | INFO     | src.policies:train:121 - Mean episode return: 137.0\n",
      "2021-08-25 10:46:55.116 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 75.32\n",
      "2021-08-25 10:46:55.117 | WARNING  | src.policies:train:131 - The actual batch size is 295, instead of 200\n",
      "2021-08-25 10:46:55.122 | INFO     | src.policies:train:157 - Total loss: 417.8559265136719\n",
      "2021-08-25 10:46:55.123 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:55.126 | INFO     | src.policies:train:103 - Epoch 327 / 800\n",
      "2021-08-25 10:46:55.127 | INFO     | src.policies:train:109 - Episode 2219\n",
      "2021-08-25 10:46:55.138 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:55.139 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 10:46:55.140 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 74.95\n",
      "2021-08-25 10:46:55.140 | INFO     | src.policies:train:109 - Episode 2220\n",
      "2021-08-25 10:46:55.181 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:55.182 | INFO     | src.policies:train:121 - Mean episode return: 114.0\n",
      "2021-08-25 10:46:55.183 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 75.88\n",
      "2021-08-25 10:46:55.184 | INFO     | src.policies:train:109 - Episode 2221\n",
      "2021-08-25 10:46:55.222 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:55.223 | INFO     | src.policies:train:121 - Mean episode return: 105.0\n",
      "2021-08-25 10:46:55.224 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 75.79\n",
      "2021-08-25 10:46:55.225 | WARNING  | src.policies:train:131 - The actual batch size is 242, instead of 200\n",
      "2021-08-25 10:46:55.230 | INFO     | src.policies:train:157 - Total loss: 322.35845947265625\n",
      "2021-08-25 10:46:55.231 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:55.234 | INFO     | src.policies:train:103 - Epoch 328 / 800\n",
      "2021-08-25 10:46:55.235 | INFO     | src.policies:train:109 - Episode 2222\n",
      "2021-08-25 10:46:55.301 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:55.302 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:46:55.303 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 77.65\n",
      "2021-08-25 10:46:55.308 | INFO     | src.policies:train:157 - Total loss: 653.4721069335938\n",
      "2021-08-25 10:46:55.309 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:55.312 | INFO     | src.policies:train:103 - Epoch 329 / 800\n",
      "2021-08-25 10:46:55.313 | INFO     | src.policies:train:109 - Episode 2223\n",
      "2021-08-25 10:46:55.352 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:55.354 | INFO     | src.policies:train:121 - Mean episode return: 109.0\n",
      "2021-08-25 10:46:55.355 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 78.32\n",
      "2021-08-25 10:46:55.355 | INFO     | src.policies:train:109 - Episode 2224\n",
      "2021-08-25 10:46:55.419 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:55.420 | INFO     | src.policies:train:121 - Mean episode return: 191.0\n",
      "2021-08-25 10:46:55.421 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 80.11\n",
      "2021-08-25 10:46:55.422 | WARNING  | src.policies:train:131 - The actual batch size is 300, instead of 200\n",
      "2021-08-25 10:46:55.427 | INFO     | src.policies:train:157 - Total loss: 413.1375732421875\n",
      "2021-08-25 10:46:55.428 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:55.431 | INFO     | src.policies:train:103 - Epoch 330 / 800\n",
      "2021-08-25 10:46:55.432 | INFO     | src.policies:train:109 - Episode 2225\n",
      "2021-08-25 10:46:55.472 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:55.473 | INFO     | src.policies:train:121 - Mean episode return: 116.0\n",
      "2021-08-25 10:46:55.474 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 81.01\n",
      "2021-08-25 10:46:55.475 | INFO     | src.policies:train:109 - Episode 2226\n",
      "2021-08-25 10:46:55.505 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:55.507 | INFO     | src.policies:train:121 - Mean episode return: 83.0\n",
      "2021-08-25 10:46:55.507 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 81.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:55.508 | INFO     | src.policies:train:109 - Episode 2227\n",
      "2021-08-25 10:46:55.548 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:55.549 | INFO     | src.policies:train:121 - Mean episode return: 109.0\n",
      "2021-08-25 10:46:55.550 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 81.93\n",
      "2021-08-25 10:46:55.551 | WARNING  | src.policies:train:131 - The actual batch size is 308, instead of 200\n",
      "2021-08-25 10:46:55.556 | INFO     | src.policies:train:157 - Total loss: 304.3032531738281\n",
      "2021-08-25 10:46:55.557 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:55.560 | INFO     | src.policies:train:103 - Epoch 331 / 800\n",
      "2021-08-25 10:46:55.561 | INFO     | src.policies:train:109 - Episode 2228\n",
      "2021-08-25 10:46:55.610 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:55.611 | INFO     | src.policies:train:121 - Mean episode return: 141.0\n",
      "2021-08-25 10:46:55.612 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 81.87\n",
      "2021-08-25 10:46:55.613 | INFO     | src.policies:train:109 - Episode 2229\n",
      "2021-08-25 10:46:55.659 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:55.660 | INFO     | src.policies:train:121 - Mean episode return: 125.0\n",
      "2021-08-25 10:46:55.661 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 82.23\n",
      "2021-08-25 10:46:55.661 | WARNING  | src.policies:train:131 - The actual batch size is 266, instead of 200\n",
      "2021-08-25 10:46:55.667 | INFO     | src.policies:train:157 - Total loss: 388.9384460449219\n",
      "2021-08-25 10:46:55.668 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:55.671 | INFO     | src.policies:train:103 - Epoch 332 / 800\n",
      "2021-08-25 10:46:55.672 | INFO     | src.policies:train:109 - Episode 2230\n",
      "2021-08-25 10:46:55.717 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:55.719 | INFO     | src.policies:train:121 - Mean episode return: 132.0\n",
      "2021-08-25 10:46:55.720 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 82.87\n",
      "2021-08-25 10:46:55.720 | INFO     | src.policies:train:109 - Episode 2231\n",
      "2021-08-25 10:46:55.765 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:55.766 | INFO     | src.policies:train:121 - Mean episode return: 119.0\n",
      "2021-08-25 10:46:55.767 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 83.56\n",
      "2021-08-25 10:46:55.768 | WARNING  | src.policies:train:131 - The actual batch size is 251, instead of 200\n",
      "2021-08-25 10:46:55.773 | INFO     | src.policies:train:157 - Total loss: 288.52789306640625\n",
      "2021-08-25 10:46:55.774 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:55.777 | INFO     | src.policies:train:103 - Epoch 333 / 800\n",
      "2021-08-25 10:46:55.778 | INFO     | src.policies:train:109 - Episode 2232\n",
      "2021-08-25 10:46:55.840 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:55.841 | INFO     | src.policies:train:121 - Mean episode return: 182.0\n",
      "2021-08-25 10:46:55.842 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 84.96\n",
      "2021-08-25 10:46:55.843 | INFO     | src.policies:train:109 - Episode 2233\n",
      "2021-08-25 10:46:55.877 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:55.878 | INFO     | src.policies:train:121 - Mean episode return: 94.0\n",
      "2021-08-25 10:46:55.879 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 85.49\n",
      "2021-08-25 10:46:55.880 | WARNING  | src.policies:train:131 - The actual batch size is 276, instead of 200\n",
      "2021-08-25 10:46:55.886 | INFO     | src.policies:train:157 - Total loss: 339.09259033203125\n",
      "2021-08-25 10:46:55.887 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:55.890 | INFO     | src.policies:train:103 - Epoch 334 / 800\n",
      "2021-08-25 10:46:55.891 | INFO     | src.policies:train:109 - Episode 2234\n",
      "2021-08-25 10:46:55.926 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:55.928 | INFO     | src.policies:train:121 - Mean episode return: 100.0\n",
      "2021-08-25 10:46:55.928 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 86.05\n",
      "2021-08-25 10:46:55.929 | INFO     | src.policies:train:109 - Episode 2235\n",
      "2021-08-25 10:46:55.958 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:55.959 | INFO     | src.policies:train:121 - Mean episode return: 77.0\n",
      "2021-08-25 10:46:55.959 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 86.65\n",
      "2021-08-25 10:46:55.960 | INFO     | src.policies:train:109 - Episode 2236\n",
      "2021-08-25 10:46:56.000 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:56.001 | INFO     | src.policies:train:121 - Mean episode return: 106.0\n",
      "2021-08-25 10:46:56.002 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 87.37\n",
      "2021-08-25 10:46:56.003 | WARNING  | src.policies:train:131 - The actual batch size is 283, instead of 200\n",
      "2021-08-25 10:46:56.009 | INFO     | src.policies:train:157 - Total loss: 275.24456787109375\n",
      "2021-08-25 10:46:56.010 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:56.013 | INFO     | src.policies:train:103 - Epoch 335 / 800\n",
      "2021-08-25 10:46:56.014 | INFO     | src.policies:train:109 - Episode 2237\n",
      "2021-08-25 10:46:56.062 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:56.064 | INFO     | src.policies:train:121 - Mean episode return: 141.0\n",
      "2021-08-25 10:46:56.065 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 87.9\n",
      "2021-08-25 10:46:56.065 | INFO     | src.policies:train:109 - Episode 2238\n",
      "2021-08-25 10:46:56.113 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:56.114 | INFO     | src.policies:train:121 - Mean episode return: 132.0\n",
      "2021-08-25 10:46:56.115 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 88.79\n",
      "2021-08-25 10:46:56.116 | WARNING  | src.policies:train:131 - The actual batch size is 273, instead of 200\n",
      "2021-08-25 10:46:56.121 | INFO     | src.policies:train:157 - Total loss: 339.6830749511719\n",
      "2021-08-25 10:46:56.122 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:56.125 | INFO     | src.policies:train:103 - Epoch 336 / 800\n",
      "2021-08-25 10:46:56.126 | INFO     | src.policies:train:109 - Episode 2239\n",
      "2021-08-25 10:46:56.163 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:56.165 | INFO     | src.policies:train:121 - Mean episode return: 106.0\n",
      "2021-08-25 10:46:56.166 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 89.27\n",
      "2021-08-25 10:46:56.166 | INFO     | src.policies:train:109 - Episode 2240\n",
      "2021-08-25 10:46:56.206 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:56.207 | INFO     | src.policies:train:121 - Mean episode return: 111.0\n",
      "2021-08-25 10:46:56.208 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 89.62\n",
      "2021-08-25 10:46:56.209 | WARNING  | src.policies:train:131 - The actual batch size is 217, instead of 200\n",
      "2021-08-25 10:46:56.216 | INFO     | src.policies:train:157 - Total loss: 312.6354064941406\n",
      "2021-08-25 10:46:56.217 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:56.221 | INFO     | src.policies:train:103 - Epoch 337 / 800\n",
      "2021-08-25 10:46:56.223 | INFO     | src.policies:train:109 - Episode 2241\n",
      "2021-08-25 10:46:56.263 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:56.265 | INFO     | src.policies:train:121 - Mean episode return: 108.0\n",
      "2021-08-25 10:46:56.266 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 90.55\n",
      "2021-08-25 10:46:56.267 | INFO     | src.policies:train:109 - Episode 2242\n",
      "2021-08-25 10:46:56.310 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:56.312 | INFO     | src.policies:train:121 - Mean episode return: 112.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:56.313 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 90.97\n",
      "2021-08-25 10:46:56.314 | WARNING  | src.policies:train:131 - The actual batch size is 220, instead of 200\n",
      "2021-08-25 10:46:56.322 | INFO     | src.policies:train:157 - Total loss: 222.52041625976562\n",
      "2021-08-25 10:46:56.323 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:56.328 | INFO     | src.policies:train:103 - Epoch 338 / 800\n",
      "2021-08-25 10:46:56.329 | INFO     | src.policies:train:109 - Episode 2243\n",
      "2021-08-25 10:46:56.375 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:56.376 | INFO     | src.policies:train:121 - Mean episode return: 132.0\n",
      "2021-08-25 10:46:56.377 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 91.89\n",
      "2021-08-25 10:46:56.378 | INFO     | src.policies:train:109 - Episode 2244\n",
      "2021-08-25 10:46:56.432 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:56.433 | INFO     | src.policies:train:121 - Mean episode return: 155.0\n",
      "2021-08-25 10:46:56.433 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 93.26\n",
      "2021-08-25 10:46:56.434 | WARNING  | src.policies:train:131 - The actual batch size is 287, instead of 200\n",
      "2021-08-25 10:46:56.440 | INFO     | src.policies:train:157 - Total loss: 421.7522277832031\n",
      "2021-08-25 10:46:56.441 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:56.443 | INFO     | src.policies:train:103 - Epoch 339 / 800\n",
      "2021-08-25 10:46:56.444 | INFO     | src.policies:train:109 - Episode 2245\n",
      "2021-08-25 10:46:56.465 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:56.466 | INFO     | src.policies:train:121 - Mean episode return: 58.0\n",
      "2021-08-25 10:46:56.467 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 93.63\n",
      "2021-08-25 10:46:56.468 | INFO     | src.policies:train:109 - Episode 2246\n",
      "2021-08-25 10:46:56.510 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:56.511 | INFO     | src.policies:train:121 - Mean episode return: 116.0\n",
      "2021-08-25 10:46:56.511 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 94.55\n",
      "2021-08-25 10:46:56.512 | INFO     | src.policies:train:109 - Episode 2247\n",
      "2021-08-25 10:46:56.548 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:56.549 | INFO     | src.policies:train:121 - Mean episode return: 98.0\n",
      "2021-08-25 10:46:56.550 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 94.18\n",
      "2021-08-25 10:46:56.551 | WARNING  | src.policies:train:131 - The actual batch size is 272, instead of 200\n",
      "2021-08-25 10:46:56.556 | INFO     | src.policies:train:157 - Total loss: 299.3326416015625\n",
      "2021-08-25 10:46:56.556 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:56.560 | INFO     | src.policies:train:103 - Epoch 340 / 800\n",
      "2021-08-25 10:46:56.561 | INFO     | src.policies:train:109 - Episode 2248\n",
      "2021-08-25 10:46:56.596 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:56.598 | INFO     | src.policies:train:121 - Mean episode return: 105.0\n",
      "2021-08-25 10:46:56.599 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 94.4\n",
      "2021-08-25 10:46:56.599 | INFO     | src.policies:train:109 - Episode 2249\n",
      "2021-08-25 10:46:56.649 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:56.650 | INFO     | src.policies:train:121 - Mean episode return: 139.0\n",
      "2021-08-25 10:46:56.650 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 95.68\n",
      "2021-08-25 10:46:56.651 | WARNING  | src.policies:train:131 - The actual batch size is 244, instead of 200\n",
      "2021-08-25 10:46:56.657 | INFO     | src.policies:train:157 - Total loss: 255.1886444091797\n",
      "2021-08-25 10:46:56.658 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:56.661 | INFO     | src.policies:train:103 - Epoch 341 / 800\n",
      "2021-08-25 10:46:56.662 | INFO     | src.policies:train:109 - Episode 2250\n",
      "2021-08-25 10:46:56.688 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:56.689 | INFO     | src.policies:train:121 - Mean episode return: 71.0\n",
      "2021-08-25 10:46:56.691 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 95.59\n",
      "2021-08-25 10:46:56.691 | INFO     | src.policies:train:109 - Episode 2251\n",
      "2021-08-25 10:46:56.699 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:56.700 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 10:46:56.701 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 94.78\n",
      "2021-08-25 10:46:56.702 | INFO     | src.policies:train:109 - Episode 2252\n",
      "2021-08-25 10:46:56.771 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:56.772 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:46:56.772 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 96.59\n",
      "2021-08-25 10:46:56.773 | WARNING  | src.policies:train:131 - The actual batch size is 282, instead of 200\n",
      "2021-08-25 10:46:56.779 | INFO     | src.policies:train:157 - Total loss: 650.36572265625\n",
      "2021-08-25 10:46:56.780 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:56.783 | INFO     | src.policies:train:103 - Epoch 342 / 800\n",
      "2021-08-25 10:46:56.784 | INFO     | src.policies:train:109 - Episode 2253\n",
      "2021-08-25 10:46:56.817 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:56.819 | INFO     | src.policies:train:121 - Mean episode return: 89.0\n",
      "2021-08-25 10:46:56.820 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 96.54\n",
      "2021-08-25 10:46:56.820 | INFO     | src.policies:train:109 - Episode 2254\n",
      "2021-08-25 10:46:56.852 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:56.853 | INFO     | src.policies:train:121 - Mean episode return: 84.0\n",
      "2021-08-25 10:46:56.853 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 96.93\n",
      "2021-08-25 10:46:56.854 | INFO     | src.policies:train:109 - Episode 2255\n",
      "2021-08-25 10:46:56.906 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:56.907 | INFO     | src.policies:train:121 - Mean episode return: 142.0\n",
      "2021-08-25 10:46:56.908 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 97.64\n",
      "2021-08-25 10:46:56.909 | WARNING  | src.policies:train:131 - The actual batch size is 315, instead of 200\n",
      "2021-08-25 10:46:56.914 | INFO     | src.policies:train:157 - Total loss: 279.86383056640625\n",
      "2021-08-25 10:46:56.915 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:56.918 | INFO     | src.policies:train:103 - Epoch 343 / 800\n",
      "2021-08-25 10:46:56.919 | INFO     | src.policies:train:109 - Episode 2256\n",
      "2021-08-25 10:46:56.973 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:56.975 | INFO     | src.policies:train:121 - Mean episode return: 164.0\n",
      "2021-08-25 10:46:56.976 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 99.09\n",
      "2021-08-25 10:46:56.976 | INFO     | src.policies:train:109 - Episode 2257\n",
      "2021-08-25 10:46:57.044 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:57.046 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:46:57.046 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 99.71\n",
      "2021-08-25 10:46:57.047 | WARNING  | src.policies:train:131 - The actual batch size is 364, instead of 200\n",
      "2021-08-25 10:46:57.053 | INFO     | src.policies:train:157 - Total loss: 867.719482421875\n",
      "2021-08-25 10:46:57.054 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:57.056 | INFO     | src.policies:train:103 - Epoch 344 / 800\n",
      "2021-08-25 10:46:57.058 | INFO     | src.policies:train:109 - Episode 2258\n",
      "2021-08-25 10:46:57.089 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:57.090 | INFO     | src.policies:train:121 - Mean episode return: 88.0\n",
      "2021-08-25 10:46:57.091 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 99.85\n",
      "2021-08-25 10:46:57.092 | INFO     | src.policies:train:109 - Episode 2259\n",
      "2021-08-25 10:46:57.161 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:57.162 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:46:57.163 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 100.82\n",
      "2021-08-25 10:46:57.164 | WARNING  | src.policies:train:131 - The actual batch size is 288, instead of 200\n",
      "2021-08-25 10:46:57.170 | INFO     | src.policies:train:157 - Total loss: 446.3867492675781\n",
      "2021-08-25 10:46:57.171 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:57.174 | INFO     | src.policies:train:103 - Epoch 345 / 800\n",
      "2021-08-25 10:46:57.175 | INFO     | src.policies:train:109 - Episode 2260\n",
      "2021-08-25 10:46:57.223 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:57.224 | INFO     | src.policies:train:121 - Mean episode return: 144.0\n",
      "2021-08-25 10:46:57.225 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 102.02\n",
      "2021-08-25 10:46:57.226 | INFO     | src.policies:train:109 - Episode 2261\n",
      "2021-08-25 10:46:57.267 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:57.268 | INFO     | src.policies:train:121 - Mean episode return: 112.0\n",
      "2021-08-25 10:46:57.269 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 102.58\n",
      "2021-08-25 10:46:57.270 | WARNING  | src.policies:train:131 - The actual batch size is 256, instead of 200\n",
      "2021-08-25 10:46:57.275 | INFO     | src.policies:train:157 - Total loss: 660.14501953125\n",
      "2021-08-25 10:46:57.276 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:57.279 | INFO     | src.policies:train:103 - Epoch 346 / 800\n",
      "2021-08-25 10:46:57.280 | INFO     | src.policies:train:109 - Episode 2262\n",
      "2021-08-25 10:46:57.340 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:57.341 | INFO     | src.policies:train:121 - Mean episode return: 179.0\n",
      "2021-08-25 10:46:57.342 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 104.23\n",
      "2021-08-25 10:46:57.343 | INFO     | src.policies:train:109 - Episode 2263\n",
      "2021-08-25 10:46:57.380 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:57.381 | INFO     | src.policies:train:121 - Mean episode return: 104.0\n",
      "2021-08-25 10:46:57.382 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 104.31\n",
      "2021-08-25 10:46:57.383 | WARNING  | src.policies:train:131 - The actual batch size is 283, instead of 200\n",
      "2021-08-25 10:46:57.389 | INFO     | src.policies:train:157 - Total loss: 345.4712219238281\n",
      "2021-08-25 10:46:57.389 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:57.393 | INFO     | src.policies:train:103 - Epoch 347 / 800\n",
      "2021-08-25 10:46:57.394 | INFO     | src.policies:train:109 - Episode 2264\n",
      "2021-08-25 10:46:57.457 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:57.459 | INFO     | src.policies:train:121 - Mean episode return: 194.0\n",
      "2021-08-25 10:46:57.460 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 105.76\n",
      "2021-08-25 10:46:57.461 | INFO     | src.policies:train:109 - Episode 2265\n",
      "2021-08-25 10:46:57.524 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:57.525 | INFO     | src.policies:train:121 - Mean episode return: 183.0\n",
      "2021-08-25 10:46:57.526 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 106.9\n",
      "2021-08-25 10:46:57.528 | WARNING  | src.policies:train:131 - The actual batch size is 377, instead of 200\n",
      "2021-08-25 10:46:57.535 | INFO     | src.policies:train:157 - Total loss: 424.78973388671875\n",
      "2021-08-25 10:46:57.536 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:57.540 | INFO     | src.policies:train:103 - Epoch 348 / 800\n",
      "2021-08-25 10:46:57.541 | INFO     | src.policies:train:109 - Episode 2266\n",
      "2021-08-25 10:46:57.591 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:57.593 | INFO     | src.policies:train:121 - Mean episode return: 141.0\n",
      "2021-08-25 10:46:57.594 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 107.49\n",
      "2021-08-25 10:46:57.595 | INFO     | src.policies:train:109 - Episode 2267\n",
      "2021-08-25 10:46:57.649 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:57.650 | INFO     | src.policies:train:121 - Mean episode return: 157.0\n",
      "2021-08-25 10:46:57.651 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 108.82\n",
      "2021-08-25 10:46:57.652 | WARNING  | src.policies:train:131 - The actual batch size is 298, instead of 200\n",
      "2021-08-25 10:46:57.658 | INFO     | src.policies:train:157 - Total loss: 338.6844787597656\n",
      "2021-08-25 10:46:57.659 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:57.663 | INFO     | src.policies:train:103 - Epoch 349 / 800\n",
      "2021-08-25 10:46:57.664 | INFO     | src.policies:train:109 - Episode 2268\n",
      "2021-08-25 10:46:57.705 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:57.707 | INFO     | src.policies:train:121 - Mean episode return: 114.0\n",
      "2021-08-25 10:46:57.708 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 109.24\n",
      "2021-08-25 10:46:57.708 | INFO     | src.policies:train:109 - Episode 2269\n",
      "2021-08-25 10:46:57.773 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:57.774 | INFO     | src.policies:train:121 - Mean episode return: 178.0\n",
      "2021-08-25 10:46:57.775 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 110.81\n",
      "2021-08-25 10:46:57.775 | WARNING  | src.policies:train:131 - The actual batch size is 292, instead of 200\n",
      "2021-08-25 10:46:57.781 | INFO     | src.policies:train:157 - Total loss: 472.1045837402344\n",
      "2021-08-25 10:46:57.781 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:57.785 | INFO     | src.policies:train:103 - Epoch 350 / 800\n",
      "2021-08-25 10:46:57.786 | INFO     | src.policies:train:109 - Episode 2270\n",
      "2021-08-25 10:46:57.854 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:57.856 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:46:57.857 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 112.44\n",
      "2021-08-25 10:46:57.861 | INFO     | src.policies:train:157 - Total loss: 545.2384033203125\n",
      "2021-08-25 10:46:57.862 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:57.865 | INFO     | src.policies:train:103 - Epoch 351 / 800\n",
      "2021-08-25 10:46:57.866 | INFO     | src.policies:train:109 - Episode 2271\n",
      "2021-08-25 10:46:57.933 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:57.935 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:46:57.936 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 114.01\n",
      "2021-08-25 10:46:57.940 | INFO     | src.policies:train:157 - Total loss: 572.1480102539062\n",
      "2021-08-25 10:46:57.941 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:57.944 | INFO     | src.policies:train:103 - Epoch 352 / 800\n",
      "2021-08-25 10:46:57.945 | INFO     | src.policies:train:109 - Episode 2272\n",
      "2021-08-25 10:46:57.985 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:57.987 | INFO     | src.policies:train:121 - Mean episode return: 109.0\n",
      "2021-08-25 10:46:57.988 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 114.12\n",
      "2021-08-25 10:46:57.989 | INFO     | src.policies:train:109 - Episode 2273\n",
      "2021-08-25 10:46:58.043 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:58.044 | INFO     | src.policies:train:121 - Mean episode return: 157.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:58.045 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 115.24\n",
      "2021-08-25 10:46:58.046 | WARNING  | src.policies:train:131 - The actual batch size is 266, instead of 200\n",
      "2021-08-25 10:46:58.051 | INFO     | src.policies:train:157 - Total loss: 456.7421569824219\n",
      "2021-08-25 10:46:58.052 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:58.055 | INFO     | src.policies:train:103 - Epoch 353 / 800\n",
      "2021-08-25 10:46:58.056 | INFO     | src.policies:train:109 - Episode 2274\n",
      "2021-08-25 10:46:58.123 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:58.124 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:46:58.125 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 116.24\n",
      "2021-08-25 10:46:58.130 | INFO     | src.policies:train:157 - Total loss: 590.6574096679688\n",
      "2021-08-25 10:46:58.130 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:58.134 | INFO     | src.policies:train:103 - Epoch 354 / 800\n",
      "2021-08-25 10:46:58.135 | INFO     | src.policies:train:109 - Episode 2275\n",
      "2021-08-25 10:46:58.205 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:58.206 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:46:58.207 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 116.75\n",
      "2021-08-25 10:46:58.212 | INFO     | src.policies:train:157 - Total loss: 715.4108276367188\n",
      "2021-08-25 10:46:58.213 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:58.216 | INFO     | src.policies:train:103 - Epoch 355 / 800\n",
      "2021-08-25 10:46:58.217 | INFO     | src.policies:train:109 - Episode 2276\n",
      "2021-08-25 10:46:58.281 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:58.282 | INFO     | src.policies:train:121 - Mean episode return: 188.0\n",
      "2021-08-25 10:46:58.283 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 118.26\n",
      "2021-08-25 10:46:58.284 | INFO     | src.policies:train:109 - Episode 2277\n",
      "2021-08-25 10:46:58.327 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:58.328 | INFO     | src.policies:train:121 - Mean episode return: 120.0\n",
      "2021-08-25 10:46:58.329 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 118.56\n",
      "2021-08-25 10:46:58.330 | WARNING  | src.policies:train:131 - The actual batch size is 308, instead of 200\n",
      "2021-08-25 10:46:58.335 | INFO     | src.policies:train:157 - Total loss: 914.6149291992188\n",
      "2021-08-25 10:46:58.336 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:58.340 | INFO     | src.policies:train:103 - Epoch 356 / 800\n",
      "2021-08-25 10:46:58.341 | INFO     | src.policies:train:109 - Episode 2278\n",
      "2021-08-25 10:46:58.407 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:58.408 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:46:58.409 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 120.08\n",
      "2021-08-25 10:46:58.414 | INFO     | src.policies:train:157 - Total loss: 438.67431640625\n",
      "2021-08-25 10:46:58.415 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:58.418 | INFO     | src.policies:train:103 - Epoch 357 / 800\n",
      "2021-08-25 10:46:58.419 | INFO     | src.policies:train:109 - Episode 2279\n",
      "2021-08-25 10:46:58.454 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:58.456 | INFO     | src.policies:train:121 - Mean episode return: 106.0\n",
      "2021-08-25 10:46:58.457 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 120.88\n",
      "2021-08-25 10:46:58.457 | INFO     | src.policies:train:109 - Episode 2280\n",
      "2021-08-25 10:46:58.491 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:58.492 | INFO     | src.policies:train:121 - Mean episode return: 89.0\n",
      "2021-08-25 10:46:58.493 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 120.89\n",
      "2021-08-25 10:46:58.494 | INFO     | src.policies:train:109 - Episode 2281\n",
      "2021-08-25 10:46:58.523 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:58.524 | INFO     | src.policies:train:121 - Mean episode return: 81.0\n",
      "2021-08-25 10:46:58.525 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 121.31\n",
      "2021-08-25 10:46:58.526 | WARNING  | src.policies:train:131 - The actual batch size is 276, instead of 200\n",
      "2021-08-25 10:46:58.531 | INFO     | src.policies:train:157 - Total loss: 342.88470458984375\n",
      "2021-08-25 10:46:58.532 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:58.535 | INFO     | src.policies:train:103 - Epoch 358 / 800\n",
      "2021-08-25 10:46:58.536 | INFO     | src.policies:train:109 - Episode 2282\n",
      "2021-08-25 10:46:58.605 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:58.606 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:46:58.607 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 122.81\n",
      "2021-08-25 10:46:58.612 | INFO     | src.policies:train:157 - Total loss: 775.1702880859375\n",
      "2021-08-25 10:46:58.612 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:58.615 | INFO     | src.policies:train:103 - Epoch 359 / 800\n",
      "2021-08-25 10:46:58.616 | INFO     | src.policies:train:109 - Episode 2283\n",
      "2021-08-25 10:46:58.656 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:58.657 | INFO     | src.policies:train:121 - Mean episode return: 115.0\n",
      "2021-08-25 10:46:58.658 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 123.48\n",
      "2021-08-25 10:46:58.659 | INFO     | src.policies:train:109 - Episode 2284\n",
      "2021-08-25 10:46:58.728 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:58.729 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:46:58.730 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 124.22\n",
      "2021-08-25 10:46:58.731 | WARNING  | src.policies:train:131 - The actual batch size is 315, instead of 200\n",
      "2021-08-25 10:46:58.737 | INFO     | src.policies:train:157 - Total loss: 777.9713134765625\n",
      "2021-08-25 10:46:58.737 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:58.741 | INFO     | src.policies:train:103 - Epoch 360 / 800\n",
      "2021-08-25 10:46:58.742 | INFO     | src.policies:train:109 - Episode 2285\n",
      "2021-08-25 10:46:58.816 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:58.818 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:46:58.819 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 125.97\n",
      "2021-08-25 10:46:58.825 | INFO     | src.policies:train:157 - Total loss: 427.9919738769531\n",
      "2021-08-25 10:46:58.826 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:58.829 | INFO     | src.policies:train:103 - Epoch 361 / 800\n",
      "2021-08-25 10:46:58.830 | INFO     | src.policies:train:109 - Episode 2286\n",
      "2021-08-25 10:46:58.894 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:58.895 | INFO     | src.policies:train:121 - Mean episode return: 187.0\n",
      "2021-08-25 10:46:58.896 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 126.95\n",
      "2021-08-25 10:46:58.897 | INFO     | src.policies:train:109 - Episode 2287\n",
      "2021-08-25 10:46:58.944 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:58.945 | INFO     | src.policies:train:121 - Mean episode return: 125.0\n",
      "2021-08-25 10:46:58.946 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 127.22\n",
      "2021-08-25 10:46:58.947 | WARNING  | src.policies:train:131 - The actual batch size is 312, instead of 200\n",
      "2021-08-25 10:46:58.955 | INFO     | src.policies:train:157 - Total loss: 870.9969482421875\n",
      "2021-08-25 10:46:58.955 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:58.960 | INFO     | src.policies:train:103 - Epoch 362 / 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:46:58.961 | INFO     | src.policies:train:109 - Episode 2288\n",
      "2021-08-25 10:46:59.034 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:59.036 | INFO     | src.policies:train:121 - Mean episode return: 199.0\n",
      "2021-08-25 10:46:59.037 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 127.59\n",
      "2021-08-25 10:46:59.037 | INFO     | src.policies:train:109 - Episode 2289\n",
      "2021-08-25 10:46:59.066 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:59.068 | INFO     | src.policies:train:121 - Mean episode return: 68.0\n",
      "2021-08-25 10:46:59.069 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 127.34\n",
      "2021-08-25 10:46:59.070 | WARNING  | src.policies:train:131 - The actual batch size is 267, instead of 200\n",
      "2021-08-25 10:46:59.076 | INFO     | src.policies:train:157 - Total loss: 385.54119873046875\n",
      "2021-08-25 10:46:59.077 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:59.080 | INFO     | src.policies:train:103 - Epoch 363 / 800\n",
      "2021-08-25 10:46:59.081 | INFO     | src.policies:train:109 - Episode 2290\n",
      "2021-08-25 10:46:59.155 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:59.156 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:46:59.157 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 128.28\n",
      "2021-08-25 10:46:59.162 | INFO     | src.policies:train:157 - Total loss: 682.1259765625\n",
      "2021-08-25 10:46:59.164 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:59.167 | INFO     | src.policies:train:103 - Epoch 364 / 800\n",
      "2021-08-25 10:46:59.168 | INFO     | src.policies:train:109 - Episode 2291\n",
      "2021-08-25 10:46:59.240 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:59.242 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:46:59.243 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 129.53\n",
      "2021-08-25 10:46:59.248 | INFO     | src.policies:train:157 - Total loss: 859.8026733398438\n",
      "2021-08-25 10:46:59.249 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:59.252 | INFO     | src.policies:train:103 - Epoch 365 / 800\n",
      "2021-08-25 10:46:59.253 | INFO     | src.policies:train:109 - Episode 2292\n",
      "2021-08-25 10:46:59.296 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:59.298 | INFO     | src.policies:train:121 - Mean episode return: 114.0\n",
      "2021-08-25 10:46:59.299 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 130.35\n",
      "2021-08-25 10:46:59.300 | INFO     | src.policies:train:109 - Episode 2293\n",
      "2021-08-25 10:46:59.359 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:59.360 | INFO     | src.policies:train:121 - Mean episode return: 158.0\n",
      "2021-08-25 10:46:59.361 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 131.08\n",
      "2021-08-25 10:46:59.362 | WARNING  | src.policies:train:131 - The actual batch size is 272, instead of 200\n",
      "2021-08-25 10:46:59.369 | INFO     | src.policies:train:157 - Total loss: 703.3538818359375\n",
      "2021-08-25 10:46:59.370 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:59.373 | INFO     | src.policies:train:103 - Epoch 366 / 800\n",
      "2021-08-25 10:46:59.375 | INFO     | src.policies:train:109 - Episode 2294\n",
      "2021-08-25 10:46:59.400 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:59.402 | INFO     | src.policies:train:121 - Mean episode return: 64.0\n",
      "2021-08-25 10:46:59.403 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 130.07\n",
      "2021-08-25 10:46:59.404 | INFO     | src.policies:train:109 - Episode 2295\n",
      "2021-08-25 10:46:59.473 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:59.474 | INFO     | src.policies:train:121 - Mean episode return: 184.0\n",
      "2021-08-25 10:46:59.476 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 130.96\n",
      "2021-08-25 10:46:59.476 | WARNING  | src.policies:train:131 - The actual batch size is 248, instead of 200\n",
      "2021-08-25 10:46:59.482 | INFO     | src.policies:train:157 - Total loss: 357.501220703125\n",
      "2021-08-25 10:46:59.483 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:59.487 | INFO     | src.policies:train:103 - Epoch 367 / 800\n",
      "2021-08-25 10:46:59.488 | INFO     | src.policies:train:109 - Episode 2296\n",
      "2021-08-25 10:46:59.513 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:59.514 | INFO     | src.policies:train:121 - Mean episode return: 62.0\n",
      "2021-08-25 10:46:59.515 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 130.9\n",
      "2021-08-25 10:46:59.516 | INFO     | src.policies:train:109 - Episode 2297\n",
      "2021-08-25 10:46:59.554 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:59.556 | INFO     | src.policies:train:121 - Mean episode return: 96.0\n",
      "2021-08-25 10:46:59.557 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 131.02\n",
      "2021-08-25 10:46:59.558 | INFO     | src.policies:train:109 - Episode 2298\n",
      "2021-08-25 10:46:59.621 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:59.622 | INFO     | src.policies:train:121 - Mean episode return: 171.0\n",
      "2021-08-25 10:46:59.624 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 131.36\n",
      "2021-08-25 10:46:59.625 | WARNING  | src.policies:train:131 - The actual batch size is 329, instead of 200\n",
      "2021-08-25 10:46:59.632 | INFO     | src.policies:train:157 - Total loss: 583.0579223632812\n",
      "2021-08-25 10:46:59.633 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:59.638 | INFO     | src.policies:train:103 - Epoch 368 / 800\n",
      "2021-08-25 10:46:59.639 | INFO     | src.policies:train:109 - Episode 2299\n",
      "2021-08-25 10:46:59.712 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:59.714 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:46:59.715 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 131.57\n",
      "2021-08-25 10:46:59.721 | INFO     | src.policies:train:157 - Total loss: 569.1732177734375\n",
      "2021-08-25 10:46:59.722 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:59.726 | INFO     | src.policies:train:103 - Epoch 369 / 800\n",
      "2021-08-25 10:46:59.727 | INFO     | src.policies:train:109 - Episode 2300\n",
      "2021-08-25 10:46:59.800 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:59.802 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:46:59.803 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 132.93\n",
      "2021-08-25 10:46:59.807 | INFO     | src.policies:train:157 - Total loss: 623.97412109375\n",
      "2021-08-25 10:46:59.808 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:59.811 | INFO     | src.policies:train:103 - Epoch 370 / 800\n",
      "2021-08-25 10:46:59.812 | INFO     | src.policies:train:109 - Episode 2301\n",
      "2021-08-25 10:46:59.884 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:59.886 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:46:59.887 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 133.88\n",
      "2021-08-25 10:46:59.893 | INFO     | src.policies:train:157 - Total loss: 550.8394165039062\n",
      "2021-08-25 10:46:59.894 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:46:59.897 | INFO     | src.policies:train:103 - Epoch 371 / 800\n",
      "2021-08-25 10:46:59.898 | INFO     | src.policies:train:109 - Episode 2302\n",
      "2021-08-25 10:46:59.925 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:46:59.927 | INFO     | src.policies:train:121 - Mean episode return: 63.0\n",
      "2021-08-25 10:46:59.928 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 133.24\n",
      "2021-08-25 10:46:59.929 | INFO     | src.policies:train:109 - Episode 2303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:47:00.003 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:00.005 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:00.006 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 134.08\n",
      "2021-08-25 10:47:00.007 | WARNING  | src.policies:train:131 - The actual batch size is 263, instead of 200\n",
      "2021-08-25 10:47:00.014 | INFO     | src.policies:train:157 - Total loss: 353.6727294921875\n",
      "2021-08-25 10:47:00.016 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:00.020 | INFO     | src.policies:train:103 - Epoch 372 / 800\n",
      "2021-08-25 10:47:00.021 | INFO     | src.policies:train:109 - Episode 2304\n",
      "2021-08-25 10:47:00.095 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:00.097 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:00.098 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 134.84\n",
      "2021-08-25 10:47:00.104 | INFO     | src.policies:train:157 - Total loss: 456.9593811035156\n",
      "2021-08-25 10:47:00.105 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:00.109 | INFO     | src.policies:train:103 - Epoch 373 / 800\n",
      "2021-08-25 10:47:00.110 | INFO     | src.policies:train:109 - Episode 2305\n",
      "2021-08-25 10:47:00.185 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:00.187 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:00.188 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 134.87\n",
      "2021-08-25 10:47:00.193 | INFO     | src.policies:train:157 - Total loss: 536.6970825195312\n",
      "2021-08-25 10:47:00.194 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:00.199 | INFO     | src.policies:train:103 - Epoch 374 / 800\n",
      "2021-08-25 10:47:00.200 | INFO     | src.policies:train:109 - Episode 2306\n",
      "2021-08-25 10:47:00.250 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:00.252 | INFO     | src.policies:train:121 - Mean episode return: 134.0\n",
      "2021-08-25 10:47:00.253 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 134.94\n",
      "2021-08-25 10:47:00.254 | INFO     | src.policies:train:109 - Episode 2307\n",
      "2021-08-25 10:47:00.273 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:00.274 | INFO     | src.policies:train:121 - Mean episode return: 41.0\n",
      "2021-08-25 10:47:00.275 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 134.34\n",
      "2021-08-25 10:47:00.276 | INFO     | src.policies:train:109 - Episode 2308\n",
      "2021-08-25 10:47:00.336 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:00.337 | INFO     | src.policies:train:121 - Mean episode return: 163.0\n",
      "2021-08-25 10:47:00.338 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 135.25\n",
      "2021-08-25 10:47:00.339 | WARNING  | src.policies:train:131 - The actual batch size is 338, instead of 200\n",
      "2021-08-25 10:47:00.345 | INFO     | src.policies:train:157 - Total loss: 318.9495849609375\n",
      "2021-08-25 10:47:00.346 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:00.349 | INFO     | src.policies:train:103 - Epoch 375 / 800\n",
      "2021-08-25 10:47:00.351 | INFO     | src.policies:train:109 - Episode 2309\n",
      "2021-08-25 10:47:00.417 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:00.418 | INFO     | src.policies:train:121 - Mean episode return: 185.0\n",
      "2021-08-25 10:47:00.420 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 136.84\n",
      "2021-08-25 10:47:00.421 | INFO     | src.policies:train:109 - Episode 2310\n",
      "2021-08-25 10:47:00.475 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:00.476 | INFO     | src.policies:train:121 - Mean episode return: 146.0\n",
      "2021-08-25 10:47:00.477 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 137.4\n",
      "2021-08-25 10:47:00.478 | WARNING  | src.policies:train:131 - The actual batch size is 331, instead of 200\n",
      "2021-08-25 10:47:00.484 | INFO     | src.policies:train:157 - Total loss: 365.4637451171875\n",
      "2021-08-25 10:47:00.485 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:00.489 | INFO     | src.policies:train:103 - Epoch 376 / 800\n",
      "2021-08-25 10:47:00.490 | INFO     | src.policies:train:109 - Episode 2311\n",
      "2021-08-25 10:47:00.561 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:00.563 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:00.564 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 138.3\n",
      "2021-08-25 10:47:00.568 | INFO     | src.policies:train:157 - Total loss: 567.0003051757812\n",
      "2021-08-25 10:47:00.569 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:00.572 | INFO     | src.policies:train:103 - Epoch 377 / 800\n",
      "2021-08-25 10:47:00.573 | INFO     | src.policies:train:109 - Episode 2312\n",
      "2021-08-25 10:47:00.623 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:00.625 | INFO     | src.policies:train:121 - Mean episode return: 139.0\n",
      "2021-08-25 10:47:00.626 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 138.59\n",
      "2021-08-25 10:47:00.626 | INFO     | src.policies:train:109 - Episode 2313\n",
      "2021-08-25 10:47:00.691 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:00.692 | INFO     | src.policies:train:121 - Mean episode return: 180.0\n",
      "2021-08-25 10:47:00.693 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 139.25\n",
      "2021-08-25 10:47:00.694 | WARNING  | src.policies:train:131 - The actual batch size is 319, instead of 200\n",
      "2021-08-25 10:47:00.700 | INFO     | src.policies:train:157 - Total loss: 362.2035217285156\n",
      "2021-08-25 10:47:00.701 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:00.704 | INFO     | src.policies:train:103 - Epoch 378 / 800\n",
      "2021-08-25 10:47:00.705 | INFO     | src.policies:train:109 - Episode 2314\n",
      "2021-08-25 10:47:00.760 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:00.762 | INFO     | src.policies:train:121 - Mean episode return: 157.0\n",
      "2021-08-25 10:47:00.763 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 139.47\n",
      "2021-08-25 10:47:00.763 | INFO     | src.policies:train:109 - Episode 2315\n",
      "2021-08-25 10:47:00.821 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:00.822 | INFO     | src.policies:train:121 - Mean episode return: 158.0\n",
      "2021-08-25 10:47:00.823 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 140.4\n",
      "2021-08-25 10:47:00.824 | WARNING  | src.policies:train:131 - The actual batch size is 315, instead of 200\n",
      "2021-08-25 10:47:00.830 | INFO     | src.policies:train:157 - Total loss: 377.6551208496094\n",
      "2021-08-25 10:47:00.831 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:00.834 | INFO     | src.policies:train:103 - Epoch 379 / 800\n",
      "2021-08-25 10:47:00.835 | INFO     | src.policies:train:109 - Episode 2316\n",
      "2021-08-25 10:47:00.887 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:00.888 | INFO     | src.policies:train:121 - Mean episode return: 150.0\n",
      "2021-08-25 10:47:00.889 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 139.98\n",
      "2021-08-25 10:47:00.890 | INFO     | src.policies:train:109 - Episode 2317\n",
      "2021-08-25 10:47:00.963 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:00.964 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:00.965 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 140.4\n",
      "2021-08-25 10:47:00.966 | WARNING  | src.policies:train:131 - The actual batch size is 350, instead of 200\n",
      "2021-08-25 10:47:00.972 | INFO     | src.policies:train:157 - Total loss: 368.39166259765625\n",
      "2021-08-25 10:47:00.972 | INFO     | src.policies:train:161 - Epoch infos: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:47:00.976 | INFO     | src.policies:train:103 - Epoch 380 / 800\n",
      "2021-08-25 10:47:00.977 | INFO     | src.policies:train:109 - Episode 2318\n",
      "2021-08-25 10:47:01.029 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:01.030 | INFO     | src.policies:train:121 - Mean episode return: 142.0\n",
      "2021-08-25 10:47:01.031 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 140.45\n",
      "2021-08-25 10:47:01.032 | INFO     | src.policies:train:109 - Episode 2319\n",
      "2021-08-25 10:47:01.072 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:01.073 | INFO     | src.policies:train:121 - Mean episode return: 108.0\n",
      "2021-08-25 10:47:01.074 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 141.3\n",
      "2021-08-25 10:47:01.075 | WARNING  | src.policies:train:131 - The actual batch size is 250, instead of 200\n",
      "2021-08-25 10:47:01.080 | INFO     | src.policies:train:157 - Total loss: 266.49078369140625\n",
      "2021-08-25 10:47:01.081 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:01.085 | INFO     | src.policies:train:103 - Epoch 381 / 800\n",
      "2021-08-25 10:47:01.086 | INFO     | src.policies:train:109 - Episode 2320\n",
      "2021-08-25 10:47:01.146 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:01.148 | INFO     | src.policies:train:121 - Mean episode return: 173.0\n",
      "2021-08-25 10:47:01.149 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 141.89\n",
      "2021-08-25 10:47:01.150 | INFO     | src.policies:train:109 - Episode 2321\n",
      "2021-08-25 10:47:01.212 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:01.214 | INFO     | src.policies:train:121 - Mean episode return: 171.0\n",
      "2021-08-25 10:47:01.214 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 142.55\n",
      "2021-08-25 10:47:01.215 | WARNING  | src.policies:train:131 - The actual batch size is 344, instead of 200\n",
      "2021-08-25 10:47:01.221 | INFO     | src.policies:train:157 - Total loss: 366.054931640625\n",
      "2021-08-25 10:47:01.222 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:01.225 | INFO     | src.policies:train:103 - Epoch 382 / 800\n",
      "2021-08-25 10:47:01.226 | INFO     | src.policies:train:109 - Episode 2322\n",
      "2021-08-25 10:47:01.282 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:01.284 | INFO     | src.policies:train:121 - Mean episode return: 154.0\n",
      "2021-08-25 10:47:01.285 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 142.09\n",
      "2021-08-25 10:47:01.286 | INFO     | src.policies:train:109 - Episode 2323\n",
      "2021-08-25 10:47:01.326 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:01.328 | INFO     | src.policies:train:121 - Mean episode return: 108.0\n",
      "2021-08-25 10:47:01.328 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 142.08\n",
      "2021-08-25 10:47:01.329 | WARNING  | src.policies:train:131 - The actual batch size is 262, instead of 200\n",
      "2021-08-25 10:47:01.335 | INFO     | src.policies:train:157 - Total loss: 279.3938903808594\n",
      "2021-08-25 10:47:01.336 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:01.339 | INFO     | src.policies:train:103 - Epoch 383 / 800\n",
      "2021-08-25 10:47:01.340 | INFO     | src.policies:train:109 - Episode 2324\n",
      "2021-08-25 10:47:01.406 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:01.408 | INFO     | src.policies:train:121 - Mean episode return: 188.0\n",
      "2021-08-25 10:47:01.409 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 142.05\n",
      "2021-08-25 10:47:01.409 | INFO     | src.policies:train:109 - Episode 2325\n",
      "2021-08-25 10:47:01.461 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:01.463 | INFO     | src.policies:train:121 - Mean episode return: 138.0\n",
      "2021-08-25 10:47:01.463 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 142.27\n",
      "2021-08-25 10:47:01.464 | WARNING  | src.policies:train:131 - The actual batch size is 326, instead of 200\n",
      "2021-08-25 10:47:01.470 | INFO     | src.policies:train:157 - Total loss: 322.552734375\n",
      "2021-08-25 10:47:01.471 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:01.474 | INFO     | src.policies:train:103 - Epoch 384 / 800\n",
      "2021-08-25 10:47:01.475 | INFO     | src.policies:train:109 - Episode 2326\n",
      "2021-08-25 10:47:01.545 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:01.547 | INFO     | src.policies:train:121 - Mean episode return: 198.0\n",
      "2021-08-25 10:47:01.548 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 143.42\n",
      "2021-08-25 10:47:01.549 | INFO     | src.policies:train:109 - Episode 2327\n",
      "2021-08-25 10:47:01.603 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:01.604 | INFO     | src.policies:train:121 - Mean episode return: 145.0\n",
      "2021-08-25 10:47:01.605 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 143.78\n",
      "2021-08-25 10:47:01.606 | WARNING  | src.policies:train:131 - The actual batch size is 343, instead of 200\n",
      "2021-08-25 10:47:01.612 | INFO     | src.policies:train:157 - Total loss: 400.1698913574219\n",
      "2021-08-25 10:47:01.613 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:01.617 | INFO     | src.policies:train:103 - Epoch 385 / 800\n",
      "2021-08-25 10:47:01.618 | INFO     | src.policies:train:109 - Episode 2328\n",
      "2021-08-25 10:47:01.671 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:01.673 | INFO     | src.policies:train:121 - Mean episode return: 151.0\n",
      "2021-08-25 10:47:01.674 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 143.88\n",
      "2021-08-25 10:47:01.675 | INFO     | src.policies:train:109 - Episode 2329\n",
      "2021-08-25 10:47:01.724 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:01.725 | INFO     | src.policies:train:121 - Mean episode return: 138.0\n",
      "2021-08-25 10:47:01.726 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 144.01\n",
      "2021-08-25 10:47:01.727 | WARNING  | src.policies:train:131 - The actual batch size is 289, instead of 200\n",
      "2021-08-25 10:47:01.733 | INFO     | src.policies:train:157 - Total loss: 275.5101013183594\n",
      "2021-08-25 10:47:01.734 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:01.737 | INFO     | src.policies:train:103 - Epoch 386 / 800\n",
      "2021-08-25 10:47:01.738 | INFO     | src.policies:train:109 - Episode 2330\n",
      "2021-08-25 10:47:01.793 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:01.795 | INFO     | src.policies:train:121 - Mean episode return: 158.0\n",
      "2021-08-25 10:47:01.796 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 144.27\n",
      "2021-08-25 10:47:01.797 | INFO     | src.policies:train:109 - Episode 2331\n",
      "2021-08-25 10:47:01.852 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:01.853 | INFO     | src.policies:train:121 - Mean episode return: 143.0\n",
      "2021-08-25 10:47:01.854 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 144.51\n",
      "2021-08-25 10:47:01.855 | WARNING  | src.policies:train:131 - The actual batch size is 301, instead of 200\n",
      "2021-08-25 10:47:01.860 | INFO     | src.policies:train:157 - Total loss: 306.642333984375\n",
      "2021-08-25 10:47:01.861 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:01.864 | INFO     | src.policies:train:103 - Epoch 387 / 800\n",
      "2021-08-25 10:47:01.865 | INFO     | src.policies:train:109 - Episode 2332\n",
      "2021-08-25 10:47:01.917 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:01.918 | INFO     | src.policies:train:121 - Mean episode return: 142.0\n",
      "2021-08-25 10:47:01.919 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 144.11\n",
      "2021-08-25 10:47:01.920 | INFO     | src.policies:train:109 - Episode 2333\n",
      "2021-08-25 10:47:01.966 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:47:01.967 | INFO     | src.policies:train:121 - Mean episode return: 119.0\n",
      "2021-08-25 10:47:01.968 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 144.36\n",
      "2021-08-25 10:47:01.969 | WARNING  | src.policies:train:131 - The actual batch size is 261, instead of 200\n",
      "2021-08-25 10:47:01.974 | INFO     | src.policies:train:157 - Total loss: 242.70516967773438\n",
      "2021-08-25 10:47:01.975 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:01.978 | INFO     | src.policies:train:103 - Epoch 388 / 800\n",
      "2021-08-25 10:47:01.979 | INFO     | src.policies:train:109 - Episode 2334\n",
      "2021-08-25 10:47:02.026 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:02.028 | INFO     | src.policies:train:121 - Mean episode return: 125.0\n",
      "2021-08-25 10:47:02.029 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 144.61\n",
      "2021-08-25 10:47:02.030 | INFO     | src.policies:train:109 - Episode 2335\n",
      "2021-08-25 10:47:02.074 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:02.076 | INFO     | src.policies:train:121 - Mean episode return: 118.0\n",
      "2021-08-25 10:47:02.076 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 145.02\n",
      "2021-08-25 10:47:02.077 | WARNING  | src.policies:train:131 - The actual batch size is 243, instead of 200\n",
      "2021-08-25 10:47:02.083 | INFO     | src.policies:train:157 - Total loss: 206.10870361328125\n",
      "2021-08-25 10:47:02.084 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:02.087 | INFO     | src.policies:train:103 - Epoch 389 / 800\n",
      "2021-08-25 10:47:02.088 | INFO     | src.policies:train:109 - Episode 2336\n",
      "2021-08-25 10:47:02.133 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:02.135 | INFO     | src.policies:train:121 - Mean episode return: 125.0\n",
      "2021-08-25 10:47:02.136 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 145.21\n",
      "2021-08-25 10:47:02.137 | INFO     | src.policies:train:109 - Episode 2337\n",
      "2021-08-25 10:47:02.185 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:02.187 | INFO     | src.policies:train:121 - Mean episode return: 130.0\n",
      "2021-08-25 10:47:02.187 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 145.1\n",
      "2021-08-25 10:47:02.188 | WARNING  | src.policies:train:131 - The actual batch size is 255, instead of 200\n",
      "2021-08-25 10:47:02.194 | INFO     | src.policies:train:157 - Total loss: 291.7514953613281\n",
      "2021-08-25 10:47:02.195 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:02.198 | INFO     | src.policies:train:103 - Epoch 390 / 800\n",
      "2021-08-25 10:47:02.198 | INFO     | src.policies:train:109 - Episode 2338\n",
      "2021-08-25 10:47:02.248 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:02.250 | INFO     | src.policies:train:121 - Mean episode return: 142.0\n",
      "2021-08-25 10:47:02.251 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 145.2\n",
      "2021-08-25 10:47:02.251 | INFO     | src.policies:train:109 - Episode 2339\n",
      "2021-08-25 10:47:02.324 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:02.325 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:02.326 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 146.14\n",
      "2021-08-25 10:47:02.327 | WARNING  | src.policies:train:131 - The actual batch size is 342, instead of 200\n",
      "2021-08-25 10:47:02.333 | INFO     | src.policies:train:157 - Total loss: 381.59283447265625\n",
      "2021-08-25 10:47:02.334 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:02.337 | INFO     | src.policies:train:103 - Epoch 391 / 800\n",
      "2021-08-25 10:47:02.338 | INFO     | src.policies:train:109 - Episode 2340\n",
      "2021-08-25 10:47:02.381 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:02.382 | INFO     | src.policies:train:121 - Mean episode return: 114.0\n",
      "2021-08-25 10:47:02.383 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 146.17\n",
      "2021-08-25 10:47:02.384 | INFO     | src.policies:train:109 - Episode 2341\n",
      "2021-08-25 10:47:02.428 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:02.429 | INFO     | src.policies:train:121 - Mean episode return: 118.0\n",
      "2021-08-25 10:47:02.430 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 146.27\n",
      "2021-08-25 10:47:02.431 | WARNING  | src.policies:train:131 - The actual batch size is 232, instead of 200\n",
      "2021-08-25 10:47:02.436 | INFO     | src.policies:train:157 - Total loss: 245.51112365722656\n",
      "2021-08-25 10:47:02.437 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:02.440 | INFO     | src.policies:train:103 - Epoch 392 / 800\n",
      "2021-08-25 10:47:02.441 | INFO     | src.policies:train:109 - Episode 2342\n",
      "2021-08-25 10:47:02.492 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:02.493 | INFO     | src.policies:train:121 - Mean episode return: 135.0\n",
      "2021-08-25 10:47:02.494 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 146.5\n",
      "2021-08-25 10:47:02.495 | INFO     | src.policies:train:109 - Episode 2343\n",
      "2021-08-25 10:47:02.516 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:02.517 | INFO     | src.policies:train:121 - Mean episode return: 52.0\n",
      "2021-08-25 10:47:02.518 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 145.7\n",
      "2021-08-25 10:47:02.519 | INFO     | src.policies:train:109 - Episode 2344\n",
      "2021-08-25 10:47:02.588 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:02.589 | INFO     | src.policies:train:121 - Mean episode return: 188.0\n",
      "2021-08-25 10:47:02.590 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 146.03\n",
      "2021-08-25 10:47:02.590 | WARNING  | src.policies:train:131 - The actual batch size is 375, instead of 200\n",
      "2021-08-25 10:47:02.597 | INFO     | src.policies:train:157 - Total loss: 316.70269775390625\n",
      "2021-08-25 10:47:02.598 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:02.601 | INFO     | src.policies:train:103 - Epoch 393 / 800\n",
      "2021-08-25 10:47:02.602 | INFO     | src.policies:train:109 - Episode 2345\n",
      "2021-08-25 10:47:02.666 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:02.668 | INFO     | src.policies:train:121 - Mean episode return: 178.0\n",
      "2021-08-25 10:47:02.669 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 147.23\n",
      "2021-08-25 10:47:02.670 | INFO     | src.policies:train:109 - Episode 2346\n",
      "2021-08-25 10:47:02.742 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:02.743 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:02.744 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 148.07\n",
      "2021-08-25 10:47:02.745 | WARNING  | src.policies:train:131 - The actual batch size is 378, instead of 200\n",
      "2021-08-25 10:47:02.751 | INFO     | src.policies:train:157 - Total loss: 492.52032470703125\n",
      "2021-08-25 10:47:02.752 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:02.755 | INFO     | src.policies:train:103 - Epoch 394 / 800\n",
      "2021-08-25 10:47:02.756 | INFO     | src.policies:train:109 - Episode 2347\n",
      "2021-08-25 10:47:02.814 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:02.815 | INFO     | src.policies:train:121 - Mean episode return: 155.0\n",
      "2021-08-25 10:47:02.816 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 148.64\n",
      "2021-08-25 10:47:02.817 | INFO     | src.policies:train:109 - Episode 2348\n",
      "2021-08-25 10:47:02.869 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:02.871 | INFO     | src.policies:train:121 - Mean episode return: 145.0\n",
      "2021-08-25 10:47:02.872 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 149.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:47:02.873 | WARNING  | src.policies:train:131 - The actual batch size is 300, instead of 200\n",
      "2021-08-25 10:47:02.878 | INFO     | src.policies:train:157 - Total loss: 251.0276641845703\n",
      "2021-08-25 10:47:02.879 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:02.882 | INFO     | src.policies:train:103 - Epoch 395 / 800\n",
      "2021-08-25 10:47:02.883 | INFO     | src.policies:train:109 - Episode 2349\n",
      "2021-08-25 10:47:02.949 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:02.951 | INFO     | src.policies:train:121 - Mean episode return: 188.0\n",
      "2021-08-25 10:47:02.952 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 149.53\n",
      "2021-08-25 10:47:02.953 | INFO     | src.policies:train:109 - Episode 2350\n",
      "2021-08-25 10:47:03.003 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:03.004 | INFO     | src.policies:train:121 - Mean episode return: 141.0\n",
      "2021-08-25 10:47:03.005 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 150.23\n",
      "2021-08-25 10:47:03.006 | WARNING  | src.policies:train:131 - The actual batch size is 329, instead of 200\n",
      "2021-08-25 10:47:03.012 | INFO     | src.policies:train:157 - Total loss: 266.084228515625\n",
      "2021-08-25 10:47:03.013 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:03.016 | INFO     | src.policies:train:103 - Epoch 396 / 800\n",
      "2021-08-25 10:47:03.018 | INFO     | src.policies:train:109 - Episode 2351\n",
      "2021-08-25 10:47:03.091 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:03.092 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:03.093 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 152.12\n",
      "2021-08-25 10:47:03.099 | INFO     | src.policies:train:157 - Total loss: 648.0492553710938\n",
      "2021-08-25 10:47:03.099 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:03.103 | INFO     | src.policies:train:103 - Epoch 397 / 800\n",
      "2021-08-25 10:47:03.104 | INFO     | src.policies:train:109 - Episode 2352\n",
      "2021-08-25 10:47:03.167 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:03.169 | INFO     | src.policies:train:121 - Mean episode return: 176.0\n",
      "2021-08-25 10:47:03.170 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 151.88\n",
      "2021-08-25 10:47:03.171 | INFO     | src.policies:train:109 - Episode 2353\n",
      "2021-08-25 10:47:03.225 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:03.226 | INFO     | src.policies:train:121 - Mean episode return: 147.0\n",
      "2021-08-25 10:47:03.227 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 152.46\n",
      "2021-08-25 10:47:03.228 | WARNING  | src.policies:train:131 - The actual batch size is 323, instead of 200\n",
      "2021-08-25 10:47:03.234 | INFO     | src.policies:train:157 - Total loss: 249.04322814941406\n",
      "2021-08-25 10:47:03.235 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:03.237 | INFO     | src.policies:train:103 - Epoch 398 / 800\n",
      "2021-08-25 10:47:03.238 | INFO     | src.policies:train:109 - Episode 2354\n",
      "2021-08-25 10:47:03.310 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:03.311 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:03.312 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 153.62\n",
      "2021-08-25 10:47:03.317 | INFO     | src.policies:train:157 - Total loss: 443.406005859375\n",
      "2021-08-25 10:47:03.318 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:03.321 | INFO     | src.policies:train:103 - Epoch 399 / 800\n",
      "2021-08-25 10:47:03.322 | INFO     | src.policies:train:109 - Episode 2355\n",
      "2021-08-25 10:47:03.392 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:03.393 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:03.394 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 154.2\n",
      "2021-08-25 10:47:03.399 | INFO     | src.policies:train:157 - Total loss: 361.7816467285156\n",
      "2021-08-25 10:47:03.400 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:03.403 | INFO     | src.policies:train:103 - Epoch 400 / 800\n",
      "2021-08-25 10:47:03.404 | INFO     | src.policies:train:109 - Episode 2356\n",
      "2021-08-25 10:47:03.469 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:03.471 | INFO     | src.policies:train:121 - Mean episode return: 182.0\n",
      "2021-08-25 10:47:03.472 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 154.38\n",
      "2021-08-25 10:47:03.472 | INFO     | src.policies:train:109 - Episode 2357\n",
      "2021-08-25 10:47:03.528 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:03.529 | INFO     | src.policies:train:121 - Mean episode return: 152.0\n",
      "2021-08-25 10:47:03.530 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 153.9\n",
      "2021-08-25 10:47:03.531 | WARNING  | src.policies:train:131 - The actual batch size is 334, instead of 200\n",
      "2021-08-25 10:47:03.539 | INFO     | src.policies:train:157 - Total loss: 252.6091766357422\n",
      "2021-08-25 10:47:03.540 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:03.544 | INFO     | src.policies:train:103 - Epoch 401 / 800\n",
      "2021-08-25 10:47:03.545 | INFO     | src.policies:train:109 - Episode 2358\n",
      "2021-08-25 10:47:03.598 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:03.599 | INFO     | src.policies:train:121 - Mean episode return: 146.0\n",
      "2021-08-25 10:47:03.600 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 154.48\n",
      "2021-08-25 10:47:03.601 | INFO     | src.policies:train:109 - Episode 2359\n",
      "2021-08-25 10:47:03.653 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:03.654 | INFO     | src.policies:train:121 - Mean episode return: 146.0\n",
      "2021-08-25 10:47:03.655 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 153.94\n",
      "2021-08-25 10:47:03.656 | WARNING  | src.policies:train:131 - The actual batch size is 292, instead of 200\n",
      "2021-08-25 10:47:03.662 | INFO     | src.policies:train:157 - Total loss: 225.3173370361328\n",
      "2021-08-25 10:47:03.663 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:03.666 | INFO     | src.policies:train:103 - Epoch 402 / 800\n",
      "2021-08-25 10:47:03.667 | INFO     | src.policies:train:109 - Episode 2360\n",
      "2021-08-25 10:47:03.727 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:03.728 | INFO     | src.policies:train:121 - Mean episode return: 168.0\n",
      "2021-08-25 10:47:03.729 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 154.18\n",
      "2021-08-25 10:47:03.730 | INFO     | src.policies:train:109 - Episode 2361\n",
      "2021-08-25 10:47:03.771 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:03.773 | INFO     | src.policies:train:121 - Mean episode return: 109.0\n",
      "2021-08-25 10:47:03.773 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 154.15\n",
      "2021-08-25 10:47:03.774 | WARNING  | src.policies:train:131 - The actual batch size is 277, instead of 200\n",
      "2021-08-25 10:47:03.780 | INFO     | src.policies:train:157 - Total loss: 186.4176788330078\n",
      "2021-08-25 10:47:03.781 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:03.784 | INFO     | src.policies:train:103 - Epoch 403 / 800\n",
      "2021-08-25 10:47:03.786 | INFO     | src.policies:train:109 - Episode 2362\n",
      "2021-08-25 10:47:03.847 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:03.848 | INFO     | src.policies:train:121 - Mean episode return: 174.0\n",
      "2021-08-25 10:47:03.849 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 154.1\n",
      "2021-08-25 10:47:03.850 | INFO     | src.policies:train:109 - Episode 2363\n",
      "2021-08-25 10:47:03.897 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:47:03.898 | INFO     | src.policies:train:121 - Mean episode return: 126.0\n",
      "2021-08-25 10:47:03.899 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 154.32\n",
      "2021-08-25 10:47:03.900 | WARNING  | src.policies:train:131 - The actual batch size is 300, instead of 200\n",
      "2021-08-25 10:47:03.905 | INFO     | src.policies:train:157 - Total loss: 224.23544311523438\n",
      "2021-08-25 10:47:03.906 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:03.909 | INFO     | src.policies:train:103 - Epoch 404 / 800\n",
      "2021-08-25 10:47:03.910 | INFO     | src.policies:train:109 - Episode 2364\n",
      "2021-08-25 10:47:03.982 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:03.983 | INFO     | src.policies:train:121 - Mean episode return: 198.0\n",
      "2021-08-25 10:47:03.984 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 154.36\n",
      "2021-08-25 10:47:03.985 | INFO     | src.policies:train:109 - Episode 2365\n",
      "2021-08-25 10:47:04.051 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:04.052 | INFO     | src.policies:train:121 - Mean episode return: 185.0\n",
      "2021-08-25 10:47:04.053 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 154.38\n",
      "2021-08-25 10:47:04.054 | WARNING  | src.policies:train:131 - The actual batch size is 383, instead of 200\n",
      "2021-08-25 10:47:04.060 | INFO     | src.policies:train:157 - Total loss: 301.45843505859375\n",
      "2021-08-25 10:47:04.061 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:04.064 | INFO     | src.policies:train:103 - Epoch 405 / 800\n",
      "2021-08-25 10:47:04.065 | INFO     | src.policies:train:109 - Episode 2366\n",
      "2021-08-25 10:47:04.126 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:04.127 | INFO     | src.policies:train:121 - Mean episode return: 166.0\n",
      "2021-08-25 10:47:04.128 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 154.63\n",
      "2021-08-25 10:47:04.129 | INFO     | src.policies:train:109 - Episode 2367\n",
      "2021-08-25 10:47:04.189 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:04.190 | INFO     | src.policies:train:121 - Mean episode return: 170.0\n",
      "2021-08-25 10:47:04.191 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 154.76\n",
      "2021-08-25 10:47:04.192 | WARNING  | src.policies:train:131 - The actual batch size is 336, instead of 200\n",
      "2021-08-25 10:47:04.198 | INFO     | src.policies:train:157 - Total loss: 245.638427734375\n",
      "2021-08-25 10:47:04.199 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:04.202 | INFO     | src.policies:train:103 - Epoch 406 / 800\n",
      "2021-08-25 10:47:04.203 | INFO     | src.policies:train:109 - Episode 2368\n",
      "2021-08-25 10:47:04.257 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:04.259 | INFO     | src.policies:train:121 - Mean episode return: 154.0\n",
      "2021-08-25 10:47:04.260 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 155.16\n",
      "2021-08-25 10:47:04.261 | INFO     | src.policies:train:109 - Episode 2369\n",
      "2021-08-25 10:47:04.316 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:04.318 | INFO     | src.policies:train:121 - Mean episode return: 154.0\n",
      "2021-08-25 10:47:04.319 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 154.92\n",
      "2021-08-25 10:47:04.320 | WARNING  | src.policies:train:131 - The actual batch size is 308, instead of 200\n",
      "2021-08-25 10:47:04.326 | INFO     | src.policies:train:157 - Total loss: 215.37245178222656\n",
      "2021-08-25 10:47:04.327 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:04.330 | INFO     | src.policies:train:103 - Epoch 407 / 800\n",
      "2021-08-25 10:47:04.331 | INFO     | src.policies:train:109 - Episode 2370\n",
      "2021-08-25 10:47:04.397 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:04.399 | INFO     | src.policies:train:121 - Mean episode return: 191.0\n",
      "2021-08-25 10:47:04.400 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 154.83\n",
      "2021-08-25 10:47:04.400 | INFO     | src.policies:train:109 - Episode 2371\n",
      "2021-08-25 10:47:04.453 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:04.455 | INFO     | src.policies:train:121 - Mean episode return: 149.0\n",
      "2021-08-25 10:47:04.456 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 154.32\n",
      "2021-08-25 10:47:04.457 | WARNING  | src.policies:train:131 - The actual batch size is 340, instead of 200\n",
      "2021-08-25 10:47:04.463 | INFO     | src.policies:train:157 - Total loss: 248.1784210205078\n",
      "2021-08-25 10:47:04.464 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:04.467 | INFO     | src.policies:train:103 - Epoch 408 / 800\n",
      "2021-08-25 10:47:04.468 | INFO     | src.policies:train:109 - Episode 2372\n",
      "2021-08-25 10:47:04.529 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:04.531 | INFO     | src.policies:train:121 - Mean episode return: 170.0\n",
      "2021-08-25 10:47:04.532 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 154.93\n",
      "2021-08-25 10:47:04.533 | INFO     | src.policies:train:109 - Episode 2373\n",
      "2021-08-25 10:47:04.588 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:04.589 | INFO     | src.policies:train:121 - Mean episode return: 156.0\n",
      "2021-08-25 10:47:04.590 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 154.92\n",
      "2021-08-25 10:47:04.591 | WARNING  | src.policies:train:131 - The actual batch size is 326, instead of 200\n",
      "2021-08-25 10:47:04.597 | INFO     | src.policies:train:157 - Total loss: 195.00831604003906\n",
      "2021-08-25 10:47:04.598 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:04.601 | INFO     | src.policies:train:103 - Epoch 409 / 800\n",
      "2021-08-25 10:47:04.602 | INFO     | src.policies:train:109 - Episode 2374\n",
      "2021-08-25 10:47:04.654 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:04.656 | INFO     | src.policies:train:121 - Mean episode return: 143.0\n",
      "2021-08-25 10:47:04.657 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 154.35\n",
      "2021-08-25 10:47:04.658 | INFO     | src.policies:train:109 - Episode 2375\n",
      "2021-08-25 10:47:04.729 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:04.730 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:04.731 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 154.35\n",
      "2021-08-25 10:47:04.732 | WARNING  | src.policies:train:131 - The actual batch size is 343, instead of 200\n",
      "2021-08-25 10:47:04.738 | INFO     | src.policies:train:157 - Total loss: 333.0313720703125\n",
      "2021-08-25 10:47:04.739 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:04.742 | INFO     | src.policies:train:103 - Epoch 410 / 800\n",
      "2021-08-25 10:47:04.744 | INFO     | src.policies:train:109 - Episode 2376\n",
      "2021-08-25 10:47:04.801 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:04.803 | INFO     | src.policies:train:121 - Mean episode return: 164.0\n",
      "2021-08-25 10:47:04.804 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 154.11\n",
      "2021-08-25 10:47:04.806 | INFO     | src.policies:train:109 - Episode 2377\n",
      "2021-08-25 10:47:04.868 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:04.869 | INFO     | src.policies:train:121 - Mean episode return: 180.0\n",
      "2021-08-25 10:47:04.870 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 154.71\n",
      "2021-08-25 10:47:04.871 | WARNING  | src.policies:train:131 - The actual batch size is 344, instead of 200\n",
      "2021-08-25 10:47:04.877 | INFO     | src.policies:train:157 - Total loss: 227.80337524414062\n",
      "2021-08-25 10:47:04.878 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:04.881 | INFO     | src.policies:train:103 - Epoch 411 / 800\n",
      "2021-08-25 10:47:04.882 | INFO     | src.policies:train:109 - Episode 2378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:47:04.926 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:04.928 | INFO     | src.policies:train:121 - Mean episode return: 126.0\n",
      "2021-08-25 10:47:04.929 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 153.97\n",
      "2021-08-25 10:47:04.929 | INFO     | src.policies:train:109 - Episode 2379\n",
      "2021-08-25 10:47:04.976 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:04.977 | INFO     | src.policies:train:121 - Mean episode return: 125.0\n",
      "2021-08-25 10:47:04.978 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 154.16\n",
      "2021-08-25 10:47:04.979 | WARNING  | src.policies:train:131 - The actual batch size is 251, instead of 200\n",
      "2021-08-25 10:47:04.985 | INFO     | src.policies:train:157 - Total loss: 157.6848602294922\n",
      "2021-08-25 10:47:04.986 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:04.989 | INFO     | src.policies:train:103 - Epoch 412 / 800\n",
      "2021-08-25 10:47:04.990 | INFO     | src.policies:train:109 - Episode 2380\n",
      "2021-08-25 10:47:05.034 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:05.035 | INFO     | src.policies:train:121 - Mean episode return: 119.0\n",
      "2021-08-25 10:47:05.036 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 154.46\n",
      "2021-08-25 10:47:05.037 | INFO     | src.policies:train:109 - Episode 2381\n",
      "2021-08-25 10:47:05.093 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:05.094 | INFO     | src.policies:train:121 - Mean episode return: 147.0\n",
      "2021-08-25 10:47:05.095 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 155.12\n",
      "2021-08-25 10:47:05.096 | WARNING  | src.policies:train:131 - The actual batch size is 266, instead of 200\n",
      "2021-08-25 10:47:05.101 | INFO     | src.policies:train:157 - Total loss: 187.4681396484375\n",
      "2021-08-25 10:47:05.102 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:05.105 | INFO     | src.policies:train:103 - Epoch 413 / 800\n",
      "2021-08-25 10:47:05.106 | INFO     | src.policies:train:109 - Episode 2382\n",
      "2021-08-25 10:47:05.178 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:05.179 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:05.180 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 155.12\n",
      "2021-08-25 10:47:05.185 | INFO     | src.policies:train:157 - Total loss: 478.62969970703125\n",
      "2021-08-25 10:47:05.185 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:05.188 | INFO     | src.policies:train:103 - Epoch 414 / 800\n",
      "2021-08-25 10:47:05.189 | INFO     | src.policies:train:109 - Episode 2383\n",
      "2021-08-25 10:47:05.214 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:05.216 | INFO     | src.policies:train:121 - Mean episode return: 65.0\n",
      "2021-08-25 10:47:05.217 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 154.62\n",
      "2021-08-25 10:47:05.217 | INFO     | src.policies:train:109 - Episode 2384\n",
      "2021-08-25 10:47:05.277 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:05.278 | INFO     | src.policies:train:121 - Mean episode return: 169.0\n",
      "2021-08-25 10:47:05.279 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 154.31\n",
      "2021-08-25 10:47:05.280 | WARNING  | src.policies:train:131 - The actual batch size is 234, instead of 200\n",
      "2021-08-25 10:47:05.285 | INFO     | src.policies:train:157 - Total loss: 197.68798828125\n",
      "2021-08-25 10:47:05.286 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:05.288 | INFO     | src.policies:train:103 - Epoch 415 / 800\n",
      "2021-08-25 10:47:05.290 | INFO     | src.policies:train:109 - Episode 2385\n",
      "2021-08-25 10:47:05.338 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:05.340 | INFO     | src.policies:train:121 - Mean episode return: 137.0\n",
      "2021-08-25 10:47:05.341 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 153.68\n",
      "2021-08-25 10:47:05.342 | INFO     | src.policies:train:109 - Episode 2386\n",
      "2021-08-25 10:47:05.371 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:05.372 | INFO     | src.policies:train:121 - Mean episode return: 70.0\n",
      "2021-08-25 10:47:05.373 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 152.51\n",
      "2021-08-25 10:47:05.374 | WARNING  | src.policies:train:131 - The actual batch size is 207, instead of 200\n",
      "2021-08-25 10:47:05.379 | INFO     | src.policies:train:157 - Total loss: 225.40078735351562\n",
      "2021-08-25 10:47:05.380 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:05.383 | INFO     | src.policies:train:103 - Epoch 416 / 800\n",
      "2021-08-25 10:47:05.384 | INFO     | src.policies:train:109 - Episode 2387\n",
      "2021-08-25 10:47:05.453 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:05.455 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:05.456 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 153.26\n",
      "2021-08-25 10:47:05.460 | INFO     | src.policies:train:157 - Total loss: 366.19329833984375\n",
      "2021-08-25 10:47:05.461 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:05.464 | INFO     | src.policies:train:103 - Epoch 417 / 800\n",
      "2021-08-25 10:47:05.465 | INFO     | src.policies:train:109 - Episode 2388\n",
      "2021-08-25 10:47:05.520 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:05.522 | INFO     | src.policies:train:121 - Mean episode return: 151.0\n",
      "2021-08-25 10:47:05.523 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 152.78\n",
      "2021-08-25 10:47:05.524 | INFO     | src.policies:train:109 - Episode 2389\n",
      "2021-08-25 10:47:05.593 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:05.595 | INFO     | src.policies:train:121 - Mean episode return: 183.0\n",
      "2021-08-25 10:47:05.596 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 153.93\n",
      "2021-08-25 10:47:05.597 | WARNING  | src.policies:train:131 - The actual batch size is 334, instead of 200\n",
      "2021-08-25 10:47:05.602 | INFO     | src.policies:train:157 - Total loss: 203.63719177246094\n",
      "2021-08-25 10:47:05.603 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:05.606 | INFO     | src.policies:train:103 - Epoch 418 / 800\n",
      "2021-08-25 10:47:05.607 | INFO     | src.policies:train:109 - Episode 2390\n",
      "2021-08-25 10:47:05.673 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:05.674 | INFO     | src.policies:train:121 - Mean episode return: 185.0\n",
      "2021-08-25 10:47:05.675 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 153.78\n",
      "2021-08-25 10:47:05.676 | INFO     | src.policies:train:109 - Episode 2391\n",
      "2021-08-25 10:47:05.735 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:05.737 | INFO     | src.policies:train:121 - Mean episode return: 159.0\n",
      "2021-08-25 10:47:05.738 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 153.37\n",
      "2021-08-25 10:47:05.738 | WARNING  | src.policies:train:131 - The actual batch size is 344, instead of 200\n",
      "2021-08-25 10:47:05.745 | INFO     | src.policies:train:157 - Total loss: 199.41416931152344\n",
      "2021-08-25 10:47:05.746 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:05.749 | INFO     | src.policies:train:103 - Epoch 419 / 800\n",
      "2021-08-25 10:47:05.750 | INFO     | src.policies:train:109 - Episode 2392\n",
      "2021-08-25 10:47:05.821 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:05.822 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:05.824 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 154.23\n",
      "2021-08-25 10:47:05.829 | INFO     | src.policies:train:157 - Total loss: 229.12326049804688\n",
      "2021-08-25 10:47:05.830 | INFO     | src.policies:train:161 - Epoch infos: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:47:05.833 | INFO     | src.policies:train:103 - Epoch 420 / 800\n",
      "2021-08-25 10:47:05.834 | INFO     | src.policies:train:109 - Episode 2393\n",
      "2021-08-25 10:47:05.899 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:05.901 | INFO     | src.policies:train:121 - Mean episode return: 183.0\n",
      "2021-08-25 10:47:05.902 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 154.48\n",
      "2021-08-25 10:47:05.902 | INFO     | src.policies:train:109 - Episode 2394\n",
      "2021-08-25 10:47:05.975 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:05.976 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:05.977 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 155.84\n",
      "2021-08-25 10:47:05.978 | WARNING  | src.policies:train:131 - The actual batch size is 383, instead of 200\n",
      "2021-08-25 10:47:05.984 | INFO     | src.policies:train:157 - Total loss: 311.01300048828125\n",
      "2021-08-25 10:47:05.985 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:05.988 | INFO     | src.policies:train:103 - Epoch 421 / 800\n",
      "2021-08-25 10:47:05.989 | INFO     | src.policies:train:109 - Episode 2395\n",
      "2021-08-25 10:47:06.055 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:06.057 | INFO     | src.policies:train:121 - Mean episode return: 177.0\n",
      "2021-08-25 10:47:06.058 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 155.77\n",
      "2021-08-25 10:47:06.058 | INFO     | src.policies:train:109 - Episode 2396\n",
      "2021-08-25 10:47:06.127 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:06.128 | INFO     | src.policies:train:121 - Mean episode return: 186.0\n",
      "2021-08-25 10:47:06.129 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 157.01\n",
      "2021-08-25 10:47:06.130 | WARNING  | src.policies:train:131 - The actual batch size is 363, instead of 200\n",
      "2021-08-25 10:47:06.136 | INFO     | src.policies:train:157 - Total loss: 190.60694885253906\n",
      "2021-08-25 10:47:06.136 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:06.139 | INFO     | src.policies:train:103 - Epoch 422 / 800\n",
      "2021-08-25 10:47:06.140 | INFO     | src.policies:train:109 - Episode 2397\n",
      "2021-08-25 10:47:06.206 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:06.208 | INFO     | src.policies:train:121 - Mean episode return: 184.0\n",
      "2021-08-25 10:47:06.209 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 157.89\n",
      "2021-08-25 10:47:06.210 | INFO     | src.policies:train:109 - Episode 2398\n",
      "2021-08-25 10:47:06.264 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:06.265 | INFO     | src.policies:train:121 - Mean episode return: 149.0\n",
      "2021-08-25 10:47:06.266 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 157.67\n",
      "2021-08-25 10:47:06.267 | WARNING  | src.policies:train:131 - The actual batch size is 333, instead of 200\n",
      "2021-08-25 10:47:06.273 | INFO     | src.policies:train:157 - Total loss: 247.9907989501953\n",
      "2021-08-25 10:47:06.274 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:06.277 | INFO     | src.policies:train:103 - Epoch 423 / 800\n",
      "2021-08-25 10:47:06.278 | INFO     | src.policies:train:109 - Episode 2399\n",
      "2021-08-25 10:47:06.349 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:06.351 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:06.352 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 157.67\n",
      "2021-08-25 10:47:06.356 | INFO     | src.policies:train:157 - Total loss: 803.6409301757812\n",
      "2021-08-25 10:47:06.357 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:06.361 | INFO     | src.policies:train:103 - Epoch 424 / 800\n",
      "2021-08-25 10:47:06.362 | INFO     | src.policies:train:109 - Episode 2400\n",
      "2021-08-25 10:47:06.429 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:06.431 | INFO     | src.policies:train:121 - Mean episode return: 193.0\n",
      "2021-08-25 10:47:06.432 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 157.6\n",
      "2021-08-25 10:47:06.432 | INFO     | src.policies:train:109 - Episode 2401\n",
      "2021-08-25 10:47:06.505 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:06.506 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:06.507 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 157.6\n",
      "2021-08-25 10:47:06.508 | WARNING  | src.policies:train:131 - The actual batch size is 393, instead of 200\n",
      "2021-08-25 10:47:06.514 | INFO     | src.policies:train:157 - Total loss: 251.22695922851562\n",
      "2021-08-25 10:47:06.515 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:06.519 | INFO     | src.policies:train:103 - Epoch 425 / 800\n",
      "2021-08-25 10:47:06.520 | INFO     | src.policies:train:109 - Episode 2402\n",
      "2021-08-25 10:47:06.586 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:06.588 | INFO     | src.policies:train:121 - Mean episode return: 180.0\n",
      "2021-08-25 10:47:06.589 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 158.77\n",
      "2021-08-25 10:47:06.589 | INFO     | src.policies:train:109 - Episode 2403\n",
      "2021-08-25 10:47:06.649 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:06.651 | INFO     | src.policies:train:121 - Mean episode return: 162.0\n",
      "2021-08-25 10:47:06.652 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 158.39\n",
      "2021-08-25 10:47:06.652 | WARNING  | src.policies:train:131 - The actual batch size is 342, instead of 200\n",
      "2021-08-25 10:47:06.659 | INFO     | src.policies:train:157 - Total loss: 200.8618621826172\n",
      "2021-08-25 10:47:06.660 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:06.663 | INFO     | src.policies:train:103 - Epoch 426 / 800\n",
      "2021-08-25 10:47:06.664 | INFO     | src.policies:train:109 - Episode 2404\n",
      "2021-08-25 10:47:06.737 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:06.739 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:06.740 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 158.39\n",
      "2021-08-25 10:47:06.745 | INFO     | src.policies:train:157 - Total loss: 219.3590087890625\n",
      "2021-08-25 10:47:06.745 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:06.748 | INFO     | src.policies:train:103 - Epoch 427 / 800\n",
      "2021-08-25 10:47:06.749 | INFO     | src.policies:train:109 - Episode 2405\n",
      "2021-08-25 10:47:06.797 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:06.798 | INFO     | src.policies:train:121 - Mean episode return: 133.0\n",
      "2021-08-25 10:47:06.799 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 157.72\n",
      "2021-08-25 10:47:06.800 | INFO     | src.policies:train:109 - Episode 2406\n",
      "2021-08-25 10:47:06.875 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:06.876 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:06.877 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 158.38\n",
      "2021-08-25 10:47:06.878 | WARNING  | src.policies:train:131 - The actual batch size is 333, instead of 200\n",
      "2021-08-25 10:47:06.884 | INFO     | src.policies:train:157 - Total loss: 250.85562133789062\n",
      "2021-08-25 10:47:06.884 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:06.887 | INFO     | src.policies:train:103 - Epoch 428 / 800\n",
      "2021-08-25 10:47:06.888 | INFO     | src.policies:train:109 - Episode 2407\n",
      "2021-08-25 10:47:06.947 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:06.948 | INFO     | src.policies:train:121 - Mean episode return: 164.0\n",
      "2021-08-25 10:47:06.949 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 159.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:47:06.950 | INFO     | src.policies:train:109 - Episode 2408\n",
      "2021-08-25 10:47:07.011 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:07.013 | INFO     | src.policies:train:121 - Mean episode return: 170.0\n",
      "2021-08-25 10:47:07.014 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 159.68\n",
      "2021-08-25 10:47:07.014 | WARNING  | src.policies:train:131 - The actual batch size is 334, instead of 200\n",
      "2021-08-25 10:47:07.020 | INFO     | src.policies:train:157 - Total loss: 178.64529418945312\n",
      "2021-08-25 10:47:07.021 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:07.025 | INFO     | src.policies:train:103 - Epoch 429 / 800\n",
      "2021-08-25 10:47:07.026 | INFO     | src.policies:train:109 - Episode 2409\n",
      "2021-08-25 10:47:07.097 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:07.099 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:07.100 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 159.83\n",
      "2021-08-25 10:47:07.106 | INFO     | src.policies:train:157 - Total loss: 265.0233154296875\n",
      "2021-08-25 10:47:07.107 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:07.111 | INFO     | src.policies:train:103 - Epoch 430 / 800\n",
      "2021-08-25 10:47:07.112 | INFO     | src.policies:train:109 - Episode 2410\n",
      "2021-08-25 10:47:07.187 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:07.189 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:07.190 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 160.37\n",
      "2021-08-25 10:47:07.196 | INFO     | src.policies:train:157 - Total loss: 683.6572265625\n",
      "2021-08-25 10:47:07.197 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:07.201 | INFO     | src.policies:train:103 - Epoch 431 / 800\n",
      "2021-08-25 10:47:07.202 | INFO     | src.policies:train:109 - Episode 2411\n",
      "2021-08-25 10:47:07.270 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:07.272 | INFO     | src.policies:train:121 - Mean episode return: 180.0\n",
      "2021-08-25 10:47:07.273 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 160.17\n",
      "2021-08-25 10:47:07.274 | INFO     | src.policies:train:109 - Episode 2412\n",
      "2021-08-25 10:47:07.320 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:07.321 | INFO     | src.policies:train:121 - Mean episode return: 123.0\n",
      "2021-08-25 10:47:07.322 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 160.01\n",
      "2021-08-25 10:47:07.323 | WARNING  | src.policies:train:131 - The actual batch size is 303, instead of 200\n",
      "2021-08-25 10:47:07.329 | INFO     | src.policies:train:157 - Total loss: 201.5439910888672\n",
      "2021-08-25 10:47:07.330 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:07.334 | INFO     | src.policies:train:103 - Epoch 432 / 800\n",
      "2021-08-25 10:47:07.335 | INFO     | src.policies:train:109 - Episode 2413\n",
      "2021-08-25 10:47:07.405 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:07.406 | INFO     | src.policies:train:121 - Mean episode return: 199.0\n",
      "2021-08-25 10:47:07.407 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 160.2\n",
      "2021-08-25 10:47:07.408 | INFO     | src.policies:train:109 - Episode 2414\n",
      "2021-08-25 10:47:07.480 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:07.481 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:07.482 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 160.63\n",
      "2021-08-25 10:47:07.483 | WARNING  | src.policies:train:131 - The actual batch size is 399, instead of 200\n",
      "2021-08-25 10:47:07.489 | INFO     | src.policies:train:157 - Total loss: 212.8277587890625\n",
      "2021-08-25 10:47:07.490 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:07.493 | INFO     | src.policies:train:103 - Epoch 433 / 800\n",
      "2021-08-25 10:47:07.494 | INFO     | src.policies:train:109 - Episode 2415\n",
      "2021-08-25 10:47:07.563 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:07.565 | INFO     | src.policies:train:121 - Mean episode return: 192.0\n",
      "2021-08-25 10:47:07.566 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 160.97\n",
      "2021-08-25 10:47:07.567 | INFO     | src.policies:train:109 - Episode 2416\n",
      "2021-08-25 10:47:07.634 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:07.636 | INFO     | src.policies:train:121 - Mean episode return: 190.0\n",
      "2021-08-25 10:47:07.637 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 161.37\n",
      "2021-08-25 10:47:07.637 | WARNING  | src.policies:train:131 - The actual batch size is 382, instead of 200\n",
      "2021-08-25 10:47:07.644 | INFO     | src.policies:train:157 - Total loss: 244.4807586669922\n",
      "2021-08-25 10:47:07.645 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:07.648 | INFO     | src.policies:train:103 - Epoch 434 / 800\n",
      "2021-08-25 10:47:07.649 | INFO     | src.policies:train:109 - Episode 2417\n",
      "2021-08-25 10:47:07.720 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:07.721 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:07.723 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 161.37\n",
      "2021-08-25 10:47:07.728 | INFO     | src.policies:train:157 - Total loss: 184.4265594482422\n",
      "2021-08-25 10:47:07.729 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:07.732 | INFO     | src.policies:train:103 - Epoch 435 / 800\n",
      "2021-08-25 10:47:07.733 | INFO     | src.policies:train:109 - Episode 2418\n",
      "2021-08-25 10:47:07.789 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:07.790 | INFO     | src.policies:train:121 - Mean episode return: 159.0\n",
      "2021-08-25 10:47:07.791 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 161.54\n",
      "2021-08-25 10:47:07.792 | INFO     | src.policies:train:109 - Episode 2419\n",
      "2021-08-25 10:47:07.834 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:07.835 | INFO     | src.policies:train:121 - Mean episode return: 115.0\n",
      "2021-08-25 10:47:07.836 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 161.61\n",
      "2021-08-25 10:47:07.837 | WARNING  | src.policies:train:131 - The actual batch size is 274, instead of 200\n",
      "2021-08-25 10:47:07.843 | INFO     | src.policies:train:157 - Total loss: 157.7476043701172\n",
      "2021-08-25 10:47:07.844 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:07.847 | INFO     | src.policies:train:103 - Epoch 436 / 800\n",
      "2021-08-25 10:47:07.848 | INFO     | src.policies:train:109 - Episode 2420\n",
      "2021-08-25 10:47:07.907 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:07.908 | INFO     | src.policies:train:121 - Mean episode return: 164.0\n",
      "2021-08-25 10:47:07.909 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 161.52\n",
      "2021-08-25 10:47:07.910 | INFO     | src.policies:train:109 - Episode 2421\n",
      "2021-08-25 10:47:07.980 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:07.982 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:07.983 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 161.81\n",
      "2021-08-25 10:47:07.983 | WARNING  | src.policies:train:131 - The actual batch size is 364, instead of 200\n",
      "2021-08-25 10:47:07.989 | INFO     | src.policies:train:157 - Total loss: 185.59580993652344\n",
      "2021-08-25 10:47:07.990 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:07.993 | INFO     | src.policies:train:103 - Epoch 437 / 800\n",
      "2021-08-25 10:47:07.994 | INFO     | src.policies:train:109 - Episode 2422\n",
      "2021-08-25 10:47:08.065 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:47:08.067 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:08.068 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 162.27\n",
      "2021-08-25 10:47:08.073 | INFO     | src.policies:train:157 - Total loss: 391.68865966796875\n",
      "2021-08-25 10:47:08.074 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:08.077 | INFO     | src.policies:train:103 - Epoch 438 / 800\n",
      "2021-08-25 10:47:08.077 | INFO     | src.policies:train:109 - Episode 2423\n",
      "2021-08-25 10:47:08.098 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:08.100 | INFO     | src.policies:train:121 - Mean episode return: 53.0\n",
      "2021-08-25 10:47:08.101 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 161.72\n",
      "2021-08-25 10:47:08.102 | INFO     | src.policies:train:109 - Episode 2424\n",
      "2021-08-25 10:47:08.170 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:08.171 | INFO     | src.policies:train:121 - Mean episode return: 190.0\n",
      "2021-08-25 10:47:08.172 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 161.74\n",
      "2021-08-25 10:47:08.173 | WARNING  | src.policies:train:131 - The actual batch size is 243, instead of 200\n",
      "2021-08-25 10:47:08.178 | INFO     | src.policies:train:157 - Total loss: 239.46311950683594\n",
      "2021-08-25 10:47:08.179 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:08.182 | INFO     | src.policies:train:103 - Epoch 439 / 800\n",
      "2021-08-25 10:47:08.182 | INFO     | src.policies:train:109 - Episode 2425\n",
      "2021-08-25 10:47:08.252 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:08.254 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:08.255 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 162.36\n",
      "2021-08-25 10:47:08.260 | INFO     | src.policies:train:157 - Total loss: 169.34628295898438\n",
      "2021-08-25 10:47:08.260 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:08.264 | INFO     | src.policies:train:103 - Epoch 440 / 800\n",
      "2021-08-25 10:47:08.264 | INFO     | src.policies:train:109 - Episode 2426\n",
      "2021-08-25 10:47:08.335 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:08.337 | INFO     | src.policies:train:121 - Mean episode return: 196.0\n",
      "2021-08-25 10:47:08.338 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 162.34\n",
      "2021-08-25 10:47:08.338 | INFO     | src.policies:train:109 - Episode 2427\n",
      "2021-08-25 10:47:08.398 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:08.399 | INFO     | src.policies:train:121 - Mean episode return: 160.0\n",
      "2021-08-25 10:47:08.400 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 162.49\n",
      "2021-08-25 10:47:08.401 | WARNING  | src.policies:train:131 - The actual batch size is 356, instead of 200\n",
      "2021-08-25 10:47:08.407 | INFO     | src.policies:train:157 - Total loss: 191.76235961914062\n",
      "2021-08-25 10:47:08.408 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:08.411 | INFO     | src.policies:train:103 - Epoch 441 / 800\n",
      "2021-08-25 10:47:08.412 | INFO     | src.policies:train:109 - Episode 2428\n",
      "2021-08-25 10:47:08.422 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:08.423 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 10:47:08.424 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 161.19\n",
      "2021-08-25 10:47:08.425 | INFO     | src.policies:train:109 - Episode 2429\n",
      "2021-08-25 10:47:08.475 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:08.476 | INFO     | src.policies:train:121 - Mean episode return: 136.0\n",
      "2021-08-25 10:47:08.477 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 161.17\n",
      "2021-08-25 10:47:08.478 | INFO     | src.policies:train:109 - Episode 2430\n",
      "2021-08-25 10:47:08.543 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:08.544 | INFO     | src.policies:train:121 - Mean episode return: 178.0\n",
      "2021-08-25 10:47:08.545 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 161.37\n",
      "2021-08-25 10:47:08.546 | WARNING  | src.policies:train:131 - The actual batch size is 335, instead of 200\n",
      "2021-08-25 10:47:08.552 | INFO     | src.policies:train:157 - Total loss: 345.71258544921875\n",
      "2021-08-25 10:47:08.553 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:08.556 | INFO     | src.policies:train:103 - Epoch 442 / 800\n",
      "2021-08-25 10:47:08.557 | INFO     | src.policies:train:109 - Episode 2431\n",
      "2021-08-25 10:47:08.630 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:08.632 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:08.633 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 161.94\n",
      "2021-08-25 10:47:08.637 | INFO     | src.policies:train:157 - Total loss: 202.3142547607422\n",
      "2021-08-25 10:47:08.638 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:08.641 | INFO     | src.policies:train:103 - Epoch 443 / 800\n",
      "2021-08-25 10:47:08.642 | INFO     | src.policies:train:109 - Episode 2432\n",
      "2021-08-25 10:47:08.715 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:08.717 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:08.718 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 162.52\n",
      "2021-08-25 10:47:08.722 | INFO     | src.policies:train:157 - Total loss: 189.3306427001953\n",
      "2021-08-25 10:47:08.723 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:08.727 | INFO     | src.policies:train:103 - Epoch 444 / 800\n",
      "2021-08-25 10:47:08.728 | INFO     | src.policies:train:109 - Episode 2433\n",
      "2021-08-25 10:47:08.800 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:08.801 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:08.802 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 163.33\n",
      "2021-08-25 10:47:08.807 | INFO     | src.policies:train:157 - Total loss: 245.1325225830078\n",
      "2021-08-25 10:47:08.808 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:08.811 | INFO     | src.policies:train:103 - Epoch 445 / 800\n",
      "2021-08-25 10:47:08.812 | INFO     | src.policies:train:109 - Episode 2434\n",
      "2021-08-25 10:47:08.877 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:08.879 | INFO     | src.policies:train:121 - Mean episode return: 179.0\n",
      "2021-08-25 10:47:08.880 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 163.87\n",
      "2021-08-25 10:47:08.881 | INFO     | src.policies:train:109 - Episode 2435\n",
      "2021-08-25 10:47:08.936 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:08.938 | INFO     | src.policies:train:121 - Mean episode return: 149.0\n",
      "2021-08-25 10:47:08.938 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 164.18\n",
      "2021-08-25 10:47:08.939 | WARNING  | src.policies:train:131 - The actual batch size is 328, instead of 200\n",
      "2021-08-25 10:47:08.946 | INFO     | src.policies:train:157 - Total loss: 180.1969757080078\n",
      "2021-08-25 10:47:08.947 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:08.951 | INFO     | src.policies:train:103 - Epoch 446 / 800\n",
      "2021-08-25 10:47:08.952 | INFO     | src.policies:train:109 - Episode 2436\n",
      "2021-08-25 10:47:09.024 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:09.026 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:09.027 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 164.93\n",
      "2021-08-25 10:47:09.033 | INFO     | src.policies:train:157 - Total loss: 198.58067321777344\n",
      "2021-08-25 10:47:09.033 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:09.037 | INFO     | src.policies:train:103 - Epoch 447 / 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:47:09.037 | INFO     | src.policies:train:109 - Episode 2437\n",
      "2021-08-25 10:47:09.107 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:09.109 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:09.110 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 165.63\n",
      "2021-08-25 10:47:09.115 | INFO     | src.policies:train:157 - Total loss: 199.7146759033203\n",
      "2021-08-25 10:47:09.115 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:09.119 | INFO     | src.policies:train:103 - Epoch 448 / 800\n",
      "2021-08-25 10:47:09.120 | INFO     | src.policies:train:109 - Episode 2438\n",
      "2021-08-25 10:47:09.152 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:09.154 | INFO     | src.policies:train:121 - Mean episode return: 83.0\n",
      "2021-08-25 10:47:09.155 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 165.04\n",
      "2021-08-25 10:47:09.156 | INFO     | src.policies:train:109 - Episode 2439\n",
      "2021-08-25 10:47:09.217 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:09.219 | INFO     | src.policies:train:121 - Mean episode return: 176.0\n",
      "2021-08-25 10:47:09.219 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 164.8\n",
      "2021-08-25 10:47:09.220 | WARNING  | src.policies:train:131 - The actual batch size is 259, instead of 200\n",
      "2021-08-25 10:47:09.227 | INFO     | src.policies:train:157 - Total loss: 273.67755126953125\n",
      "2021-08-25 10:47:09.228 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:09.232 | INFO     | src.policies:train:103 - Epoch 449 / 800\n",
      "2021-08-25 10:47:09.233 | INFO     | src.policies:train:109 - Episode 2440\n",
      "2021-08-25 10:47:09.304 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:09.305 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:09.306 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 165.66\n",
      "2021-08-25 10:47:09.311 | INFO     | src.policies:train:157 - Total loss: 586.099365234375\n",
      "2021-08-25 10:47:09.312 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:09.316 | INFO     | src.policies:train:103 - Epoch 450 / 800\n",
      "2021-08-25 10:47:09.317 | INFO     | src.policies:train:109 - Episode 2441\n",
      "2021-08-25 10:47:09.386 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:09.388 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:09.389 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 166.48\n",
      "2021-08-25 10:47:09.393 | INFO     | src.policies:train:157 - Total loss: 244.7667999267578\n",
      "2021-08-25 10:47:09.394 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:09.397 | INFO     | src.policies:train:103 - Epoch 451 / 800\n",
      "2021-08-25 10:47:09.398 | INFO     | src.policies:train:109 - Episode 2442\n",
      "2021-08-25 10:47:09.471 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:09.472 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:09.473 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 167.13\n",
      "2021-08-25 10:47:09.478 | INFO     | src.policies:train:157 - Total loss: 189.1944122314453\n",
      "2021-08-25 10:47:09.479 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:09.482 | INFO     | src.policies:train:103 - Epoch 452 / 800\n",
      "2021-08-25 10:47:09.483 | INFO     | src.policies:train:109 - Episode 2443\n",
      "2021-08-25 10:47:09.506 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:09.507 | INFO     | src.policies:train:121 - Mean episode return: 58.0\n",
      "2021-08-25 10:47:09.508 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 167.19\n",
      "2021-08-25 10:47:09.509 | INFO     | src.policies:train:109 - Episode 2444\n",
      "2021-08-25 10:47:09.572 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:09.573 | INFO     | src.policies:train:121 - Mean episode return: 168.0\n",
      "2021-08-25 10:47:09.574 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 166.99\n",
      "2021-08-25 10:47:09.575 | WARNING  | src.policies:train:131 - The actual batch size is 226, instead of 200\n",
      "2021-08-25 10:47:09.581 | INFO     | src.policies:train:157 - Total loss: 389.12725830078125\n",
      "2021-08-25 10:47:09.581 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:09.585 | INFO     | src.policies:train:103 - Epoch 453 / 800\n",
      "2021-08-25 10:47:09.586 | INFO     | src.policies:train:109 - Episode 2445\n",
      "2021-08-25 10:47:09.655 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:09.657 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:09.658 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 167.21\n",
      "2021-08-25 10:47:09.662 | INFO     | src.policies:train:157 - Total loss: 655.6439819335938\n",
      "2021-08-25 10:47:09.663 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:09.666 | INFO     | src.policies:train:103 - Epoch 454 / 800\n",
      "2021-08-25 10:47:09.667 | INFO     | src.policies:train:109 - Episode 2446\n",
      "2021-08-25 10:47:09.740 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:09.742 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:09.743 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 167.21\n",
      "2021-08-25 10:47:09.747 | INFO     | src.policies:train:157 - Total loss: 551.8416748046875\n",
      "2021-08-25 10:47:09.748 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:09.751 | INFO     | src.policies:train:103 - Epoch 455 / 800\n",
      "2021-08-25 10:47:09.752 | INFO     | src.policies:train:109 - Episode 2447\n",
      "2021-08-25 10:47:09.827 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:09.829 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:09.830 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 167.66\n",
      "2021-08-25 10:47:09.836 | INFO     | src.policies:train:157 - Total loss: 516.4268798828125\n",
      "2021-08-25 10:47:09.837 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:09.841 | INFO     | src.policies:train:103 - Epoch 456 / 800\n",
      "2021-08-25 10:47:09.843 | INFO     | src.policies:train:109 - Episode 2448\n",
      "2021-08-25 10:47:09.918 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:09.920 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:09.921 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 168.21\n",
      "2021-08-25 10:47:09.928 | INFO     | src.policies:train:157 - Total loss: 433.31842041015625\n",
      "2021-08-25 10:47:09.929 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:09.933 | INFO     | src.policies:train:103 - Epoch 457 / 800\n",
      "2021-08-25 10:47:09.934 | INFO     | src.policies:train:109 - Episode 2449\n",
      "2021-08-25 10:47:10.007 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:10.008 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:10.009 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 168.33\n",
      "2021-08-25 10:47:10.014 | INFO     | src.policies:train:157 - Total loss: 170.14450073242188\n",
      "2021-08-25 10:47:10.015 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:10.019 | INFO     | src.policies:train:103 - Epoch 458 / 800\n",
      "2021-08-25 10:47:10.020 | INFO     | src.policies:train:109 - Episode 2450\n",
      "2021-08-25 10:47:10.094 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:10.095 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:10.096 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 168.92\n",
      "2021-08-25 10:47:10.103 | INFO     | src.policies:train:157 - Total loss: 185.28427124023438\n",
      "2021-08-25 10:47:10.104 | INFO     | src.policies:train:161 - Epoch infos: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:47:10.108 | INFO     | src.policies:train:103 - Epoch 459 / 800\n",
      "2021-08-25 10:47:10.109 | INFO     | src.policies:train:109 - Episode 2451\n",
      "2021-08-25 10:47:10.185 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:10.186 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:10.187 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 168.92\n",
      "2021-08-25 10:47:10.193 | INFO     | src.policies:train:157 - Total loss: 269.92742919921875\n",
      "2021-08-25 10:47:10.194 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:10.199 | INFO     | src.policies:train:103 - Epoch 460 / 800\n",
      "2021-08-25 10:47:10.200 | INFO     | src.policies:train:109 - Episode 2452\n",
      "2021-08-25 10:47:10.270 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:10.272 | INFO     | src.policies:train:121 - Mean episode return: 189.0\n",
      "2021-08-25 10:47:10.273 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 169.05\n",
      "2021-08-25 10:47:10.274 | INFO     | src.policies:train:109 - Episode 2453\n",
      "2021-08-25 10:47:10.349 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:10.350 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:10.351 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 169.58\n",
      "2021-08-25 10:47:10.352 | WARNING  | src.policies:train:131 - The actual batch size is 389, instead of 200\n",
      "2021-08-25 10:47:10.361 | INFO     | src.policies:train:157 - Total loss: 233.81114196777344\n",
      "2021-08-25 10:47:10.362 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:10.366 | INFO     | src.policies:train:103 - Epoch 461 / 800\n",
      "2021-08-25 10:47:10.367 | INFO     | src.policies:train:109 - Episode 2454\n",
      "2021-08-25 10:47:10.442 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:10.443 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:10.445 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 169.58\n",
      "2021-08-25 10:47:10.450 | INFO     | src.policies:train:157 - Total loss: 238.73939514160156\n",
      "2021-08-25 10:47:10.451 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:10.456 | INFO     | src.policies:train:103 - Epoch 462 / 800\n",
      "2021-08-25 10:47:10.457 | INFO     | src.policies:train:109 - Episode 2455\n",
      "2021-08-25 10:47:10.528 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:10.530 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:10.531 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 169.58\n",
      "2021-08-25 10:47:10.538 | INFO     | src.policies:train:157 - Total loss: 1167.0638427734375\n",
      "2021-08-25 10:47:10.539 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:10.543 | INFO     | src.policies:train:103 - Epoch 463 / 800\n",
      "2021-08-25 10:47:10.544 | INFO     | src.policies:train:109 - Episode 2456\n",
      "2021-08-25 10:47:10.617 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:10.618 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:10.619 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 169.76\n",
      "2021-08-25 10:47:10.624 | INFO     | src.policies:train:157 - Total loss: 707.3172607421875\n",
      "2021-08-25 10:47:10.625 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:10.629 | INFO     | src.policies:train:103 - Epoch 464 / 800\n",
      "2021-08-25 10:47:10.630 | INFO     | src.policies:train:109 - Episode 2457\n",
      "2021-08-25 10:47:10.704 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:10.705 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:10.706 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 170.24\n",
      "2021-08-25 10:47:10.712 | INFO     | src.policies:train:157 - Total loss: 302.78277587890625\n",
      "2021-08-25 10:47:10.713 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:10.718 | INFO     | src.policies:train:103 - Epoch 465 / 800\n",
      "2021-08-25 10:47:10.719 | INFO     | src.policies:train:109 - Episode 2458\n",
      "2021-08-25 10:47:10.793 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:10.795 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:10.796 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 170.78\n",
      "2021-08-25 10:47:10.802 | INFO     | src.policies:train:157 - Total loss: 904.4105224609375\n",
      "2021-08-25 10:47:10.803 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:10.807 | INFO     | src.policies:train:103 - Epoch 466 / 800\n",
      "2021-08-25 10:47:10.808 | INFO     | src.policies:train:109 - Episode 2459\n",
      "2021-08-25 10:47:10.881 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:10.883 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:10.884 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 171.32\n",
      "2021-08-25 10:47:10.890 | INFO     | src.policies:train:157 - Total loss: 264.6142272949219\n",
      "2021-08-25 10:47:10.891 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:10.895 | INFO     | src.policies:train:103 - Epoch 467 / 800\n",
      "2021-08-25 10:47:10.896 | INFO     | src.policies:train:109 - Episode 2460\n",
      "2021-08-25 10:47:10.967 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:10.969 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:10.970 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 171.64\n",
      "2021-08-25 10:47:10.974 | INFO     | src.policies:train:157 - Total loss: 216.74586486816406\n",
      "2021-08-25 10:47:10.975 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:10.978 | INFO     | src.policies:train:103 - Epoch 468 / 800\n",
      "2021-08-25 10:47:10.979 | INFO     | src.policies:train:109 - Episode 2461\n",
      "2021-08-25 10:47:11.024 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:11.025 | INFO     | src.policies:train:121 - Mean episode return: 120.0\n",
      "2021-08-25 10:47:11.026 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 171.75\n",
      "2021-08-25 10:47:11.027 | INFO     | src.policies:train:109 - Episode 2462\n",
      "2021-08-25 10:47:11.101 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:11.102 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:11.103 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.01\n",
      "2021-08-25 10:47:11.105 | WARNING  | src.policies:train:131 - The actual batch size is 320, instead of 200\n",
      "2021-08-25 10:47:11.112 | INFO     | src.policies:train:157 - Total loss: 765.2188110351562\n",
      "2021-08-25 10:47:11.113 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:11.116 | INFO     | src.policies:train:103 - Epoch 469 / 800\n",
      "2021-08-25 10:47:11.118 | INFO     | src.policies:train:109 - Episode 2463\n",
      "2021-08-25 10:47:11.190 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:11.192 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:11.193 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.75\n",
      "2021-08-25 10:47:11.198 | INFO     | src.policies:train:157 - Total loss: 585.3103637695312\n",
      "2021-08-25 10:47:11.199 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:11.202 | INFO     | src.policies:train:103 - Epoch 470 / 800\n",
      "2021-08-25 10:47:11.203 | INFO     | src.policies:train:109 - Episode 2464\n",
      "2021-08-25 10:47:11.275 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:11.276 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:11.278 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.77\n",
      "2021-08-25 10:47:11.282 | INFO     | src.policies:train:157 - Total loss: 184.19580078125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:47:11.283 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:11.286 | INFO     | src.policies:train:103 - Epoch 471 / 800\n",
      "2021-08-25 10:47:11.287 | INFO     | src.policies:train:109 - Episode 2465\n",
      "2021-08-25 10:47:11.358 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:11.360 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:11.361 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.92\n",
      "2021-08-25 10:47:11.365 | INFO     | src.policies:train:157 - Total loss: 989.5156860351562\n",
      "2021-08-25 10:47:11.366 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:11.369 | INFO     | src.policies:train:103 - Epoch 472 / 800\n",
      "2021-08-25 10:47:11.370 | INFO     | src.policies:train:109 - Episode 2466\n",
      "2021-08-25 10:47:11.438 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:11.439 | INFO     | src.policies:train:121 - Mean episode return: 191.0\n",
      "2021-08-25 10:47:11.440 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 173.17\n",
      "2021-08-25 10:47:11.441 | INFO     | src.policies:train:109 - Episode 2467\n",
      "2021-08-25 10:47:11.512 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:11.513 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:11.514 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 173.47\n",
      "2021-08-25 10:47:11.515 | WARNING  | src.policies:train:131 - The actual batch size is 391, instead of 200\n",
      "2021-08-25 10:47:11.521 | INFO     | src.policies:train:157 - Total loss: 615.2762451171875\n",
      "2021-08-25 10:47:11.521 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:11.524 | INFO     | src.policies:train:103 - Epoch 473 / 800\n",
      "2021-08-25 10:47:11.525 | INFO     | src.policies:train:109 - Episode 2468\n",
      "2021-08-25 10:47:11.566 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:11.567 | INFO     | src.policies:train:121 - Mean episode return: 113.0\n",
      "2021-08-25 10:47:11.568 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 173.06\n",
      "2021-08-25 10:47:11.569 | INFO     | src.policies:train:109 - Episode 2469\n",
      "2021-08-25 10:47:11.642 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:11.644 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:11.645 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 173.52\n",
      "2021-08-25 10:47:11.646 | WARNING  | src.policies:train:131 - The actual batch size is 313, instead of 200\n",
      "2021-08-25 10:47:11.652 | INFO     | src.policies:train:157 - Total loss: 298.4984130859375\n",
      "2021-08-25 10:47:11.653 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:11.656 | INFO     | src.policies:train:103 - Epoch 474 / 800\n",
      "2021-08-25 10:47:11.657 | INFO     | src.policies:train:109 - Episode 2470\n",
      "2021-08-25 10:47:11.710 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:11.712 | INFO     | src.policies:train:121 - Mean episode return: 151.0\n",
      "2021-08-25 10:47:11.713 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 173.12\n",
      "2021-08-25 10:47:11.714 | INFO     | src.policies:train:109 - Episode 2471\n",
      "2021-08-25 10:47:11.784 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:11.785 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:11.786 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 173.63\n",
      "2021-08-25 10:47:11.787 | WARNING  | src.policies:train:131 - The actual batch size is 351, instead of 200\n",
      "2021-08-25 10:47:11.793 | INFO     | src.policies:train:157 - Total loss: 547.82861328125\n",
      "2021-08-25 10:47:11.794 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:11.797 | INFO     | src.policies:train:103 - Epoch 475 / 800\n",
      "2021-08-25 10:47:11.798 | INFO     | src.policies:train:109 - Episode 2472\n",
      "2021-08-25 10:47:11.866 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:11.868 | INFO     | src.policies:train:121 - Mean episode return: 188.0\n",
      "2021-08-25 10:47:11.869 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 173.81\n",
      "2021-08-25 10:47:11.870 | INFO     | src.policies:train:109 - Episode 2473\n",
      "2021-08-25 10:47:11.929 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:11.931 | INFO     | src.policies:train:121 - Mean episode return: 167.0\n",
      "2021-08-25 10:47:11.931 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 173.92\n",
      "2021-08-25 10:47:11.932 | WARNING  | src.policies:train:131 - The actual batch size is 355, instead of 200\n",
      "2021-08-25 10:47:11.938 | INFO     | src.policies:train:157 - Total loss: 736.7921142578125\n",
      "2021-08-25 10:47:11.939 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:11.942 | INFO     | src.policies:train:103 - Epoch 476 / 800\n",
      "2021-08-25 10:47:11.943 | INFO     | src.policies:train:109 - Episode 2474\n",
      "2021-08-25 10:47:12.014 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:12.016 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:12.017 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.49\n",
      "2021-08-25 10:47:12.021 | INFO     | src.policies:train:157 - Total loss: 614.6648559570312\n",
      "2021-08-25 10:47:12.022 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:12.025 | INFO     | src.policies:train:103 - Epoch 477 / 800\n",
      "2021-08-25 10:47:12.026 | INFO     | src.policies:train:109 - Episode 2475\n",
      "2021-08-25 10:47:12.095 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:12.097 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:12.098 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.49\n",
      "2021-08-25 10:47:12.103 | INFO     | src.policies:train:157 - Total loss: 251.18505859375\n",
      "2021-08-25 10:47:12.103 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:12.106 | INFO     | src.policies:train:103 - Epoch 478 / 800\n",
      "2021-08-25 10:47:12.107 | INFO     | src.policies:train:109 - Episode 2476\n",
      "2021-08-25 10:47:12.180 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:12.181 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:12.182 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.85\n",
      "2021-08-25 10:47:12.187 | INFO     | src.policies:train:157 - Total loss: 664.4696044921875\n",
      "2021-08-25 10:47:12.188 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:12.191 | INFO     | src.policies:train:103 - Epoch 479 / 800\n",
      "2021-08-25 10:47:12.192 | INFO     | src.policies:train:109 - Episode 2477\n",
      "2021-08-25 10:47:12.262 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:12.263 | INFO     | src.policies:train:121 - Mean episode return: 197.0\n",
      "2021-08-25 10:47:12.264 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.02\n",
      "2021-08-25 10:47:12.265 | INFO     | src.policies:train:109 - Episode 2478\n",
      "2021-08-25 10:47:12.339 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:12.341 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:12.341 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.76\n",
      "2021-08-25 10:47:12.342 | WARNING  | src.policies:train:131 - The actual batch size is 397, instead of 200\n",
      "2021-08-25 10:47:12.348 | INFO     | src.policies:train:157 - Total loss: 331.8102111816406\n",
      "2021-08-25 10:47:12.349 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:12.352 | INFO     | src.policies:train:103 - Epoch 480 / 800\n",
      "2021-08-25 10:47:12.353 | INFO     | src.policies:train:109 - Episode 2479\n",
      "2021-08-25 10:47:12.424 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:47:12.426 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:12.427 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.51\n",
      "2021-08-25 10:47:12.432 | INFO     | src.policies:train:157 - Total loss: 297.9515686035156\n",
      "2021-08-25 10:47:12.433 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:12.436 | INFO     | src.policies:train:103 - Epoch 481 / 800\n",
      "2021-08-25 10:47:12.436 | INFO     | src.policies:train:109 - Episode 2480\n",
      "2021-08-25 10:47:12.508 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:12.510 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:12.511 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 177.32\n",
      "2021-08-25 10:47:12.515 | INFO     | src.policies:train:157 - Total loss: 783.3734741210938\n",
      "2021-08-25 10:47:12.516 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:12.520 | INFO     | src.policies:train:103 - Epoch 482 / 800\n",
      "2021-08-25 10:47:12.521 | INFO     | src.policies:train:109 - Episode 2481\n",
      "2021-08-25 10:47:12.594 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:12.595 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:12.596 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 177.85\n",
      "2021-08-25 10:47:12.601 | INFO     | src.policies:train:157 - Total loss: 295.2130126953125\n",
      "2021-08-25 10:47:12.602 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:12.604 | INFO     | src.policies:train:103 - Epoch 483 / 800\n",
      "2021-08-25 10:47:12.605 | INFO     | src.policies:train:109 - Episode 2482\n",
      "2021-08-25 10:47:12.655 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:12.657 | INFO     | src.policies:train:121 - Mean episode return: 135.0\n",
      "2021-08-25 10:47:12.658 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 177.2\n",
      "2021-08-25 10:47:12.658 | INFO     | src.policies:train:109 - Episode 2483\n",
      "2021-08-25 10:47:12.732 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:12.734 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:12.735 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 178.55\n",
      "2021-08-25 10:47:12.736 | WARNING  | src.policies:train:131 - The actual batch size is 335, instead of 200\n",
      "2021-08-25 10:47:12.742 | INFO     | src.policies:train:157 - Total loss: 546.2052612304688\n",
      "2021-08-25 10:47:12.743 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:12.746 | INFO     | src.policies:train:103 - Epoch 484 / 800\n",
      "2021-08-25 10:47:12.747 | INFO     | src.policies:train:109 - Episode 2484\n",
      "2021-08-25 10:47:12.817 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:12.819 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:12.820 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 178.86\n",
      "2021-08-25 10:47:12.825 | INFO     | src.policies:train:157 - Total loss: 1217.495849609375\n",
      "2021-08-25 10:47:12.825 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:12.829 | INFO     | src.policies:train:103 - Epoch 485 / 800\n",
      "2021-08-25 10:47:12.830 | INFO     | src.policies:train:109 - Episode 2485\n",
      "2021-08-25 10:47:12.902 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:12.904 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:12.905 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 179.49\n",
      "2021-08-25 10:47:12.909 | INFO     | src.policies:train:157 - Total loss: 791.318359375\n",
      "2021-08-25 10:47:12.910 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:12.913 | INFO     | src.policies:train:103 - Epoch 486 / 800\n",
      "2021-08-25 10:47:12.914 | INFO     | src.policies:train:109 - Episode 2486\n",
      "2021-08-25 10:47:12.986 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:12.987 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:12.988 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 180.79\n",
      "2021-08-25 10:47:12.993 | INFO     | src.policies:train:157 - Total loss: 420.9950256347656\n",
      "2021-08-25 10:47:12.994 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:12.997 | INFO     | src.policies:train:103 - Epoch 487 / 800\n",
      "2021-08-25 10:47:12.997 | INFO     | src.policies:train:109 - Episode 2487\n",
      "2021-08-25 10:47:13.069 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:13.070 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:13.071 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 180.79\n",
      "2021-08-25 10:47:13.076 | INFO     | src.policies:train:157 - Total loss: 745.0675659179688\n",
      "2021-08-25 10:47:13.077 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:13.080 | INFO     | src.policies:train:103 - Epoch 488 / 800\n",
      "2021-08-25 10:47:13.081 | INFO     | src.policies:train:109 - Episode 2488\n",
      "2021-08-25 10:47:13.151 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:13.153 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:13.154 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.28\n",
      "2021-08-25 10:47:13.159 | INFO     | src.policies:train:157 - Total loss: 362.861083984375\n",
      "2021-08-25 10:47:13.159 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:13.162 | INFO     | src.policies:train:103 - Epoch 489 / 800\n",
      "2021-08-25 10:47:13.163 | INFO     | src.policies:train:109 - Episode 2489\n",
      "2021-08-25 10:47:13.214 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:13.215 | INFO     | src.policies:train:121 - Mean episode return: 142.0\n",
      "2021-08-25 10:47:13.216 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 180.87\n",
      "2021-08-25 10:47:13.217 | INFO     | src.policies:train:109 - Episode 2490\n",
      "2021-08-25 10:47:13.290 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:13.292 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:13.292 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.02\n",
      "2021-08-25 10:47:13.293 | WARNING  | src.policies:train:131 - The actual batch size is 342, instead of 200\n",
      "2021-08-25 10:47:13.299 | INFO     | src.policies:train:157 - Total loss: 725.2393798828125\n",
      "2021-08-25 10:47:13.300 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:13.303 | INFO     | src.policies:train:103 - Epoch 490 / 800\n",
      "2021-08-25 10:47:13.304 | INFO     | src.policies:train:109 - Episode 2491\n",
      "2021-08-25 10:47:13.375 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:13.377 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:13.378 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.43\n",
      "2021-08-25 10:47:13.383 | INFO     | src.policies:train:157 - Total loss: 955.3365478515625\n",
      "2021-08-25 10:47:13.383 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:13.386 | INFO     | src.policies:train:103 - Epoch 491 / 800\n",
      "2021-08-25 10:47:13.387 | INFO     | src.policies:train:109 - Episode 2492\n",
      "2021-08-25 10:47:13.460 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:13.462 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:13.463 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.43\n",
      "2021-08-25 10:47:13.467 | INFO     | src.policies:train:157 - Total loss: 585.6965942382812\n",
      "2021-08-25 10:47:13.468 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:13.471 | INFO     | src.policies:train:103 - Epoch 492 / 800\n",
      "2021-08-25 10:47:13.472 | INFO     | src.policies:train:109 - Episode 2493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:47:13.536 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:13.537 | INFO     | src.policies:train:121 - Mean episode return: 178.0\n",
      "2021-08-25 10:47:13.538 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.38\n",
      "2021-08-25 10:47:13.539 | INFO     | src.policies:train:109 - Episode 2494\n",
      "2021-08-25 10:47:13.611 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:13.612 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:13.613 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.38\n",
      "2021-08-25 10:47:13.614 | WARNING  | src.policies:train:131 - The actual batch size is 378, instead of 200\n",
      "2021-08-25 10:47:13.620 | INFO     | src.policies:train:157 - Total loss: 888.3699340820312\n",
      "2021-08-25 10:47:13.621 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:13.625 | INFO     | src.policies:train:103 - Epoch 493 / 800\n",
      "2021-08-25 10:47:13.626 | INFO     | src.policies:train:109 - Episode 2495\n",
      "2021-08-25 10:47:13.696 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:13.698 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:13.699 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.61\n",
      "2021-08-25 10:47:13.704 | INFO     | src.policies:train:157 - Total loss: 802.481689453125\n",
      "2021-08-25 10:47:13.705 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:13.708 | INFO     | src.policies:train:103 - Epoch 494 / 800\n",
      "2021-08-25 10:47:13.709 | INFO     | src.policies:train:109 - Episode 2496\n",
      "2021-08-25 10:47:13.780 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:13.781 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:13.782 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.75\n",
      "2021-08-25 10:47:13.787 | INFO     | src.policies:train:157 - Total loss: 1061.1522216796875\n",
      "2021-08-25 10:47:13.788 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:13.791 | INFO     | src.policies:train:103 - Epoch 495 / 800\n",
      "2021-08-25 10:47:13.792 | INFO     | src.policies:train:109 - Episode 2497\n",
      "2021-08-25 10:47:13.844 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:13.846 | INFO     | src.policies:train:121 - Mean episode return: 146.0\n",
      "2021-08-25 10:47:13.847 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.37\n",
      "2021-08-25 10:47:13.848 | INFO     | src.policies:train:109 - Episode 2498\n",
      "2021-08-25 10:47:13.876 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:13.877 | INFO     | src.policies:train:121 - Mean episode return: 71.0\n",
      "2021-08-25 10:47:13.878 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 180.59\n",
      "2021-08-25 10:47:13.879 | WARNING  | src.policies:train:131 - The actual batch size is 217, instead of 200\n",
      "2021-08-25 10:47:13.885 | INFO     | src.policies:train:157 - Total loss: 572.3677978515625\n",
      "2021-08-25 10:47:13.886 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:13.889 | INFO     | src.policies:train:103 - Epoch 496 / 800\n",
      "2021-08-25 10:47:13.891 | INFO     | src.policies:train:109 - Episode 2499\n",
      "2021-08-25 10:47:13.962 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:13.963 | INFO     | src.policies:train:121 - Mean episode return: 191.0\n",
      "2021-08-25 10:47:13.964 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 180.5\n",
      "2021-08-25 10:47:13.965 | INFO     | src.policies:train:109 - Episode 2500\n",
      "2021-08-25 10:47:14.032 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:14.033 | INFO     | src.policies:train:121 - Mean episode return: 187.0\n",
      "2021-08-25 10:47:14.034 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 180.44\n",
      "2021-08-25 10:47:14.035 | WARNING  | src.policies:train:131 - The actual batch size is 378, instead of 200\n",
      "2021-08-25 10:47:14.041 | INFO     | src.policies:train:157 - Total loss: 869.8272094726562\n",
      "2021-08-25 10:47:14.042 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:14.046 | INFO     | src.policies:train:103 - Epoch 497 / 800\n",
      "2021-08-25 10:47:14.047 | INFO     | src.policies:train:109 - Episode 2501\n",
      "2021-08-25 10:47:14.117 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:14.119 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:14.120 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 180.44\n",
      "2021-08-25 10:47:14.125 | INFO     | src.policies:train:157 - Total loss: 956.5950927734375\n",
      "2021-08-25 10:47:14.126 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:14.129 | INFO     | src.policies:train:103 - Epoch 498 / 800\n",
      "2021-08-25 10:47:14.130 | INFO     | src.policies:train:109 - Episode 2502\n",
      "2021-08-25 10:47:14.201 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:14.202 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:14.203 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 180.64\n",
      "2021-08-25 10:47:14.208 | INFO     | src.policies:train:157 - Total loss: 472.5690612792969\n",
      "2021-08-25 10:47:14.209 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:14.212 | INFO     | src.policies:train:103 - Epoch 499 / 800\n",
      "2021-08-25 10:47:14.212 | INFO     | src.policies:train:109 - Episode 2503\n",
      "2021-08-25 10:47:14.282 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:14.283 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:14.284 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.02\n",
      "2021-08-25 10:47:14.289 | INFO     | src.policies:train:157 - Total loss: 816.2733154296875\n",
      "2021-08-25 10:47:14.290 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:14.293 | INFO     | src.policies:train:103 - Epoch 500 / 800\n",
      "2021-08-25 10:47:14.294 | INFO     | src.policies:train:109 - Episode 2504\n",
      "2021-08-25 10:47:14.366 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:14.368 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:14.369 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.02\n",
      "2021-08-25 10:47:14.373 | INFO     | src.policies:train:157 - Total loss: 515.5888671875\n",
      "2021-08-25 10:47:14.374 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:14.377 | INFO     | src.policies:train:103 - Epoch 501 / 800\n",
      "2021-08-25 10:47:14.378 | INFO     | src.policies:train:109 - Episode 2505\n",
      "2021-08-25 10:47:14.447 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:14.449 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:14.450 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.69\n",
      "2021-08-25 10:47:14.456 | INFO     | src.policies:train:157 - Total loss: 709.9306640625\n",
      "2021-08-25 10:47:14.457 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:14.460 | INFO     | src.policies:train:103 - Epoch 502 / 800\n",
      "2021-08-25 10:47:14.461 | INFO     | src.policies:train:109 - Episode 2506\n",
      "2021-08-25 10:47:14.531 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:14.532 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:14.533 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.69\n",
      "2021-08-25 10:47:14.538 | INFO     | src.policies:train:157 - Total loss: 827.8279418945312\n",
      "2021-08-25 10:47:14.539 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:14.542 | INFO     | src.policies:train:103 - Epoch 503 / 800\n",
      "2021-08-25 10:47:14.543 | INFO     | src.policies:train:109 - Episode 2507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:47:14.615 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:14.617 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:14.618 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.05\n",
      "2021-08-25 10:47:14.622 | INFO     | src.policies:train:157 - Total loss: 722.765380859375\n",
      "2021-08-25 10:47:14.623 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:14.627 | INFO     | src.policies:train:103 - Epoch 504 / 800\n",
      "2021-08-25 10:47:14.628 | INFO     | src.policies:train:109 - Episode 2508\n",
      "2021-08-25 10:47:14.701 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:14.702 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:14.703 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.35\n",
      "2021-08-25 10:47:14.708 | INFO     | src.policies:train:157 - Total loss: 383.5592346191406\n",
      "2021-08-25 10:47:14.709 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:14.712 | INFO     | src.policies:train:103 - Epoch 505 / 800\n",
      "2021-08-25 10:47:14.713 | INFO     | src.policies:train:109 - Episode 2509\n",
      "2021-08-25 10:47:14.783 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:14.785 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:14.786 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.35\n",
      "2021-08-25 10:47:14.790 | INFO     | src.policies:train:157 - Total loss: 642.7001342773438\n",
      "2021-08-25 10:47:14.791 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:14.795 | INFO     | src.policies:train:103 - Epoch 506 / 800\n",
      "2021-08-25 10:47:14.796 | INFO     | src.policies:train:109 - Episode 2510\n",
      "2021-08-25 10:47:14.867 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:14.869 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:14.870 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.35\n",
      "2021-08-25 10:47:14.875 | INFO     | src.policies:train:157 - Total loss: 738.7348022460938\n",
      "2021-08-25 10:47:14.876 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:14.879 | INFO     | src.policies:train:103 - Epoch 507 / 800\n",
      "2021-08-25 10:47:14.880 | INFO     | src.policies:train:109 - Episode 2511\n",
      "2021-08-25 10:47:14.952 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:14.953 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:14.954 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.55\n",
      "2021-08-25 10:47:14.959 | INFO     | src.policies:train:157 - Total loss: 638.992919921875\n",
      "2021-08-25 10:47:14.960 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:14.963 | INFO     | src.policies:train:103 - Epoch 508 / 800\n",
      "2021-08-25 10:47:14.964 | INFO     | src.policies:train:109 - Episode 2512\n",
      "2021-08-25 10:47:15.035 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:15.037 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:15.038 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 183.32\n",
      "2021-08-25 10:47:15.043 | INFO     | src.policies:train:157 - Total loss: 698.230224609375\n",
      "2021-08-25 10:47:15.044 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:15.047 | INFO     | src.policies:train:103 - Epoch 509 / 800\n",
      "2021-08-25 10:47:15.048 | INFO     | src.policies:train:109 - Episode 2513\n",
      "2021-08-25 10:47:15.118 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:15.119 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:15.120 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 183.33\n",
      "2021-08-25 10:47:15.125 | INFO     | src.policies:train:157 - Total loss: 722.2781372070312\n",
      "2021-08-25 10:47:15.126 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:15.129 | INFO     | src.policies:train:103 - Epoch 510 / 800\n",
      "2021-08-25 10:47:15.130 | INFO     | src.policies:train:109 - Episode 2514\n",
      "2021-08-25 10:47:15.196 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:15.198 | INFO     | src.policies:train:121 - Mean episode return: 189.0\n",
      "2021-08-25 10:47:15.199 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 183.22\n",
      "2021-08-25 10:47:15.199 | INFO     | src.policies:train:109 - Episode 2515\n",
      "2021-08-25 10:47:15.271 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:15.273 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:15.274 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 183.3\n",
      "2021-08-25 10:47:15.274 | WARNING  | src.policies:train:131 - The actual batch size is 389, instead of 200\n",
      "2021-08-25 10:47:15.280 | INFO     | src.policies:train:157 - Total loss: 667.5142211914062\n",
      "2021-08-25 10:47:15.281 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:15.285 | INFO     | src.policies:train:103 - Epoch 511 / 800\n",
      "2021-08-25 10:47:15.286 | INFO     | src.policies:train:109 - Episode 2516\n",
      "2021-08-25 10:47:15.359 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:15.361 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:15.362 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 183.4\n",
      "2021-08-25 10:47:15.367 | INFO     | src.policies:train:157 - Total loss: 731.1732177734375\n",
      "2021-08-25 10:47:15.367 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:15.371 | INFO     | src.policies:train:103 - Epoch 512 / 800\n",
      "2021-08-25 10:47:15.371 | INFO     | src.policies:train:109 - Episode 2517\n",
      "2021-08-25 10:47:15.442 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:15.443 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:15.444 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 183.4\n",
      "2021-08-25 10:47:15.449 | INFO     | src.policies:train:157 - Total loss: 824.452880859375\n",
      "2021-08-25 10:47:15.450 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:15.454 | INFO     | src.policies:train:103 - Epoch 513 / 800\n",
      "2021-08-25 10:47:15.455 | INFO     | src.policies:train:109 - Episode 2518\n",
      "2021-08-25 10:47:15.527 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:15.529 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:15.530 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 183.81\n",
      "2021-08-25 10:47:15.535 | INFO     | src.policies:train:157 - Total loss: 736.1028442382812\n",
      "2021-08-25 10:47:15.535 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:15.538 | INFO     | src.policies:train:103 - Epoch 514 / 800\n",
      "2021-08-25 10:47:15.539 | INFO     | src.policies:train:109 - Episode 2519\n",
      "2021-08-25 10:47:15.610 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:15.612 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:15.613 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 184.66\n",
      "2021-08-25 10:47:15.617 | INFO     | src.policies:train:157 - Total loss: 440.2267150878906\n",
      "2021-08-25 10:47:15.618 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:15.621 | INFO     | src.policies:train:103 - Epoch 515 / 800\n",
      "2021-08-25 10:47:15.622 | INFO     | src.policies:train:109 - Episode 2520\n",
      "2021-08-25 10:47:15.692 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:15.694 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:15.695 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 185.02\n",
      "2021-08-25 10:47:15.700 | INFO     | src.policies:train:157 - Total loss: 675.6122436523438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:47:15.700 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:15.703 | INFO     | src.policies:train:103 - Epoch 516 / 800\n",
      "2021-08-25 10:47:15.704 | INFO     | src.policies:train:109 - Episode 2521\n",
      "2021-08-25 10:47:15.776 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:15.777 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:15.778 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 185.02\n",
      "2021-08-25 10:47:15.783 | INFO     | src.policies:train:157 - Total loss: 620.53662109375\n",
      "2021-08-25 10:47:15.783 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:15.786 | INFO     | src.policies:train:103 - Epoch 517 / 800\n",
      "2021-08-25 10:47:15.787 | INFO     | src.policies:train:109 - Episode 2522\n",
      "2021-08-25 10:47:15.859 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:15.861 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:15.862 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 185.02\n",
      "2021-08-25 10:47:15.866 | INFO     | src.policies:train:157 - Total loss: 611.4992065429688\n",
      "2021-08-25 10:47:15.867 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:15.871 | INFO     | src.policies:train:103 - Epoch 518 / 800\n",
      "2021-08-25 10:47:15.872 | INFO     | src.policies:train:109 - Episode 2523\n",
      "2021-08-25 10:47:15.943 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:15.944 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:15.945 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 186.49\n",
      "2021-08-25 10:47:15.950 | INFO     | src.policies:train:157 - Total loss: 646.0201416015625\n",
      "2021-08-25 10:47:15.951 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:15.955 | INFO     | src.policies:train:103 - Epoch 519 / 800\n",
      "2021-08-25 10:47:15.955 | INFO     | src.policies:train:109 - Episode 2524\n",
      "2021-08-25 10:47:16.027 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:16.028 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:16.029 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 186.59\n",
      "2021-08-25 10:47:16.034 | INFO     | src.policies:train:157 - Total loss: 527.7266845703125\n",
      "2021-08-25 10:47:16.034 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:16.038 | INFO     | src.policies:train:103 - Epoch 520 / 800\n",
      "2021-08-25 10:47:16.039 | INFO     | src.policies:train:109 - Episode 2525\n",
      "2021-08-25 10:47:16.111 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:16.113 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:16.114 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 186.59\n",
      "2021-08-25 10:47:16.118 | INFO     | src.policies:train:157 - Total loss: 658.4600219726562\n",
      "2021-08-25 10:47:16.119 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:16.122 | INFO     | src.policies:train:103 - Epoch 521 / 800\n",
      "2021-08-25 10:47:16.123 | INFO     | src.policies:train:109 - Episode 2526\n",
      "2021-08-25 10:47:16.196 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:16.197 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:16.198 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 186.63\n",
      "2021-08-25 10:47:16.203 | INFO     | src.policies:train:157 - Total loss: 661.5728149414062\n",
      "2021-08-25 10:47:16.204 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:16.207 | INFO     | src.policies:train:103 - Epoch 522 / 800\n",
      "2021-08-25 10:47:16.207 | INFO     | src.policies:train:109 - Episode 2527\n",
      "2021-08-25 10:47:16.281 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:16.282 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:16.283 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 187.03\n",
      "2021-08-25 10:47:16.288 | INFO     | src.policies:train:157 - Total loss: 628.165771484375\n",
      "2021-08-25 10:47:16.289 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:16.292 | INFO     | src.policies:train:103 - Epoch 523 / 800\n",
      "2021-08-25 10:47:16.293 | INFO     | src.policies:train:109 - Episode 2528\n",
      "2021-08-25 10:47:16.364 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:16.366 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:16.367 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 188.82\n",
      "2021-08-25 10:47:16.371 | INFO     | src.policies:train:157 - Total loss: 668.3032836914062\n",
      "2021-08-25 10:47:16.372 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:16.375 | INFO     | src.policies:train:103 - Epoch 524 / 800\n",
      "2021-08-25 10:47:16.376 | INFO     | src.policies:train:109 - Episode 2529\n",
      "2021-08-25 10:47:16.447 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:16.449 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:16.450 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 189.46\n",
      "2021-08-25 10:47:16.454 | INFO     | src.policies:train:157 - Total loss: 616.1886596679688\n",
      "2021-08-25 10:47:16.455 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:16.458 | INFO     | src.policies:train:103 - Epoch 525 / 800\n",
      "2021-08-25 10:47:16.459 | INFO     | src.policies:train:109 - Episode 2530\n",
      "2021-08-25 10:47:16.529 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:16.530 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:16.531 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 189.68\n",
      "2021-08-25 10:47:16.536 | INFO     | src.policies:train:157 - Total loss: 628.6915893554688\n",
      "2021-08-25 10:47:16.537 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:16.540 | INFO     | src.policies:train:103 - Epoch 526 / 800\n",
      "2021-08-25 10:47:16.541 | INFO     | src.policies:train:109 - Episode 2531\n",
      "2021-08-25 10:47:16.612 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:16.613 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:16.614 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 189.68\n",
      "2021-08-25 10:47:16.619 | INFO     | src.policies:train:157 - Total loss: 717.9572143554688\n",
      "2021-08-25 10:47:16.620 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:16.623 | INFO     | src.policies:train:103 - Epoch 527 / 800\n",
      "2021-08-25 10:47:16.624 | INFO     | src.policies:train:109 - Episode 2532\n",
      "2021-08-25 10:47:16.695 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:16.697 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:16.698 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 189.68\n",
      "2021-08-25 10:47:16.702 | INFO     | src.policies:train:157 - Total loss: 655.8159790039062\n",
      "2021-08-25 10:47:16.703 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:16.706 | INFO     | src.policies:train:103 - Epoch 528 / 800\n",
      "2021-08-25 10:47:16.707 | INFO     | src.policies:train:109 - Episode 2533\n",
      "2021-08-25 10:47:16.779 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:16.780 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:16.782 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 189.68\n",
      "2021-08-25 10:47:16.786 | INFO     | src.policies:train:157 - Total loss: 503.1796875\n",
      "2021-08-25 10:47:16.787 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:16.790 | INFO     | src.policies:train:103 - Epoch 529 / 800\n",
      "2021-08-25 10:47:16.791 | INFO     | src.policies:train:109 - Episode 2534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:47:16.862 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:16.864 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:16.865 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 189.89\n",
      "2021-08-25 10:47:16.870 | INFO     | src.policies:train:157 - Total loss: 555.3593139648438\n",
      "2021-08-25 10:47:16.870 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:16.873 | INFO     | src.policies:train:103 - Epoch 530 / 800\n",
      "2021-08-25 10:47:16.874 | INFO     | src.policies:train:109 - Episode 2535\n",
      "2021-08-25 10:47:16.934 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:16.936 | INFO     | src.policies:train:121 - Mean episode return: 166.0\n",
      "2021-08-25 10:47:16.937 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 190.06\n",
      "2021-08-25 10:47:16.937 | INFO     | src.policies:train:109 - Episode 2536\n",
      "2021-08-25 10:47:17.010 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:17.011 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:17.012 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 190.06\n",
      "2021-08-25 10:47:17.013 | WARNING  | src.policies:train:131 - The actual batch size is 366, instead of 200\n",
      "2021-08-25 10:47:17.019 | INFO     | src.policies:train:157 - Total loss: 654.1342163085938\n",
      "2021-08-25 10:47:17.020 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:17.023 | INFO     | src.policies:train:103 - Epoch 531 / 800\n",
      "2021-08-25 10:47:17.024 | INFO     | src.policies:train:109 - Episode 2537\n",
      "2021-08-25 10:47:17.095 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:17.097 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:17.098 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 190.06\n",
      "2021-08-25 10:47:17.103 | INFO     | src.policies:train:157 - Total loss: 519.5816040039062\n",
      "2021-08-25 10:47:17.103 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:17.107 | INFO     | src.policies:train:103 - Epoch 532 / 800\n",
      "2021-08-25 10:47:17.107 | INFO     | src.policies:train:109 - Episode 2538\n",
      "2021-08-25 10:47:17.179 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:17.181 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:17.182 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 191.23\n",
      "2021-08-25 10:47:17.187 | INFO     | src.policies:train:157 - Total loss: 615.41943359375\n",
      "2021-08-25 10:47:17.188 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:17.191 | INFO     | src.policies:train:103 - Epoch 533 / 800\n",
      "2021-08-25 10:47:17.192 | INFO     | src.policies:train:109 - Episode 2539\n",
      "2021-08-25 10:47:17.254 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:17.255 | INFO     | src.policies:train:121 - Mean episode return: 170.0\n",
      "2021-08-25 10:47:17.256 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 191.17\n",
      "2021-08-25 10:47:17.257 | INFO     | src.policies:train:109 - Episode 2540\n",
      "2021-08-25 10:47:17.328 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:17.329 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:17.330 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 191.17\n",
      "2021-08-25 10:47:17.331 | WARNING  | src.policies:train:131 - The actual batch size is 370, instead of 200\n",
      "2021-08-25 10:47:17.337 | INFO     | src.policies:train:157 - Total loss: 557.6192626953125\n",
      "2021-08-25 10:47:17.338 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:17.341 | INFO     | src.policies:train:103 - Epoch 534 / 800\n",
      "2021-08-25 10:47:17.342 | INFO     | src.policies:train:109 - Episode 2541\n",
      "2021-08-25 10:47:17.389 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:17.390 | INFO     | src.policies:train:121 - Mean episode return: 130.0\n",
      "2021-08-25 10:47:17.391 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 190.47\n",
      "2021-08-25 10:47:17.392 | INFO     | src.policies:train:109 - Episode 2542\n",
      "2021-08-25 10:47:17.427 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:17.428 | INFO     | src.policies:train:121 - Mean episode return: 94.0\n",
      "2021-08-25 10:47:17.429 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 189.41\n",
      "2021-08-25 10:47:17.430 | WARNING  | src.policies:train:131 - The actual batch size is 224, instead of 200\n",
      "2021-08-25 10:47:17.435 | INFO     | src.policies:train:157 - Total loss: 322.49346923828125\n",
      "2021-08-25 10:47:17.436 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:17.440 | INFO     | src.policies:train:103 - Epoch 535 / 800\n",
      "2021-08-25 10:47:17.441 | INFO     | src.policies:train:109 - Episode 2543\n",
      "2021-08-25 10:47:17.511 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:17.512 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:17.513 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 190.83\n",
      "2021-08-25 10:47:17.518 | INFO     | src.policies:train:157 - Total loss: 678.3270263671875\n",
      "2021-08-25 10:47:17.519 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:17.522 | INFO     | src.policies:train:103 - Epoch 536 / 800\n",
      "2021-08-25 10:47:17.523 | INFO     | src.policies:train:109 - Episode 2544\n",
      "2021-08-25 10:47:17.596 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:17.597 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:17.598 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 191.15\n",
      "2021-08-25 10:47:17.603 | INFO     | src.policies:train:157 - Total loss: 632.6964111328125\n",
      "2021-08-25 10:47:17.604 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:17.607 | INFO     | src.policies:train:103 - Epoch 537 / 800\n",
      "2021-08-25 10:47:17.607 | INFO     | src.policies:train:109 - Episode 2545\n",
      "2021-08-25 10:47:17.679 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:17.680 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:17.681 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 191.15\n",
      "2021-08-25 10:47:17.686 | INFO     | src.policies:train:157 - Total loss: 527.1214599609375\n",
      "2021-08-25 10:47:17.687 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:17.690 | INFO     | src.policies:train:103 - Epoch 538 / 800\n",
      "2021-08-25 10:47:17.691 | INFO     | src.policies:train:109 - Episode 2546\n",
      "2021-08-25 10:47:17.761 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:17.763 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:17.764 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 191.15\n",
      "2021-08-25 10:47:17.768 | INFO     | src.policies:train:157 - Total loss: 611.7769775390625\n",
      "2021-08-25 10:47:17.769 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:17.772 | INFO     | src.policies:train:103 - Epoch 539 / 800\n",
      "2021-08-25 10:47:17.773 | INFO     | src.policies:train:109 - Episode 2547\n",
      "2021-08-25 10:47:17.846 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:17.847 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:17.848 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 191.15\n",
      "2021-08-25 10:47:17.853 | INFO     | src.policies:train:157 - Total loss: 432.9193420410156\n",
      "2021-08-25 10:47:17.854 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:17.857 | INFO     | src.policies:train:103 - Epoch 540 / 800\n",
      "2021-08-25 10:47:17.858 | INFO     | src.policies:train:109 - Episode 2548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:47:17.928 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:17.930 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:17.931 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 191.15\n",
      "2021-08-25 10:47:17.935 | INFO     | src.policies:train:157 - Total loss: 589.1818237304688\n",
      "2021-08-25 10:47:17.936 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:17.940 | INFO     | src.policies:train:103 - Epoch 541 / 800\n",
      "2021-08-25 10:47:17.940 | INFO     | src.policies:train:109 - Episode 2549\n",
      "2021-08-25 10:47:18.015 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:18.016 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:18.017 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 191.15\n",
      "2021-08-25 10:47:18.022 | INFO     | src.policies:train:157 - Total loss: 435.5231018066406\n",
      "2021-08-25 10:47:18.023 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:18.026 | INFO     | src.policies:train:103 - Epoch 542 / 800\n",
      "2021-08-25 10:47:18.027 | INFO     | src.policies:train:109 - Episode 2550\n",
      "2021-08-25 10:47:18.100 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:18.102 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:18.103 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 191.15\n",
      "2021-08-25 10:47:18.109 | INFO     | src.policies:train:157 - Total loss: 417.4621887207031\n",
      "2021-08-25 10:47:18.110 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:18.114 | INFO     | src.policies:train:103 - Epoch 543 / 800\n",
      "2021-08-25 10:47:18.115 | INFO     | src.policies:train:109 - Episode 2551\n",
      "2021-08-25 10:47:18.189 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:18.190 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:18.191 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 191.15\n",
      "2021-08-25 10:47:18.197 | INFO     | src.policies:train:157 - Total loss: 655.2214965820312\n",
      "2021-08-25 10:47:18.198 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:18.202 | INFO     | src.policies:train:103 - Epoch 544 / 800\n",
      "2021-08-25 10:47:18.203 | INFO     | src.policies:train:109 - Episode 2552\n",
      "2021-08-25 10:47:18.275 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:18.276 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:18.277 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 191.26\n",
      "2021-08-25 10:47:18.282 | INFO     | src.policies:train:157 - Total loss: 603.0831298828125\n",
      "2021-08-25 10:47:18.283 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:18.286 | INFO     | src.policies:train:103 - Epoch 545 / 800\n",
      "2021-08-25 10:47:18.287 | INFO     | src.policies:train:109 - Episode 2553\n",
      "2021-08-25 10:47:18.356 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:18.358 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:18.359 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 191.26\n",
      "2021-08-25 10:47:18.364 | INFO     | src.policies:train:157 - Total loss: 610.316650390625\n",
      "2021-08-25 10:47:18.365 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:18.368 | INFO     | src.policies:train:103 - Epoch 546 / 800\n",
      "2021-08-25 10:47:18.368 | INFO     | src.policies:train:109 - Episode 2554\n",
      "2021-08-25 10:47:18.440 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:18.441 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:18.442 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 191.26\n",
      "2021-08-25 10:47:18.447 | INFO     | src.policies:train:157 - Total loss: 433.873046875\n",
      "2021-08-25 10:47:18.448 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:18.451 | INFO     | src.policies:train:103 - Epoch 547 / 800\n",
      "2021-08-25 10:47:18.452 | INFO     | src.policies:train:109 - Episode 2555\n",
      "2021-08-25 10:47:18.522 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:18.524 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:18.525 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 191.26\n",
      "2021-08-25 10:47:18.529 | INFO     | src.policies:train:157 - Total loss: 413.0998229980469\n",
      "2021-08-25 10:47:18.530 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:18.533 | INFO     | src.policies:train:103 - Epoch 548 / 800\n",
      "2021-08-25 10:47:18.534 | INFO     | src.policies:train:109 - Episode 2556\n",
      "2021-08-25 10:47:18.604 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:18.606 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:18.607 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 191.26\n",
      "2021-08-25 10:47:18.612 | INFO     | src.policies:train:157 - Total loss: 404.30926513671875\n",
      "2021-08-25 10:47:18.612 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:18.615 | INFO     | src.policies:train:103 - Epoch 549 / 800\n",
      "2021-08-25 10:47:18.616 | INFO     | src.policies:train:109 - Episode 2557\n",
      "2021-08-25 10:47:18.686 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:18.688 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:18.689 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 191.26\n",
      "2021-08-25 10:47:18.693 | INFO     | src.policies:train:157 - Total loss: 620.2179565429688\n",
      "2021-08-25 10:47:18.694 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:18.697 | INFO     | src.policies:train:103 - Epoch 550 / 800\n",
      "2021-08-25 10:47:18.699 | INFO     | src.policies:train:109 - Episode 2558\n",
      "2021-08-25 10:47:18.774 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:18.775 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:18.776 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 191.26\n",
      "2021-08-25 10:47:18.781 | INFO     | src.policies:train:157 - Total loss: 433.4890441894531\n",
      "2021-08-25 10:47:18.782 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:18.785 | INFO     | src.policies:train:103 - Epoch 551 / 800\n",
      "2021-08-25 10:47:18.786 | INFO     | src.policies:train:109 - Episode 2559\n",
      "2021-08-25 10:47:18.856 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:18.858 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:18.859 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 191.26\n",
      "2021-08-25 10:47:18.864 | INFO     | src.policies:train:157 - Total loss: 477.3155517578125\n",
      "2021-08-25 10:47:18.864 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:18.867 | INFO     | src.policies:train:103 - Epoch 552 / 800\n",
      "2021-08-25 10:47:18.868 | INFO     | src.policies:train:109 - Episode 2560\n",
      "2021-08-25 10:47:18.942 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:18.943 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:18.944 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 191.26\n",
      "2021-08-25 10:47:18.950 | INFO     | src.policies:train:157 - Total loss: 406.1153259277344\n",
      "2021-08-25 10:47:18.951 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:18.954 | INFO     | src.policies:train:103 - Epoch 553 / 800\n",
      "2021-08-25 10:47:18.955 | INFO     | src.policies:train:109 - Episode 2561\n",
      "2021-08-25 10:47:19.026 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:19.028 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:47:19.029 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 192.06\n",
      "2021-08-25 10:47:19.034 | INFO     | src.policies:train:157 - Total loss: 504.1355285644531\n",
      "2021-08-25 10:47:19.035 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:19.038 | INFO     | src.policies:train:103 - Epoch 554 / 800\n",
      "2021-08-25 10:47:19.038 | INFO     | src.policies:train:109 - Episode 2562\n",
      "2021-08-25 10:47:19.111 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:19.113 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:19.114 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 192.06\n",
      "2021-08-25 10:47:19.119 | INFO     | src.policies:train:157 - Total loss: 655.6625366210938\n",
      "2021-08-25 10:47:19.120 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:19.123 | INFO     | src.policies:train:103 - Epoch 555 / 800\n",
      "2021-08-25 10:47:19.123 | INFO     | src.policies:train:109 - Episode 2563\n",
      "2021-08-25 10:47:19.195 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:19.196 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:19.197 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 192.06\n",
      "2021-08-25 10:47:19.202 | INFO     | src.policies:train:157 - Total loss: 530.1261596679688\n",
      "2021-08-25 10:47:19.203 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:19.206 | INFO     | src.policies:train:103 - Epoch 556 / 800\n",
      "2021-08-25 10:47:19.206 | INFO     | src.policies:train:109 - Episode 2564\n",
      "2021-08-25 10:47:19.277 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:19.278 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:19.280 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 192.06\n",
      "2021-08-25 10:47:19.285 | INFO     | src.policies:train:157 - Total loss: 609.5955200195312\n",
      "2021-08-25 10:47:19.286 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:19.289 | INFO     | src.policies:train:103 - Epoch 557 / 800\n",
      "2021-08-25 10:47:19.290 | INFO     | src.policies:train:109 - Episode 2565\n",
      "2021-08-25 10:47:19.360 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:19.362 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:19.363 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 192.06\n",
      "2021-08-25 10:47:19.368 | INFO     | src.policies:train:157 - Total loss: 388.5569763183594\n",
      "2021-08-25 10:47:19.368 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:19.372 | INFO     | src.policies:train:103 - Epoch 558 / 800\n",
      "2021-08-25 10:47:19.373 | INFO     | src.policies:train:109 - Episode 2566\n",
      "2021-08-25 10:47:19.445 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:19.447 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:19.448 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 192.15\n",
      "2021-08-25 10:47:19.452 | INFO     | src.policies:train:157 - Total loss: 609.4204711914062\n",
      "2021-08-25 10:47:19.453 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:19.456 | INFO     | src.policies:train:103 - Epoch 559 / 800\n",
      "2021-08-25 10:47:19.457 | INFO     | src.policies:train:109 - Episode 2567\n",
      "2021-08-25 10:47:19.527 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:19.529 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:19.530 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 192.15\n",
      "2021-08-25 10:47:19.535 | INFO     | src.policies:train:157 - Total loss: 536.5576171875\n",
      "2021-08-25 10:47:19.536 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:19.539 | INFO     | src.policies:train:103 - Epoch 560 / 800\n",
      "2021-08-25 10:47:19.540 | INFO     | src.policies:train:109 - Episode 2568\n",
      "2021-08-25 10:47:19.612 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:19.614 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:19.615 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 193.02\n",
      "2021-08-25 10:47:19.619 | INFO     | src.policies:train:157 - Total loss: 546.9476318359375\n",
      "2021-08-25 10:47:19.620 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:19.623 | INFO     | src.policies:train:103 - Epoch 561 / 800\n",
      "2021-08-25 10:47:19.624 | INFO     | src.policies:train:109 - Episode 2569\n",
      "2021-08-25 10:47:19.696 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:19.697 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:19.698 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 193.02\n",
      "2021-08-25 10:47:19.703 | INFO     | src.policies:train:157 - Total loss: 407.7986145019531\n",
      "2021-08-25 10:47:19.704 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:19.707 | INFO     | src.policies:train:103 - Epoch 562 / 800\n",
      "2021-08-25 10:47:19.708 | INFO     | src.policies:train:109 - Episode 2570\n",
      "2021-08-25 10:47:19.746 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:19.748 | INFO     | src.policies:train:121 - Mean episode return: 102.0\n",
      "2021-08-25 10:47:19.749 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 192.53\n",
      "2021-08-25 10:47:19.750 | INFO     | src.policies:train:109 - Episode 2571\n",
      "2021-08-25 10:47:19.823 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:19.824 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:19.825 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 192.53\n",
      "2021-08-25 10:47:19.826 | WARNING  | src.policies:train:131 - The actual batch size is 302, instead of 200\n",
      "2021-08-25 10:47:19.832 | INFO     | src.policies:train:157 - Total loss: 368.3949890136719\n",
      "2021-08-25 10:47:19.833 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:19.837 | INFO     | src.policies:train:103 - Epoch 563 / 800\n",
      "2021-08-25 10:47:19.838 | INFO     | src.policies:train:109 - Episode 2572\n",
      "2021-08-25 10:47:19.911 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:19.913 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:19.914 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 192.65\n",
      "2021-08-25 10:47:19.918 | INFO     | src.policies:train:157 - Total loss: 380.6321716308594\n",
      "2021-08-25 10:47:19.919 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:19.922 | INFO     | src.policies:train:103 - Epoch 564 / 800\n",
      "2021-08-25 10:47:19.923 | INFO     | src.policies:train:109 - Episode 2573\n",
      "2021-08-25 10:47:19.995 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:19.997 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:19.998 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 192.98\n",
      "2021-08-25 10:47:20.003 | INFO     | src.policies:train:157 - Total loss: 538.2750244140625\n",
      "2021-08-25 10:47:20.004 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:20.008 | INFO     | src.policies:train:103 - Epoch 565 / 800\n",
      "2021-08-25 10:47:20.009 | INFO     | src.policies:train:109 - Episode 2574\n",
      "2021-08-25 10:47:20.082 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:20.084 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:20.085 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 192.98\n",
      "2021-08-25 10:47:20.090 | INFO     | src.policies:train:157 - Total loss: 499.92138671875\n",
      "2021-08-25 10:47:20.090 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:20.094 | INFO     | src.policies:train:103 - Epoch 566 / 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:47:20.094 | INFO     | src.policies:train:109 - Episode 2575\n",
      "2021-08-25 10:47:20.166 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:20.167 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:20.169 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 192.98\n",
      "2021-08-25 10:47:20.173 | INFO     | src.policies:train:157 - Total loss: 325.7951965332031\n",
      "2021-08-25 10:47:20.174 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:20.178 | INFO     | src.policies:train:103 - Epoch 567 / 800\n",
      "2021-08-25 10:47:20.179 | INFO     | src.policies:train:109 - Episode 2576\n",
      "2021-08-25 10:47:20.251 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:20.252 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:20.253 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 192.98\n",
      "2021-08-25 10:47:20.258 | INFO     | src.policies:train:157 - Total loss: 638.0813598632812\n",
      "2021-08-25 10:47:20.259 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:20.263 | INFO     | src.policies:train:103 - Epoch 568 / 800\n",
      "2021-08-25 10:47:20.263 | INFO     | src.policies:train:109 - Episode 2577\n",
      "2021-08-25 10:47:20.337 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:20.338 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:20.339 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 193.01\n",
      "2021-08-25 10:47:20.344 | INFO     | src.policies:train:157 - Total loss: 324.97821044921875\n",
      "2021-08-25 10:47:20.345 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:20.348 | INFO     | src.policies:train:103 - Epoch 569 / 800\n",
      "2021-08-25 10:47:20.349 | INFO     | src.policies:train:109 - Episode 2578\n",
      "2021-08-25 10:47:20.414 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:20.416 | INFO     | src.policies:train:121 - Mean episode return: 185.0\n",
      "2021-08-25 10:47:20.417 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 192.86\n",
      "2021-08-25 10:47:20.418 | INFO     | src.policies:train:109 - Episode 2579\n",
      "2021-08-25 10:47:20.492 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:20.494 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:20.494 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 192.86\n",
      "2021-08-25 10:47:20.495 | WARNING  | src.policies:train:131 - The actual batch size is 385, instead of 200\n",
      "2021-08-25 10:47:20.502 | INFO     | src.policies:train:157 - Total loss: 356.1866149902344\n",
      "2021-08-25 10:47:20.502 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:20.505 | INFO     | src.policies:train:103 - Epoch 570 / 800\n",
      "2021-08-25 10:47:20.507 | INFO     | src.policies:train:109 - Episode 2580\n",
      "2021-08-25 10:47:20.579 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:20.581 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:20.582 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 192.86\n",
      "2021-08-25 10:47:20.586 | INFO     | src.policies:train:157 - Total loss: 471.6794128417969\n",
      "2021-08-25 10:47:20.587 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:20.590 | INFO     | src.policies:train:103 - Epoch 571 / 800\n",
      "2021-08-25 10:47:20.591 | INFO     | src.policies:train:109 - Episode 2581\n",
      "2021-08-25 10:47:20.663 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:20.665 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:20.666 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 192.86\n",
      "2021-08-25 10:47:20.670 | INFO     | src.policies:train:157 - Total loss: 445.6653747558594\n",
      "2021-08-25 10:47:20.671 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:20.675 | INFO     | src.policies:train:103 - Epoch 572 / 800\n",
      "2021-08-25 10:47:20.676 | INFO     | src.policies:train:109 - Episode 2582\n",
      "2021-08-25 10:47:20.752 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:20.753 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:20.754 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 193.51\n",
      "2021-08-25 10:47:20.760 | INFO     | src.policies:train:157 - Total loss: 584.1980590820312\n",
      "2021-08-25 10:47:20.761 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:20.765 | INFO     | src.policies:train:103 - Epoch 573 / 800\n",
      "2021-08-25 10:47:20.766 | INFO     | src.policies:train:109 - Episode 2583\n",
      "2021-08-25 10:47:20.842 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:20.843 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:20.844 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 193.51\n",
      "2021-08-25 10:47:20.850 | INFO     | src.policies:train:157 - Total loss: 346.60430908203125\n",
      "2021-08-25 10:47:20.851 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:20.855 | INFO     | src.policies:train:103 - Epoch 574 / 800\n",
      "2021-08-25 10:47:20.857 | INFO     | src.policies:train:109 - Episode 2584\n",
      "2021-08-25 10:47:20.930 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:20.932 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:20.933 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 193.51\n",
      "2021-08-25 10:47:20.938 | INFO     | src.policies:train:157 - Total loss: 336.7589416503906\n",
      "2021-08-25 10:47:20.940 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:20.944 | INFO     | src.policies:train:103 - Epoch 575 / 800\n",
      "2021-08-25 10:47:20.945 | INFO     | src.policies:train:109 - Episode 2585\n",
      "2021-08-25 10:47:20.999 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:21.001 | INFO     | src.policies:train:121 - Mean episode return: 144.0\n",
      "2021-08-25 10:47:21.002 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 192.95\n",
      "2021-08-25 10:47:21.003 | INFO     | src.policies:train:109 - Episode 2586\n",
      "2021-08-25 10:47:21.078 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:21.079 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:21.080 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 192.95\n",
      "2021-08-25 10:47:21.081 | WARNING  | src.policies:train:131 - The actual batch size is 344, instead of 200\n",
      "2021-08-25 10:47:21.088 | INFO     | src.policies:train:157 - Total loss: 454.3465881347656\n",
      "2021-08-25 10:47:21.089 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:21.093 | INFO     | src.policies:train:103 - Epoch 576 / 800\n",
      "2021-08-25 10:47:21.094 | INFO     | src.policies:train:109 - Episode 2587\n",
      "2021-08-25 10:47:21.167 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:21.169 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:21.170 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 192.95\n",
      "2021-08-25 10:47:21.174 | INFO     | src.policies:train:157 - Total loss: 362.3517761230469\n",
      "2021-08-25 10:47:21.175 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:21.178 | INFO     | src.policies:train:103 - Epoch 577 / 800\n",
      "2021-08-25 10:47:21.180 | INFO     | src.policies:train:109 - Episode 2588\n",
      "2021-08-25 10:47:21.253 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:21.254 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:21.255 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 192.95\n",
      "2021-08-25 10:47:21.261 | INFO     | src.policies:train:157 - Total loss: 350.9715881347656\n",
      "2021-08-25 10:47:21.262 | INFO     | src.policies:train:161 - Epoch infos: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:47:21.267 | INFO     | src.policies:train:103 - Epoch 578 / 800\n",
      "2021-08-25 10:47:21.268 | INFO     | src.policies:train:109 - Episode 2589\n",
      "2021-08-25 10:47:21.343 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:21.345 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:21.346 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 193.53\n",
      "2021-08-25 10:47:21.352 | INFO     | src.policies:train:157 - Total loss: 701.2713012695312\n",
      "2021-08-25 10:47:21.352 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:21.355 | INFO     | src.policies:train:103 - Epoch 579 / 800\n",
      "2021-08-25 10:47:21.356 | INFO     | src.policies:train:109 - Episode 2590\n",
      "2021-08-25 10:47:21.429 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:21.430 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:21.431 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 193.53\n",
      "2021-08-25 10:47:21.437 | INFO     | src.policies:train:157 - Total loss: 406.1410827636719\n",
      "2021-08-25 10:47:21.438 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:21.442 | INFO     | src.policies:train:103 - Epoch 580 / 800\n",
      "2021-08-25 10:47:21.443 | INFO     | src.policies:train:109 - Episode 2591\n",
      "2021-08-25 10:47:21.517 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:21.518 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:21.519 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 193.53\n",
      "2021-08-25 10:47:21.525 | INFO     | src.policies:train:157 - Total loss: 391.3251953125\n",
      "2021-08-25 10:47:21.526 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:21.530 | INFO     | src.policies:train:103 - Epoch 581 / 800\n",
      "2021-08-25 10:47:21.531 | INFO     | src.policies:train:109 - Episode 2592\n",
      "2021-08-25 10:47:21.603 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:21.605 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:21.606 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 193.53\n",
      "2021-08-25 10:47:21.612 | INFO     | src.policies:train:157 - Total loss: 431.52978515625\n",
      "2021-08-25 10:47:21.613 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:21.617 | INFO     | src.policies:train:103 - Epoch 582 / 800\n",
      "2021-08-25 10:47:21.618 | INFO     | src.policies:train:109 - Episode 2593\n",
      "2021-08-25 10:47:21.689 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:21.690 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:21.691 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 193.75\n",
      "2021-08-25 10:47:21.697 | INFO     | src.policies:train:157 - Total loss: 382.8898010253906\n",
      "2021-08-25 10:47:21.698 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:21.702 | INFO     | src.policies:train:103 - Epoch 583 / 800\n",
      "2021-08-25 10:47:21.704 | INFO     | src.policies:train:109 - Episode 2594\n",
      "2021-08-25 10:47:21.776 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:21.777 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:21.779 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 193.75\n",
      "2021-08-25 10:47:21.784 | INFO     | src.policies:train:157 - Total loss: 322.78558349609375\n",
      "2021-08-25 10:47:21.785 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:21.789 | INFO     | src.policies:train:103 - Epoch 584 / 800\n",
      "2021-08-25 10:47:21.790 | INFO     | src.policies:train:109 - Episode 2595\n",
      "2021-08-25 10:47:21.863 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:21.865 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:21.866 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 193.75\n",
      "2021-08-25 10:47:21.871 | INFO     | src.policies:train:157 - Total loss: 403.0189514160156\n",
      "2021-08-25 10:47:21.871 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:21.874 | INFO     | src.policies:train:103 - Epoch 585 / 800\n",
      "2021-08-25 10:47:21.875 | INFO     | src.policies:train:109 - Episode 2596\n",
      "2021-08-25 10:47:21.949 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:21.951 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:21.952 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 193.75\n",
      "2021-08-25 10:47:21.958 | INFO     | src.policies:train:157 - Total loss: 330.0945739746094\n",
      "2021-08-25 10:47:21.959 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:21.963 | INFO     | src.policies:train:103 - Epoch 586 / 800\n",
      "2021-08-25 10:47:21.964 | INFO     | src.policies:train:109 - Episode 2597\n",
      "2021-08-25 10:47:22.038 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:22.039 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:22.040 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 194.29\n",
      "2021-08-25 10:47:22.047 | INFO     | src.policies:train:157 - Total loss: 668.0624389648438\n",
      "2021-08-25 10:47:22.048 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:22.052 | INFO     | src.policies:train:103 - Epoch 587 / 800\n",
      "2021-08-25 10:47:22.053 | INFO     | src.policies:train:109 - Episode 2598\n",
      "2021-08-25 10:47:22.127 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:22.128 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:22.129 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 195.58\n",
      "2021-08-25 10:47:22.134 | INFO     | src.policies:train:157 - Total loss: 624.8057250976562\n",
      "2021-08-25 10:47:22.135 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:22.138 | INFO     | src.policies:train:103 - Epoch 588 / 800\n",
      "2021-08-25 10:47:22.139 | INFO     | src.policies:train:109 - Episode 2599\n",
      "2021-08-25 10:47:22.210 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:22.212 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:22.213 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 195.67\n",
      "2021-08-25 10:47:22.218 | INFO     | src.policies:train:157 - Total loss: 547.5494995117188\n",
      "2021-08-25 10:47:22.219 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:22.222 | INFO     | src.policies:train:103 - Epoch 589 / 800\n",
      "2021-08-25 10:47:22.223 | INFO     | src.policies:train:109 - Episode 2600\n",
      "2021-08-25 10:47:22.295 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:22.297 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:22.298 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 195.8\n",
      "2021-08-25 10:47:22.303 | INFO     | src.policies:train:157 - Total loss: 676.0244140625\n",
      "2021-08-25 10:47:22.303 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:22.306 | INFO     | src.policies:train:103 - Epoch 590 / 800\n",
      "2021-08-25 10:47:22.307 | INFO     | src.policies:train:109 - Episode 2601\n",
      "2021-08-25 10:47:22.377 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:22.379 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:22.380 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 195.8\n",
      "2021-08-25 10:47:22.384 | INFO     | src.policies:train:157 - Total loss: 712.311767578125\n",
      "2021-08-25 10:47:22.385 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:22.388 | INFO     | src.policies:train:103 - Epoch 591 / 800\n",
      "2021-08-25 10:47:22.388 | INFO     | src.policies:train:109 - Episode 2602\n",
      "2021-08-25 10:47:22.460 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:47:22.461 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:22.462 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 195.8\n",
      "2021-08-25 10:47:22.467 | INFO     | src.policies:train:157 - Total loss: 728.1613159179688\n",
      "2021-08-25 10:47:22.468 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:22.471 | INFO     | src.policies:train:103 - Epoch 592 / 800\n",
      "2021-08-25 10:47:22.472 | INFO     | src.policies:train:109 - Episode 2603\n",
      "2021-08-25 10:47:22.542 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:22.544 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:22.545 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 195.8\n",
      "2021-08-25 10:47:22.550 | INFO     | src.policies:train:157 - Total loss: 707.6143188476562\n",
      "2021-08-25 10:47:22.550 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:22.554 | INFO     | src.policies:train:103 - Epoch 593 / 800\n",
      "2021-08-25 10:47:22.555 | INFO     | src.policies:train:109 - Episode 2604\n",
      "2021-08-25 10:47:22.625 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:22.626 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:22.627 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 195.8\n",
      "2021-08-25 10:47:22.632 | INFO     | src.policies:train:157 - Total loss: 762.786376953125\n",
      "2021-08-25 10:47:22.633 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:22.636 | INFO     | src.policies:train:103 - Epoch 594 / 800\n",
      "2021-08-25 10:47:22.637 | INFO     | src.policies:train:109 - Episode 2605\n",
      "2021-08-25 10:47:22.709 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:22.711 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:22.712 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 195.8\n",
      "2021-08-25 10:47:22.717 | INFO     | src.policies:train:157 - Total loss: 746.4637451171875\n",
      "2021-08-25 10:47:22.717 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:22.721 | INFO     | src.policies:train:103 - Epoch 595 / 800\n",
      "2021-08-25 10:47:22.722 | INFO     | src.policies:train:109 - Episode 2606\n",
      "2021-08-25 10:47:22.794 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:22.795 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:22.797 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 195.8\n",
      "2021-08-25 10:47:22.802 | INFO     | src.policies:train:157 - Total loss: 720.9801025390625\n",
      "2021-08-25 10:47:22.803 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:22.807 | INFO     | src.policies:train:103 - Epoch 596 / 800\n",
      "2021-08-25 10:47:22.808 | INFO     | src.policies:train:109 - Episode 2607\n",
      "2021-08-25 10:47:22.881 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:22.882 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:22.883 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 195.8\n",
      "2021-08-25 10:47:22.888 | INFO     | src.policies:train:157 - Total loss: 662.415771484375\n",
      "2021-08-25 10:47:22.889 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:22.892 | INFO     | src.policies:train:103 - Epoch 597 / 800\n",
      "2021-08-25 10:47:22.893 | INFO     | src.policies:train:109 - Episode 2608\n",
      "2021-08-25 10:47:22.964 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:22.966 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:22.967 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 195.8\n",
      "2021-08-25 10:47:22.971 | INFO     | src.policies:train:157 - Total loss: 684.5101928710938\n",
      "2021-08-25 10:47:22.972 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:22.975 | INFO     | src.policies:train:103 - Epoch 598 / 800\n",
      "2021-08-25 10:47:22.976 | INFO     | src.policies:train:109 - Episode 2609\n",
      "2021-08-25 10:47:23.045 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:23.047 | INFO     | src.policies:train:121 - Mean episode return: 190.0\n",
      "2021-08-25 10:47:23.048 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 195.7\n",
      "2021-08-25 10:47:23.049 | INFO     | src.policies:train:109 - Episode 2610\n",
      "2021-08-25 10:47:23.121 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:23.122 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:23.123 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 195.7\n",
      "2021-08-25 10:47:23.124 | WARNING  | src.policies:train:131 - The actual batch size is 390, instead of 200\n",
      "2021-08-25 10:47:23.130 | INFO     | src.policies:train:157 - Total loss: 728.7489624023438\n",
      "2021-08-25 10:47:23.131 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:23.134 | INFO     | src.policies:train:103 - Epoch 599 / 800\n",
      "2021-08-25 10:47:23.135 | INFO     | src.policies:train:109 - Episode 2611\n",
      "2021-08-25 10:47:23.208 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:23.210 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:23.211 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 195.7\n",
      "2021-08-25 10:47:23.216 | INFO     | src.policies:train:157 - Total loss: 545.917724609375\n",
      "2021-08-25 10:47:23.217 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:23.220 | INFO     | src.policies:train:103 - Epoch 600 / 800\n",
      "2021-08-25 10:47:23.220 | INFO     | src.policies:train:109 - Episode 2612\n",
      "2021-08-25 10:47:23.290 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:23.292 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:23.293 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 195.7\n",
      "2021-08-25 10:47:23.298 | INFO     | src.policies:train:157 - Total loss: 448.51025390625\n",
      "2021-08-25 10:47:23.298 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:23.301 | INFO     | src.policies:train:103 - Epoch 601 / 800\n",
      "2021-08-25 10:47:23.302 | INFO     | src.policies:train:109 - Episode 2613\n",
      "2021-08-25 10:47:23.373 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:23.375 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:23.376 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 195.7\n",
      "2021-08-25 10:47:23.381 | INFO     | src.policies:train:157 - Total loss: 702.7843627929688\n",
      "2021-08-25 10:47:23.382 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:23.385 | INFO     | src.policies:train:103 - Epoch 602 / 800\n",
      "2021-08-25 10:47:23.385 | INFO     | src.policies:train:109 - Episode 2614\n",
      "2021-08-25 10:47:23.406 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:23.407 | INFO     | src.policies:train:121 - Mean episode return: 52.0\n",
      "2021-08-25 10:47:23.408 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 194.33\n",
      "2021-08-25 10:47:23.409 | INFO     | src.policies:train:109 - Episode 2615\n",
      "2021-08-25 10:47:23.481 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:23.483 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:23.483 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 194.33\n",
      "2021-08-25 10:47:23.484 | WARNING  | src.policies:train:131 - The actual batch size is 252, instead of 200\n",
      "2021-08-25 10:47:23.490 | INFO     | src.policies:train:157 - Total loss: 589.3301391601562\n",
      "2021-08-25 10:47:23.491 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:23.494 | INFO     | src.policies:train:103 - Epoch 603 / 800\n",
      "2021-08-25 10:47:23.495 | INFO     | src.policies:train:109 - Episode 2616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:47:23.565 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:23.567 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:23.568 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 194.33\n",
      "2021-08-25 10:47:23.573 | INFO     | src.policies:train:157 - Total loss: 497.6723937988281\n",
      "2021-08-25 10:47:23.573 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:23.577 | INFO     | src.policies:train:103 - Epoch 604 / 800\n",
      "2021-08-25 10:47:23.578 | INFO     | src.policies:train:109 - Episode 2617\n",
      "2021-08-25 10:47:23.648 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:23.649 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:23.650 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 194.33\n",
      "2021-08-25 10:47:23.655 | INFO     | src.policies:train:157 - Total loss: 592.2322387695312\n",
      "2021-08-25 10:47:23.656 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:23.659 | INFO     | src.policies:train:103 - Epoch 605 / 800\n",
      "2021-08-25 10:47:23.660 | INFO     | src.policies:train:109 - Episode 2618\n",
      "2021-08-25 10:47:23.732 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:23.734 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:23.735 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 194.33\n",
      "2021-08-25 10:47:23.740 | INFO     | src.policies:train:157 - Total loss: 571.8795776367188\n",
      "2021-08-25 10:47:23.741 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:23.744 | INFO     | src.policies:train:103 - Epoch 606 / 800\n",
      "2021-08-25 10:47:23.744 | INFO     | src.policies:train:109 - Episode 2619\n",
      "2021-08-25 10:47:23.817 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:23.819 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:23.820 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 194.33\n",
      "2021-08-25 10:47:23.825 | INFO     | src.policies:train:157 - Total loss: 688.6897583007812\n",
      "2021-08-25 10:47:23.826 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:23.829 | INFO     | src.policies:train:103 - Epoch 607 / 800\n",
      "2021-08-25 10:47:23.830 | INFO     | src.policies:train:109 - Episode 2620\n",
      "2021-08-25 10:47:23.902 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:23.904 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:23.905 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 194.33\n",
      "2021-08-25 10:47:23.909 | INFO     | src.policies:train:157 - Total loss: 717.3143920898438\n",
      "2021-08-25 10:47:23.910 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:23.913 | INFO     | src.policies:train:103 - Epoch 608 / 800\n",
      "2021-08-25 10:47:23.914 | INFO     | src.policies:train:109 - Episode 2621\n",
      "2021-08-25 10:47:23.986 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:23.988 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:23.989 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 194.33\n",
      "2021-08-25 10:47:23.994 | INFO     | src.policies:train:157 - Total loss: 701.012451171875\n",
      "2021-08-25 10:47:23.994 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:23.998 | INFO     | src.policies:train:103 - Epoch 609 / 800\n",
      "2021-08-25 10:47:23.999 | INFO     | src.policies:train:109 - Episode 2622\n",
      "2021-08-25 10:47:24.071 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:24.072 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:24.073 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 194.33\n",
      "2021-08-25 10:47:24.078 | INFO     | src.policies:train:157 - Total loss: 613.8245849609375\n",
      "2021-08-25 10:47:24.079 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:24.082 | INFO     | src.policies:train:103 - Epoch 610 / 800\n",
      "2021-08-25 10:47:24.083 | INFO     | src.policies:train:109 - Episode 2623\n",
      "2021-08-25 10:47:24.157 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:24.158 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:24.159 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 194.33\n",
      "2021-08-25 10:47:24.164 | INFO     | src.policies:train:157 - Total loss: 639.4518432617188\n",
      "2021-08-25 10:47:24.164 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:24.167 | INFO     | src.policies:train:103 - Epoch 611 / 800\n",
      "2021-08-25 10:47:24.168 | INFO     | src.policies:train:109 - Episode 2624\n",
      "2021-08-25 10:47:24.240 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:24.242 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:24.242 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 194.33\n",
      "2021-08-25 10:47:24.247 | INFO     | src.policies:train:157 - Total loss: 629.203857421875\n",
      "2021-08-25 10:47:24.248 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:24.251 | INFO     | src.policies:train:103 - Epoch 612 / 800\n",
      "2021-08-25 10:47:24.251 | INFO     | src.policies:train:109 - Episode 2625\n",
      "2021-08-25 10:47:24.322 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:24.324 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:24.325 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 194.33\n",
      "2021-08-25 10:47:24.330 | INFO     | src.policies:train:157 - Total loss: 626.3585815429688\n",
      "2021-08-25 10:47:24.330 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:24.333 | INFO     | src.policies:train:103 - Epoch 613 / 800\n",
      "2021-08-25 10:47:24.334 | INFO     | src.policies:train:109 - Episode 2626\n",
      "2021-08-25 10:47:24.406 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:24.408 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:24.409 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 194.33\n",
      "2021-08-25 10:47:24.414 | INFO     | src.policies:train:157 - Total loss: 647.5704345703125\n",
      "2021-08-25 10:47:24.415 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:24.417 | INFO     | src.policies:train:103 - Epoch 614 / 800\n",
      "2021-08-25 10:47:24.418 | INFO     | src.policies:train:109 - Episode 2627\n",
      "2021-08-25 10:47:24.491 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:24.492 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:24.494 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 194.33\n",
      "2021-08-25 10:47:24.499 | INFO     | src.policies:train:157 - Total loss: 648.32373046875\n",
      "2021-08-25 10:47:24.499 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:24.503 | INFO     | src.policies:train:103 - Epoch 615 / 800\n",
      "2021-08-25 10:47:24.504 | INFO     | src.policies:train:109 - Episode 2628\n",
      "2021-08-25 10:47:24.559 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:24.560 | INFO     | src.policies:train:121 - Mean episode return: 149.0\n",
      "2021-08-25 10:47:24.561 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 193.82\n",
      "2021-08-25 10:47:24.562 | INFO     | src.policies:train:109 - Episode 2629\n",
      "2021-08-25 10:47:24.608 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:24.609 | INFO     | src.policies:train:121 - Mean episode return: 124.0\n",
      "2021-08-25 10:47:24.610 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 193.06\n",
      "2021-08-25 10:47:24.611 | WARNING  | src.policies:train:131 - The actual batch size is 273, instead of 200\n",
      "2021-08-25 10:47:24.616 | INFO     | src.policies:train:157 - Total loss: 522.0864868164062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:47:24.617 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:24.620 | INFO     | src.policies:train:103 - Epoch 616 / 800\n",
      "2021-08-25 10:47:24.621 | INFO     | src.policies:train:109 - Episode 2630\n",
      "2021-08-25 10:47:24.681 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:24.683 | INFO     | src.policies:train:121 - Mean episode return: 163.0\n",
      "2021-08-25 10:47:24.684 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 192.69\n",
      "2021-08-25 10:47:24.685 | INFO     | src.policies:train:109 - Episode 2631\n",
      "2021-08-25 10:47:24.758 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:24.759 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:24.760 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 192.69\n",
      "2021-08-25 10:47:24.761 | WARNING  | src.policies:train:131 - The actual batch size is 363, instead of 200\n",
      "2021-08-25 10:47:24.767 | INFO     | src.policies:train:157 - Total loss: 598.2463989257812\n",
      "2021-08-25 10:47:24.768 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:24.771 | INFO     | src.policies:train:103 - Epoch 617 / 800\n",
      "2021-08-25 10:47:24.772 | INFO     | src.policies:train:109 - Episode 2632\n",
      "2021-08-25 10:47:24.843 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:24.844 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:24.846 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 192.69\n",
      "2021-08-25 10:47:24.850 | INFO     | src.policies:train:157 - Total loss: 579.6658935546875\n",
      "2021-08-25 10:47:24.851 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:24.854 | INFO     | src.policies:train:103 - Epoch 618 / 800\n",
      "2021-08-25 10:47:24.855 | INFO     | src.policies:train:109 - Episode 2633\n",
      "2021-08-25 10:47:24.911 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:24.912 | INFO     | src.policies:train:121 - Mean episode return: 155.0\n",
      "2021-08-25 10:47:24.913 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 192.24\n",
      "2021-08-25 10:47:24.914 | INFO     | src.policies:train:109 - Episode 2634\n",
      "2021-08-25 10:47:24.963 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:24.964 | INFO     | src.policies:train:121 - Mean episode return: 135.0\n",
      "2021-08-25 10:47:24.965 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 191.59\n",
      "2021-08-25 10:47:24.966 | WARNING  | src.policies:train:131 - The actual batch size is 290, instead of 200\n",
      "2021-08-25 10:47:24.972 | INFO     | src.policies:train:157 - Total loss: 505.1967468261719\n",
      "2021-08-25 10:47:24.972 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:24.975 | INFO     | src.policies:train:103 - Epoch 619 / 800\n",
      "2021-08-25 10:47:24.976 | INFO     | src.policies:train:109 - Episode 2635\n",
      "2021-08-25 10:47:25.050 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:25.051 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:25.053 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 191.93\n",
      "2021-08-25 10:47:25.057 | INFO     | src.policies:train:157 - Total loss: 629.7404174804688\n",
      "2021-08-25 10:47:25.058 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:25.061 | INFO     | src.policies:train:103 - Epoch 620 / 800\n",
      "2021-08-25 10:47:25.062 | INFO     | src.policies:train:109 - Episode 2636\n",
      "2021-08-25 10:47:25.132 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:25.134 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:25.135 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 191.93\n",
      "2021-08-25 10:47:25.139 | INFO     | src.policies:train:157 - Total loss: 648.3284912109375\n",
      "2021-08-25 10:47:25.140 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:25.144 | INFO     | src.policies:train:103 - Epoch 621 / 800\n",
      "2021-08-25 10:47:25.144 | INFO     | src.policies:train:109 - Episode 2637\n",
      "2021-08-25 10:47:25.217 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:25.218 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:25.219 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 191.93\n",
      "2021-08-25 10:47:25.224 | INFO     | src.policies:train:157 - Total loss: 624.579833984375\n",
      "2021-08-25 10:47:25.225 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:25.228 | INFO     | src.policies:train:103 - Epoch 622 / 800\n",
      "2021-08-25 10:47:25.229 | INFO     | src.policies:train:109 - Episode 2638\n",
      "2021-08-25 10:47:25.301 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:25.302 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:25.303 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 191.93\n",
      "2021-08-25 10:47:25.309 | INFO     | src.policies:train:157 - Total loss: 632.6221313476562\n",
      "2021-08-25 10:47:25.309 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:25.313 | INFO     | src.policies:train:103 - Epoch 623 / 800\n",
      "2021-08-25 10:47:25.313 | INFO     | src.policies:train:109 - Episode 2639\n",
      "2021-08-25 10:47:25.384 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:25.385 | INFO     | src.policies:train:121 - Mean episode return: 197.0\n",
      "2021-08-25 10:47:25.386 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 192.2\n",
      "2021-08-25 10:47:25.387 | INFO     | src.policies:train:109 - Episode 2640\n",
      "2021-08-25 10:47:25.459 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:25.460 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:25.461 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 192.2\n",
      "2021-08-25 10:47:25.462 | WARNING  | src.policies:train:131 - The actual batch size is 397, instead of 200\n",
      "2021-08-25 10:47:25.468 | INFO     | src.policies:train:157 - Total loss: 644.7327880859375\n",
      "2021-08-25 10:47:25.469 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:25.472 | INFO     | src.policies:train:103 - Epoch 624 / 800\n",
      "2021-08-25 10:47:25.473 | INFO     | src.policies:train:109 - Episode 2641\n",
      "2021-08-25 10:47:25.543 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:25.544 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:25.545 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 192.9\n",
      "2021-08-25 10:47:25.550 | INFO     | src.policies:train:157 - Total loss: 611.8286743164062\n",
      "2021-08-25 10:47:25.551 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:25.554 | INFO     | src.policies:train:103 - Epoch 625 / 800\n",
      "2021-08-25 10:47:25.555 | INFO     | src.policies:train:109 - Episode 2642\n",
      "2021-08-25 10:47:25.626 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:25.628 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:25.629 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 193.96\n",
      "2021-08-25 10:47:25.633 | INFO     | src.policies:train:157 - Total loss: 648.6954345703125\n",
      "2021-08-25 10:47:25.634 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:25.637 | INFO     | src.policies:train:103 - Epoch 626 / 800\n",
      "2021-08-25 10:47:25.637 | INFO     | src.policies:train:109 - Episode 2643\n",
      "2021-08-25 10:47:25.706 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:25.708 | INFO     | src.policies:train:121 - Mean episode return: 197.0\n",
      "2021-08-25 10:47:25.709 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 193.93\n",
      "2021-08-25 10:47:25.709 | INFO     | src.policies:train:109 - Episode 2644\n",
      "2021-08-25 10:47:25.773 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:47:25.775 | INFO     | src.policies:train:121 - Mean episode return: 176.0\n",
      "2021-08-25 10:47:25.775 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 193.69\n",
      "2021-08-25 10:47:25.776 | WARNING  | src.policies:train:131 - The actual batch size is 373, instead of 200\n",
      "2021-08-25 10:47:25.783 | INFO     | src.policies:train:157 - Total loss: 599.33837890625\n",
      "2021-08-25 10:47:25.784 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:25.786 | INFO     | src.policies:train:103 - Epoch 627 / 800\n",
      "2021-08-25 10:47:25.788 | INFO     | src.policies:train:109 - Episode 2645\n",
      "2021-08-25 10:47:25.835 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:25.837 | INFO     | src.policies:train:121 - Mean episode return: 132.0\n",
      "2021-08-25 10:47:25.838 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 193.01\n",
      "2021-08-25 10:47:25.839 | INFO     | src.policies:train:109 - Episode 2646\n",
      "2021-08-25 10:47:25.904 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:25.906 | INFO     | src.policies:train:121 - Mean episode return: 186.0\n",
      "2021-08-25 10:47:25.906 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 192.87\n",
      "2021-08-25 10:47:25.908 | WARNING  | src.policies:train:131 - The actual batch size is 318, instead of 200\n",
      "2021-08-25 10:47:25.913 | INFO     | src.policies:train:157 - Total loss: 549.478759765625\n",
      "2021-08-25 10:47:25.914 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:25.917 | INFO     | src.policies:train:103 - Epoch 628 / 800\n",
      "2021-08-25 10:47:25.918 | INFO     | src.policies:train:109 - Episode 2647\n",
      "2021-08-25 10:47:25.964 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:25.966 | INFO     | src.policies:train:121 - Mean episode return: 131.0\n",
      "2021-08-25 10:47:25.967 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 192.18\n",
      "2021-08-25 10:47:25.967 | INFO     | src.policies:train:109 - Episode 2648\n",
      "2021-08-25 10:47:26.037 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:26.039 | INFO     | src.policies:train:121 - Mean episode return: 190.0\n",
      "2021-08-25 10:47:26.039 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 192.08\n",
      "2021-08-25 10:47:26.040 | WARNING  | src.policies:train:131 - The actual batch size is 321, instead of 200\n",
      "2021-08-25 10:47:26.047 | INFO     | src.policies:train:157 - Total loss: 535.4248657226562\n",
      "2021-08-25 10:47:26.047 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:26.051 | INFO     | src.policies:train:103 - Epoch 629 / 800\n",
      "2021-08-25 10:47:26.052 | INFO     | src.policies:train:109 - Episode 2649\n",
      "2021-08-25 10:47:26.118 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:26.120 | INFO     | src.policies:train:121 - Mean episode return: 187.0\n",
      "2021-08-25 10:47:26.121 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 191.95\n",
      "2021-08-25 10:47:26.121 | INFO     | src.policies:train:109 - Episode 2650\n",
      "2021-08-25 10:47:26.154 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:26.155 | INFO     | src.policies:train:121 - Mean episode return: 88.0\n",
      "2021-08-25 10:47:26.156 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 190.83\n",
      "2021-08-25 10:47:26.157 | WARNING  | src.policies:train:131 - The actual batch size is 275, instead of 200\n",
      "2021-08-25 10:47:26.163 | INFO     | src.policies:train:157 - Total loss: 488.296630859375\n",
      "2021-08-25 10:47:26.164 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:26.167 | INFO     | src.policies:train:103 - Epoch 630 / 800\n",
      "2021-08-25 10:47:26.168 | INFO     | src.policies:train:109 - Episode 2651\n",
      "2021-08-25 10:47:26.228 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:26.229 | INFO     | src.policies:train:121 - Mean episode return: 169.0\n",
      "2021-08-25 10:47:26.230 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 190.52\n",
      "2021-08-25 10:47:26.230 | INFO     | src.policies:train:109 - Episode 2652\n",
      "2021-08-25 10:47:26.295 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:26.296 | INFO     | src.policies:train:121 - Mean episode return: 178.0\n",
      "2021-08-25 10:47:26.297 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 190.3\n",
      "2021-08-25 10:47:26.298 | WARNING  | src.policies:train:131 - The actual batch size is 347, instead of 200\n",
      "2021-08-25 10:47:26.304 | INFO     | src.policies:train:157 - Total loss: 545.24462890625\n",
      "2021-08-25 10:47:26.305 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:26.308 | INFO     | src.policies:train:103 - Epoch 631 / 800\n",
      "2021-08-25 10:47:26.309 | INFO     | src.policies:train:109 - Episode 2653\n",
      "2021-08-25 10:47:26.367 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:26.368 | INFO     | src.policies:train:121 - Mean episode return: 163.0\n",
      "2021-08-25 10:47:26.369 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 189.93\n",
      "2021-08-25 10:47:26.370 | INFO     | src.policies:train:109 - Episode 2654\n",
      "2021-08-25 10:47:26.431 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:26.432 | INFO     | src.policies:train:121 - Mean episode return: 168.0\n",
      "2021-08-25 10:47:26.433 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 189.61\n",
      "2021-08-25 10:47:26.434 | WARNING  | src.policies:train:131 - The actual batch size is 331, instead of 200\n",
      "2021-08-25 10:47:26.440 | INFO     | src.policies:train:157 - Total loss: 521.4157104492188\n",
      "2021-08-25 10:47:26.441 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:26.444 | INFO     | src.policies:train:103 - Epoch 632 / 800\n",
      "2021-08-25 10:47:26.445 | INFO     | src.policies:train:109 - Episode 2655\n",
      "2021-08-25 10:47:26.513 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:26.515 | INFO     | src.policies:train:121 - Mean episode return: 189.0\n",
      "2021-08-25 10:47:26.515 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 189.5\n",
      "2021-08-25 10:47:26.516 | INFO     | src.policies:train:109 - Episode 2656\n",
      "2021-08-25 10:47:26.575 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:26.577 | INFO     | src.policies:train:121 - Mean episode return: 167.0\n",
      "2021-08-25 10:47:26.578 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 189.17\n",
      "2021-08-25 10:47:26.578 | WARNING  | src.policies:train:131 - The actual batch size is 356, instead of 200\n",
      "2021-08-25 10:47:26.584 | INFO     | src.policies:train:157 - Total loss: 549.6259155273438\n",
      "2021-08-25 10:47:26.585 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:26.588 | INFO     | src.policies:train:103 - Epoch 633 / 800\n",
      "2021-08-25 10:47:26.589 | INFO     | src.policies:train:109 - Episode 2657\n",
      "2021-08-25 10:47:26.631 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:26.633 | INFO     | src.policies:train:121 - Mean episode return: 121.0\n",
      "2021-08-25 10:47:26.634 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 188.38\n",
      "2021-08-25 10:47:26.635 | INFO     | src.policies:train:109 - Episode 2658\n",
      "2021-08-25 10:47:26.651 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:26.652 | INFO     | src.policies:train:121 - Mean episode return: 38.0\n",
      "2021-08-25 10:47:26.653 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 186.76\n",
      "2021-08-25 10:47:26.654 | INFO     | src.policies:train:109 - Episode 2659\n",
      "2021-08-25 10:47:26.718 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:26.719 | INFO     | src.policies:train:121 - Mean episode return: 172.0\n",
      "2021-08-25 10:47:26.720 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 186.48\n",
      "2021-08-25 10:47:26.721 | WARNING  | src.policies:train:131 - The actual batch size is 331, instead of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:47:26.727 | INFO     | src.policies:train:157 - Total loss: 455.884521484375\n",
      "2021-08-25 10:47:26.728 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:26.731 | INFO     | src.policies:train:103 - Epoch 634 / 800\n",
      "2021-08-25 10:47:26.732 | INFO     | src.policies:train:109 - Episode 2660\n",
      "2021-08-25 10:47:26.790 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:26.792 | INFO     | src.policies:train:121 - Mean episode return: 166.0\n",
      "2021-08-25 10:47:26.793 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 186.14\n",
      "2021-08-25 10:47:26.794 | INFO     | src.policies:train:109 - Episode 2661\n",
      "2021-08-25 10:47:26.857 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:26.858 | INFO     | src.policies:train:121 - Mean episode return: 177.0\n",
      "2021-08-25 10:47:26.859 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 185.91\n",
      "2021-08-25 10:47:26.860 | WARNING  | src.policies:train:131 - The actual batch size is 343, instead of 200\n",
      "2021-08-25 10:47:26.866 | INFO     | src.policies:train:157 - Total loss: 521.2453002929688\n",
      "2021-08-25 10:47:26.867 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:26.870 | INFO     | src.policies:train:103 - Epoch 635 / 800\n",
      "2021-08-25 10:47:26.871 | INFO     | src.policies:train:109 - Episode 2662\n",
      "2021-08-25 10:47:26.925 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:26.926 | INFO     | src.policies:train:121 - Mean episode return: 153.0\n",
      "2021-08-25 10:47:26.927 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 185.44\n",
      "2021-08-25 10:47:26.928 | INFO     | src.policies:train:109 - Episode 2663\n",
      "2021-08-25 10:47:26.978 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:26.979 | INFO     | src.policies:train:121 - Mean episode return: 141.0\n",
      "2021-08-25 10:47:26.980 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 184.85\n",
      "2021-08-25 10:47:26.981 | WARNING  | src.policies:train:131 - The actual batch size is 294, instead of 200\n",
      "2021-08-25 10:47:26.987 | INFO     | src.policies:train:157 - Total loss: 453.43145751953125\n",
      "2021-08-25 10:47:26.988 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:26.991 | INFO     | src.policies:train:103 - Epoch 636 / 800\n",
      "2021-08-25 10:47:26.992 | INFO     | src.policies:train:109 - Episode 2664\n",
      "2021-08-25 10:47:27.051 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:27.052 | INFO     | src.policies:train:121 - Mean episode return: 165.0\n",
      "2021-08-25 10:47:27.053 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 184.5\n",
      "2021-08-25 10:47:27.054 | INFO     | src.policies:train:109 - Episode 2665\n",
      "2021-08-25 10:47:27.106 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:27.108 | INFO     | src.policies:train:121 - Mean episode return: 143.0\n",
      "2021-08-25 10:47:27.109 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 183.93\n",
      "2021-08-25 10:47:27.110 | WARNING  | src.policies:train:131 - The actual batch size is 308, instead of 200\n",
      "2021-08-25 10:47:27.115 | INFO     | src.policies:train:157 - Total loss: 474.51898193359375\n",
      "2021-08-25 10:47:27.116 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:27.119 | INFO     | src.policies:train:103 - Epoch 637 / 800\n",
      "2021-08-25 10:47:27.120 | INFO     | src.policies:train:109 - Episode 2666\n",
      "2021-08-25 10:47:27.175 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:27.177 | INFO     | src.policies:train:121 - Mean episode return: 157.0\n",
      "2021-08-25 10:47:27.177 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 183.5\n",
      "2021-08-25 10:47:27.178 | INFO     | src.policies:train:109 - Episode 2667\n",
      "2021-08-25 10:47:27.233 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:27.235 | INFO     | src.policies:train:121 - Mean episode return: 146.0\n",
      "2021-08-25 10:47:27.236 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.96\n",
      "2021-08-25 10:47:27.236 | WARNING  | src.policies:train:131 - The actual batch size is 303, instead of 200\n",
      "2021-08-25 10:47:27.242 | INFO     | src.policies:train:157 - Total loss: 466.82861328125\n",
      "2021-08-25 10:47:27.243 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:27.246 | INFO     | src.policies:train:103 - Epoch 638 / 800\n",
      "2021-08-25 10:47:27.248 | INFO     | src.policies:train:109 - Episode 2668\n",
      "2021-08-25 10:47:27.300 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:27.301 | INFO     | src.policies:train:121 - Mean episode return: 147.0\n",
      "2021-08-25 10:47:27.302 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.43\n",
      "2021-08-25 10:47:27.303 | INFO     | src.policies:train:109 - Episode 2669\n",
      "2021-08-25 10:47:27.318 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:27.319 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 10:47:27.320 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 180.74\n",
      "2021-08-25 10:47:27.321 | INFO     | src.policies:train:109 - Episode 2670\n",
      "2021-08-25 10:47:27.380 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:27.382 | INFO     | src.policies:train:121 - Mean episode return: 168.0\n",
      "2021-08-25 10:47:27.383 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.4\n",
      "2021-08-25 10:47:27.383 | WARNING  | src.policies:train:131 - The actual batch size is 346, instead of 200\n",
      "2021-08-25 10:47:27.389 | INFO     | src.policies:train:157 - Total loss: 463.3442687988281\n",
      "2021-08-25 10:47:27.390 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:27.393 | INFO     | src.policies:train:103 - Epoch 639 / 800\n",
      "2021-08-25 10:47:27.394 | INFO     | src.policies:train:109 - Episode 2671\n",
      "2021-08-25 10:47:27.449 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:27.451 | INFO     | src.policies:train:121 - Mean episode return: 147.0\n",
      "2021-08-25 10:47:27.452 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 180.87\n",
      "2021-08-25 10:47:27.452 | INFO     | src.policies:train:109 - Episode 2672\n",
      "2021-08-25 10:47:27.506 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:27.507 | INFO     | src.policies:train:121 - Mean episode return: 149.0\n",
      "2021-08-25 10:47:27.508 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 180.36\n",
      "2021-08-25 10:47:27.509 | WARNING  | src.policies:train:131 - The actual batch size is 296, instead of 200\n",
      "2021-08-25 10:47:27.515 | INFO     | src.policies:train:157 - Total loss: 455.03033447265625\n",
      "2021-08-25 10:47:27.516 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:27.518 | INFO     | src.policies:train:103 - Epoch 640 / 800\n",
      "2021-08-25 10:47:27.519 | INFO     | src.policies:train:109 - Episode 2673\n",
      "2021-08-25 10:47:27.579 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:27.580 | INFO     | src.policies:train:121 - Mean episode return: 166.0\n",
      "2021-08-25 10:47:27.582 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 180.02\n",
      "2021-08-25 10:47:27.582 | INFO     | src.policies:train:109 - Episode 2674\n",
      "2021-08-25 10:47:27.630 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:27.631 | INFO     | src.policies:train:121 - Mean episode return: 119.0\n",
      "2021-08-25 10:47:27.632 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 179.21\n",
      "2021-08-25 10:47:27.633 | WARNING  | src.policies:train:131 - The actual batch size is 285, instead of 200\n",
      "2021-08-25 10:47:27.639 | INFO     | src.policies:train:157 - Total loss: 437.99114990234375\n",
      "2021-08-25 10:47:27.640 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:27.643 | INFO     | src.policies:train:103 - Epoch 641 / 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:47:27.644 | INFO     | src.policies:train:109 - Episode 2675\n",
      "2021-08-25 10:47:27.694 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:27.695 | INFO     | src.policies:train:121 - Mean episode return: 137.0\n",
      "2021-08-25 10:47:27.696 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 178.58\n",
      "2021-08-25 10:47:27.697 | INFO     | src.policies:train:109 - Episode 2676\n",
      "2021-08-25 10:47:27.759 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:27.760 | INFO     | src.policies:train:121 - Mean episode return: 169.0\n",
      "2021-08-25 10:47:27.761 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 178.27\n",
      "2021-08-25 10:47:27.762 | WARNING  | src.policies:train:131 - The actual batch size is 306, instead of 200\n",
      "2021-08-25 10:47:27.768 | INFO     | src.policies:train:157 - Total loss: 442.4185485839844\n",
      "2021-08-25 10:47:27.769 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:27.772 | INFO     | src.policies:train:103 - Epoch 642 / 800\n",
      "2021-08-25 10:47:27.773 | INFO     | src.policies:train:109 - Episode 2677\n",
      "2021-08-25 10:47:27.833 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:27.835 | INFO     | src.policies:train:121 - Mean episode return: 166.0\n",
      "2021-08-25 10:47:27.836 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 177.93\n",
      "2021-08-25 10:47:27.836 | INFO     | src.policies:train:109 - Episode 2678\n",
      "2021-08-25 10:47:27.884 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:27.886 | INFO     | src.policies:train:121 - Mean episode return: 132.0\n",
      "2021-08-25 10:47:27.887 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 177.4\n",
      "2021-08-25 10:47:27.887 | WARNING  | src.policies:train:131 - The actual batch size is 298, instead of 200\n",
      "2021-08-25 10:47:27.893 | INFO     | src.policies:train:157 - Total loss: 421.0392150878906\n",
      "2021-08-25 10:47:27.894 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:27.897 | INFO     | src.policies:train:103 - Epoch 643 / 800\n",
      "2021-08-25 10:47:27.898 | INFO     | src.policies:train:109 - Episode 2679\n",
      "2021-08-25 10:47:27.947 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:27.948 | INFO     | src.policies:train:121 - Mean episode return: 141.0\n",
      "2021-08-25 10:47:27.950 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.81\n",
      "2021-08-25 10:47:27.950 | INFO     | src.policies:train:109 - Episode 2680\n",
      "2021-08-25 10:47:28.008 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:28.009 | INFO     | src.policies:train:121 - Mean episode return: 159.0\n",
      "2021-08-25 10:47:28.010 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.4\n",
      "2021-08-25 10:47:28.011 | WARNING  | src.policies:train:131 - The actual batch size is 300, instead of 200\n",
      "2021-08-25 10:47:28.017 | INFO     | src.policies:train:157 - Total loss: 425.7080993652344\n",
      "2021-08-25 10:47:28.018 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:28.022 | INFO     | src.policies:train:103 - Epoch 644 / 800\n",
      "2021-08-25 10:47:28.023 | INFO     | src.policies:train:109 - Episode 2681\n",
      "2021-08-25 10:47:28.070 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:28.071 | INFO     | src.policies:train:121 - Mean episode return: 127.0\n",
      "2021-08-25 10:47:28.072 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.67\n",
      "2021-08-25 10:47:28.073 | INFO     | src.policies:train:109 - Episode 2682\n",
      "2021-08-25 10:47:28.095 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:28.096 | INFO     | src.policies:train:121 - Mean episode return: 51.0\n",
      "2021-08-25 10:47:28.097 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.18\n",
      "2021-08-25 10:47:28.098 | INFO     | src.policies:train:109 - Episode 2683\n",
      "2021-08-25 10:47:28.130 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:28.131 | INFO     | src.policies:train:121 - Mean episode return: 81.0\n",
      "2021-08-25 10:47:28.132 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.99\n",
      "2021-08-25 10:47:28.133 | WARNING  | src.policies:train:131 - The actual batch size is 259, instead of 200\n",
      "2021-08-25 10:47:28.139 | INFO     | src.policies:train:157 - Total loss: 315.9147644042969\n",
      "2021-08-25 10:47:28.139 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:28.143 | INFO     | src.policies:train:103 - Epoch 645 / 800\n",
      "2021-08-25 10:47:28.144 | INFO     | src.policies:train:109 - Episode 2684\n",
      "2021-08-25 10:47:28.197 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:28.198 | INFO     | src.policies:train:121 - Mean episode return: 142.0\n",
      "2021-08-25 10:47:28.199 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.41\n",
      "2021-08-25 10:47:28.200 | INFO     | src.policies:train:109 - Episode 2685\n",
      "2021-08-25 10:47:28.249 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:28.250 | INFO     | src.policies:train:121 - Mean episode return: 128.0\n",
      "2021-08-25 10:47:28.251 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.25\n",
      "2021-08-25 10:47:28.252 | WARNING  | src.policies:train:131 - The actual batch size is 270, instead of 200\n",
      "2021-08-25 10:47:28.257 | INFO     | src.policies:train:157 - Total loss: 373.65814208984375\n",
      "2021-08-25 10:47:28.258 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:28.261 | INFO     | src.policies:train:103 - Epoch 646 / 800\n",
      "2021-08-25 10:47:28.262 | INFO     | src.policies:train:109 - Episode 2686\n",
      "2021-08-25 10:47:28.307 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:28.308 | INFO     | src.policies:train:121 - Mean episode return: 119.0\n",
      "2021-08-25 10:47:28.309 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 171.44\n",
      "2021-08-25 10:47:28.310 | INFO     | src.policies:train:109 - Episode 2687\n",
      "2021-08-25 10:47:28.366 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:28.367 | INFO     | src.policies:train:121 - Mean episode return: 158.0\n",
      "2021-08-25 10:47:28.368 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 171.02\n",
      "2021-08-25 10:47:28.369 | WARNING  | src.policies:train:131 - The actual batch size is 277, instead of 200\n",
      "2021-08-25 10:47:28.375 | INFO     | src.policies:train:157 - Total loss: 380.5306701660156\n",
      "2021-08-25 10:47:28.376 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:28.378 | INFO     | src.policies:train:103 - Epoch 647 / 800\n",
      "2021-08-25 10:47:28.379 | INFO     | src.policies:train:109 - Episode 2688\n",
      "2021-08-25 10:47:28.396 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:28.397 | INFO     | src.policies:train:121 - Mean episode return: 43.0\n",
      "2021-08-25 10:47:28.398 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 169.45\n",
      "2021-08-25 10:47:28.399 | INFO     | src.policies:train:109 - Episode 2689\n",
      "2021-08-25 10:47:28.452 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:28.454 | INFO     | src.policies:train:121 - Mean episode return: 145.0\n",
      "2021-08-25 10:47:28.455 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 168.9\n",
      "2021-08-25 10:47:28.456 | INFO     | src.policies:train:109 - Episode 2690\n",
      "2021-08-25 10:47:28.498 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:28.499 | INFO     | src.policies:train:121 - Mean episode return: 119.0\n",
      "2021-08-25 10:47:28.500 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 168.09\n",
      "2021-08-25 10:47:28.501 | WARNING  | src.policies:train:131 - The actual batch size is 307, instead of 200\n",
      "2021-08-25 10:47:28.508 | INFO     | src.policies:train:157 - Total loss: 342.03741455078125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:47:28.509 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:28.512 | INFO     | src.policies:train:103 - Epoch 648 / 800\n",
      "2021-08-25 10:47:28.514 | INFO     | src.policies:train:109 - Episode 2691\n",
      "2021-08-25 10:47:28.564 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:28.566 | INFO     | src.policies:train:121 - Mean episode return: 137.0\n",
      "2021-08-25 10:47:28.567 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 167.46\n",
      "2021-08-25 10:47:28.567 | INFO     | src.policies:train:109 - Episode 2692\n",
      "2021-08-25 10:47:28.584 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:28.585 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 10:47:28.586 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 165.83\n",
      "2021-08-25 10:47:28.587 | INFO     | src.policies:train:109 - Episode 2693\n",
      "2021-08-25 10:47:28.633 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:28.634 | INFO     | src.policies:train:121 - Mean episode return: 123.0\n",
      "2021-08-25 10:47:28.635 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 165.06\n",
      "2021-08-25 10:47:28.636 | WARNING  | src.policies:train:131 - The actual batch size is 297, instead of 200\n",
      "2021-08-25 10:47:28.641 | INFO     | src.policies:train:157 - Total loss: 330.823974609375\n",
      "2021-08-25 10:47:28.642 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:28.646 | INFO     | src.policies:train:103 - Epoch 649 / 800\n",
      "2021-08-25 10:47:28.647 | INFO     | src.policies:train:109 - Episode 2694\n",
      "2021-08-25 10:47:28.691 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:28.692 | INFO     | src.policies:train:121 - Mean episode return: 123.0\n",
      "2021-08-25 10:47:28.693 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 164.29\n",
      "2021-08-25 10:47:28.694 | INFO     | src.policies:train:109 - Episode 2695\n",
      "2021-08-25 10:47:28.749 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:28.750 | INFO     | src.policies:train:121 - Mean episode return: 140.0\n",
      "2021-08-25 10:47:28.751 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 163.69\n",
      "2021-08-25 10:47:28.752 | WARNING  | src.policies:train:131 - The actual batch size is 263, instead of 200\n",
      "2021-08-25 10:47:28.757 | INFO     | src.policies:train:157 - Total loss: 335.1615905761719\n",
      "2021-08-25 10:47:28.758 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:28.762 | INFO     | src.policies:train:103 - Epoch 650 / 800\n",
      "2021-08-25 10:47:28.763 | INFO     | src.policies:train:109 - Episode 2696\n",
      "2021-08-25 10:47:28.777 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:28.779 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 10:47:28.780 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 162.03\n",
      "2021-08-25 10:47:28.780 | INFO     | src.policies:train:109 - Episode 2697\n",
      "2021-08-25 10:47:28.831 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:28.832 | INFO     | src.policies:train:121 - Mean episode return: 133.0\n",
      "2021-08-25 10:47:28.833 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 161.36\n",
      "2021-08-25 10:47:28.834 | INFO     | src.policies:train:109 - Episode 2698\n",
      "2021-08-25 10:47:28.883 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:28.884 | INFO     | src.policies:train:121 - Mean episode return: 130.0\n",
      "2021-08-25 10:47:28.885 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 160.66\n",
      "2021-08-25 10:47:28.886 | WARNING  | src.policies:train:131 - The actual batch size is 297, instead of 200\n",
      "2021-08-25 10:47:28.892 | INFO     | src.policies:train:157 - Total loss: 333.6977844238281\n",
      "2021-08-25 10:47:28.893 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:28.896 | INFO     | src.policies:train:103 - Epoch 651 / 800\n",
      "2021-08-25 10:47:28.897 | INFO     | src.policies:train:109 - Episode 2699\n",
      "2021-08-25 10:47:28.940 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:28.941 | INFO     | src.policies:train:121 - Mean episode return: 123.0\n",
      "2021-08-25 10:47:28.942 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 159.89\n",
      "2021-08-25 10:47:28.943 | INFO     | src.policies:train:109 - Episode 2700\n",
      "2021-08-25 10:47:28.995 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:28.996 | INFO     | src.policies:train:121 - Mean episode return: 123.0\n",
      "2021-08-25 10:47:28.997 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 159.12\n",
      "2021-08-25 10:47:28.998 | WARNING  | src.policies:train:131 - The actual batch size is 246, instead of 200\n",
      "2021-08-25 10:47:29.006 | INFO     | src.policies:train:157 - Total loss: 308.2272644042969\n",
      "2021-08-25 10:47:29.007 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:29.011 | INFO     | src.policies:train:103 - Epoch 652 / 800\n",
      "2021-08-25 10:47:29.013 | INFO     | src.policies:train:109 - Episode 2701\n",
      "2021-08-25 10:47:29.061 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:29.063 | INFO     | src.policies:train:121 - Mean episode return: 124.0\n",
      "2021-08-25 10:47:29.064 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 158.36\n",
      "2021-08-25 10:47:29.066 | INFO     | src.policies:train:109 - Episode 2702\n",
      "2021-08-25 10:47:29.118 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:29.119 | INFO     | src.policies:train:121 - Mean episode return: 128.0\n",
      "2021-08-25 10:47:29.121 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 157.64\n",
      "2021-08-25 10:47:29.122 | WARNING  | src.policies:train:131 - The actual batch size is 252, instead of 200\n",
      "2021-08-25 10:47:29.130 | INFO     | src.policies:train:157 - Total loss: 310.4293212890625\n",
      "2021-08-25 10:47:29.131 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:29.134 | INFO     | src.policies:train:103 - Epoch 653 / 800\n",
      "2021-08-25 10:47:29.135 | INFO     | src.policies:train:109 - Episode 2703\n",
      "2021-08-25 10:47:29.184 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:29.185 | INFO     | src.policies:train:121 - Mean episode return: 135.0\n",
      "2021-08-25 10:47:29.186 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 156.99\n",
      "2021-08-25 10:47:29.187 | INFO     | src.policies:train:109 - Episode 2704\n",
      "2021-08-25 10:47:29.233 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:29.234 | INFO     | src.policies:train:121 - Mean episode return: 117.0\n",
      "2021-08-25 10:47:29.235 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 156.16\n",
      "2021-08-25 10:47:29.236 | WARNING  | src.policies:train:131 - The actual batch size is 252, instead of 200\n",
      "2021-08-25 10:47:29.241 | INFO     | src.policies:train:157 - Total loss: 310.60479736328125\n",
      "2021-08-25 10:47:29.242 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:29.245 | INFO     | src.policies:train:103 - Epoch 654 / 800\n",
      "2021-08-25 10:47:29.246 | INFO     | src.policies:train:109 - Episode 2705\n",
      "2021-08-25 10:47:29.293 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:29.295 | INFO     | src.policies:train:121 - Mean episode return: 128.0\n",
      "2021-08-25 10:47:29.296 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 155.44\n",
      "2021-08-25 10:47:29.296 | INFO     | src.policies:train:109 - Episode 2706\n",
      "2021-08-25 10:47:29.339 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:29.340 | INFO     | src.policies:train:121 - Mean episode return: 111.0\n",
      "2021-08-25 10:47:29.341 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 154.55\n",
      "2021-08-25 10:47:29.342 | WARNING  | src.policies:train:131 - The actual batch size is 239, instead of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:47:29.347 | INFO     | src.policies:train:157 - Total loss: 294.1414794921875\n",
      "2021-08-25 10:47:29.348 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:29.351 | INFO     | src.policies:train:103 - Epoch 655 / 800\n",
      "2021-08-25 10:47:29.352 | INFO     | src.policies:train:109 - Episode 2707\n",
      "2021-08-25 10:47:29.405 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:29.406 | INFO     | src.policies:train:121 - Mean episode return: 147.0\n",
      "2021-08-25 10:47:29.407 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 154.02\n",
      "2021-08-25 10:47:29.408 | INFO     | src.policies:train:109 - Episode 2708\n",
      "2021-08-25 10:47:29.462 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:29.463 | INFO     | src.policies:train:121 - Mean episode return: 148.0\n",
      "2021-08-25 10:47:29.464 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 153.5\n",
      "2021-08-25 10:47:29.465 | WARNING  | src.policies:train:131 - The actual batch size is 295, instead of 200\n",
      "2021-08-25 10:47:29.471 | INFO     | src.policies:train:157 - Total loss: 361.0817565917969\n",
      "2021-08-25 10:47:29.471 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:29.474 | INFO     | src.policies:train:103 - Epoch 656 / 800\n",
      "2021-08-25 10:47:29.475 | INFO     | src.policies:train:109 - Episode 2709\n",
      "2021-08-25 10:47:29.519 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:29.521 | INFO     | src.policies:train:121 - Mean episode return: 123.0\n",
      "2021-08-25 10:47:29.522 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 152.83\n",
      "2021-08-25 10:47:29.523 | INFO     | src.policies:train:109 - Episode 2710\n",
      "2021-08-25 10:47:29.576 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:29.577 | INFO     | src.policies:train:121 - Mean episode return: 141.0\n",
      "2021-08-25 10:47:29.578 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 152.24\n",
      "2021-08-25 10:47:29.579 | WARNING  | src.policies:train:131 - The actual batch size is 264, instead of 200\n",
      "2021-08-25 10:47:29.585 | INFO     | src.policies:train:157 - Total loss: 314.4915466308594\n",
      "2021-08-25 10:47:29.585 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:29.589 | INFO     | src.policies:train:103 - Epoch 657 / 800\n",
      "2021-08-25 10:47:29.590 | INFO     | src.policies:train:109 - Episode 2711\n",
      "2021-08-25 10:47:29.640 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:29.641 | INFO     | src.policies:train:121 - Mean episode return: 140.0\n",
      "2021-08-25 10:47:29.642 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 151.64\n",
      "2021-08-25 10:47:29.643 | INFO     | src.policies:train:109 - Episode 2712\n",
      "2021-08-25 10:47:29.700 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:29.701 | INFO     | src.policies:train:121 - Mean episode return: 153.0\n",
      "2021-08-25 10:47:29.702 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 151.17\n",
      "2021-08-25 10:47:29.703 | WARNING  | src.policies:train:131 - The actual batch size is 293, instead of 200\n",
      "2021-08-25 10:47:29.709 | INFO     | src.policies:train:157 - Total loss: 342.7215881347656\n",
      "2021-08-25 10:47:29.710 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:29.713 | INFO     | src.policies:train:103 - Epoch 658 / 800\n",
      "2021-08-25 10:47:29.714 | INFO     | src.policies:train:109 - Episode 2713\n",
      "2021-08-25 10:47:29.767 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:29.768 | INFO     | src.policies:train:121 - Mean episode return: 149.0\n",
      "2021-08-25 10:47:29.769 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 150.66\n",
      "2021-08-25 10:47:29.770 | INFO     | src.policies:train:109 - Episode 2714\n",
      "2021-08-25 10:47:29.822 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:29.823 | INFO     | src.policies:train:121 - Mean episode return: 142.0\n",
      "2021-08-25 10:47:29.824 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 151.56\n",
      "2021-08-25 10:47:29.825 | WARNING  | src.policies:train:131 - The actual batch size is 291, instead of 200\n",
      "2021-08-25 10:47:29.831 | INFO     | src.policies:train:157 - Total loss: 351.61138916015625\n",
      "2021-08-25 10:47:29.831 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:29.834 | INFO     | src.policies:train:103 - Epoch 659 / 800\n",
      "2021-08-25 10:47:29.835 | INFO     | src.policies:train:109 - Episode 2715\n",
      "2021-08-25 10:47:29.846 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:29.847 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 10:47:29.848 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 149.78\n",
      "2021-08-25 10:47:29.849 | INFO     | src.policies:train:109 - Episode 2716\n",
      "2021-08-25 10:47:29.903 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:29.905 | INFO     | src.policies:train:121 - Mean episode return: 149.0\n",
      "2021-08-25 10:47:29.905 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 149.27\n",
      "2021-08-25 10:47:29.907 | INFO     | src.policies:train:109 - Episode 2717\n",
      "2021-08-25 10:47:29.959 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:29.960 | INFO     | src.policies:train:121 - Mean episode return: 140.0\n",
      "2021-08-25 10:47:29.961 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 148.67\n",
      "2021-08-25 10:47:29.962 | WARNING  | src.policies:train:131 - The actual batch size is 311, instead of 200\n",
      "2021-08-25 10:47:29.968 | INFO     | src.policies:train:157 - Total loss: 351.3590087890625\n",
      "2021-08-25 10:47:29.969 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:29.972 | INFO     | src.policies:train:103 - Epoch 660 / 800\n",
      "2021-08-25 10:47:29.973 | INFO     | src.policies:train:109 - Episode 2718\n",
      "2021-08-25 10:47:30.028 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:30.029 | INFO     | src.policies:train:121 - Mean episode return: 158.0\n",
      "2021-08-25 10:47:30.031 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 148.25\n",
      "2021-08-25 10:47:30.032 | INFO     | src.policies:train:109 - Episode 2719\n",
      "2021-08-25 10:47:30.080 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:30.081 | INFO     | src.policies:train:121 - Mean episode return: 132.0\n",
      "2021-08-25 10:47:30.082 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 147.57\n",
      "2021-08-25 10:47:30.083 | WARNING  | src.policies:train:131 - The actual batch size is 290, instead of 200\n",
      "2021-08-25 10:47:30.089 | INFO     | src.policies:train:157 - Total loss: 353.23004150390625\n",
      "2021-08-25 10:47:30.090 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:30.093 | INFO     | src.policies:train:103 - Epoch 661 / 800\n",
      "2021-08-25 10:47:30.094 | INFO     | src.policies:train:109 - Episode 2720\n",
      "2021-08-25 10:47:30.149 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:30.150 | INFO     | src.policies:train:121 - Mean episode return: 150.0\n",
      "2021-08-25 10:47:30.151 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 147.07\n",
      "2021-08-25 10:47:30.152 | INFO     | src.policies:train:109 - Episode 2721\n",
      "2021-08-25 10:47:30.224 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:30.225 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:30.225 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 147.07\n",
      "2021-08-25 10:47:30.226 | WARNING  | src.policies:train:131 - The actual batch size is 350, instead of 200\n",
      "2021-08-25 10:47:30.232 | INFO     | src.policies:train:157 - Total loss: 409.36541748046875\n",
      "2021-08-25 10:47:30.233 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:30.236 | INFO     | src.policies:train:103 - Epoch 662 / 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:47:30.237 | INFO     | src.policies:train:109 - Episode 2722\n",
      "2021-08-25 10:47:30.307 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:30.309 | INFO     | src.policies:train:121 - Mean episode return: 195.0\n",
      "2021-08-25 10:47:30.310 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 147.02\n",
      "2021-08-25 10:47:30.311 | INFO     | src.policies:train:109 - Episode 2723\n",
      "2021-08-25 10:47:30.365 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:30.367 | INFO     | src.policies:train:121 - Mean episode return: 152.0\n",
      "2021-08-25 10:47:30.367 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 146.54\n",
      "2021-08-25 10:47:30.368 | WARNING  | src.policies:train:131 - The actual batch size is 347, instead of 200\n",
      "2021-08-25 10:47:30.374 | INFO     | src.policies:train:157 - Total loss: 388.5416259765625\n",
      "2021-08-25 10:47:30.375 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:30.378 | INFO     | src.policies:train:103 - Epoch 663 / 800\n",
      "2021-08-25 10:47:30.379 | INFO     | src.policies:train:109 - Episode 2724\n",
      "2021-08-25 10:47:30.443 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:30.445 | INFO     | src.policies:train:121 - Mean episode return: 174.0\n",
      "2021-08-25 10:47:30.446 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 146.28\n",
      "2021-08-25 10:47:30.446 | INFO     | src.policies:train:109 - Episode 2725\n",
      "2021-08-25 10:47:30.507 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:30.508 | INFO     | src.policies:train:121 - Mean episode return: 163.0\n",
      "2021-08-25 10:47:30.509 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 145.91\n",
      "2021-08-25 10:47:30.510 | WARNING  | src.policies:train:131 - The actual batch size is 337, instead of 200\n",
      "2021-08-25 10:47:30.516 | INFO     | src.policies:train:157 - Total loss: 360.1279602050781\n",
      "2021-08-25 10:47:30.516 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:30.520 | INFO     | src.policies:train:103 - Epoch 664 / 800\n",
      "2021-08-25 10:47:30.521 | INFO     | src.policies:train:109 - Episode 2726\n",
      "2021-08-25 10:47:30.579 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:30.580 | INFO     | src.policies:train:121 - Mean episode return: 162.0\n",
      "2021-08-25 10:47:30.581 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 145.53\n",
      "2021-08-25 10:47:30.582 | INFO     | src.policies:train:109 - Episode 2727\n",
      "2021-08-25 10:47:30.600 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:30.601 | INFO     | src.policies:train:121 - Mean episode return: 38.0\n",
      "2021-08-25 10:47:30.602 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 143.91\n",
      "2021-08-25 10:47:30.607 | INFO     | src.policies:train:157 - Total loss: 341.0365295410156\n",
      "2021-08-25 10:47:30.608 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:30.611 | INFO     | src.policies:train:103 - Epoch 665 / 800\n",
      "2021-08-25 10:47:30.612 | INFO     | src.policies:train:109 - Episode 2728\n",
      "2021-08-25 10:47:30.673 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:30.675 | INFO     | src.policies:train:121 - Mean episode return: 173.0\n",
      "2021-08-25 10:47:30.675 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 144.15\n",
      "2021-08-25 10:47:30.676 | INFO     | src.policies:train:109 - Episode 2729\n",
      "2021-08-25 10:47:30.728 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:30.729 | INFO     | src.policies:train:121 - Mean episode return: 132.0\n",
      "2021-08-25 10:47:30.730 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 144.23\n",
      "2021-08-25 10:47:30.731 | WARNING  | src.policies:train:131 - The actual batch size is 305, instead of 200\n",
      "2021-08-25 10:47:30.737 | INFO     | src.policies:train:157 - Total loss: 350.0248718261719\n",
      "2021-08-25 10:47:30.738 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:30.741 | INFO     | src.policies:train:103 - Epoch 666 / 800\n",
      "2021-08-25 10:47:30.742 | INFO     | src.policies:train:109 - Episode 2730\n",
      "2021-08-25 10:47:30.807 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:30.808 | INFO     | src.policies:train:121 - Mean episode return: 176.0\n",
      "2021-08-25 10:47:30.809 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 144.36\n",
      "2021-08-25 10:47:30.810 | INFO     | src.policies:train:109 - Episode 2731\n",
      "2021-08-25 10:47:30.872 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:30.873 | INFO     | src.policies:train:121 - Mean episode return: 175.0\n",
      "2021-08-25 10:47:30.874 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 144.11\n",
      "2021-08-25 10:47:30.875 | WARNING  | src.policies:train:131 - The actual batch size is 351, instead of 200\n",
      "2021-08-25 10:47:30.881 | INFO     | src.policies:train:157 - Total loss: 358.3802795410156\n",
      "2021-08-25 10:47:30.881 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:30.885 | INFO     | src.policies:train:103 - Epoch 667 / 800\n",
      "2021-08-25 10:47:30.886 | INFO     | src.policies:train:109 - Episode 2732\n",
      "2021-08-25 10:47:30.942 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:30.943 | INFO     | src.policies:train:121 - Mean episode return: 158.0\n",
      "2021-08-25 10:47:30.944 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 143.69\n",
      "2021-08-25 10:47:30.945 | INFO     | src.policies:train:109 - Episode 2733\n",
      "2021-08-25 10:47:31.006 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:31.007 | INFO     | src.policies:train:121 - Mean episode return: 167.0\n",
      "2021-08-25 10:47:31.008 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 143.81\n",
      "2021-08-25 10:47:31.009 | WARNING  | src.policies:train:131 - The actual batch size is 325, instead of 200\n",
      "2021-08-25 10:47:31.015 | INFO     | src.policies:train:157 - Total loss: 329.34539794921875\n",
      "2021-08-25 10:47:31.016 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:31.019 | INFO     | src.policies:train:103 - Epoch 668 / 800\n",
      "2021-08-25 10:47:31.020 | INFO     | src.policies:train:109 - Episode 2734\n",
      "2021-08-25 10:47:31.078 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:31.080 | INFO     | src.policies:train:121 - Mean episode return: 165.0\n",
      "2021-08-25 10:47:31.081 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 144.11\n",
      "2021-08-25 10:47:31.081 | INFO     | src.policies:train:109 - Episode 2735\n",
      "2021-08-25 10:47:31.137 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:31.138 | INFO     | src.policies:train:121 - Mean episode return: 155.0\n",
      "2021-08-25 10:47:31.139 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 143.66\n",
      "2021-08-25 10:47:31.140 | WARNING  | src.policies:train:131 - The actual batch size is 320, instead of 200\n",
      "2021-08-25 10:47:31.146 | INFO     | src.policies:train:157 - Total loss: 317.4243469238281\n",
      "2021-08-25 10:47:31.147 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:31.150 | INFO     | src.policies:train:103 - Epoch 669 / 800\n",
      "2021-08-25 10:47:31.151 | INFO     | src.policies:train:109 - Episode 2736\n",
      "2021-08-25 10:47:31.209 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:31.211 | INFO     | src.policies:train:121 - Mean episode return: 163.0\n",
      "2021-08-25 10:47:31.212 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 143.29\n",
      "2021-08-25 10:47:31.212 | INFO     | src.policies:train:109 - Episode 2737\n",
      "2021-08-25 10:47:31.259 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:31.260 | INFO     | src.policies:train:121 - Mean episode return: 124.0\n",
      "2021-08-25 10:47:31.261 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 142.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:47:31.262 | WARNING  | src.policies:train:131 - The actual batch size is 287, instead of 200\n",
      "2021-08-25 10:47:31.269 | INFO     | src.policies:train:157 - Total loss: 304.82952880859375\n",
      "2021-08-25 10:47:31.269 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:31.273 | INFO     | src.policies:train:103 - Epoch 670 / 800\n",
      "2021-08-25 10:47:31.274 | INFO     | src.policies:train:109 - Episode 2738\n",
      "2021-08-25 10:47:31.325 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:31.327 | INFO     | src.policies:train:121 - Mean episode return: 143.0\n",
      "2021-08-25 10:47:31.328 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 141.96\n",
      "2021-08-25 10:47:31.329 | INFO     | src.policies:train:109 - Episode 2739\n",
      "2021-08-25 10:47:31.399 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:31.401 | INFO     | src.policies:train:121 - Mean episode return: 187.0\n",
      "2021-08-25 10:47:31.402 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 141.86\n",
      "2021-08-25 10:47:31.402 | WARNING  | src.policies:train:131 - The actual batch size is 330, instead of 200\n",
      "2021-08-25 10:47:31.409 | INFO     | src.policies:train:157 - Total loss: 327.4197998046875\n",
      "2021-08-25 10:47:31.410 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:31.413 | INFO     | src.policies:train:103 - Epoch 671 / 800\n",
      "2021-08-25 10:47:31.414 | INFO     | src.policies:train:109 - Episode 2740\n",
      "2021-08-25 10:47:31.484 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:31.486 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:31.487 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 141.86\n",
      "2021-08-25 10:47:31.492 | INFO     | src.policies:train:157 - Total loss: 365.39013671875\n",
      "2021-08-25 10:47:31.493 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:31.496 | INFO     | src.policies:train:103 - Epoch 672 / 800\n",
      "2021-08-25 10:47:31.497 | INFO     | src.policies:train:109 - Episode 2741\n",
      "2021-08-25 10:47:31.545 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:31.547 | INFO     | src.policies:train:121 - Mean episode return: 132.0\n",
      "2021-08-25 10:47:31.548 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 141.18\n",
      "2021-08-25 10:47:31.548 | INFO     | src.policies:train:109 - Episode 2742\n",
      "2021-08-25 10:47:31.605 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:31.606 | INFO     | src.policies:train:121 - Mean episode return: 154.0\n",
      "2021-08-25 10:47:31.607 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 140.72\n",
      "2021-08-25 10:47:31.608 | WARNING  | src.policies:train:131 - The actual batch size is 286, instead of 200\n",
      "2021-08-25 10:47:31.617 | INFO     | src.policies:train:157 - Total loss: 280.63775634765625\n",
      "2021-08-25 10:47:31.618 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:31.622 | INFO     | src.policies:train:103 - Epoch 673 / 800\n",
      "2021-08-25 10:47:31.623 | INFO     | src.policies:train:109 - Episode 2743\n",
      "2021-08-25 10:47:31.697 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:31.698 | INFO     | src.policies:train:121 - Mean episode return: 199.0\n",
      "2021-08-25 10:47:31.699 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 140.74\n",
      "2021-08-25 10:47:31.700 | INFO     | src.policies:train:109 - Episode 2744\n",
      "2021-08-25 10:47:31.756 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:31.758 | INFO     | src.policies:train:121 - Mean episode return: 147.0\n",
      "2021-08-25 10:47:31.759 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 140.45\n",
      "2021-08-25 10:47:31.760 | WARNING  | src.policies:train:131 - The actual batch size is 346, instead of 200\n",
      "2021-08-25 10:47:31.768 | INFO     | src.policies:train:157 - Total loss: 322.0078125\n",
      "2021-08-25 10:47:31.769 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:31.773 | INFO     | src.policies:train:103 - Epoch 674 / 800\n",
      "2021-08-25 10:47:31.775 | INFO     | src.policies:train:109 - Episode 2745\n",
      "2021-08-25 10:47:31.832 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:31.833 | INFO     | src.policies:train:121 - Mean episode return: 151.0\n",
      "2021-08-25 10:47:31.834 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 140.64\n",
      "2021-08-25 10:47:31.835 | INFO     | src.policies:train:109 - Episode 2746\n",
      "2021-08-25 10:47:31.893 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:31.894 | INFO     | src.policies:train:121 - Mean episode return: 160.0\n",
      "2021-08-25 10:47:31.895 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 140.38\n",
      "2021-08-25 10:47:31.896 | WARNING  | src.policies:train:131 - The actual batch size is 311, instead of 200\n",
      "2021-08-25 10:47:31.903 | INFO     | src.policies:train:157 - Total loss: 296.7720947265625\n",
      "2021-08-25 10:47:31.905 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:31.909 | INFO     | src.policies:train:103 - Epoch 675 / 800\n",
      "2021-08-25 10:47:31.910 | INFO     | src.policies:train:109 - Episode 2747\n",
      "2021-08-25 10:47:31.965 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:31.967 | INFO     | src.policies:train:121 - Mean episode return: 154.0\n",
      "2021-08-25 10:47:31.968 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 140.61\n",
      "2021-08-25 10:47:31.969 | INFO     | src.policies:train:109 - Episode 2748\n",
      "2021-08-25 10:47:32.023 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:32.024 | INFO     | src.policies:train:121 - Mean episode return: 144.0\n",
      "2021-08-25 10:47:32.025 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 140.15\n",
      "2021-08-25 10:47:32.027 | WARNING  | src.policies:train:131 - The actual batch size is 298, instead of 200\n",
      "2021-08-25 10:47:32.033 | INFO     | src.policies:train:157 - Total loss: 278.2921142578125\n",
      "2021-08-25 10:47:32.034 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:32.038 | INFO     | src.policies:train:103 - Epoch 676 / 800\n",
      "2021-08-25 10:47:32.039 | INFO     | src.policies:train:109 - Episode 2749\n",
      "2021-08-25 10:47:32.093 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:32.094 | INFO     | src.policies:train:121 - Mean episode return: 144.0\n",
      "2021-08-25 10:47:32.095 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 139.72\n",
      "2021-08-25 10:47:32.096 | INFO     | src.policies:train:109 - Episode 2750\n",
      "2021-08-25 10:47:32.146 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:32.147 | INFO     | src.policies:train:121 - Mean episode return: 133.0\n",
      "2021-08-25 10:47:32.148 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 140.17\n",
      "2021-08-25 10:47:32.149 | WARNING  | src.policies:train:131 - The actual batch size is 277, instead of 200\n",
      "2021-08-25 10:47:32.156 | INFO     | src.policies:train:157 - Total loss: 245.44580078125\n",
      "2021-08-25 10:47:32.157 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:32.161 | INFO     | src.policies:train:103 - Epoch 677 / 800\n",
      "2021-08-25 10:47:32.162 | INFO     | src.policies:train:109 - Episode 2751\n",
      "2021-08-25 10:47:32.223 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:32.224 | INFO     | src.policies:train:121 - Mean episode return: 162.0\n",
      "2021-08-25 10:47:32.225 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 140.1\n",
      "2021-08-25 10:47:32.226 | INFO     | src.policies:train:109 - Episode 2752\n",
      "2021-08-25 10:47:32.283 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:32.285 | INFO     | src.policies:train:121 - Mean episode return: 148.0\n",
      "2021-08-25 10:47:32.286 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 139.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:47:32.287 | WARNING  | src.policies:train:131 - The actual batch size is 310, instead of 200\n",
      "2021-08-25 10:47:32.293 | INFO     | src.policies:train:157 - Total loss: 279.0473937988281\n",
      "2021-08-25 10:47:32.294 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:32.297 | INFO     | src.policies:train:103 - Epoch 678 / 800\n",
      "2021-08-25 10:47:32.298 | INFO     | src.policies:train:109 - Episode 2753\n",
      "2021-08-25 10:47:32.358 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:32.360 | INFO     | src.policies:train:121 - Mean episode return: 169.0\n",
      "2021-08-25 10:47:32.361 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 139.86\n",
      "2021-08-25 10:47:32.362 | INFO     | src.policies:train:109 - Episode 2754\n",
      "2021-08-25 10:47:32.412 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:32.413 | INFO     | src.policies:train:121 - Mean episode return: 134.0\n",
      "2021-08-25 10:47:32.414 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 139.52\n",
      "2021-08-25 10:47:32.415 | WARNING  | src.policies:train:131 - The actual batch size is 303, instead of 200\n",
      "2021-08-25 10:47:32.423 | INFO     | src.policies:train:157 - Total loss: 285.2160949707031\n",
      "2021-08-25 10:47:32.424 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:32.428 | INFO     | src.policies:train:103 - Epoch 679 / 800\n",
      "2021-08-25 10:47:32.430 | INFO     | src.policies:train:109 - Episode 2755\n",
      "2021-08-25 10:47:32.491 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:32.493 | INFO     | src.policies:train:121 - Mean episode return: 164.0\n",
      "2021-08-25 10:47:32.494 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 139.27\n",
      "2021-08-25 10:47:32.495 | INFO     | src.policies:train:109 - Episode 2756\n",
      "2021-08-25 10:47:32.551 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:32.553 | INFO     | src.policies:train:121 - Mean episode return: 148.0\n",
      "2021-08-25 10:47:32.554 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 139.08\n",
      "2021-08-25 10:47:32.555 | WARNING  | src.policies:train:131 - The actual batch size is 312, instead of 200\n",
      "2021-08-25 10:47:32.560 | INFO     | src.policies:train:157 - Total loss: 280.49169921875\n",
      "2021-08-25 10:47:32.561 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:32.565 | INFO     | src.policies:train:103 - Epoch 680 / 800\n",
      "2021-08-25 10:47:32.566 | INFO     | src.policies:train:109 - Episode 2757\n",
      "2021-08-25 10:47:32.630 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:32.632 | INFO     | src.policies:train:121 - Mean episode return: 181.0\n",
      "2021-08-25 10:47:32.633 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 139.68\n",
      "2021-08-25 10:47:32.634 | INFO     | src.policies:train:109 - Episode 2758\n",
      "2021-08-25 10:47:32.686 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:32.687 | INFO     | src.policies:train:121 - Mean episode return: 134.0\n",
      "2021-08-25 10:47:32.688 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 140.64\n",
      "2021-08-25 10:47:32.689 | WARNING  | src.policies:train:131 - The actual batch size is 315, instead of 200\n",
      "2021-08-25 10:47:32.696 | INFO     | src.policies:train:157 - Total loss: 289.65966796875\n",
      "2021-08-25 10:47:32.697 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:32.701 | INFO     | src.policies:train:103 - Epoch 681 / 800\n",
      "2021-08-25 10:47:32.702 | INFO     | src.policies:train:109 - Episode 2759\n",
      "2021-08-25 10:47:32.764 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:32.765 | INFO     | src.policies:train:121 - Mean episode return: 168.0\n",
      "2021-08-25 10:47:32.766 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 140.6\n",
      "2021-08-25 10:47:32.767 | INFO     | src.policies:train:109 - Episode 2760\n",
      "2021-08-25 10:47:32.825 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:32.827 | INFO     | src.policies:train:121 - Mean episode return: 159.0\n",
      "2021-08-25 10:47:32.828 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 140.53\n",
      "2021-08-25 10:47:32.829 | WARNING  | src.policies:train:131 - The actual batch size is 327, instead of 200\n",
      "2021-08-25 10:47:32.837 | INFO     | src.policies:train:157 - Total loss: 272.2585144042969\n",
      "2021-08-25 10:47:32.838 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:32.843 | INFO     | src.policies:train:103 - Epoch 682 / 800\n",
      "2021-08-25 10:47:32.844 | INFO     | src.policies:train:109 - Episode 2761\n",
      "2021-08-25 10:47:32.894 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:32.896 | INFO     | src.policies:train:121 - Mean episode return: 137.0\n",
      "2021-08-25 10:47:32.897 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 140.13\n",
      "2021-08-25 10:47:32.898 | INFO     | src.policies:train:109 - Episode 2762\n",
      "2021-08-25 10:47:32.952 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:32.953 | INFO     | src.policies:train:121 - Mean episode return: 143.0\n",
      "2021-08-25 10:47:32.954 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 140.03\n",
      "2021-08-25 10:47:32.955 | WARNING  | src.policies:train:131 - The actual batch size is 280, instead of 200\n",
      "2021-08-25 10:47:32.962 | INFO     | src.policies:train:157 - Total loss: 242.0399627685547\n",
      "2021-08-25 10:47:32.962 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:32.967 | INFO     | src.policies:train:103 - Epoch 683 / 800\n",
      "2021-08-25 10:47:32.968 | INFO     | src.policies:train:109 - Episode 2763\n",
      "2021-08-25 10:47:33.024 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:33.025 | INFO     | src.policies:train:121 - Mean episode return: 152.0\n",
      "2021-08-25 10:47:33.026 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 140.14\n",
      "2021-08-25 10:47:33.027 | INFO     | src.policies:train:109 - Episode 2764\n",
      "2021-08-25 10:47:33.093 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:33.094 | INFO     | src.policies:train:121 - Mean episode return: 171.0\n",
      "2021-08-25 10:47:33.095 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 140.2\n",
      "2021-08-25 10:47:33.096 | WARNING  | src.policies:train:131 - The actual batch size is 323, instead of 200\n",
      "2021-08-25 10:47:33.102 | INFO     | src.policies:train:157 - Total loss: 261.12457275390625\n",
      "2021-08-25 10:47:33.103 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:33.106 | INFO     | src.policies:train:103 - Epoch 684 / 800\n",
      "2021-08-25 10:47:33.107 | INFO     | src.policies:train:109 - Episode 2765\n",
      "2021-08-25 10:47:33.156 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:33.158 | INFO     | src.policies:train:121 - Mean episode return: 135.0\n",
      "2021-08-25 10:47:33.159 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 140.12\n",
      "2021-08-25 10:47:33.159 | INFO     | src.policies:train:109 - Episode 2766\n",
      "2021-08-25 10:47:33.217 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:33.218 | INFO     | src.policies:train:121 - Mean episode return: 160.0\n",
      "2021-08-25 10:47:33.219 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 140.15\n",
      "2021-08-25 10:47:33.220 | WARNING  | src.policies:train:131 - The actual batch size is 295, instead of 200\n",
      "2021-08-25 10:47:33.226 | INFO     | src.policies:train:157 - Total loss: 251.7443389892578\n",
      "2021-08-25 10:47:33.227 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:33.230 | INFO     | src.policies:train:103 - Epoch 685 / 800\n",
      "2021-08-25 10:47:33.231 | INFO     | src.policies:train:109 - Episode 2767\n",
      "2021-08-25 10:47:33.288 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:33.290 | INFO     | src.policies:train:121 - Mean episode return: 162.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:47:33.291 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 140.31\n",
      "2021-08-25 10:47:33.292 | INFO     | src.policies:train:109 - Episode 2768\n",
      "2021-08-25 10:47:33.364 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:33.365 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:33.366 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 140.84\n",
      "2021-08-25 10:47:33.367 | WARNING  | src.policies:train:131 - The actual batch size is 362, instead of 200\n",
      "2021-08-25 10:47:33.373 | INFO     | src.policies:train:157 - Total loss: 320.2264709472656\n",
      "2021-08-25 10:47:33.374 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:33.377 | INFO     | src.policies:train:103 - Epoch 686 / 800\n",
      "2021-08-25 10:47:33.378 | INFO     | src.policies:train:109 - Episode 2769\n",
      "2021-08-25 10:47:33.432 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:33.433 | INFO     | src.policies:train:121 - Mean episode return: 149.0\n",
      "2021-08-25 10:47:33.434 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 142.02\n",
      "2021-08-25 10:47:33.435 | INFO     | src.policies:train:109 - Episode 2770\n",
      "2021-08-25 10:47:33.488 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:33.490 | INFO     | src.policies:train:121 - Mean episode return: 150.0\n",
      "2021-08-25 10:47:33.490 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 141.84\n",
      "2021-08-25 10:47:33.491 | WARNING  | src.policies:train:131 - The actual batch size is 299, instead of 200\n",
      "2021-08-25 10:47:33.497 | INFO     | src.policies:train:157 - Total loss: 238.2416534423828\n",
      "2021-08-25 10:47:33.498 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:33.501 | INFO     | src.policies:train:103 - Epoch 687 / 800\n",
      "2021-08-25 10:47:33.502 | INFO     | src.policies:train:109 - Episode 2771\n",
      "2021-08-25 10:47:33.567 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:33.569 | INFO     | src.policies:train:121 - Mean episode return: 189.0\n",
      "2021-08-25 10:47:33.570 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 142.26\n",
      "2021-08-25 10:47:33.570 | INFO     | src.policies:train:109 - Episode 2772\n",
      "2021-08-25 10:47:33.633 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:33.635 | INFO     | src.policies:train:121 - Mean episode return: 168.0\n",
      "2021-08-25 10:47:33.635 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 142.45\n",
      "2021-08-25 10:47:33.636 | WARNING  | src.policies:train:131 - The actual batch size is 357, instead of 200\n",
      "2021-08-25 10:47:33.642 | INFO     | src.policies:train:157 - Total loss: 289.97247314453125\n",
      "2021-08-25 10:47:33.643 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:33.646 | INFO     | src.policies:train:103 - Epoch 688 / 800\n",
      "2021-08-25 10:47:33.647 | INFO     | src.policies:train:109 - Episode 2773\n",
      "2021-08-25 10:47:33.719 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:33.721 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:33.722 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 142.79\n",
      "2021-08-25 10:47:33.727 | INFO     | src.policies:train:157 - Total loss: 317.7855224609375\n",
      "2021-08-25 10:47:33.727 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:33.731 | INFO     | src.policies:train:103 - Epoch 689 / 800\n",
      "2021-08-25 10:47:33.732 | INFO     | src.policies:train:109 - Episode 2774\n",
      "2021-08-25 10:47:33.792 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:33.793 | INFO     | src.policies:train:121 - Mean episode return: 171.0\n",
      "2021-08-25 10:47:33.794 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 143.31\n",
      "2021-08-25 10:47:33.795 | INFO     | src.policies:train:109 - Episode 2775\n",
      "2021-08-25 10:47:33.859 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:33.860 | INFO     | src.policies:train:121 - Mean episode return: 181.0\n",
      "2021-08-25 10:47:33.861 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 143.75\n",
      "2021-08-25 10:47:33.862 | WARNING  | src.policies:train:131 - The actual batch size is 352, instead of 200\n",
      "2021-08-25 10:47:33.868 | INFO     | src.policies:train:157 - Total loss: 274.4714660644531\n",
      "2021-08-25 10:47:33.869 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:33.872 | INFO     | src.policies:train:103 - Epoch 690 / 800\n",
      "2021-08-25 10:47:33.874 | INFO     | src.policies:train:109 - Episode 2776\n",
      "2021-08-25 10:47:33.941 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:33.942 | INFO     | src.policies:train:121 - Mean episode return: 192.0\n",
      "2021-08-25 10:47:33.943 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 143.98\n",
      "2021-08-25 10:47:33.944 | INFO     | src.policies:train:109 - Episode 2777\n",
      "2021-08-25 10:47:34.014 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:34.015 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:34.016 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 144.32\n",
      "2021-08-25 10:47:34.017 | WARNING  | src.policies:train:131 - The actual batch size is 392, instead of 200\n",
      "2021-08-25 10:47:34.024 | INFO     | src.policies:train:157 - Total loss: 371.943115234375\n",
      "2021-08-25 10:47:34.024 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:34.028 | INFO     | src.policies:train:103 - Epoch 691 / 800\n",
      "2021-08-25 10:47:34.029 | INFO     | src.policies:train:109 - Episode 2778\n",
      "2021-08-25 10:47:34.099 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:34.101 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:34.102 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 145.0\n",
      "2021-08-25 10:47:34.107 | INFO     | src.policies:train:157 - Total loss: 460.66632080078125\n",
      "2021-08-25 10:47:34.108 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:34.110 | INFO     | src.policies:train:103 - Epoch 692 / 800\n",
      "2021-08-25 10:47:34.111 | INFO     | src.policies:train:109 - Episode 2779\n",
      "2021-08-25 10:47:34.180 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:34.181 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:34.182 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 145.59\n",
      "2021-08-25 10:47:34.187 | INFO     | src.policies:train:157 - Total loss: 307.3715515136719\n",
      "2021-08-25 10:47:34.187 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:34.191 | INFO     | src.policies:train:103 - Epoch 693 / 800\n",
      "2021-08-25 10:47:34.191 | INFO     | src.policies:train:109 - Episode 2780\n",
      "2021-08-25 10:47:34.264 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:34.266 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:34.267 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 146.0\n",
      "2021-08-25 10:47:34.272 | INFO     | src.policies:train:157 - Total loss: 345.5765075683594\n",
      "2021-08-25 10:47:34.272 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:34.275 | INFO     | src.policies:train:103 - Epoch 694 / 800\n",
      "2021-08-25 10:47:34.276 | INFO     | src.policies:train:109 - Episode 2781\n",
      "2021-08-25 10:47:34.348 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:34.350 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:34.351 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 146.73\n",
      "2021-08-25 10:47:34.356 | INFO     | src.policies:train:157 - Total loss: 460.13653564453125\n",
      "2021-08-25 10:47:34.356 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:34.359 | INFO     | src.policies:train:103 - Epoch 695 / 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:47:34.360 | INFO     | src.policies:train:109 - Episode 2782\n",
      "2021-08-25 10:47:34.430 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:34.432 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:34.433 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 148.22\n",
      "2021-08-25 10:47:34.438 | INFO     | src.policies:train:157 - Total loss: 457.1365051269531\n",
      "2021-08-25 10:47:34.438 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:34.441 | INFO     | src.policies:train:103 - Epoch 696 / 800\n",
      "2021-08-25 10:47:34.442 | INFO     | src.policies:train:109 - Episode 2783\n",
      "2021-08-25 10:47:34.512 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:34.514 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:34.515 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 149.41\n",
      "2021-08-25 10:47:34.519 | INFO     | src.policies:train:157 - Total loss: 664.55126953125\n",
      "2021-08-25 10:47:34.520 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:34.523 | INFO     | src.policies:train:103 - Epoch 697 / 800\n",
      "2021-08-25 10:47:34.524 | INFO     | src.policies:train:109 - Episode 2784\n",
      "2021-08-25 10:47:34.593 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:34.594 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:34.595 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 149.99\n",
      "2021-08-25 10:47:34.601 | INFO     | src.policies:train:157 - Total loss: 480.8562316894531\n",
      "2021-08-25 10:47:34.601 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:34.605 | INFO     | src.policies:train:103 - Epoch 698 / 800\n",
      "2021-08-25 10:47:34.606 | INFO     | src.policies:train:109 - Episode 2785\n",
      "2021-08-25 10:47:34.679 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:34.681 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:34.682 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 150.71\n",
      "2021-08-25 10:47:34.686 | INFO     | src.policies:train:157 - Total loss: 450.74920654296875\n",
      "2021-08-25 10:47:34.687 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:34.690 | INFO     | src.policies:train:103 - Epoch 699 / 800\n",
      "2021-08-25 10:47:34.691 | INFO     | src.policies:train:109 - Episode 2786\n",
      "2021-08-25 10:47:34.762 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:34.763 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:34.764 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 151.52\n",
      "2021-08-25 10:47:34.768 | INFO     | src.policies:train:157 - Total loss: 460.45330810546875\n",
      "2021-08-25 10:47:34.769 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:34.772 | INFO     | src.policies:train:103 - Epoch 700 / 800\n",
      "2021-08-25 10:47:34.772 | INFO     | src.policies:train:109 - Episode 2787\n",
      "2021-08-25 10:47:34.842 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:34.844 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:34.845 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 151.94\n",
      "2021-08-25 10:47:34.851 | INFO     | src.policies:train:157 - Total loss: 509.3570251464844\n",
      "2021-08-25 10:47:34.852 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:34.855 | INFO     | src.policies:train:103 - Epoch 701 / 800\n",
      "2021-08-25 10:47:34.856 | INFO     | src.policies:train:109 - Episode 2788\n",
      "2021-08-25 10:47:34.929 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:34.931 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:34.932 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 153.51\n",
      "2021-08-25 10:47:34.937 | INFO     | src.policies:train:157 - Total loss: 589.5318603515625\n",
      "2021-08-25 10:47:34.937 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:34.940 | INFO     | src.policies:train:103 - Epoch 702 / 800\n",
      "2021-08-25 10:47:34.941 | INFO     | src.policies:train:109 - Episode 2789\n",
      "2021-08-25 10:47:35.012 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:35.014 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:35.015 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 154.06\n",
      "2021-08-25 10:47:35.021 | INFO     | src.policies:train:157 - Total loss: 524.7064208984375\n",
      "2021-08-25 10:47:35.022 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:35.026 | INFO     | src.policies:train:103 - Epoch 703 / 800\n",
      "2021-08-25 10:47:35.027 | INFO     | src.policies:train:109 - Episode 2790\n",
      "2021-08-25 10:47:35.100 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:35.101 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:35.102 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 154.87\n",
      "2021-08-25 10:47:35.107 | INFO     | src.policies:train:157 - Total loss: 621.7027587890625\n",
      "2021-08-25 10:47:35.108 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:35.111 | INFO     | src.policies:train:103 - Epoch 704 / 800\n",
      "2021-08-25 10:47:35.112 | INFO     | src.policies:train:109 - Episode 2791\n",
      "2021-08-25 10:47:35.182 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:35.184 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:35.185 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 155.5\n",
      "2021-08-25 10:47:35.190 | INFO     | src.policies:train:157 - Total loss: 452.4884033203125\n",
      "2021-08-25 10:47:35.191 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:35.194 | INFO     | src.policies:train:103 - Epoch 705 / 800\n",
      "2021-08-25 10:47:35.195 | INFO     | src.policies:train:109 - Episode 2792\n",
      "2021-08-25 10:47:35.266 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:35.268 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:35.269 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 157.13\n",
      "2021-08-25 10:47:35.274 | INFO     | src.policies:train:157 - Total loss: 341.3343505859375\n",
      "2021-08-25 10:47:35.275 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:35.278 | INFO     | src.policies:train:103 - Epoch 706 / 800\n",
      "2021-08-25 10:47:35.279 | INFO     | src.policies:train:109 - Episode 2793\n",
      "2021-08-25 10:47:35.352 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:35.353 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:35.354 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 157.9\n",
      "2021-08-25 10:47:35.359 | INFO     | src.policies:train:157 - Total loss: 592.6466674804688\n",
      "2021-08-25 10:47:35.359 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:35.362 | INFO     | src.policies:train:103 - Epoch 707 / 800\n",
      "2021-08-25 10:47:35.363 | INFO     | src.policies:train:109 - Episode 2794\n",
      "2021-08-25 10:47:35.437 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:35.438 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:35.439 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 158.67\n",
      "2021-08-25 10:47:35.444 | INFO     | src.policies:train:157 - Total loss: 357.76202392578125\n",
      "2021-08-25 10:47:35.445 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:35.449 | INFO     | src.policies:train:103 - Epoch 708 / 800\n",
      "2021-08-25 10:47:35.449 | INFO     | src.policies:train:109 - Episode 2795\n",
      "2021-08-25 10:47:35.522 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:35.524 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:47:35.525 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 159.27\n",
      "2021-08-25 10:47:35.530 | INFO     | src.policies:train:157 - Total loss: 509.78399658203125\n",
      "2021-08-25 10:47:35.530 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:35.533 | INFO     | src.policies:train:103 - Epoch 709 / 800\n",
      "2021-08-25 10:47:35.534 | INFO     | src.policies:train:109 - Episode 2796\n",
      "2021-08-25 10:47:35.606 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:35.608 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:35.609 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 160.93\n",
      "2021-08-25 10:47:35.614 | INFO     | src.policies:train:157 - Total loss: 679.3924560546875\n",
      "2021-08-25 10:47:35.615 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:35.619 | INFO     | src.policies:train:103 - Epoch 710 / 800\n",
      "2021-08-25 10:47:35.619 | INFO     | src.policies:train:109 - Episode 2797\n",
      "2021-08-25 10:47:35.691 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:35.693 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:35.694 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 161.6\n",
      "2021-08-25 10:47:35.699 | INFO     | src.policies:train:157 - Total loss: 646.1466674804688\n",
      "2021-08-25 10:47:35.700 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:35.704 | INFO     | src.policies:train:103 - Epoch 711 / 800\n",
      "2021-08-25 10:47:35.705 | INFO     | src.policies:train:109 - Episode 2798\n",
      "2021-08-25 10:47:35.777 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:35.779 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:35.780 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 162.3\n",
      "2021-08-25 10:47:35.785 | INFO     | src.policies:train:157 - Total loss: 677.7567749023438\n",
      "2021-08-25 10:47:35.786 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:35.789 | INFO     | src.policies:train:103 - Epoch 712 / 800\n",
      "2021-08-25 10:47:35.790 | INFO     | src.policies:train:109 - Episode 2799\n",
      "2021-08-25 10:47:35.862 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:35.864 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:35.865 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 163.07\n",
      "2021-08-25 10:47:35.871 | INFO     | src.policies:train:157 - Total loss: 608.9564208984375\n",
      "2021-08-25 10:47:35.872 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:35.876 | INFO     | src.policies:train:103 - Epoch 713 / 800\n",
      "2021-08-25 10:47:35.876 | INFO     | src.policies:train:109 - Episode 2800\n",
      "2021-08-25 10:47:35.950 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:35.952 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:35.953 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 163.84\n",
      "2021-08-25 10:47:35.959 | INFO     | src.policies:train:157 - Total loss: 577.3335571289062\n",
      "2021-08-25 10:47:35.959 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:35.963 | INFO     | src.policies:train:103 - Epoch 714 / 800\n",
      "2021-08-25 10:47:35.964 | INFO     | src.policies:train:109 - Episode 2801\n",
      "2021-08-25 10:47:36.036 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:36.038 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:36.039 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 164.6\n",
      "2021-08-25 10:47:36.045 | INFO     | src.policies:train:157 - Total loss: 628.0285034179688\n",
      "2021-08-25 10:47:36.046 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:36.050 | INFO     | src.policies:train:103 - Epoch 715 / 800\n",
      "2021-08-25 10:47:36.051 | INFO     | src.policies:train:109 - Episode 2802\n",
      "2021-08-25 10:47:36.123 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:36.125 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:36.126 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 165.32\n",
      "2021-08-25 10:47:36.131 | INFO     | src.policies:train:157 - Total loss: 662.3717651367188\n",
      "2021-08-25 10:47:36.132 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:36.135 | INFO     | src.policies:train:103 - Epoch 716 / 800\n",
      "2021-08-25 10:47:36.136 | INFO     | src.policies:train:109 - Episode 2803\n",
      "2021-08-25 10:47:36.207 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:36.209 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:36.210 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 165.97\n",
      "2021-08-25 10:47:36.215 | INFO     | src.policies:train:157 - Total loss: 591.5667724609375\n",
      "2021-08-25 10:47:36.216 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:36.220 | INFO     | src.policies:train:103 - Epoch 717 / 800\n",
      "2021-08-25 10:47:36.220 | INFO     | src.policies:train:109 - Episode 2804\n",
      "2021-08-25 10:47:36.293 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:36.294 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:36.295 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 166.8\n",
      "2021-08-25 10:47:36.301 | INFO     | src.policies:train:157 - Total loss: 635.2130126953125\n",
      "2021-08-25 10:47:36.302 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:36.305 | INFO     | src.policies:train:103 - Epoch 718 / 800\n",
      "2021-08-25 10:47:36.305 | INFO     | src.policies:train:109 - Episode 2805\n",
      "2021-08-25 10:47:36.376 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:36.378 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:36.379 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 167.52\n",
      "2021-08-25 10:47:36.384 | INFO     | src.policies:train:157 - Total loss: 503.2148742675781\n",
      "2021-08-25 10:47:36.385 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:36.388 | INFO     | src.policies:train:103 - Epoch 719 / 800\n",
      "2021-08-25 10:47:36.389 | INFO     | src.policies:train:109 - Episode 2806\n",
      "2021-08-25 10:47:36.461 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:36.462 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:36.463 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 168.41\n",
      "2021-08-25 10:47:36.468 | INFO     | src.policies:train:157 - Total loss: 624.5591430664062\n",
      "2021-08-25 10:47:36.469 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:36.472 | INFO     | src.policies:train:103 - Epoch 720 / 800\n",
      "2021-08-25 10:47:36.473 | INFO     | src.policies:train:109 - Episode 2807\n",
      "2021-08-25 10:47:36.545 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:36.547 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:36.548 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 168.94\n",
      "2021-08-25 10:47:36.553 | INFO     | src.policies:train:157 - Total loss: 645.7277221679688\n",
      "2021-08-25 10:47:36.554 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:36.557 | INFO     | src.policies:train:103 - Epoch 721 / 800\n",
      "2021-08-25 10:47:36.558 | INFO     | src.policies:train:109 - Episode 2808\n",
      "2021-08-25 10:47:36.631 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:36.633 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:36.634 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 169.46\n",
      "2021-08-25 10:47:36.639 | INFO     | src.policies:train:157 - Total loss: 557.890869140625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:47:36.640 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:36.642 | INFO     | src.policies:train:103 - Epoch 722 / 800\n",
      "2021-08-25 10:47:36.643 | INFO     | src.policies:train:109 - Episode 2809\n",
      "2021-08-25 10:47:36.717 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:36.718 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:36.720 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 170.23\n",
      "2021-08-25 10:47:36.725 | INFO     | src.policies:train:157 - Total loss: 497.3808898925781\n",
      "2021-08-25 10:47:36.726 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:36.729 | INFO     | src.policies:train:103 - Epoch 723 / 800\n",
      "2021-08-25 10:47:36.730 | INFO     | src.policies:train:109 - Episode 2810\n",
      "2021-08-25 10:47:36.803 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:36.804 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:36.805 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 170.82\n",
      "2021-08-25 10:47:36.810 | INFO     | src.policies:train:157 - Total loss: 521.1701049804688\n",
      "2021-08-25 10:47:36.811 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:36.814 | INFO     | src.policies:train:103 - Epoch 724 / 800\n",
      "2021-08-25 10:47:36.815 | INFO     | src.policies:train:109 - Episode 2811\n",
      "2021-08-25 10:47:36.887 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:36.889 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:36.890 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 171.42\n",
      "2021-08-25 10:47:36.895 | INFO     | src.policies:train:157 - Total loss: 624.8038940429688\n",
      "2021-08-25 10:47:36.896 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:36.899 | INFO     | src.policies:train:103 - Epoch 725 / 800\n",
      "2021-08-25 10:47:36.899 | INFO     | src.policies:train:109 - Episode 2812\n",
      "2021-08-25 10:47:36.972 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:36.974 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:36.975 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 171.89\n",
      "2021-08-25 10:47:36.980 | INFO     | src.policies:train:157 - Total loss: 561.4179077148438\n",
      "2021-08-25 10:47:36.981 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:36.984 | INFO     | src.policies:train:103 - Epoch 726 / 800\n",
      "2021-08-25 10:47:36.985 | INFO     | src.policies:train:109 - Episode 2813\n",
      "2021-08-25 10:47:37.057 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:37.059 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:37.060 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.4\n",
      "2021-08-25 10:47:37.065 | INFO     | src.policies:train:157 - Total loss: 458.9844665527344\n",
      "2021-08-25 10:47:37.066 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:37.069 | INFO     | src.policies:train:103 - Epoch 727 / 800\n",
      "2021-08-25 10:47:37.070 | INFO     | src.policies:train:109 - Episode 2814\n",
      "2021-08-25 10:47:37.142 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:37.144 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:37.145 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.98\n",
      "2021-08-25 10:47:37.149 | INFO     | src.policies:train:157 - Total loss: 464.4494323730469\n",
      "2021-08-25 10:47:37.150 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:37.153 | INFO     | src.policies:train:103 - Epoch 728 / 800\n",
      "2021-08-25 10:47:37.154 | INFO     | src.policies:train:109 - Episode 2815\n",
      "2021-08-25 10:47:37.225 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:37.226 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:37.227 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.76\n",
      "2021-08-25 10:47:37.232 | INFO     | src.policies:train:157 - Total loss: 571.423583984375\n",
      "2021-08-25 10:47:37.233 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:37.237 | INFO     | src.policies:train:103 - Epoch 729 / 800\n",
      "2021-08-25 10:47:37.238 | INFO     | src.policies:train:109 - Episode 2816\n",
      "2021-08-25 10:47:37.310 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:37.312 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:37.313 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.27\n",
      "2021-08-25 10:47:37.318 | INFO     | src.policies:train:157 - Total loss: 589.4439697265625\n",
      "2021-08-25 10:47:37.319 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:37.322 | INFO     | src.policies:train:103 - Epoch 730 / 800\n",
      "2021-08-25 10:47:37.323 | INFO     | src.policies:train:109 - Episode 2817\n",
      "2021-08-25 10:47:37.394 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:37.395 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:37.396 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.87\n",
      "2021-08-25 10:47:37.401 | INFO     | src.policies:train:157 - Total loss: 507.7650146484375\n",
      "2021-08-25 10:47:37.401 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:37.405 | INFO     | src.policies:train:103 - Epoch 731 / 800\n",
      "2021-08-25 10:47:37.406 | INFO     | src.policies:train:109 - Episode 2818\n",
      "2021-08-25 10:47:37.479 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:37.481 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:37.482 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.29\n",
      "2021-08-25 10:47:37.487 | INFO     | src.policies:train:157 - Total loss: 620.0773315429688\n",
      "2021-08-25 10:47:37.488 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:37.490 | INFO     | src.policies:train:103 - Epoch 732 / 800\n",
      "2021-08-25 10:47:37.491 | INFO     | src.policies:train:109 - Episode 2819\n",
      "2021-08-25 10:47:37.561 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:37.563 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:37.564 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.97\n",
      "2021-08-25 10:47:37.570 | INFO     | src.policies:train:157 - Total loss: 528.498779296875\n",
      "2021-08-25 10:47:37.571 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:37.575 | INFO     | src.policies:train:103 - Epoch 733 / 800\n",
      "2021-08-25 10:47:37.576 | INFO     | src.policies:train:109 - Episode 2820\n",
      "2021-08-25 10:47:37.647 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:37.649 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:37.650 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 177.47\n",
      "2021-08-25 10:47:37.656 | INFO     | src.policies:train:157 - Total loss: 507.1899719238281\n",
      "2021-08-25 10:47:37.657 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:37.660 | INFO     | src.policies:train:103 - Epoch 734 / 800\n",
      "2021-08-25 10:47:37.661 | INFO     | src.policies:train:109 - Episode 2821\n",
      "2021-08-25 10:47:37.735 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:37.737 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:37.738 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 177.47\n",
      "2021-08-25 10:47:37.743 | INFO     | src.policies:train:157 - Total loss: 462.4549255371094\n",
      "2021-08-25 10:47:37.744 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:37.747 | INFO     | src.policies:train:103 - Epoch 735 / 800\n",
      "2021-08-25 10:47:37.748 | INFO     | src.policies:train:109 - Episode 2822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:47:37.819 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:37.821 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:37.822 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 177.52\n",
      "2021-08-25 10:47:37.827 | INFO     | src.policies:train:157 - Total loss: 575.942626953125\n",
      "2021-08-25 10:47:37.828 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:37.831 | INFO     | src.policies:train:103 - Epoch 736 / 800\n",
      "2021-08-25 10:47:37.833 | INFO     | src.policies:train:109 - Episode 2823\n",
      "2021-08-25 10:47:37.903 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:37.905 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:37.906 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 178.0\n",
      "2021-08-25 10:47:37.910 | INFO     | src.policies:train:157 - Total loss: 586.8952026367188\n",
      "2021-08-25 10:47:37.911 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:37.915 | INFO     | src.policies:train:103 - Epoch 737 / 800\n",
      "2021-08-25 10:47:37.915 | INFO     | src.policies:train:109 - Episode 2824\n",
      "2021-08-25 10:47:37.988 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:37.989 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:37.990 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 178.26\n",
      "2021-08-25 10:47:37.994 | INFO     | src.policies:train:157 - Total loss: 513.4659423828125\n",
      "2021-08-25 10:47:37.995 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:37.999 | INFO     | src.policies:train:103 - Epoch 738 / 800\n",
      "2021-08-25 10:47:37.999 | INFO     | src.policies:train:109 - Episode 2825\n",
      "2021-08-25 10:47:38.071 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:38.073 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:38.074 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 178.63\n",
      "2021-08-25 10:47:38.078 | INFO     | src.policies:train:157 - Total loss: 545.0864868164062\n",
      "2021-08-25 10:47:38.079 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:38.082 | INFO     | src.policies:train:103 - Epoch 739 / 800\n",
      "2021-08-25 10:47:38.083 | INFO     | src.policies:train:109 - Episode 2826\n",
      "2021-08-25 10:47:38.155 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:38.156 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:38.157 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 179.01\n",
      "2021-08-25 10:47:38.162 | INFO     | src.policies:train:157 - Total loss: 453.9023132324219\n",
      "2021-08-25 10:47:38.163 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:38.166 | INFO     | src.policies:train:103 - Epoch 740 / 800\n",
      "2021-08-25 10:47:38.166 | INFO     | src.policies:train:109 - Episode 2827\n",
      "2021-08-25 10:47:38.237 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:38.238 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:38.239 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 180.63\n",
      "2021-08-25 10:47:38.244 | INFO     | src.policies:train:157 - Total loss: 551.3545532226562\n",
      "2021-08-25 10:47:38.245 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:38.248 | INFO     | src.policies:train:103 - Epoch 741 / 800\n",
      "2021-08-25 10:47:38.249 | INFO     | src.policies:train:109 - Episode 2828\n",
      "2021-08-25 10:47:38.320 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:38.322 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:38.323 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 180.9\n",
      "2021-08-25 10:47:38.328 | INFO     | src.policies:train:157 - Total loss: 579.652099609375\n",
      "2021-08-25 10:47:38.328 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:38.331 | INFO     | src.policies:train:103 - Epoch 742 / 800\n",
      "2021-08-25 10:47:38.332 | INFO     | src.policies:train:109 - Episode 2829\n",
      "2021-08-25 10:47:38.405 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:38.406 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:38.407 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.58\n",
      "2021-08-25 10:47:38.412 | INFO     | src.policies:train:157 - Total loss: 429.3961486816406\n",
      "2021-08-25 10:47:38.413 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:38.416 | INFO     | src.policies:train:103 - Epoch 743 / 800\n",
      "2021-08-25 10:47:38.417 | INFO     | src.policies:train:109 - Episode 2830\n",
      "2021-08-25 10:47:38.487 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:38.488 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:38.489 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.82\n",
      "2021-08-25 10:47:38.494 | INFO     | src.policies:train:157 - Total loss: 535.5904541015625\n",
      "2021-08-25 10:47:38.495 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:38.498 | INFO     | src.policies:train:103 - Epoch 744 / 800\n",
      "2021-08-25 10:47:38.499 | INFO     | src.policies:train:109 - Episode 2831\n",
      "2021-08-25 10:47:38.572 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:38.574 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:38.575 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.07\n",
      "2021-08-25 10:47:38.579 | INFO     | src.policies:train:157 - Total loss: 510.0191955566406\n",
      "2021-08-25 10:47:38.580 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:38.583 | INFO     | src.policies:train:103 - Epoch 745 / 800\n",
      "2021-08-25 10:47:38.584 | INFO     | src.policies:train:109 - Episode 2832\n",
      "2021-08-25 10:47:38.654 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:38.655 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:38.656 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.49\n",
      "2021-08-25 10:47:38.661 | INFO     | src.policies:train:157 - Total loss: 583.3591918945312\n",
      "2021-08-25 10:47:38.662 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:38.665 | INFO     | src.policies:train:103 - Epoch 746 / 800\n",
      "2021-08-25 10:47:38.665 | INFO     | src.policies:train:109 - Episode 2833\n",
      "2021-08-25 10:47:38.736 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:38.738 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:38.739 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.82\n",
      "2021-08-25 10:47:38.743 | INFO     | src.policies:train:157 - Total loss: 373.47296142578125\n",
      "2021-08-25 10:47:38.744 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:38.747 | INFO     | src.policies:train:103 - Epoch 747 / 800\n",
      "2021-08-25 10:47:38.747 | INFO     | src.policies:train:109 - Episode 2834\n",
      "2021-08-25 10:47:38.820 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:38.821 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:38.822 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 183.17\n",
      "2021-08-25 10:47:38.827 | INFO     | src.policies:train:157 - Total loss: 532.9495239257812\n",
      "2021-08-25 10:47:38.828 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:38.831 | INFO     | src.policies:train:103 - Epoch 748 / 800\n",
      "2021-08-25 10:47:38.831 | INFO     | src.policies:train:109 - Episode 2835\n",
      "2021-08-25 10:47:38.903 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:38.904 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:47:38.905 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 183.62\n",
      "2021-08-25 10:47:38.910 | INFO     | src.policies:train:157 - Total loss: 588.3477172851562\n",
      "2021-08-25 10:47:38.910 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:38.914 | INFO     | src.policies:train:103 - Epoch 749 / 800\n",
      "2021-08-25 10:47:38.914 | INFO     | src.policies:train:109 - Episode 2836\n",
      "2021-08-25 10:47:38.986 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:38.987 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:38.988 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 183.99\n",
      "2021-08-25 10:47:38.993 | INFO     | src.policies:train:157 - Total loss: 573.646484375\n",
      "2021-08-25 10:47:38.994 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:38.997 | INFO     | src.policies:train:103 - Epoch 750 / 800\n",
      "2021-08-25 10:47:38.998 | INFO     | src.policies:train:109 - Episode 2837\n",
      "2021-08-25 10:47:39.070 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:39.071 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:39.072 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 184.75\n",
      "2021-08-25 10:47:39.077 | INFO     | src.policies:train:157 - Total loss: 471.82257080078125\n",
      "2021-08-25 10:47:39.078 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:39.081 | INFO     | src.policies:train:103 - Epoch 751 / 800\n",
      "2021-08-25 10:47:39.082 | INFO     | src.policies:train:109 - Episode 2838\n",
      "2021-08-25 10:47:39.154 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:39.156 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:39.157 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 185.32\n",
      "2021-08-25 10:47:39.162 | INFO     | src.policies:train:157 - Total loss: 589.73046875\n",
      "2021-08-25 10:47:39.162 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:39.165 | INFO     | src.policies:train:103 - Epoch 752 / 800\n",
      "2021-08-25 10:47:39.166 | INFO     | src.policies:train:109 - Episode 2839\n",
      "2021-08-25 10:47:39.237 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:39.238 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:39.240 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 185.45\n",
      "2021-08-25 10:47:39.244 | INFO     | src.policies:train:157 - Total loss: 562.1452026367188\n",
      "2021-08-25 10:47:39.245 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:39.248 | INFO     | src.policies:train:103 - Epoch 753 / 800\n",
      "2021-08-25 10:47:39.249 | INFO     | src.policies:train:109 - Episode 2840\n",
      "2021-08-25 10:47:39.320 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:39.322 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:39.323 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 185.45\n",
      "2021-08-25 10:47:39.328 | INFO     | src.policies:train:157 - Total loss: 548.0726928710938\n",
      "2021-08-25 10:47:39.329 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:39.332 | INFO     | src.policies:train:103 - Epoch 754 / 800\n",
      "2021-08-25 10:47:39.332 | INFO     | src.policies:train:109 - Episode 2841\n",
      "2021-08-25 10:47:39.402 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:39.404 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:39.405 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 186.13\n",
      "2021-08-25 10:47:39.410 | INFO     | src.policies:train:157 - Total loss: 522.0660400390625\n",
      "2021-08-25 10:47:39.411 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:39.414 | INFO     | src.policies:train:103 - Epoch 755 / 800\n",
      "2021-08-25 10:47:39.415 | INFO     | src.policies:train:109 - Episode 2842\n",
      "2021-08-25 10:47:39.486 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:39.487 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:39.488 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 186.59\n",
      "2021-08-25 10:47:39.493 | INFO     | src.policies:train:157 - Total loss: 571.22314453125\n",
      "2021-08-25 10:47:39.494 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:39.497 | INFO     | src.policies:train:103 - Epoch 756 / 800\n",
      "2021-08-25 10:47:39.498 | INFO     | src.policies:train:109 - Episode 2843\n",
      "2021-08-25 10:47:39.569 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:39.571 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:39.572 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 186.6\n",
      "2021-08-25 10:47:39.577 | INFO     | src.policies:train:157 - Total loss: 613.7859497070312\n",
      "2021-08-25 10:47:39.577 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:39.581 | INFO     | src.policies:train:103 - Epoch 757 / 800\n",
      "2021-08-25 10:47:39.581 | INFO     | src.policies:train:109 - Episode 2844\n",
      "2021-08-25 10:47:39.655 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:39.656 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:39.657 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 187.13\n",
      "2021-08-25 10:47:39.662 | INFO     | src.policies:train:157 - Total loss: 597.371337890625\n",
      "2021-08-25 10:47:39.663 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:39.665 | INFO     | src.policies:train:103 - Epoch 758 / 800\n",
      "2021-08-25 10:47:39.666 | INFO     | src.policies:train:109 - Episode 2845\n",
      "2021-08-25 10:47:39.737 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:39.738 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:39.740 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 187.62\n",
      "2021-08-25 10:47:39.744 | INFO     | src.policies:train:157 - Total loss: 565.4260864257812\n",
      "2021-08-25 10:47:39.745 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:39.748 | INFO     | src.policies:train:103 - Epoch 759 / 800\n",
      "2021-08-25 10:47:39.749 | INFO     | src.policies:train:109 - Episode 2846\n",
      "2021-08-25 10:47:39.819 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:39.821 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:39.822 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 188.02\n",
      "2021-08-25 10:47:39.826 | INFO     | src.policies:train:157 - Total loss: 581.100830078125\n",
      "2021-08-25 10:47:39.827 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:39.830 | INFO     | src.policies:train:103 - Epoch 760 / 800\n",
      "2021-08-25 10:47:39.831 | INFO     | src.policies:train:109 - Episode 2847\n",
      "2021-08-25 10:47:39.904 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:39.906 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:39.906 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 188.48\n",
      "2021-08-25 10:47:39.912 | INFO     | src.policies:train:157 - Total loss: 466.681396484375\n",
      "2021-08-25 10:47:39.913 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:39.916 | INFO     | src.policies:train:103 - Epoch 761 / 800\n",
      "2021-08-25 10:47:39.917 | INFO     | src.policies:train:109 - Episode 2848\n",
      "2021-08-25 10:47:39.988 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:39.990 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:39.991 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 189.04\n",
      "2021-08-25 10:47:39.996 | INFO     | src.policies:train:157 - Total loss: 599.2482299804688\n",
      "2021-08-25 10:47:39.996 | INFO     | src.policies:train:161 - Epoch infos: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:47:40.000 | INFO     | src.policies:train:103 - Epoch 762 / 800\n",
      "2021-08-25 10:47:40.000 | INFO     | src.policies:train:109 - Episode 2849\n",
      "2021-08-25 10:47:40.076 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:40.078 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:40.079 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 189.6\n",
      "2021-08-25 10:47:40.085 | INFO     | src.policies:train:157 - Total loss: 586.1451416015625\n",
      "2021-08-25 10:47:40.086 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:40.090 | INFO     | src.policies:train:103 - Epoch 763 / 800\n",
      "2021-08-25 10:47:40.091 | INFO     | src.policies:train:109 - Episode 2850\n",
      "2021-08-25 10:47:40.170 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:40.172 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:40.173 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 190.27\n",
      "2021-08-25 10:47:40.179 | INFO     | src.policies:train:157 - Total loss: 517.2069091796875\n",
      "2021-08-25 10:47:40.180 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:40.184 | INFO     | src.policies:train:103 - Epoch 764 / 800\n",
      "2021-08-25 10:47:40.185 | INFO     | src.policies:train:109 - Episode 2851\n",
      "2021-08-25 10:47:40.255 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:40.257 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:40.258 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 190.65\n",
      "2021-08-25 10:47:40.263 | INFO     | src.policies:train:157 - Total loss: 480.7602233886719\n",
      "2021-08-25 10:47:40.264 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:40.267 | INFO     | src.policies:train:103 - Epoch 765 / 800\n",
      "2021-08-25 10:47:40.267 | INFO     | src.policies:train:109 - Episode 2852\n",
      "2021-08-25 10:47:40.339 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:40.340 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:40.341 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 191.17\n",
      "2021-08-25 10:47:40.346 | INFO     | src.policies:train:157 - Total loss: 498.42041015625\n",
      "2021-08-25 10:47:40.347 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:40.350 | INFO     | src.policies:train:103 - Epoch 766 / 800\n",
      "2021-08-25 10:47:40.351 | INFO     | src.policies:train:109 - Episode 2853\n",
      "2021-08-25 10:47:40.423 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:40.424 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:40.425 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 191.48\n",
      "2021-08-25 10:47:40.430 | INFO     | src.policies:train:157 - Total loss: 543.3150024414062\n",
      "2021-08-25 10:47:40.430 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:40.433 | INFO     | src.policies:train:103 - Epoch 767 / 800\n",
      "2021-08-25 10:47:40.434 | INFO     | src.policies:train:109 - Episode 2854\n",
      "2021-08-25 10:47:40.505 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:40.507 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:40.508 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 192.14\n",
      "2021-08-25 10:47:40.512 | INFO     | src.policies:train:157 - Total loss: 544.1870727539062\n",
      "2021-08-25 10:47:40.513 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:40.516 | INFO     | src.policies:train:103 - Epoch 768 / 800\n",
      "2021-08-25 10:47:40.517 | INFO     | src.policies:train:109 - Episode 2855\n",
      "2021-08-25 10:47:40.588 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:40.589 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:40.590 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 192.5\n",
      "2021-08-25 10:47:40.595 | INFO     | src.policies:train:157 - Total loss: 504.0207824707031\n",
      "2021-08-25 10:47:40.596 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:40.598 | INFO     | src.policies:train:103 - Epoch 769 / 800\n",
      "2021-08-25 10:47:40.599 | INFO     | src.policies:train:109 - Episode 2856\n",
      "2021-08-25 10:47:40.671 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:40.672 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:40.673 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 193.02\n",
      "2021-08-25 10:47:40.678 | INFO     | src.policies:train:157 - Total loss: 590.0084838867188\n",
      "2021-08-25 10:47:40.679 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:40.682 | INFO     | src.policies:train:103 - Epoch 770 / 800\n",
      "2021-08-25 10:47:40.683 | INFO     | src.policies:train:109 - Episode 2857\n",
      "2021-08-25 10:47:40.753 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:40.754 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:40.755 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 193.21\n",
      "2021-08-25 10:47:40.760 | INFO     | src.policies:train:157 - Total loss: 579.2782592773438\n",
      "2021-08-25 10:47:40.761 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:40.764 | INFO     | src.policies:train:103 - Epoch 771 / 800\n",
      "2021-08-25 10:47:40.764 | INFO     | src.policies:train:109 - Episode 2858\n",
      "2021-08-25 10:47:40.831 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:40.833 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:40.834 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 193.87\n",
      "2021-08-25 10:47:40.838 | INFO     | src.policies:train:157 - Total loss: 577.9353637695312\n",
      "2021-08-25 10:47:40.839 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:40.842 | INFO     | src.policies:train:103 - Epoch 772 / 800\n",
      "2021-08-25 10:47:40.843 | INFO     | src.policies:train:109 - Episode 2859\n",
      "2021-08-25 10:47:40.909 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:40.911 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:40.912 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 194.19\n",
      "2021-08-25 10:47:40.916 | INFO     | src.policies:train:157 - Total loss: 574.4129028320312\n",
      "2021-08-25 10:47:40.917 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:40.920 | INFO     | src.policies:train:103 - Epoch 773 / 800\n",
      "2021-08-25 10:47:40.920 | INFO     | src.policies:train:109 - Episode 2860\n",
      "2021-08-25 10:47:40.989 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:40.991 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:40.992 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 194.6\n",
      "2021-08-25 10:47:40.996 | INFO     | src.policies:train:157 - Total loss: 492.7162780761719\n",
      "2021-08-25 10:47:40.997 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:41.000 | INFO     | src.policies:train:103 - Epoch 774 / 800\n",
      "2021-08-25 10:47:41.001 | INFO     | src.policies:train:109 - Episode 2861\n",
      "2021-08-25 10:47:41.068 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:41.070 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:41.071 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 195.23\n",
      "2021-08-25 10:47:41.075 | INFO     | src.policies:train:157 - Total loss: 554.2843017578125\n",
      "2021-08-25 10:47:41.076 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:41.079 | INFO     | src.policies:train:103 - Epoch 775 / 800\n",
      "2021-08-25 10:47:41.080 | INFO     | src.policies:train:109 - Episode 2862\n",
      "2021-08-25 10:47:41.148 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:47:41.150 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:41.151 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 195.8\n",
      "2021-08-25 10:47:41.155 | INFO     | src.policies:train:157 - Total loss: 540.7841186523438\n",
      "2021-08-25 10:47:41.156 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:41.159 | INFO     | src.policies:train:103 - Epoch 776 / 800\n",
      "2021-08-25 10:47:41.159 | INFO     | src.policies:train:109 - Episode 2863\n",
      "2021-08-25 10:47:41.227 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:41.229 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:41.230 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 196.28\n",
      "2021-08-25 10:47:41.234 | INFO     | src.policies:train:157 - Total loss: 551.5658569335938\n",
      "2021-08-25 10:47:41.235 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:41.238 | INFO     | src.policies:train:103 - Epoch 777 / 800\n",
      "2021-08-25 10:47:41.239 | INFO     | src.policies:train:109 - Episode 2864\n",
      "2021-08-25 10:47:41.306 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:41.308 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:41.309 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 196.57\n",
      "2021-08-25 10:47:41.314 | INFO     | src.policies:train:157 - Total loss: 532.025146484375\n",
      "2021-08-25 10:47:41.314 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:41.318 | INFO     | src.policies:train:103 - Epoch 778 / 800\n",
      "2021-08-25 10:47:41.319 | INFO     | src.policies:train:109 - Episode 2865\n",
      "2021-08-25 10:47:41.387 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:41.389 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:41.389 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 197.22\n",
      "2021-08-25 10:47:41.394 | INFO     | src.policies:train:157 - Total loss: 593.0435180664062\n",
      "2021-08-25 10:47:41.395 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:41.398 | INFO     | src.policies:train:103 - Epoch 779 / 800\n",
      "2021-08-25 10:47:41.399 | INFO     | src.policies:train:109 - Episode 2866\n",
      "2021-08-25 10:47:41.466 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:41.468 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:41.469 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 197.62\n",
      "2021-08-25 10:47:41.473 | INFO     | src.policies:train:157 - Total loss: 548.94482421875\n",
      "2021-08-25 10:47:41.474 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:41.478 | INFO     | src.policies:train:103 - Epoch 780 / 800\n",
      "2021-08-25 10:47:41.478 | INFO     | src.policies:train:109 - Episode 2867\n",
      "2021-08-25 10:47:41.548 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:41.549 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:41.550 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 198.0\n",
      "2021-08-25 10:47:41.555 | INFO     | src.policies:train:157 - Total loss: 582.1956176757812\n",
      "2021-08-25 10:47:41.556 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:41.558 | INFO     | src.policies:train:103 - Epoch 781 / 800\n",
      "2021-08-25 10:47:41.559 | INFO     | src.policies:train:109 - Episode 2868\n",
      "2021-08-25 10:47:41.628 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:41.630 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:41.631 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 198.0\n",
      "2021-08-25 10:47:41.636 | INFO     | src.policies:train:157 - Total loss: 579.1972045898438\n",
      "2021-08-25 10:47:41.636 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:41.639 | INFO     | src.policies:train:103 - Epoch 782 / 800\n",
      "2021-08-25 10:47:41.640 | INFO     | src.policies:train:109 - Episode 2869\n",
      "2021-08-25 10:47:41.708 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:41.709 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:41.710 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 198.51\n",
      "2021-08-25 10:47:41.715 | INFO     | src.policies:train:157 - Total loss: 589.6563720703125\n",
      "2021-08-25 10:47:41.715 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:41.718 | INFO     | src.policies:train:103 - Epoch 783 / 800\n",
      "2021-08-25 10:47:41.719 | INFO     | src.policies:train:109 - Episode 2870\n",
      "2021-08-25 10:47:41.785 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:41.787 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:41.788 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 199.01\n",
      "2021-08-25 10:47:41.792 | INFO     | src.policies:train:157 - Total loss: 520.0341796875\n",
      "2021-08-25 10:47:41.793 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:41.796 | INFO     | src.policies:train:103 - Epoch 784 / 800\n",
      "2021-08-25 10:47:41.796 | INFO     | src.policies:train:109 - Episode 2871\n",
      "2021-08-25 10:47:41.865 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:41.867 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:41.868 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 199.12\n",
      "2021-08-25 10:47:41.872 | INFO     | src.policies:train:157 - Total loss: 472.6501159667969\n",
      "2021-08-25 10:47:41.873 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:41.876 | INFO     | src.policies:train:103 - Epoch 785 / 800\n",
      "2021-08-25 10:47:41.877 | INFO     | src.policies:train:109 - Episode 2872\n",
      "2021-08-25 10:47:41.944 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:41.946 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:41.947 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 199.44\n",
      "2021-08-25 10:47:41.952 | INFO     | src.policies:train:157 - Total loss: 496.1777038574219\n",
      "2021-08-25 10:47:41.953 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:41.956 | INFO     | src.policies:train:103 - Epoch 786 / 800\n",
      "2021-08-25 10:47:41.957 | INFO     | src.policies:train:109 - Episode 2873\n",
      "2021-08-25 10:47:42.024 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:42.026 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:42.027 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 199.44\n",
      "2021-08-25 10:47:42.031 | INFO     | src.policies:train:157 - Total loss: 531.7139892578125\n",
      "2021-08-25 10:47:42.032 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:42.035 | INFO     | src.policies:train:103 - Epoch 787 / 800\n",
      "2021-08-25 10:47:42.035 | INFO     | src.policies:train:109 - Episode 2874\n",
      "2021-08-25 10:47:42.104 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:42.105 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:42.106 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 199.73\n",
      "2021-08-25 10:47:42.111 | INFO     | src.policies:train:157 - Total loss: 467.6954040527344\n",
      "2021-08-25 10:47:42.112 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:42.114 | INFO     | src.policies:train:103 - Epoch 788 / 800\n",
      "2021-08-25 10:47:42.115 | INFO     | src.policies:train:109 - Episode 2875\n",
      "2021-08-25 10:47:42.183 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:42.185 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:42.186 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 199.92\n",
      "2021-08-25 10:47:42.190 | INFO     | src.policies:train:157 - Total loss: 485.2875061035156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 10:47:42.191 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:42.194 | INFO     | src.policies:train:103 - Epoch 789 / 800\n",
      "2021-08-25 10:47:42.194 | INFO     | src.policies:train:109 - Episode 2876\n",
      "2021-08-25 10:47:42.263 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:42.264 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:42.265 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 200.0\n",
      "2021-08-25 10:47:42.270 | INFO     | src.policies:train:157 - Total loss: 596.014892578125\n",
      "2021-08-25 10:47:42.270 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:42.274 | INFO     | src.policies:train:103 - Epoch 790 / 800\n",
      "2021-08-25 10:47:42.275 | INFO     | src.policies:train:109 - Episode 2877\n",
      "2021-08-25 10:47:42.342 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:42.344 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:42.344 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 200.0\n",
      "2021-08-25 10:47:42.349 | INFO     | src.policies:train:157 - Total loss: 540.6973266601562\n",
      "2021-08-25 10:47:42.349 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:42.352 | INFO     | src.policies:train:103 - Epoch 791 / 800\n",
      "2021-08-25 10:47:42.353 | INFO     | src.policies:train:109 - Episode 2878\n",
      "2021-08-25 10:47:42.422 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:42.423 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:42.424 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 200.0\n",
      "2021-08-25 10:47:42.429 | INFO     | src.policies:train:157 - Total loss: 565.1511840820312\n",
      "2021-08-25 10:47:42.430 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:42.433 | INFO     | src.policies:train:103 - Epoch 792 / 800\n",
      "2021-08-25 10:47:42.434 | INFO     | src.policies:train:109 - Episode 2879\n",
      "2021-08-25 10:47:42.502 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:42.503 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:42.504 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 200.0\n",
      "2021-08-25 10:47:42.509 | INFO     | src.policies:train:157 - Total loss: 479.8475646972656\n",
      "2021-08-25 10:47:42.510 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:42.513 | INFO     | src.policies:train:103 - Epoch 793 / 800\n",
      "2021-08-25 10:47:42.514 | INFO     | src.policies:train:109 - Episode 2880\n",
      "2021-08-25 10:47:42.581 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:42.582 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:42.583 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 200.0\n",
      "2021-08-25 10:47:42.588 | INFO     | src.policies:train:157 - Total loss: 548.5396118164062\n",
      "2021-08-25 10:47:42.588 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:42.591 | INFO     | src.policies:train:103 - Epoch 794 / 800\n",
      "2021-08-25 10:47:42.592 | INFO     | src.policies:train:109 - Episode 2881\n",
      "2021-08-25 10:47:42.664 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:42.666 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:42.667 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 200.0\n",
      "2021-08-25 10:47:42.673 | INFO     | src.policies:train:157 - Total loss: 556.837890625\n",
      "2021-08-25 10:47:42.674 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:42.678 | INFO     | src.policies:train:103 - Epoch 795 / 800\n",
      "2021-08-25 10:47:42.679 | INFO     | src.policies:train:109 - Episode 2882\n",
      "2021-08-25 10:47:42.750 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:42.751 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:42.753 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 200.0\n",
      "2021-08-25 10:47:42.759 | INFO     | src.policies:train:157 - Total loss: 577.3617553710938\n",
      "2021-08-25 10:47:42.760 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:42.764 | INFO     | src.policies:train:103 - Epoch 796 / 800\n",
      "2021-08-25 10:47:42.765 | INFO     | src.policies:train:109 - Episode 2883\n",
      "2021-08-25 10:47:42.835 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:42.837 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:42.838 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 200.0\n",
      "2021-08-25 10:47:42.842 | INFO     | src.policies:train:157 - Total loss: 466.2358703613281\n",
      "2021-08-25 10:47:42.843 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:42.846 | INFO     | src.policies:train:103 - Epoch 797 / 800\n",
      "2021-08-25 10:47:42.847 | INFO     | src.policies:train:109 - Episode 2884\n",
      "2021-08-25 10:47:42.915 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:42.917 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:42.918 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 200.0\n",
      "2021-08-25 10:47:42.923 | INFO     | src.policies:train:157 - Total loss: 510.0298767089844\n",
      "2021-08-25 10:47:42.924 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:42.928 | INFO     | src.policies:train:103 - Epoch 798 / 800\n",
      "2021-08-25 10:47:42.929 | INFO     | src.policies:train:109 - Episode 2885\n",
      "2021-08-25 10:47:43.000 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:43.002 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:43.003 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 200.0\n",
      "2021-08-25 10:47:43.009 | INFO     | src.policies:train:157 - Total loss: 478.7526550292969\n",
      "2021-08-25 10:47:43.010 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:43.014 | INFO     | src.policies:train:103 - Epoch 799 / 800\n",
      "2021-08-25 10:47:43.015 | INFO     | src.policies:train:109 - Episode 2886\n",
      "2021-08-25 10:47:43.085 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:43.087 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:43.088 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 200.0\n",
      "2021-08-25 10:47:43.092 | INFO     | src.policies:train:157 - Total loss: 426.5714416503906\n",
      "2021-08-25 10:47:43.093 | INFO     | src.policies:train:161 - Epoch infos: {}\n",
      "2021-08-25 10:47:43.096 | INFO     | src.policies:train:103 - Epoch 800 / 800\n",
      "2021-08-25 10:47:43.097 | INFO     | src.policies:train:109 - Episode 2887\n",
      "2021-08-25 10:47:43.166 | DEBUG    | src.policies:execute_episode:266 - Early stopping, all agents done\n",
      "2021-08-25 10:47:43.167 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 10:47:43.168 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 200.0\n",
      "2021-08-25 10:47:43.174 | INFO     | src.policies:train:157 - Total loss: 577.8089599609375\n",
      "2021-08-25 10:47:43.175 | INFO     | src.policies:train:161 - Epoch infos: {}\n"
     ]
    }
   ],
   "source": [
    "vpg_policy_nn = models.MLP(observation_space_size, hidden_sizes, action_space_size)\n",
    "vpg_baseline_nn = models.MLP(observation_space_size, hidden_sizes, 1, log_softmax=False)\n",
    "vpg_policy = policies.VPGPolicy(env, vpg_policy_nn, baseline_nn=vpg_baseline_nn)\n",
    "vpg_policy.train(\n",
    "    epochs,\n",
    "    steps_per_epoch,\n",
    "    enable_wandb=False,\n",
    "    episodes_mean_reward=episodes_mean_reward\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503ea7aa",
   "metadata": {},
   "source": [
    "## TRPO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68972e5e",
   "metadata": {},
   "source": [
    "This section deals with training a Cartpole agent using our custom Trust Region Policy Optimization implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdddef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 1.0\n",
    "kl_target = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f959403",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:27.623 | INFO     | src.policies:train:103 - Epoch 1 / 800\n",
      "2021-08-25 11:17:27.624 | INFO     | src.policies:train:109 - Episode 1\n",
      "2021-08-25 11:17:27.647 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:27.648 | INFO     | src.policies:train:121 - Mean episode return: 73.0\n",
      "2021-08-25 11:17:27.649 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 73.0\n",
      "2021-08-25 11:17:27.650 | INFO     | src.policies:train:109 - Episode 2\n",
      "2021-08-25 11:17:27.658 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:27.659 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:17:27.660 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 43.0\n",
      "2021-08-25 11:17:27.661 | INFO     | src.policies:train:109 - Episode 3\n",
      "2021-08-25 11:17:27.669 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:27.670 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:17:27.671 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.333333333333336\n",
      "2021-08-25 11:17:27.672 | INFO     | src.policies:train:109 - Episode 4\n",
      "2021-08-25 11:17:27.686 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:27.687 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 11:17:27.688 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.25\n",
      "2021-08-25 11:17:27.689 | INFO     | src.policies:train:109 - Episode 5\n",
      "2021-08-25 11:17:27.701 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:27.702 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:17:27.703 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.2\n",
      "2021-08-25 11:17:27.704 | INFO     | src.policies:train:109 - Episode 6\n",
      "2021-08-25 11:17:27.711 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:27.712 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:17:27.713 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.833333333333332\n",
      "2021-08-25 11:17:27.714 | INFO     | src.policies:train:109 - Episode 7\n",
      "2021-08-25 11:17:27.728 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:27.729 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 11:17:27.730 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.285714285714285\n",
      "2021-08-25 11:17:27.731 | WARNING  | src.policies:train:131 - The actual batch size is 212, instead of 200\n",
      "2021-08-25 11:17:27.736 | INFO     | src.policies:train:157 - Total loss: 1.167586326599121\n",
      "2021-08-25 11:17:27.739 | INFO     | src.policies:train:103 - Epoch 2 / 800\n",
      "2021-08-25 11:17:27.740 | INFO     | src.policies:train:109 - Episode 8\n",
      "2021-08-25 11:17:27.749 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:27.750 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:17:27.751 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.125\n",
      "2021-08-25 11:17:27.752 | INFO     | src.policies:train:109 - Episode 9\n",
      "2021-08-25 11:17:27.767 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:27.768 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 11:17:27.769 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.0\n",
      "2021-08-25 11:17:27.770 | INFO     | src.policies:train:109 - Episode 10\n",
      "2021-08-25 11:17:27.776 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:27.777 | INFO     | src.policies:train:121 - Mean episode return: 9.0\n",
      "2021-08-25 11:17:27.778 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.9\n",
      "2021-08-25 11:17:27.779 | INFO     | src.policies:train:109 - Episode 11\n",
      "2021-08-25 11:17:27.794 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:27.795 | INFO     | src.policies:train:121 - Mean episode return: 39.0\n",
      "2021-08-25 11:17:27.796 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.90909090909091\n",
      "2021-08-25 11:17:27.797 | INFO     | src.policies:train:109 - Episode 12\n",
      "2021-08-25 11:17:27.814 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:27.816 | INFO     | src.policies:train:121 - Mean episode return: 41.0\n",
      "2021-08-25 11:17:27.816 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.916666666666668\n",
      "2021-08-25 11:17:27.817 | INFO     | src.policies:train:109 - Episode 13\n",
      "2021-08-25 11:17:27.829 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:27.831 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:17:27.831 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.615384615384617\n",
      "2021-08-25 11:17:27.832 | INFO     | src.policies:train:109 - Episode 14\n",
      "2021-08-25 11:17:27.842 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:27.843 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:17:27.843 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.857142857142858\n",
      "2021-08-25 11:17:27.844 | INFO     | src.policies:train:109 - Episode 15\n",
      "2021-08-25 11:17:27.858 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:27.859 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 11:17:27.860 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.066666666666666\n",
      "2021-08-25 11:17:27.861 | WARNING  | src.policies:train:131 - The actual batch size is 224, instead of 200\n",
      "2021-08-25 11:17:27.868 | INFO     | src.policies:train:157 - Total loss: 1.1550800800323486\n",
      "2021-08-25 11:17:27.871 | INFO     | src.policies:train:103 - Epoch 3 / 800\n",
      "2021-08-25 11:17:27.873 | INFO     | src.policies:train:109 - Episode 16\n",
      "2021-08-25 11:17:27.891 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:27.892 | INFO     | src.policies:train:121 - Mean episode return: 49.0\n",
      "2021-08-25 11:17:27.893 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.3125\n",
      "2021-08-25 11:17:27.894 | INFO     | src.policies:train:109 - Episode 17\n",
      "2021-08-25 11:17:27.908 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:27.908 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 11:17:27.909 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.352941176470587\n",
      "2021-08-25 11:17:27.910 | INFO     | src.policies:train:109 - Episode 18\n",
      "2021-08-25 11:17:27.921 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:27.922 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:17:27.923 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.0\n",
      "2021-08-25 11:17:27.924 | INFO     | src.policies:train:109 - Episode 19\n",
      "2021-08-25 11:17:27.931 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:27.932 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:17:27.933 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.05263157894737\n",
      "2021-08-25 11:17:27.934 | INFO     | src.policies:train:109 - Episode 20\n",
      "2021-08-25 11:17:27.943 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:27.944 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:17:27.945 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.65\n",
      "2021-08-25 11:17:27.946 | INFO     | src.policies:train:109 - Episode 21\n",
      "2021-08-25 11:17:27.957 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:27.958 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:17:27.959 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.333333333333332\n",
      "2021-08-25 11:17:27.960 | INFO     | src.policies:train:109 - Episode 22\n",
      "2021-08-25 11:17:27.967 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:27.969 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:17:27.970 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.59090909090909\n",
      "2021-08-25 11:17:27.971 | INFO     | src.policies:train:109 - Episode 23\n",
      "2021-08-25 11:17:27.987 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:27.989 | INFO     | src.policies:train:121 - Mean episode return: 43.0\n",
      "2021-08-25 11:17:27.989 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.26086956521739\n",
      "2021-08-25 11:17:27.990 | WARNING  | src.policies:train:131 - The actual batch size is 214, instead of 200\n",
      "2021-08-25 11:17:27.997 | INFO     | src.policies:train:157 - Total loss: 1.1274653673171997\n",
      "2021-08-25 11:17:27.999 | INFO     | src.policies:train:103 - Epoch 4 / 800\n",
      "2021-08-25 11:17:28.000 | INFO     | src.policies:train:109 - Episode 24\n",
      "2021-08-25 11:17:28.010 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:28.012 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 11:17:28.013 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.125\n",
      "2021-08-25 11:17:28.013 | INFO     | src.policies:train:109 - Episode 25\n",
      "2021-08-25 11:17:28.022 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:28.023 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:17:28.024 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.64\n",
      "2021-08-25 11:17:28.025 | INFO     | src.policies:train:109 - Episode 26\n",
      "2021-08-25 11:17:28.032 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:28.033 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:17:28.034 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.153846153846153\n",
      "2021-08-25 11:17:28.035 | INFO     | src.policies:train:109 - Episode 27\n",
      "2021-08-25 11:17:28.044 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:28.045 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:17:28.046 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.88888888888889\n",
      "2021-08-25 11:17:28.047 | INFO     | src.policies:train:109 - Episode 28\n",
      "2021-08-25 11:17:28.055 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:28.057 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:17:28.057 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.607142857142858\n",
      "2021-08-25 11:17:28.058 | INFO     | src.policies:train:109 - Episode 29\n",
      "2021-08-25 11:17:28.066 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:28.068 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:17:28.068 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.20689655172414\n",
      "2021-08-25 11:17:28.069 | INFO     | src.policies:train:109 - Episode 30\n",
      "2021-08-25 11:17:28.077 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:28.079 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:17:28.079 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.833333333333332\n",
      "2021-08-25 11:17:28.080 | INFO     | src.policies:train:109 - Episode 31\n",
      "2021-08-25 11:17:28.090 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:28.091 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:17:28.092 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.741935483870968\n",
      "2021-08-25 11:17:28.093 | INFO     | src.policies:train:109 - Episode 32\n",
      "2021-08-25 11:17:28.100 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:28.101 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:17:28.102 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.28125\n",
      "2021-08-25 11:17:28.102 | INFO     | src.policies:train:109 - Episode 33\n",
      "2021-08-25 11:17:28.111 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:28.112 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:17:28.113 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.060606060606062\n",
      "2021-08-25 11:17:28.114 | INFO     | src.policies:train:109 - Episode 34\n",
      "2021-08-25 11:17:28.120 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:28.121 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:17:28.122 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.647058823529413\n",
      "2021-08-25 11:17:28.123 | INFO     | src.policies:train:109 - Episode 35\n",
      "2021-08-25 11:17:28.141 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:28.142 | INFO     | src.policies:train:121 - Mean episode return: 50.0\n",
      "2021-08-25 11:17:28.143 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.37142857142857\n",
      "2021-08-25 11:17:28.144 | WARNING  | src.policies:train:131 - The actual batch size is 238, instead of 200\n",
      "2021-08-25 11:17:28.150 | INFO     | src.policies:train:157 - Total loss: 1.0845164060592651\n",
      "2021-08-25 11:17:28.153 | INFO     | src.policies:train:103 - Epoch 5 / 800\n",
      "2021-08-25 11:17:28.154 | INFO     | src.policies:train:109 - Episode 36\n",
      "2021-08-25 11:17:28.162 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:28.163 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:17:28.164 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.13888888888889\n",
      "2021-08-25 11:17:28.165 | INFO     | src.policies:train:109 - Episode 37\n",
      "2021-08-25 11:17:28.180 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:28.181 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 11:17:28.182 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.405405405405407\n",
      "2021-08-25 11:17:28.183 | INFO     | src.policies:train:109 - Episode 38\n",
      "2021-08-25 11:17:28.196 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:28.198 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 11:17:28.199 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.63157894736842\n",
      "2021-08-25 11:17:28.199 | INFO     | src.policies:train:109 - Episode 39\n",
      "2021-08-25 11:17:28.218 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:28.219 | INFO     | src.policies:train:121 - Mean episode return: 51.0\n",
      "2021-08-25 11:17:28.220 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.28205128205128\n",
      "2021-08-25 11:17:28.221 | INFO     | src.policies:train:109 - Episode 40\n",
      "2021-08-25 11:17:28.238 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:28.240 | INFO     | src.policies:train:121 - Mean episode return: 47.0\n",
      "2021-08-25 11:17:28.240 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.8\n",
      "2021-08-25 11:17:28.241 | INFO     | src.policies:train:109 - Episode 41\n",
      "2021-08-25 11:17:28.253 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:28.254 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:17:28.254 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.78048780487805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:28.255 | WARNING  | src.policies:train:131 - The actual batch size is 210, instead of 200\n",
      "2021-08-25 11:17:28.261 | INFO     | src.policies:train:157 - Total loss: 1.1009654998779297\n",
      "2021-08-25 11:17:28.263 | INFO     | src.policies:train:103 - Epoch 6 / 800\n",
      "2021-08-25 11:17:28.264 | INFO     | src.policies:train:109 - Episode 42\n",
      "2021-08-25 11:17:28.274 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:28.275 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:17:28.275 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.666666666666668\n",
      "2021-08-25 11:17:28.276 | INFO     | src.policies:train:109 - Episode 43\n",
      "2021-08-25 11:17:28.283 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:28.284 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:17:28.285 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.325581395348838\n",
      "2021-08-25 11:17:28.286 | INFO     | src.policies:train:109 - Episode 44\n",
      "2021-08-25 11:17:28.296 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:28.297 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:17:28.298 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.25\n",
      "2021-08-25 11:17:28.299 | INFO     | src.policies:train:109 - Episode 45\n",
      "2021-08-25 11:17:28.308 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:28.308 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:17:28.309 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.08888888888889\n",
      "2021-08-25 11:17:28.310 | INFO     | src.policies:train:109 - Episode 46\n",
      "2021-08-25 11:17:28.317 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:28.318 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:17:28.319 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.76086956521739\n",
      "2021-08-25 11:17:28.320 | INFO     | src.policies:train:109 - Episode 47\n",
      "2021-08-25 11:17:28.327 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:28.328 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:17:28.329 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.5531914893617\n",
      "2021-08-25 11:17:28.329 | INFO     | src.policies:train:109 - Episode 48\n",
      "2021-08-25 11:17:28.336 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:28.337 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:17:28.338 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.3125\n",
      "2021-08-25 11:17:28.339 | INFO     | src.policies:train:109 - Episode 49\n",
      "2021-08-25 11:17:28.348 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:28.349 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:17:28.350 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.224489795918366\n",
      "2021-08-25 11:17:28.351 | INFO     | src.policies:train:109 - Episode 50\n",
      "2021-08-25 11:17:28.358 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:28.359 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:17:28.360 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.98\n",
      "2021-08-25 11:17:28.361 | INFO     | src.policies:train:109 - Episode 51\n",
      "2021-08-25 11:17:28.370 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:28.371 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:17:28.372 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.901960784313726\n",
      "2021-08-25 11:17:28.373 | INFO     | src.policies:train:109 - Episode 52\n",
      "2021-08-25 11:17:28.392 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:28.393 | INFO     | src.policies:train:121 - Mean episode return: 51.0\n",
      "2021-08-25 11:17:28.394 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.403846153846153\n",
      "2021-08-25 11:17:28.395 | WARNING  | src.policies:train:131 - The actual batch size is 223, instead of 200\n",
      "2021-08-25 11:17:28.401 | INFO     | src.policies:train:157 - Total loss: 1.089806079864502\n",
      "2021-08-25 11:17:28.404 | INFO     | src.policies:train:103 - Epoch 7 / 800\n",
      "2021-08-25 11:17:28.405 | INFO     | src.policies:train:109 - Episode 53\n",
      "2021-08-25 11:17:28.413 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:28.414 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:17:28.415 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.30188679245283\n",
      "2021-08-25 11:17:28.415 | INFO     | src.policies:train:109 - Episode 54\n",
      "2021-08-25 11:17:28.426 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:28.427 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 11:17:28.428 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.296296296296298\n",
      "2021-08-25 11:17:28.429 | INFO     | src.policies:train:109 - Episode 55\n",
      "2021-08-25 11:17:28.442 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:28.443 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 11:17:28.444 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.436363636363637\n",
      "2021-08-25 11:17:28.444 | INFO     | src.policies:train:109 - Episode 56\n",
      "2021-08-25 11:17:28.463 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:28.464 | INFO     | src.policies:train:121 - Mean episode return: 51.0\n",
      "2021-08-25 11:17:28.465 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.892857142857142\n",
      "2021-08-25 11:17:28.466 | INFO     | src.policies:train:109 - Episode 57\n",
      "2021-08-25 11:17:28.472 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:28.473 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 11:17:28.473 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.614035087719298\n",
      "2021-08-25 11:17:28.474 | INFO     | src.policies:train:109 - Episode 58\n",
      "2021-08-25 11:17:28.484 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:28.485 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:17:28.486 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.53448275862069\n",
      "2021-08-25 11:17:28.487 | INFO     | src.policies:train:109 - Episode 59\n",
      "2021-08-25 11:17:28.495 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:28.497 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:17:28.498 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.322033898305083\n",
      "2021-08-25 11:17:28.499 | INFO     | src.policies:train:109 - Episode 60\n",
      "2021-08-25 11:17:28.512 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:28.513 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:17:28.514 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.25\n",
      "2021-08-25 11:17:28.515 | INFO     | src.policies:train:109 - Episode 61\n",
      "2021-08-25 11:17:28.525 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:28.526 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:17:28.527 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.147540983606557\n",
      "2021-08-25 11:17:28.528 | WARNING  | src.policies:train:131 - The actual batch size is 213, instead of 200\n",
      "2021-08-25 11:17:28.534 | INFO     | src.policies:train:157 - Total loss: 1.0588774681091309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:28.536 | INFO     | src.policies:train:103 - Epoch 8 / 800\n",
      "2021-08-25 11:17:28.537 | INFO     | src.policies:train:109 - Episode 62\n",
      "2021-08-25 11:17:28.555 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:28.556 | INFO     | src.policies:train:121 - Mean episode return: 50.0\n",
      "2021-08-25 11:17:28.557 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.548387096774192\n",
      "2021-08-25 11:17:28.558 | INFO     | src.policies:train:109 - Episode 63\n",
      "2021-08-25 11:17:28.589 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:28.591 | INFO     | src.policies:train:121 - Mean episode return: 89.0\n",
      "2021-08-25 11:17:28.591 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.555555555555557\n",
      "2021-08-25 11:17:28.592 | INFO     | src.policies:train:109 - Episode 64\n",
      "2021-08-25 11:17:28.624 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:28.625 | INFO     | src.policies:train:121 - Mean episode return: 86.0\n",
      "2021-08-25 11:17:28.626 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.484375\n",
      "2021-08-25 11:17:28.627 | WARNING  | src.policies:train:131 - The actual batch size is 225, instead of 200\n",
      "2021-08-25 11:17:28.633 | INFO     | src.policies:train:157 - Total loss: 1.0633069276809692\n",
      "2021-08-25 11:17:28.635 | INFO     | src.policies:train:103 - Epoch 9 / 800\n",
      "2021-08-25 11:17:28.636 | INFO     | src.policies:train:109 - Episode 65\n",
      "2021-08-25 11:17:28.643 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:28.644 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:17:28.645 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.29230769230769\n",
      "2021-08-25 11:17:28.645 | INFO     | src.policies:train:109 - Episode 66\n",
      "2021-08-25 11:17:28.656 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:28.657 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:17:28.658 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.242424242424242\n",
      "2021-08-25 11:17:28.659 | INFO     | src.policies:train:109 - Episode 67\n",
      "2021-08-25 11:17:28.669 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:28.670 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:17:28.671 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.149253731343283\n",
      "2021-08-25 11:17:28.671 | INFO     | src.policies:train:109 - Episode 68\n",
      "2021-08-25 11:17:28.681 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:28.682 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:17:28.683 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.058823529411764\n",
      "2021-08-25 11:17:28.684 | INFO     | src.policies:train:109 - Episode 69\n",
      "2021-08-25 11:17:28.701 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:28.703 | INFO     | src.policies:train:121 - Mean episode return: 41.0\n",
      "2021-08-25 11:17:28.703 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.26086956521739\n",
      "2021-08-25 11:17:28.704 | INFO     | src.policies:train:109 - Episode 70\n",
      "2021-08-25 11:17:28.723 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:28.724 | INFO     | src.policies:train:121 - Mean episode return: 51.0\n",
      "2021-08-25 11:17:28.724 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.6\n",
      "2021-08-25 11:17:28.725 | INFO     | src.policies:train:109 - Episode 71\n",
      "2021-08-25 11:17:28.732 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:28.733 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:17:28.734 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.408450704225352\n",
      "2021-08-25 11:17:28.735 | INFO     | src.policies:train:109 - Episode 72\n",
      "2021-08-25 11:17:28.742 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:28.743 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:17:28.744 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.194444444444443\n",
      "2021-08-25 11:17:28.744 | INFO     | src.policies:train:109 - Episode 73\n",
      "2021-08-25 11:17:28.753 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:28.754 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:17:28.755 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.123287671232877\n",
      "2021-08-25 11:17:28.756 | WARNING  | src.policies:train:131 - The actual batch size is 221, instead of 200\n",
      "2021-08-25 11:17:28.762 | INFO     | src.policies:train:157 - Total loss: 1.026004672050476\n",
      "2021-08-25 11:17:28.764 | INFO     | src.policies:train:103 - Epoch 10 / 800\n",
      "2021-08-25 11:17:28.765 | INFO     | src.policies:train:109 - Episode 74\n",
      "2021-08-25 11:17:28.771 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:28.772 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:17:28.773 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.91891891891892\n",
      "2021-08-25 11:17:28.773 | INFO     | src.policies:train:109 - Episode 75\n",
      "2021-08-25 11:17:28.784 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:28.785 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:17:28.785 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.866666666666667\n",
      "2021-08-25 11:17:28.786 | INFO     | src.policies:train:109 - Episode 76\n",
      "2021-08-25 11:17:28.798 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:28.799 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:17:28.800 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.855263157894736\n",
      "2021-08-25 11:17:28.800 | INFO     | src.policies:train:109 - Episode 77\n",
      "2021-08-25 11:17:28.809 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:28.811 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:17:28.811 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.766233766233768\n",
      "2021-08-25 11:17:28.812 | INFO     | src.policies:train:109 - Episode 78\n",
      "2021-08-25 11:17:28.829 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:28.830 | INFO     | src.policies:train:121 - Mean episode return: 47.0\n",
      "2021-08-25 11:17:28.831 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.025641025641026\n",
      "2021-08-25 11:17:28.832 | INFO     | src.policies:train:109 - Episode 79\n",
      "2021-08-25 11:17:28.843 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:28.844 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:17:28.845 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.0126582278481\n",
      "2021-08-25 11:17:28.845 | INFO     | src.policies:train:109 - Episode 80\n",
      "2021-08-25 11:17:28.853 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:28.854 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:17:28.855 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.8625\n",
      "2021-08-25 11:17:28.856 | INFO     | src.policies:train:109 - Episode 81\n",
      "2021-08-25 11:17:28.868 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:28.869 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 11:17:28.870 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.901234567901234\n",
      "2021-08-25 11:17:28.871 | INFO     | src.policies:train:109 - Episode 82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:28.885 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:28.886 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 11:17:28.887 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.98780487804878\n",
      "2021-08-25 11:17:28.888 | WARNING  | src.policies:train:131 - The actual batch size is 233, instead of 200\n",
      "2021-08-25 11:17:28.894 | INFO     | src.policies:train:157 - Total loss: 1.0239838361740112\n",
      "2021-08-25 11:17:28.896 | INFO     | src.policies:train:103 - Epoch 11 / 800\n",
      "2021-08-25 11:17:28.897 | INFO     | src.policies:train:109 - Episode 83\n",
      "2021-08-25 11:17:28.915 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:28.916 | INFO     | src.policies:train:121 - Mean episode return: 50.0\n",
      "2021-08-25 11:17:28.917 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.265060240963855\n",
      "2021-08-25 11:17:28.918 | INFO     | src.policies:train:109 - Episode 84\n",
      "2021-08-25 11:17:28.926 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:28.927 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:17:28.927 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.13095238095238\n",
      "2021-08-25 11:17:28.928 | INFO     | src.policies:train:109 - Episode 85\n",
      "2021-08-25 11:17:28.935 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:28.936 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 11:17:28.937 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.929411764705883\n",
      "2021-08-25 11:17:28.938 | INFO     | src.policies:train:109 - Episode 86\n",
      "2021-08-25 11:17:28.945 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:28.946 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:17:28.947 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.790697674418606\n",
      "2021-08-25 11:17:28.947 | INFO     | src.policies:train:109 - Episode 87\n",
      "2021-08-25 11:17:28.960 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:28.961 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:17:28.962 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.816091954022987\n",
      "2021-08-25 11:17:28.963 | INFO     | src.policies:train:109 - Episode 88\n",
      "2021-08-25 11:17:28.970 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:28.971 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:17:28.971 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.65909090909091\n",
      "2021-08-25 11:17:28.972 | INFO     | src.policies:train:109 - Episode 89\n",
      "2021-08-25 11:17:28.980 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:28.981 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:17:28.982 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.528089887640448\n",
      "2021-08-25 11:17:28.982 | INFO     | src.policies:train:109 - Episode 90\n",
      "2021-08-25 11:17:29.002 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.003 | INFO     | src.policies:train:121 - Mean episode return: 54.0\n",
      "2021-08-25 11:17:29.003 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.833333333333332\n",
      "2021-08-25 11:17:29.004 | WARNING  | src.policies:train:131 - The actual batch size is 202, instead of 200\n",
      "2021-08-25 11:17:29.010 | INFO     | src.policies:train:157 - Total loss: 1.0076502561569214\n",
      "2021-08-25 11:17:29.012 | INFO     | src.policies:train:103 - Epoch 12 / 800\n",
      "2021-08-25 11:17:29.013 | INFO     | src.policies:train:109 - Episode 91\n",
      "2021-08-25 11:17:29.020 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.021 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:17:29.022 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.692307692307693\n",
      "2021-08-25 11:17:29.023 | INFO     | src.policies:train:109 - Episode 92\n",
      "2021-08-25 11:17:29.029 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.030 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:17:29.031 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.554347826086957\n",
      "2021-08-25 11:17:29.032 | INFO     | src.policies:train:109 - Episode 93\n",
      "2021-08-25 11:17:29.038 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.039 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:17:29.040 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.387096774193548\n",
      "2021-08-25 11:17:29.041 | INFO     | src.policies:train:109 - Episode 94\n",
      "2021-08-25 11:17:29.050 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.051 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:17:29.052 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.329787234042552\n",
      "2021-08-25 11:17:29.052 | INFO     | src.policies:train:109 - Episode 95\n",
      "2021-08-25 11:17:29.064 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.065 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 11:17:29.066 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.378947368421052\n",
      "2021-08-25 11:17:29.067 | INFO     | src.policies:train:109 - Episode 96\n",
      "2021-08-25 11:17:29.076 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.077 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:17:29.078 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.291666666666668\n",
      "2021-08-25 11:17:29.079 | INFO     | src.policies:train:109 - Episode 97\n",
      "2021-08-25 11:17:29.087 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.088 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:17:29.089 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.216494845360824\n",
      "2021-08-25 11:17:29.090 | INFO     | src.policies:train:109 - Episode 98\n",
      "2021-08-25 11:17:29.096 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.097 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 11:17:29.098 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.051020408163264\n",
      "2021-08-25 11:17:29.099 | INFO     | src.policies:train:109 - Episode 99\n",
      "2021-08-25 11:17:29.115 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.116 | INFO     | src.policies:train:121 - Mean episode return: 43.0\n",
      "2021-08-25 11:17:29.117 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.22222222222222\n",
      "2021-08-25 11:17:29.118 | INFO     | src.policies:train:109 - Episode 100\n",
      "2021-08-25 11:17:29.126 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.127 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:17:29.128 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.12\n",
      "2021-08-25 11:17:29.129 | INFO     | src.policies:train:109 - Episode 101\n",
      "2021-08-25 11:17:29.136 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.138 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:17:29.138 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.54\n",
      "2021-08-25 11:17:29.139 | WARNING  | src.policies:train:131 - The actual batch size is 212, instead of 200\n",
      "2021-08-25 11:17:29.145 | INFO     | src.policies:train:157 - Total loss: 0.9943472743034363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:29.147 | INFO     | src.policies:train:103 - Epoch 13 / 800\n",
      "2021-08-25 11:17:29.148 | INFO     | src.policies:train:109 - Episode 102\n",
      "2021-08-25 11:17:29.157 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.158 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:17:29.159 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.6\n",
      "2021-08-25 11:17:29.159 | INFO     | src.policies:train:109 - Episode 103\n",
      "2021-08-25 11:17:29.167 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.168 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:17:29.169 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.61\n",
      "2021-08-25 11:17:29.170 | INFO     | src.policies:train:109 - Episode 104\n",
      "2021-08-25 11:17:29.184 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.185 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 11:17:29.185 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.58\n",
      "2021-08-25 11:17:29.186 | INFO     | src.policies:train:109 - Episode 105\n",
      "2021-08-25 11:17:29.193 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.194 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:17:29.195 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.41\n",
      "2021-08-25 11:17:29.196 | INFO     | src.policies:train:109 - Episode 106\n",
      "2021-08-25 11:17:29.202 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.203 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:17:29.204 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.39\n",
      "2021-08-25 11:17:29.205 | INFO     | src.policies:train:109 - Episode 107\n",
      "2021-08-25 11:17:29.237 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.238 | INFO     | src.policies:train:121 - Mean episode return: 90.0\n",
      "2021-08-25 11:17:29.238 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.96\n",
      "2021-08-25 11:17:29.239 | INFO     | src.policies:train:109 - Episode 108\n",
      "2021-08-25 11:17:29.260 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.261 | INFO     | src.policies:train:121 - Mean episode return: 59.0\n",
      "2021-08-25 11:17:29.261 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.34\n",
      "2021-08-25 11:17:29.262 | WARNING  | src.policies:train:131 - The actual batch size is 240, instead of 200\n",
      "2021-08-25 11:17:29.268 | INFO     | src.policies:train:157 - Total loss: 0.9970916509628296\n",
      "2021-08-25 11:17:29.271 | INFO     | src.policies:train:103 - Epoch 14 / 800\n",
      "2021-08-25 11:17:29.272 | INFO     | src.policies:train:109 - Episode 109\n",
      "2021-08-25 11:17:29.284 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.285 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 11:17:29.286 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.27\n",
      "2021-08-25 11:17:29.286 | INFO     | src.policies:train:109 - Episode 110\n",
      "2021-08-25 11:17:29.294 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.295 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:17:29.295 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.3\n",
      "2021-08-25 11:17:29.296 | INFO     | src.policies:train:109 - Episode 111\n",
      "2021-08-25 11:17:29.310 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.311 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 11:17:29.312 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.28\n",
      "2021-08-25 11:17:29.313 | INFO     | src.policies:train:109 - Episode 112\n",
      "2021-08-25 11:17:29.320 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.321 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 11:17:29.321 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.97\n",
      "2021-08-25 11:17:29.322 | INFO     | src.policies:train:109 - Episode 113\n",
      "2021-08-25 11:17:29.331 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.332 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:17:29.333 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.89\n",
      "2021-08-25 11:17:29.334 | INFO     | src.policies:train:109 - Episode 114\n",
      "2021-08-25 11:17:29.347 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.348 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 11:17:29.349 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.03\n",
      "2021-08-25 11:17:29.350 | INFO     | src.policies:train:109 - Episode 115\n",
      "2021-08-25 11:17:29.358 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.359 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:17:29.360 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.86\n",
      "2021-08-25 11:17:29.361 | INFO     | src.policies:train:109 - Episode 116\n",
      "2021-08-25 11:17:29.373 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.374 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 11:17:29.375 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.67\n",
      "2021-08-25 11:17:29.376 | INFO     | src.policies:train:109 - Episode 117\n",
      "2021-08-25 11:17:29.400 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.401 | INFO     | src.policies:train:121 - Mean episode return: 65.0\n",
      "2021-08-25 11:17:29.402 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.01\n",
      "2021-08-25 11:17:29.402 | WARNING  | src.policies:train:131 - The actual batch size is 250, instead of 200\n",
      "2021-08-25 11:17:29.408 | INFO     | src.policies:train:157 - Total loss: 1.0044100284576416\n",
      "2021-08-25 11:17:29.410 | INFO     | src.policies:train:103 - Epoch 15 / 800\n",
      "2021-08-25 11:17:29.411 | INFO     | src.policies:train:109 - Episode 118\n",
      "2021-08-25 11:17:29.425 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.427 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 11:17:29.427 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.17\n",
      "2021-08-25 11:17:29.428 | INFO     | src.policies:train:109 - Episode 119\n",
      "2021-08-25 11:17:29.436 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.437 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:17:29.438 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.19\n",
      "2021-08-25 11:17:29.439 | INFO     | src.policies:train:109 - Episode 120\n",
      "2021-08-25 11:17:29.445 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.446 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:17:29.447 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.09\n",
      "2021-08-25 11:17:29.448 | INFO     | src.policies:train:109 - Episode 121\n",
      "2021-08-25 11:17:29.466 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.467 | INFO     | src.policies:train:121 - Mean episode return: 49.0\n",
      "2021-08-25 11:17:29.468 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.36\n",
      "2021-08-25 11:17:29.469 | INFO     | src.policies:train:109 - Episode 122\n",
      "2021-08-25 11:17:29.477 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.479 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:29.479 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.41\n",
      "2021-08-25 11:17:29.480 | INFO     | src.policies:train:109 - Episode 123\n",
      "2021-08-25 11:17:29.499 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.500 | INFO     | src.policies:train:121 - Mean episode return: 48.0\n",
      "2021-08-25 11:17:29.501 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.46\n",
      "2021-08-25 11:17:29.502 | INFO     | src.policies:train:109 - Episode 124\n",
      "2021-08-25 11:17:29.509 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.510 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:17:29.511 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.37\n",
      "2021-08-25 11:17:29.512 | INFO     | src.policies:train:109 - Episode 125\n",
      "2021-08-25 11:17:29.522 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.523 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:17:29.523 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.39\n",
      "2021-08-25 11:17:29.524 | WARNING  | src.policies:train:131 - The actual batch size is 213, instead of 200\n",
      "2021-08-25 11:17:29.530 | INFO     | src.policies:train:157 - Total loss: 0.9994030594825745\n",
      "2021-08-25 11:17:29.532 | INFO     | src.policies:train:103 - Epoch 16 / 800\n",
      "2021-08-25 11:17:29.533 | INFO     | src.policies:train:109 - Episode 126\n",
      "2021-08-25 11:17:29.539 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.540 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:17:29.541 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.36\n",
      "2021-08-25 11:17:29.541 | INFO     | src.policies:train:109 - Episode 127\n",
      "2021-08-25 11:17:29.549 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.550 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:17:29.551 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.32\n",
      "2021-08-25 11:17:29.552 | INFO     | src.policies:train:109 - Episode 128\n",
      "2021-08-25 11:17:29.560 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.561 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:17:29.562 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.31\n",
      "2021-08-25 11:17:29.563 | INFO     | src.policies:train:109 - Episode 129\n",
      "2021-08-25 11:17:29.571 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.572 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:17:29.572 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.34\n",
      "2021-08-25 11:17:29.573 | INFO     | src.policies:train:109 - Episode 130\n",
      "2021-08-25 11:17:29.581 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.582 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:17:29.583 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.34\n",
      "2021-08-25 11:17:29.584 | INFO     | src.policies:train:109 - Episode 131\n",
      "2021-08-25 11:17:29.590 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.591 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 11:17:29.592 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.21\n",
      "2021-08-25 11:17:29.593 | INFO     | src.policies:train:109 - Episode 132\n",
      "2021-08-25 11:17:29.599 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.600 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:17:29.601 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.22\n",
      "2021-08-25 11:17:29.602 | INFO     | src.policies:train:109 - Episode 133\n",
      "2021-08-25 11:17:29.611 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.612 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:17:29.613 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.23\n",
      "2021-08-25 11:17:29.614 | INFO     | src.policies:train:109 - Episode 134\n",
      "2021-08-25 11:17:29.623 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.624 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:17:29.625 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.3\n",
      "2021-08-25 11:17:29.626 | INFO     | src.policies:train:109 - Episode 135\n",
      "2021-08-25 11:17:29.634 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.635 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:17:29.636 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.96\n",
      "2021-08-25 11:17:29.637 | INFO     | src.policies:train:109 - Episode 136\n",
      "2021-08-25 11:17:29.650 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.651 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 11:17:29.652 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.12\n",
      "2021-08-25 11:17:29.653 | INFO     | src.policies:train:109 - Episode 137\n",
      "2021-08-25 11:17:29.660 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.661 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:17:29.662 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.89\n",
      "2021-08-25 11:17:29.663 | INFO     | src.policies:train:109 - Episode 138\n",
      "2021-08-25 11:17:29.670 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.671 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:17:29.671 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.67\n",
      "2021-08-25 11:17:29.672 | WARNING  | src.policies:train:131 - The actual batch size is 211, instead of 200\n",
      "2021-08-25 11:17:29.679 | INFO     | src.policies:train:157 - Total loss: 0.9942748546600342\n",
      "2021-08-25 11:17:29.682 | INFO     | src.policies:train:103 - Epoch 17 / 800\n",
      "2021-08-25 11:17:29.683 | INFO     | src.policies:train:109 - Episode 139\n",
      "2021-08-25 11:17:29.692 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.693 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:17:29.693 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.4\n",
      "2021-08-25 11:17:29.694 | INFO     | src.policies:train:109 - Episode 140\n",
      "2021-08-25 11:17:29.700 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.701 | INFO     | src.policies:train:121 - Mean episode return: 9.0\n",
      "2021-08-25 11:17:29.702 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.02\n",
      "2021-08-25 11:17:29.703 | INFO     | src.policies:train:109 - Episode 141\n",
      "2021-08-25 11:17:29.716 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.717 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 11:17:29.718 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.07\n",
      "2021-08-25 11:17:29.719 | INFO     | src.policies:train:109 - Episode 142\n",
      "2021-08-25 11:17:29.733 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.734 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 11:17:29.735 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.22\n",
      "2021-08-25 11:17:29.736 | INFO     | src.policies:train:109 - Episode 143\n",
      "2021-08-25 11:17:29.751 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.752 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:29.752 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.46\n",
      "2021-08-25 11:17:29.753 | INFO     | src.policies:train:109 - Episode 144\n",
      "2021-08-25 11:17:29.764 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.765 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:17:29.765 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.45\n",
      "2021-08-25 11:17:29.766 | INFO     | src.policies:train:109 - Episode 145\n",
      "2021-08-25 11:17:29.772 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.773 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 11:17:29.774 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.36\n",
      "2021-08-25 11:17:29.775 | INFO     | src.policies:train:109 - Episode 146\n",
      "2021-08-25 11:17:29.794 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.795 | INFO     | src.policies:train:121 - Mean episode return: 50.0\n",
      "2021-08-25 11:17:29.796 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.75\n",
      "2021-08-25 11:17:29.797 | WARNING  | src.policies:train:131 - The actual batch size is 219, instead of 200\n",
      "2021-08-25 11:17:29.802 | INFO     | src.policies:train:157 - Total loss: 0.9955456256866455\n",
      "2021-08-25 11:17:29.805 | INFO     | src.policies:train:103 - Epoch 18 / 800\n",
      "2021-08-25 11:17:29.806 | INFO     | src.policies:train:109 - Episode 147\n",
      "2021-08-25 11:17:29.817 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.818 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 11:17:29.819 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.86\n",
      "2021-08-25 11:17:29.819 | INFO     | src.policies:train:109 - Episode 148\n",
      "2021-08-25 11:17:29.829 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.830 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:17:29.831 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.95\n",
      "2021-08-25 11:17:29.832 | INFO     | src.policies:train:109 - Episode 149\n",
      "2021-08-25 11:17:29.842 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.843 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:17:29.844 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.95\n",
      "2021-08-25 11:17:29.845 | INFO     | src.policies:train:109 - Episode 150\n",
      "2021-08-25 11:17:29.863 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.864 | INFO     | src.policies:train:121 - Mean episode return: 48.0\n",
      "2021-08-25 11:17:29.865 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.3\n",
      "2021-08-25 11:17:29.866 | INFO     | src.policies:train:109 - Episode 151\n",
      "2021-08-25 11:17:29.873 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.874 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:17:29.875 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.22\n",
      "2021-08-25 11:17:29.876 | INFO     | src.policies:train:109 - Episode 152\n",
      "2021-08-25 11:17:29.887 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.888 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 11:17:29.889 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.96\n",
      "2021-08-25 11:17:29.890 | INFO     | src.policies:train:109 - Episode 153\n",
      "2021-08-25 11:17:29.898 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.899 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:17:29.900 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.94\n",
      "2021-08-25 11:17:29.901 | INFO     | src.policies:train:109 - Episode 154\n",
      "2021-08-25 11:17:29.908 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.909 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:17:29.910 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.85\n",
      "2021-08-25 11:17:29.911 | INFO     | src.policies:train:109 - Episode 155\n",
      "2021-08-25 11:17:29.921 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.922 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:17:29.922 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.75\n",
      "2021-08-25 11:17:29.923 | WARNING  | src.policies:train:131 - The actual batch size is 214, instead of 200\n",
      "2021-08-25 11:17:29.929 | INFO     | src.policies:train:157 - Total loss: 0.995374321937561\n",
      "2021-08-25 11:17:29.931 | INFO     | src.policies:train:103 - Epoch 19 / 800\n",
      "2021-08-25 11:17:29.932 | INFO     | src.policies:train:109 - Episode 156\n",
      "2021-08-25 11:17:29.939 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.941 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:17:29.941 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.41\n",
      "2021-08-25 11:17:29.942 | INFO     | src.policies:train:109 - Episode 157\n",
      "2021-08-25 11:17:29.951 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.952 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:17:29.953 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.52\n",
      "2021-08-25 11:17:29.954 | INFO     | src.policies:train:109 - Episode 158\n",
      "2021-08-25 11:17:29.969 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.970 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 11:17:29.970 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.67\n",
      "2021-08-25 11:17:29.971 | INFO     | src.policies:train:109 - Episode 159\n",
      "2021-08-25 11:17:29.979 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.980 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:17:29.980 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.68\n",
      "2021-08-25 11:17:29.981 | INFO     | src.policies:train:109 - Episode 160\n",
      "2021-08-25 11:17:29.988 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:29.989 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:17:29.990 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.62\n",
      "2021-08-25 11:17:29.991 | INFO     | src.policies:train:109 - Episode 161\n",
      "2021-08-25 11:17:30.001 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:30.002 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:17:30.003 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.65\n",
      "2021-08-25 11:17:30.003 | INFO     | src.policies:train:109 - Episode 162\n",
      "2021-08-25 11:17:30.014 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:30.016 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:17:30.016 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.41\n",
      "2021-08-25 11:17:30.017 | INFO     | src.policies:train:109 - Episode 163\n",
      "2021-08-25 11:17:30.027 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:30.028 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:17:30.029 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.74\n",
      "2021-08-25 11:17:30.030 | INFO     | src.policies:train:109 - Episode 164\n",
      "2021-08-25 11:17:30.040 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:30.041 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:30.042 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.12\n",
      "2021-08-25 11:17:30.043 | INFO     | src.policies:train:109 - Episode 165\n",
      "2021-08-25 11:17:30.051 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:30.052 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:17:30.053 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.14\n",
      "2021-08-25 11:17:30.054 | WARNING  | src.policies:train:131 - The actual batch size is 214, instead of 200\n",
      "2021-08-25 11:17:30.060 | INFO     | src.policies:train:157 - Total loss: 0.9953268766403198\n",
      "2021-08-25 11:17:30.062 | INFO     | src.policies:train:103 - Epoch 20 / 800\n",
      "2021-08-25 11:17:30.064 | INFO     | src.policies:train:109 - Episode 166\n",
      "2021-08-25 11:17:30.070 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:30.072 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:17:30.072 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.07\n",
      "2021-08-25 11:17:30.073 | INFO     | src.policies:train:109 - Episode 167\n",
      "2021-08-25 11:17:30.086 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:30.087 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 11:17:30.087 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.18\n",
      "2021-08-25 11:17:30.088 | INFO     | src.policies:train:109 - Episode 168\n",
      "2021-08-25 11:17:30.110 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:30.111 | INFO     | src.policies:train:121 - Mean episode return: 55.0\n",
      "2021-08-25 11:17:30.112 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.52\n",
      "2021-08-25 11:17:30.113 | INFO     | src.policies:train:109 - Episode 169\n",
      "2021-08-25 11:17:30.129 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:30.130 | INFO     | src.policies:train:121 - Mean episode return: 41.0\n",
      "2021-08-25 11:17:30.131 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.52\n",
      "2021-08-25 11:17:30.132 | INFO     | src.policies:train:109 - Episode 170\n",
      "2021-08-25 11:17:30.143 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:30.144 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:17:30.144 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.23\n",
      "2021-08-25 11:17:30.145 | INFO     | src.policies:train:109 - Episode 171\n",
      "2021-08-25 11:17:30.179 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:30.180 | INFO     | src.policies:train:121 - Mean episode return: 101.0\n",
      "2021-08-25 11:17:30.181 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.1\n",
      "2021-08-25 11:17:30.182 | WARNING  | src.policies:train:131 - The actual batch size is 268, instead of 200\n",
      "2021-08-25 11:17:30.187 | INFO     | src.policies:train:157 - Total loss: 0.9963335394859314\n",
      "2021-08-25 11:17:30.190 | INFO     | src.policies:train:103 - Epoch 21 / 800\n",
      "2021-08-25 11:17:30.191 | INFO     | src.policies:train:109 - Episode 172\n",
      "2021-08-25 11:17:30.214 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:30.215 | INFO     | src.policies:train:121 - Mean episode return: 70.0\n",
      "2021-08-25 11:17:30.216 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.68\n",
      "2021-08-25 11:17:30.217 | INFO     | src.policies:train:109 - Episode 173\n",
      "2021-08-25 11:17:30.233 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:30.234 | INFO     | src.policies:train:121 - Mean episode return: 41.0\n",
      "2021-08-25 11:17:30.235 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.87\n",
      "2021-08-25 11:17:30.236 | INFO     | src.policies:train:109 - Episode 174\n",
      "2021-08-25 11:17:30.246 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:30.247 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:17:30.248 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.99\n",
      "2021-08-25 11:17:30.249 | INFO     | src.policies:train:109 - Episode 175\n",
      "2021-08-25 11:17:30.259 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:30.260 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:17:30.261 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.99\n",
      "2021-08-25 11:17:30.262 | INFO     | src.policies:train:109 - Episode 176\n",
      "2021-08-25 11:17:30.271 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:30.273 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:17:30.274 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.95\n",
      "2021-08-25 11:17:30.275 | INFO     | src.policies:train:109 - Episode 177\n",
      "2021-08-25 11:17:30.283 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:30.284 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:17:30.284 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.89\n",
      "2021-08-25 11:17:30.285 | INFO     | src.policies:train:109 - Episode 178\n",
      "2021-08-25 11:17:30.297 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:30.299 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:17:30.299 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.71\n",
      "2021-08-25 11:17:30.300 | WARNING  | src.policies:train:131 - The actual batch size is 223, instead of 200\n",
      "2021-08-25 11:17:30.306 | INFO     | src.policies:train:157 - Total loss: 0.9960584044456482\n",
      "2021-08-25 11:17:30.308 | INFO     | src.policies:train:103 - Epoch 22 / 800\n",
      "2021-08-25 11:17:30.309 | INFO     | src.policies:train:109 - Episode 179\n",
      "2021-08-25 11:17:30.318 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:30.319 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:17:30.320 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.69\n",
      "2021-08-25 11:17:30.321 | INFO     | src.policies:train:109 - Episode 180\n",
      "2021-08-25 11:17:30.336 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:30.337 | INFO     | src.policies:train:121 - Mean episode return: 38.0\n",
      "2021-08-25 11:17:30.337 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.92\n",
      "2021-08-25 11:17:30.338 | INFO     | src.policies:train:109 - Episode 181\n",
      "2021-08-25 11:17:30.345 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:30.346 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:17:30.347 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.73\n",
      "2021-08-25 11:17:30.348 | INFO     | src.policies:train:109 - Episode 182\n",
      "2021-08-25 11:17:30.355 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:30.356 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:17:30.357 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.54\n",
      "2021-08-25 11:17:30.358 | INFO     | src.policies:train:109 - Episode 183\n",
      "2021-08-25 11:17:30.364 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:30.365 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:17:30.366 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.16\n",
      "2021-08-25 11:17:30.367 | INFO     | src.policies:train:109 - Episode 184\n",
      "2021-08-25 11:17:30.374 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:30.374 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:17:30.375 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:30.376 | INFO     | src.policies:train:109 - Episode 185\n",
      "2021-08-25 11:17:30.384 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:30.385 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:17:30.386 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.16\n",
      "2021-08-25 11:17:30.387 | INFO     | src.policies:train:109 - Episode 186\n",
      "2021-08-25 11:17:30.396 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:30.397 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:17:30.398 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.21\n",
      "2021-08-25 11:17:30.399 | INFO     | src.policies:train:109 - Episode 187\n",
      "2021-08-25 11:17:30.409 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:30.410 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 11:17:30.411 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.17\n",
      "2021-08-25 11:17:30.412 | INFO     | src.policies:train:109 - Episode 188\n",
      "2021-08-25 11:17:30.432 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:30.433 | INFO     | src.policies:train:121 - Mean episode return: 54.0\n",
      "2021-08-25 11:17:30.433 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.58\n",
      "2021-08-25 11:17:30.434 | WARNING  | src.policies:train:131 - The actual batch size is 225, instead of 200\n",
      "2021-08-25 11:17:30.441 | INFO     | src.policies:train:157 - Total loss: 0.9955552220344543\n",
      "2021-08-25 11:17:30.443 | INFO     | src.policies:train:103 - Epoch 23 / 800\n",
      "2021-08-25 11:17:30.444 | INFO     | src.policies:train:109 - Episode 189\n",
      "2021-08-25 11:17:30.451 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:30.452 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:17:30.453 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.58\n",
      "2021-08-25 11:17:30.454 | INFO     | src.policies:train:109 - Episode 190\n",
      "2021-08-25 11:17:30.469 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:30.470 | INFO     | src.policies:train:121 - Mean episode return: 38.0\n",
      "2021-08-25 11:17:30.471 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.42\n",
      "2021-08-25 11:17:30.472 | INFO     | src.policies:train:109 - Episode 191\n",
      "2021-08-25 11:17:30.489 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:30.490 | INFO     | src.policies:train:121 - Mean episode return: 43.0\n",
      "2021-08-25 11:17:30.491 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.71\n",
      "2021-08-25 11:17:30.492 | INFO     | src.policies:train:109 - Episode 192\n",
      "2021-08-25 11:17:30.504 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:30.505 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:17:30.506 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.83\n",
      "2021-08-25 11:17:30.507 | INFO     | src.policies:train:109 - Episode 193\n",
      "2021-08-25 11:17:30.518 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:30.519 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 11:17:30.520 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.97\n",
      "2021-08-25 11:17:30.521 | INFO     | src.policies:train:109 - Episode 194\n",
      "2021-08-25 11:17:30.537 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:30.538 | INFO     | src.policies:train:121 - Mean episode return: 43.0\n",
      "2021-08-25 11:17:30.539 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.19\n",
      "2021-08-25 11:17:30.540 | INFO     | src.policies:train:109 - Episode 195\n",
      "2021-08-25 11:17:30.546 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:30.547 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:17:30.547 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.0\n",
      "2021-08-25 11:17:30.548 | WARNING  | src.policies:train:131 - The actual batch size is 202, instead of 200\n",
      "2021-08-25 11:17:30.554 | INFO     | src.policies:train:157 - Total loss: 0.9950494170188904\n",
      "2021-08-25 11:17:30.556 | INFO     | src.policies:train:103 - Epoch 24 / 800\n",
      "2021-08-25 11:17:30.558 | INFO     | src.policies:train:109 - Episode 196\n",
      "2021-08-25 11:17:30.564 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:30.565 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:17:30.565 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.96\n",
      "2021-08-25 11:17:30.566 | INFO     | src.policies:train:109 - Episode 197\n",
      "2021-08-25 11:17:30.577 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:30.578 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:17:30.579 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.0\n",
      "2021-08-25 11:17:30.580 | INFO     | src.policies:train:109 - Episode 198\n",
      "2021-08-25 11:17:30.588 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:30.589 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:17:30.589 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.06\n",
      "2021-08-25 11:17:30.590 | INFO     | src.policies:train:109 - Episode 199\n",
      "2021-08-25 11:17:30.600 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:30.601 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:17:30.602 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.84\n",
      "2021-08-25 11:17:30.603 | INFO     | src.policies:train:109 - Episode 200\n",
      "2021-08-25 11:17:30.611 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:30.612 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:17:30.613 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.85\n",
      "2021-08-25 11:17:30.613 | INFO     | src.policies:train:109 - Episode 201\n",
      "2021-08-25 11:17:30.621 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:30.622 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:17:30.622 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.84\n",
      "2021-08-25 11:17:30.623 | INFO     | src.policies:train:109 - Episode 202\n",
      "2021-08-25 11:17:30.631 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:30.632 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:17:30.633 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.82\n",
      "2021-08-25 11:17:30.634 | INFO     | src.policies:train:109 - Episode 203\n",
      "2021-08-25 11:17:30.644 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:30.645 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:17:30.646 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.88\n",
      "2021-08-25 11:17:30.647 | INFO     | src.policies:train:109 - Episode 204\n",
      "2021-08-25 11:17:30.659 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:30.660 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 11:17:30.661 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.84\n",
      "2021-08-25 11:17:30.662 | INFO     | src.policies:train:109 - Episode 205\n",
      "2021-08-25 11:17:30.673 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:30.675 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:17:30.675 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:30.677 | INFO     | src.policies:train:109 - Episode 206\n",
      "2021-08-25 11:17:30.686 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:30.687 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:17:30.688 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.02\n",
      "2021-08-25 11:17:30.689 | WARNING  | src.policies:train:131 - The actual batch size is 214, instead of 200\n",
      "2021-08-25 11:17:30.697 | INFO     | src.policies:train:157 - Total loss: 0.9953267574310303\n",
      "2021-08-25 11:17:30.701 | INFO     | src.policies:train:103 - Epoch 25 / 800\n",
      "2021-08-25 11:17:30.703 | INFO     | src.policies:train:109 - Episode 207\n",
      "2021-08-25 11:17:30.710 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:30.711 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:17:30.712 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.25\n",
      "2021-08-25 11:17:30.713 | INFO     | src.policies:train:109 - Episode 208\n",
      "2021-08-25 11:17:30.723 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:30.724 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:17:30.725 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.82\n",
      "2021-08-25 11:17:30.726 | INFO     | src.policies:train:109 - Episode 209\n",
      "2021-08-25 11:17:30.734 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:30.736 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:17:30.737 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.65\n",
      "2021-08-25 11:17:30.738 | INFO     | src.policies:train:109 - Episode 210\n",
      "2021-08-25 11:17:30.747 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:30.749 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:17:30.750 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.68\n",
      "2021-08-25 11:17:30.751 | INFO     | src.policies:train:109 - Episode 211\n",
      "2021-08-25 11:17:30.768 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:30.769 | INFO     | src.policies:train:121 - Mean episode return: 38.0\n",
      "2021-08-25 11:17:30.770 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.69\n",
      "2021-08-25 11:17:30.771 | INFO     | src.policies:train:109 - Episode 212\n",
      "2021-08-25 11:17:30.780 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:30.781 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:17:30.782 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.71\n",
      "2021-08-25 11:17:30.783 | INFO     | src.policies:train:109 - Episode 213\n",
      "2021-08-25 11:17:30.794 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:30.795 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:17:30.796 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.71\n",
      "2021-08-25 11:17:30.797 | INFO     | src.policies:train:109 - Episode 214\n",
      "2021-08-25 11:17:30.806 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:30.807 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:17:30.808 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.49\n",
      "2021-08-25 11:17:30.809 | INFO     | src.policies:train:109 - Episode 215\n",
      "2021-08-25 11:17:30.819 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:30.820 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:17:30.821 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.53\n",
      "2021-08-25 11:17:30.822 | INFO     | src.policies:train:109 - Episode 216\n",
      "2021-08-25 11:17:30.836 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:30.837 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 11:17:30.838 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.5\n",
      "2021-08-25 11:17:30.839 | INFO     | src.policies:train:109 - Episode 217\n",
      "2021-08-25 11:17:30.852 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:30.853 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 11:17:30.854 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.19\n",
      "2021-08-25 11:17:30.855 | WARNING  | src.policies:train:131 - The actual batch size is 216, instead of 200\n",
      "2021-08-25 11:17:30.861 | INFO     | src.policies:train:157 - Total loss: 0.9953700304031372\n",
      "2021-08-25 11:17:30.864 | INFO     | src.policies:train:103 - Epoch 26 / 800\n",
      "2021-08-25 11:17:30.865 | INFO     | src.policies:train:109 - Episode 218\n",
      "2021-08-25 11:17:30.879 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:30.880 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 11:17:30.881 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.19\n",
      "2021-08-25 11:17:30.882 | INFO     | src.policies:train:109 - Episode 219\n",
      "2021-08-25 11:17:30.896 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:30.898 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 11:17:30.899 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.42\n",
      "2021-08-25 11:17:30.899 | INFO     | src.policies:train:109 - Episode 220\n",
      "2021-08-25 11:17:30.909 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:30.910 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:17:30.911 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.54\n",
      "2021-08-25 11:17:30.912 | INFO     | src.policies:train:109 - Episode 221\n",
      "2021-08-25 11:17:30.920 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:30.921 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:17:30.922 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.23\n",
      "2021-08-25 11:17:30.923 | INFO     | src.policies:train:109 - Episode 222\n",
      "2021-08-25 11:17:30.932 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:30.933 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:17:30.933 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.26\n",
      "2021-08-25 11:17:30.934 | INFO     | src.policies:train:109 - Episode 223\n",
      "2021-08-25 11:17:30.951 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:30.952 | INFO     | src.policies:train:121 - Mean episode return: 44.0\n",
      "2021-08-25 11:17:30.953 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.22\n",
      "2021-08-25 11:17:30.954 | INFO     | src.policies:train:109 - Episode 224\n",
      "2021-08-25 11:17:30.961 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:30.962 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 11:17:30.963 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.16\n",
      "2021-08-25 11:17:30.964 | INFO     | src.policies:train:109 - Episode 225\n",
      "2021-08-25 11:17:30.973 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:30.974 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:17:30.974 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.17\n",
      "2021-08-25 11:17:30.975 | WARNING  | src.policies:train:131 - The actual batch size is 211, instead of 200\n",
      "2021-08-25 11:17:30.981 | INFO     | src.policies:train:157 - Total loss: 0.9952603578567505\n",
      "2021-08-25 11:17:30.984 | INFO     | src.policies:train:103 - Epoch 27 / 800\n",
      "2021-08-25 11:17:30.985 | INFO     | src.policies:train:109 - Episode 226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:30.990 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:30.991 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:17:30.992 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.16\n",
      "2021-08-25 11:17:30.993 | INFO     | src.policies:train:109 - Episode 227\n",
      "2021-08-25 11:17:31.011 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:31.012 | INFO     | src.policies:train:121 - Mean episode return: 49.0\n",
      "2021-08-25 11:17:31.013 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.49\n",
      "2021-08-25 11:17:31.014 | INFO     | src.policies:train:109 - Episode 228\n",
      "2021-08-25 11:17:31.027 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:31.028 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 11:17:31.029 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.62\n",
      "2021-08-25 11:17:31.030 | INFO     | src.policies:train:109 - Episode 229\n",
      "2021-08-25 11:17:31.040 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:31.041 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:17:31.042 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.64\n",
      "2021-08-25 11:17:31.043 | INFO     | src.policies:train:109 - Episode 230\n",
      "2021-08-25 11:17:31.052 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:31.053 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:17:31.054 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.71\n",
      "2021-08-25 11:17:31.055 | INFO     | src.policies:train:109 - Episode 231\n",
      "2021-08-25 11:17:31.064 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:31.065 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:17:31.066 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.81\n",
      "2021-08-25 11:17:31.067 | INFO     | src.policies:train:109 - Episode 232\n",
      "2021-08-25 11:17:31.077 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:31.078 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:17:31.079 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.91\n",
      "2021-08-25 11:17:31.080 | INFO     | src.policies:train:109 - Episode 233\n",
      "2021-08-25 11:17:31.088 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:31.089 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:17:31.090 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.92\n",
      "2021-08-25 11:17:31.091 | INFO     | src.policies:train:109 - Episode 234\n",
      "2021-08-25 11:17:31.110 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:31.111 | INFO     | src.policies:train:121 - Mean episode return: 53.0\n",
      "2021-08-25 11:17:31.112 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.27\n",
      "2021-08-25 11:17:31.112 | WARNING  | src.policies:train:131 - The actual batch size is 248, instead of 200\n",
      "2021-08-25 11:17:31.119 | INFO     | src.policies:train:157 - Total loss: 0.9959675073623657\n",
      "2021-08-25 11:17:31.121 | INFO     | src.policies:train:103 - Epoch 28 / 800\n",
      "2021-08-25 11:17:31.122 | INFO     | src.policies:train:109 - Episode 235\n",
      "2021-08-25 11:17:31.128 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:31.129 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:17:31.130 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.25\n",
      "2021-08-25 11:17:31.131 | INFO     | src.policies:train:109 - Episode 236\n",
      "2021-08-25 11:17:31.140 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:31.141 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:17:31.141 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.09\n",
      "2021-08-25 11:17:31.142 | INFO     | src.policies:train:109 - Episode 237\n",
      "2021-08-25 11:17:31.154 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:31.155 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 11:17:31.156 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.25\n",
      "2021-08-25 11:17:31.157 | INFO     | src.policies:train:109 - Episode 238\n",
      "2021-08-25 11:17:31.171 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:31.172 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 11:17:31.173 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.45\n",
      "2021-08-25 11:17:31.174 | INFO     | src.policies:train:109 - Episode 239\n",
      "2021-08-25 11:17:31.186 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:31.187 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 11:17:31.188 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.49\n",
      "2021-08-25 11:17:31.189 | INFO     | src.policies:train:109 - Episode 240\n",
      "2021-08-25 11:17:31.204 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:31.205 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 11:17:31.206 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.8\n",
      "2021-08-25 11:17:31.207 | INFO     | src.policies:train:109 - Episode 241\n",
      "2021-08-25 11:17:31.215 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:31.217 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:17:31.217 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.66\n",
      "2021-08-25 11:17:31.218 | INFO     | src.policies:train:109 - Episode 242\n",
      "2021-08-25 11:17:31.229 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:31.230 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:17:31.231 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.55\n",
      "2021-08-25 11:17:31.232 | WARNING  | src.policies:train:131 - The actual batch size is 202, instead of 200\n",
      "2021-08-25 11:17:31.238 | INFO     | src.policies:train:157 - Total loss: 0.9950494170188904\n",
      "2021-08-25 11:17:31.241 | INFO     | src.policies:train:103 - Epoch 29 / 800\n",
      "2021-08-25 11:17:31.242 | INFO     | src.policies:train:109 - Episode 243\n",
      "2021-08-25 11:17:31.251 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:31.252 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:17:31.253 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.43\n",
      "2021-08-25 11:17:31.254 | INFO     | src.policies:train:109 - Episode 244\n",
      "2021-08-25 11:17:31.265 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:31.266 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:17:31.267 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.5\n",
      "2021-08-25 11:17:31.268 | INFO     | src.policies:train:109 - Episode 245\n",
      "2021-08-25 11:17:31.275 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:31.276 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:17:31.277 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.55\n",
      "2021-08-25 11:17:31.278 | INFO     | src.policies:train:109 - Episode 246\n",
      "2021-08-25 11:17:31.288 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:31.289 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:17:31.290 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.28\n",
      "2021-08-25 11:17:31.291 | INFO     | src.policies:train:109 - Episode 247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:31.300 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:31.301 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:17:31.301 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.2\n",
      "2021-08-25 11:17:31.302 | INFO     | src.policies:train:109 - Episode 248\n",
      "2021-08-25 11:17:31.311 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:31.312 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:17:31.313 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.15\n",
      "2021-08-25 11:17:31.313 | INFO     | src.policies:train:109 - Episode 249\n",
      "2021-08-25 11:17:31.324 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:31.325 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:17:31.326 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.17\n",
      "2021-08-25 11:17:31.326 | INFO     | src.policies:train:109 - Episode 250\n",
      "2021-08-25 11:17:31.334 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:31.335 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:17:31.336 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.83\n",
      "2021-08-25 11:17:31.337 | INFO     | src.policies:train:109 - Episode 251\n",
      "2021-08-25 11:17:31.347 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:31.348 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:17:31.348 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.92\n",
      "2021-08-25 11:17:31.349 | INFO     | src.policies:train:109 - Episode 252\n",
      "2021-08-25 11:17:31.359 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:31.360 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:17:31.361 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.86\n",
      "2021-08-25 11:17:31.362 | WARNING  | src.policies:train:131 - The actual batch size is 206, instead of 200\n",
      "2021-08-25 11:17:31.367 | INFO     | src.policies:train:157 - Total loss: 0.9951454401016235\n",
      "2021-08-25 11:17:31.370 | INFO     | src.policies:train:103 - Epoch 30 / 800\n",
      "2021-08-25 11:17:31.371 | INFO     | src.policies:train:109 - Episode 253\n",
      "2021-08-25 11:17:31.381 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:31.382 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:17:31.382 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.92\n",
      "2021-08-25 11:17:31.383 | INFO     | src.policies:train:109 - Episode 254\n",
      "2021-08-25 11:17:31.389 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:31.390 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 11:17:31.391 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.86\n",
      "2021-08-25 11:17:31.392 | INFO     | src.policies:train:109 - Episode 255\n",
      "2021-08-25 11:17:31.403 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:31.404 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 11:17:31.405 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.9\n",
      "2021-08-25 11:17:31.406 | INFO     | src.policies:train:109 - Episode 256\n",
      "2021-08-25 11:17:31.413 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:31.414 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:17:31.415 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.87\n",
      "2021-08-25 11:17:31.416 | INFO     | src.policies:train:109 - Episode 257\n",
      "2021-08-25 11:17:31.449 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:31.450 | INFO     | src.policies:train:121 - Mean episode return: 98.0\n",
      "2021-08-25 11:17:31.451 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.64\n",
      "2021-08-25 11:17:31.452 | INFO     | src.policies:train:109 - Episode 258\n",
      "2021-08-25 11:17:31.468 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:31.469 | INFO     | src.policies:train:121 - Mean episode return: 41.0\n",
      "2021-08-25 11:17:31.470 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.69\n",
      "2021-08-25 11:17:31.470 | WARNING  | src.policies:train:131 - The actual batch size is 214, instead of 200\n",
      "2021-08-25 11:17:31.477 | INFO     | src.policies:train:157 - Total loss: 0.9953272342681885\n",
      "2021-08-25 11:17:31.479 | INFO     | src.policies:train:103 - Epoch 31 / 800\n",
      "2021-08-25 11:17:31.480 | INFO     | src.policies:train:109 - Episode 259\n",
      "2021-08-25 11:17:31.489 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:31.490 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:17:31.491 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.77\n",
      "2021-08-25 11:17:31.492 | INFO     | src.policies:train:109 - Episode 260\n",
      "2021-08-25 11:17:31.501 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:31.502 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:17:31.503 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.81\n",
      "2021-08-25 11:17:31.504 | INFO     | src.policies:train:109 - Episode 261\n",
      "2021-08-25 11:17:31.513 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:31.514 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:17:31.514 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.76\n",
      "2021-08-25 11:17:31.515 | INFO     | src.policies:train:109 - Episode 262\n",
      "2021-08-25 11:17:31.521 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:31.523 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:17:31.523 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.61\n",
      "2021-08-25 11:17:31.524 | INFO     | src.policies:train:109 - Episode 263\n",
      "2021-08-25 11:17:31.535 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:31.536 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 11:17:31.537 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.66\n",
      "2021-08-25 11:17:31.538 | INFO     | src.policies:train:109 - Episode 264\n",
      "2021-08-25 11:17:31.547 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:31.548 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:17:31.549 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.62\n",
      "2021-08-25 11:17:31.550 | INFO     | src.policies:train:109 - Episode 265\n",
      "2021-08-25 11:17:31.567 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:31.568 | INFO     | src.policies:train:121 - Mean episode return: 45.0\n",
      "2021-08-25 11:17:31.569 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.9\n",
      "2021-08-25 11:17:31.570 | INFO     | src.policies:train:109 - Episode 266\n",
      "2021-08-25 11:17:31.577 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:31.579 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:17:31.579 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.88\n",
      "2021-08-25 11:17:31.580 | INFO     | src.policies:train:109 - Episode 267\n",
      "2021-08-25 11:17:31.589 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:31.590 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:17:31.590 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.75\n",
      "2021-08-25 11:17:31.591 | INFO     | src.policies:train:109 - Episode 268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:31.603 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:31.604 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 11:17:31.605 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.48\n",
      "2021-08-25 11:17:31.606 | WARNING  | src.policies:train:131 - The actual batch size is 223, instead of 200\n",
      "2021-08-25 11:17:31.611 | INFO     | src.policies:train:157 - Total loss: 0.9955157041549683\n",
      "2021-08-25 11:17:31.614 | INFO     | src.policies:train:103 - Epoch 32 / 800\n",
      "2021-08-25 11:17:31.615 | INFO     | src.policies:train:109 - Episode 269\n",
      "2021-08-25 11:17:31.624 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:31.625 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:17:31.626 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.29\n",
      "2021-08-25 11:17:31.626 | INFO     | src.policies:train:109 - Episode 270\n",
      "2021-08-25 11:17:31.644 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:31.645 | INFO     | src.policies:train:121 - Mean episode return: 46.0\n",
      "2021-08-25 11:17:31.646 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.53\n",
      "2021-08-25 11:17:31.647 | INFO     | src.policies:train:109 - Episode 271\n",
      "2021-08-25 11:17:31.654 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:31.655 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:17:31.656 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.65\n",
      "2021-08-25 11:17:31.657 | INFO     | src.policies:train:109 - Episode 272\n",
      "2021-08-25 11:17:31.665 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:31.666 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:17:31.667 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.15\n",
      "2021-08-25 11:17:31.668 | INFO     | src.policies:train:109 - Episode 273\n",
      "2021-08-25 11:17:31.679 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:31.680 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:17:31.681 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.0\n",
      "2021-08-25 11:17:31.682 | INFO     | src.policies:train:109 - Episode 274\n",
      "2021-08-25 11:17:31.694 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:31.695 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 11:17:31.696 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.06\n",
      "2021-08-25 11:17:31.697 | INFO     | src.policies:train:109 - Episode 275\n",
      "2021-08-25 11:17:31.707 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:31.708 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:17:31.709 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.03\n",
      "2021-08-25 11:17:31.710 | INFO     | src.policies:train:109 - Episode 276\n",
      "2021-08-25 11:17:31.720 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:31.721 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:17:31.721 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.01\n",
      "2021-08-25 11:17:31.722 | INFO     | src.policies:train:109 - Episode 277\n",
      "2021-08-25 11:17:31.733 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:31.734 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 11:17:31.735 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.14\n",
      "2021-08-25 11:17:31.736 | WARNING  | src.policies:train:131 - The actual batch size is 224, instead of 200\n",
      "2021-08-25 11:17:31.742 | INFO     | src.policies:train:157 - Total loss: 0.9955353736877441\n",
      "2021-08-25 11:17:31.744 | INFO     | src.policies:train:103 - Epoch 33 / 800\n",
      "2021-08-25 11:17:31.745 | INFO     | src.policies:train:109 - Episode 278\n",
      "2021-08-25 11:17:31.754 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:31.756 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:17:31.756 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.08\n",
      "2021-08-25 11:17:31.757 | INFO     | src.policies:train:109 - Episode 279\n",
      "2021-08-25 11:17:31.767 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:31.767 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:17:31.768 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.04\n",
      "2021-08-25 11:17:31.769 | INFO     | src.policies:train:109 - Episode 280\n",
      "2021-08-25 11:17:31.785 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:31.786 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 11:17:31.787 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.06\n",
      "2021-08-25 11:17:31.788 | INFO     | src.policies:train:109 - Episode 281\n",
      "2021-08-25 11:17:31.802 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:31.803 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 11:17:31.803 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.31\n",
      "2021-08-25 11:17:31.804 | INFO     | src.policies:train:109 - Episode 282\n",
      "2021-08-25 11:17:31.812 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:31.813 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:17:31.813 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.31\n",
      "2021-08-25 11:17:31.814 | INFO     | src.policies:train:109 - Episode 283\n",
      "2021-08-25 11:17:31.832 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:31.833 | INFO     | src.policies:train:121 - Mean episode return: 48.0\n",
      "2021-08-25 11:17:31.834 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.67\n",
      "2021-08-25 11:17:31.835 | INFO     | src.policies:train:109 - Episode 284\n",
      "2021-08-25 11:17:31.842 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:31.843 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:17:31.843 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.66\n",
      "2021-08-25 11:17:31.844 | INFO     | src.policies:train:109 - Episode 285\n",
      "2021-08-25 11:17:31.852 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:31.853 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:17:31.854 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.68\n",
      "2021-08-25 11:17:31.855 | WARNING  | src.policies:train:131 - The actual batch size is 209, instead of 200\n",
      "2021-08-25 11:17:31.860 | INFO     | src.policies:train:157 - Total loss: 0.9952150583267212\n",
      "2021-08-25 11:17:31.863 | INFO     | src.policies:train:103 - Epoch 34 / 800\n",
      "2021-08-25 11:17:31.864 | INFO     | src.policies:train:109 - Episode 286\n",
      "2021-08-25 11:17:31.875 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:31.876 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:17:31.877 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.77\n",
      "2021-08-25 11:17:31.878 | INFO     | src.policies:train:109 - Episode 287\n",
      "2021-08-25 11:17:31.891 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:31.892 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 11:17:31.893 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.86\n",
      "2021-08-25 11:17:31.894 | INFO     | src.policies:train:109 - Episode 288\n",
      "2021-08-25 11:17:31.904 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:31.905 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:17:31.906 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.56\n",
      "2021-08-25 11:17:31.907 | INFO     | src.policies:train:109 - Episode 289\n",
      "2021-08-25 11:17:31.914 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:31.915 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:17:31.916 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.55\n",
      "2021-08-25 11:17:31.917 | INFO     | src.policies:train:109 - Episode 290\n",
      "2021-08-25 11:17:31.926 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:31.927 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:17:31.927 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.35\n",
      "2021-08-25 11:17:31.928 | INFO     | src.policies:train:109 - Episode 291\n",
      "2021-08-25 11:17:31.941 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:31.942 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 11:17:31.943 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.22\n",
      "2021-08-25 11:17:31.943 | INFO     | src.policies:train:109 - Episode 292\n",
      "2021-08-25 11:17:31.950 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:31.951 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:17:31.952 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.11\n",
      "2021-08-25 11:17:31.953 | INFO     | src.policies:train:109 - Episode 293\n",
      "2021-08-25 11:17:31.961 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:31.962 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:17:31.963 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.0\n",
      "2021-08-25 11:17:31.964 | INFO     | src.policies:train:109 - Episode 294\n",
      "2021-08-25 11:17:31.981 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:31.982 | INFO     | src.policies:train:121 - Mean episode return: 47.0\n",
      "2021-08-25 11:17:31.983 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.04\n",
      "2021-08-25 11:17:31.983 | WARNING  | src.policies:train:131 - The actual batch size is 225, instead of 200\n",
      "2021-08-25 11:17:31.989 | INFO     | src.policies:train:157 - Total loss: 0.9955551624298096\n",
      "2021-08-25 11:17:31.991 | INFO     | src.policies:train:103 - Epoch 35 / 800\n",
      "2021-08-25 11:17:31.992 | INFO     | src.policies:train:109 - Episode 295\n",
      "2021-08-25 11:17:32.001 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:32.002 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:17:32.003 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.14\n",
      "2021-08-25 11:17:32.004 | INFO     | src.policies:train:109 - Episode 296\n",
      "2021-08-25 11:17:32.011 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:32.012 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:17:32.013 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.15\n",
      "2021-08-25 11:17:32.014 | INFO     | src.policies:train:109 - Episode 297\n",
      "2021-08-25 11:17:32.031 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:32.032 | INFO     | src.policies:train:121 - Mean episode return: 44.0\n",
      "2021-08-25 11:17:32.033 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.36\n",
      "2021-08-25 11:17:32.034 | INFO     | src.policies:train:109 - Episode 298\n",
      "2021-08-25 11:17:32.046 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:32.047 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:17:32.048 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.46\n",
      "2021-08-25 11:17:32.049 | INFO     | src.policies:train:109 - Episode 299\n",
      "2021-08-25 11:17:32.066 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:32.067 | INFO     | src.policies:train:121 - Mean episode return: 44.0\n",
      "2021-08-25 11:17:32.068 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.69\n",
      "2021-08-25 11:17:32.069 | INFO     | src.policies:train:109 - Episode 300\n",
      "2021-08-25 11:17:32.078 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:32.079 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:17:32.080 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.69\n",
      "2021-08-25 11:17:32.081 | INFO     | src.policies:train:109 - Episode 301\n",
      "2021-08-25 11:17:32.086 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:32.087 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 11:17:32.088 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.65\n",
      "2021-08-25 11:17:32.089 | INFO     | src.policies:train:109 - Episode 302\n",
      "2021-08-25 11:17:32.098 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:32.099 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:17:32.099 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.65\n",
      "2021-08-25 11:17:32.100 | INFO     | src.policies:train:109 - Episode 303\n",
      "2021-08-25 11:17:32.107 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:32.108 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:17:32.109 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.56\n",
      "2021-08-25 11:17:32.110 | WARNING  | src.policies:train:131 - The actual batch size is 207, instead of 200\n",
      "2021-08-25 11:17:32.115 | INFO     | src.policies:train:157 - Total loss: 0.9951688051223755\n",
      "2021-08-25 11:17:32.118 | INFO     | src.policies:train:103 - Epoch 36 / 800\n",
      "2021-08-25 11:17:32.119 | INFO     | src.policies:train:109 - Episode 304\n",
      "2021-08-25 11:17:32.131 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:32.132 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 11:17:32.133 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.57\n",
      "2021-08-25 11:17:32.134 | INFO     | src.policies:train:109 - Episode 305\n",
      "2021-08-25 11:17:32.147 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:32.148 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 11:17:32.149 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.65\n",
      "2021-08-25 11:17:32.150 | INFO     | src.policies:train:109 - Episode 306\n",
      "2021-08-25 11:17:32.159 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:32.160 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:17:32.161 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.7\n",
      "2021-08-25 11:17:32.162 | INFO     | src.policies:train:109 - Episode 307\n",
      "2021-08-25 11:17:32.171 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:32.172 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:17:32.172 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.78\n",
      "2021-08-25 11:17:32.173 | INFO     | src.policies:train:109 - Episode 308\n",
      "2021-08-25 11:17:32.182 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:32.183 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:17:32.184 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.81\n",
      "2021-08-25 11:17:32.185 | INFO     | src.policies:train:109 - Episode 309\n",
      "2021-08-25 11:17:32.198 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:32.199 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 11:17:32.199 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.0\n",
      "2021-08-25 11:17:32.200 | INFO     | src.policies:train:109 - Episode 310\n",
      "2021-08-25 11:17:32.211 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:32.212 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 11:17:32.213 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.12\n",
      "2021-08-25 11:17:32.214 | INFO     | src.policies:train:109 - Episode 311\n",
      "2021-08-25 11:17:32.231 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:32.232 | INFO     | src.policies:train:121 - Mean episode return: 47.0\n",
      "2021-08-25 11:17:32.233 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.21\n",
      "2021-08-25 11:17:32.234 | WARNING  | src.policies:train:131 - The actual batch size is 231, instead of 200\n",
      "2021-08-25 11:17:32.240 | INFO     | src.policies:train:157 - Total loss: 0.9956705570220947\n",
      "2021-08-25 11:17:32.243 | INFO     | src.policies:train:103 - Epoch 37 / 800\n",
      "2021-08-25 11:17:32.244 | INFO     | src.policies:train:109 - Episode 312\n",
      "2021-08-25 11:17:32.254 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:32.255 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:17:32.256 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.35\n",
      "2021-08-25 11:17:32.257 | INFO     | src.policies:train:109 - Episode 313\n",
      "2021-08-25 11:17:32.269 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:32.271 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 11:17:32.272 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.44\n",
      "2021-08-25 11:17:32.272 | INFO     | src.policies:train:109 - Episode 314\n",
      "2021-08-25 11:17:32.295 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:32.296 | INFO     | src.policies:train:121 - Mean episode return: 58.0\n",
      "2021-08-25 11:17:32.297 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.91\n",
      "2021-08-25 11:17:32.298 | INFO     | src.policies:train:109 - Episode 315\n",
      "2021-08-25 11:17:32.308 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:32.309 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:17:32.310 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.96\n",
      "2021-08-25 11:17:32.311 | INFO     | src.policies:train:109 - Episode 316\n",
      "2021-08-25 11:17:32.322 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:32.323 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:17:32.324 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.92\n",
      "2021-08-25 11:17:32.324 | INFO     | src.policies:train:109 - Episode 317\n",
      "2021-08-25 11:17:32.335 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:32.336 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 11:17:32.337 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.83\n",
      "2021-08-25 11:17:32.338 | INFO     | src.policies:train:109 - Episode 318\n",
      "2021-08-25 11:17:32.353 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:32.354 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:17:32.355 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.66\n",
      "2021-08-25 11:17:32.356 | WARNING  | src.policies:train:131 - The actual batch size is 206, instead of 200\n",
      "2021-08-25 11:17:32.363 | INFO     | src.policies:train:157 - Total loss: 0.9951453804969788\n",
      "2021-08-25 11:17:32.365 | INFO     | src.policies:train:103 - Epoch 38 / 800\n",
      "2021-08-25 11:17:32.366 | INFO     | src.policies:train:109 - Episode 319\n",
      "2021-08-25 11:17:32.384 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:32.385 | INFO     | src.policies:train:121 - Mean episode return: 44.0\n",
      "2021-08-25 11:17:32.386 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.73\n",
      "2021-08-25 11:17:32.386 | INFO     | src.policies:train:109 - Episode 320\n",
      "2021-08-25 11:17:32.394 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:32.395 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:17:32.396 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.65\n",
      "2021-08-25 11:17:32.397 | INFO     | src.policies:train:109 - Episode 321\n",
      "2021-08-25 11:17:32.403 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:32.404 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:17:32.405 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.59\n",
      "2021-08-25 11:17:32.406 | INFO     | src.policies:train:109 - Episode 322\n",
      "2021-08-25 11:17:32.417 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:32.418 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:17:32.419 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.65\n",
      "2021-08-25 11:17:32.420 | INFO     | src.policies:train:109 - Episode 323\n",
      "2021-08-25 11:17:32.432 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:32.434 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 11:17:32.435 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.53\n",
      "2021-08-25 11:17:32.436 | INFO     | src.policies:train:109 - Episode 324\n",
      "2021-08-25 11:17:32.455 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:32.456 | INFO     | src.policies:train:121 - Mean episode return: 54.0\n",
      "2021-08-25 11:17:32.457 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.97\n",
      "2021-08-25 11:17:32.458 | INFO     | src.policies:train:109 - Episode 325\n",
      "2021-08-25 11:17:32.466 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:32.467 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:17:32.468 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.93\n",
      "2021-08-25 11:17:32.469 | INFO     | src.policies:train:109 - Episode 326\n",
      "2021-08-25 11:17:32.479 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:32.480 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:17:32.481 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.99\n",
      "2021-08-25 11:17:32.482 | WARNING  | src.policies:train:131 - The actual batch size is 215, instead of 200\n",
      "2021-08-25 11:17:32.487 | INFO     | src.policies:train:157 - Total loss: 0.9953486323356628\n",
      "2021-08-25 11:17:32.490 | INFO     | src.policies:train:103 - Epoch 39 / 800\n",
      "2021-08-25 11:17:32.491 | INFO     | src.policies:train:109 - Episode 327\n",
      "2021-08-25 11:17:32.501 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:32.503 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:17:32.503 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.73\n",
      "2021-08-25 11:17:32.504 | INFO     | src.policies:train:109 - Episode 328\n",
      "2021-08-25 11:17:32.514 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:32.515 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:17:32.516 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.63\n",
      "2021-08-25 11:17:32.517 | INFO     | src.policies:train:109 - Episode 329\n",
      "2021-08-25 11:17:32.530 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:32.531 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:32.532 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.73\n",
      "2021-08-25 11:17:32.533 | INFO     | src.policies:train:109 - Episode 330\n",
      "2021-08-25 11:17:32.545 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:32.546 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:17:32.547 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.77\n",
      "2021-08-25 11:17:32.547 | INFO     | src.policies:train:109 - Episode 331\n",
      "2021-08-25 11:17:32.569 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:32.570 | INFO     | src.policies:train:121 - Mean episode return: 52.0\n",
      "2021-08-25 11:17:32.571 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.09\n",
      "2021-08-25 11:17:32.572 | INFO     | src.policies:train:109 - Episode 332\n",
      "2021-08-25 11:17:32.585 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:32.586 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 11:17:32.586 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.18\n",
      "2021-08-25 11:17:32.587 | INFO     | src.policies:train:109 - Episode 333\n",
      "2021-08-25 11:17:32.596 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:32.597 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:17:32.598 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.11\n",
      "2021-08-25 11:17:32.599 | INFO     | src.policies:train:109 - Episode 334\n",
      "2021-08-25 11:17:32.623 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:32.624 | INFO     | src.policies:train:121 - Mean episode return: 67.0\n",
      "2021-08-25 11:17:32.625 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.25\n",
      "2021-08-25 11:17:32.626 | WARNING  | src.policies:train:131 - The actual batch size is 263, instead of 200\n",
      "2021-08-25 11:17:32.633 | INFO     | src.policies:train:157 - Total loss: 0.996197521686554\n",
      "2021-08-25 11:17:32.636 | INFO     | src.policies:train:103 - Epoch 40 / 800\n",
      "2021-08-25 11:17:32.637 | INFO     | src.policies:train:109 - Episode 335\n",
      "2021-08-25 11:17:32.646 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:32.647 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:17:32.648 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.32\n",
      "2021-08-25 11:17:32.649 | INFO     | src.policies:train:109 - Episode 336\n",
      "2021-08-25 11:17:32.657 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:32.658 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:17:32.659 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.28\n",
      "2021-08-25 11:17:32.660 | INFO     | src.policies:train:109 - Episode 337\n",
      "2021-08-25 11:17:32.670 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:32.671 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:17:32.672 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.24\n",
      "2021-08-25 11:17:32.673 | INFO     | src.policies:train:109 - Episode 338\n",
      "2021-08-25 11:17:32.683 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:32.684 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:17:32.685 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.09\n",
      "2021-08-25 11:17:32.686 | INFO     | src.policies:train:109 - Episode 339\n",
      "2021-08-25 11:17:32.694 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:32.695 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:17:32.696 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.94\n",
      "2021-08-25 11:17:32.697 | INFO     | src.policies:train:109 - Episode 340\n",
      "2021-08-25 11:17:32.706 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:32.707 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:17:32.707 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.73\n",
      "2021-08-25 11:17:32.708 | INFO     | src.policies:train:109 - Episode 341\n",
      "2021-08-25 11:17:32.717 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:32.718 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:17:32.718 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.69\n",
      "2021-08-25 11:17:32.719 | INFO     | src.policies:train:109 - Episode 342\n",
      "2021-08-25 11:17:32.727 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:32.728 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:17:32.728 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.57\n",
      "2021-08-25 11:17:32.729 | INFO     | src.policies:train:109 - Episode 343\n",
      "2021-08-25 11:17:32.752 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:32.753 | INFO     | src.policies:train:121 - Mean episode return: 61.0\n",
      "2021-08-25 11:17:32.754 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.94\n",
      "2021-08-25 11:17:32.755 | INFO     | src.policies:train:109 - Episode 344\n",
      "2021-08-25 11:17:32.773 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:32.774 | INFO     | src.policies:train:121 - Mean episode return: 46.0\n",
      "2021-08-25 11:17:32.775 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.11\n",
      "2021-08-25 11:17:32.776 | WARNING  | src.policies:train:131 - The actual batch size is 241, instead of 200\n",
      "2021-08-25 11:17:32.783 | INFO     | src.policies:train:157 - Total loss: 0.9958505630493164\n",
      "2021-08-25 11:17:32.785 | INFO     | src.policies:train:103 - Epoch 41 / 800\n",
      "2021-08-25 11:17:32.786 | INFO     | src.policies:train:109 - Episode 345\n",
      "2021-08-25 11:17:32.793 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:32.795 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:17:32.795 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.1\n",
      "2021-08-25 11:17:32.796 | INFO     | src.policies:train:109 - Episode 346\n",
      "2021-08-25 11:17:32.803 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:32.804 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 11:17:32.805 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.97\n",
      "2021-08-25 11:17:32.806 | INFO     | src.policies:train:109 - Episode 347\n",
      "2021-08-25 11:17:32.818 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:32.819 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:17:32.820 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.04\n",
      "2021-08-25 11:17:32.821 | INFO     | src.policies:train:109 - Episode 348\n",
      "2021-08-25 11:17:32.829 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:32.830 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:17:32.831 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.03\n",
      "2021-08-25 11:17:32.832 | INFO     | src.policies:train:109 - Episode 349\n",
      "2021-08-25 11:17:32.842 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:32.843 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:17:32.843 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.99\n",
      "2021-08-25 11:17:32.844 | INFO     | src.policies:train:109 - Episode 350\n",
      "2021-08-25 11:17:32.855 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:32.856 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:32.857 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.1\n",
      "2021-08-25 11:17:32.858 | INFO     | src.policies:train:109 - Episode 351\n",
      "2021-08-25 11:17:32.870 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:32.871 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 11:17:32.872 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.18\n",
      "2021-08-25 11:17:32.873 | INFO     | src.policies:train:109 - Episode 352\n",
      "2021-08-25 11:17:32.883 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:32.884 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:17:32.884 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.2\n",
      "2021-08-25 11:17:32.885 | INFO     | src.policies:train:109 - Episode 353\n",
      "2021-08-25 11:17:32.914 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:32.915 | INFO     | src.policies:train:121 - Mean episode return: 81.0\n",
      "2021-08-25 11:17:32.916 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.77\n",
      "2021-08-25 11:17:32.917 | WARNING  | src.policies:train:131 - The actual batch size is 243, instead of 200\n",
      "2021-08-25 11:17:32.923 | INFO     | src.policies:train:157 - Total loss: 0.9958845376968384\n",
      "2021-08-25 11:17:32.925 | INFO     | src.policies:train:103 - Epoch 42 / 800\n",
      "2021-08-25 11:17:32.926 | INFO     | src.policies:train:109 - Episode 354\n",
      "2021-08-25 11:17:32.938 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:32.940 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 11:17:32.940 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.0\n",
      "2021-08-25 11:17:32.941 | INFO     | src.policies:train:109 - Episode 355\n",
      "2021-08-25 11:17:32.954 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:32.955 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 11:17:32.956 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.04\n",
      "2021-08-25 11:17:32.957 | INFO     | src.policies:train:109 - Episode 356\n",
      "2021-08-25 11:17:32.963 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:32.964 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 11:17:32.965 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.0\n",
      "2021-08-25 11:17:32.966 | INFO     | src.policies:train:109 - Episode 357\n",
      "2021-08-25 11:17:32.976 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:32.977 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 11:17:32.978 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.27\n",
      "2021-08-25 11:17:32.979 | INFO     | src.policies:train:109 - Episode 358\n",
      "2021-08-25 11:17:32.985 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:32.986 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 11:17:32.987 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.96\n",
      "2021-08-25 11:17:32.987 | INFO     | src.policies:train:109 - Episode 359\n",
      "2021-08-25 11:17:32.999 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:33.000 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 11:17:33.001 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.99\n",
      "2021-08-25 11:17:33.002 | INFO     | src.policies:train:109 - Episode 360\n",
      "2021-08-25 11:17:33.018 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:33.019 | INFO     | src.policies:train:121 - Mean episode return: 47.0\n",
      "2021-08-25 11:17:33.020 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.27\n",
      "2021-08-25 11:17:33.021 | INFO     | src.policies:train:109 - Episode 361\n",
      "2021-08-25 11:17:33.028 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:33.028 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:17:33.029 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.22\n",
      "2021-08-25 11:17:33.030 | INFO     | src.policies:train:109 - Episode 362\n",
      "2021-08-25 11:17:33.040 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:33.041 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:17:33.042 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.31\n",
      "2021-08-25 11:17:33.042 | WARNING  | src.policies:train:131 - The actual batch size is 213, instead of 200\n",
      "2021-08-25 11:17:33.048 | INFO     | src.policies:train:157 - Total loss: 0.9953050017356873\n",
      "2021-08-25 11:17:33.051 | INFO     | src.policies:train:103 - Epoch 43 / 800\n",
      "2021-08-25 11:17:33.052 | INFO     | src.policies:train:109 - Episode 363\n",
      "2021-08-25 11:17:33.061 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:33.063 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:17:33.064 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.25\n",
      "2021-08-25 11:17:33.064 | INFO     | src.policies:train:109 - Episode 364\n",
      "2021-08-25 11:17:33.071 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:33.072 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:17:33.073 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.17\n",
      "2021-08-25 11:17:33.074 | INFO     | src.policies:train:109 - Episode 365\n",
      "2021-08-25 11:17:33.087 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:33.088 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 11:17:33.089 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.03\n",
      "2021-08-25 11:17:33.090 | INFO     | src.policies:train:109 - Episode 366\n",
      "2021-08-25 11:17:33.109 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:33.110 | INFO     | src.policies:train:121 - Mean episode return: 46.0\n",
      "2021-08-25 11:17:33.111 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.34\n",
      "2021-08-25 11:17:33.112 | INFO     | src.policies:train:109 - Episode 367\n",
      "2021-08-25 11:17:33.124 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:33.125 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:17:33.126 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.37\n",
      "2021-08-25 11:17:33.127 | INFO     | src.policies:train:109 - Episode 368\n",
      "2021-08-25 11:17:33.137 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:33.138 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:17:33.139 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.25\n",
      "2021-08-25 11:17:33.140 | INFO     | src.policies:train:109 - Episode 369\n",
      "2021-08-25 11:17:33.149 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:33.150 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:17:33.151 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.17\n",
      "2021-08-25 11:17:33.153 | INFO     | src.policies:train:109 - Episode 370\n",
      "2021-08-25 11:17:33.163 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:33.164 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:17:33.165 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.87\n",
      "2021-08-25 11:17:33.166 | INFO     | src.policies:train:109 - Episode 371\n",
      "2021-08-25 11:17:33.185 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:33.186 | INFO     | src.policies:train:121 - Mean episode return: 43.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:33.187 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.17\n",
      "2021-08-25 11:17:33.188 | WARNING  | src.policies:train:131 - The actual batch size is 221, instead of 200\n",
      "2021-08-25 11:17:33.196 | INFO     | src.policies:train:157 - Total loss: 0.9954748749732971\n",
      "2021-08-25 11:17:33.200 | INFO     | src.policies:train:103 - Epoch 44 / 800\n",
      "2021-08-25 11:17:33.201 | INFO     | src.policies:train:109 - Episode 372\n",
      "2021-08-25 11:17:33.208 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:33.209 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:17:33.210 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.08\n",
      "2021-08-25 11:17:33.211 | INFO     | src.policies:train:109 - Episode 373\n",
      "2021-08-25 11:17:33.221 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:33.222 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:17:33.223 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.94\n",
      "2021-08-25 11:17:33.224 | INFO     | src.policies:train:109 - Episode 374\n",
      "2021-08-25 11:17:33.237 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:33.238 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:17:33.239 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.9\n",
      "2021-08-25 11:17:33.240 | INFO     | src.policies:train:109 - Episode 375\n",
      "2021-08-25 11:17:33.250 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:33.251 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:17:33.252 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.85\n",
      "2021-08-25 11:17:33.253 | INFO     | src.policies:train:109 - Episode 376\n",
      "2021-08-25 11:17:33.264 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:33.265 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:17:33.266 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.82\n",
      "2021-08-25 11:17:33.267 | INFO     | src.policies:train:109 - Episode 377\n",
      "2021-08-25 11:17:33.276 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:33.277 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:17:33.278 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.67\n",
      "2021-08-25 11:17:33.279 | INFO     | src.policies:train:109 - Episode 378\n",
      "2021-08-25 11:17:33.291 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:33.292 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 11:17:33.293 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.69\n",
      "2021-08-25 11:17:33.294 | INFO     | src.policies:train:109 - Episode 379\n",
      "2021-08-25 11:17:33.310 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:33.311 | INFO     | src.policies:train:121 - Mean episode return: 42.0\n",
      "2021-08-25 11:17:33.311 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.91\n",
      "2021-08-25 11:17:33.312 | INFO     | src.policies:train:109 - Episode 380\n",
      "2021-08-25 11:17:33.324 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:33.325 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 11:17:33.326 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.79\n",
      "2021-08-25 11:17:33.327 | INFO     | src.policies:train:109 - Episode 381\n",
      "2021-08-25 11:17:33.339 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:33.340 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:17:33.341 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.66\n",
      "2021-08-25 11:17:33.342 | WARNING  | src.policies:train:131 - The actual batch size is 211, instead of 200\n",
      "2021-08-25 11:17:33.349 | INFO     | src.policies:train:157 - Total loss: 0.9952603578567505\n",
      "2021-08-25 11:17:33.352 | INFO     | src.policies:train:103 - Epoch 45 / 800\n",
      "2021-08-25 11:17:33.353 | INFO     | src.policies:train:109 - Episode 382\n",
      "2021-08-25 11:17:33.364 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:33.365 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:17:33.366 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.75\n",
      "2021-08-25 11:17:33.367 | INFO     | src.policies:train:109 - Episode 383\n",
      "2021-08-25 11:17:33.380 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:33.381 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:17:33.382 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.56\n",
      "2021-08-25 11:17:33.383 | INFO     | src.policies:train:109 - Episode 384\n",
      "2021-08-25 11:17:33.391 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:33.392 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:17:33.393 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.57\n",
      "2021-08-25 11:17:33.394 | INFO     | src.policies:train:109 - Episode 385\n",
      "2021-08-25 11:17:33.404 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:33.405 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:17:33.406 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.59\n",
      "2021-08-25 11:17:33.407 | INFO     | src.policies:train:109 - Episode 386\n",
      "2021-08-25 11:17:33.424 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:33.425 | INFO     | src.policies:train:121 - Mean episode return: 38.0\n",
      "2021-08-25 11:17:33.426 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.68\n",
      "2021-08-25 11:17:33.427 | INFO     | src.policies:train:109 - Episode 387\n",
      "2021-08-25 11:17:33.449 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:33.451 | INFO     | src.policies:train:121 - Mean episode return: 57.0\n",
      "2021-08-25 11:17:33.452 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.91\n",
      "2021-08-25 11:17:33.453 | INFO     | src.policies:train:109 - Episode 388\n",
      "2021-08-25 11:17:33.463 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:33.465 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:17:33.465 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.83\n",
      "2021-08-25 11:17:33.466 | INFO     | src.policies:train:109 - Episode 389\n",
      "2021-08-25 11:17:33.484 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:33.485 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 11:17:33.486 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.09\n",
      "2021-08-25 11:17:33.487 | WARNING  | src.policies:train:131 - The actual batch size is 234, instead of 200\n",
      "2021-08-25 11:17:33.495 | INFO     | src.policies:train:157 - Total loss: 0.9957263469696045\n",
      "2021-08-25 11:17:33.498 | INFO     | src.policies:train:103 - Epoch 46 / 800\n",
      "2021-08-25 11:17:33.500 | INFO     | src.policies:train:109 - Episode 390\n",
      "2021-08-25 11:17:33.510 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:33.511 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:17:33.512 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.13\n",
      "2021-08-25 11:17:33.513 | INFO     | src.policies:train:109 - Episode 391\n",
      "2021-08-25 11:17:33.521 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:33.522 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:17:33.522 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:33.524 | INFO     | src.policies:train:109 - Episode 392\n",
      "2021-08-25 11:17:33.530 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:33.531 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 11:17:33.532 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.89\n",
      "2021-08-25 11:17:33.533 | INFO     | src.policies:train:109 - Episode 393\n",
      "2021-08-25 11:17:33.539 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:33.540 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:17:33.541 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.87\n",
      "2021-08-25 11:17:33.542 | INFO     | src.policies:train:109 - Episode 394\n",
      "2021-08-25 11:17:33.552 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:33.553 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:17:33.554 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.61\n",
      "2021-08-25 11:17:33.555 | INFO     | src.policies:train:109 - Episode 395\n",
      "2021-08-25 11:17:33.572 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:33.573 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 11:17:33.574 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.74\n",
      "2021-08-25 11:17:33.575 | INFO     | src.policies:train:109 - Episode 396\n",
      "2021-08-25 11:17:33.597 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:33.598 | INFO     | src.policies:train:121 - Mean episode return: 55.0\n",
      "2021-08-25 11:17:33.599 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.14\n",
      "2021-08-25 11:17:33.600 | INFO     | src.policies:train:109 - Episode 397\n",
      "2021-08-25 11:17:33.611 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:33.612 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:17:33.613 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.9\n",
      "2021-08-25 11:17:33.614 | INFO     | src.policies:train:109 - Episode 398\n",
      "2021-08-25 11:17:33.631 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:33.633 | INFO     | src.policies:train:121 - Mean episode return: 38.0\n",
      "2021-08-25 11:17:33.634 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.02\n",
      "2021-08-25 11:17:33.634 | WARNING  | src.policies:train:131 - The actual batch size is 224, instead of 200\n",
      "2021-08-25 11:17:33.642 | INFO     | src.policies:train:157 - Total loss: 0.9955354332923889\n",
      "2021-08-25 11:17:33.645 | INFO     | src.policies:train:103 - Epoch 47 / 800\n",
      "2021-08-25 11:17:33.646 | INFO     | src.policies:train:109 - Episode 399\n",
      "2021-08-25 11:17:33.658 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:33.660 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 11:17:33.660 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.86\n",
      "2021-08-25 11:17:33.661 | INFO     | src.policies:train:109 - Episode 400\n",
      "2021-08-25 11:17:33.680 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:33.682 | INFO     | src.policies:train:121 - Mean episode return: 46.0\n",
      "2021-08-25 11:17:33.683 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.15\n",
      "2021-08-25 11:17:33.683 | INFO     | src.policies:train:109 - Episode 401\n",
      "2021-08-25 11:17:33.695 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:33.697 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:17:33.698 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.29\n",
      "2021-08-25 11:17:33.698 | INFO     | src.policies:train:109 - Episode 402\n",
      "2021-08-25 11:17:33.711 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:33.713 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 11:17:33.714 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.4\n",
      "2021-08-25 11:17:33.715 | INFO     | src.policies:train:109 - Episode 403\n",
      "2021-08-25 11:17:33.729 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:33.730 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:17:33.732 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.57\n",
      "2021-08-25 11:17:33.732 | INFO     | src.policies:train:109 - Episode 404\n",
      "2021-08-25 11:17:33.742 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:33.743 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:17:33.744 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.46\n",
      "2021-08-25 11:17:33.744 | INFO     | src.policies:train:109 - Episode 405\n",
      "2021-08-25 11:17:33.752 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:33.754 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:17:33.754 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.3\n",
      "2021-08-25 11:17:33.755 | INFO     | src.policies:train:109 - Episode 406\n",
      "2021-08-25 11:17:33.762 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:33.763 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:17:33.763 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.21\n",
      "2021-08-25 11:17:33.765 | WARNING  | src.policies:train:131 - The actual batch size is 204, instead of 200\n",
      "2021-08-25 11:17:33.772 | INFO     | src.policies:train:157 - Total loss: 0.9950978755950928\n",
      "2021-08-25 11:17:33.775 | INFO     | src.policies:train:103 - Epoch 48 / 800\n",
      "2021-08-25 11:17:33.776 | INFO     | src.policies:train:109 - Episode 407\n",
      "2021-08-25 11:17:33.791 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:33.792 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 11:17:33.793 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.4\n",
      "2021-08-25 11:17:33.794 | INFO     | src.policies:train:109 - Episode 408\n",
      "2021-08-25 11:17:33.805 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:33.806 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:17:33.806 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.39\n",
      "2021-08-25 11:17:33.807 | INFO     | src.policies:train:109 - Episode 409\n",
      "2021-08-25 11:17:33.825 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:33.826 | INFO     | src.policies:train:121 - Mean episode return: 38.0\n",
      "2021-08-25 11:17:33.826 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.45\n",
      "2021-08-25 11:17:33.827 | INFO     | src.policies:train:109 - Episode 410\n",
      "2021-08-25 11:17:33.838 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:33.839 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:17:33.840 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.36\n",
      "2021-08-25 11:17:33.841 | INFO     | src.policies:train:109 - Episode 411\n",
      "2021-08-25 11:17:33.852 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:33.853 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:17:33.854 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.07\n",
      "2021-08-25 11:17:33.855 | INFO     | src.policies:train:109 - Episode 412\n",
      "2021-08-25 11:17:33.865 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:33.866 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:17:33.867 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:33.868 | INFO     | src.policies:train:109 - Episode 413\n",
      "2021-08-25 11:17:33.879 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:33.881 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:17:33.882 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.9\n",
      "2021-08-25 11:17:33.882 | INFO     | src.policies:train:109 - Episode 414\n",
      "2021-08-25 11:17:33.894 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:33.895 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:17:33.896 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.56\n",
      "2021-08-25 11:17:33.897 | INFO     | src.policies:train:109 - Episode 415\n",
      "2021-08-25 11:17:33.908 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:33.909 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:17:33.910 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.49\n",
      "2021-08-25 11:17:33.911 | WARNING  | src.policies:train:131 - The actual batch size is 209, instead of 200\n",
      "2021-08-25 11:17:33.919 | INFO     | src.policies:train:157 - Total loss: 0.9952150583267212\n",
      "2021-08-25 11:17:33.921 | INFO     | src.policies:train:103 - Epoch 49 / 800\n",
      "2021-08-25 11:17:33.922 | INFO     | src.policies:train:109 - Episode 416\n",
      "2021-08-25 11:17:33.931 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:33.933 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:17:33.934 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.45\n",
      "2021-08-25 11:17:33.935 | INFO     | src.policies:train:109 - Episode 417\n",
      "2021-08-25 11:17:33.946 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:33.947 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:17:33.948 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.38\n",
      "2021-08-25 11:17:33.949 | INFO     | src.policies:train:109 - Episode 418\n",
      "2021-08-25 11:17:33.960 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:33.961 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:17:33.962 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.36\n",
      "2021-08-25 11:17:33.962 | INFO     | src.policies:train:109 - Episode 419\n",
      "2021-08-25 11:17:33.971 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:33.973 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:17:33.973 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.12\n",
      "2021-08-25 11:17:33.974 | INFO     | src.policies:train:109 - Episode 420\n",
      "2021-08-25 11:17:34.010 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:34.011 | INFO     | src.policies:train:121 - Mean episode return: 104.0\n",
      "2021-08-25 11:17:34.012 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.01\n",
      "2021-08-25 11:17:34.013 | INFO     | src.policies:train:109 - Episode 421\n",
      "2021-08-25 11:17:34.024 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:34.025 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:17:34.026 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.08\n",
      "2021-08-25 11:17:34.027 | WARNING  | src.policies:train:131 - The actual batch size is 201, instead of 200\n",
      "2021-08-25 11:17:34.034 | INFO     | src.policies:train:157 - Total loss: 0.9950246214866638\n",
      "2021-08-25 11:17:34.037 | INFO     | src.policies:train:103 - Epoch 50 / 800\n",
      "2021-08-25 11:17:34.038 | INFO     | src.policies:train:109 - Episode 422\n",
      "2021-08-25 11:17:34.048 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:34.049 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:17:34.050 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.03\n",
      "2021-08-25 11:17:34.051 | INFO     | src.policies:train:109 - Episode 423\n",
      "2021-08-25 11:17:34.062 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:34.063 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:17:34.064 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.89\n",
      "2021-08-25 11:17:34.065 | INFO     | src.policies:train:109 - Episode 424\n",
      "2021-08-25 11:17:34.083 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:34.084 | INFO     | src.policies:train:121 - Mean episode return: 43.0\n",
      "2021-08-25 11:17:34.085 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.78\n",
      "2021-08-25 11:17:34.086 | INFO     | src.policies:train:109 - Episode 425\n",
      "2021-08-25 11:17:34.103 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:34.104 | INFO     | src.policies:train:121 - Mean episode return: 41.0\n",
      "2021-08-25 11:17:34.105 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.04\n",
      "2021-08-25 11:17:34.106 | INFO     | src.policies:train:109 - Episode 426\n",
      "2021-08-25 11:17:34.127 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:34.128 | INFO     | src.policies:train:121 - Mean episode return: 51.0\n",
      "2021-08-25 11:17:34.129 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.38\n",
      "2021-08-25 11:17:34.130 | INFO     | src.policies:train:109 - Episode 427\n",
      "2021-08-25 11:17:34.140 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:34.141 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:17:34.142 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.34\n",
      "2021-08-25 11:17:34.143 | INFO     | src.policies:train:109 - Episode 428\n",
      "2021-08-25 11:17:34.151 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:34.152 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 11:17:34.153 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.23\n",
      "2021-08-25 11:17:34.154 | WARNING  | src.policies:train:131 - The actual batch size is 203, instead of 200\n",
      "2021-08-25 11:17:34.162 | INFO     | src.policies:train:157 - Total loss: 0.995073676109314\n",
      "2021-08-25 11:17:34.164 | INFO     | src.policies:train:103 - Epoch 51 / 800\n",
      "2021-08-25 11:17:34.165 | INFO     | src.policies:train:109 - Episode 429\n",
      "2021-08-25 11:17:34.176 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:34.177 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 11:17:34.177 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.18\n",
      "2021-08-25 11:17:34.179 | INFO     | src.policies:train:109 - Episode 430\n",
      "2021-08-25 11:17:34.190 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:34.191 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 11:17:34.192 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.19\n",
      "2021-08-25 11:17:34.193 | INFO     | src.policies:train:109 - Episode 431\n",
      "2021-08-25 11:17:34.206 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:34.207 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 11:17:34.208 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.01\n",
      "2021-08-25 11:17:34.209 | INFO     | src.policies:train:109 - Episode 432\n",
      "2021-08-25 11:17:34.218 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:34.219 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:17:34.219 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.88\n",
      "2021-08-25 11:17:34.220 | INFO     | src.policies:train:109 - Episode 433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:34.231 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:34.232 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:17:34.233 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.95\n",
      "2021-08-25 11:17:34.234 | INFO     | src.policies:train:109 - Episode 434\n",
      "2021-08-25 11:17:34.248 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:34.249 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 11:17:34.250 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.59\n",
      "2021-08-25 11:17:34.251 | INFO     | src.policies:train:109 - Episode 435\n",
      "2021-08-25 11:17:34.260 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:34.261 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:17:34.262 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.51\n",
      "2021-08-25 11:17:34.263 | INFO     | src.policies:train:109 - Episode 436\n",
      "2021-08-25 11:17:34.278 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:34.279 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 11:17:34.279 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.74\n",
      "2021-08-25 11:17:34.280 | WARNING  | src.policies:train:131 - The actual batch size is 204, instead of 200\n",
      "2021-08-25 11:17:34.287 | INFO     | src.policies:train:157 - Total loss: 0.995097815990448\n",
      "2021-08-25 11:17:34.289 | INFO     | src.policies:train:103 - Epoch 52 / 800\n",
      "2021-08-25 11:17:34.290 | INFO     | src.policies:train:109 - Episode 437\n",
      "2021-08-25 11:17:34.311 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:34.312 | INFO     | src.policies:train:121 - Mean episode return: 54.0\n",
      "2021-08-25 11:17:34.313 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.04\n",
      "2021-08-25 11:17:34.314 | INFO     | src.policies:train:109 - Episode 438\n",
      "2021-08-25 11:17:34.333 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:34.334 | INFO     | src.policies:train:121 - Mean episode return: 45.0\n",
      "2021-08-25 11:17:34.335 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.32\n",
      "2021-08-25 11:17:34.336 | INFO     | src.policies:train:109 - Episode 439\n",
      "2021-08-25 11:17:34.348 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:34.350 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:17:34.350 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.43\n",
      "2021-08-25 11:17:34.352 | INFO     | src.policies:train:109 - Episode 440\n",
      "2021-08-25 11:17:34.375 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:34.377 | INFO     | src.policies:train:121 - Mean episode return: 62.0\n",
      "2021-08-25 11:17:34.378 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.86\n",
      "2021-08-25 11:17:34.378 | INFO     | src.policies:train:109 - Episode 441\n",
      "2021-08-25 11:17:34.406 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:34.407 | INFO     | src.policies:train:121 - Mean episode return: 75.0\n",
      "2021-08-25 11:17:34.408 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.48\n",
      "2021-08-25 11:17:34.409 | WARNING  | src.policies:train:131 - The actual batch size is 260, instead of 200\n",
      "2021-08-25 11:17:34.415 | INFO     | src.policies:train:157 - Total loss: 0.9961538314819336\n",
      "2021-08-25 11:17:34.418 | INFO     | src.policies:train:103 - Epoch 53 / 800\n",
      "2021-08-25 11:17:34.419 | INFO     | src.policies:train:109 - Episode 442\n",
      "2021-08-25 11:17:34.427 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:34.429 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:17:34.429 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.57\n",
      "2021-08-25 11:17:34.430 | INFO     | src.policies:train:109 - Episode 443\n",
      "2021-08-25 11:17:34.440 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:34.441 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:17:34.442 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.15\n",
      "2021-08-25 11:17:34.443 | INFO     | src.policies:train:109 - Episode 444\n",
      "2021-08-25 11:17:34.450 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:34.451 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:17:34.452 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.83\n",
      "2021-08-25 11:17:34.453 | INFO     | src.policies:train:109 - Episode 445\n",
      "2021-08-25 11:17:34.463 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:34.464 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:17:34.465 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.87\n",
      "2021-08-25 11:17:34.465 | INFO     | src.policies:train:109 - Episode 446\n",
      "2021-08-25 11:17:34.478 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:34.479 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 11:17:34.480 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.09\n",
      "2021-08-25 11:17:34.481 | INFO     | src.policies:train:109 - Episode 447\n",
      "2021-08-25 11:17:34.491 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:34.492 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:17:34.493 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.06\n",
      "2021-08-25 11:17:34.494 | INFO     | src.policies:train:109 - Episode 448\n",
      "2021-08-25 11:17:34.501 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:34.502 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:17:34.503 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.04\n",
      "2021-08-25 11:17:34.504 | INFO     | src.policies:train:109 - Episode 449\n",
      "2021-08-25 11:17:34.519 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:34.520 | INFO     | src.policies:train:121 - Mean episode return: 38.0\n",
      "2021-08-25 11:17:34.521 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.23\n",
      "2021-08-25 11:17:34.522 | INFO     | src.policies:train:109 - Episode 450\n",
      "2021-08-25 11:17:34.529 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:34.530 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:17:34.531 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.12\n",
      "2021-08-25 11:17:34.532 | INFO     | src.policies:train:109 - Episode 451\n",
      "2021-08-25 11:17:34.548 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:34.549 | INFO     | src.policies:train:121 - Mean episode return: 44.0\n",
      "2021-08-25 11:17:34.550 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.26\n",
      "2021-08-25 11:17:34.551 | WARNING  | src.policies:train:131 - The actual batch size is 240, instead of 200\n",
      "2021-08-25 11:17:34.558 | INFO     | src.policies:train:157 - Total loss: 0.9958330988883972\n",
      "2021-08-25 11:17:34.561 | INFO     | src.policies:train:103 - Epoch 54 / 800\n",
      "2021-08-25 11:17:34.562 | INFO     | src.policies:train:109 - Episode 452\n",
      "2021-08-25 11:17:34.570 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:34.571 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:17:34.572 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.27\n",
      "2021-08-25 11:17:34.573 | INFO     | src.policies:train:109 - Episode 453\n",
      "2021-08-25 11:17:34.580 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:34.581 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:17:34.581 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.58\n",
      "2021-08-25 11:17:34.582 | INFO     | src.policies:train:109 - Episode 454\n",
      "2021-08-25 11:17:34.588 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:34.589 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:17:34.590 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.37\n",
      "2021-08-25 11:17:34.591 | INFO     | src.policies:train:109 - Episode 455\n",
      "2021-08-25 11:17:34.598 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:34.599 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:17:34.599 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.2\n",
      "2021-08-25 11:17:34.600 | INFO     | src.policies:train:109 - Episode 456\n",
      "2021-08-25 11:17:34.612 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:34.613 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:17:34.613 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.36\n",
      "2021-08-25 11:17:34.614 | INFO     | src.policies:train:109 - Episode 457\n",
      "2021-08-25 11:17:34.625 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:34.626 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 11:17:34.627 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.36\n",
      "2021-08-25 11:17:34.628 | INFO     | src.policies:train:109 - Episode 458\n",
      "2021-08-25 11:17:34.637 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:34.638 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:17:34.639 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.43\n",
      "2021-08-25 11:17:34.639 | INFO     | src.policies:train:109 - Episode 459\n",
      "2021-08-25 11:17:34.648 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:34.649 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:17:34.649 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.34\n",
      "2021-08-25 11:17:34.650 | INFO     | src.policies:train:109 - Episode 460\n",
      "2021-08-25 11:17:34.660 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:34.661 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:17:34.662 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.1\n",
      "2021-08-25 11:17:34.663 | INFO     | src.policies:train:109 - Episode 461\n",
      "2021-08-25 11:17:34.678 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:34.680 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:17:34.680 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.27\n",
      "2021-08-25 11:17:34.681 | INFO     | src.policies:train:109 - Episode 462\n",
      "2021-08-25 11:17:34.690 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:34.691 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:17:34.693 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.21\n",
      "2021-08-25 11:17:34.694 | WARNING  | src.policies:train:131 - The actual batch size is 210, instead of 200\n",
      "2021-08-25 11:17:34.700 | INFO     | src.policies:train:157 - Total loss: 0.9952377676963806\n",
      "2021-08-25 11:17:34.702 | INFO     | src.policies:train:103 - Epoch 55 / 800\n",
      "2021-08-25 11:17:34.703 | INFO     | src.policies:train:109 - Episode 463\n",
      "2021-08-25 11:17:34.713 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:34.714 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 11:17:34.715 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.27\n",
      "2021-08-25 11:17:34.716 | INFO     | src.policies:train:109 - Episode 464\n",
      "2021-08-25 11:17:34.724 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:34.725 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:17:34.726 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.36\n",
      "2021-08-25 11:17:34.727 | INFO     | src.policies:train:109 - Episode 465\n",
      "2021-08-25 11:17:34.735 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:34.736 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:17:34.737 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.22\n",
      "2021-08-25 11:17:34.738 | INFO     | src.policies:train:109 - Episode 466\n",
      "2021-08-25 11:17:34.744 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:34.745 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:17:34.746 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.89\n",
      "2021-08-25 11:17:34.746 | INFO     | src.policies:train:109 - Episode 467\n",
      "2021-08-25 11:17:34.767 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:34.768 | INFO     | src.policies:train:121 - Mean episode return: 60.0\n",
      "2021-08-25 11:17:34.769 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.27\n",
      "2021-08-25 11:17:34.770 | INFO     | src.policies:train:109 - Episode 468\n",
      "2021-08-25 11:17:34.789 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:34.790 | INFO     | src.policies:train:121 - Mean episode return: 50.0\n",
      "2021-08-25 11:17:34.791 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.61\n",
      "2021-08-25 11:17:34.792 | INFO     | src.policies:train:109 - Episode 469\n",
      "2021-08-25 11:17:34.806 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:34.807 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 11:17:34.807 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.81\n",
      "2021-08-25 11:17:34.808 | WARNING  | src.policies:train:131 - The actual batch size is 222, instead of 200\n",
      "2021-08-25 11:17:34.815 | INFO     | src.policies:train:157 - Total loss: 0.9954952001571655\n",
      "2021-08-25 11:17:34.817 | INFO     | src.policies:train:103 - Epoch 56 / 800\n",
      "2021-08-25 11:17:34.818 | INFO     | src.policies:train:109 - Episode 470\n",
      "2021-08-25 11:17:34.825 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:34.826 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:17:34.827 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.83\n",
      "2021-08-25 11:17:34.828 | INFO     | src.policies:train:109 - Episode 471\n",
      "2021-08-25 11:17:34.841 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:34.842 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 11:17:34.843 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.72\n",
      "2021-08-25 11:17:34.844 | INFO     | src.policies:train:109 - Episode 472\n",
      "2021-08-25 11:17:34.851 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:34.852 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:17:34.853 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.75\n",
      "2021-08-25 11:17:34.854 | INFO     | src.policies:train:109 - Episode 473\n",
      "2021-08-25 11:17:34.865 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:34.866 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 11:17:34.867 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.91\n",
      "2021-08-25 11:17:34.867 | INFO     | src.policies:train:109 - Episode 474\n",
      "2021-08-25 11:17:34.875 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:34.876 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:17:34.876 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.77\n",
      "2021-08-25 11:17:34.877 | INFO     | src.policies:train:109 - Episode 475\n",
      "2021-08-25 11:17:34.889 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:34.890 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 11:17:34.891 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.92\n",
      "2021-08-25 11:17:34.892 | INFO     | src.policies:train:109 - Episode 476\n",
      "2021-08-25 11:17:34.900 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:34.901 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:17:34.902 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.92\n",
      "2021-08-25 11:17:34.903 | INFO     | src.policies:train:109 - Episode 477\n",
      "2021-08-25 11:17:34.914 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:34.915 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:17:34.916 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.09\n",
      "2021-08-25 11:17:34.916 | INFO     | src.policies:train:109 - Episode 478\n",
      "2021-08-25 11:17:34.925 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:34.926 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:17:34.927 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.05\n",
      "2021-08-25 11:17:34.928 | WARNING  | src.policies:train:131 - The actual batch size is 201, instead of 200\n",
      "2021-08-25 11:17:34.934 | INFO     | src.policies:train:157 - Total loss: 0.9950245022773743\n",
      "2021-08-25 11:17:34.936 | INFO     | src.policies:train:103 - Epoch 57 / 800\n",
      "2021-08-25 11:17:34.937 | INFO     | src.policies:train:109 - Episode 479\n",
      "2021-08-25 11:17:34.955 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:34.957 | INFO     | src.policies:train:121 - Mean episode return: 53.0\n",
      "2021-08-25 11:17:34.957 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.16\n",
      "2021-08-25 11:17:34.958 | INFO     | src.policies:train:109 - Episode 480\n",
      "2021-08-25 11:17:34.975 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:34.976 | INFO     | src.policies:train:121 - Mean episode return: 47.0\n",
      "2021-08-25 11:17:34.977 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.35\n",
      "2021-08-25 11:17:34.978 | INFO     | src.policies:train:109 - Episode 481\n",
      "2021-08-25 11:17:34.992 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:34.993 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 11:17:34.993 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.48\n",
      "2021-08-25 11:17:34.994 | INFO     | src.policies:train:109 - Episode 482\n",
      "2021-08-25 11:17:35.001 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:35.002 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:17:35.003 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.38\n",
      "2021-08-25 11:17:35.004 | INFO     | src.policies:train:109 - Episode 483\n",
      "2021-08-25 11:17:35.014 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:35.016 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 11:17:35.016 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.36\n",
      "2021-08-25 11:17:35.017 | INFO     | src.policies:train:109 - Episode 484\n",
      "2021-08-25 11:17:35.023 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:35.024 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:17:35.024 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.35\n",
      "2021-08-25 11:17:35.025 | INFO     | src.policies:train:109 - Episode 485\n",
      "2021-08-25 11:17:35.034 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:35.035 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:17:35.035 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.35\n",
      "2021-08-25 11:17:35.036 | WARNING  | src.policies:train:131 - The actual batch size is 206, instead of 200\n",
      "2021-08-25 11:17:35.041 | INFO     | src.policies:train:157 - Total loss: 0.9951455593109131\n",
      "2021-08-25 11:17:35.043 | INFO     | src.policies:train:103 - Epoch 58 / 800\n",
      "2021-08-25 11:17:35.044 | INFO     | src.policies:train:109 - Episode 486\n",
      "2021-08-25 11:17:35.071 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:35.072 | INFO     | src.policies:train:121 - Mean episode return: 84.0\n",
      "2021-08-25 11:17:35.073 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.81\n",
      "2021-08-25 11:17:35.074 | INFO     | src.policies:train:109 - Episode 487\n",
      "2021-08-25 11:17:35.085 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:35.086 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:17:35.087 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.5\n",
      "2021-08-25 11:17:35.087 | INFO     | src.policies:train:109 - Episode 488\n",
      "2021-08-25 11:17:35.095 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:35.096 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:17:35.097 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.51\n",
      "2021-08-25 11:17:35.098 | INFO     | src.policies:train:109 - Episode 489\n",
      "2021-08-25 11:17:35.106 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:35.107 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:17:35.107 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.27\n",
      "2021-08-25 11:17:35.108 | INFO     | src.policies:train:109 - Episode 490\n",
      "2021-08-25 11:17:35.131 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:35.132 | INFO     | src.policies:train:121 - Mean episode return: 63.0\n",
      "2021-08-25 11:17:35.133 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.68\n",
      "2021-08-25 11:17:35.134 | WARNING  | src.policies:train:131 - The actual batch size is 206, instead of 200\n",
      "2021-08-25 11:17:35.139 | INFO     | src.policies:train:157 - Total loss: 0.9951456189155579\n",
      "2021-08-25 11:17:35.142 | INFO     | src.policies:train:103 - Epoch 59 / 800\n",
      "2021-08-25 11:17:35.143 | INFO     | src.policies:train:109 - Episode 491\n",
      "2021-08-25 11:17:35.153 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:35.154 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 11:17:35.154 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.85\n",
      "2021-08-25 11:17:35.155 | INFO     | src.policies:train:109 - Episode 492\n",
      "2021-08-25 11:17:35.167 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:35.168 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:17:35.168 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.04\n",
      "2021-08-25 11:17:35.169 | INFO     | src.policies:train:109 - Episode 493\n",
      "2021-08-25 11:17:35.177 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:35.178 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:17:35.179 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.09\n",
      "2021-08-25 11:17:35.180 | INFO     | src.policies:train:109 - Episode 494\n",
      "2021-08-25 11:17:35.196 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:35.197 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:35.198 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.28\n",
      "2021-08-25 11:17:35.199 | INFO     | src.policies:train:109 - Episode 495\n",
      "2021-08-25 11:17:35.207 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:35.208 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:17:35.209 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.09\n",
      "2021-08-25 11:17:35.210 | INFO     | src.policies:train:109 - Episode 496\n",
      "2021-08-25 11:17:35.216 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:35.218 | INFO     | src.policies:train:121 - Mean episode return: 9.0\n",
      "2021-08-25 11:17:35.218 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.63\n",
      "2021-08-25 11:17:35.219 | INFO     | src.policies:train:109 - Episode 497\n",
      "2021-08-25 11:17:35.229 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:35.231 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:17:35.231 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.65\n",
      "2021-08-25 11:17:35.233 | INFO     | src.policies:train:109 - Episode 498\n",
      "2021-08-25 11:17:35.252 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:35.254 | INFO     | src.policies:train:121 - Mean episode return: 50.0\n",
      "2021-08-25 11:17:35.255 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.77\n",
      "2021-08-25 11:17:35.256 | WARNING  | src.policies:train:131 - The actual batch size is 211, instead of 200\n",
      "2021-08-25 11:17:35.263 | INFO     | src.policies:train:157 - Total loss: 0.9952605366706848\n",
      "2021-08-25 11:17:35.265 | INFO     | src.policies:train:103 - Epoch 60 / 800\n",
      "2021-08-25 11:17:35.266 | INFO     | src.policies:train:109 - Episode 499\n",
      "2021-08-25 11:17:35.280 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:35.282 | INFO     | src.policies:train:121 - Mean episode return: 38.0\n",
      "2021-08-25 11:17:35.282 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.87\n",
      "2021-08-25 11:17:35.283 | INFO     | src.policies:train:109 - Episode 500\n",
      "2021-08-25 11:17:35.299 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:35.300 | INFO     | src.policies:train:121 - Mean episode return: 39.0\n",
      "2021-08-25 11:17:35.302 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.8\n",
      "2021-08-25 11:17:35.302 | INFO     | src.policies:train:109 - Episode 501\n",
      "2021-08-25 11:17:35.313 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:35.315 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:17:35.316 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.77\n",
      "2021-08-25 11:17:35.317 | INFO     | src.policies:train:109 - Episode 502\n",
      "2021-08-25 11:17:35.328 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:35.329 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:17:35.330 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.73\n",
      "2021-08-25 11:17:35.331 | INFO     | src.policies:train:109 - Episode 503\n",
      "2021-08-25 11:17:35.348 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:35.349 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 11:17:35.350 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.77\n",
      "2021-08-25 11:17:35.351 | INFO     | src.policies:train:109 - Episode 504\n",
      "2021-08-25 11:17:35.361 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:35.362 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:17:35.363 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.75\n",
      "2021-08-25 11:17:35.364 | INFO     | src.policies:train:109 - Episode 505\n",
      "2021-08-25 11:17:35.378 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:35.379 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 11:17:35.380 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.87\n",
      "2021-08-25 11:17:35.381 | WARNING  | src.policies:train:131 - The actual batch size is 203, instead of 200\n",
      "2021-08-25 11:17:35.387 | INFO     | src.policies:train:157 - Total loss: 0.9950737357139587\n",
      "2021-08-25 11:17:35.389 | INFO     | src.policies:train:103 - Epoch 61 / 800\n",
      "2021-08-25 11:17:35.391 | INFO     | src.policies:train:109 - Episode 506\n",
      "2021-08-25 11:17:35.397 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:35.399 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:17:35.400 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.87\n",
      "2021-08-25 11:17:35.400 | INFO     | src.policies:train:109 - Episode 507\n",
      "2021-08-25 11:17:35.408 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:35.410 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:17:35.411 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.64\n",
      "2021-08-25 11:17:35.412 | INFO     | src.policies:train:109 - Episode 508\n",
      "2021-08-25 11:17:35.424 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:35.425 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:17:35.426 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.75\n",
      "2021-08-25 11:17:35.427 | INFO     | src.policies:train:109 - Episode 509\n",
      "2021-08-25 11:17:35.438 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:35.439 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:17:35.440 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.57\n",
      "2021-08-25 11:17:35.441 | INFO     | src.policies:train:109 - Episode 510\n",
      "2021-08-25 11:17:35.450 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:35.451 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:17:35.453 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.56\n",
      "2021-08-25 11:17:35.453 | INFO     | src.policies:train:109 - Episode 511\n",
      "2021-08-25 11:17:35.481 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:35.482 | INFO     | src.policies:train:121 - Mean episode return: 71.0\n",
      "2021-08-25 11:17:35.483 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.09\n",
      "2021-08-25 11:17:35.484 | INFO     | src.policies:train:109 - Episode 512\n",
      "2021-08-25 11:17:35.497 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:35.498 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 11:17:35.499 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.23\n",
      "2021-08-25 11:17:35.500 | INFO     | src.policies:train:109 - Episode 513\n",
      "2021-08-25 11:17:35.510 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:35.512 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:17:35.513 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.21\n",
      "2021-08-25 11:17:35.514 | WARNING  | src.policies:train:131 - The actual batch size is 213, instead of 200\n",
      "2021-08-25 11:17:35.521 | INFO     | src.policies:train:157 - Total loss: 0.9953048825263977\n",
      "2021-08-25 11:17:35.524 | INFO     | src.policies:train:103 - Epoch 62 / 800\n",
      "2021-08-25 11:17:35.525 | INFO     | src.policies:train:109 - Episode 514\n",
      "2021-08-25 11:17:35.540 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:35.542 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 11:17:35.542 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:35.543 | INFO     | src.policies:train:109 - Episode 515\n",
      "2021-08-25 11:17:35.552 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:35.554 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:17:35.555 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.3\n",
      "2021-08-25 11:17:35.555 | INFO     | src.policies:train:109 - Episode 516\n",
      "2021-08-25 11:17:35.566 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:35.567 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:17:35.568 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.29\n",
      "2021-08-25 11:17:35.569 | INFO     | src.policies:train:109 - Episode 517\n",
      "2021-08-25 11:17:35.590 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:35.592 | INFO     | src.policies:train:121 - Mean episode return: 52.0\n",
      "2021-08-25 11:17:35.593 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.63\n",
      "2021-08-25 11:17:35.594 | INFO     | src.policies:train:109 - Episode 518\n",
      "2021-08-25 11:17:35.623 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:35.624 | INFO     | src.policies:train:121 - Mean episode return: 78.0\n",
      "2021-08-25 11:17:35.624 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.2\n",
      "2021-08-25 11:17:35.625 | INFO     | src.policies:train:109 - Episode 519\n",
      "2021-08-25 11:17:35.636 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:35.637 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:17:35.638 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.21\n",
      "2021-08-25 11:17:35.639 | WARNING  | src.policies:train:131 - The actual batch size is 219, instead of 200\n",
      "2021-08-25 11:17:35.645 | INFO     | src.policies:train:157 - Total loss: 0.995433509349823\n",
      "2021-08-25 11:17:35.648 | INFO     | src.policies:train:103 - Epoch 63 / 800\n",
      "2021-08-25 11:17:35.649 | INFO     | src.policies:train:109 - Episode 520\n",
      "2021-08-25 11:17:35.661 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:35.663 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:17:35.664 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.46\n",
      "2021-08-25 11:17:35.665 | INFO     | src.policies:train:109 - Episode 521\n",
      "2021-08-25 11:17:35.682 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:35.683 | INFO     | src.policies:train:121 - Mean episode return: 43.0\n",
      "2021-08-25 11:17:35.684 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.7\n",
      "2021-08-25 11:17:35.685 | INFO     | src.policies:train:109 - Episode 522\n",
      "2021-08-25 11:17:35.698 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:35.699 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:17:35.700 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.78\n",
      "2021-08-25 11:17:35.700 | INFO     | src.policies:train:109 - Episode 523\n",
      "2021-08-25 11:17:35.709 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:35.710 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:17:35.711 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.78\n",
      "2021-08-25 11:17:35.712 | INFO     | src.policies:train:109 - Episode 524\n",
      "2021-08-25 11:17:35.722 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:35.723 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:17:35.724 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.53\n",
      "2021-08-25 11:17:35.725 | INFO     | src.policies:train:109 - Episode 525\n",
      "2021-08-25 11:17:35.736 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:35.737 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:17:35.738 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.36\n",
      "2021-08-25 11:17:35.739 | INFO     | src.policies:train:109 - Episode 526\n",
      "2021-08-25 11:17:35.753 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:35.754 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 11:17:35.755 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.21\n",
      "2021-08-25 11:17:35.756 | INFO     | src.policies:train:109 - Episode 527\n",
      "2021-08-25 11:17:35.770 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:35.772 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 11:17:35.773 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.37\n",
      "2021-08-25 11:17:35.774 | WARNING  | src.policies:train:131 - The actual batch size is 232, instead of 200\n",
      "2021-08-25 11:17:35.781 | INFO     | src.policies:train:157 - Total loss: 0.9956893920898438\n",
      "2021-08-25 11:17:35.783 | INFO     | src.policies:train:103 - Epoch 64 / 800\n",
      "2021-08-25 11:17:35.784 | INFO     | src.policies:train:109 - Episode 528\n",
      "2021-08-25 11:17:35.793 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:35.795 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:17:35.795 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.48\n",
      "2021-08-25 11:17:35.796 | INFO     | src.policies:train:109 - Episode 529\n",
      "2021-08-25 11:17:35.809 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:35.811 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 11:17:35.812 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.54\n",
      "2021-08-25 11:17:35.812 | INFO     | src.policies:train:109 - Episode 530\n",
      "2021-08-25 11:17:35.822 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:35.823 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:17:35.823 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.42\n",
      "2021-08-25 11:17:35.824 | INFO     | src.policies:train:109 - Episode 531\n",
      "2021-08-25 11:17:35.833 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:35.834 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:17:35.835 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.2\n",
      "2021-08-25 11:17:35.836 | INFO     | src.policies:train:109 - Episode 532\n",
      "2021-08-25 11:17:35.854 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:35.855 | INFO     | src.policies:train:121 - Mean episode return: 41.0\n",
      "2021-08-25 11:17:35.855 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.43\n",
      "2021-08-25 11:17:35.856 | INFO     | src.policies:train:109 - Episode 533\n",
      "2021-08-25 11:17:35.872 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:35.873 | INFO     | src.policies:train:121 - Mean episode return: 38.0\n",
      "2021-08-25 11:17:35.875 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.61\n",
      "2021-08-25 11:17:35.876 | INFO     | src.policies:train:109 - Episode 534\n",
      "2021-08-25 11:17:35.898 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:35.899 | INFO     | src.policies:train:121 - Mean episode return: 58.0\n",
      "2021-08-25 11:17:35.900 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.88\n",
      "2021-08-25 11:17:35.901 | WARNING  | src.policies:train:131 - The actual batch size is 216, instead of 200\n",
      "2021-08-25 11:17:35.906 | INFO     | src.policies:train:157 - Total loss: 0.995370090007782\n",
      "2021-08-25 11:17:35.909 | INFO     | src.policies:train:103 - Epoch 65 / 800\n",
      "2021-08-25 11:17:35.910 | INFO     | src.policies:train:109 - Episode 535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:35.925 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:35.926 | INFO     | src.policies:train:121 - Mean episode return: 41.0\n",
      "2021-08-25 11:17:35.927 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.16\n",
      "2021-08-25 11:17:35.928 | INFO     | src.policies:train:109 - Episode 536\n",
      "2021-08-25 11:17:35.944 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:35.945 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 11:17:35.945 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.15\n",
      "2021-08-25 11:17:35.946 | INFO     | src.policies:train:109 - Episode 537\n",
      "2021-08-25 11:17:35.956 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:35.957 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:17:35.958 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.77\n",
      "2021-08-25 11:17:35.959 | INFO     | src.policies:train:109 - Episode 538\n",
      "2021-08-25 11:17:35.966 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:35.968 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:17:35.968 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.45\n",
      "2021-08-25 11:17:35.969 | INFO     | src.policies:train:109 - Episode 539\n",
      "2021-08-25 11:17:35.979 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:35.980 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:17:35.981 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.38\n",
      "2021-08-25 11:17:35.982 | INFO     | src.policies:train:109 - Episode 540\n",
      "2021-08-25 11:17:35.991 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:35.992 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:17:35.993 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.96\n",
      "2021-08-25 11:17:35.994 | INFO     | src.policies:train:109 - Episode 541\n",
      "2021-08-25 11:17:36.002 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:36.003 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:17:36.004 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.35\n",
      "2021-08-25 11:17:36.005 | INFO     | src.policies:train:109 - Episode 542\n",
      "2021-08-25 11:17:36.014 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:36.015 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:17:36.016 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.27\n",
      "2021-08-25 11:17:36.017 | INFO     | src.policies:train:109 - Episode 543\n",
      "2021-08-25 11:17:36.026 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:36.027 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:17:36.028 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.27\n",
      "2021-08-25 11:17:36.029 | INFO     | src.policies:train:109 - Episode 544\n",
      "2021-08-25 11:17:36.057 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:36.058 | INFO     | src.policies:train:121 - Mean episode return: 75.0\n",
      "2021-08-25 11:17:36.058 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.88\n",
      "2021-08-25 11:17:36.059 | WARNING  | src.policies:train:131 - The actual batch size is 265, instead of 200\n",
      "2021-08-25 11:17:36.066 | INFO     | src.policies:train:157 - Total loss: 0.9962263107299805\n",
      "2021-08-25 11:17:36.068 | INFO     | src.policies:train:103 - Epoch 66 / 800\n",
      "2021-08-25 11:17:36.069 | INFO     | src.policies:train:109 - Episode 545\n",
      "2021-08-25 11:17:36.079 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:36.080 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:17:36.081 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.9\n",
      "2021-08-25 11:17:36.082 | INFO     | src.policies:train:109 - Episode 546\n",
      "2021-08-25 11:17:36.092 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:36.094 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:17:36.094 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.8\n",
      "2021-08-25 11:17:36.095 | INFO     | src.policies:train:109 - Episode 547\n",
      "2021-08-25 11:17:36.103 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:36.104 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:17:36.104 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.7\n",
      "2021-08-25 11:17:36.105 | INFO     | src.policies:train:109 - Episode 548\n",
      "2021-08-25 11:17:36.118 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:36.120 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 11:17:36.120 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.87\n",
      "2021-08-25 11:17:36.121 | INFO     | src.policies:train:109 - Episode 549\n",
      "2021-08-25 11:17:36.131 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:36.132 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:17:36.133 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.68\n",
      "2021-08-25 11:17:36.134 | INFO     | src.policies:train:109 - Episode 550\n",
      "2021-08-25 11:17:36.147 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:36.148 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:17:36.149 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.83\n",
      "2021-08-25 11:17:36.150 | INFO     | src.policies:train:109 - Episode 551\n",
      "2021-08-25 11:17:36.161 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:36.162 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:17:36.163 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.57\n",
      "2021-08-25 11:17:36.163 | INFO     | src.policies:train:109 - Episode 552\n",
      "2021-08-25 11:17:36.188 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:36.190 | INFO     | src.policies:train:121 - Mean episode return: 70.0\n",
      "2021-08-25 11:17:36.190 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.05\n",
      "2021-08-25 11:17:36.191 | WARNING  | src.policies:train:131 - The actual batch size is 223, instead of 200\n",
      "2021-08-25 11:17:36.198 | INFO     | src.policies:train:157 - Total loss: 0.9955153465270996\n",
      "2021-08-25 11:17:36.201 | INFO     | src.policies:train:103 - Epoch 67 / 800\n",
      "2021-08-25 11:17:36.202 | INFO     | src.policies:train:109 - Episode 553\n",
      "2021-08-25 11:17:36.219 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:36.220 | INFO     | src.policies:train:121 - Mean episode return: 46.0\n",
      "2021-08-25 11:17:36.221 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.39\n",
      "2021-08-25 11:17:36.222 | INFO     | src.policies:train:109 - Episode 554\n",
      "2021-08-25 11:17:36.231 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:36.233 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:17:36.233 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.46\n",
      "2021-08-25 11:17:36.234 | INFO     | src.policies:train:109 - Episode 555\n",
      "2021-08-25 11:17:36.246 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:36.247 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 11:17:36.247 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.57\n",
      "2021-08-25 11:17:36.248 | INFO     | src.policies:train:109 - Episode 556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:36.257 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:36.258 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:17:36.259 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.45\n",
      "2021-08-25 11:17:36.260 | INFO     | src.policies:train:109 - Episode 557\n",
      "2021-08-25 11:17:36.271 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:36.272 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:17:36.273 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.42\n",
      "2021-08-25 11:17:36.274 | INFO     | src.policies:train:109 - Episode 558\n",
      "2021-08-25 11:17:36.292 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:36.293 | INFO     | src.policies:train:121 - Mean episode return: 44.0\n",
      "2021-08-25 11:17:36.293 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.69\n",
      "2021-08-25 11:17:36.294 | INFO     | src.policies:train:109 - Episode 559\n",
      "2021-08-25 11:17:36.302 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:36.303 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:17:36.304 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.65\n",
      "2021-08-25 11:17:36.305 | INFO     | src.policies:train:109 - Episode 560\n",
      "2021-08-25 11:17:36.313 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:36.314 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:17:36.315 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.57\n",
      "2021-08-25 11:17:36.316 | INFO     | src.policies:train:109 - Episode 561\n",
      "2021-08-25 11:17:36.324 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:36.325 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:17:36.326 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.42\n",
      "2021-08-25 11:17:36.326 | WARNING  | src.policies:train:131 - The actual batch size is 211, instead of 200\n",
      "2021-08-25 11:17:36.333 | INFO     | src.policies:train:157 - Total loss: 0.9952605366706848\n",
      "2021-08-25 11:17:36.336 | INFO     | src.policies:train:103 - Epoch 68 / 800\n",
      "2021-08-25 11:17:36.337 | INFO     | src.policies:train:109 - Episode 562\n",
      "2021-08-25 11:17:36.346 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:36.347 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:17:36.348 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.49\n",
      "2021-08-25 11:17:36.349 | INFO     | src.policies:train:109 - Episode 563\n",
      "2021-08-25 11:17:36.380 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:36.381 | INFO     | src.policies:train:121 - Mean episode return: 81.0\n",
      "2021-08-25 11:17:36.382 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.03\n",
      "2021-08-25 11:17:36.382 | INFO     | src.policies:train:109 - Episode 564\n",
      "2021-08-25 11:17:36.410 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:36.412 | INFO     | src.policies:train:121 - Mean episode return: 80.0\n",
      "2021-08-25 11:17:36.413 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.62\n",
      "2021-08-25 11:17:36.414 | INFO     | src.policies:train:109 - Episode 565\n",
      "2021-08-25 11:17:36.426 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:36.427 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:17:36.428 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.74\n",
      "2021-08-25 11:17:36.429 | WARNING  | src.policies:train:131 - The actual batch size is 211, instead of 200\n",
      "2021-08-25 11:17:36.435 | INFO     | src.policies:train:157 - Total loss: 0.9952605962753296\n",
      "2021-08-25 11:17:36.437 | INFO     | src.policies:train:103 - Epoch 69 / 800\n",
      "2021-08-25 11:17:36.438 | INFO     | src.policies:train:109 - Episode 566\n",
      "2021-08-25 11:17:36.447 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:36.449 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:17:36.449 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.83\n",
      "2021-08-25 11:17:36.450 | INFO     | src.policies:train:109 - Episode 567\n",
      "2021-08-25 11:17:36.463 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:36.464 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:17:36.465 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.52\n",
      "2021-08-25 11:17:36.466 | INFO     | src.policies:train:109 - Episode 568\n",
      "2021-08-25 11:17:36.475 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:36.476 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:17:36.477 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.16\n",
      "2021-08-25 11:17:36.478 | INFO     | src.policies:train:109 - Episode 569\n",
      "2021-08-25 11:17:36.489 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:36.491 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 11:17:36.491 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.09\n",
      "2021-08-25 11:17:36.493 | INFO     | src.policies:train:109 - Episode 570\n",
      "2021-08-25 11:17:36.507 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:36.509 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 11:17:36.509 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.26\n",
      "2021-08-25 11:17:36.510 | INFO     | src.policies:train:109 - Episode 571\n",
      "2021-08-25 11:17:36.521 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:36.522 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:17:36.523 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.15\n",
      "2021-08-25 11:17:36.524 | INFO     | src.policies:train:109 - Episode 572\n",
      "2021-08-25 11:17:36.536 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:36.537 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:17:36.538 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.27\n",
      "2021-08-25 11:17:36.539 | INFO     | src.policies:train:109 - Episode 573\n",
      "2021-08-25 11:17:36.554 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:36.555 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 11:17:36.556 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.34\n",
      "2021-08-25 11:17:36.557 | WARNING  | src.policies:train:131 - The actual batch size is 209, instead of 200\n",
      "2021-08-25 11:17:36.564 | INFO     | src.policies:train:157 - Total loss: 0.9952149391174316\n",
      "2021-08-25 11:17:36.567 | INFO     | src.policies:train:103 - Epoch 70 / 800\n",
      "2021-08-25 11:17:36.568 | INFO     | src.policies:train:109 - Episode 574\n",
      "2021-08-25 11:17:36.580 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:36.581 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 11:17:36.582 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.52\n",
      "2021-08-25 11:17:36.583 | INFO     | src.policies:train:109 - Episode 575\n",
      "2021-08-25 11:17:36.606 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:36.608 | INFO     | src.policies:train:121 - Mean episode return: 68.0\n",
      "2021-08-25 11:17:36.609 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.9\n",
      "2021-08-25 11:17:36.610 | INFO     | src.policies:train:109 - Episode 576\n",
      "2021-08-25 11:17:36.616 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:36.617 | INFO     | src.policies:train:121 - Mean episode return: 9.0\n",
      "2021-08-25 11:17:36.618 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.82\n",
      "2021-08-25 11:17:36.619 | INFO     | src.policies:train:109 - Episode 577\n",
      "2021-08-25 11:17:36.630 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:36.631 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:17:36.632 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.75\n",
      "2021-08-25 11:17:36.633 | INFO     | src.policies:train:109 - Episode 578\n",
      "2021-08-25 11:17:36.642 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:36.643 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:17:36.644 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.69\n",
      "2021-08-25 11:17:36.644 | INFO     | src.policies:train:109 - Episode 579\n",
      "2021-08-25 11:17:36.656 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:36.657 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 11:17:36.658 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.44\n",
      "2021-08-25 11:17:36.659 | INFO     | src.policies:train:109 - Episode 580\n",
      "2021-08-25 11:17:36.667 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:36.668 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:17:36.669 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.12\n",
      "2021-08-25 11:17:36.670 | INFO     | src.policies:train:109 - Episode 581\n",
      "2021-08-25 11:17:36.680 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:36.681 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:17:36.682 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.89\n",
      "2021-08-25 11:17:36.687 | INFO     | src.policies:train:157 - Total loss: 0.9949997067451477\n",
      "2021-08-25 11:17:36.690 | INFO     | src.policies:train:103 - Epoch 71 / 800\n",
      "2021-08-25 11:17:36.691 | INFO     | src.policies:train:109 - Episode 582\n",
      "2021-08-25 11:17:36.708 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:36.710 | INFO     | src.policies:train:121 - Mean episode return: 50.0\n",
      "2021-08-25 11:17:36.711 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.25\n",
      "2021-08-25 11:17:36.711 | INFO     | src.policies:train:109 - Episode 583\n",
      "2021-08-25 11:17:36.727 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:36.728 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 11:17:36.729 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.35\n",
      "2021-08-25 11:17:36.730 | INFO     | src.policies:train:109 - Episode 584\n",
      "2021-08-25 11:17:36.740 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:36.741 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:17:36.742 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.41\n",
      "2021-08-25 11:17:36.743 | INFO     | src.policies:train:109 - Episode 585\n",
      "2021-08-25 11:17:36.758 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:36.759 | INFO     | src.policies:train:121 - Mean episode return: 39.0\n",
      "2021-08-25 11:17:36.760 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.62\n",
      "2021-08-25 11:17:36.761 | INFO     | src.policies:train:109 - Episode 586\n",
      "2021-08-25 11:17:36.771 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:36.772 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:17:36.773 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.0\n",
      "2021-08-25 11:17:36.774 | INFO     | src.policies:train:109 - Episode 587\n",
      "2021-08-25 11:17:36.792 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:36.793 | INFO     | src.policies:train:121 - Mean episode return: 45.0\n",
      "2021-08-25 11:17:36.794 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.19\n",
      "2021-08-25 11:17:36.795 | WARNING  | src.policies:train:131 - The actual batch size is 210, instead of 200\n",
      "2021-08-25 11:17:36.801 | INFO     | src.policies:train:157 - Total loss: 0.9952379465103149\n",
      "2021-08-25 11:17:36.804 | INFO     | src.policies:train:103 - Epoch 72 / 800\n",
      "2021-08-25 11:17:36.805 | INFO     | src.policies:train:109 - Episode 588\n",
      "2021-08-25 11:17:36.814 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:36.815 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:17:36.816 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.24\n",
      "2021-08-25 11:17:36.816 | INFO     | src.policies:train:109 - Episode 589\n",
      "2021-08-25 11:17:36.829 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:36.830 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:17:36.831 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.37\n",
      "2021-08-25 11:17:36.832 | INFO     | src.policies:train:109 - Episode 590\n",
      "2021-08-25 11:17:36.851 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:36.852 | INFO     | src.policies:train:121 - Mean episode return: 47.0\n",
      "2021-08-25 11:17:36.853 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.21\n",
      "2021-08-25 11:17:36.854 | INFO     | src.policies:train:109 - Episode 591\n",
      "2021-08-25 11:17:36.869 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:36.870 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 11:17:36.871 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.3\n",
      "2021-08-25 11:17:36.872 | INFO     | src.policies:train:109 - Episode 592\n",
      "2021-08-25 11:17:36.889 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:36.891 | INFO     | src.policies:train:121 - Mean episode return: 43.0\n",
      "2021-08-25 11:17:36.892 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.44\n",
      "2021-08-25 11:17:36.893 | INFO     | src.policies:train:109 - Episode 593\n",
      "2021-08-25 11:17:36.900 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:36.901 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:17:36.901 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.38\n",
      "2021-08-25 11:17:36.902 | INFO     | src.policies:train:109 - Episode 594\n",
      "2021-08-25 11:17:36.911 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:36.913 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:17:36.914 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.16\n",
      "2021-08-25 11:17:36.915 | WARNING  | src.policies:train:131 - The actual batch size is 207, instead of 200\n",
      "2021-08-25 11:17:36.921 | INFO     | src.policies:train:157 - Total loss: 0.995168924331665\n",
      "2021-08-25 11:17:36.923 | INFO     | src.policies:train:103 - Epoch 73 / 800\n",
      "2021-08-25 11:17:36.924 | INFO     | src.policies:train:109 - Episode 595\n",
      "2021-08-25 11:17:36.934 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:36.935 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:17:36.936 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.2\n",
      "2021-08-25 11:17:36.937 | INFO     | src.policies:train:109 - Episode 596\n",
      "2021-08-25 11:17:36.956 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:36.957 | INFO     | src.policies:train:121 - Mean episode return: 47.0\n",
      "2021-08-25 11:17:36.958 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:36.959 | INFO     | src.policies:train:109 - Episode 597\n",
      "2021-08-25 11:17:36.968 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:36.969 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:17:36.970 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.53\n",
      "2021-08-25 11:17:36.971 | INFO     | src.policies:train:109 - Episode 598\n",
      "2021-08-25 11:17:36.982 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:36.983 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 11:17:36.984 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.28\n",
      "2021-08-25 11:17:36.985 | INFO     | src.policies:train:109 - Episode 599\n",
      "2021-08-25 11:17:37.000 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:37.001 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 11:17:37.002 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.24\n",
      "2021-08-25 11:17:37.003 | INFO     | src.policies:train:109 - Episode 600\n",
      "2021-08-25 11:17:37.012 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:37.014 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:17:37.014 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.05\n",
      "2021-08-25 11:17:37.015 | INFO     | src.policies:train:109 - Episode 601\n",
      "2021-08-25 11:17:37.025 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:37.025 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:17:37.026 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.01\n",
      "2021-08-25 11:17:37.027 | INFO     | src.policies:train:109 - Episode 602\n",
      "2021-08-25 11:17:37.036 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:37.037 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:17:37.038 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.92\n",
      "2021-08-25 11:17:37.039 | INFO     | src.policies:train:109 - Episode 603\n",
      "2021-08-25 11:17:37.053 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:37.054 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 11:17:37.055 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.95\n",
      "2021-08-25 11:17:37.056 | WARNING  | src.policies:train:131 - The actual batch size is 231, instead of 200\n",
      "2021-08-25 11:17:37.063 | INFO     | src.policies:train:157 - Total loss: 0.9956706762313843\n",
      "2021-08-25 11:17:37.065 | INFO     | src.policies:train:103 - Epoch 74 / 800\n",
      "2021-08-25 11:17:37.066 | INFO     | src.policies:train:109 - Episode 604\n",
      "2021-08-25 11:17:37.074 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:37.075 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:17:37.076 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.92\n",
      "2021-08-25 11:17:37.077 | INFO     | src.policies:train:109 - Episode 605\n",
      "2021-08-25 11:17:37.084 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:37.085 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 11:17:37.085 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.72\n",
      "2021-08-25 11:17:37.086 | INFO     | src.policies:train:109 - Episode 606\n",
      "2021-08-25 11:17:37.094 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:37.095 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:17:37.096 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.72\n",
      "2021-08-25 11:17:37.097 | INFO     | src.policies:train:109 - Episode 607\n",
      "2021-08-25 11:17:37.107 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:37.108 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:17:37.109 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.77\n",
      "2021-08-25 11:17:37.110 | INFO     | src.policies:train:109 - Episode 608\n",
      "2021-08-25 11:17:37.138 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:37.139 | INFO     | src.policies:train:121 - Mean episode return: 72.0\n",
      "2021-08-25 11:17:37.140 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.2\n",
      "2021-08-25 11:17:37.141 | INFO     | src.policies:train:109 - Episode 609\n",
      "2021-08-25 11:17:37.149 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:37.150 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:17:37.151 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.13\n",
      "2021-08-25 11:17:37.152 | INFO     | src.policies:train:109 - Episode 610\n",
      "2021-08-25 11:17:37.165 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:37.166 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:17:37.166 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.19\n",
      "2021-08-25 11:17:37.167 | INFO     | src.policies:train:109 - Episode 611\n",
      "2021-08-25 11:17:37.176 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:37.177 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:17:37.178 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.6\n",
      "2021-08-25 11:17:37.179 | INFO     | src.policies:train:109 - Episode 612\n",
      "2021-08-25 11:17:37.194 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:37.195 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 11:17:37.196 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.66\n",
      "2021-08-25 11:17:37.197 | WARNING  | src.policies:train:131 - The actual batch size is 214, instead of 200\n",
      "2021-08-25 11:17:37.205 | INFO     | src.policies:train:157 - Total loss: 0.9953269362449646\n",
      "2021-08-25 11:17:37.208 | INFO     | src.policies:train:103 - Epoch 75 / 800\n",
      "2021-08-25 11:17:37.210 | INFO     | src.policies:train:109 - Episode 613\n",
      "2021-08-25 11:17:37.228 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:37.229 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 11:17:37.230 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.88\n",
      "2021-08-25 11:17:37.231 | INFO     | src.policies:train:109 - Episode 614\n",
      "2021-08-25 11:17:37.241 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:37.242 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:17:37.243 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.7\n",
      "2021-08-25 11:17:37.244 | INFO     | src.policies:train:109 - Episode 615\n",
      "2021-08-25 11:17:37.259 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:37.260 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 11:17:37.261 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.82\n",
      "2021-08-25 11:17:37.262 | INFO     | src.policies:train:109 - Episode 616\n",
      "2021-08-25 11:17:37.271 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:37.273 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:17:37.274 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.8\n",
      "2021-08-25 11:17:37.275 | INFO     | src.policies:train:109 - Episode 617\n",
      "2021-08-25 11:17:37.292 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:37.293 | INFO     | src.policies:train:121 - Mean episode return: 39.0\n",
      "2021-08-25 11:17:37.294 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:37.295 | INFO     | src.policies:train:109 - Episode 618\n",
      "2021-08-25 11:17:37.309 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:37.310 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 11:17:37.311 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.21\n",
      "2021-08-25 11:17:37.312 | INFO     | src.policies:train:109 - Episode 619\n",
      "2021-08-25 11:17:37.326 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:37.327 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 11:17:37.328 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.36\n",
      "2021-08-25 11:17:37.329 | WARNING  | src.policies:train:131 - The actual batch size is 207, instead of 200\n",
      "2021-08-25 11:17:37.336 | INFO     | src.policies:train:157 - Total loss: 0.9951690435409546\n",
      "2021-08-25 11:17:37.339 | INFO     | src.policies:train:103 - Epoch 76 / 800\n",
      "2021-08-25 11:17:37.340 | INFO     | src.policies:train:109 - Episode 620\n",
      "2021-08-25 11:17:37.364 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:37.365 | INFO     | src.policies:train:121 - Mean episode return: 70.0\n",
      "2021-08-25 11:17:37.366 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.77\n",
      "2021-08-25 11:17:37.367 | INFO     | src.policies:train:109 - Episode 621\n",
      "2021-08-25 11:17:37.379 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:37.380 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:17:37.381 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.58\n",
      "2021-08-25 11:17:37.381 | INFO     | src.policies:train:109 - Episode 622\n",
      "2021-08-25 11:17:37.391 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:37.392 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:17:37.393 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.48\n",
      "2021-08-25 11:17:37.394 | INFO     | src.policies:train:109 - Episode 623\n",
      "2021-08-25 11:17:37.407 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:37.408 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 11:17:37.409 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.57\n",
      "2021-08-25 11:17:37.410 | INFO     | src.policies:train:109 - Episode 624\n",
      "2021-08-25 11:17:37.420 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:37.421 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:17:37.422 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.59\n",
      "2021-08-25 11:17:37.423 | INFO     | src.policies:train:109 - Episode 625\n",
      "2021-08-25 11:17:37.437 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:37.438 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 11:17:37.439 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.67\n",
      "2021-08-25 11:17:37.440 | INFO     | src.policies:train:109 - Episode 626\n",
      "2021-08-25 11:17:37.448 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:37.449 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:17:37.450 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.45\n",
      "2021-08-25 11:17:37.451 | WARNING  | src.policies:train:131 - The actual batch size is 206, instead of 200\n",
      "2021-08-25 11:17:37.458 | INFO     | src.policies:train:157 - Total loss: 0.9951455593109131\n",
      "2021-08-25 11:17:37.462 | INFO     | src.policies:train:103 - Epoch 77 / 800\n",
      "2021-08-25 11:17:37.463 | INFO     | src.policies:train:109 - Episode 627\n",
      "2021-08-25 11:17:37.476 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:37.478 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 11:17:37.479 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.43\n",
      "2021-08-25 11:17:37.481 | INFO     | src.policies:train:109 - Episode 628\n",
      "2021-08-25 11:17:37.488 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:37.489 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:17:37.490 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.38\n",
      "2021-08-25 11:17:37.491 | INFO     | src.policies:train:109 - Episode 629\n",
      "2021-08-25 11:17:37.502 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:37.503 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:17:37.504 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.28\n",
      "2021-08-25 11:17:37.505 | INFO     | src.policies:train:109 - Episode 630\n",
      "2021-08-25 11:17:37.514 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:37.515 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:17:37.515 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.28\n",
      "2021-08-25 11:17:37.516 | INFO     | src.policies:train:109 - Episode 631\n",
      "2021-08-25 11:17:37.526 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:37.527 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:17:37.528 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.35\n",
      "2021-08-25 11:17:37.529 | INFO     | src.policies:train:109 - Episode 632\n",
      "2021-08-25 11:17:37.538 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:37.539 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:17:37.540 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.08\n",
      "2021-08-25 11:17:37.541 | INFO     | src.policies:train:109 - Episode 633\n",
      "2021-08-25 11:17:37.554 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:37.555 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 11:17:37.556 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.02\n",
      "2021-08-25 11:17:37.557 | INFO     | src.policies:train:109 - Episode 634\n",
      "2021-08-25 11:17:37.572 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:37.573 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 11:17:37.574 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.78\n",
      "2021-08-25 11:17:37.575 | INFO     | src.policies:train:109 - Episode 635\n",
      "2021-08-25 11:17:37.584 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:37.585 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:17:37.586 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.51\n",
      "2021-08-25 11:17:37.587 | INFO     | src.policies:train:109 - Episode 636\n",
      "2021-08-25 11:17:37.599 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:37.600 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:17:37.600 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.4\n",
      "2021-08-25 11:17:37.602 | WARNING  | src.policies:train:131 - The actual batch size is 222, instead of 200\n",
      "2021-08-25 11:17:37.608 | INFO     | src.policies:train:157 - Total loss: 0.9954952597618103\n",
      "2021-08-25 11:17:37.611 | INFO     | src.policies:train:103 - Epoch 78 / 800\n",
      "2021-08-25 11:17:37.612 | INFO     | src.policies:train:109 - Episode 637\n",
      "2021-08-25 11:17:37.620 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:37.621 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:17:37.622 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.4\n",
      "2021-08-25 11:17:37.623 | INFO     | src.policies:train:109 - Episode 638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:37.645 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:37.646 | INFO     | src.policies:train:121 - Mean episode return: 58.0\n",
      "2021-08-25 11:17:37.647 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.85\n",
      "2021-08-25 11:17:37.648 | INFO     | src.policies:train:109 - Episode 639\n",
      "2021-08-25 11:17:37.656 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:37.657 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:17:37.657 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.79\n",
      "2021-08-25 11:17:37.658 | INFO     | src.policies:train:109 - Episode 640\n",
      "2021-08-25 11:17:37.673 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:37.674 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 11:17:37.675 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.92\n",
      "2021-08-25 11:17:37.676 | INFO     | src.policies:train:109 - Episode 641\n",
      "2021-08-25 11:17:37.685 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:37.686 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:17:37.687 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.92\n",
      "2021-08-25 11:17:37.688 | INFO     | src.policies:train:109 - Episode 642\n",
      "2021-08-25 11:17:37.702 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:37.703 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 11:17:37.704 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.1\n",
      "2021-08-25 11:17:37.705 | INFO     | src.policies:train:109 - Episode 643\n",
      "2021-08-25 11:17:37.719 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:37.720 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 11:17:37.721 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.22\n",
      "2021-08-25 11:17:37.722 | INFO     | src.policies:train:109 - Episode 644\n",
      "2021-08-25 11:17:37.730 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:37.731 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:17:37.732 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.61\n",
      "2021-08-25 11:17:37.733 | WARNING  | src.policies:train:131 - The actual batch size is 210, instead of 200\n",
      "2021-08-25 11:17:37.740 | INFO     | src.policies:train:157 - Total loss: 0.9952378273010254\n",
      "2021-08-25 11:17:37.743 | INFO     | src.policies:train:103 - Epoch 79 / 800\n",
      "2021-08-25 11:17:37.744 | INFO     | src.policies:train:109 - Episode 645\n",
      "2021-08-25 11:17:37.753 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:37.754 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:17:37.754 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.61\n",
      "2021-08-25 11:17:37.755 | INFO     | src.policies:train:109 - Episode 646\n",
      "2021-08-25 11:17:37.768 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:37.769 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:17:37.770 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.68\n",
      "2021-08-25 11:17:37.771 | INFO     | src.policies:train:109 - Episode 647\n",
      "2021-08-25 11:17:37.778 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:37.779 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:17:37.780 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.67\n",
      "2021-08-25 11:17:37.781 | INFO     | src.policies:train:109 - Episode 648\n",
      "2021-08-25 11:17:37.789 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:37.790 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:17:37.791 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.49\n",
      "2021-08-25 11:17:37.792 | INFO     | src.policies:train:109 - Episode 649\n",
      "2021-08-25 11:17:37.804 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:37.805 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:17:37.806 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.51\n",
      "2021-08-25 11:17:37.807 | INFO     | src.policies:train:109 - Episode 650\n",
      "2021-08-25 11:17:37.823 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:37.824 | INFO     | src.policies:train:121 - Mean episode return: 39.0\n",
      "2021-08-25 11:17:37.825 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.61\n",
      "2021-08-25 11:17:37.825 | INFO     | src.policies:train:109 - Episode 651\n",
      "2021-08-25 11:17:37.833 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:37.834 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:17:37.834 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.55\n",
      "2021-08-25 11:17:37.835 | INFO     | src.policies:train:109 - Episode 652\n",
      "2021-08-25 11:17:37.847 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:37.848 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 11:17:37.849 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.1\n",
      "2021-08-25 11:17:37.850 | INFO     | src.policies:train:109 - Episode 653\n",
      "2021-08-25 11:17:37.869 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:37.870 | INFO     | src.policies:train:121 - Mean episode return: 44.0\n",
      "2021-08-25 11:17:37.871 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.08\n",
      "2021-08-25 11:17:37.872 | WARNING  | src.policies:train:131 - The actual batch size is 216, instead of 200\n",
      "2021-08-25 11:17:37.880 | INFO     | src.policies:train:157 - Total loss: 0.9953701496124268\n",
      "2021-08-25 11:17:37.882 | INFO     | src.policies:train:103 - Epoch 80 / 800\n",
      "2021-08-25 11:17:37.883 | INFO     | src.policies:train:109 - Episode 654\n",
      "2021-08-25 11:17:37.889 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:37.891 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:17:37.891 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.0\n",
      "2021-08-25 11:17:37.892 | INFO     | src.policies:train:109 - Episode 655\n",
      "2021-08-25 11:17:37.910 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:37.911 | INFO     | src.policies:train:121 - Mean episode return: 43.0\n",
      "2021-08-25 11:17:37.912 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.18\n",
      "2021-08-25 11:17:37.913 | INFO     | src.policies:train:109 - Episode 656\n",
      "2021-08-25 11:17:37.926 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:37.927 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:17:37.927 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.3\n",
      "2021-08-25 11:17:37.928 | INFO     | src.policies:train:109 - Episode 657\n",
      "2021-08-25 11:17:37.937 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:37.938 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:17:37.939 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.22\n",
      "2021-08-25 11:17:37.940 | INFO     | src.policies:train:109 - Episode 658\n",
      "2021-08-25 11:17:37.963 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:37.964 | INFO     | src.policies:train:121 - Mean episode return: 60.0\n",
      "2021-08-25 11:17:37.965 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.38\n",
      "2021-08-25 11:17:37.966 | INFO     | src.policies:train:109 - Episode 659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:37.977 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:37.978 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:17:37.979 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.5\n",
      "2021-08-25 11:17:37.980 | INFO     | src.policies:train:109 - Episode 660\n",
      "2021-08-25 11:17:37.988 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:37.989 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:17:37.990 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.52\n",
      "2021-08-25 11:17:37.991 | INFO     | src.policies:train:109 - Episode 661\n",
      "2021-08-25 11:17:38.000 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.001 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:17:38.002 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.53\n",
      "2021-08-25 11:17:38.003 | WARNING  | src.policies:train:131 - The actual batch size is 210, instead of 200\n",
      "2021-08-25 11:17:38.009 | INFO     | src.policies:train:157 - Total loss: 0.9952377080917358\n",
      "2021-08-25 11:17:38.012 | INFO     | src.policies:train:103 - Epoch 81 / 800\n",
      "2021-08-25 11:17:38.013 | INFO     | src.policies:train:109 - Episode 662\n",
      "2021-08-25 11:17:38.019 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.020 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 11:17:38.021 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.42\n",
      "2021-08-25 11:17:38.022 | INFO     | src.policies:train:109 - Episode 663\n",
      "2021-08-25 11:17:38.030 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.031 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:17:38.032 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.77\n",
      "2021-08-25 11:17:38.033 | INFO     | src.policies:train:109 - Episode 664\n",
      "2021-08-25 11:17:38.044 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.045 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:17:38.046 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.19\n",
      "2021-08-25 11:17:38.047 | INFO     | src.policies:train:109 - Episode 665\n",
      "2021-08-25 11:17:38.054 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.055 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 11:17:38.056 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.0\n",
      "2021-08-25 11:17:38.057 | INFO     | src.policies:train:109 - Episode 666\n",
      "2021-08-25 11:17:38.068 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.069 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:17:38.069 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.0\n",
      "2021-08-25 11:17:38.070 | INFO     | src.policies:train:109 - Episode 667\n",
      "2021-08-25 11:17:38.086 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.088 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 11:17:38.088 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.08\n",
      "2021-08-25 11:17:38.089 | INFO     | src.policies:train:109 - Episode 668\n",
      "2021-08-25 11:17:38.101 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.102 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 11:17:38.103 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.21\n",
      "2021-08-25 11:17:38.104 | INFO     | src.policies:train:109 - Episode 669\n",
      "2021-08-25 11:17:38.111 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.112 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:17:38.112 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.08\n",
      "2021-08-25 11:17:38.113 | INFO     | src.policies:train:109 - Episode 670\n",
      "2021-08-25 11:17:38.123 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.124 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:17:38.125 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.92\n",
      "2021-08-25 11:17:38.125 | INFO     | src.policies:train:109 - Episode 671\n",
      "2021-08-25 11:17:38.135 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.136 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:17:38.137 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.94\n",
      "2021-08-25 11:17:38.143 | INFO     | src.policies:train:157 - Total loss: 0.9949994683265686\n",
      "2021-08-25 11:17:38.145 | INFO     | src.policies:train:103 - Epoch 82 / 800\n",
      "2021-08-25 11:17:38.146 | INFO     | src.policies:train:109 - Episode 672\n",
      "2021-08-25 11:17:38.171 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.172 | INFO     | src.policies:train:121 - Mean episode return: 73.0\n",
      "2021-08-25 11:17:38.173 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.41\n",
      "2021-08-25 11:17:38.174 | INFO     | src.policies:train:109 - Episode 673\n",
      "2021-08-25 11:17:38.188 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.190 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 11:17:38.191 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.43\n",
      "2021-08-25 11:17:38.192 | INFO     | src.policies:train:109 - Episode 674\n",
      "2021-08-25 11:17:38.204 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.205 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 11:17:38.206 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.45\n",
      "2021-08-25 11:17:38.207 | INFO     | src.policies:train:109 - Episode 675\n",
      "2021-08-25 11:17:38.216 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.217 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:17:38.218 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.95\n",
      "2021-08-25 11:17:38.219 | INFO     | src.policies:train:109 - Episode 676\n",
      "2021-08-25 11:17:38.228 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.230 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:17:38.230 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.07\n",
      "2021-08-25 11:17:38.231 | INFO     | src.policies:train:109 - Episode 677\n",
      "2021-08-25 11:17:38.243 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.245 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 11:17:38.245 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.15\n",
      "2021-08-25 11:17:38.246 | WARNING  | src.policies:train:131 - The actual batch size is 211, instead of 200\n",
      "2021-08-25 11:17:38.252 | INFO     | src.policies:train:157 - Total loss: 0.9952605366706848\n",
      "2021-08-25 11:17:38.256 | INFO     | src.policies:train:103 - Epoch 83 / 800\n",
      "2021-08-25 11:17:38.257 | INFO     | src.policies:train:109 - Episode 678\n",
      "2021-08-25 11:17:38.263 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.264 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:17:38.265 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.12\n",
      "2021-08-25 11:17:38.266 | INFO     | src.policies:train:109 - Episode 679\n",
      "2021-08-25 11:17:38.282 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.283 | INFO     | src.policies:train:121 - Mean episode return: 43.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:38.284 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.27\n",
      "2021-08-25 11:17:38.284 | INFO     | src.policies:train:109 - Episode 680\n",
      "2021-08-25 11:17:38.293 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.294 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:17:38.295 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.29\n",
      "2021-08-25 11:17:38.296 | INFO     | src.policies:train:109 - Episode 681\n",
      "2021-08-25 11:17:38.304 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.305 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:17:38.306 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.31\n",
      "2021-08-25 11:17:38.307 | INFO     | src.policies:train:109 - Episode 682\n",
      "2021-08-25 11:17:38.315 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.316 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:17:38.317 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.97\n",
      "2021-08-25 11:17:38.317 | INFO     | src.policies:train:109 - Episode 683\n",
      "2021-08-25 11:17:38.325 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.326 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:17:38.326 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.75\n",
      "2021-08-25 11:17:38.327 | INFO     | src.policies:train:109 - Episode 684\n",
      "2021-08-25 11:17:38.336 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.337 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:17:38.338 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.78\n",
      "2021-08-25 11:17:38.339 | INFO     | src.policies:train:109 - Episode 685\n",
      "2021-08-25 11:17:38.345 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.346 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 11:17:38.346 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.49\n",
      "2021-08-25 11:17:38.347 | INFO     | src.policies:train:109 - Episode 686\n",
      "2021-08-25 11:17:38.358 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.359 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:17:38.360 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.53\n",
      "2021-08-25 11:17:38.361 | INFO     | src.policies:train:109 - Episode 687\n",
      "2021-08-25 11:17:38.368 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.369 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:17:38.369 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.22\n",
      "2021-08-25 11:17:38.370 | INFO     | src.policies:train:109 - Episode 688\n",
      "2021-08-25 11:17:38.377 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.378 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:17:38.379 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.12\n",
      "2021-08-25 11:17:38.384 | INFO     | src.policies:train:157 - Total loss: 0.9949996471405029\n",
      "2021-08-25 11:17:38.386 | INFO     | src.policies:train:103 - Epoch 84 / 800\n",
      "2021-08-25 11:17:38.387 | INFO     | src.policies:train:109 - Episode 689\n",
      "2021-08-25 11:17:38.405 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.406 | INFO     | src.policies:train:121 - Mean episode return: 52.0\n",
      "2021-08-25 11:17:38.407 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.35\n",
      "2021-08-25 11:17:38.407 | INFO     | src.policies:train:109 - Episode 690\n",
      "2021-08-25 11:17:38.415 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.416 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:17:38.417 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.03\n",
      "2021-08-25 11:17:38.418 | INFO     | src.policies:train:109 - Episode 691\n",
      "2021-08-25 11:17:38.425 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.426 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:17:38.426 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.78\n",
      "2021-08-25 11:17:38.427 | INFO     | src.policies:train:109 - Episode 692\n",
      "2021-08-25 11:17:38.466 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.467 | INFO     | src.policies:train:121 - Mean episode return: 116.0\n",
      "2021-08-25 11:17:38.468 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.51\n",
      "2021-08-25 11:17:38.469 | INFO     | src.policies:train:109 - Episode 693\n",
      "2021-08-25 11:17:38.481 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.482 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:17:38.483 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.69\n",
      "2021-08-25 11:17:38.484 | WARNING  | src.policies:train:131 - The actual batch size is 224, instead of 200\n",
      "2021-08-25 11:17:38.489 | INFO     | src.policies:train:157 - Total loss: 0.9955354928970337\n",
      "2021-08-25 11:17:38.491 | INFO     | src.policies:train:103 - Epoch 85 / 800\n",
      "2021-08-25 11:17:38.493 | INFO     | src.policies:train:109 - Episode 694\n",
      "2021-08-25 11:17:38.508 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.509 | INFO     | src.policies:train:121 - Mean episode return: 41.0\n",
      "2021-08-25 11:17:38.510 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.92\n",
      "2021-08-25 11:17:38.511 | INFO     | src.policies:train:109 - Episode 695\n",
      "2021-08-25 11:17:38.521 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.523 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:17:38.523 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.91\n",
      "2021-08-25 11:17:38.524 | INFO     | src.policies:train:109 - Episode 696\n",
      "2021-08-25 11:17:38.531 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.532 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:17:38.533 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.56\n",
      "2021-08-25 11:17:38.534 | INFO     | src.policies:train:109 - Episode 697\n",
      "2021-08-25 11:17:38.556 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.557 | INFO     | src.policies:train:121 - Mean episode return: 59.0\n",
      "2021-08-25 11:17:38.558 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.98\n",
      "2021-08-25 11:17:38.559 | INFO     | src.policies:train:109 - Episode 698\n",
      "2021-08-25 11:17:38.567 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.568 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:17:38.569 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.92\n",
      "2021-08-25 11:17:38.570 | INFO     | src.policies:train:109 - Episode 699\n",
      "2021-08-25 11:17:38.577 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.578 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:17:38.579 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.7\n",
      "2021-08-25 11:17:38.580 | INFO     | src.policies:train:109 - Episode 700\n",
      "2021-08-25 11:17:38.591 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.592 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 11:17:38.593 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:38.594 | INFO     | src.policies:train:109 - Episode 701\n",
      "2021-08-25 11:17:38.601 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.602 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:17:38.603 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.74\n",
      "2021-08-25 11:17:38.604 | WARNING  | src.policies:train:131 - The actual batch size is 203, instead of 200\n",
      "2021-08-25 11:17:38.609 | INFO     | src.policies:train:157 - Total loss: 0.9950737953186035\n",
      "2021-08-25 11:17:38.611 | INFO     | src.policies:train:103 - Epoch 86 / 800\n",
      "2021-08-25 11:17:38.612 | INFO     | src.policies:train:109 - Episode 702\n",
      "2021-08-25 11:17:38.619 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.620 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:17:38.621 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.73\n",
      "2021-08-25 11:17:38.622 | INFO     | src.policies:train:109 - Episode 703\n",
      "2021-08-25 11:17:38.633 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.634 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 11:17:38.635 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.68\n",
      "2021-08-25 11:17:38.636 | INFO     | src.policies:train:109 - Episode 704\n",
      "2021-08-25 11:17:38.644 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.645 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:17:38.646 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.7\n",
      "2021-08-25 11:17:38.646 | INFO     | src.policies:train:109 - Episode 705\n",
      "2021-08-25 11:17:38.654 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.655 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:17:38.656 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.76\n",
      "2021-08-25 11:17:38.657 | INFO     | src.policies:train:109 - Episode 706\n",
      "2021-08-25 11:17:38.664 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.665 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:17:38.665 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.79\n",
      "2021-08-25 11:17:38.666 | INFO     | src.policies:train:109 - Episode 707\n",
      "2021-08-25 11:17:38.673 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.674 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:17:38.675 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.71\n",
      "2021-08-25 11:17:38.676 | INFO     | src.policies:train:109 - Episode 708\n",
      "2021-08-25 11:17:38.684 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.686 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:17:38.686 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.14\n",
      "2021-08-25 11:17:38.687 | INFO     | src.policies:train:109 - Episode 709\n",
      "2021-08-25 11:17:38.696 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.698 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:17:38.698 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.22\n",
      "2021-08-25 11:17:38.699 | INFO     | src.policies:train:109 - Episode 710\n",
      "2021-08-25 11:17:38.708 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.708 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:17:38.709 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.2\n",
      "2021-08-25 11:17:38.710 | INFO     | src.policies:train:109 - Episode 711\n",
      "2021-08-25 11:17:38.719 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.720 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:17:38.721 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.26\n",
      "2021-08-25 11:17:38.722 | INFO     | src.policies:train:109 - Episode 712\n",
      "2021-08-25 11:17:38.739 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.740 | INFO     | src.policies:train:121 - Mean episode return: 46.0\n",
      "2021-08-25 11:17:38.740 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.36\n",
      "2021-08-25 11:17:38.741 | WARNING  | src.policies:train:131 - The actual batch size is 227, instead of 200\n",
      "2021-08-25 11:17:38.747 | INFO     | src.policies:train:157 - Total loss: 0.9955943822860718\n",
      "2021-08-25 11:17:38.750 | INFO     | src.policies:train:103 - Epoch 87 / 800\n",
      "2021-08-25 11:17:38.751 | INFO     | src.policies:train:109 - Episode 713\n",
      "2021-08-25 11:17:38.756 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.758 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:17:38.758 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.08\n",
      "2021-08-25 11:17:38.759 | INFO     | src.policies:train:109 - Episode 714\n",
      "2021-08-25 11:17:38.766 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.766 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:17:38.767 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.03\n",
      "2021-08-25 11:17:38.768 | INFO     | src.policies:train:109 - Episode 715\n",
      "2021-08-25 11:17:38.781 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.782 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 11:17:38.783 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.06\n",
      "2021-08-25 11:17:38.784 | INFO     | src.policies:train:109 - Episode 716\n",
      "2021-08-25 11:17:38.789 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.790 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 11:17:38.791 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.0\n",
      "2021-08-25 11:17:38.792 | INFO     | src.policies:train:109 - Episode 717\n",
      "2021-08-25 11:17:38.803 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.804 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:17:38.805 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.87\n",
      "2021-08-25 11:17:38.806 | INFO     | src.policies:train:109 - Episode 718\n",
      "2021-08-25 11:17:38.824 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.825 | INFO     | src.policies:train:121 - Mean episode return: 43.0\n",
      "2021-08-25 11:17:38.826 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.98\n",
      "2021-08-25 11:17:38.826 | INFO     | src.policies:train:109 - Episode 719\n",
      "2021-08-25 11:17:38.839 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.841 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 11:17:38.841 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.93\n",
      "2021-08-25 11:17:38.842 | INFO     | src.policies:train:109 - Episode 720\n",
      "2021-08-25 11:17:38.848 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.849 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 11:17:38.850 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.33\n",
      "2021-08-25 11:17:38.851 | INFO     | src.policies:train:109 - Episode 721\n",
      "2021-08-25 11:17:38.867 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.868 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 11:17:38.869 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:38.870 | WARNING  | src.policies:train:131 - The actual batch size is 214, instead of 200\n",
      "2021-08-25 11:17:38.876 | INFO     | src.policies:train:157 - Total loss: 0.9953268766403198\n",
      "2021-08-25 11:17:38.878 | INFO     | src.policies:train:103 - Epoch 88 / 800\n",
      "2021-08-25 11:17:38.879 | INFO     | src.policies:train:109 - Episode 722\n",
      "2021-08-25 11:17:38.887 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.888 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:17:38.889 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.48\n",
      "2021-08-25 11:17:38.890 | INFO     | src.policies:train:109 - Episode 723\n",
      "2021-08-25 11:17:38.910 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.911 | INFO     | src.policies:train:121 - Mean episode return: 52.0\n",
      "2021-08-25 11:17:38.912 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.73\n",
      "2021-08-25 11:17:38.913 | INFO     | src.policies:train:109 - Episode 724\n",
      "2021-08-25 11:17:38.925 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.926 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:17:38.927 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.82\n",
      "2021-08-25 11:17:38.928 | INFO     | src.policies:train:109 - Episode 725\n",
      "2021-08-25 11:17:38.944 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.945 | INFO     | src.policies:train:121 - Mean episode return: 39.0\n",
      "2021-08-25 11:17:38.946 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.89\n",
      "2021-08-25 11:17:38.947 | INFO     | src.policies:train:109 - Episode 726\n",
      "2021-08-25 11:17:38.962 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.963 | INFO     | src.policies:train:121 - Mean episode return: 38.0\n",
      "2021-08-25 11:17:38.964 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.13\n",
      "2021-08-25 11:17:38.965 | INFO     | src.policies:train:109 - Episode 727\n",
      "2021-08-25 11:17:38.974 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.975 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:17:38.976 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.0\n",
      "2021-08-25 11:17:38.977 | INFO     | src.policies:train:109 - Episode 728\n",
      "2021-08-25 11:17:38.988 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:38.989 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:17:38.989 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.1\n",
      "2021-08-25 11:17:38.990 | WARNING  | src.policies:train:131 - The actual batch size is 222, instead of 200\n",
      "2021-08-25 11:17:38.997 | INFO     | src.policies:train:157 - Total loss: 0.9954952597618103\n",
      "2021-08-25 11:17:38.999 | INFO     | src.policies:train:103 - Epoch 89 / 800\n",
      "2021-08-25 11:17:39.000 | INFO     | src.policies:train:109 - Episode 729\n",
      "2021-08-25 11:17:39.012 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:39.013 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 11:17:39.014 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.2\n",
      "2021-08-25 11:17:39.015 | INFO     | src.policies:train:109 - Episode 730\n",
      "2021-08-25 11:17:39.024 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:39.025 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:17:39.026 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.23\n",
      "2021-08-25 11:17:39.026 | INFO     | src.policies:train:109 - Episode 731\n",
      "2021-08-25 11:17:39.037 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:39.038 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:17:39.038 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.28\n",
      "2021-08-25 11:17:39.039 | INFO     | src.policies:train:109 - Episode 732\n",
      "2021-08-25 11:17:39.047 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:39.048 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:17:39.049 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.27\n",
      "2021-08-25 11:17:39.049 | INFO     | src.policies:train:109 - Episode 733\n",
      "2021-08-25 11:17:39.065 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:39.066 | INFO     | src.policies:train:121 - Mean episode return: 42.0\n",
      "2021-08-25 11:17:39.067 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.37\n",
      "2021-08-25 11:17:39.068 | INFO     | src.policies:train:109 - Episode 734\n",
      "2021-08-25 11:17:39.078 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:39.079 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:17:39.080 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.24\n",
      "2021-08-25 11:17:39.081 | INFO     | src.policies:train:109 - Episode 735\n",
      "2021-08-25 11:17:39.090 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:39.091 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:17:39.092 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.31\n",
      "2021-08-25 11:17:39.093 | INFO     | src.policies:train:109 - Episode 736\n",
      "2021-08-25 11:17:39.099 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:39.100 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:17:39.101 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.18\n",
      "2021-08-25 11:17:39.101 | INFO     | src.policies:train:109 - Episode 737\n",
      "2021-08-25 11:17:39.109 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:39.110 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:17:39.111 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.19\n",
      "2021-08-25 11:17:39.112 | INFO     | src.policies:train:109 - Episode 738\n",
      "2021-08-25 11:17:39.132 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:39.133 | INFO     | src.policies:train:121 - Mean episode return: 57.0\n",
      "2021-08-25 11:17:39.134 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.18\n",
      "2021-08-25 11:17:39.135 | WARNING  | src.policies:train:131 - The actual batch size is 255, instead of 200\n",
      "2021-08-25 11:17:39.141 | INFO     | src.policies:train:157 - Total loss: 0.9960781931877136\n",
      "2021-08-25 11:17:39.144 | INFO     | src.policies:train:103 - Epoch 90 / 800\n",
      "2021-08-25 11:17:39.145 | INFO     | src.policies:train:109 - Episode 739\n",
      "2021-08-25 11:17:39.150 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:39.151 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:17:39.152 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.19\n",
      "2021-08-25 11:17:39.153 | INFO     | src.policies:train:109 - Episode 740\n",
      "2021-08-25 11:17:39.165 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:39.166 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 11:17:39.167 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.17\n",
      "2021-08-25 11:17:39.168 | INFO     | src.policies:train:109 - Episode 741\n",
      "2021-08-25 11:17:39.175 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:39.176 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:17:39.177 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.17\n",
      "2021-08-25 11:17:39.178 | INFO     | src.policies:train:109 - Episode 742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:39.187 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:39.188 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:17:39.189 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.06\n",
      "2021-08-25 11:17:39.190 | INFO     | src.policies:train:109 - Episode 743\n",
      "2021-08-25 11:17:39.206 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:39.207 | INFO     | src.policies:train:121 - Mean episode return: 42.0\n",
      "2021-08-25 11:17:39.208 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.17\n",
      "2021-08-25 11:17:39.209 | INFO     | src.policies:train:109 - Episode 744\n",
      "2021-08-25 11:17:39.217 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:39.218 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:17:39.219 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.19\n",
      "2021-08-25 11:17:39.220 | INFO     | src.policies:train:109 - Episode 745\n",
      "2021-08-25 11:17:39.234 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:39.235 | INFO     | src.policies:train:121 - Mean episode return: 38.0\n",
      "2021-08-25 11:17:39.236 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.37\n",
      "2021-08-25 11:17:39.237 | INFO     | src.policies:train:109 - Episode 746\n",
      "2021-08-25 11:17:39.249 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:39.251 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 11:17:39.251 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.39\n",
      "2021-08-25 11:17:39.252 | WARNING  | src.policies:train:131 - The actual batch size is 206, instead of 200\n",
      "2021-08-25 11:17:39.258 | INFO     | src.policies:train:157 - Total loss: 0.9951454401016235\n",
      "2021-08-25 11:17:39.261 | INFO     | src.policies:train:103 - Epoch 91 / 800\n",
      "2021-08-25 11:17:39.262 | INFO     | src.policies:train:109 - Episode 747\n",
      "2021-08-25 11:17:39.274 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:39.275 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 11:17:39.276 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.61\n",
      "2021-08-25 11:17:39.277 | INFO     | src.policies:train:109 - Episode 748\n",
      "2021-08-25 11:17:39.294 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:39.295 | INFO     | src.policies:train:121 - Mean episode return: 45.0\n",
      "2021-08-25 11:17:39.296 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.92\n",
      "2021-08-25 11:17:39.297 | INFO     | src.policies:train:109 - Episode 749\n",
      "2021-08-25 11:17:39.313 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:39.314 | INFO     | src.policies:train:121 - Mean episode return: 38.0\n",
      "2021-08-25 11:17:39.315 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.09\n",
      "2021-08-25 11:17:39.316 | INFO     | src.policies:train:109 - Episode 750\n",
      "2021-08-25 11:17:39.327 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:39.328 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 11:17:39.329 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.95\n",
      "2021-08-25 11:17:39.330 | INFO     | src.policies:train:109 - Episode 751\n",
      "2021-08-25 11:17:39.340 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:39.341 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:17:39.342 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.05\n",
      "2021-08-25 11:17:39.343 | INFO     | src.policies:train:109 - Episode 752\n",
      "2021-08-25 11:17:39.349 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:39.350 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:17:39.351 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.91\n",
      "2021-08-25 11:17:39.351 | INFO     | src.policies:train:109 - Episode 753\n",
      "2021-08-25 11:17:39.359 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:39.360 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:17:39.361 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.58\n",
      "2021-08-25 11:17:39.361 | INFO     | src.policies:train:109 - Episode 754\n",
      "2021-08-25 11:17:39.373 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:39.374 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 11:17:39.375 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.75\n",
      "2021-08-25 11:17:39.376 | WARNING  | src.policies:train:131 - The actual batch size is 214, instead of 200\n",
      "2021-08-25 11:17:39.382 | INFO     | src.policies:train:157 - Total loss: 0.9953268766403198\n",
      "2021-08-25 11:17:39.384 | INFO     | src.policies:train:103 - Epoch 92 / 800\n",
      "2021-08-25 11:17:39.385 | INFO     | src.policies:train:109 - Episode 755\n",
      "2021-08-25 11:17:39.407 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:39.409 | INFO     | src.policies:train:121 - Mean episode return: 66.0\n",
      "2021-08-25 11:17:39.409 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.98\n",
      "2021-08-25 11:17:39.410 | INFO     | src.policies:train:109 - Episode 756\n",
      "2021-08-25 11:17:39.420 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:39.421 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:17:39.422 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.93\n",
      "2021-08-25 11:17:39.423 | INFO     | src.policies:train:109 - Episode 757\n",
      "2021-08-25 11:17:39.441 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:39.442 | INFO     | src.policies:train:121 - Mean episode return: 50.0\n",
      "2021-08-25 11:17:39.443 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.29\n",
      "2021-08-25 11:17:39.444 | INFO     | src.policies:train:109 - Episode 758\n",
      "2021-08-25 11:17:39.467 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:39.468 | INFO     | src.policies:train:121 - Mean episode return: 65.0\n",
      "2021-08-25 11:17:39.469 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.34\n",
      "2021-08-25 11:17:39.470 | WARNING  | src.policies:train:131 - The actual batch size is 202, instead of 200\n",
      "2021-08-25 11:17:39.475 | INFO     | src.policies:train:157 - Total loss: 0.9950494170188904\n",
      "2021-08-25 11:17:39.478 | INFO     | src.policies:train:103 - Epoch 93 / 800\n",
      "2021-08-25 11:17:39.478 | INFO     | src.policies:train:109 - Episode 759\n",
      "2021-08-25 11:17:39.486 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:39.487 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:17:39.488 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.29\n",
      "2021-08-25 11:17:39.488 | INFO     | src.policies:train:109 - Episode 760\n",
      "2021-08-25 11:17:39.504 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:39.505 | INFO     | src.policies:train:121 - Mean episode return: 42.0\n",
      "2021-08-25 11:17:39.506 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.54\n",
      "2021-08-25 11:17:39.507 | INFO     | src.policies:train:109 - Episode 761\n",
      "2021-08-25 11:17:39.521 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:39.522 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 11:17:39.523 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.74\n",
      "2021-08-25 11:17:39.524 | INFO     | src.policies:train:109 - Episode 762\n",
      "2021-08-25 11:17:39.538 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:39.539 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 11:17:39.540 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.99\n",
      "2021-08-25 11:17:39.541 | INFO     | src.policies:train:109 - Episode 763\n",
      "2021-08-25 11:17:39.547 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:39.548 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:17:39.549 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.95\n",
      "2021-08-25 11:17:39.550 | INFO     | src.policies:train:109 - Episode 764\n",
      "2021-08-25 11:17:39.558 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:39.559 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:17:39.560 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.89\n",
      "2021-08-25 11:17:39.560 | INFO     | src.policies:train:109 - Episode 765\n",
      "2021-08-25 11:17:39.568 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:39.569 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:17:39.570 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.95\n",
      "2021-08-25 11:17:39.571 | INFO     | src.policies:train:109 - Episode 766\n",
      "2021-08-25 11:17:39.584 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:39.585 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 11:17:39.586 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.04\n",
      "2021-08-25 11:17:39.587 | WARNING  | src.policies:train:131 - The actual batch size is 206, instead of 200\n",
      "2021-08-25 11:17:39.594 | INFO     | src.policies:train:157 - Total loss: 0.9951456785202026\n",
      "2021-08-25 11:17:39.597 | INFO     | src.policies:train:103 - Epoch 94 / 800\n",
      "2021-08-25 11:17:39.599 | INFO     | src.policies:train:109 - Episode 767\n",
      "2021-08-25 11:17:39.613 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:39.615 | INFO     | src.policies:train:121 - Mean episode return: 39.0\n",
      "2021-08-25 11:17:39.616 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.06\n",
      "2021-08-25 11:17:39.617 | INFO     | src.policies:train:109 - Episode 768\n",
      "2021-08-25 11:17:39.628 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:39.629 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 11:17:39.630 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.04\n",
      "2021-08-25 11:17:39.631 | INFO     | src.policies:train:109 - Episode 769\n",
      "2021-08-25 11:17:39.647 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:39.648 | INFO     | src.policies:train:121 - Mean episode return: 42.0\n",
      "2021-08-25 11:17:39.649 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.32\n",
      "2021-08-25 11:17:39.650 | INFO     | src.policies:train:109 - Episode 770\n",
      "2021-08-25 11:17:39.658 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:39.659 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:17:39.660 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.29\n",
      "2021-08-25 11:17:39.661 | INFO     | src.policies:train:109 - Episode 771\n",
      "2021-08-25 11:17:39.675 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:39.676 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 11:17:39.677 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.41\n",
      "2021-08-25 11:17:39.678 | INFO     | src.policies:train:109 - Episode 772\n",
      "2021-08-25 11:17:39.689 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:39.690 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 11:17:39.691 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.96\n",
      "2021-08-25 11:17:39.692 | INFO     | src.policies:train:109 - Episode 773\n",
      "2021-08-25 11:17:39.710 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:39.712 | INFO     | src.policies:train:121 - Mean episode return: 47.0\n",
      "2021-08-25 11:17:39.712 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.06\n",
      "2021-08-25 11:17:39.713 | WARNING  | src.policies:train:131 - The actual batch size is 232, instead of 200\n",
      "2021-08-25 11:17:39.719 | INFO     | src.policies:train:157 - Total loss: 0.9956895709037781\n",
      "2021-08-25 11:17:39.722 | INFO     | src.policies:train:103 - Epoch 95 / 800\n",
      "2021-08-25 11:17:39.723 | INFO     | src.policies:train:109 - Episode 774\n",
      "2021-08-25 11:17:39.731 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:39.732 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:17:39.733 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.94\n",
      "2021-08-25 11:17:39.734 | INFO     | src.policies:train:109 - Episode 775\n",
      "2021-08-25 11:17:39.753 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:39.754 | INFO     | src.policies:train:121 - Mean episode return: 51.0\n",
      "2021-08-25 11:17:39.755 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.27\n",
      "2021-08-25 11:17:39.756 | INFO     | src.policies:train:109 - Episode 776\n",
      "2021-08-25 11:17:39.768 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:39.769 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 11:17:39.770 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.34\n",
      "2021-08-25 11:17:39.771 | INFO     | src.policies:train:109 - Episode 777\n",
      "2021-08-25 11:17:39.779 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:39.780 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:17:39.781 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.19\n",
      "2021-08-25 11:17:39.781 | INFO     | src.policies:train:109 - Episode 778\n",
      "2021-08-25 11:17:39.790 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:39.791 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:17:39.791 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.23\n",
      "2021-08-25 11:17:39.792 | INFO     | src.policies:train:109 - Episode 779\n",
      "2021-08-25 11:17:39.808 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:39.809 | INFO     | src.policies:train:121 - Mean episode return: 41.0\n",
      "2021-08-25 11:17:39.809 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.21\n",
      "2021-08-25 11:17:39.810 | INFO     | src.policies:train:109 - Episode 780\n",
      "2021-08-25 11:17:39.823 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:39.824 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 11:17:39.825 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.35\n",
      "2021-08-25 11:17:39.826 | WARNING  | src.policies:train:131 - The actual batch size is 202, instead of 200\n",
      "2021-08-25 11:17:39.832 | INFO     | src.policies:train:157 - Total loss: 0.9950491189956665\n",
      "2021-08-25 11:17:39.834 | INFO     | src.policies:train:103 - Epoch 96 / 800\n",
      "2021-08-25 11:17:39.835 | INFO     | src.policies:train:109 - Episode 781\n",
      "2021-08-25 11:17:39.845 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:39.846 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:17:39.846 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.44\n",
      "2021-08-25 11:17:39.847 | INFO     | src.policies:train:109 - Episode 782\n",
      "2021-08-25 11:17:39.861 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:39.862 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:39.863 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.63\n",
      "2021-08-25 11:17:39.864 | INFO     | src.policies:train:109 - Episode 783\n",
      "2021-08-25 11:17:39.872 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:39.873 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:17:39.874 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.66\n",
      "2021-08-25 11:17:39.875 | INFO     | src.policies:train:109 - Episode 784\n",
      "2021-08-25 11:17:39.885 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:39.886 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:17:39.887 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.68\n",
      "2021-08-25 11:17:39.887 | INFO     | src.policies:train:109 - Episode 785\n",
      "2021-08-25 11:17:39.904 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:39.905 | INFO     | src.policies:train:121 - Mean episode return: 41.0\n",
      "2021-08-25 11:17:39.906 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.99\n",
      "2021-08-25 11:17:39.907 | INFO     | src.policies:train:109 - Episode 786\n",
      "2021-08-25 11:17:39.920 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:39.921 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 11:17:39.921 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.04\n",
      "2021-08-25 11:17:39.922 | INFO     | src.policies:train:109 - Episode 787\n",
      "2021-08-25 11:17:39.930 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:39.931 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:17:39.931 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.05\n",
      "2021-08-25 11:17:39.932 | INFO     | src.policies:train:109 - Episode 788\n",
      "2021-08-25 11:17:39.950 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:39.951 | INFO     | src.policies:train:121 - Mean episode return: 45.0\n",
      "2021-08-25 11:17:39.951 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.38\n",
      "2021-08-25 11:17:39.952 | WARNING  | src.policies:train:131 - The actual batch size is 231, instead of 200\n",
      "2021-08-25 11:17:39.960 | INFO     | src.policies:train:157 - Total loss: 0.9956709146499634\n",
      "2021-08-25 11:17:39.963 | INFO     | src.policies:train:103 - Epoch 97 / 800\n",
      "2021-08-25 11:17:39.964 | INFO     | src.policies:train:109 - Episode 789\n",
      "2021-08-25 11:17:39.972 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:39.973 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:17:39.974 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.05\n",
      "2021-08-25 11:17:39.975 | INFO     | src.policies:train:109 - Episode 790\n",
      "2021-08-25 11:17:39.997 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:39.998 | INFO     | src.policies:train:121 - Mean episode return: 60.0\n",
      "2021-08-25 11:17:39.999 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.5\n",
      "2021-08-25 11:17:40.000 | INFO     | src.policies:train:109 - Episode 791\n",
      "2021-08-25 11:17:40.007 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:40.008 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:17:40.009 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.51\n",
      "2021-08-25 11:17:40.010 | INFO     | src.policies:train:109 - Episode 792\n",
      "2021-08-25 11:17:40.020 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:40.021 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:17:40.022 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.58\n",
      "2021-08-25 11:17:40.023 | INFO     | src.policies:train:109 - Episode 793\n",
      "2021-08-25 11:17:40.035 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:40.036 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 11:17:40.037 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.59\n",
      "2021-08-25 11:17:40.038 | INFO     | src.policies:train:109 - Episode 794\n",
      "2021-08-25 11:17:40.051 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:40.052 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 11:17:40.053 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.53\n",
      "2021-08-25 11:17:40.054 | INFO     | src.policies:train:109 - Episode 795\n",
      "2021-08-25 11:17:40.062 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:40.063 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:17:40.063 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.48\n",
      "2021-08-25 11:17:40.064 | INFO     | src.policies:train:109 - Episode 796\n",
      "2021-08-25 11:17:40.075 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:40.076 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:17:40.077 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.59\n",
      "2021-08-25 11:17:40.078 | WARNING  | src.policies:train:131 - The actual batch size is 217, instead of 200\n",
      "2021-08-25 11:17:40.083 | INFO     | src.policies:train:157 - Total loss: 0.9953916668891907\n",
      "2021-08-25 11:17:40.086 | INFO     | src.policies:train:103 - Epoch 98 / 800\n",
      "2021-08-25 11:17:40.087 | INFO     | src.policies:train:109 - Episode 797\n",
      "2021-08-25 11:17:40.099 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:40.100 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 11:17:40.101 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.35\n",
      "2021-08-25 11:17:40.102 | INFO     | src.policies:train:109 - Episode 798\n",
      "2021-08-25 11:17:40.117 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:40.118 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 11:17:40.119 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.56\n",
      "2021-08-25 11:17:40.120 | INFO     | src.policies:train:109 - Episode 799\n",
      "2021-08-25 11:17:40.130 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:40.131 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:17:40.132 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.65\n",
      "2021-08-25 11:17:40.133 | INFO     | src.policies:train:109 - Episode 800\n",
      "2021-08-25 11:17:40.141 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:40.142 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:17:40.142 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.55\n",
      "2021-08-25 11:17:40.143 | INFO     | src.policies:train:109 - Episode 801\n",
      "2021-08-25 11:17:40.151 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:40.153 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:17:40.154 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.57\n",
      "2021-08-25 11:17:40.154 | INFO     | src.policies:train:109 - Episode 802\n",
      "2021-08-25 11:17:40.164 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:40.165 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:17:40.166 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.64\n",
      "2021-08-25 11:17:40.167 | INFO     | src.policies:train:109 - Episode 803\n",
      "2021-08-25 11:17:40.174 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:40.176 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:40.176 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.47\n",
      "2021-08-25 11:17:40.177 | INFO     | src.policies:train:109 - Episode 804\n",
      "2021-08-25 11:17:40.193 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:40.194 | INFO     | src.policies:train:121 - Mean episode return: 41.0\n",
      "2021-08-25 11:17:40.195 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.71\n",
      "2021-08-25 11:17:40.196 | WARNING  | src.policies:train:131 - The actual batch size is 205, instead of 200\n",
      "2021-08-25 11:17:40.202 | INFO     | src.policies:train:157 - Total loss: 0.9951218366622925\n",
      "2021-08-25 11:17:40.205 | INFO     | src.policies:train:103 - Epoch 99 / 800\n",
      "2021-08-25 11:17:40.205 | INFO     | src.policies:train:109 - Episode 805\n",
      "2021-08-25 11:17:40.212 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:40.213 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:17:40.214 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.69\n",
      "2021-08-25 11:17:40.215 | INFO     | src.policies:train:109 - Episode 806\n",
      "2021-08-25 11:17:40.223 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:40.224 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:17:40.225 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.71\n",
      "2021-08-25 11:17:40.226 | INFO     | src.policies:train:109 - Episode 807\n",
      "2021-08-25 11:17:40.244 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:40.245 | INFO     | src.policies:train:121 - Mean episode return: 50.0\n",
      "2021-08-25 11:17:40.246 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.07\n",
      "2021-08-25 11:17:40.246 | INFO     | src.policies:train:109 - Episode 808\n",
      "2021-08-25 11:17:40.271 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:40.272 | INFO     | src.policies:train:121 - Mean episode return: 68.0\n",
      "2021-08-25 11:17:40.273 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.6\n",
      "2021-08-25 11:17:40.274 | INFO     | src.policies:train:109 - Episode 809\n",
      "2021-08-25 11:17:40.282 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:40.283 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:17:40.283 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.53\n",
      "2021-08-25 11:17:40.284 | INFO     | src.policies:train:109 - Episode 810\n",
      "2021-08-25 11:17:40.302 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:40.303 | INFO     | src.policies:train:121 - Mean episode return: 50.0\n",
      "2021-08-25 11:17:40.304 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.82\n",
      "2021-08-25 11:17:40.305 | WARNING  | src.policies:train:131 - The actual batch size is 212, instead of 200\n",
      "2021-08-25 11:17:40.310 | INFO     | src.policies:train:157 - Total loss: 0.9952828884124756\n",
      "2021-08-25 11:17:40.312 | INFO     | src.policies:train:103 - Epoch 100 / 800\n",
      "2021-08-25 11:17:40.314 | INFO     | src.policies:train:109 - Episode 811\n",
      "2021-08-25 11:17:40.325 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:40.326 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 11:17:40.327 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.94\n",
      "2021-08-25 11:17:40.328 | INFO     | src.policies:train:109 - Episode 812\n",
      "2021-08-25 11:17:40.337 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:40.338 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:17:40.339 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.66\n",
      "2021-08-25 11:17:40.340 | INFO     | src.policies:train:109 - Episode 813\n",
      "2021-08-25 11:17:40.356 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:40.358 | INFO     | src.policies:train:121 - Mean episode return: 43.0\n",
      "2021-08-25 11:17:40.358 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.97\n",
      "2021-08-25 11:17:40.359 | INFO     | src.policies:train:109 - Episode 814\n",
      "2021-08-25 11:17:40.373 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:40.375 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 11:17:40.375 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.22\n",
      "2021-08-25 11:17:40.376 | INFO     | src.policies:train:109 - Episode 815\n",
      "2021-08-25 11:17:40.403 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:40.404 | INFO     | src.policies:train:121 - Mean episode return: 75.0\n",
      "2021-08-25 11:17:40.405 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.67\n",
      "2021-08-25 11:17:40.406 | WARNING  | src.policies:train:131 - The actual batch size is 203, instead of 200\n",
      "2021-08-25 11:17:40.411 | INFO     | src.policies:train:157 - Total loss: 0.9950734376907349\n",
      "2021-08-25 11:17:40.414 | INFO     | src.policies:train:103 - Epoch 101 / 800\n",
      "2021-08-25 11:17:40.415 | INFO     | src.policies:train:109 - Episode 816\n",
      "2021-08-25 11:17:40.420 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:40.421 | INFO     | src.policies:train:121 - Mean episode return: 9.0\n",
      "2021-08-25 11:17:40.422 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.66\n",
      "2021-08-25 11:17:40.423 | INFO     | src.policies:train:109 - Episode 817\n",
      "2021-08-25 11:17:40.429 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:40.430 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:17:40.430 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.52\n",
      "2021-08-25 11:17:40.431 | INFO     | src.policies:train:109 - Episode 818\n",
      "2021-08-25 11:17:40.443 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:40.444 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 11:17:40.445 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.41\n",
      "2021-08-25 11:17:40.446 | INFO     | src.policies:train:109 - Episode 819\n",
      "2021-08-25 11:17:40.454 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:40.455 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:17:40.456 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.24\n",
      "2021-08-25 11:17:40.457 | INFO     | src.policies:train:109 - Episode 820\n",
      "2021-08-25 11:17:40.465 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:40.466 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:17:40.467 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.31\n",
      "2021-08-25 11:17:40.468 | INFO     | src.policies:train:109 - Episode 821\n",
      "2021-08-25 11:17:40.480 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:40.481 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 11:17:40.482 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.18\n",
      "2021-08-25 11:17:40.483 | INFO     | src.policies:train:109 - Episode 822\n",
      "2021-08-25 11:17:40.496 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:40.497 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 11:17:40.498 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.34\n",
      "2021-08-25 11:17:40.499 | INFO     | src.policies:train:109 - Episode 823\n",
      "2021-08-25 11:17:40.505 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:40.506 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 11:17:40.507 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:40.508 | INFO     | src.policies:train:109 - Episode 824\n",
      "2021-08-25 11:17:40.516 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:40.517 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:17:40.518 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.78\n",
      "2021-08-25 11:17:40.519 | INFO     | src.policies:train:109 - Episode 825\n",
      "2021-08-25 11:17:40.532 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:40.533 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 11:17:40.534 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.72\n",
      "2021-08-25 11:17:40.535 | WARNING  | src.policies:train:131 - The actual batch size is 203, instead of 200\n",
      "2021-08-25 11:17:40.541 | INFO     | src.policies:train:157 - Total loss: 0.995073676109314\n",
      "2021-08-25 11:17:40.543 | INFO     | src.policies:train:103 - Epoch 102 / 800\n",
      "2021-08-25 11:17:40.544 | INFO     | src.policies:train:109 - Episode 826\n",
      "2021-08-25 11:17:40.550 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:40.552 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:17:40.552 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.48\n",
      "2021-08-25 11:17:40.553 | INFO     | src.policies:train:109 - Episode 827\n",
      "2021-08-25 11:17:40.561 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:40.562 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:17:40.563 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.42\n",
      "2021-08-25 11:17:40.564 | INFO     | src.policies:train:109 - Episode 828\n",
      "2021-08-25 11:17:40.571 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:40.573 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:17:40.574 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.34\n",
      "2021-08-25 11:17:40.574 | INFO     | src.policies:train:109 - Episode 829\n",
      "2021-08-25 11:17:40.590 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:40.591 | INFO     | src.policies:train:121 - Mean episode return: 44.0\n",
      "2021-08-25 11:17:40.592 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.47\n",
      "2021-08-25 11:17:40.593 | INFO     | src.policies:train:109 - Episode 830\n",
      "2021-08-25 11:17:40.605 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:40.607 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 11:17:40.608 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.57\n",
      "2021-08-25 11:17:40.608 | INFO     | src.policies:train:109 - Episode 831\n",
      "2021-08-25 11:17:40.636 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:40.637 | INFO     | src.policies:train:121 - Mean episode return: 77.0\n",
      "2021-08-25 11:17:40.638 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.1\n",
      "2021-08-25 11:17:40.639 | INFO     | src.policies:train:109 - Episode 832\n",
      "2021-08-25 11:17:40.656 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:40.657 | INFO     | src.policies:train:121 - Mean episode return: 42.0\n",
      "2021-08-25 11:17:40.658 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.39\n",
      "2021-08-25 11:17:40.659 | WARNING  | src.policies:train:131 - The actual batch size is 237, instead of 200\n",
      "2021-08-25 11:17:40.664 | INFO     | src.policies:train:157 - Total loss: 0.9957804679870605\n",
      "2021-08-25 11:17:40.667 | INFO     | src.policies:train:103 - Epoch 103 / 800\n",
      "2021-08-25 11:17:40.668 | INFO     | src.policies:train:109 - Episode 833\n",
      "2021-08-25 11:17:40.675 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:40.676 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:17:40.677 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.15\n",
      "2021-08-25 11:17:40.678 | INFO     | src.policies:train:109 - Episode 834\n",
      "2021-08-25 11:17:40.685 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:40.686 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:17:40.687 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.08\n",
      "2021-08-25 11:17:40.688 | INFO     | src.policies:train:109 - Episode 835\n",
      "2021-08-25 11:17:40.695 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:40.697 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:17:40.698 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.03\n",
      "2021-08-25 11:17:40.699 | INFO     | src.policies:train:109 - Episode 836\n",
      "2021-08-25 11:17:40.717 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:40.718 | INFO     | src.policies:train:121 - Mean episode return: 45.0\n",
      "2021-08-25 11:17:40.719 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.37\n",
      "2021-08-25 11:17:40.720 | INFO     | src.policies:train:109 - Episode 837\n",
      "2021-08-25 11:17:40.737 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:40.738 | INFO     | src.policies:train:121 - Mean episode return: 44.0\n",
      "2021-08-25 11:17:40.738 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.64\n",
      "2021-08-25 11:17:40.739 | INFO     | src.policies:train:109 - Episode 838\n",
      "2021-08-25 11:17:40.750 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:40.751 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:17:40.752 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.3\n",
      "2021-08-25 11:17:40.753 | INFO     | src.policies:train:109 - Episode 839\n",
      "2021-08-25 11:17:40.764 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:40.766 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:17:40.767 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.35\n",
      "2021-08-25 11:17:40.768 | INFO     | src.policies:train:109 - Episode 840\n",
      "2021-08-25 11:17:40.782 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:40.783 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:17:40.784 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.26\n",
      "2021-08-25 11:17:40.785 | INFO     | src.policies:train:109 - Episode 841\n",
      "2021-08-25 11:17:40.797 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:40.798 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:17:40.799 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.34\n",
      "2021-08-25 11:17:40.800 | WARNING  | src.policies:train:131 - The actual batch size is 221, instead of 200\n",
      "2021-08-25 11:17:40.809 | INFO     | src.policies:train:157 - Total loss: 0.9954748153686523\n",
      "2021-08-25 11:17:40.812 | INFO     | src.policies:train:103 - Epoch 104 / 800\n",
      "2021-08-25 11:17:40.814 | INFO     | src.policies:train:109 - Episode 842\n",
      "2021-08-25 11:17:40.821 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:40.822 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:17:40.823 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.25\n",
      "2021-08-25 11:17:40.825 | INFO     | src.policies:train:109 - Episode 843\n",
      "2021-08-25 11:17:40.834 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:40.836 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:17:40.837 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.99\n",
      "2021-08-25 11:17:40.837 | INFO     | src.policies:train:109 - Episode 844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:40.847 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:40.848 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:17:40.849 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.97\n",
      "2021-08-25 11:17:40.850 | INFO     | src.policies:train:109 - Episode 845\n",
      "2021-08-25 11:17:40.867 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:40.868 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 11:17:40.869 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.91\n",
      "2021-08-25 11:17:40.870 | INFO     | src.policies:train:109 - Episode 846\n",
      "2021-08-25 11:17:40.880 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:40.882 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:17:40.883 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.73\n",
      "2021-08-25 11:17:40.884 | INFO     | src.policies:train:109 - Episode 847\n",
      "2021-08-25 11:17:40.894 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:40.895 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:17:40.897 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.53\n",
      "2021-08-25 11:17:40.898 | INFO     | src.policies:train:109 - Episode 848\n",
      "2021-08-25 11:17:40.909 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:40.910 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:17:40.912 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.29\n",
      "2021-08-25 11:17:40.912 | INFO     | src.policies:train:109 - Episode 849\n",
      "2021-08-25 11:17:40.923 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:40.923 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:17:40.924 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.09\n",
      "2021-08-25 11:17:40.925 | INFO     | src.policies:train:109 - Episode 850\n",
      "2021-08-25 11:17:40.933 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:40.934 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:17:40.935 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.01\n",
      "2021-08-25 11:17:40.936 | INFO     | src.policies:train:109 - Episode 851\n",
      "2021-08-25 11:17:40.954 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:40.955 | INFO     | src.policies:train:121 - Mean episode return: 48.0\n",
      "2021-08-25 11:17:40.956 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.27\n",
      "2021-08-25 11:17:40.957 | WARNING  | src.policies:train:131 - The actual batch size is 206, instead of 200\n",
      "2021-08-25 11:17:40.963 | INFO     | src.policies:train:157 - Total loss: 0.9951454401016235\n",
      "2021-08-25 11:17:40.966 | INFO     | src.policies:train:103 - Epoch 105 / 800\n",
      "2021-08-25 11:17:40.967 | INFO     | src.policies:train:109 - Episode 852\n",
      "2021-08-25 11:17:40.978 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:40.979 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 11:17:40.980 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.46\n",
      "2021-08-25 11:17:40.981 | INFO     | src.policies:train:109 - Episode 853\n",
      "2021-08-25 11:17:40.992 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:40.993 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:17:40.994 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.61\n",
      "2021-08-25 11:17:40.995 | INFO     | src.policies:train:109 - Episode 854\n",
      "2021-08-25 11:17:41.009 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:41.010 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 11:17:41.011 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.69\n",
      "2021-08-25 11:17:41.012 | INFO     | src.policies:train:109 - Episode 855\n",
      "2021-08-25 11:17:41.040 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:41.041 | INFO     | src.policies:train:121 - Mean episode return: 78.0\n",
      "2021-08-25 11:17:41.041 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.81\n",
      "2021-08-25 11:17:41.042 | INFO     | src.policies:train:109 - Episode 856\n",
      "2021-08-25 11:17:41.051 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:41.052 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:17:41.053 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.78\n",
      "2021-08-25 11:17:41.054 | INFO     | src.policies:train:109 - Episode 857\n",
      "2021-08-25 11:17:41.065 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:41.066 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 11:17:41.067 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.53\n",
      "2021-08-25 11:17:41.068 | WARNING  | src.policies:train:131 - The actual batch size is 213, instead of 200\n",
      "2021-08-25 11:17:41.074 | INFO     | src.policies:train:157 - Total loss: 0.9953049421310425\n",
      "2021-08-25 11:17:41.076 | INFO     | src.policies:train:103 - Epoch 106 / 800\n",
      "2021-08-25 11:17:41.077 | INFO     | src.policies:train:109 - Episode 858\n",
      "2021-08-25 11:17:41.085 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:41.086 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:17:41.087 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.06\n",
      "2021-08-25 11:17:41.088 | INFO     | src.policies:train:109 - Episode 859\n",
      "2021-08-25 11:17:41.098 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:41.099 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:17:41.100 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.07\n",
      "2021-08-25 11:17:41.101 | INFO     | src.policies:train:109 - Episode 860\n",
      "2021-08-25 11:17:41.111 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:41.112 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 11:17:41.112 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.9\n",
      "2021-08-25 11:17:41.114 | INFO     | src.policies:train:109 - Episode 861\n",
      "2021-08-25 11:17:41.129 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:41.130 | INFO     | src.policies:train:121 - Mean episode return: 39.0\n",
      "2021-08-25 11:17:41.131 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.94\n",
      "2021-08-25 11:17:41.132 | INFO     | src.policies:train:109 - Episode 862\n",
      "2021-08-25 11:17:41.147 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:41.148 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 11:17:41.149 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.99\n",
      "2021-08-25 11:17:41.149 | INFO     | src.policies:train:109 - Episode 863\n",
      "2021-08-25 11:17:41.172 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:41.173 | INFO     | src.policies:train:121 - Mean episode return: 61.0\n",
      "2021-08-25 11:17:41.174 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.48\n",
      "2021-08-25 11:17:41.175 | WARNING  | src.policies:train:131 - The actual batch size is 203, instead of 200\n",
      "2021-08-25 11:17:41.181 | INFO     | src.policies:train:157 - Total loss: 0.9950736165046692\n",
      "2021-08-25 11:17:41.183 | INFO     | src.policies:train:103 - Epoch 107 / 800\n",
      "2021-08-25 11:17:41.184 | INFO     | src.policies:train:109 - Episode 864\n",
      "2021-08-25 11:17:41.196 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:41.197 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 11:17:41.198 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.64\n",
      "2021-08-25 11:17:41.199 | INFO     | src.policies:train:109 - Episode 865\n",
      "2021-08-25 11:17:41.209 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:41.210 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:17:41.210 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.71\n",
      "2021-08-25 11:17:41.211 | INFO     | src.policies:train:109 - Episode 866\n",
      "2021-08-25 11:17:41.219 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:41.220 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:17:41.221 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.53\n",
      "2021-08-25 11:17:41.222 | INFO     | src.policies:train:109 - Episode 867\n",
      "2021-08-25 11:17:41.230 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:41.231 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:17:41.232 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.32\n",
      "2021-08-25 11:17:41.232 | INFO     | src.policies:train:109 - Episode 868\n",
      "2021-08-25 11:17:41.253 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:41.255 | INFO     | src.policies:train:121 - Mean episode return: 56.0\n",
      "2021-08-25 11:17:41.255 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.63\n",
      "2021-08-25 11:17:41.256 | INFO     | src.policies:train:109 - Episode 869\n",
      "2021-08-25 11:17:41.266 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:41.267 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:17:41.267 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.43\n",
      "2021-08-25 11:17:41.268 | INFO     | src.policies:train:109 - Episode 870\n",
      "2021-08-25 11:17:41.277 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:41.278 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:17:41.279 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.43\n",
      "2021-08-25 11:17:41.280 | INFO     | src.policies:train:109 - Episode 871\n",
      "2021-08-25 11:17:41.286 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:41.287 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:17:41.288 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.2\n",
      "2021-08-25 11:17:41.289 | INFO     | src.policies:train:109 - Episode 872\n",
      "2021-08-25 11:17:41.306 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:41.307 | INFO     | src.policies:train:121 - Mean episode return: 47.0\n",
      "2021-08-25 11:17:41.308 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.39\n",
      "2021-08-25 11:17:41.309 | WARNING  | src.policies:train:131 - The actual batch size is 239, instead of 200\n",
      "2021-08-25 11:17:41.315 | INFO     | src.policies:train:157 - Total loss: 0.9958156943321228\n",
      "2021-08-25 11:17:41.317 | INFO     | src.policies:train:103 - Epoch 108 / 800\n",
      "2021-08-25 11:17:41.319 | INFO     | src.policies:train:109 - Episode 873\n",
      "2021-08-25 11:17:41.325 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:41.326 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:17:41.327 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.08\n",
      "2021-08-25 11:17:41.328 | INFO     | src.policies:train:109 - Episode 874\n",
      "2021-08-25 11:17:41.354 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:41.355 | INFO     | src.policies:train:121 - Mean episode return: 73.0\n",
      "2021-08-25 11:17:41.355 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.61\n",
      "2021-08-25 11:17:41.356 | INFO     | src.policies:train:109 - Episode 875\n",
      "2021-08-25 11:17:41.365 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:41.366 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:17:41.367 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.29\n",
      "2021-08-25 11:17:41.368 | INFO     | src.policies:train:109 - Episode 876\n",
      "2021-08-25 11:17:41.377 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:41.378 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:17:41.379 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.17\n",
      "2021-08-25 11:17:41.380 | INFO     | src.policies:train:109 - Episode 877\n",
      "2021-08-25 11:17:41.392 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:41.393 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 11:17:41.393 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.32\n",
      "2021-08-25 11:17:41.394 | INFO     | src.policies:train:109 - Episode 878\n",
      "2021-08-25 11:17:41.403 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:41.404 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:17:41.405 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.33\n",
      "2021-08-25 11:17:41.406 | INFO     | src.policies:train:109 - Episode 879\n",
      "2021-08-25 11:17:41.413 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:41.415 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:17:41.415 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.06\n",
      "2021-08-25 11:17:41.416 | INFO     | src.policies:train:109 - Episode 880\n",
      "2021-08-25 11:17:41.426 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:41.427 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:17:41.428 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.96\n",
      "2021-08-25 11:17:41.429 | WARNING  | src.policies:train:131 - The actual batch size is 206, instead of 200\n",
      "2021-08-25 11:17:41.435 | INFO     | src.policies:train:157 - Total loss: 0.9951454997062683\n",
      "2021-08-25 11:17:41.437 | INFO     | src.policies:train:103 - Epoch 109 / 800\n",
      "2021-08-25 11:17:41.438 | INFO     | src.policies:train:109 - Episode 881\n",
      "2021-08-25 11:17:41.452 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:41.453 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 11:17:41.454 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.09\n",
      "2021-08-25 11:17:41.455 | INFO     | src.policies:train:109 - Episode 882\n",
      "2021-08-25 11:17:41.467 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:41.468 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:17:41.469 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.0\n",
      "2021-08-25 11:17:41.470 | INFO     | src.policies:train:109 - Episode 883\n",
      "2021-08-25 11:17:41.493 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:41.494 | INFO     | src.policies:train:121 - Mean episode return: 62.0\n",
      "2021-08-25 11:17:41.495 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.44\n",
      "2021-08-25 11:17:41.496 | INFO     | src.policies:train:109 - Episode 884\n",
      "2021-08-25 11:17:41.504 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:41.505 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:17:41.506 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.38\n",
      "2021-08-25 11:17:41.507 | INFO     | src.policies:train:109 - Episode 885\n",
      "2021-08-25 11:17:41.521 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:41.522 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 11:17:41.523 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.32\n",
      "2021-08-25 11:17:41.524 | INFO     | src.policies:train:109 - Episode 886\n",
      "2021-08-25 11:17:41.537 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:41.538 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 11:17:41.539 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.34\n",
      "2021-08-25 11:17:41.540 | WARNING  | src.policies:train:131 - The actual batch size is 209, instead of 200\n",
      "2021-08-25 11:17:41.545 | INFO     | src.policies:train:157 - Total loss: 0.9952152967453003\n",
      "2021-08-25 11:17:41.547 | INFO     | src.policies:train:103 - Epoch 110 / 800\n",
      "2021-08-25 11:17:41.548 | INFO     | src.policies:train:109 - Episode 887\n",
      "2021-08-25 11:17:41.554 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:41.555 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:17:41.556 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.3\n",
      "2021-08-25 11:17:41.557 | INFO     | src.policies:train:109 - Episode 888\n",
      "2021-08-25 11:17:41.564 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:41.565 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:17:41.565 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.99\n",
      "2021-08-25 11:17:41.566 | INFO     | src.policies:train:109 - Episode 889\n",
      "2021-08-25 11:17:41.584 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:41.585 | INFO     | src.policies:train:121 - Mean episode return: 50.0\n",
      "2021-08-25 11:17:41.586 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.3\n",
      "2021-08-25 11:17:41.587 | INFO     | src.policies:train:109 - Episode 890\n",
      "2021-08-25 11:17:41.594 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:41.596 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:17:41.597 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.83\n",
      "2021-08-25 11:17:41.597 | INFO     | src.policies:train:109 - Episode 891\n",
      "2021-08-25 11:17:41.608 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:41.609 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 11:17:41.610 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.95\n",
      "2021-08-25 11:17:41.611 | INFO     | src.policies:train:109 - Episode 892\n",
      "2021-08-25 11:17:41.625 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:41.626 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 11:17:41.627 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.07\n",
      "2021-08-25 11:17:41.628 | INFO     | src.policies:train:109 - Episode 893\n",
      "2021-08-25 11:17:41.640 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:41.641 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:17:41.642 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.01\n",
      "2021-08-25 11:17:41.642 | INFO     | src.policies:train:109 - Episode 894\n",
      "2021-08-25 11:17:41.656 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:41.657 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 11:17:41.658 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.98\n",
      "2021-08-25 11:17:41.659 | WARNING  | src.policies:train:131 - The actual batch size is 204, instead of 200\n",
      "2021-08-25 11:17:41.664 | INFO     | src.policies:train:157 - Total loss: 0.9950976967811584\n",
      "2021-08-25 11:17:41.667 | INFO     | src.policies:train:103 - Epoch 111 / 800\n",
      "2021-08-25 11:17:41.668 | INFO     | src.policies:train:109 - Episode 895\n",
      "2021-08-25 11:17:41.674 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:41.675 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:17:41.676 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.96\n",
      "2021-08-25 11:17:41.677 | INFO     | src.policies:train:109 - Episode 896\n",
      "2021-08-25 11:17:41.700 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:41.701 | INFO     | src.policies:train:121 - Mean episode return: 68.0\n",
      "2021-08-25 11:17:41.702 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.41\n",
      "2021-08-25 11:17:41.703 | INFO     | src.policies:train:109 - Episode 897\n",
      "2021-08-25 11:17:41.715 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:41.717 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 11:17:41.717 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.37\n",
      "2021-08-25 11:17:41.718 | INFO     | src.policies:train:109 - Episode 898\n",
      "2021-08-25 11:17:41.727 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:41.728 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:17:41.729 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.14\n",
      "2021-08-25 11:17:41.729 | INFO     | src.policies:train:109 - Episode 899\n",
      "2021-08-25 11:17:41.737 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:41.739 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:17:41.740 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.1\n",
      "2021-08-25 11:17:41.740 | INFO     | src.policies:train:109 - Episode 900\n",
      "2021-08-25 11:17:41.750 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:41.751 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:17:41.752 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.16\n",
      "2021-08-25 11:17:41.753 | INFO     | src.policies:train:109 - Episode 901\n",
      "2021-08-25 11:17:41.768 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:41.769 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 11:17:41.770 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.38\n",
      "2021-08-25 11:17:41.771 | WARNING  | src.policies:train:131 - The actual batch size is 206, instead of 200\n",
      "2021-08-25 11:17:41.777 | INFO     | src.policies:train:157 - Total loss: 0.995145320892334\n",
      "2021-08-25 11:17:41.780 | INFO     | src.policies:train:103 - Epoch 112 / 800\n",
      "2021-08-25 11:17:41.781 | INFO     | src.policies:train:109 - Episode 902\n",
      "2021-08-25 11:17:41.789 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:41.790 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:17:41.791 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.35\n",
      "2021-08-25 11:17:41.792 | INFO     | src.policies:train:109 - Episode 903\n",
      "2021-08-25 11:17:41.800 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:41.801 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:17:41.802 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.36\n",
      "2021-08-25 11:17:41.802 | INFO     | src.policies:train:109 - Episode 904\n",
      "2021-08-25 11:17:41.809 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:41.810 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:17:41.811 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.07\n",
      "2021-08-25 11:17:41.812 | INFO     | src.policies:train:109 - Episode 905\n",
      "2021-08-25 11:17:41.819 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:41.820 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:41.821 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.09\n",
      "2021-08-25 11:17:41.822 | INFO     | src.policies:train:109 - Episode 906\n",
      "2021-08-25 11:17:41.830 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:41.831 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:17:41.832 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.08\n",
      "2021-08-25 11:17:41.833 | INFO     | src.policies:train:109 - Episode 907\n",
      "2021-08-25 11:17:41.848 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:41.849 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 11:17:41.850 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.98\n",
      "2021-08-25 11:17:41.851 | INFO     | src.policies:train:109 - Episode 908\n",
      "2021-08-25 11:17:41.870 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:41.871 | INFO     | src.policies:train:121 - Mean episode return: 45.0\n",
      "2021-08-25 11:17:41.872 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.75\n",
      "2021-08-25 11:17:41.873 | INFO     | src.policies:train:109 - Episode 909\n",
      "2021-08-25 11:17:41.890 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:41.891 | INFO     | src.policies:train:121 - Mean episode return: 46.0\n",
      "2021-08-25 11:17:41.892 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.07\n",
      "2021-08-25 11:17:41.893 | WARNING  | src.policies:train:131 - The actual batch size is 207, instead of 200\n",
      "2021-08-25 11:17:41.899 | INFO     | src.policies:train:157 - Total loss: 0.9951687455177307\n",
      "2021-08-25 11:17:41.901 | INFO     | src.policies:train:103 - Epoch 113 / 800\n",
      "2021-08-25 11:17:41.902 | INFO     | src.policies:train:109 - Episode 910\n",
      "2021-08-25 11:17:41.907 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:41.908 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 11:17:41.909 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.67\n",
      "2021-08-25 11:17:41.910 | INFO     | src.policies:train:109 - Episode 911\n",
      "2021-08-25 11:17:41.919 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:41.920 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:17:41.921 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.52\n",
      "2021-08-25 11:17:41.921 | INFO     | src.policies:train:109 - Episode 912\n",
      "2021-08-25 11:17:41.927 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:41.928 | INFO     | src.policies:train:121 - Mean episode return: 9.0\n",
      "2021-08-25 11:17:41.928 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.43\n",
      "2021-08-25 11:17:41.929 | INFO     | src.policies:train:109 - Episode 913\n",
      "2021-08-25 11:17:41.938 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:41.940 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:17:41.940 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.2\n",
      "2021-08-25 11:17:41.941 | INFO     | src.policies:train:109 - Episode 914\n",
      "2021-08-25 11:17:41.947 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:41.948 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:17:41.949 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.94\n",
      "2021-08-25 11:17:41.949 | INFO     | src.policies:train:109 - Episode 915\n",
      "2021-08-25 11:17:41.961 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:41.962 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 11:17:41.963 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.46\n",
      "2021-08-25 11:17:41.964 | INFO     | src.policies:train:109 - Episode 916\n",
      "2021-08-25 11:17:41.983 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:41.984 | INFO     | src.policies:train:121 - Mean episode return: 53.0\n",
      "2021-08-25 11:17:41.985 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.9\n",
      "2021-08-25 11:17:41.985 | INFO     | src.policies:train:109 - Episode 917\n",
      "2021-08-25 11:17:41.996 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:41.997 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:17:41.998 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.02\n",
      "2021-08-25 11:17:41.999 | INFO     | src.policies:train:109 - Episode 918\n",
      "2021-08-25 11:17:42.019 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:42.020 | INFO     | src.policies:train:121 - Mean episode return: 51.0\n",
      "2021-08-25 11:17:42.021 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.21\n",
      "2021-08-25 11:17:42.022 | WARNING  | src.policies:train:131 - The actual batch size is 220, instead of 200\n",
      "2021-08-25 11:17:42.028 | INFO     | src.policies:train:157 - Total loss: 0.9954544305801392\n",
      "2021-08-25 11:17:42.030 | INFO     | src.policies:train:103 - Epoch 114 / 800\n",
      "2021-08-25 11:17:42.031 | INFO     | src.policies:train:109 - Episode 919\n",
      "2021-08-25 11:17:42.041 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:42.042 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 11:17:42.043 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.34\n",
      "2021-08-25 11:17:42.044 | INFO     | src.policies:train:109 - Episode 920\n",
      "2021-08-25 11:17:42.054 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:42.055 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:17:42.055 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.36\n",
      "2021-08-25 11:17:42.056 | INFO     | src.policies:train:109 - Episode 921\n",
      "2021-08-25 11:17:42.070 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:42.071 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 11:17:42.072 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.46\n",
      "2021-08-25 11:17:42.073 | INFO     | src.policies:train:109 - Episode 922\n",
      "2021-08-25 11:17:42.084 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:42.085 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:17:42.086 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.36\n",
      "2021-08-25 11:17:42.086 | INFO     | src.policies:train:109 - Episode 923\n",
      "2021-08-25 11:17:42.095 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:42.097 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:17:42.097 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.45\n",
      "2021-08-25 11:17:42.098 | INFO     | src.policies:train:109 - Episode 924\n",
      "2021-08-25 11:17:42.115 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:42.116 | INFO     | src.policies:train:121 - Mean episode return: 42.0\n",
      "2021-08-25 11:17:42.117 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.72\n",
      "2021-08-25 11:17:42.118 | INFO     | src.policies:train:109 - Episode 925\n",
      "2021-08-25 11:17:42.129 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:42.130 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 11:17:42.131 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.64\n",
      "2021-08-25 11:17:42.132 | INFO     | src.policies:train:109 - Episode 926\n",
      "2021-08-25 11:17:42.145 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:42.146 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:42.146 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.81\n",
      "2021-08-25 11:17:42.147 | WARNING  | src.policies:train:131 - The actual batch size is 224, instead of 200\n",
      "2021-08-25 11:17:42.153 | INFO     | src.policies:train:157 - Total loss: 0.9955354332923889\n",
      "2021-08-25 11:17:42.156 | INFO     | src.policies:train:103 - Epoch 115 / 800\n",
      "2021-08-25 11:17:42.157 | INFO     | src.policies:train:109 - Episode 927\n",
      "2021-08-25 11:17:42.166 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:42.167 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:17:42.168 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.88\n",
      "2021-08-25 11:17:42.169 | INFO     | src.policies:train:109 - Episode 928\n",
      "2021-08-25 11:17:42.180 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:42.181 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:17:42.182 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.93\n",
      "2021-08-25 11:17:42.183 | INFO     | src.policies:train:109 - Episode 929\n",
      "2021-08-25 11:17:42.210 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:42.211 | INFO     | src.policies:train:121 - Mean episode return: 82.0\n",
      "2021-08-25 11:17:42.212 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.31\n",
      "2021-08-25 11:17:42.213 | INFO     | src.policies:train:109 - Episode 930\n",
      "2021-08-25 11:17:42.233 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:42.234 | INFO     | src.policies:train:121 - Mean episode return: 54.0\n",
      "2021-08-25 11:17:42.235 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.57\n",
      "2021-08-25 11:17:42.236 | INFO     | src.policies:train:109 - Episode 931\n",
      "2021-08-25 11:17:42.244 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:42.245 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:17:42.246 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.97\n",
      "2021-08-25 11:17:42.247 | INFO     | src.policies:train:109 - Episode 932\n",
      "2021-08-25 11:17:42.263 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:42.264 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 11:17:42.265 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.95\n",
      "2021-08-25 11:17:42.265 | WARNING  | src.policies:train:131 - The actual batch size is 237, instead of 200\n",
      "2021-08-25 11:17:42.271 | INFO     | src.policies:train:157 - Total loss: 0.9957805871963501\n",
      "2021-08-25 11:17:42.273 | INFO     | src.policies:train:103 - Epoch 116 / 800\n",
      "2021-08-25 11:17:42.275 | INFO     | src.policies:train:109 - Episode 933\n",
      "2021-08-25 11:17:42.290 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:42.291 | INFO     | src.policies:train:121 - Mean episode return: 44.0\n",
      "2021-08-25 11:17:42.292 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.21\n",
      "2021-08-25 11:17:42.293 | INFO     | src.policies:train:109 - Episode 934\n",
      "2021-08-25 11:17:42.300 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:42.301 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 11:17:42.302 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.17\n",
      "2021-08-25 11:17:42.303 | INFO     | src.policies:train:109 - Episode 935\n",
      "2021-08-25 11:17:42.311 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:42.312 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:17:42.313 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.18\n",
      "2021-08-25 11:17:42.314 | INFO     | src.policies:train:109 - Episode 936\n",
      "2021-08-25 11:17:42.330 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:42.331 | INFO     | src.policies:train:121 - Mean episode return: 41.0\n",
      "2021-08-25 11:17:42.332 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.14\n",
      "2021-08-25 11:17:42.333 | INFO     | src.policies:train:109 - Episode 937\n",
      "2021-08-25 11:17:42.338 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:42.339 | INFO     | src.policies:train:121 - Mean episode return: 9.0\n",
      "2021-08-25 11:17:42.340 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.79\n",
      "2021-08-25 11:17:42.341 | INFO     | src.policies:train:109 - Episode 938\n",
      "2021-08-25 11:17:42.350 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:42.351 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:17:42.352 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.77\n",
      "2021-08-25 11:17:42.353 | INFO     | src.policies:train:109 - Episode 939\n",
      "2021-08-25 11:17:42.362 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:42.363 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:17:42.364 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.74\n",
      "2021-08-25 11:17:42.365 | INFO     | src.policies:train:109 - Episode 940\n",
      "2021-08-25 11:17:42.381 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:42.382 | INFO     | src.policies:train:121 - Mean episode return: 46.0\n",
      "2021-08-25 11:17:42.383 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.98\n",
      "2021-08-25 11:17:42.384 | WARNING  | src.policies:train:131 - The actual batch size is 202, instead of 200\n",
      "2021-08-25 11:17:42.390 | INFO     | src.policies:train:157 - Total loss: 0.9950494766235352\n",
      "2021-08-25 11:17:42.392 | INFO     | src.policies:train:103 - Epoch 117 / 800\n",
      "2021-08-25 11:17:42.393 | INFO     | src.policies:train:109 - Episode 941\n",
      "2021-08-25 11:17:42.418 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:42.420 | INFO     | src.policies:train:121 - Mean episode return: 75.0\n",
      "2021-08-25 11:17:42.421 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.51\n",
      "2021-08-25 11:17:42.422 | INFO     | src.policies:train:109 - Episode 942\n",
      "2021-08-25 11:17:42.436 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:42.438 | INFO     | src.policies:train:121 - Mean episode return: 39.0\n",
      "2021-08-25 11:17:42.438 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.77\n",
      "2021-08-25 11:17:42.440 | INFO     | src.policies:train:109 - Episode 943\n",
      "2021-08-25 11:17:42.450 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:42.451 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:17:42.452 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.83\n",
      "2021-08-25 11:17:42.453 | INFO     | src.policies:train:109 - Episode 944\n",
      "2021-08-25 11:17:42.468 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:42.469 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 11:17:42.470 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.05\n",
      "2021-08-25 11:17:42.471 | INFO     | src.policies:train:109 - Episode 945\n",
      "2021-08-25 11:17:42.480 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:42.481 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:17:42.482 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.91\n",
      "2021-08-25 11:17:42.483 | INFO     | src.policies:train:109 - Episode 946\n",
      "2021-08-25 11:17:42.498 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:42.499 | INFO     | src.policies:train:121 - Mean episode return: 38.0\n",
      "2021-08-25 11:17:42.500 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:42.501 | WARNING  | src.policies:train:131 - The actual batch size is 228, instead of 200\n",
      "2021-08-25 11:17:42.507 | INFO     | src.policies:train:157 - Total loss: 0.9956139326095581\n",
      "2021-08-25 11:17:42.509 | INFO     | src.policies:train:103 - Epoch 118 / 800\n",
      "2021-08-25 11:17:42.511 | INFO     | src.policies:train:109 - Episode 947\n",
      "2021-08-25 11:17:42.526 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:42.527 | INFO     | src.policies:train:121 - Mean episode return: 41.0\n",
      "2021-08-25 11:17:42.527 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.43\n",
      "2021-08-25 11:17:42.528 | INFO     | src.policies:train:109 - Episode 948\n",
      "2021-08-25 11:17:42.545 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:42.546 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 11:17:42.547 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.62\n",
      "2021-08-25 11:17:42.548 | INFO     | src.policies:train:109 - Episode 949\n",
      "2021-08-25 11:17:42.562 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:42.563 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 11:17:42.564 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.78\n",
      "2021-08-25 11:17:42.565 | INFO     | src.policies:train:109 - Episode 950\n",
      "2021-08-25 11:17:42.575 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:42.577 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:17:42.577 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.85\n",
      "2021-08-25 11:17:42.578 | INFO     | src.policies:train:109 - Episode 951\n",
      "2021-08-25 11:17:42.594 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:42.595 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 11:17:42.596 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.73\n",
      "2021-08-25 11:17:42.597 | INFO     | src.policies:train:109 - Episode 952\n",
      "2021-08-25 11:17:42.605 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:42.606 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:17:42.607 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.57\n",
      "2021-08-25 11:17:42.608 | INFO     | src.policies:train:109 - Episode 953\n",
      "2021-08-25 11:17:42.627 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:42.628 | INFO     | src.policies:train:121 - Mean episode return: 46.0\n",
      "2021-08-25 11:17:42.629 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.77\n",
      "2021-08-25 11:17:42.630 | WARNING  | src.policies:train:131 - The actual batch size is 235, instead of 200\n",
      "2021-08-25 11:17:42.637 | INFO     | src.policies:train:157 - Total loss: 0.9957443475723267\n",
      "2021-08-25 11:17:42.640 | INFO     | src.policies:train:103 - Epoch 119 / 800\n",
      "2021-08-25 11:17:42.642 | INFO     | src.policies:train:109 - Episode 954\n",
      "2021-08-25 11:17:42.648 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:42.649 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:17:42.650 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.55\n",
      "2021-08-25 11:17:42.651 | INFO     | src.policies:train:109 - Episode 955\n",
      "2021-08-25 11:17:42.673 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:42.675 | INFO     | src.policies:train:121 - Mean episode return: 56.0\n",
      "2021-08-25 11:17:42.675 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.33\n",
      "2021-08-25 11:17:42.676 | INFO     | src.policies:train:109 - Episode 956\n",
      "2021-08-25 11:17:42.694 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:42.695 | INFO     | src.policies:train:121 - Mean episode return: 39.0\n",
      "2021-08-25 11:17:42.696 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.54\n",
      "2021-08-25 11:17:42.697 | INFO     | src.policies:train:109 - Episode 957\n",
      "2021-08-25 11:17:42.712 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:42.713 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 11:17:42.714 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.6\n",
      "2021-08-25 11:17:42.715 | INFO     | src.policies:train:109 - Episode 958\n",
      "2021-08-25 11:17:42.727 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:42.728 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:17:42.729 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.66\n",
      "2021-08-25 11:17:42.730 | INFO     | src.policies:train:109 - Episode 959\n",
      "2021-08-25 11:17:42.738 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:42.740 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:17:42.740 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.59\n",
      "2021-08-25 11:17:42.741 | INFO     | src.policies:train:109 - Episode 960\n",
      "2021-08-25 11:17:42.755 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:42.756 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 11:17:42.757 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.64\n",
      "2021-08-25 11:17:42.758 | WARNING  | src.policies:train:131 - The actual batch size is 207, instead of 200\n",
      "2021-08-25 11:17:42.765 | INFO     | src.policies:train:157 - Total loss: 0.9951686859130859\n",
      "2021-08-25 11:17:42.767 | INFO     | src.policies:train:103 - Epoch 120 / 800\n",
      "2021-08-25 11:17:42.768 | INFO     | src.policies:train:109 - Episode 961\n",
      "2021-08-25 11:17:42.774 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:42.776 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:17:42.776 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.36\n",
      "2021-08-25 11:17:42.777 | INFO     | src.policies:train:109 - Episode 962\n",
      "2021-08-25 11:17:42.793 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:42.794 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 11:17:42.795 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.33\n",
      "2021-08-25 11:17:42.796 | INFO     | src.policies:train:109 - Episode 963\n",
      "2021-08-25 11:17:42.812 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:42.813 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 11:17:42.813 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.04\n",
      "2021-08-25 11:17:42.815 | INFO     | src.policies:train:109 - Episode 964\n",
      "2021-08-25 11:17:42.828 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:42.829 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 11:17:42.830 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.07\n",
      "2021-08-25 11:17:42.831 | INFO     | src.policies:train:109 - Episode 965\n",
      "2021-08-25 11:17:42.845 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:42.846 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 11:17:42.847 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.15\n",
      "2021-08-25 11:17:42.848 | INFO     | src.policies:train:109 - Episode 966\n",
      "2021-08-25 11:17:42.856 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:42.857 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:17:42.858 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.17\n",
      "2021-08-25 11:17:42.859 | INFO     | src.policies:train:109 - Episode 967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:42.881 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:42.882 | INFO     | src.policies:train:121 - Mean episode return: 57.0\n",
      "2021-08-25 11:17:42.883 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.56\n",
      "2021-08-25 11:17:42.884 | WARNING  | src.policies:train:131 - The actual batch size is 218, instead of 200\n",
      "2021-08-25 11:17:42.890 | INFO     | src.policies:train:157 - Total loss: 0.9954127073287964\n",
      "2021-08-25 11:17:42.893 | INFO     | src.policies:train:103 - Epoch 121 / 800\n",
      "2021-08-25 11:17:42.894 | INFO     | src.policies:train:109 - Episode 968\n",
      "2021-08-25 11:17:42.905 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:42.906 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 11:17:42.907 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.25\n",
      "2021-08-25 11:17:42.908 | INFO     | src.policies:train:109 - Episode 969\n",
      "2021-08-25 11:17:42.929 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:42.930 | INFO     | src.policies:train:121 - Mean episode return: 50.0\n",
      "2021-08-25 11:17:42.931 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.53\n",
      "2021-08-25 11:17:42.932 | INFO     | src.policies:train:109 - Episode 970\n",
      "2021-08-25 11:17:42.946 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:42.947 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 11:17:42.948 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.68\n",
      "2021-08-25 11:17:42.949 | INFO     | src.policies:train:109 - Episode 971\n",
      "2021-08-25 11:17:42.966 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:42.967 | INFO     | src.policies:train:121 - Mean episode return: 39.0\n",
      "2021-08-25 11:17:42.968 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.95\n",
      "2021-08-25 11:17:42.969 | INFO     | src.policies:train:109 - Episode 972\n",
      "2021-08-25 11:17:43.022 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:43.023 | INFO     | src.policies:train:121 - Mean episode return: 150.0\n",
      "2021-08-25 11:17:43.023 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.98\n",
      "2021-08-25 11:17:43.024 | WARNING  | src.policies:train:131 - The actual batch size is 295, instead of 200\n",
      "2021-08-25 11:17:43.031 | INFO     | src.policies:train:157 - Total loss: 0.9966098666191101\n",
      "2021-08-25 11:17:43.033 | INFO     | src.policies:train:103 - Epoch 122 / 800\n",
      "2021-08-25 11:17:43.034 | INFO     | src.policies:train:109 - Episode 973\n",
      "2021-08-25 11:17:43.049 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:43.051 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 11:17:43.052 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.19\n",
      "2021-08-25 11:17:43.053 | INFO     | src.policies:train:109 - Episode 974\n",
      "2021-08-25 11:17:43.070 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:43.071 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 11:17:43.072 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.86\n",
      "2021-08-25 11:17:43.073 | INFO     | src.policies:train:109 - Episode 975\n",
      "2021-08-25 11:17:43.086 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:43.087 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:17:43.088 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.93\n",
      "2021-08-25 11:17:43.089 | INFO     | src.policies:train:109 - Episode 976\n",
      "2021-08-25 11:17:43.108 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:43.109 | INFO     | src.policies:train:121 - Mean episode return: 49.0\n",
      "2021-08-25 11:17:43.110 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.26\n",
      "2021-08-25 11:17:43.111 | INFO     | src.policies:train:109 - Episode 977\n",
      "2021-08-25 11:17:43.122 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:43.123 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:17:43.124 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.2\n",
      "2021-08-25 11:17:43.125 | INFO     | src.policies:train:109 - Episode 978\n",
      "2021-08-25 11:17:43.136 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:43.138 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:17:43.138 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.24\n",
      "2021-08-25 11:17:43.139 | INFO     | src.policies:train:109 - Episode 979\n",
      "2021-08-25 11:17:43.155 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:43.156 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 11:17:43.157 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.46\n",
      "2021-08-25 11:17:43.158 | WARNING  | src.policies:train:131 - The actual batch size is 233, instead of 200\n",
      "2021-08-25 11:17:43.165 | INFO     | src.policies:train:157 - Total loss: 0.9957081079483032\n",
      "2021-08-25 11:17:43.168 | INFO     | src.policies:train:103 - Epoch 123 / 800\n",
      "2021-08-25 11:17:43.169 | INFO     | src.policies:train:109 - Episode 980\n",
      "2021-08-25 11:17:43.179 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:43.181 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 11:17:43.181 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.5\n",
      "2021-08-25 11:17:43.182 | INFO     | src.policies:train:109 - Episode 981\n",
      "2021-08-25 11:17:43.189 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:43.190 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:17:43.191 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.24\n",
      "2021-08-25 11:17:43.192 | INFO     | src.policies:train:109 - Episode 982\n",
      "2021-08-25 11:17:43.200 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:43.202 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 11:17:43.203 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.08\n",
      "2021-08-25 11:17:43.205 | INFO     | src.policies:train:109 - Episode 983\n",
      "2021-08-25 11:17:43.220 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:43.222 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 11:17:43.223 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.78\n",
      "2021-08-25 11:17:43.225 | INFO     | src.policies:train:109 - Episode 984\n",
      "2021-08-25 11:17:43.238 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:43.239 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:17:43.241 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.85\n",
      "2021-08-25 11:17:43.242 | INFO     | src.policies:train:109 - Episode 985\n",
      "2021-08-25 11:17:43.254 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:43.255 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:17:43.256 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.71\n",
      "2021-08-25 11:17:43.258 | INFO     | src.policies:train:109 - Episode 986\n",
      "2021-08-25 11:17:43.267 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:43.268 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:17:43.269 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.53\n",
      "2021-08-25 11:17:43.271 | INFO     | src.policies:train:109 - Episode 987\n",
      "2021-08-25 11:17:43.283 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:43.284 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:17:43.285 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.63\n",
      "2021-08-25 11:17:43.286 | INFO     | src.policies:train:109 - Episode 988\n",
      "2021-08-25 11:17:43.311 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:43.312 | INFO     | src.policies:train:121 - Mean episode return: 59.0\n",
      "2021-08-25 11:17:43.314 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.08\n",
      "2021-08-25 11:17:43.315 | WARNING  | src.policies:train:131 - The actual batch size is 217, instead of 200\n",
      "2021-08-25 11:17:43.324 | INFO     | src.policies:train:157 - Total loss: 0.9953915476799011\n",
      "2021-08-25 11:17:43.327 | INFO     | src.policies:train:103 - Epoch 124 / 800\n",
      "2021-08-25 11:17:43.328 | INFO     | src.policies:train:109 - Episode 989\n",
      "2021-08-25 11:17:43.335 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:43.336 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:17:43.338 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.7\n",
      "2021-08-25 11:17:43.339 | INFO     | src.policies:train:109 - Episode 990\n",
      "2021-08-25 11:17:43.357 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:43.358 | INFO     | src.policies:train:121 - Mean episode return: 38.0\n",
      "2021-08-25 11:17:43.360 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.95\n",
      "2021-08-25 11:17:43.361 | INFO     | src.policies:train:109 - Episode 991\n",
      "2021-08-25 11:17:43.374 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:43.375 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 11:17:43.377 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.95\n",
      "2021-08-25 11:17:43.378 | INFO     | src.policies:train:109 - Episode 992\n",
      "2021-08-25 11:17:43.392 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:43.393 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:17:43.394 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.89\n",
      "2021-08-25 11:17:43.395 | INFO     | src.policies:train:109 - Episode 993\n",
      "2021-08-25 11:17:43.418 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:43.419 | INFO     | src.policies:train:121 - Mean episode return: 54.0\n",
      "2021-08-25 11:17:43.420 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.19\n",
      "2021-08-25 11:17:43.421 | INFO     | src.policies:train:109 - Episode 994\n",
      "2021-08-25 11:17:43.447 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:43.449 | INFO     | src.policies:train:121 - Mean episode return: 72.0\n",
      "2021-08-25 11:17:43.449 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.59\n",
      "2021-08-25 11:17:43.451 | WARNING  | src.policies:train:131 - The actual batch size is 230, instead of 200\n",
      "2021-08-25 11:17:43.458 | INFO     | src.policies:train:157 - Total loss: 0.9956520199775696\n",
      "2021-08-25 11:17:43.461 | INFO     | src.policies:train:103 - Epoch 125 / 800\n",
      "2021-08-25 11:17:43.462 | INFO     | src.policies:train:109 - Episode 995\n",
      "2021-08-25 11:17:43.468 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:43.469 | INFO     | src.policies:train:121 - Mean episode return: 8.0\n",
      "2021-08-25 11:17:43.470 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.55\n",
      "2021-08-25 11:17:43.471 | INFO     | src.policies:train:109 - Episode 996\n",
      "2021-08-25 11:17:43.480 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:43.482 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:17:43.483 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.02\n",
      "2021-08-25 11:17:43.484 | INFO     | src.policies:train:109 - Episode 997\n",
      "2021-08-25 11:17:43.492 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:43.493 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:17:43.494 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.82\n",
      "2021-08-25 11:17:43.495 | INFO     | src.policies:train:109 - Episode 998\n",
      "2021-08-25 11:17:43.506 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:43.507 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:17:43.507 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.82\n",
      "2021-08-25 11:17:43.509 | INFO     | src.policies:train:109 - Episode 999\n",
      "2021-08-25 11:17:43.521 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:43.523 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:17:43.524 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.86\n",
      "2021-08-25 11:17:43.525 | INFO     | src.policies:train:109 - Episode 1000\n",
      "2021-08-25 11:17:43.544 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:43.546 | INFO     | src.policies:train:121 - Mean episode return: 43.0\n",
      "2021-08-25 11:17:43.546 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.08\n",
      "2021-08-25 11:17:43.547 | INFO     | src.policies:train:109 - Episode 1001\n",
      "2021-08-25 11:17:43.563 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:43.564 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 11:17:43.565 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.98\n",
      "2021-08-25 11:17:43.566 | INFO     | src.policies:train:109 - Episode 1002\n",
      "2021-08-25 11:17:43.576 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:43.578 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:17:43.579 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.97\n",
      "2021-08-25 11:17:43.580 | INFO     | src.policies:train:109 - Episode 1003\n",
      "2021-08-25 11:17:43.597 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:43.598 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 11:17:43.599 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.15\n",
      "2021-08-25 11:17:43.600 | INFO     | src.policies:train:109 - Episode 1004\n",
      "2021-08-25 11:17:43.609 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:43.610 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:17:43.612 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.17\n",
      "2021-08-25 11:17:43.613 | WARNING  | src.policies:train:131 - The actual batch size is 209, instead of 200\n",
      "2021-08-25 11:17:43.622 | INFO     | src.policies:train:157 - Total loss: 0.9952150583267212\n",
      "2021-08-25 11:17:43.625 | INFO     | src.policies:train:103 - Epoch 126 / 800\n",
      "2021-08-25 11:17:43.626 | INFO     | src.policies:train:109 - Episode 1005\n",
      "2021-08-25 11:17:43.643 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:43.645 | INFO     | src.policies:train:121 - Mean episode return: 45.0\n",
      "2021-08-25 11:17:43.645 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.46\n",
      "2021-08-25 11:17:43.646 | INFO     | src.policies:train:109 - Episode 1006\n",
      "2021-08-25 11:17:43.665 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:43.666 | INFO     | src.policies:train:121 - Mean episode return: 46.0\n",
      "2021-08-25 11:17:43.667 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.77\n",
      "2021-08-25 11:17:43.668 | INFO     | src.policies:train:109 - Episode 1007\n",
      "2021-08-25 11:17:43.680 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:43.681 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:43.682 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.62\n",
      "2021-08-25 11:17:43.683 | INFO     | src.policies:train:109 - Episode 1008\n",
      "2021-08-25 11:17:43.693 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:43.694 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:17:43.695 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.36\n",
      "2021-08-25 11:17:43.696 | INFO     | src.policies:train:109 - Episode 1009\n",
      "2021-08-25 11:17:43.716 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:43.718 | INFO     | src.policies:train:121 - Mean episode return: 49.0\n",
      "2021-08-25 11:17:43.719 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.39\n",
      "2021-08-25 11:17:43.720 | INFO     | src.policies:train:109 - Episode 1010\n",
      "2021-08-25 11:17:43.736 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:43.738 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 11:17:43.739 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.64\n",
      "2021-08-25 11:17:43.740 | WARNING  | src.policies:train:131 - The actual batch size is 219, instead of 200\n",
      "2021-08-25 11:17:43.748 | INFO     | src.policies:train:157 - Total loss: 0.9954335689544678\n",
      "2021-08-25 11:17:43.751 | INFO     | src.policies:train:103 - Epoch 127 / 800\n",
      "2021-08-25 11:17:43.752 | INFO     | src.policies:train:109 - Episode 1011\n",
      "2021-08-25 11:17:43.765 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:43.767 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:17:43.768 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.78\n",
      "2021-08-25 11:17:43.769 | INFO     | src.policies:train:109 - Episode 1012\n",
      "2021-08-25 11:17:43.783 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:43.784 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:17:43.785 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.95\n",
      "2021-08-25 11:17:43.785 | INFO     | src.policies:train:109 - Episode 1013\n",
      "2021-08-25 11:17:43.795 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:43.797 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:17:43.798 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.9\n",
      "2021-08-25 11:17:43.799 | INFO     | src.policies:train:109 - Episode 1014\n",
      "2021-08-25 11:17:43.809 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:43.811 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:17:43.812 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.95\n",
      "2021-08-25 11:17:43.813 | INFO     | src.policies:train:109 - Episode 1015\n",
      "2021-08-25 11:17:43.825 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:43.826 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:17:43.827 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.89\n",
      "2021-08-25 11:17:43.828 | INFO     | src.policies:train:109 - Episode 1016\n",
      "2021-08-25 11:17:43.841 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:43.842 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 11:17:43.843 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.61\n",
      "2021-08-25 11:17:43.844 | INFO     | src.policies:train:109 - Episode 1017\n",
      "2021-08-25 11:17:43.860 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:43.861 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 11:17:43.862 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.69\n",
      "2021-08-25 11:17:43.863 | INFO     | src.policies:train:109 - Episode 1018\n",
      "2021-08-25 11:17:43.873 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:43.875 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:17:43.876 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.36\n",
      "2021-08-25 11:17:43.877 | INFO     | src.policies:train:109 - Episode 1019\n",
      "2021-08-25 11:17:43.888 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:43.890 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:17:43.891 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.29\n",
      "2021-08-25 11:17:43.892 | WARNING  | src.policies:train:131 - The actual batch size is 202, instead of 200\n",
      "2021-08-25 11:17:43.900 | INFO     | src.policies:train:157 - Total loss: 0.9950490593910217\n",
      "2021-08-25 11:17:43.903 | INFO     | src.policies:train:103 - Epoch 128 / 800\n",
      "2021-08-25 11:17:43.905 | INFO     | src.policies:train:109 - Episode 1020\n",
      "2021-08-25 11:17:43.915 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:43.917 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 11:17:43.918 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.37\n",
      "2021-08-25 11:17:43.919 | INFO     | src.policies:train:109 - Episode 1021\n",
      "2021-08-25 11:17:43.934 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:43.935 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 11:17:43.936 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.4\n",
      "2021-08-25 11:17:43.937 | INFO     | src.policies:train:109 - Episode 1022\n",
      "2021-08-25 11:17:43.954 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:43.955 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 11:17:43.957 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.56\n",
      "2021-08-25 11:17:43.958 | INFO     | src.policies:train:109 - Episode 1023\n",
      "2021-08-25 11:17:43.970 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:43.971 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:17:43.973 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.58\n",
      "2021-08-25 11:17:43.973 | INFO     | src.policies:train:109 - Episode 1024\n",
      "2021-08-25 11:17:43.999 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:44.001 | INFO     | src.policies:train:121 - Mean episode return: 61.0\n",
      "2021-08-25 11:17:44.002 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.77\n",
      "2021-08-25 11:17:44.003 | INFO     | src.policies:train:109 - Episode 1025\n",
      "2021-08-25 11:17:44.018 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:44.019 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:17:44.020 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.81\n",
      "2021-08-25 11:17:44.021 | WARNING  | src.policies:train:131 - The actual batch size is 218, instead of 200\n",
      "2021-08-25 11:17:44.029 | INFO     | src.policies:train:157 - Total loss: 0.9954127073287964\n",
      "2021-08-25 11:17:44.032 | INFO     | src.policies:train:103 - Epoch 129 / 800\n",
      "2021-08-25 11:17:44.033 | INFO     | src.policies:train:109 - Episode 1026\n",
      "2021-08-25 11:17:44.056 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:44.057 | INFO     | src.policies:train:121 - Mean episode return: 60.0\n",
      "2021-08-25 11:17:44.059 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.1\n",
      "2021-08-25 11:17:44.060 | INFO     | src.policies:train:109 - Episode 1027\n",
      "2021-08-25 11:17:44.075 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:44.076 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 11:17:44.077 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:44.078 | INFO     | src.policies:train:109 - Episode 1028\n",
      "2021-08-25 11:17:44.116 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:44.118 | INFO     | src.policies:train:121 - Mean episode return: 98.0\n",
      "2021-08-25 11:17:44.119 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.94\n",
      "2021-08-25 11:17:44.120 | INFO     | src.policies:train:109 - Episode 1029\n",
      "2021-08-25 11:17:44.132 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:44.133 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:17:44.134 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.38\n",
      "2021-08-25 11:17:44.135 | WARNING  | src.policies:train:131 - The actual batch size is 214, instead of 200\n",
      "2021-08-25 11:17:44.143 | INFO     | src.policies:train:157 - Total loss: 0.995326817035675\n",
      "2021-08-25 11:17:44.146 | INFO     | src.policies:train:103 - Epoch 130 / 800\n",
      "2021-08-25 11:17:44.147 | INFO     | src.policies:train:109 - Episode 1030\n",
      "2021-08-25 11:17:44.174 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:44.176 | INFO     | src.policies:train:121 - Mean episode return: 74.0\n",
      "2021-08-25 11:17:44.176 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.58\n",
      "2021-08-25 11:17:44.177 | INFO     | src.policies:train:109 - Episode 1031\n",
      "2021-08-25 11:17:44.189 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:44.191 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 11:17:44.191 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.72\n",
      "2021-08-25 11:17:44.193 | INFO     | src.policies:train:109 - Episode 1032\n",
      "2021-08-25 11:17:44.217 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:44.218 | INFO     | src.policies:train:121 - Mean episode return: 56.0\n",
      "2021-08-25 11:17:44.219 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.88\n",
      "2021-08-25 11:17:44.221 | INFO     | src.policies:train:109 - Episode 1033\n",
      "2021-08-25 11:17:44.243 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:44.244 | INFO     | src.policies:train:121 - Mean episode return: 49.0\n",
      "2021-08-25 11:17:44.245 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.93\n",
      "2021-08-25 11:17:44.246 | WARNING  | src.policies:train:131 - The actual batch size is 210, instead of 200\n",
      "2021-08-25 11:17:44.253 | INFO     | src.policies:train:157 - Total loss: 0.9952378869056702\n",
      "2021-08-25 11:17:44.256 | INFO     | src.policies:train:103 - Epoch 131 / 800\n",
      "2021-08-25 11:17:44.258 | INFO     | src.policies:train:109 - Episode 1034\n",
      "2021-08-25 11:17:44.285 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:44.286 | INFO     | src.policies:train:121 - Mean episode return: 72.0\n",
      "2021-08-25 11:17:44.287 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.55\n",
      "2021-08-25 11:17:44.288 | INFO     | src.policies:train:109 - Episode 1035\n",
      "2021-08-25 11:17:44.327 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:44.329 | INFO     | src.policies:train:121 - Mean episode return: 107.0\n",
      "2021-08-25 11:17:44.330 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.45\n",
      "2021-08-25 11:17:44.331 | INFO     | src.policies:train:109 - Episode 1036\n",
      "2021-08-25 11:17:44.342 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:44.343 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:17:44.344 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.22\n",
      "2021-08-25 11:17:44.346 | INFO     | src.policies:train:109 - Episode 1037\n",
      "2021-08-25 11:17:44.359 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:44.361 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:17:44.362 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.42\n",
      "2021-08-25 11:17:44.363 | WARNING  | src.policies:train:131 - The actual batch size is 226, instead of 200\n",
      "2021-08-25 11:17:44.370 | INFO     | src.policies:train:157 - Total loss: 0.9955751299858093\n",
      "2021-08-25 11:17:44.374 | INFO     | src.policies:train:103 - Epoch 132 / 800\n",
      "2021-08-25 11:17:44.376 | INFO     | src.policies:train:109 - Episode 1038\n",
      "2021-08-25 11:17:44.385 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:44.386 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:17:44.387 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.39\n",
      "2021-08-25 11:17:44.388 | INFO     | src.policies:train:109 - Episode 1039\n",
      "2021-08-25 11:17:44.405 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:44.406 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 11:17:44.407 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.61\n",
      "2021-08-25 11:17:44.408 | INFO     | src.policies:train:109 - Episode 1040\n",
      "2021-08-25 11:17:44.460 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:44.461 | INFO     | src.policies:train:121 - Mean episode return: 141.0\n",
      "2021-08-25 11:17:44.462 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.56\n",
      "2021-08-25 11:17:44.463 | INFO     | src.policies:train:109 - Episode 1041\n",
      "2021-08-25 11:17:44.475 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:44.476 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:17:44.477 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.03\n",
      "2021-08-25 11:17:44.478 | WARNING  | src.policies:train:131 - The actual batch size is 217, instead of 200\n",
      "2021-08-25 11:17:44.486 | INFO     | src.policies:train:157 - Total loss: 0.9953915476799011\n",
      "2021-08-25 11:17:44.489 | INFO     | src.policies:train:103 - Epoch 133 / 800\n",
      "2021-08-25 11:17:44.490 | INFO     | src.policies:train:109 - Episode 1042\n",
      "2021-08-25 11:17:44.516 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:44.518 | INFO     | src.policies:train:121 - Mean episode return: 68.0\n",
      "2021-08-25 11:17:44.519 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.32\n",
      "2021-08-25 11:17:44.520 | INFO     | src.policies:train:109 - Episode 1043\n",
      "2021-08-25 11:17:44.548 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:44.549 | INFO     | src.policies:train:121 - Mean episode return: 70.0\n",
      "2021-08-25 11:17:44.550 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.8\n",
      "2021-08-25 11:17:44.551 | INFO     | src.policies:train:109 - Episode 1044\n",
      "2021-08-25 11:17:44.563 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:44.564 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:17:44.565 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.63\n",
      "2021-08-25 11:17:44.566 | INFO     | src.policies:train:109 - Episode 1045\n",
      "2021-08-25 11:17:44.598 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:44.599 | INFO     | src.policies:train:121 - Mean episode return: 84.0\n",
      "2021-08-25 11:17:44.600 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.29\n",
      "2021-08-25 11:17:44.601 | WARNING  | src.policies:train:131 - The actual batch size is 241, instead of 200\n",
      "2021-08-25 11:17:44.609 | INFO     | src.policies:train:157 - Total loss: 0.9958506226539612\n",
      "2021-08-25 11:17:44.612 | INFO     | src.policies:train:103 - Epoch 134 / 800\n",
      "2021-08-25 11:17:44.614 | INFO     | src.policies:train:109 - Episode 1046\n",
      "2021-08-25 11:17:44.632 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:44.634 | INFO     | src.policies:train:121 - Mean episode return: 46.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:44.635 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.37\n",
      "2021-08-25 11:17:44.636 | INFO     | src.policies:train:109 - Episode 1047\n",
      "2021-08-25 11:17:44.646 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:44.647 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:17:44.648 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.12\n",
      "2021-08-25 11:17:44.649 | INFO     | src.policies:train:109 - Episode 1048\n",
      "2021-08-25 11:17:44.659 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:44.660 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:17:44.661 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.93\n",
      "2021-08-25 11:17:44.662 | INFO     | src.policies:train:109 - Episode 1049\n",
      "2021-08-25 11:17:44.693 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:44.694 | INFO     | src.policies:train:121 - Mean episode return: 80.0\n",
      "2021-08-25 11:17:44.695 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.39\n",
      "2021-08-25 11:17:44.696 | INFO     | src.policies:train:109 - Episode 1050\n",
      "2021-08-25 11:17:44.733 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:44.734 | INFO     | src.policies:train:121 - Mean episode return: 107.0\n",
      "2021-08-25 11:17:44.735 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.22\n",
      "2021-08-25 11:17:44.736 | WARNING  | src.policies:train:131 - The actual batch size is 270, instead of 200\n",
      "2021-08-25 11:17:44.742 | INFO     | src.policies:train:157 - Total loss: 0.9962959885597229\n",
      "2021-08-25 11:17:44.744 | INFO     | src.policies:train:103 - Epoch 135 / 800\n",
      "2021-08-25 11:17:44.745 | INFO     | src.policies:train:109 - Episode 1051\n",
      "2021-08-25 11:17:44.775 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:44.776 | INFO     | src.policies:train:121 - Mean episode return: 86.0\n",
      "2021-08-25 11:17:44.777 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.72\n",
      "2021-08-25 11:17:44.778 | INFO     | src.policies:train:109 - Episode 1052\n",
      "2021-08-25 11:17:44.795 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:44.796 | INFO     | src.policies:train:121 - Mean episode return: 47.0\n",
      "2021-08-25 11:17:44.797 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.05\n",
      "2021-08-25 11:17:44.798 | INFO     | src.policies:train:109 - Episode 1053\n",
      "2021-08-25 11:17:44.808 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:44.809 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:17:44.810 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.79\n",
      "2021-08-25 11:17:44.811 | INFO     | src.policies:train:109 - Episode 1054\n",
      "2021-08-25 11:17:44.823 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:44.825 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 11:17:44.825 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.96\n",
      "2021-08-25 11:17:44.826 | INFO     | src.policies:train:109 - Episode 1055\n",
      "2021-08-25 11:17:44.836 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:44.837 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:17:44.838 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.57\n",
      "2021-08-25 11:17:44.839 | WARNING  | src.policies:train:131 - The actual batch size is 201, instead of 200\n",
      "2021-08-25 11:17:44.844 | INFO     | src.policies:train:157 - Total loss: 0.9950248003005981\n",
      "2021-08-25 11:17:44.846 | INFO     | src.policies:train:103 - Epoch 136 / 800\n",
      "2021-08-25 11:17:44.847 | INFO     | src.policies:train:109 - Episode 1056\n",
      "2021-08-25 11:17:44.877 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:44.878 | INFO     | src.policies:train:121 - Mean episode return: 84.0\n",
      "2021-08-25 11:17:44.879 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.02\n",
      "2021-08-25 11:17:44.880 | INFO     | src.policies:train:109 - Episode 1057\n",
      "2021-08-25 11:17:44.908 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:44.909 | INFO     | src.policies:train:121 - Mean episode return: 78.0\n",
      "2021-08-25 11:17:44.910 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.49\n",
      "2021-08-25 11:17:44.911 | INFO     | src.policies:train:109 - Episode 1058\n",
      "2021-08-25 11:17:44.921 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:44.922 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:17:44.923 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.43\n",
      "2021-08-25 11:17:44.924 | INFO     | src.policies:train:109 - Episode 1059\n",
      "2021-08-25 11:17:44.932 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:44.934 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:17:44.935 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.44\n",
      "2021-08-25 11:17:44.936 | INFO     | src.policies:train:109 - Episode 1060\n",
      "2021-08-25 11:17:44.951 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:44.952 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 11:17:44.954 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.42\n",
      "2021-08-25 11:17:44.955 | WARNING  | src.policies:train:131 - The actual batch size is 222, instead of 200\n",
      "2021-08-25 11:17:44.961 | INFO     | src.policies:train:157 - Total loss: 0.9954952001571655\n",
      "2021-08-25 11:17:44.964 | INFO     | src.policies:train:103 - Epoch 137 / 800\n",
      "2021-08-25 11:17:44.965 | INFO     | src.policies:train:109 - Episode 1061\n",
      "2021-08-25 11:17:44.973 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:44.975 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:17:44.975 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.5\n",
      "2021-08-25 11:17:44.976 | INFO     | src.policies:train:109 - Episode 1062\n",
      "2021-08-25 11:17:44.991 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:44.992 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 11:17:44.993 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.46\n",
      "2021-08-25 11:17:44.993 | INFO     | src.policies:train:109 - Episode 1063\n",
      "2021-08-25 11:17:45.008 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:45.009 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 11:17:45.010 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.46\n",
      "2021-08-25 11:17:45.011 | INFO     | src.policies:train:109 - Episode 1064\n",
      "2021-08-25 11:17:45.022 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:45.023 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:17:45.024 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.34\n",
      "2021-08-25 11:17:45.025 | INFO     | src.policies:train:109 - Episode 1065\n",
      "2021-08-25 11:17:45.045 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:45.046 | INFO     | src.policies:train:121 - Mean episode return: 52.0\n",
      "2021-08-25 11:17:45.047 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.55\n",
      "2021-08-25 11:17:45.048 | INFO     | src.policies:train:109 - Episode 1066\n",
      "2021-08-25 11:17:45.059 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:45.060 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:17:45.061 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:45.062 | INFO     | src.policies:train:109 - Episode 1067\n",
      "2021-08-25 11:17:45.106 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:45.107 | INFO     | src.policies:train:121 - Mean episode return: 130.0\n",
      "2021-08-25 11:17:45.108 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.39\n",
      "2021-08-25 11:17:45.109 | WARNING  | src.policies:train:131 - The actual batch size is 315, instead of 200\n",
      "2021-08-25 11:17:45.115 | INFO     | src.policies:train:157 - Total loss: 0.9968251585960388\n",
      "2021-08-25 11:17:45.118 | INFO     | src.policies:train:103 - Epoch 138 / 800\n",
      "2021-08-25 11:17:45.119 | INFO     | src.policies:train:109 - Episode 1068\n",
      "2021-08-25 11:17:45.131 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:45.132 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 11:17:45.133 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.47\n",
      "2021-08-25 11:17:45.134 | INFO     | src.policies:train:109 - Episode 1069\n",
      "2021-08-25 11:17:45.144 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:45.145 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:17:45.146 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.17\n",
      "2021-08-25 11:17:45.147 | INFO     | src.policies:train:109 - Episode 1070\n",
      "2021-08-25 11:17:45.159 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:45.161 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 11:17:45.161 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.13\n",
      "2021-08-25 11:17:45.162 | INFO     | src.policies:train:109 - Episode 1071\n",
      "2021-08-25 11:17:45.183 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:45.184 | INFO     | src.policies:train:121 - Mean episode return: 57.0\n",
      "2021-08-25 11:17:45.185 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.31\n",
      "2021-08-25 11:17:45.186 | INFO     | src.policies:train:109 - Episode 1072\n",
      "2021-08-25 11:17:45.208 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:45.209 | INFO     | src.policies:train:121 - Mean episode return: 59.0\n",
      "2021-08-25 11:17:45.210 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.4\n",
      "2021-08-25 11:17:45.211 | INFO     | src.policies:train:109 - Episode 1073\n",
      "2021-08-25 11:17:45.230 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:45.231 | INFO     | src.policies:train:121 - Mean episode return: 46.0\n",
      "2021-08-25 11:17:45.232 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.49\n",
      "2021-08-25 11:17:45.233 | WARNING  | src.policies:train:131 - The actual batch size is 242, instead of 200\n",
      "2021-08-25 11:17:45.239 | INFO     | src.policies:train:157 - Total loss: 0.9958677291870117\n",
      "2021-08-25 11:17:45.242 | INFO     | src.policies:train:103 - Epoch 139 / 800\n",
      "2021-08-25 11:17:45.243 | INFO     | src.policies:train:109 - Episode 1074\n",
      "2021-08-25 11:17:45.275 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:45.277 | INFO     | src.policies:train:121 - Mean episode return: 95.0\n",
      "2021-08-25 11:17:45.278 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.04\n",
      "2021-08-25 11:17:45.278 | INFO     | src.policies:train:109 - Episode 1075\n",
      "2021-08-25 11:17:45.295 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:45.297 | INFO     | src.policies:train:121 - Mean episode return: 47.0\n",
      "2021-08-25 11:17:45.298 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.25\n",
      "2021-08-25 11:17:45.299 | INFO     | src.policies:train:109 - Episode 1076\n",
      "2021-08-25 11:17:45.315 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:45.316 | INFO     | src.policies:train:121 - Mean episode return: 39.0\n",
      "2021-08-25 11:17:45.317 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.15\n",
      "2021-08-25 11:17:45.318 | INFO     | src.policies:train:109 - Episode 1077\n",
      "2021-08-25 11:17:45.332 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:45.333 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 11:17:45.334 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.26\n",
      "2021-08-25 11:17:45.335 | WARNING  | src.policies:train:131 - The actual batch size is 216, instead of 200\n",
      "2021-08-25 11:17:45.341 | INFO     | src.policies:train:157 - Total loss: 0.9953701496124268\n",
      "2021-08-25 11:17:45.344 | INFO     | src.policies:train:103 - Epoch 140 / 800\n",
      "2021-08-25 11:17:45.345 | INFO     | src.policies:train:109 - Episode 1078\n",
      "2021-08-25 11:17:45.365 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:45.366 | INFO     | src.policies:train:121 - Mean episode return: 56.0\n",
      "2021-08-25 11:17:45.366 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.61\n",
      "2021-08-25 11:17:45.367 | INFO     | src.policies:train:109 - Episode 1079\n",
      "2021-08-25 11:17:45.375 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:45.376 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:17:45.377 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.37\n",
      "2021-08-25 11:17:45.378 | INFO     | src.policies:train:109 - Episode 1080\n",
      "2021-08-25 11:17:45.391 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:45.392 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:17:45.393 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.41\n",
      "2021-08-25 11:17:45.394 | INFO     | src.policies:train:109 - Episode 1081\n",
      "2021-08-25 11:17:45.404 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:45.405 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:17:45.406 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.51\n",
      "2021-08-25 11:17:45.407 | INFO     | src.policies:train:109 - Episode 1082\n",
      "2021-08-25 11:17:45.416 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:45.417 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:17:45.417 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.57\n",
      "2021-08-25 11:17:45.418 | INFO     | src.policies:train:109 - Episode 1083\n",
      "2021-08-25 11:17:45.435 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:45.437 | INFO     | src.policies:train:121 - Mean episode return: 41.0\n",
      "2021-08-25 11:17:45.438 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.66\n",
      "2021-08-25 11:17:45.439 | INFO     | src.policies:train:109 - Episode 1084\n",
      "2021-08-25 11:17:45.457 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:45.458 | INFO     | src.policies:train:121 - Mean episode return: 46.0\n",
      "2021-08-25 11:17:45.459 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.89\n",
      "2021-08-25 11:17:45.460 | WARNING  | src.policies:train:131 - The actual batch size is 221, instead of 200\n",
      "2021-08-25 11:17:45.466 | INFO     | src.policies:train:157 - Total loss: 0.9954748749732971\n",
      "2021-08-25 11:17:45.468 | INFO     | src.policies:train:103 - Epoch 141 / 800\n",
      "2021-08-25 11:17:45.470 | INFO     | src.policies:train:109 - Episode 1085\n",
      "2021-08-25 11:17:45.501 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:45.502 | INFO     | src.policies:train:121 - Mean episode return: 88.0\n",
      "2021-08-25 11:17:45.503 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 40.56\n",
      "2021-08-25 11:17:45.504 | INFO     | src.policies:train:109 - Episode 1086\n",
      "2021-08-25 11:17:45.528 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:45.529 | INFO     | src.policies:train:121 - Mean episode return: 65.0\n",
      "2021-08-25 11:17:45.529 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 41.06\n",
      "2021-08-25 11:17:45.530 | INFO     | src.policies:train:109 - Episode 1087\n",
      "2021-08-25 11:17:45.539 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:45.540 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:17:45.541 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 40.98\n",
      "2021-08-25 11:17:45.542 | INFO     | src.policies:train:109 - Episode 1088\n",
      "2021-08-25 11:17:45.551 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:45.552 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:17:45.553 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 40.6\n",
      "2021-08-25 11:17:45.554 | INFO     | src.policies:train:109 - Episode 1089\n",
      "2021-08-25 11:17:45.570 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:45.572 | INFO     | src.policies:train:121 - Mean episode return: 38.0\n",
      "2021-08-25 11:17:45.573 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 40.86\n",
      "2021-08-25 11:17:45.574 | WARNING  | src.policies:train:131 - The actual batch size is 225, instead of 200\n",
      "2021-08-25 11:17:45.580 | INFO     | src.policies:train:157 - Total loss: 0.995555579662323\n",
      "2021-08-25 11:17:45.582 | INFO     | src.policies:train:103 - Epoch 142 / 800\n",
      "2021-08-25 11:17:45.583 | INFO     | src.policies:train:109 - Episode 1090\n",
      "2021-08-25 11:17:45.598 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:45.599 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 11:17:45.600 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 40.84\n",
      "2021-08-25 11:17:45.601 | INFO     | src.policies:train:109 - Episode 1091\n",
      "2021-08-25 11:17:45.616 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:45.617 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 11:17:45.617 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 40.95\n",
      "2021-08-25 11:17:45.618 | INFO     | src.policies:train:109 - Episode 1092\n",
      "2021-08-25 11:17:45.642 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:45.643 | INFO     | src.policies:train:121 - Mean episode return: 64.0\n",
      "2021-08-25 11:17:45.644 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 41.3\n",
      "2021-08-25 11:17:45.645 | INFO     | src.policies:train:109 - Episode 1093\n",
      "2021-08-25 11:17:45.654 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:45.656 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:17:45.656 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 40.95\n",
      "2021-08-25 11:17:45.657 | INFO     | src.policies:train:109 - Episode 1094\n",
      "2021-08-25 11:17:45.675 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:45.676 | INFO     | src.policies:train:121 - Mean episode return: 45.0\n",
      "2021-08-25 11:17:45.677 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 40.68\n",
      "2021-08-25 11:17:45.683 | INFO     | src.policies:train:157 - Total loss: 0.9949997067451477\n",
      "2021-08-25 11:17:45.685 | INFO     | src.policies:train:103 - Epoch 143 / 800\n",
      "2021-08-25 11:17:45.686 | INFO     | src.policies:train:109 - Episode 1095\n",
      "2021-08-25 11:17:45.699 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:45.700 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 11:17:45.701 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 40.93\n",
      "2021-08-25 11:17:45.701 | INFO     | src.policies:train:109 - Episode 1096\n",
      "2021-08-25 11:17:45.711 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:45.713 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:17:45.714 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 41.0\n",
      "2021-08-25 11:17:45.714 | INFO     | src.policies:train:109 - Episode 1097\n",
      "2021-08-25 11:17:45.727 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:45.728 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 11:17:45.729 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 41.19\n",
      "2021-08-25 11:17:45.730 | INFO     | src.policies:train:109 - Episode 1098\n",
      "2021-08-25 11:17:45.757 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:45.758 | INFO     | src.policies:train:121 - Mean episode return: 70.0\n",
      "2021-08-25 11:17:45.759 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 41.72\n",
      "2021-08-25 11:17:45.760 | INFO     | src.policies:train:109 - Episode 1099\n",
      "2021-08-25 11:17:45.774 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:45.775 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 11:17:45.776 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 41.84\n",
      "2021-08-25 11:17:45.777 | INFO     | src.policies:train:109 - Episode 1100\n",
      "2021-08-25 11:17:45.790 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:45.791 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 11:17:45.792 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 41.71\n",
      "2021-08-25 11:17:45.793 | WARNING  | src.policies:train:131 - The actual batch size is 218, instead of 200\n",
      "2021-08-25 11:17:45.799 | INFO     | src.policies:train:157 - Total loss: 0.9954127669334412\n",
      "2021-08-25 11:17:45.802 | INFO     | src.policies:train:103 - Epoch 144 / 800\n",
      "2021-08-25 11:17:45.803 | INFO     | src.policies:train:109 - Episode 1101\n",
      "2021-08-25 11:17:45.822 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:45.823 | INFO     | src.policies:train:121 - Mean episode return: 50.0\n",
      "2021-08-25 11:17:45.823 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 41.91\n",
      "2021-08-25 11:17:45.824 | INFO     | src.policies:train:109 - Episode 1102\n",
      "2021-08-25 11:17:45.858 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:45.859 | INFO     | src.policies:train:121 - Mean episode return: 93.0\n",
      "2021-08-25 11:17:45.860 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 42.67\n",
      "2021-08-25 11:17:45.861 | INFO     | src.policies:train:109 - Episode 1103\n",
      "2021-08-25 11:17:45.883 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:45.884 | INFO     | src.policies:train:121 - Mean episode return: 59.0\n",
      "2021-08-25 11:17:45.885 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 42.93\n",
      "2021-08-25 11:17:45.886 | WARNING  | src.policies:train:131 - The actual batch size is 202, instead of 200\n",
      "2021-08-25 11:17:45.891 | INFO     | src.policies:train:157 - Total loss: 0.9950492978096008\n",
      "2021-08-25 11:17:45.894 | INFO     | src.policies:train:103 - Epoch 145 / 800\n",
      "2021-08-25 11:17:45.895 | INFO     | src.policies:train:109 - Episode 1104\n",
      "2021-08-25 11:17:45.927 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:45.928 | INFO     | src.policies:train:121 - Mean episode return: 93.0\n",
      "2021-08-25 11:17:45.929 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 43.72\n",
      "2021-08-25 11:17:45.930 | INFO     | src.policies:train:109 - Episode 1105\n",
      "2021-08-25 11:17:45.943 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:45.944 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 11:17:45.945 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 43.55\n",
      "2021-08-25 11:17:45.946 | INFO     | src.policies:train:109 - Episode 1106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:45.955 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:45.956 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:17:45.957 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 43.29\n",
      "2021-08-25 11:17:45.958 | INFO     | src.policies:train:109 - Episode 1107\n",
      "2021-08-25 11:17:45.975 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:45.976 | INFO     | src.policies:train:121 - Mean episode return: 42.0\n",
      "2021-08-25 11:17:45.977 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 43.46\n",
      "2021-08-25 11:17:45.978 | INFO     | src.policies:train:109 - Episode 1108\n",
      "2021-08-25 11:17:46.029 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:46.030 | INFO     | src.policies:train:121 - Mean episode return: 145.0\n",
      "2021-08-25 11:17:46.031 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 44.72\n",
      "2021-08-25 11:17:46.032 | WARNING  | src.policies:train:131 - The actual batch size is 328, instead of 200\n",
      "2021-08-25 11:17:46.038 | INFO     | src.policies:train:157 - Total loss: 0.9988908171653748\n",
      "2021-08-25 11:17:46.041 | INFO     | src.policies:train:103 - Epoch 146 / 800\n",
      "2021-08-25 11:17:46.042 | INFO     | src.policies:train:109 - Episode 1109\n",
      "2021-08-25 11:17:46.051 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:46.053 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:17:46.054 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 44.46\n",
      "2021-08-25 11:17:46.055 | INFO     | src.policies:train:109 - Episode 1110\n",
      "2021-08-25 11:17:46.068 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:46.069 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:17:46.070 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 44.4\n",
      "2021-08-25 11:17:46.071 | INFO     | src.policies:train:109 - Episode 1111\n",
      "2021-08-25 11:17:46.081 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:46.082 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:17:46.082 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 44.31\n",
      "2021-08-25 11:17:46.083 | INFO     | src.policies:train:109 - Episode 1112\n",
      "2021-08-25 11:17:46.119 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:46.120 | INFO     | src.policies:train:121 - Mean episode return: 102.0\n",
      "2021-08-25 11:17:46.121 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 45.07\n",
      "2021-08-25 11:17:46.122 | INFO     | src.policies:train:109 - Episode 1113\n",
      "2021-08-25 11:17:46.138 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:46.139 | INFO     | src.policies:train:121 - Mean episode return: 38.0\n",
      "2021-08-25 11:17:46.139 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 45.3\n",
      "2021-08-25 11:17:46.140 | WARNING  | src.policies:train:131 - The actual batch size is 212, instead of 200\n",
      "2021-08-25 11:17:46.146 | INFO     | src.policies:train:157 - Total loss: 0.9952828884124756\n",
      "2021-08-25 11:17:46.149 | INFO     | src.policies:train:103 - Epoch 147 / 800\n",
      "2021-08-25 11:17:46.150 | INFO     | src.policies:train:109 - Episode 1114\n",
      "2021-08-25 11:17:46.167 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:46.168 | INFO     | src.policies:train:121 - Mean episode return: 47.0\n",
      "2021-08-25 11:17:46.169 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 45.61\n",
      "2021-08-25 11:17:46.170 | INFO     | src.policies:train:109 - Episode 1115\n",
      "2021-08-25 11:17:46.217 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:46.218 | INFO     | src.policies:train:121 - Mean episode return: 135.0\n",
      "2021-08-25 11:17:46.219 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 46.75\n",
      "2021-08-25 11:17:46.220 | INFO     | src.policies:train:109 - Episode 1116\n",
      "2021-08-25 11:17:46.231 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:46.232 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:17:46.233 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 46.76\n",
      "2021-08-25 11:17:46.234 | WARNING  | src.policies:train:131 - The actual batch size is 208, instead of 200\n",
      "2021-08-25 11:17:46.239 | INFO     | src.policies:train:157 - Total loss: 0.9951918721199036\n",
      "2021-08-25 11:17:46.242 | INFO     | src.policies:train:103 - Epoch 148 / 800\n",
      "2021-08-25 11:17:46.243 | INFO     | src.policies:train:109 - Episode 1117\n",
      "2021-08-25 11:17:46.269 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:46.270 | INFO     | src.policies:train:121 - Mean episode return: 75.0\n",
      "2021-08-25 11:17:46.271 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 47.19\n",
      "2021-08-25 11:17:46.272 | INFO     | src.policies:train:109 - Episode 1118\n",
      "2021-08-25 11:17:46.282 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:46.283 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:17:46.284 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 47.16\n",
      "2021-08-25 11:17:46.285 | INFO     | src.policies:train:109 - Episode 1119\n",
      "2021-08-25 11:17:46.303 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:46.304 | INFO     | src.policies:train:121 - Mean episode return: 49.0\n",
      "2021-08-25 11:17:46.305 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 47.45\n",
      "2021-08-25 11:17:46.306 | INFO     | src.policies:train:109 - Episode 1120\n",
      "2021-08-25 11:17:46.316 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:46.317 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:17:46.318 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 47.41\n",
      "2021-08-25 11:17:46.319 | INFO     | src.policies:train:109 - Episode 1121\n",
      "2021-08-25 11:17:46.340 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:46.342 | INFO     | src.policies:train:121 - Mean episode return: 54.0\n",
      "2021-08-25 11:17:46.342 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 47.55\n",
      "2021-08-25 11:17:46.343 | WARNING  | src.policies:train:131 - The actual batch size is 216, instead of 200\n",
      "2021-08-25 11:17:46.348 | INFO     | src.policies:train:157 - Total loss: 0.9953701496124268\n",
      "2021-08-25 11:17:46.351 | INFO     | src.policies:train:103 - Epoch 149 / 800\n",
      "2021-08-25 11:17:46.352 | INFO     | src.policies:train:109 - Episode 1122\n",
      "2021-08-25 11:17:46.367 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:46.368 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 11:17:46.368 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 47.55\n",
      "2021-08-25 11:17:46.369 | INFO     | src.policies:train:109 - Episode 1123\n",
      "2021-08-25 11:17:46.415 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:46.417 | INFO     | src.policies:train:121 - Mean episode return: 134.0\n",
      "2021-08-25 11:17:46.418 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 48.68\n",
      "2021-08-25 11:17:46.418 | INFO     | src.policies:train:109 - Episode 1124\n",
      "2021-08-25 11:17:46.431 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:46.432 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 11:17:46.433 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 48.37\n",
      "2021-08-25 11:17:46.434 | WARNING  | src.policies:train:131 - The actual batch size is 204, instead of 200\n",
      "2021-08-25 11:17:46.439 | INFO     | src.policies:train:157 - Total loss: 0.9950979351997375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:46.442 | INFO     | src.policies:train:103 - Epoch 150 / 800\n",
      "2021-08-25 11:17:46.443 | INFO     | src.policies:train:109 - Episode 1125\n",
      "2021-08-25 11:17:46.450 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:46.452 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:17:46.453 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 48.23\n",
      "2021-08-25 11:17:46.453 | INFO     | src.policies:train:109 - Episode 1126\n",
      "2021-08-25 11:17:46.464 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:46.466 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 11:17:46.466 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 47.88\n",
      "2021-08-25 11:17:46.467 | INFO     | src.policies:train:109 - Episode 1127\n",
      "2021-08-25 11:17:46.479 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:46.480 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 11:17:46.481 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 47.83\n",
      "2021-08-25 11:17:46.482 | INFO     | src.policies:train:109 - Episode 1128\n",
      "2021-08-25 11:17:46.523 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:46.524 | INFO     | src.policies:train:121 - Mean episode return: 121.0\n",
      "2021-08-25 11:17:46.525 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 48.06\n",
      "2021-08-25 11:17:46.525 | INFO     | src.policies:train:109 - Episode 1129\n",
      "2021-08-25 11:17:46.534 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:46.535 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:17:46.536 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 47.98\n",
      "2021-08-25 11:17:46.537 | WARNING  | src.policies:train:131 - The actual batch size is 204, instead of 200\n",
      "2021-08-25 11:17:46.543 | INFO     | src.policies:train:157 - Total loss: 0.9950977563858032\n",
      "2021-08-25 11:17:46.546 | INFO     | src.policies:train:103 - Epoch 151 / 800\n",
      "2021-08-25 11:17:46.547 | INFO     | src.policies:train:109 - Episode 1130\n",
      "2021-08-25 11:17:46.568 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:46.569 | INFO     | src.policies:train:121 - Mean episode return: 60.0\n",
      "2021-08-25 11:17:46.570 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 47.84\n",
      "2021-08-25 11:17:46.571 | INFO     | src.policies:train:109 - Episode 1131\n",
      "2021-08-25 11:17:46.580 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:46.581 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:17:46.582 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 47.68\n",
      "2021-08-25 11:17:46.583 | INFO     | src.policies:train:109 - Episode 1132\n",
      "2021-08-25 11:17:46.591 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:46.592 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:17:46.592 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 47.27\n",
      "2021-08-25 11:17:46.593 | INFO     | src.policies:train:109 - Episode 1133\n",
      "2021-08-25 11:17:46.610 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:46.611 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 11:17:46.612 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 47.18\n",
      "2021-08-25 11:17:46.613 | INFO     | src.policies:train:109 - Episode 1134\n",
      "2021-08-25 11:17:46.645 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:46.647 | INFO     | src.policies:train:121 - Mean episode return: 86.0\n",
      "2021-08-25 11:17:46.647 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 47.32\n",
      "2021-08-25 11:17:46.648 | WARNING  | src.policies:train:131 - The actual batch size is 216, instead of 200\n",
      "2021-08-25 11:17:46.654 | INFO     | src.policies:train:157 - Total loss: 0.9953703284263611\n",
      "2021-08-25 11:17:46.657 | INFO     | src.policies:train:103 - Epoch 152 / 800\n",
      "2021-08-25 11:17:46.658 | INFO     | src.policies:train:109 - Episode 1135\n",
      "2021-08-25 11:17:46.695 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:46.696 | INFO     | src.policies:train:121 - Mean episode return: 109.0\n",
      "2021-08-25 11:17:46.697 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 47.34\n",
      "2021-08-25 11:17:46.698 | INFO     | src.policies:train:109 - Episode 1136\n",
      "2021-08-25 11:17:46.717 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:46.718 | INFO     | src.policies:train:121 - Mean episode return: 52.0\n",
      "2021-08-25 11:17:46.719 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 47.68\n",
      "2021-08-25 11:17:46.720 | INFO     | src.policies:train:109 - Episode 1137\n",
      "2021-08-25 11:17:46.759 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:46.760 | INFO     | src.policies:train:121 - Mean episode return: 109.0\n",
      "2021-08-25 11:17:46.761 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 48.48\n",
      "2021-08-25 11:17:46.762 | WARNING  | src.policies:train:131 - The actual batch size is 270, instead of 200\n",
      "2021-08-25 11:17:46.767 | INFO     | src.policies:train:157 - Total loss: 0.9962959289550781\n",
      "2021-08-25 11:17:46.770 | INFO     | src.policies:train:103 - Epoch 153 / 800\n",
      "2021-08-25 11:17:46.771 | INFO     | src.policies:train:109 - Episode 1138\n",
      "2021-08-25 11:17:46.782 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:46.783 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 11:17:46.784 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 48.57\n",
      "2021-08-25 11:17:46.785 | INFO     | src.policies:train:109 - Episode 1139\n",
      "2021-08-25 11:17:46.796 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:46.797 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 11:17:46.798 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 48.46\n",
      "2021-08-25 11:17:46.799 | INFO     | src.policies:train:109 - Episode 1140\n",
      "2021-08-25 11:17:46.841 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:46.842 | INFO     | src.policies:train:121 - Mean episode return: 122.0\n",
      "2021-08-25 11:17:46.843 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 48.27\n",
      "2021-08-25 11:17:46.844 | INFO     | src.policies:train:109 - Episode 1141\n",
      "2021-08-25 11:17:46.871 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:46.872 | INFO     | src.policies:train:121 - Mean episode return: 76.0\n",
      "2021-08-25 11:17:46.873 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 48.81\n",
      "2021-08-25 11:17:46.874 | WARNING  | src.policies:train:131 - The actual batch size is 250, instead of 200\n",
      "2021-08-25 11:17:46.880 | INFO     | src.policies:train:157 - Total loss: 0.995999813079834\n",
      "2021-08-25 11:17:46.882 | INFO     | src.policies:train:103 - Epoch 154 / 800\n",
      "2021-08-25 11:17:46.883 | INFO     | src.policies:train:109 - Episode 1142\n",
      "2021-08-25 11:17:46.905 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:46.906 | INFO     | src.policies:train:121 - Mean episode return: 61.0\n",
      "2021-08-25 11:17:46.907 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 48.74\n",
      "2021-08-25 11:17:46.908 | INFO     | src.policies:train:109 - Episode 1143\n",
      "2021-08-25 11:17:46.918 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:46.919 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:17:46.920 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 48.24\n",
      "2021-08-25 11:17:46.921 | INFO     | src.policies:train:109 - Episode 1144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:46.947 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:46.948 | INFO     | src.policies:train:121 - Mean episode return: 77.0\n",
      "2021-08-25 11:17:46.949 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 48.82\n",
      "2021-08-25 11:17:46.950 | INFO     | src.policies:train:109 - Episode 1145\n",
      "2021-08-25 11:17:46.971 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:46.972 | INFO     | src.policies:train:121 - Mean episode return: 51.0\n",
      "2021-08-25 11:17:46.973 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 48.49\n",
      "2021-08-25 11:17:46.973 | WARNING  | src.policies:train:131 - The actual batch size is 209, instead of 200\n",
      "2021-08-25 11:17:46.979 | INFO     | src.policies:train:157 - Total loss: 0.9952149987220764\n",
      "2021-08-25 11:17:46.982 | INFO     | src.policies:train:103 - Epoch 155 / 800\n",
      "2021-08-25 11:17:46.983 | INFO     | src.policies:train:109 - Episode 1146\n",
      "2021-08-25 11:17:47.016 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:47.018 | INFO     | src.policies:train:121 - Mean episode return: 99.0\n",
      "2021-08-25 11:17:47.018 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 49.02\n",
      "2021-08-25 11:17:47.019 | INFO     | src.policies:train:109 - Episode 1147\n",
      "2021-08-25 11:17:47.030 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:47.032 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 11:17:47.033 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 49.13\n",
      "2021-08-25 11:17:47.033 | INFO     | src.policies:train:109 - Episode 1148\n",
      "2021-08-25 11:17:47.046 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:47.047 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 11:17:47.048 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 49.19\n",
      "2021-08-25 11:17:47.049 | INFO     | src.policies:train:109 - Episode 1149\n",
      "2021-08-25 11:17:47.067 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:47.069 | INFO     | src.policies:train:121 - Mean episode return: 50.0\n",
      "2021-08-25 11:17:47.069 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 48.89\n",
      "2021-08-25 11:17:47.070 | WARNING  | src.policies:train:131 - The actual batch size is 203, instead of 200\n",
      "2021-08-25 11:17:47.076 | INFO     | src.policies:train:157 - Total loss: 0.995073676109314\n",
      "2021-08-25 11:17:47.078 | INFO     | src.policies:train:103 - Epoch 156 / 800\n",
      "2021-08-25 11:17:47.080 | INFO     | src.policies:train:109 - Episode 1150\n",
      "2021-08-25 11:17:47.091 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:47.092 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 11:17:47.093 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 48.12\n",
      "2021-08-25 11:17:47.094 | INFO     | src.policies:train:109 - Episode 1151\n",
      "2021-08-25 11:17:47.101 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:47.102 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:17:47.103 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 47.38\n",
      "2021-08-25 11:17:47.104 | INFO     | src.policies:train:109 - Episode 1152\n",
      "2021-08-25 11:17:47.141 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:47.142 | INFO     | src.policies:train:121 - Mean episode return: 109.0\n",
      "2021-08-25 11:17:47.143 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 48.0\n",
      "2021-08-25 11:17:47.144 | INFO     | src.policies:train:109 - Episode 1153\n",
      "2021-08-25 11:17:47.155 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:47.156 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:17:47.156 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 48.04\n",
      "2021-08-25 11:17:47.157 | INFO     | src.policies:train:109 - Episode 1154\n",
      "2021-08-25 11:17:47.192 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:47.193 | INFO     | src.policies:train:121 - Mean episode return: 94.0\n",
      "2021-08-25 11:17:47.194 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 48.67\n",
      "2021-08-25 11:17:47.195 | WARNING  | src.policies:train:131 - The actual batch size is 269, instead of 200\n",
      "2021-08-25 11:17:47.200 | INFO     | src.policies:train:157 - Total loss: 0.9962822794914246\n",
      "2021-08-25 11:17:47.202 | INFO     | src.policies:train:103 - Epoch 157 / 800\n",
      "2021-08-25 11:17:47.203 | INFO     | src.policies:train:109 - Episode 1155\n",
      "2021-08-25 11:17:47.213 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:47.214 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 11:17:47.215 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 48.75\n",
      "2021-08-25 11:17:47.216 | INFO     | src.policies:train:109 - Episode 1156\n",
      "2021-08-25 11:17:47.239 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:47.240 | INFO     | src.policies:train:121 - Mean episode return: 59.0\n",
      "2021-08-25 11:17:47.241 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 48.5\n",
      "2021-08-25 11:17:47.242 | INFO     | src.policies:train:109 - Episode 1157\n",
      "2021-08-25 11:17:47.264 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:47.265 | INFO     | src.policies:train:121 - Mean episode return: 60.0\n",
      "2021-08-25 11:17:47.266 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 48.32\n",
      "2021-08-25 11:17:47.267 | INFO     | src.policies:train:109 - Episode 1158\n",
      "2021-08-25 11:17:47.286 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:47.287 | INFO     | src.policies:train:121 - Mean episode return: 50.0\n",
      "2021-08-25 11:17:47.288 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 48.64\n",
      "2021-08-25 11:17:47.289 | INFO     | src.policies:train:109 - Episode 1159\n",
      "2021-08-25 11:17:47.316 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:47.317 | INFO     | src.policies:train:121 - Mean episode return: 72.0\n",
      "2021-08-25 11:17:47.318 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 49.22\n",
      "2021-08-25 11:17:47.319 | WARNING  | src.policies:train:131 - The actual batch size is 266, instead of 200\n",
      "2021-08-25 11:17:47.325 | INFO     | src.policies:train:157 - Total loss: 0.9962403774261475\n",
      "2021-08-25 11:17:47.327 | INFO     | src.policies:train:103 - Epoch 158 / 800\n",
      "2021-08-25 11:17:47.328 | INFO     | src.policies:train:109 - Episode 1160\n",
      "2021-08-25 11:17:47.347 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:47.348 | INFO     | src.policies:train:121 - Mean episode return: 50.0\n",
      "2021-08-25 11:17:47.349 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 49.44\n",
      "2021-08-25 11:17:47.350 | INFO     | src.policies:train:109 - Episode 1161\n",
      "2021-08-25 11:17:47.400 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:47.402 | INFO     | src.policies:train:121 - Mean episode return: 149.0\n",
      "2021-08-25 11:17:47.402 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 50.74\n",
      "2021-08-25 11:17:47.404 | INFO     | src.policies:train:109 - Episode 1162\n",
      "2021-08-25 11:17:47.427 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:47.428 | INFO     | src.policies:train:121 - Mean episode return: 62.0\n",
      "2021-08-25 11:17:47.428 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 51.03\n",
      "2021-08-25 11:17:47.430 | WARNING  | src.policies:train:131 - The actual batch size is 261, instead of 200\n",
      "2021-08-25 11:17:47.435 | INFO     | src.policies:train:157 - Total loss: 0.9961685538291931\n",
      "2021-08-25 11:17:47.438 | INFO     | src.policies:train:103 - Epoch 159 / 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:47.439 | INFO     | src.policies:train:109 - Episode 1163\n",
      "2021-08-25 11:17:47.450 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:47.452 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:17:47.452 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 51.0\n",
      "2021-08-25 11:17:47.454 | INFO     | src.policies:train:109 - Episode 1164\n",
      "2021-08-25 11:17:47.469 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:47.470 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 11:17:47.471 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 51.13\n",
      "2021-08-25 11:17:47.472 | INFO     | src.policies:train:109 - Episode 1165\n",
      "2021-08-25 11:17:47.535 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:47.536 | INFO     | src.policies:train:121 - Mean episode return: 184.0\n",
      "2021-08-25 11:17:47.537 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 52.45\n",
      "2021-08-25 11:17:47.538 | WARNING  | src.policies:train:131 - The actual batch size is 249, instead of 200\n",
      "2021-08-25 11:17:47.543 | INFO     | src.policies:train:157 - Total loss: 0.9959837198257446\n",
      "2021-08-25 11:17:47.546 | INFO     | src.policies:train:103 - Epoch 160 / 800\n",
      "2021-08-25 11:17:47.546 | INFO     | src.policies:train:109 - Episode 1166\n",
      "2021-08-25 11:17:47.571 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:47.573 | INFO     | src.policies:train:121 - Mean episode return: 75.0\n",
      "2021-08-25 11:17:47.574 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 52.94\n",
      "2021-08-25 11:17:47.574 | INFO     | src.policies:train:109 - Episode 1167\n",
      "2021-08-25 11:17:47.591 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:47.593 | INFO     | src.policies:train:121 - Mean episode return: 45.0\n",
      "2021-08-25 11:17:47.594 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 52.09\n",
      "2021-08-25 11:17:47.594 | INFO     | src.policies:train:109 - Episode 1168\n",
      "2021-08-25 11:17:47.607 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:47.608 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 11:17:47.609 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 52.03\n",
      "2021-08-25 11:17:47.610 | INFO     | src.policies:train:109 - Episode 1169\n",
      "2021-08-25 11:17:47.627 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:47.629 | INFO     | src.policies:train:121 - Mean episode return: 46.0\n",
      "2021-08-25 11:17:47.629 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 52.29\n",
      "2021-08-25 11:17:47.630 | INFO     | src.policies:train:109 - Episode 1170\n",
      "2021-08-25 11:17:47.650 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:47.651 | INFO     | src.policies:train:121 - Mean episode return: 48.0\n",
      "2021-08-25 11:17:47.652 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 52.5\n",
      "2021-08-25 11:17:47.653 | WARNING  | src.policies:train:131 - The actual batch size is 241, instead of 200\n",
      "2021-08-25 11:17:47.659 | INFO     | src.policies:train:157 - Total loss: 0.9958503842353821\n",
      "2021-08-25 11:17:47.661 | INFO     | src.policies:train:103 - Epoch 161 / 800\n",
      "2021-08-25 11:17:47.662 | INFO     | src.policies:train:109 - Episode 1171\n",
      "2021-08-25 11:17:47.680 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:47.682 | INFO     | src.policies:train:121 - Mean episode return: 46.0\n",
      "2021-08-25 11:17:47.683 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 52.39\n",
      "2021-08-25 11:17:47.684 | INFO     | src.policies:train:109 - Episode 1172\n",
      "2021-08-25 11:17:47.717 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:47.718 | INFO     | src.policies:train:121 - Mean episode return: 99.0\n",
      "2021-08-25 11:17:47.719 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 52.79\n",
      "2021-08-25 11:17:47.720 | INFO     | src.policies:train:109 - Episode 1173\n",
      "2021-08-25 11:17:47.764 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:47.765 | INFO     | src.policies:train:121 - Mean episode return: 131.0\n",
      "2021-08-25 11:17:47.766 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 53.64\n",
      "2021-08-25 11:17:47.767 | WARNING  | src.policies:train:131 - The actual batch size is 276, instead of 200\n",
      "2021-08-25 11:17:47.773 | INFO     | src.policies:train:157 - Total loss: 0.9963767528533936\n",
      "2021-08-25 11:17:47.776 | INFO     | src.policies:train:103 - Epoch 162 / 800\n",
      "2021-08-25 11:17:47.777 | INFO     | src.policies:train:109 - Episode 1174\n",
      "2021-08-25 11:17:47.792 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:47.794 | INFO     | src.policies:train:121 - Mean episode return: 42.0\n",
      "2021-08-25 11:17:47.794 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 53.11\n",
      "2021-08-25 11:17:47.795 | INFO     | src.policies:train:109 - Episode 1175\n",
      "2021-08-25 11:17:47.823 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:47.824 | INFO     | src.policies:train:121 - Mean episode return: 79.0\n",
      "2021-08-25 11:17:47.825 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 53.43\n",
      "2021-08-25 11:17:47.826 | INFO     | src.policies:train:109 - Episode 1176\n",
      "2021-08-25 11:17:47.851 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:47.852 | INFO     | src.policies:train:121 - Mean episode return: 72.0\n",
      "2021-08-25 11:17:47.853 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 53.76\n",
      "2021-08-25 11:17:47.854 | INFO     | src.policies:train:109 - Episode 1177\n",
      "2021-08-25 11:17:47.864 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:47.864 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:17:47.865 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 53.62\n",
      "2021-08-25 11:17:47.866 | WARNING  | src.policies:train:131 - The actual batch size is 214, instead of 200\n",
      "2021-08-25 11:17:47.872 | INFO     | src.policies:train:157 - Total loss: 0.9953268766403198\n",
      "2021-08-25 11:17:47.874 | INFO     | src.policies:train:103 - Epoch 163 / 800\n",
      "2021-08-25 11:17:47.875 | INFO     | src.policies:train:109 - Episode 1178\n",
      "2021-08-25 11:17:47.886 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:47.887 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 11:17:47.887 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 53.33\n",
      "2021-08-25 11:17:47.888 | INFO     | src.policies:train:109 - Episode 1179\n",
      "2021-08-25 11:17:47.902 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:47.903 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 11:17:47.903 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 53.52\n",
      "2021-08-25 11:17:47.904 | INFO     | src.policies:train:109 - Episode 1180\n",
      "2021-08-25 11:17:47.964 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:47.966 | INFO     | src.policies:train:121 - Mean episode return: 186.0\n",
      "2021-08-25 11:17:47.966 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 55.09\n",
      "2021-08-25 11:17:47.967 | WARNING  | src.policies:train:131 - The actual batch size is 244, instead of 200\n",
      "2021-08-25 11:17:47.972 | INFO     | src.policies:train:157 - Total loss: 0.9959015250205994\n",
      "2021-08-25 11:17:47.975 | INFO     | src.policies:train:103 - Epoch 164 / 800\n",
      "2021-08-25 11:17:47.976 | INFO     | src.policies:train:109 - Episode 1181\n",
      "2021-08-25 11:17:47.998 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:48.000 | INFO     | src.policies:train:121 - Mean episode return: 64.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:48.001 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 55.52\n",
      "2021-08-25 11:17:48.002 | INFO     | src.policies:train:109 - Episode 1182\n",
      "2021-08-25 11:17:48.017 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:48.018 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 11:17:48.019 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 55.73\n",
      "2021-08-25 11:17:48.020 | INFO     | src.policies:train:109 - Episode 1183\n",
      "2021-08-25 11:17:48.034 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:48.035 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 11:17:48.036 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 55.64\n",
      "2021-08-25 11:17:48.037 | INFO     | src.policies:train:109 - Episode 1184\n",
      "2021-08-25 11:17:48.064 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:48.065 | INFO     | src.policies:train:121 - Mean episode return: 73.0\n",
      "2021-08-25 11:17:48.066 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 55.91\n",
      "2021-08-25 11:17:48.067 | WARNING  | src.policies:train:131 - The actual batch size is 206, instead of 200\n",
      "2021-08-25 11:17:48.073 | INFO     | src.policies:train:157 - Total loss: 0.9951455593109131\n",
      "2021-08-25 11:17:48.075 | INFO     | src.policies:train:103 - Epoch 165 / 800\n",
      "2021-08-25 11:17:48.076 | INFO     | src.policies:train:109 - Episode 1185\n",
      "2021-08-25 11:17:48.101 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:48.102 | INFO     | src.policies:train:121 - Mean episode return: 68.0\n",
      "2021-08-25 11:17:48.103 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 55.71\n",
      "2021-08-25 11:17:48.104 | INFO     | src.policies:train:109 - Episode 1186\n",
      "2021-08-25 11:17:48.152 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:48.154 | INFO     | src.policies:train:121 - Mean episode return: 141.0\n",
      "2021-08-25 11:17:48.155 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 56.47\n",
      "2021-08-25 11:17:48.156 | WARNING  | src.policies:train:131 - The actual batch size is 209, instead of 200\n",
      "2021-08-25 11:17:48.161 | INFO     | src.policies:train:157 - Total loss: 0.9952149391174316\n",
      "2021-08-25 11:17:48.163 | INFO     | src.policies:train:103 - Epoch 166 / 800\n",
      "2021-08-25 11:17:48.164 | INFO     | src.policies:train:109 - Episode 1187\n",
      "2021-08-25 11:17:48.197 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:48.198 | INFO     | src.policies:train:121 - Mean episode return: 96.0\n",
      "2021-08-25 11:17:48.199 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 57.3\n",
      "2021-08-25 11:17:48.200 | INFO     | src.policies:train:109 - Episode 1188\n",
      "2021-08-25 11:17:48.214 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:48.215 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 11:17:48.216 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 57.44\n",
      "2021-08-25 11:17:48.217 | INFO     | src.policies:train:109 - Episode 1189\n",
      "2021-08-25 11:17:48.227 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:48.228 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:17:48.229 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 57.29\n",
      "2021-08-25 11:17:48.230 | INFO     | src.policies:train:109 - Episode 1190\n",
      "2021-08-25 11:17:48.292 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:48.293 | INFO     | src.policies:train:121 - Mean episode return: 180.0\n",
      "2021-08-25 11:17:48.294 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 58.73\n",
      "2021-08-25 11:17:48.295 | WARNING  | src.policies:train:131 - The actual batch size is 334, instead of 200\n",
      "2021-08-25 11:17:48.300 | INFO     | src.policies:train:157 - Total loss: 0.9970057606697083\n",
      "2021-08-25 11:17:48.303 | INFO     | src.policies:train:103 - Epoch 167 / 800\n",
      "2021-08-25 11:17:48.304 | INFO     | src.policies:train:109 - Episode 1191\n",
      "2021-08-25 11:17:48.317 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:48.318 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 11:17:48.320 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 58.68\n",
      "2021-08-25 11:17:48.320 | INFO     | src.policies:train:109 - Episode 1192\n",
      "2021-08-25 11:17:48.372 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:48.374 | INFO     | src.policies:train:121 - Mean episode return: 139.0\n",
      "2021-08-25 11:17:48.375 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 59.43\n",
      "2021-08-25 11:17:48.375 | INFO     | src.policies:train:109 - Episode 1193\n",
      "2021-08-25 11:17:48.386 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:48.387 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:17:48.388 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 59.43\n",
      "2021-08-25 11:17:48.389 | INFO     | src.policies:train:109 - Episode 1194\n",
      "2021-08-25 11:17:48.409 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:48.410 | INFO     | src.policies:train:121 - Mean episode return: 48.0\n",
      "2021-08-25 11:17:48.411 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 59.46\n",
      "2021-08-25 11:17:48.412 | WARNING  | src.policies:train:131 - The actual batch size is 237, instead of 200\n",
      "2021-08-25 11:17:48.418 | INFO     | src.policies:train:157 - Total loss: 0.995780348777771\n",
      "2021-08-25 11:17:48.422 | INFO     | src.policies:train:103 - Epoch 168 / 800\n",
      "2021-08-25 11:17:48.423 | INFO     | src.policies:train:109 - Episode 1195\n",
      "2021-08-25 11:17:48.466 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:48.468 | INFO     | src.policies:train:121 - Mean episode return: 125.0\n",
      "2021-08-25 11:17:48.468 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 60.38\n",
      "2021-08-25 11:17:48.469 | INFO     | src.policies:train:109 - Episode 1196\n",
      "2021-08-25 11:17:48.537 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:48.538 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:17:48.539 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 62.16\n",
      "2021-08-25 11:17:48.540 | WARNING  | src.policies:train:131 - The actual batch size is 325, instead of 200\n",
      "2021-08-25 11:17:48.546 | INFO     | src.policies:train:157 - Total loss: 0.9969230890274048\n",
      "2021-08-25 11:17:48.548 | INFO     | src.policies:train:103 - Epoch 169 / 800\n",
      "2021-08-25 11:17:48.549 | INFO     | src.policies:train:109 - Episode 1197\n",
      "2021-08-25 11:17:48.557 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:48.559 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:17:48.560 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 62.04\n",
      "2021-08-25 11:17:48.561 | INFO     | src.policies:train:109 - Episode 1198\n",
      "2021-08-25 11:17:48.601 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:48.602 | INFO     | src.policies:train:121 - Mean episode return: 115.0\n",
      "2021-08-25 11:17:48.603 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 62.49\n",
      "2021-08-25 11:17:48.603 | INFO     | src.policies:train:109 - Episode 1199\n",
      "2021-08-25 11:17:48.641 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:48.642 | INFO     | src.policies:train:121 - Mean episode return: 106.0\n",
      "2021-08-25 11:17:48.643 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 63.22\n",
      "2021-08-25 11:17:48.644 | WARNING  | src.policies:train:131 - The actual batch size is 239, instead of 200\n",
      "2021-08-25 11:17:48.650 | INFO     | src.policies:train:157 - Total loss: 0.995815634727478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:48.652 | INFO     | src.policies:train:103 - Epoch 170 / 800\n",
      "2021-08-25 11:17:48.653 | INFO     | src.policies:train:109 - Episode 1200\n",
      "2021-08-25 11:17:48.660 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:48.662 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:17:48.663 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 63.08\n",
      "2021-08-25 11:17:48.664 | INFO     | src.policies:train:109 - Episode 1201\n",
      "2021-08-25 11:17:48.705 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:48.706 | INFO     | src.policies:train:121 - Mean episode return: 117.0\n",
      "2021-08-25 11:17:48.707 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 63.75\n",
      "2021-08-25 11:17:48.708 | INFO     | src.policies:train:109 - Episode 1202\n",
      "2021-08-25 11:17:48.738 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:48.739 | INFO     | src.policies:train:121 - Mean episode return: 84.0\n",
      "2021-08-25 11:17:48.740 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 63.66\n",
      "2021-08-25 11:17:48.741 | WARNING  | src.policies:train:131 - The actual batch size is 217, instead of 200\n",
      "2021-08-25 11:17:48.746 | INFO     | src.policies:train:157 - Total loss: 0.9953914880752563\n",
      "2021-08-25 11:17:48.749 | INFO     | src.policies:train:103 - Epoch 171 / 800\n",
      "2021-08-25 11:17:48.750 | INFO     | src.policies:train:109 - Episode 1203\n",
      "2021-08-25 11:17:48.772 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:48.774 | INFO     | src.policies:train:121 - Mean episode return: 57.0\n",
      "2021-08-25 11:17:48.775 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 63.64\n",
      "2021-08-25 11:17:48.775 | INFO     | src.policies:train:109 - Episode 1204\n",
      "2021-08-25 11:17:48.809 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:48.810 | INFO     | src.policies:train:121 - Mean episode return: 95.0\n",
      "2021-08-25 11:17:48.811 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 63.66\n",
      "2021-08-25 11:17:48.812 | INFO     | src.policies:train:109 - Episode 1205\n",
      "2021-08-25 11:17:48.856 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:48.857 | INFO     | src.policies:train:121 - Mean episode return: 126.0\n",
      "2021-08-25 11:17:48.857 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 64.64\n",
      "2021-08-25 11:17:48.858 | WARNING  | src.policies:train:131 - The actual batch size is 278, instead of 200\n",
      "2021-08-25 11:17:48.864 | INFO     | src.policies:train:157 - Total loss: 0.9964028596878052\n",
      "2021-08-25 11:17:48.867 | INFO     | src.policies:train:103 - Epoch 172 / 800\n",
      "2021-08-25 11:17:48.867 | INFO     | src.policies:train:109 - Episode 1206\n",
      "2021-08-25 11:17:48.896 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:48.898 | INFO     | src.policies:train:121 - Mean episode return: 86.0\n",
      "2021-08-25 11:17:48.899 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 65.3\n",
      "2021-08-25 11:17:48.900 | INFO     | src.policies:train:109 - Episode 1207\n",
      "2021-08-25 11:17:48.912 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:48.913 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:17:48.914 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 65.11\n",
      "2021-08-25 11:17:48.914 | INFO     | src.policies:train:109 - Episode 1208\n",
      "2021-08-25 11:17:48.937 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:48.938 | INFO     | src.policies:train:121 - Mean episode return: 57.0\n",
      "2021-08-25 11:17:48.939 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 64.23\n",
      "2021-08-25 11:17:48.940 | INFO     | src.policies:train:109 - Episode 1209\n",
      "2021-08-25 11:17:48.962 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:48.963 | INFO     | src.policies:train:121 - Mean episode return: 53.0\n",
      "2021-08-25 11:17:48.964 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 64.53\n",
      "2021-08-25 11:17:48.965 | WARNING  | src.policies:train:131 - The actual batch size is 219, instead of 200\n",
      "2021-08-25 11:17:48.971 | INFO     | src.policies:train:157 - Total loss: 0.9954339861869812\n",
      "2021-08-25 11:17:48.973 | INFO     | src.policies:train:103 - Epoch 173 / 800\n",
      "2021-08-25 11:17:48.974 | INFO     | src.policies:train:109 - Episode 1210\n",
      "2021-08-25 11:17:48.992 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:48.993 | INFO     | src.policies:train:121 - Mean episode return: 44.0\n",
      "2021-08-25 11:17:48.994 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 64.68\n",
      "2021-08-25 11:17:48.995 | INFO     | src.policies:train:109 - Episode 1211\n",
      "2021-08-25 11:17:49.017 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:49.018 | INFO     | src.policies:train:121 - Mean episode return: 56.0\n",
      "2021-08-25 11:17:49.019 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 65.04\n",
      "2021-08-25 11:17:49.020 | INFO     | src.policies:train:109 - Episode 1212\n",
      "2021-08-25 11:17:49.072 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:49.073 | INFO     | src.policies:train:121 - Mean episode return: 152.0\n",
      "2021-08-25 11:17:49.074 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 65.54\n",
      "2021-08-25 11:17:49.075 | WARNING  | src.policies:train:131 - The actual batch size is 252, instead of 200\n",
      "2021-08-25 11:17:49.081 | INFO     | src.policies:train:157 - Total loss: 0.9960314631462097\n",
      "2021-08-25 11:17:49.083 | INFO     | src.policies:train:103 - Epoch 174 / 800\n",
      "2021-08-25 11:17:49.084 | INFO     | src.policies:train:109 - Episode 1213\n",
      "2021-08-25 11:17:49.124 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:49.125 | INFO     | src.policies:train:121 - Mean episode return: 115.0\n",
      "2021-08-25 11:17:49.126 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 66.31\n",
      "2021-08-25 11:17:49.127 | INFO     | src.policies:train:109 - Episode 1214\n",
      "2021-08-25 11:17:49.146 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:49.147 | INFO     | src.policies:train:121 - Mean episode return: 43.0\n",
      "2021-08-25 11:17:49.148 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 66.27\n",
      "2021-08-25 11:17:49.149 | INFO     | src.policies:train:109 - Episode 1215\n",
      "2021-08-25 11:17:49.208 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:49.210 | INFO     | src.policies:train:121 - Mean episode return: 174.0\n",
      "2021-08-25 11:17:49.211 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 66.66\n",
      "2021-08-25 11:17:49.212 | WARNING  | src.policies:train:131 - The actual batch size is 332, instead of 200\n",
      "2021-08-25 11:17:49.217 | INFO     | src.policies:train:157 - Total loss: 0.9969876408576965\n",
      "2021-08-25 11:17:49.220 | INFO     | src.policies:train:103 - Epoch 175 / 800\n",
      "2021-08-25 11:17:49.221 | INFO     | src.policies:train:109 - Episode 1216\n",
      "2021-08-25 11:17:49.248 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:49.249 | INFO     | src.policies:train:121 - Mean episode return: 76.0\n",
      "2021-08-25 11:17:49.251 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 67.16\n",
      "2021-08-25 11:17:49.251 | INFO     | src.policies:train:109 - Episode 1217\n",
      "2021-08-25 11:17:49.317 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:49.318 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:17:49.319 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 68.41\n",
      "2021-08-25 11:17:49.319 | WARNING  | src.policies:train:131 - The actual batch size is 276, instead of 200\n",
      "2021-08-25 11:17:49.325 | INFO     | src.policies:train:157 - Total loss: 0.996376633644104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:49.327 | INFO     | src.policies:train:103 - Epoch 176 / 800\n",
      "2021-08-25 11:17:49.328 | INFO     | src.policies:train:109 - Episode 1218\n",
      "2021-08-25 11:17:49.359 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:49.360 | INFO     | src.policies:train:121 - Mean episode return: 87.0\n",
      "2021-08-25 11:17:49.361 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 69.13\n",
      "2021-08-25 11:17:49.362 | INFO     | src.policies:train:109 - Episode 1219\n",
      "2021-08-25 11:17:49.394 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:49.395 | INFO     | src.policies:train:121 - Mean episode return: 90.0\n",
      "2021-08-25 11:17:49.396 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 69.54\n",
      "2021-08-25 11:17:49.397 | INFO     | src.policies:train:109 - Episode 1220\n",
      "2021-08-25 11:17:49.430 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:49.431 | INFO     | src.policies:train:121 - Mean episode return: 94.0\n",
      "2021-08-25 11:17:49.432 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 70.25\n",
      "2021-08-25 11:17:49.433 | WARNING  | src.policies:train:131 - The actual batch size is 271, instead of 200\n",
      "2021-08-25 11:17:49.439 | INFO     | src.policies:train:157 - Total loss: 0.996309757232666\n",
      "2021-08-25 11:17:49.442 | INFO     | src.policies:train:103 - Epoch 177 / 800\n",
      "2021-08-25 11:17:49.443 | INFO     | src.policies:train:109 - Episode 1221\n",
      "2021-08-25 11:17:49.470 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:49.471 | INFO     | src.policies:train:121 - Mean episode return: 77.0\n",
      "2021-08-25 11:17:49.472 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 70.48\n",
      "2021-08-25 11:17:49.473 | INFO     | src.policies:train:109 - Episode 1222\n",
      "2021-08-25 11:17:49.498 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:49.499 | INFO     | src.policies:train:121 - Mean episode return: 67.0\n",
      "2021-08-25 11:17:49.500 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 70.75\n",
      "2021-08-25 11:17:49.501 | INFO     | src.policies:train:109 - Episode 1223\n",
      "2021-08-25 11:17:49.541 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:49.542 | INFO     | src.policies:train:121 - Mean episode return: 115.0\n",
      "2021-08-25 11:17:49.543 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 70.56\n",
      "2021-08-25 11:17:49.544 | WARNING  | src.policies:train:131 - The actual batch size is 259, instead of 200\n",
      "2021-08-25 11:17:49.550 | INFO     | src.policies:train:157 - Total loss: 0.9961388111114502\n",
      "2021-08-25 11:17:49.553 | INFO     | src.policies:train:103 - Epoch 178 / 800\n",
      "2021-08-25 11:17:49.554 | INFO     | src.policies:train:109 - Episode 1224\n",
      "2021-08-25 11:17:49.590 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:49.592 | INFO     | src.policies:train:121 - Mean episode return: 105.0\n",
      "2021-08-25 11:17:49.593 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 71.31\n",
      "2021-08-25 11:17:49.594 | INFO     | src.policies:train:109 - Episode 1225\n",
      "2021-08-25 11:17:49.654 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:49.655 | INFO     | src.policies:train:121 - Mean episode return: 177.0\n",
      "2021-08-25 11:17:49.656 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 72.93\n",
      "2021-08-25 11:17:49.657 | WARNING  | src.policies:train:131 - The actual batch size is 282, instead of 200\n",
      "2021-08-25 11:17:49.663 | INFO     | src.policies:train:157 - Total loss: 0.9964536428451538\n",
      "2021-08-25 11:17:49.665 | INFO     | src.policies:train:103 - Epoch 179 / 800\n",
      "2021-08-25 11:17:49.666 | INFO     | src.policies:train:109 - Episode 1226\n",
      "2021-08-25 11:17:49.674 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:49.675 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:17:49.676 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 72.8\n",
      "2021-08-25 11:17:49.677 | INFO     | src.policies:train:109 - Episode 1227\n",
      "2021-08-25 11:17:49.698 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:49.699 | INFO     | src.policies:train:121 - Mean episode return: 54.0\n",
      "2021-08-25 11:17:49.700 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 73.09\n",
      "2021-08-25 11:17:49.701 | INFO     | src.policies:train:109 - Episode 1228\n",
      "2021-08-25 11:17:49.748 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:49.750 | INFO     | src.policies:train:121 - Mean episode return: 133.0\n",
      "2021-08-25 11:17:49.750 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 73.21\n",
      "2021-08-25 11:17:49.752 | INFO     | src.policies:train:109 - Episode 1229\n",
      "2021-08-25 11:17:49.779 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:49.780 | INFO     | src.policies:train:121 - Mean episode return: 71.0\n",
      "2021-08-25 11:17:49.781 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 73.74\n",
      "2021-08-25 11:17:49.782 | WARNING  | src.policies:train:131 - The actual batch size is 270, instead of 200\n",
      "2021-08-25 11:17:49.789 | INFO     | src.policies:train:157 - Total loss: 0.9962959289550781\n",
      "2021-08-25 11:17:49.792 | INFO     | src.policies:train:103 - Epoch 180 / 800\n",
      "2021-08-25 11:17:49.793 | INFO     | src.policies:train:109 - Episode 1230\n",
      "2021-08-25 11:17:49.822 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:49.823 | INFO     | src.policies:train:121 - Mean episode return: 80.0\n",
      "2021-08-25 11:17:49.824 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 73.94\n",
      "2021-08-25 11:17:49.825 | INFO     | src.policies:train:109 - Episode 1231\n",
      "2021-08-25 11:17:49.836 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:49.837 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:17:49.838 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 74.0\n",
      "2021-08-25 11:17:49.839 | INFO     | src.policies:train:109 - Episode 1232\n",
      "2021-08-25 11:17:49.857 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:49.858 | INFO     | src.policies:train:121 - Mean episode return: 39.0\n",
      "2021-08-25 11:17:49.859 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 74.24\n",
      "2021-08-25 11:17:49.860 | INFO     | src.policies:train:109 - Episode 1233\n",
      "2021-08-25 11:17:49.873 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:49.874 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:17:49.875 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 74.13\n",
      "2021-08-25 11:17:49.876 | INFO     | src.policies:train:109 - Episode 1234\n",
      "2021-08-25 11:17:49.916 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:49.917 | INFO     | src.policies:train:121 - Mean episode return: 104.0\n",
      "2021-08-25 11:17:49.917 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 74.31\n",
      "2021-08-25 11:17:49.918 | WARNING  | src.policies:train:131 - The actual batch size is 273, instead of 200\n",
      "2021-08-25 11:17:49.925 | INFO     | src.policies:train:157 - Total loss: 0.9963366389274597\n",
      "2021-08-25 11:17:49.928 | INFO     | src.policies:train:103 - Epoch 181 / 800\n",
      "2021-08-25 11:17:49.929 | INFO     | src.policies:train:109 - Episode 1235\n",
      "2021-08-25 11:17:49.974 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:49.975 | INFO     | src.policies:train:121 - Mean episode return: 132.0\n",
      "2021-08-25 11:17:49.976 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 74.54\n",
      "2021-08-25 11:17:49.977 | INFO     | src.policies:train:109 - Episode 1236\n",
      "2021-08-25 11:17:50.046 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:50.047 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:17:50.048 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 76.02\n",
      "2021-08-25 11:17:50.049 | WARNING  | src.policies:train:131 - The actual batch size is 332, instead of 200\n",
      "2021-08-25 11:17:50.055 | INFO     | src.policies:train:157 - Total loss: 0.9969878792762756\n",
      "2021-08-25 11:17:50.057 | INFO     | src.policies:train:103 - Epoch 182 / 800\n",
      "2021-08-25 11:17:50.058 | INFO     | src.policies:train:109 - Episode 1237\n",
      "2021-08-25 11:17:50.080 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:50.082 | INFO     | src.policies:train:121 - Mean episode return: 58.0\n",
      "2021-08-25 11:17:50.083 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 75.51\n",
      "2021-08-25 11:17:50.083 | INFO     | src.policies:train:109 - Episode 1238\n",
      "2021-08-25 11:17:50.101 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:50.103 | INFO     | src.policies:train:121 - Mean episode return: 46.0\n",
      "2021-08-25 11:17:50.103 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 75.7\n",
      "2021-08-25 11:17:50.104 | INFO     | src.policies:train:109 - Episode 1239\n",
      "2021-08-25 11:17:50.114 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:50.115 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:17:50.116 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 75.63\n",
      "2021-08-25 11:17:50.117 | INFO     | src.policies:train:109 - Episode 1240\n",
      "2021-08-25 11:17:50.127 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:50.129 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:17:50.129 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 74.62\n",
      "2021-08-25 11:17:50.130 | INFO     | src.policies:train:109 - Episode 1241\n",
      "2021-08-25 11:17:50.188 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:50.189 | INFO     | src.policies:train:121 - Mean episode return: 173.0\n",
      "2021-08-25 11:17:50.190 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 75.59\n",
      "2021-08-25 11:17:50.192 | WARNING  | src.policies:train:131 - The actual batch size is 316, instead of 200\n",
      "2021-08-25 11:17:50.199 | INFO     | src.policies:train:157 - Total loss: 0.9968352913856506\n",
      "2021-08-25 11:17:50.201 | INFO     | src.policies:train:103 - Epoch 183 / 800\n",
      "2021-08-25 11:17:50.202 | INFO     | src.policies:train:109 - Episode 1242\n",
      "2021-08-25 11:17:50.233 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:50.235 | INFO     | src.policies:train:121 - Mean episode return: 90.0\n",
      "2021-08-25 11:17:50.236 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 75.88\n",
      "2021-08-25 11:17:50.236 | INFO     | src.policies:train:109 - Episode 1243\n",
      "2021-08-25 11:17:50.267 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:50.268 | INFO     | src.policies:train:121 - Mean episode return: 79.0\n",
      "2021-08-25 11:17:50.268 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 76.47\n",
      "2021-08-25 11:17:50.269 | INFO     | src.policies:train:109 - Episode 1244\n",
      "2021-08-25 11:17:50.320 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:50.322 | INFO     | src.policies:train:121 - Mean episode return: 142.0\n",
      "2021-08-25 11:17:50.322 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 77.12\n",
      "2021-08-25 11:17:50.323 | WARNING  | src.policies:train:131 - The actual batch size is 311, instead of 200\n",
      "2021-08-25 11:17:50.329 | INFO     | src.policies:train:157 - Total loss: 0.9967841506004333\n",
      "2021-08-25 11:17:50.332 | INFO     | src.policies:train:103 - Epoch 184 / 800\n",
      "2021-08-25 11:17:50.333 | INFO     | src.policies:train:109 - Episode 1245\n",
      "2021-08-25 11:17:50.385 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:50.387 | INFO     | src.policies:train:121 - Mean episode return: 164.0\n",
      "2021-08-25 11:17:50.388 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 78.25\n",
      "2021-08-25 11:17:50.389 | INFO     | src.policies:train:109 - Episode 1246\n",
      "2021-08-25 11:17:50.429 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:50.430 | INFO     | src.policies:train:121 - Mean episode return: 116.0\n",
      "2021-08-25 11:17:50.431 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 78.42\n",
      "2021-08-25 11:17:50.432 | WARNING  | src.policies:train:131 - The actual batch size is 280, instead of 200\n",
      "2021-08-25 11:17:50.438 | INFO     | src.policies:train:157 - Total loss: 0.9964281916618347\n",
      "2021-08-25 11:17:50.441 | INFO     | src.policies:train:103 - Epoch 185 / 800\n",
      "2021-08-25 11:17:50.442 | INFO     | src.policies:train:109 - Episode 1247\n",
      "2021-08-25 11:17:50.486 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:50.487 | INFO     | src.policies:train:121 - Mean episode return: 130.0\n",
      "2021-08-25 11:17:50.488 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 79.45\n",
      "2021-08-25 11:17:50.489 | INFO     | src.policies:train:109 - Episode 1248\n",
      "2021-08-25 11:17:50.550 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:50.551 | INFO     | src.policies:train:121 - Mean episode return: 176.0\n",
      "2021-08-25 11:17:50.553 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 80.94\n",
      "2021-08-25 11:17:50.553 | WARNING  | src.policies:train:131 - The actual batch size is 306, instead of 200\n",
      "2021-08-25 11:17:50.559 | INFO     | src.policies:train:157 - Total loss: 0.9967320561408997\n",
      "2021-08-25 11:17:50.562 | INFO     | src.policies:train:103 - Epoch 186 / 800\n",
      "2021-08-25 11:17:50.563 | INFO     | src.policies:train:109 - Episode 1249\n",
      "2021-08-25 11:17:50.603 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:50.604 | INFO     | src.policies:train:121 - Mean episode return: 115.0\n",
      "2021-08-25 11:17:50.605 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 81.59\n",
      "2021-08-25 11:17:50.606 | INFO     | src.policies:train:109 - Episode 1250\n",
      "2021-08-25 11:17:50.667 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:50.668 | INFO     | src.policies:train:121 - Mean episode return: 176.0\n",
      "2021-08-25 11:17:50.669 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 83.05\n",
      "2021-08-25 11:17:50.670 | WARNING  | src.policies:train:131 - The actual batch size is 291, instead of 200\n",
      "2021-08-25 11:17:50.677 | INFO     | src.policies:train:157 - Total loss: 0.9965632557868958\n",
      "2021-08-25 11:17:50.679 | INFO     | src.policies:train:103 - Epoch 187 / 800\n",
      "2021-08-25 11:17:50.680 | INFO     | src.policies:train:109 - Episode 1251\n",
      "2021-08-25 11:17:50.730 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:50.732 | INFO     | src.policies:train:121 - Mean episode return: 150.0\n",
      "2021-08-25 11:17:50.733 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 84.43\n",
      "2021-08-25 11:17:50.734 | INFO     | src.policies:train:109 - Episode 1252\n",
      "2021-08-25 11:17:50.791 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:50.793 | INFO     | src.policies:train:121 - Mean episode return: 165.0\n",
      "2021-08-25 11:17:50.794 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 84.99\n",
      "2021-08-25 11:17:50.795 | WARNING  | src.policies:train:131 - The actual batch size is 315, instead of 200\n",
      "2021-08-25 11:17:50.800 | INFO     | src.policies:train:157 - Total loss: 0.9968252182006836\n",
      "2021-08-25 11:17:50.802 | INFO     | src.policies:train:103 - Epoch 188 / 800\n",
      "2021-08-25 11:17:50.803 | INFO     | src.policies:train:109 - Episode 1253\n",
      "2021-08-25 11:17:50.867 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:50.868 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:50.869 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 86.75\n",
      "2021-08-25 11:17:50.874 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:17:50.877 | INFO     | src.policies:train:103 - Epoch 189 / 800\n",
      "2021-08-25 11:17:50.877 | INFO     | src.policies:train:109 - Episode 1254\n",
      "2021-08-25 11:17:50.933 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:50.935 | INFO     | src.policies:train:121 - Mean episode return: 176.0\n",
      "2021-08-25 11:17:50.936 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 87.57\n",
      "2021-08-25 11:17:50.936 | INFO     | src.policies:train:109 - Episode 1255\n",
      "2021-08-25 11:17:50.988 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:50.989 | INFO     | src.policies:train:121 - Mean episode return: 162.0\n",
      "2021-08-25 11:17:50.990 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 88.94\n",
      "2021-08-25 11:17:50.991 | WARNING  | src.policies:train:131 - The actual batch size is 338, instead of 200\n",
      "2021-08-25 11:17:50.997 | INFO     | src.policies:train:157 - Total loss: 0.9970410466194153\n",
      "2021-08-25 11:17:51.000 | INFO     | src.policies:train:103 - Epoch 190 / 800\n",
      "2021-08-25 11:17:51.001 | INFO     | src.policies:train:109 - Episode 1256\n",
      "2021-08-25 11:17:51.065 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:51.066 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:17:51.067 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 90.35\n",
      "2021-08-25 11:17:51.072 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:17:51.074 | INFO     | src.policies:train:103 - Epoch 191 / 800\n",
      "2021-08-25 11:17:51.075 | INFO     | src.policies:train:109 - Episode 1257\n",
      "2021-08-25 11:17:51.113 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:51.115 | INFO     | src.policies:train:121 - Mean episode return: 114.0\n",
      "2021-08-25 11:17:51.116 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 90.89\n",
      "2021-08-25 11:17:51.117 | INFO     | src.policies:train:109 - Episode 1258\n",
      "2021-08-25 11:17:51.169 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:51.171 | INFO     | src.policies:train:121 - Mean episode return: 143.0\n",
      "2021-08-25 11:17:51.172 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 91.82\n",
      "2021-08-25 11:17:51.173 | WARNING  | src.policies:train:131 - The actual batch size is 257, instead of 200\n",
      "2021-08-25 11:17:51.180 | INFO     | src.policies:train:157 - Total loss: 0.996108889579773\n",
      "2021-08-25 11:17:51.183 | INFO     | src.policies:train:103 - Epoch 192 / 800\n",
      "2021-08-25 11:17:51.184 | INFO     | src.policies:train:109 - Episode 1259\n",
      "2021-08-25 11:17:51.253 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:51.254 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:17:51.255 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 93.1\n",
      "2021-08-25 11:17:51.261 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:17:51.263 | INFO     | src.policies:train:103 - Epoch 193 / 800\n",
      "2021-08-25 11:17:51.264 | INFO     | src.policies:train:109 - Episode 1260\n",
      "2021-08-25 11:17:51.329 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:51.330 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:17:51.331 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 94.6\n",
      "2021-08-25 11:17:51.337 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:17:51.339 | INFO     | src.policies:train:103 - Epoch 194 / 800\n",
      "2021-08-25 11:17:51.340 | INFO     | src.policies:train:109 - Episode 1261\n",
      "2021-08-25 11:17:51.401 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:51.403 | INFO     | src.policies:train:121 - Mean episode return: 193.0\n",
      "2021-08-25 11:17:51.404 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 95.04\n",
      "2021-08-25 11:17:51.404 | INFO     | src.policies:train:109 - Episode 1262\n",
      "2021-08-25 11:17:51.470 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:51.471 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:17:51.472 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 96.42\n",
      "2021-08-25 11:17:51.473 | WARNING  | src.policies:train:131 - The actual batch size is 393, instead of 200\n",
      "2021-08-25 11:17:51.478 | INFO     | src.policies:train:157 - Total loss: 0.9974552392959595\n",
      "2021-08-25 11:17:51.481 | INFO     | src.policies:train:103 - Epoch 195 / 800\n",
      "2021-08-25 11:17:51.482 | INFO     | src.policies:train:109 - Episode 1263\n",
      "2021-08-25 11:17:51.537 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:51.539 | INFO     | src.policies:train:121 - Mean episode return: 173.0\n",
      "2021-08-25 11:17:51.540 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 97.86\n",
      "2021-08-25 11:17:51.540 | INFO     | src.policies:train:109 - Episode 1264\n",
      "2021-08-25 11:17:51.587 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:51.588 | INFO     | src.policies:train:121 - Mean episode return: 142.0\n",
      "2021-08-25 11:17:51.588 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 98.92\n",
      "2021-08-25 11:17:51.589 | WARNING  | src.policies:train:131 - The actual batch size is 315, instead of 200\n",
      "2021-08-25 11:17:51.595 | INFO     | src.policies:train:157 - Total loss: 0.9968252182006836\n",
      "2021-08-25 11:17:51.598 | INFO     | src.policies:train:103 - Epoch 196 / 800\n",
      "2021-08-25 11:17:51.599 | INFO     | src.policies:train:109 - Episode 1265\n",
      "2021-08-25 11:17:51.642 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:51.644 | INFO     | src.policies:train:121 - Mean episode return: 122.0\n",
      "2021-08-25 11:17:51.645 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 98.3\n",
      "2021-08-25 11:17:51.645 | INFO     | src.policies:train:109 - Episode 1266\n",
      "2021-08-25 11:17:51.713 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:51.714 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:17:51.715 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 99.55\n",
      "2021-08-25 11:17:51.715 | WARNING  | src.policies:train:131 - The actual batch size is 322, instead of 200\n",
      "2021-08-25 11:17:51.721 | INFO     | src.policies:train:157 - Total loss: 0.9968942403793335\n",
      "2021-08-25 11:17:51.723 | INFO     | src.policies:train:103 - Epoch 197 / 800\n",
      "2021-08-25 11:17:51.724 | INFO     | src.policies:train:109 - Episode 1267\n",
      "2021-08-25 11:17:51.789 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:51.791 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:17:51.792 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 101.1\n",
      "2021-08-25 11:17:51.796 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:17:51.799 | INFO     | src.policies:train:103 - Epoch 198 / 800\n",
      "2021-08-25 11:17:51.800 | INFO     | src.policies:train:109 - Episode 1268\n",
      "2021-08-25 11:17:51.864 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:51.865 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:17:51.866 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 102.83\n",
      "2021-08-25 11:17:51.871 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:17:51.874 | INFO     | src.policies:train:103 - Epoch 199 / 800\n",
      "2021-08-25 11:17:51.875 | INFO     | src.policies:train:109 - Episode 1269\n",
      "2021-08-25 11:17:51.936 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:51.937 | INFO     | src.policies:train:121 - Mean episode return: 189.0\n",
      "2021-08-25 11:17:51.938 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 104.26\n",
      "2021-08-25 11:17:51.939 | INFO     | src.policies:train:109 - Episode 1270\n",
      "2021-08-25 11:17:51.957 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:51.958 | INFO     | src.policies:train:121 - Mean episode return: 47.0\n",
      "2021-08-25 11:17:51.958 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 104.25\n",
      "2021-08-25 11:17:51.959 | WARNING  | src.policies:train:131 - The actual batch size is 236, instead of 200\n",
      "2021-08-25 11:17:51.965 | INFO     | src.policies:train:157 - Total loss: 0.9957625269889832\n",
      "2021-08-25 11:17:51.968 | INFO     | src.policies:train:103 - Epoch 200 / 800\n",
      "2021-08-25 11:17:51.969 | INFO     | src.policies:train:109 - Episode 1271\n",
      "2021-08-25 11:17:52.023 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:52.024 | INFO     | src.policies:train:121 - Mean episode return: 159.0\n",
      "2021-08-25 11:17:52.025 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 105.38\n",
      "2021-08-25 11:17:52.026 | INFO     | src.policies:train:109 - Episode 1272\n",
      "2021-08-25 11:17:52.045 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:52.046 | INFO     | src.policies:train:121 - Mean episode return: 48.0\n",
      "2021-08-25 11:17:52.047 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 104.87\n",
      "2021-08-25 11:17:52.048 | WARNING  | src.policies:train:131 - The actual batch size is 207, instead of 200\n",
      "2021-08-25 11:17:52.054 | INFO     | src.policies:train:157 - Total loss: 0.9951689839363098\n",
      "2021-08-25 11:17:52.056 | INFO     | src.policies:train:103 - Epoch 201 / 800\n",
      "2021-08-25 11:17:52.058 | INFO     | src.policies:train:109 - Episode 1273\n",
      "2021-08-25 11:17:52.120 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:52.121 | INFO     | src.policies:train:121 - Mean episode return: 189.0\n",
      "2021-08-25 11:17:52.122 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 105.45\n",
      "2021-08-25 11:17:52.123 | INFO     | src.policies:train:109 - Episode 1274\n",
      "2021-08-25 11:17:52.178 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:52.179 | INFO     | src.policies:train:121 - Mean episode return: 163.0\n",
      "2021-08-25 11:17:52.180 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 106.66\n",
      "2021-08-25 11:17:52.181 | WARNING  | src.policies:train:131 - The actual batch size is 352, instead of 200\n",
      "2021-08-25 11:17:52.186 | INFO     | src.policies:train:157 - Total loss: 0.9971590638160706\n",
      "2021-08-25 11:17:52.189 | INFO     | src.policies:train:103 - Epoch 202 / 800\n",
      "2021-08-25 11:17:52.190 | INFO     | src.policies:train:109 - Episode 1275\n",
      "2021-08-25 11:17:52.255 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:52.257 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:17:52.258 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 107.87\n",
      "2021-08-25 11:17:52.265 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:17:52.268 | INFO     | src.policies:train:103 - Epoch 203 / 800\n",
      "2021-08-25 11:17:52.268 | INFO     | src.policies:train:109 - Episode 1276\n",
      "2021-08-25 11:17:52.330 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:52.332 | INFO     | src.policies:train:121 - Mean episode return: 191.0\n",
      "2021-08-25 11:17:52.333 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 109.06\n",
      "2021-08-25 11:17:52.333 | INFO     | src.policies:train:109 - Episode 1277\n",
      "2021-08-25 11:17:52.378 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:52.379 | INFO     | src.policies:train:121 - Mean episode return: 132.0\n",
      "2021-08-25 11:17:52.380 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 110.17\n",
      "2021-08-25 11:17:52.381 | WARNING  | src.policies:train:131 - The actual batch size is 323, instead of 200\n",
      "2021-08-25 11:17:52.386 | INFO     | src.policies:train:157 - Total loss: 0.9969040155410767\n",
      "2021-08-25 11:17:52.389 | INFO     | src.policies:train:103 - Epoch 204 / 800\n",
      "2021-08-25 11:17:52.391 | INFO     | src.policies:train:109 - Episode 1278\n",
      "2021-08-25 11:17:52.457 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:52.458 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:17:52.459 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 111.9\n",
      "2021-08-25 11:17:52.463 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:17:52.466 | INFO     | src.policies:train:103 - Epoch 205 / 800\n",
      "2021-08-25 11:17:52.466 | INFO     | src.policies:train:109 - Episode 1279\n",
      "2021-08-25 11:17:52.508 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:52.509 | INFO     | src.policies:train:121 - Mean episode return: 128.0\n",
      "2021-08-25 11:17:52.510 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 112.87\n",
      "2021-08-25 11:17:52.511 | INFO     | src.policies:train:109 - Episode 1280\n",
      "2021-08-25 11:17:52.561 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:52.562 | INFO     | src.policies:train:121 - Mean episode return: 146.0\n",
      "2021-08-25 11:17:52.563 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 112.47\n",
      "2021-08-25 11:17:52.564 | WARNING  | src.policies:train:131 - The actual batch size is 274, instead of 200\n",
      "2021-08-25 11:17:52.569 | INFO     | src.policies:train:157 - Total loss: 0.9963502883911133\n",
      "2021-08-25 11:17:52.572 | INFO     | src.policies:train:103 - Epoch 206 / 800\n",
      "2021-08-25 11:17:52.573 | INFO     | src.policies:train:109 - Episode 1281\n",
      "2021-08-25 11:17:52.595 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:52.596 | INFO     | src.policies:train:121 - Mean episode return: 59.0\n",
      "2021-08-25 11:17:52.597 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 112.42\n",
      "2021-08-25 11:17:52.597 | INFO     | src.policies:train:109 - Episode 1282\n",
      "2021-08-25 11:17:52.618 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:52.619 | INFO     | src.policies:train:121 - Mean episode return: 54.0\n",
      "2021-08-25 11:17:52.620 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 112.59\n",
      "2021-08-25 11:17:52.621 | INFO     | src.policies:train:109 - Episode 1283\n",
      "2021-08-25 11:17:52.649 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:52.650 | INFO     | src.policies:train:121 - Mean episode return: 80.0\n",
      "2021-08-25 11:17:52.651 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 113.07\n",
      "2021-08-25 11:17:52.652 | INFO     | src.policies:train:109 - Episode 1284\n",
      "2021-08-25 11:17:52.703 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:52.704 | INFO     | src.policies:train:121 - Mean episode return: 151.0\n",
      "2021-08-25 11:17:52.705 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 113.85\n",
      "2021-08-25 11:17:52.706 | WARNING  | src.policies:train:131 - The actual batch size is 344, instead of 200\n",
      "2021-08-25 11:17:52.712 | INFO     | src.policies:train:157 - Total loss: 0.9970928430557251\n",
      "2021-08-25 11:17:52.715 | INFO     | src.policies:train:103 - Epoch 207 / 800\n",
      "2021-08-25 11:17:52.716 | INFO     | src.policies:train:109 - Episode 1285\n",
      "2021-08-25 11:17:52.738 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:52.739 | INFO     | src.policies:train:121 - Mean episode return: 61.0\n",
      "2021-08-25 11:17:52.740 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 113.78\n",
      "2021-08-25 11:17:52.741 | INFO     | src.policies:train:109 - Episode 1286\n",
      "2021-08-25 11:17:52.808 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:52.809 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:17:52.810 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 114.37\n",
      "2021-08-25 11:17:52.811 | WARNING  | src.policies:train:131 - The actual batch size is 261, instead of 200\n",
      "2021-08-25 11:17:52.816 | INFO     | src.policies:train:157 - Total loss: 0.9961684346199036\n",
      "2021-08-25 11:17:52.818 | INFO     | src.policies:train:103 - Epoch 208 / 800\n",
      "2021-08-25 11:17:52.819 | INFO     | src.policies:train:109 - Episode 1287\n",
      "2021-08-25 11:17:52.882 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:52.884 | INFO     | src.policies:train:121 - Mean episode return: 189.0\n",
      "2021-08-25 11:17:52.885 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 115.3\n",
      "2021-08-25 11:17:52.886 | INFO     | src.policies:train:109 - Episode 1288\n",
      "2021-08-25 11:17:52.946 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:52.947 | INFO     | src.policies:train:121 - Mean episode return: 182.0\n",
      "2021-08-25 11:17:52.947 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 116.77\n",
      "2021-08-25 11:17:52.948 | WARNING  | src.policies:train:131 - The actual batch size is 371, instead of 200\n",
      "2021-08-25 11:17:52.955 | INFO     | src.policies:train:157 - Total loss: 0.9973044991493225\n",
      "2021-08-25 11:17:52.958 | INFO     | src.policies:train:103 - Epoch 209 / 800\n",
      "2021-08-25 11:17:52.959 | INFO     | src.policies:train:109 - Episode 1289\n",
      "2021-08-25 11:17:53.006 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:53.008 | INFO     | src.policies:train:121 - Mean episode return: 139.0\n",
      "2021-08-25 11:17:53.009 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 117.93\n",
      "2021-08-25 11:17:53.010 | INFO     | src.policies:train:109 - Episode 1290\n",
      "2021-08-25 11:17:53.060 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:53.061 | INFO     | src.policies:train:121 - Mean episode return: 146.0\n",
      "2021-08-25 11:17:53.062 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 117.59\n",
      "2021-08-25 11:17:53.063 | WARNING  | src.policies:train:131 - The actual batch size is 285, instead of 200\n",
      "2021-08-25 11:17:53.068 | INFO     | src.policies:train:157 - Total loss: 0.9964910745620728\n",
      "2021-08-25 11:17:53.070 | INFO     | src.policies:train:103 - Epoch 210 / 800\n",
      "2021-08-25 11:17:53.071 | INFO     | src.policies:train:109 - Episode 1291\n",
      "2021-08-25 11:17:53.136 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:53.137 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:17:53.138 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 119.28\n",
      "2021-08-25 11:17:53.143 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:17:53.145 | INFO     | src.policies:train:103 - Epoch 211 / 800\n",
      "2021-08-25 11:17:53.146 | INFO     | src.policies:train:109 - Episode 1292\n",
      "2021-08-25 11:17:53.209 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:53.211 | INFO     | src.policies:train:121 - Mean episode return: 191.0\n",
      "2021-08-25 11:17:53.212 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 119.8\n",
      "2021-08-25 11:17:53.213 | INFO     | src.policies:train:109 - Episode 1293\n",
      "2021-08-25 11:17:53.277 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:53.278 | INFO     | src.policies:train:121 - Mean episode return: 197.0\n",
      "2021-08-25 11:17:53.279 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 121.58\n",
      "2021-08-25 11:17:53.280 | WARNING  | src.policies:train:131 - The actual batch size is 388, instead of 200\n",
      "2021-08-25 11:17:53.286 | INFO     | src.policies:train:157 - Total loss: 0.9974225759506226\n",
      "2021-08-25 11:17:53.289 | INFO     | src.policies:train:103 - Epoch 212 / 800\n",
      "2021-08-25 11:17:53.290 | INFO     | src.policies:train:109 - Episode 1294\n",
      "2021-08-25 11:17:53.357 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:53.358 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:17:53.359 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 123.1\n",
      "2021-08-25 11:17:53.363 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:17:53.366 | INFO     | src.policies:train:103 - Epoch 213 / 800\n",
      "2021-08-25 11:17:53.367 | INFO     | src.policies:train:109 - Episode 1295\n",
      "2021-08-25 11:17:53.419 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:53.421 | INFO     | src.policies:train:121 - Mean episode return: 166.0\n",
      "2021-08-25 11:17:53.421 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 123.51\n",
      "2021-08-25 11:17:53.422 | INFO     | src.policies:train:109 - Episode 1296\n",
      "2021-08-25 11:17:53.475 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:53.476 | INFO     | src.policies:train:121 - Mean episode return: 155.0\n",
      "2021-08-25 11:17:53.477 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 123.06\n",
      "2021-08-25 11:17:53.478 | WARNING  | src.policies:train:131 - The actual batch size is 321, instead of 200\n",
      "2021-08-25 11:17:53.484 | INFO     | src.policies:train:157 - Total loss: 0.9968844652175903\n",
      "2021-08-25 11:17:53.486 | INFO     | src.policies:train:103 - Epoch 214 / 800\n",
      "2021-08-25 11:17:53.487 | INFO     | src.policies:train:109 - Episode 1297\n",
      "2021-08-25 11:17:53.545 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:53.546 | INFO     | src.policies:train:121 - Mean episode return: 172.0\n",
      "2021-08-25 11:17:53.547 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 124.6\n",
      "2021-08-25 11:17:53.548 | INFO     | src.policies:train:109 - Episode 1298\n",
      "2021-08-25 11:17:53.617 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:53.618 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:17:53.619 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 125.45\n",
      "2021-08-25 11:17:53.620 | WARNING  | src.policies:train:131 - The actual batch size is 372, instead of 200\n",
      "2021-08-25 11:17:53.628 | INFO     | src.policies:train:157 - Total loss: 0.9973117113113403\n",
      "2021-08-25 11:17:53.632 | INFO     | src.policies:train:103 - Epoch 215 / 800\n",
      "2021-08-25 11:17:53.633 | INFO     | src.policies:train:109 - Episode 1299\n",
      "2021-08-25 11:17:53.670 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:53.672 | INFO     | src.policies:train:121 - Mean episode return: 109.0\n",
      "2021-08-25 11:17:53.673 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 125.48\n",
      "2021-08-25 11:17:53.674 | INFO     | src.policies:train:109 - Episode 1300\n",
      "2021-08-25 11:17:53.741 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:53.743 | INFO     | src.policies:train:121 - Mean episode return: 191.0\n",
      "2021-08-25 11:17:53.743 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 127.23\n",
      "2021-08-25 11:17:53.745 | WARNING  | src.policies:train:131 - The actual batch size is 300, instead of 200\n",
      "2021-08-25 11:17:53.752 | INFO     | src.policies:train:157 - Total loss: 0.9966666102409363\n",
      "2021-08-25 11:17:53.755 | INFO     | src.policies:train:103 - Epoch 216 / 800\n",
      "2021-08-25 11:17:53.756 | INFO     | src.policies:train:109 - Episode 1301\n",
      "2021-08-25 11:17:53.823 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:53.824 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:17:53.826 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 128.06\n",
      "2021-08-25 11:17:53.831 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:17:53.834 | INFO     | src.policies:train:103 - Epoch 217 / 800\n",
      "2021-08-25 11:17:53.835 | INFO     | src.policies:train:109 - Episode 1302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:53.879 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:53.881 | INFO     | src.policies:train:121 - Mean episode return: 126.0\n",
      "2021-08-25 11:17:53.882 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 128.48\n",
      "2021-08-25 11:17:53.882 | INFO     | src.policies:train:109 - Episode 1303\n",
      "2021-08-25 11:17:53.944 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:53.945 | INFO     | src.policies:train:121 - Mean episode return: 186.0\n",
      "2021-08-25 11:17:53.946 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 129.77\n",
      "2021-08-25 11:17:53.947 | WARNING  | src.policies:train:131 - The actual batch size is 312, instead of 200\n",
      "2021-08-25 11:17:53.954 | INFO     | src.policies:train:157 - Total loss: 0.9967948198318481\n",
      "2021-08-25 11:17:53.958 | INFO     | src.policies:train:103 - Epoch 218 / 800\n",
      "2021-08-25 11:17:53.959 | INFO     | src.policies:train:109 - Episode 1304\n",
      "2021-08-25 11:17:54.025 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:54.027 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:17:54.027 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 130.82\n",
      "2021-08-25 11:17:54.032 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:17:54.034 | INFO     | src.policies:train:103 - Epoch 219 / 800\n",
      "2021-08-25 11:17:54.035 | INFO     | src.policies:train:109 - Episode 1305\n",
      "2021-08-25 11:17:54.080 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:54.082 | INFO     | src.policies:train:121 - Mean episode return: 134.0\n",
      "2021-08-25 11:17:54.083 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 130.9\n",
      "2021-08-25 11:17:54.084 | INFO     | src.policies:train:109 - Episode 1306\n",
      "2021-08-25 11:17:54.155 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:54.156 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:17:54.157 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 132.04\n",
      "2021-08-25 11:17:54.158 | WARNING  | src.policies:train:131 - The actual batch size is 334, instead of 200\n",
      "2021-08-25 11:17:54.165 | INFO     | src.policies:train:157 - Total loss: 0.997005820274353\n",
      "2021-08-25 11:17:54.168 | INFO     | src.policies:train:103 - Epoch 220 / 800\n",
      "2021-08-25 11:17:54.169 | INFO     | src.policies:train:109 - Episode 1307\n",
      "2021-08-25 11:17:54.217 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:54.219 | INFO     | src.policies:train:121 - Mean episode return: 130.0\n",
      "2021-08-25 11:17:54.220 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 133.11\n",
      "2021-08-25 11:17:54.221 | INFO     | src.policies:train:109 - Episode 1308\n",
      "2021-08-25 11:17:54.282 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:54.284 | INFO     | src.policies:train:121 - Mean episode return: 155.0\n",
      "2021-08-25 11:17:54.284 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 134.09\n",
      "2021-08-25 11:17:54.286 | WARNING  | src.policies:train:131 - The actual batch size is 285, instead of 200\n",
      "2021-08-25 11:17:54.293 | INFO     | src.policies:train:157 - Total loss: 0.9964911937713623\n",
      "2021-08-25 11:17:54.296 | INFO     | src.policies:train:103 - Epoch 221 / 800\n",
      "2021-08-25 11:17:54.297 | INFO     | src.policies:train:109 - Episode 1309\n",
      "2021-08-25 11:17:54.366 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:54.368 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:17:54.369 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 135.56\n",
      "2021-08-25 11:17:54.374 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:17:54.378 | INFO     | src.policies:train:103 - Epoch 222 / 800\n",
      "2021-08-25 11:17:54.379 | INFO     | src.policies:train:109 - Episode 1310\n",
      "2021-08-25 11:17:54.448 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:54.449 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:17:54.451 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 137.12\n",
      "2021-08-25 11:17:54.457 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:17:54.460 | INFO     | src.policies:train:103 - Epoch 223 / 800\n",
      "2021-08-25 11:17:54.460 | INFO     | src.policies:train:109 - Episode 1311\n",
      "2021-08-25 11:17:54.508 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:54.510 | INFO     | src.policies:train:121 - Mean episode return: 129.0\n",
      "2021-08-25 11:17:54.511 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 137.85\n",
      "2021-08-25 11:17:54.512 | INFO     | src.policies:train:109 - Episode 1312\n",
      "2021-08-25 11:17:54.581 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:54.582 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:17:54.583 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 138.33\n",
      "2021-08-25 11:17:54.584 | WARNING  | src.policies:train:131 - The actual batch size is 329, instead of 200\n",
      "2021-08-25 11:17:54.591 | INFO     | src.policies:train:157 - Total loss: 0.9969603419303894\n",
      "2021-08-25 11:17:54.595 | INFO     | src.policies:train:103 - Epoch 224 / 800\n",
      "2021-08-25 11:17:54.596 | INFO     | src.policies:train:109 - Episode 1313\n",
      "2021-08-25 11:17:54.665 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:54.667 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:17:54.668 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 139.18\n",
      "2021-08-25 11:17:54.674 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:17:54.677 | INFO     | src.policies:train:103 - Epoch 225 / 800\n",
      "2021-08-25 11:17:54.678 | INFO     | src.policies:train:109 - Episode 1314\n",
      "2021-08-25 11:17:54.749 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:54.751 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:17:54.752 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 140.75\n",
      "2021-08-25 11:17:54.756 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:17:54.759 | INFO     | src.policies:train:103 - Epoch 226 / 800\n",
      "2021-08-25 11:17:54.760 | INFO     | src.policies:train:109 - Episode 1315\n",
      "2021-08-25 11:17:54.817 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:54.818 | INFO     | src.policies:train:121 - Mean episode return: 161.0\n",
      "2021-08-25 11:17:54.819 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 140.62\n",
      "2021-08-25 11:17:54.820 | INFO     | src.policies:train:109 - Episode 1316\n",
      "2021-08-25 11:17:54.883 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:54.884 | INFO     | src.policies:train:121 - Mean episode return: 170.0\n",
      "2021-08-25 11:17:54.885 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 141.56\n",
      "2021-08-25 11:17:54.886 | WARNING  | src.policies:train:131 - The actual batch size is 331, instead of 200\n",
      "2021-08-25 11:17:54.894 | INFO     | src.policies:train:157 - Total loss: 0.9969788789749146\n",
      "2021-08-25 11:17:54.897 | INFO     | src.policies:train:103 - Epoch 227 / 800\n",
      "2021-08-25 11:17:54.898 | INFO     | src.policies:train:109 - Episode 1317\n",
      "2021-08-25 11:17:54.941 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:54.942 | INFO     | src.policies:train:121 - Mean episode return: 120.0\n",
      "2021-08-25 11:17:54.943 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 140.76\n",
      "2021-08-25 11:17:54.944 | INFO     | src.policies:train:109 - Episode 1318\n",
      "2021-08-25 11:17:54.999 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:55.000 | INFO     | src.policies:train:121 - Mean episode return: 148.0\n",
      "2021-08-25 11:17:55.001 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 141.37\n",
      "2021-08-25 11:17:55.002 | WARNING  | src.policies:train:131 - The actual batch size is 268, instead of 200\n",
      "2021-08-25 11:17:55.008 | INFO     | src.policies:train:157 - Total loss: 0.9962685108184814\n",
      "2021-08-25 11:17:55.010 | INFO     | src.policies:train:103 - Epoch 228 / 800\n",
      "2021-08-25 11:17:55.011 | INFO     | src.policies:train:109 - Episode 1319\n",
      "2021-08-25 11:17:55.042 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:55.044 | INFO     | src.policies:train:121 - Mean episode return: 78.0\n",
      "2021-08-25 11:17:55.045 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 141.25\n",
      "2021-08-25 11:17:55.045 | INFO     | src.policies:train:109 - Episode 1320\n",
      "2021-08-25 11:17:55.085 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:55.086 | INFO     | src.policies:train:121 - Mean episode return: 110.0\n",
      "2021-08-25 11:17:55.087 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 141.41\n",
      "2021-08-25 11:17:55.088 | INFO     | src.policies:train:109 - Episode 1321\n",
      "2021-08-25 11:17:55.159 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:55.160 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:17:55.161 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 142.64\n",
      "2021-08-25 11:17:55.162 | WARNING  | src.policies:train:131 - The actual batch size is 388, instead of 200\n",
      "2021-08-25 11:17:55.168 | INFO     | src.policies:train:157 - Total loss: 0.9974225759506226\n",
      "2021-08-25 11:17:55.170 | INFO     | src.policies:train:103 - Epoch 229 / 800\n",
      "2021-08-25 11:17:55.171 | INFO     | src.policies:train:109 - Episode 1322\n",
      "2021-08-25 11:17:55.204 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:55.206 | INFO     | src.policies:train:121 - Mean episode return: 95.0\n",
      "2021-08-25 11:17:55.207 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 142.92\n",
      "2021-08-25 11:17:55.207 | INFO     | src.policies:train:109 - Episode 1323\n",
      "2021-08-25 11:17:55.278 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:55.279 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:17:55.279 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 143.77\n",
      "2021-08-25 11:17:55.280 | WARNING  | src.policies:train:131 - The actual batch size is 295, instead of 200\n",
      "2021-08-25 11:17:55.286 | INFO     | src.policies:train:157 - Total loss: 0.9966099262237549\n",
      "2021-08-25 11:17:55.289 | INFO     | src.policies:train:103 - Epoch 230 / 800\n",
      "2021-08-25 11:17:55.290 | INFO     | src.policies:train:109 - Episode 1324\n",
      "2021-08-25 11:17:55.334 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:55.335 | INFO     | src.policies:train:121 - Mean episode return: 122.0\n",
      "2021-08-25 11:17:55.337 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 143.94\n",
      "2021-08-25 11:17:55.337 | INFO     | src.policies:train:109 - Episode 1325\n",
      "2021-08-25 11:17:55.385 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:55.386 | INFO     | src.policies:train:121 - Mean episode return: 133.0\n",
      "2021-08-25 11:17:55.387 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 143.5\n",
      "2021-08-25 11:17:55.388 | WARNING  | src.policies:train:131 - The actual batch size is 255, instead of 200\n",
      "2021-08-25 11:17:55.393 | INFO     | src.policies:train:157 - Total loss: 0.9960782527923584\n",
      "2021-08-25 11:17:55.396 | INFO     | src.policies:train:103 - Epoch 231 / 800\n",
      "2021-08-25 11:17:55.397 | INFO     | src.policies:train:109 - Episode 1326\n",
      "2021-08-25 11:17:55.453 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:55.454 | INFO     | src.policies:train:121 - Mean episode return: 156.0\n",
      "2021-08-25 11:17:55.455 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 144.94\n",
      "2021-08-25 11:17:55.456 | INFO     | src.policies:train:109 - Episode 1327\n",
      "2021-08-25 11:17:55.506 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:55.507 | INFO     | src.policies:train:121 - Mean episode return: 140.0\n",
      "2021-08-25 11:17:55.508 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 145.8\n",
      "2021-08-25 11:17:55.509 | WARNING  | src.policies:train:131 - The actual batch size is 296, instead of 200\n",
      "2021-08-25 11:17:55.514 | INFO     | src.policies:train:157 - Total loss: 0.9966213703155518\n",
      "2021-08-25 11:17:55.517 | INFO     | src.policies:train:103 - Epoch 232 / 800\n",
      "2021-08-25 11:17:55.518 | INFO     | src.policies:train:109 - Episode 1328\n",
      "2021-08-25 11:17:55.560 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:55.561 | INFO     | src.policies:train:121 - Mean episode return: 118.0\n",
      "2021-08-25 11:17:55.562 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 145.65\n",
      "2021-08-25 11:17:55.563 | INFO     | src.policies:train:109 - Episode 1329\n",
      "2021-08-25 11:17:55.607 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:55.609 | INFO     | src.policies:train:121 - Mean episode return: 126.0\n",
      "2021-08-25 11:17:55.609 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 146.2\n",
      "2021-08-25 11:17:55.610 | WARNING  | src.policies:train:131 - The actual batch size is 244, instead of 200\n",
      "2021-08-25 11:17:55.616 | INFO     | src.policies:train:157 - Total loss: 0.995901346206665\n",
      "2021-08-25 11:17:55.618 | INFO     | src.policies:train:103 - Epoch 233 / 800\n",
      "2021-08-25 11:17:55.619 | INFO     | src.policies:train:109 - Episode 1330\n",
      "2021-08-25 11:17:55.658 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:55.659 | INFO     | src.policies:train:121 - Mean episode return: 109.0\n",
      "2021-08-25 11:17:55.660 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 146.49\n",
      "2021-08-25 11:17:55.661 | INFO     | src.policies:train:109 - Episode 1331\n",
      "2021-08-25 11:17:55.713 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:55.714 | INFO     | src.policies:train:121 - Mean episode return: 151.0\n",
      "2021-08-25 11:17:55.715 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 147.79\n",
      "2021-08-25 11:17:55.716 | WARNING  | src.policies:train:131 - The actual batch size is 260, instead of 200\n",
      "2021-08-25 11:17:55.721 | INFO     | src.policies:train:157 - Total loss: 0.9961536526679993\n",
      "2021-08-25 11:17:55.724 | INFO     | src.policies:train:103 - Epoch 234 / 800\n",
      "2021-08-25 11:17:55.725 | INFO     | src.policies:train:109 - Episode 1332\n",
      "2021-08-25 11:17:55.762 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:55.763 | INFO     | src.policies:train:121 - Mean episode return: 105.0\n",
      "2021-08-25 11:17:55.764 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 148.45\n",
      "2021-08-25 11:17:55.765 | INFO     | src.policies:train:109 - Episode 1333\n",
      "2021-08-25 11:17:55.811 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:55.813 | INFO     | src.policies:train:121 - Mean episode return: 131.0\n",
      "2021-08-25 11:17:55.814 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 149.47\n",
      "2021-08-25 11:17:55.815 | WARNING  | src.policies:train:131 - The actual batch size is 236, instead of 200\n",
      "2021-08-25 11:17:55.820 | INFO     | src.policies:train:157 - Total loss: 0.9957624077796936\n",
      "2021-08-25 11:17:55.822 | INFO     | src.policies:train:103 - Epoch 235 / 800\n",
      "2021-08-25 11:17:55.823 | INFO     | src.policies:train:109 - Episode 1334\n",
      "2021-08-25 11:17:55.875 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:55.877 | INFO     | src.policies:train:121 - Mean episode return: 155.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:55.878 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 149.98\n",
      "2021-08-25 11:17:55.879 | INFO     | src.policies:train:109 - Episode 1335\n",
      "2021-08-25 11:17:55.914 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:55.915 | INFO     | src.policies:train:121 - Mean episode return: 94.0\n",
      "2021-08-25 11:17:55.916 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 149.6\n",
      "2021-08-25 11:17:55.917 | WARNING  | src.policies:train:131 - The actual batch size is 249, instead of 200\n",
      "2021-08-25 11:17:55.923 | INFO     | src.policies:train:157 - Total loss: 0.9959838390350342\n",
      "2021-08-25 11:17:55.925 | INFO     | src.policies:train:103 - Epoch 236 / 800\n",
      "2021-08-25 11:17:55.926 | INFO     | src.policies:train:109 - Episode 1336\n",
      "2021-08-25 11:17:55.951 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:55.953 | INFO     | src.policies:train:121 - Mean episode return: 70.0\n",
      "2021-08-25 11:17:55.954 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 148.3\n",
      "2021-08-25 11:17:55.954 | INFO     | src.policies:train:109 - Episode 1337\n",
      "2021-08-25 11:17:55.993 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:55.995 | INFO     | src.policies:train:121 - Mean episode return: 108.0\n",
      "2021-08-25 11:17:55.995 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 148.8\n",
      "2021-08-25 11:17:55.996 | INFO     | src.policies:train:109 - Episode 1338\n",
      "2021-08-25 11:17:56.030 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:56.031 | INFO     | src.policies:train:121 - Mean episode return: 89.0\n",
      "2021-08-25 11:17:56.032 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 149.23\n",
      "2021-08-25 11:17:56.033 | WARNING  | src.policies:train:131 - The actual batch size is 267, instead of 200\n",
      "2021-08-25 11:17:56.038 | INFO     | src.policies:train:157 - Total loss: 0.9962544441223145\n",
      "2021-08-25 11:17:56.041 | INFO     | src.policies:train:103 - Epoch 237 / 800\n",
      "2021-08-25 11:17:56.042 | INFO     | src.policies:train:109 - Episode 1339\n",
      "2021-08-25 11:17:56.086 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:56.087 | INFO     | src.policies:train:121 - Mean episode return: 129.0\n",
      "2021-08-25 11:17:56.088 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 150.34\n",
      "2021-08-25 11:17:56.088 | INFO     | src.policies:train:109 - Episode 1340\n",
      "2021-08-25 11:17:56.115 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:56.117 | INFO     | src.policies:train:121 - Mean episode return: 73.0\n",
      "2021-08-25 11:17:56.118 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 150.86\n",
      "2021-08-25 11:17:56.119 | WARNING  | src.policies:train:131 - The actual batch size is 202, instead of 200\n",
      "2021-08-25 11:17:56.124 | INFO     | src.policies:train:157 - Total loss: 0.9950494170188904\n",
      "2021-08-25 11:17:56.127 | INFO     | src.policies:train:103 - Epoch 238 / 800\n",
      "2021-08-25 11:17:56.128 | INFO     | src.policies:train:109 - Episode 1341\n",
      "2021-08-25 11:17:56.173 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:56.175 | INFO     | src.policies:train:121 - Mean episode return: 133.0\n",
      "2021-08-25 11:17:56.175 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 150.46\n",
      "2021-08-25 11:17:56.176 | INFO     | src.policies:train:109 - Episode 1342\n",
      "2021-08-25 11:17:56.233 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:56.235 | INFO     | src.policies:train:121 - Mean episode return: 165.0\n",
      "2021-08-25 11:17:56.236 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 151.21\n",
      "2021-08-25 11:17:56.236 | WARNING  | src.policies:train:131 - The actual batch size is 298, instead of 200\n",
      "2021-08-25 11:17:56.242 | INFO     | src.policies:train:157 - Total loss: 0.996644139289856\n",
      "2021-08-25 11:17:56.245 | INFO     | src.policies:train:103 - Epoch 239 / 800\n",
      "2021-08-25 11:17:56.246 | INFO     | src.policies:train:109 - Episode 1343\n",
      "2021-08-25 11:17:56.312 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:56.313 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:17:56.314 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 152.42\n",
      "2021-08-25 11:17:56.319 | INFO     | src.policies:train:157 - Total loss: 0.994999885559082\n",
      "2021-08-25 11:17:56.322 | INFO     | src.policies:train:103 - Epoch 240 / 800\n",
      "2021-08-25 11:17:56.322 | INFO     | src.policies:train:109 - Episode 1344\n",
      "2021-08-25 11:17:56.360 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:56.361 | INFO     | src.policies:train:121 - Mean episode return: 108.0\n",
      "2021-08-25 11:17:56.362 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 152.08\n",
      "2021-08-25 11:17:56.363 | INFO     | src.policies:train:109 - Episode 1345\n",
      "2021-08-25 11:17:56.408 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:56.409 | INFO     | src.policies:train:121 - Mean episode return: 126.0\n",
      "2021-08-25 11:17:56.410 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 151.7\n",
      "2021-08-25 11:17:56.411 | WARNING  | src.policies:train:131 - The actual batch size is 234, instead of 200\n",
      "2021-08-25 11:17:56.416 | INFO     | src.policies:train:157 - Total loss: 0.9957263469696045\n",
      "2021-08-25 11:17:56.419 | INFO     | src.policies:train:103 - Epoch 241 / 800\n",
      "2021-08-25 11:17:56.420 | INFO     | src.policies:train:109 - Episode 1346\n",
      "2021-08-25 11:17:56.450 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:56.451 | INFO     | src.policies:train:121 - Mean episode return: 81.0\n",
      "2021-08-25 11:17:56.453 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 151.35\n",
      "2021-08-25 11:17:56.453 | INFO     | src.policies:train:109 - Episode 1347\n",
      "2021-08-25 11:17:56.486 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:56.487 | INFO     | src.policies:train:121 - Mean episode return: 88.0\n",
      "2021-08-25 11:17:56.488 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 150.93\n",
      "2021-08-25 11:17:56.488 | INFO     | src.policies:train:109 - Episode 1348\n",
      "2021-08-25 11:17:56.527 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:56.528 | INFO     | src.policies:train:121 - Mean episode return: 104.0\n",
      "2021-08-25 11:17:56.529 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 150.21\n",
      "2021-08-25 11:17:56.530 | WARNING  | src.policies:train:131 - The actual batch size is 273, instead of 200\n",
      "2021-08-25 11:17:56.536 | INFO     | src.policies:train:157 - Total loss: 0.9963367581367493\n",
      "2021-08-25 11:17:56.538 | INFO     | src.policies:train:103 - Epoch 242 / 800\n",
      "2021-08-25 11:17:56.539 | INFO     | src.policies:train:109 - Episode 1349\n",
      "2021-08-25 11:17:56.558 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:56.560 | INFO     | src.policies:train:121 - Mean episode return: 51.0\n",
      "2021-08-25 11:17:56.561 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 149.57\n",
      "2021-08-25 11:17:56.561 | INFO     | src.policies:train:109 - Episode 1350\n",
      "2021-08-25 11:17:56.589 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:56.591 | INFO     | src.policies:train:121 - Mean episode return: 74.0\n",
      "2021-08-25 11:17:56.591 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 148.55\n",
      "2021-08-25 11:17:56.592 | INFO     | src.policies:train:109 - Episode 1351\n",
      "2021-08-25 11:17:56.621 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:56.622 | INFO     | src.policies:train:121 - Mean episode return: 71.0\n",
      "2021-08-25 11:17:56.624 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 147.76\n",
      "2021-08-25 11:17:56.625 | INFO     | src.policies:train:109 - Episode 1352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:56.678 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:56.679 | INFO     | src.policies:train:121 - Mean episode return: 131.0\n",
      "2021-08-25 11:17:56.680 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 147.42\n",
      "2021-08-25 11:17:56.680 | WARNING  | src.policies:train:131 - The actual batch size is 327, instead of 200\n",
      "2021-08-25 11:17:56.687 | INFO     | src.policies:train:157 - Total loss: 0.9969415068626404\n",
      "2021-08-25 11:17:56.690 | INFO     | src.policies:train:103 - Epoch 243 / 800\n",
      "2021-08-25 11:17:56.691 | INFO     | src.policies:train:109 - Episode 1353\n",
      "2021-08-25 11:17:56.723 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:56.724 | INFO     | src.policies:train:121 - Mean episode return: 92.0\n",
      "2021-08-25 11:17:56.725 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 146.34\n",
      "2021-08-25 11:17:56.726 | INFO     | src.policies:train:109 - Episode 1354\n",
      "2021-08-25 11:17:56.767 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:56.768 | INFO     | src.policies:train:121 - Mean episode return: 108.0\n",
      "2021-08-25 11:17:56.769 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 145.66\n",
      "2021-08-25 11:17:56.774 | INFO     | src.policies:train:157 - Total loss: 0.9949997067451477\n",
      "2021-08-25 11:17:56.777 | INFO     | src.policies:train:103 - Epoch 244 / 800\n",
      "2021-08-25 11:17:56.778 | INFO     | src.policies:train:109 - Episode 1355\n",
      "2021-08-25 11:17:56.815 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:56.817 | INFO     | src.policies:train:121 - Mean episode return: 106.0\n",
      "2021-08-25 11:17:56.818 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 145.1\n",
      "2021-08-25 11:17:56.819 | INFO     | src.policies:train:109 - Episode 1356\n",
      "2021-08-25 11:17:56.886 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:56.887 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:17:56.888 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 145.1\n",
      "2021-08-25 11:17:56.889 | WARNING  | src.policies:train:131 - The actual batch size is 306, instead of 200\n",
      "2021-08-25 11:17:56.895 | INFO     | src.policies:train:157 - Total loss: 0.9967319369316101\n",
      "2021-08-25 11:17:56.898 | INFO     | src.policies:train:103 - Epoch 245 / 800\n",
      "2021-08-25 11:17:56.899 | INFO     | src.policies:train:109 - Episode 1357\n",
      "2021-08-25 11:17:56.938 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:56.939 | INFO     | src.policies:train:121 - Mean episode return: 113.0\n",
      "2021-08-25 11:17:56.940 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 145.09\n",
      "2021-08-25 11:17:56.941 | INFO     | src.policies:train:109 - Episode 1358\n",
      "2021-08-25 11:17:56.959 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:56.961 | INFO     | src.policies:train:121 - Mean episode return: 47.0\n",
      "2021-08-25 11:17:56.961 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 144.13\n",
      "2021-08-25 11:17:56.962 | INFO     | src.policies:train:109 - Episode 1359\n",
      "2021-08-25 11:17:56.997 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:56.999 | INFO     | src.policies:train:121 - Mean episode return: 92.0\n",
      "2021-08-25 11:17:56.999 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 143.05\n",
      "2021-08-25 11:17:57.000 | WARNING  | src.policies:train:131 - The actual batch size is 252, instead of 200\n",
      "2021-08-25 11:17:57.006 | INFO     | src.policies:train:157 - Total loss: 0.9960315823554993\n",
      "2021-08-25 11:17:57.008 | INFO     | src.policies:train:103 - Epoch 246 / 800\n",
      "2021-08-25 11:17:57.009 | INFO     | src.policies:train:109 - Episode 1360\n",
      "2021-08-25 11:17:57.060 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:57.062 | INFO     | src.policies:train:121 - Mean episode return: 145.0\n",
      "2021-08-25 11:17:57.063 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 142.5\n",
      "2021-08-25 11:17:57.063 | INFO     | src.policies:train:109 - Episode 1361\n",
      "2021-08-25 11:17:57.089 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:57.090 | INFO     | src.policies:train:121 - Mean episode return: 69.0\n",
      "2021-08-25 11:17:57.091 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 141.26\n",
      "2021-08-25 11:17:57.092 | WARNING  | src.policies:train:131 - The actual batch size is 214, instead of 200\n",
      "2021-08-25 11:17:57.098 | INFO     | src.policies:train:157 - Total loss: 0.9953269362449646\n",
      "2021-08-25 11:17:57.101 | INFO     | src.policies:train:103 - Epoch 247 / 800\n",
      "2021-08-25 11:17:57.102 | INFO     | src.policies:train:109 - Episode 1362\n",
      "2021-08-25 11:17:57.113 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:57.114 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:17:57.115 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 139.52\n",
      "2021-08-25 11:17:57.116 | INFO     | src.policies:train:109 - Episode 1363\n",
      "2021-08-25 11:17:57.155 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:57.156 | INFO     | src.policies:train:121 - Mean episode return: 108.0\n",
      "2021-08-25 11:17:57.157 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 138.87\n",
      "2021-08-25 11:17:57.158 | INFO     | src.policies:train:109 - Episode 1364\n",
      "2021-08-25 11:17:57.202 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:57.203 | INFO     | src.policies:train:121 - Mean episode return: 125.0\n",
      "2021-08-25 11:17:57.204 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 138.7\n",
      "2021-08-25 11:17:57.205 | WARNING  | src.policies:train:131 - The actual batch size is 259, instead of 200\n",
      "2021-08-25 11:17:57.211 | INFO     | src.policies:train:157 - Total loss: 0.9961386919021606\n",
      "2021-08-25 11:17:57.213 | INFO     | src.policies:train:103 - Epoch 248 / 800\n",
      "2021-08-25 11:17:57.214 | INFO     | src.policies:train:109 - Episode 1365\n",
      "2021-08-25 11:17:57.225 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:57.226 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:17:57.227 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 137.71\n",
      "2021-08-25 11:17:57.228 | INFO     | src.policies:train:109 - Episode 1366\n",
      "2021-08-25 11:17:57.298 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:57.299 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:17:57.300 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 137.71\n",
      "2021-08-25 11:17:57.301 | WARNING  | src.policies:train:131 - The actual batch size is 223, instead of 200\n",
      "2021-08-25 11:17:57.306 | INFO     | src.policies:train:157 - Total loss: 0.9955155849456787\n",
      "2021-08-25 11:17:57.309 | INFO     | src.policies:train:103 - Epoch 249 / 800\n",
      "2021-08-25 11:17:57.310 | INFO     | src.policies:train:109 - Episode 1367\n",
      "2021-08-25 11:17:57.348 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:57.349 | INFO     | src.policies:train:121 - Mean episode return: 110.0\n",
      "2021-08-25 11:17:57.350 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 136.81\n",
      "2021-08-25 11:17:57.351 | INFO     | src.policies:train:109 - Episode 1368\n",
      "2021-08-25 11:17:57.412 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:57.413 | INFO     | src.policies:train:121 - Mean episode return: 172.0\n",
      "2021-08-25 11:17:57.414 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 136.53\n",
      "2021-08-25 11:17:57.415 | WARNING  | src.policies:train:131 - The actual batch size is 282, instead of 200\n",
      "2021-08-25 11:17:57.420 | INFO     | src.policies:train:157 - Total loss: 0.9964537024497986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:57.423 | INFO     | src.policies:train:103 - Epoch 250 / 800\n",
      "2021-08-25 11:17:57.423 | INFO     | src.policies:train:109 - Episode 1369\n",
      "2021-08-25 11:17:57.489 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:57.491 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:17:57.491 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 136.64\n",
      "2021-08-25 11:17:57.496 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:17:57.499 | INFO     | src.policies:train:103 - Epoch 251 / 800\n",
      "2021-08-25 11:17:57.500 | INFO     | src.policies:train:109 - Episode 1370\n",
      "2021-08-25 11:17:57.554 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:57.556 | INFO     | src.policies:train:121 - Mean episode return: 162.0\n",
      "2021-08-25 11:17:57.557 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 137.79\n",
      "2021-08-25 11:17:57.558 | INFO     | src.policies:train:109 - Episode 1371\n",
      "2021-08-25 11:17:57.616 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:57.617 | INFO     | src.policies:train:121 - Mean episode return: 164.0\n",
      "2021-08-25 11:17:57.618 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 137.84\n",
      "2021-08-25 11:17:57.619 | WARNING  | src.policies:train:131 - The actual batch size is 326, instead of 200\n",
      "2021-08-25 11:17:57.625 | INFO     | src.policies:train:157 - Total loss: 0.9969324469566345\n",
      "2021-08-25 11:17:57.628 | INFO     | src.policies:train:103 - Epoch 252 / 800\n",
      "2021-08-25 11:17:57.629 | INFO     | src.policies:train:109 - Episode 1372\n",
      "2021-08-25 11:17:57.676 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:57.678 | INFO     | src.policies:train:121 - Mean episode return: 140.0\n",
      "2021-08-25 11:17:57.679 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 138.76\n",
      "2021-08-25 11:17:57.679 | INFO     | src.policies:train:109 - Episode 1373\n",
      "2021-08-25 11:17:57.711 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:57.712 | INFO     | src.policies:train:121 - Mean episode return: 84.0\n",
      "2021-08-25 11:17:57.713 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 137.71\n",
      "2021-08-25 11:17:57.714 | WARNING  | src.policies:train:131 - The actual batch size is 224, instead of 200\n",
      "2021-08-25 11:17:57.719 | INFO     | src.policies:train:157 - Total loss: 0.9955357313156128\n",
      "2021-08-25 11:17:57.722 | INFO     | src.policies:train:103 - Epoch 253 / 800\n",
      "2021-08-25 11:17:57.723 | INFO     | src.policies:train:109 - Episode 1374\n",
      "2021-08-25 11:17:57.771 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:57.772 | INFO     | src.policies:train:121 - Mean episode return: 138.0\n",
      "2021-08-25 11:17:57.773 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 137.46\n",
      "2021-08-25 11:17:57.774 | INFO     | src.policies:train:109 - Episode 1375\n",
      "2021-08-25 11:17:57.822 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:57.824 | INFO     | src.policies:train:121 - Mean episode return: 138.0\n",
      "2021-08-25 11:17:57.824 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 136.84\n",
      "2021-08-25 11:17:57.826 | WARNING  | src.policies:train:131 - The actual batch size is 276, instead of 200\n",
      "2021-08-25 11:17:57.832 | INFO     | src.policies:train:157 - Total loss: 0.996376633644104\n",
      "2021-08-25 11:17:57.835 | INFO     | src.policies:train:103 - Epoch 254 / 800\n",
      "2021-08-25 11:17:57.836 | INFO     | src.policies:train:109 - Episode 1376\n",
      "2021-08-25 11:17:57.873 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:57.875 | INFO     | src.policies:train:121 - Mean episode return: 105.0\n",
      "2021-08-25 11:17:57.876 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 135.98\n",
      "2021-08-25 11:17:57.876 | INFO     | src.policies:train:109 - Episode 1377\n",
      "2021-08-25 11:17:57.946 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:57.947 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:17:57.948 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 136.66\n",
      "2021-08-25 11:17:57.949 | WARNING  | src.policies:train:131 - The actual batch size is 305, instead of 200\n",
      "2021-08-25 11:17:57.954 | INFO     | src.policies:train:157 - Total loss: 0.9967211484909058\n",
      "2021-08-25 11:17:57.957 | INFO     | src.policies:train:103 - Epoch 255 / 800\n",
      "2021-08-25 11:17:57.958 | INFO     | src.policies:train:109 - Episode 1378\n",
      "2021-08-25 11:17:58.026 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:58.028 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:17:58.029 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 136.66\n",
      "2021-08-25 11:17:58.034 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:17:58.037 | INFO     | src.policies:train:103 - Epoch 256 / 800\n",
      "2021-08-25 11:17:58.037 | INFO     | src.policies:train:109 - Episode 1379\n",
      "2021-08-25 11:17:58.095 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:58.097 | INFO     | src.policies:train:121 - Mean episode return: 163.0\n",
      "2021-08-25 11:17:58.098 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 137.01\n",
      "2021-08-25 11:17:58.098 | INFO     | src.policies:train:109 - Episode 1380\n",
      "2021-08-25 11:17:58.137 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:58.139 | INFO     | src.policies:train:121 - Mean episode return: 112.0\n",
      "2021-08-25 11:17:58.139 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 136.67\n",
      "2021-08-25 11:17:58.140 | WARNING  | src.policies:train:131 - The actual batch size is 275, instead of 200\n",
      "2021-08-25 11:17:58.146 | INFO     | src.policies:train:157 - Total loss: 0.9963633418083191\n",
      "2021-08-25 11:17:58.148 | INFO     | src.policies:train:103 - Epoch 257 / 800\n",
      "2021-08-25 11:17:58.149 | INFO     | src.policies:train:109 - Episode 1381\n",
      "2021-08-25 11:17:58.211 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:58.212 | INFO     | src.policies:train:121 - Mean episode return: 185.0\n",
      "2021-08-25 11:17:58.213 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 137.93\n",
      "2021-08-25 11:17:58.214 | INFO     | src.policies:train:109 - Episode 1382\n",
      "2021-08-25 11:17:58.275 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:58.277 | INFO     | src.policies:train:121 - Mean episode return: 181.0\n",
      "2021-08-25 11:17:58.277 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 139.2\n",
      "2021-08-25 11:17:58.278 | WARNING  | src.policies:train:131 - The actual batch size is 366, instead of 200\n",
      "2021-08-25 11:17:58.284 | INFO     | src.policies:train:157 - Total loss: 0.9972676038742065\n",
      "2021-08-25 11:17:58.286 | INFO     | src.policies:train:103 - Epoch 258 / 800\n",
      "2021-08-25 11:17:58.287 | INFO     | src.policies:train:109 - Episode 1383\n",
      "2021-08-25 11:17:58.341 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:58.342 | INFO     | src.policies:train:121 - Mean episode return: 160.0\n",
      "2021-08-25 11:17:58.343 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 140.0\n",
      "2021-08-25 11:17:58.344 | INFO     | src.policies:train:109 - Episode 1384\n",
      "2021-08-25 11:17:58.388 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:58.389 | INFO     | src.policies:train:121 - Mean episode return: 125.0\n",
      "2021-08-25 11:17:58.390 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 139.74\n",
      "2021-08-25 11:17:58.391 | WARNING  | src.policies:train:131 - The actual batch size is 285, instead of 200\n",
      "2021-08-25 11:17:58.397 | INFO     | src.policies:train:157 - Total loss: 0.9964911937713623\n",
      "2021-08-25 11:17:58.400 | INFO     | src.policies:train:103 - Epoch 259 / 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:58.401 | INFO     | src.policies:train:109 - Episode 1385\n",
      "2021-08-25 11:17:58.467 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:58.468 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:17:58.469 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 141.13\n",
      "2021-08-25 11:17:58.474 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:17:58.477 | INFO     | src.policies:train:103 - Epoch 260 / 800\n",
      "2021-08-25 11:17:58.478 | INFO     | src.policies:train:109 - Episode 1386\n",
      "2021-08-25 11:17:58.544 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:58.546 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:17:58.547 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 141.13\n",
      "2021-08-25 11:17:58.552 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:17:58.555 | INFO     | src.policies:train:103 - Epoch 261 / 800\n",
      "2021-08-25 11:17:58.555 | INFO     | src.policies:train:109 - Episode 1387\n",
      "2021-08-25 11:17:58.626 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:58.627 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:17:58.628 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 141.24\n",
      "2021-08-25 11:17:58.633 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:17:58.636 | INFO     | src.policies:train:103 - Epoch 262 / 800\n",
      "2021-08-25 11:17:58.637 | INFO     | src.policies:train:109 - Episode 1388\n",
      "2021-08-25 11:17:58.705 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:58.706 | INFO     | src.policies:train:121 - Mean episode return: 197.0\n",
      "2021-08-25 11:17:58.707 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 141.39\n",
      "2021-08-25 11:17:58.708 | INFO     | src.policies:train:109 - Episode 1389\n",
      "2021-08-25 11:17:58.721 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:58.722 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 11:17:58.723 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 140.28\n",
      "2021-08-25 11:17:58.724 | WARNING  | src.policies:train:131 - The actual batch size is 225, instead of 200\n",
      "2021-08-25 11:17:58.729 | INFO     | src.policies:train:157 - Total loss: 0.9955554008483887\n",
      "2021-08-25 11:17:58.731 | INFO     | src.policies:train:103 - Epoch 263 / 800\n",
      "2021-08-25 11:17:58.732 | INFO     | src.policies:train:109 - Episode 1390\n",
      "2021-08-25 11:17:58.781 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:58.782 | INFO     | src.policies:train:121 - Mean episode return: 142.0\n",
      "2021-08-25 11:17:58.783 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 140.24\n",
      "2021-08-25 11:17:58.784 | INFO     | src.policies:train:109 - Episode 1391\n",
      "2021-08-25 11:17:58.841 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:58.842 | INFO     | src.policies:train:121 - Mean episode return: 160.0\n",
      "2021-08-25 11:17:58.843 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 139.84\n",
      "2021-08-25 11:17:58.844 | WARNING  | src.policies:train:131 - The actual batch size is 302, instead of 200\n",
      "2021-08-25 11:17:58.849 | INFO     | src.policies:train:157 - Total loss: 0.9966885447502136\n",
      "2021-08-25 11:17:58.852 | INFO     | src.policies:train:103 - Epoch 264 / 800\n",
      "2021-08-25 11:17:58.853 | INFO     | src.policies:train:109 - Episode 1392\n",
      "2021-08-25 11:17:58.919 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:58.920 | INFO     | src.policies:train:121 - Mean episode return: 193.0\n",
      "2021-08-25 11:17:58.921 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 139.86\n",
      "2021-08-25 11:17:58.922 | INFO     | src.policies:train:109 - Episode 1393\n",
      "2021-08-25 11:17:58.955 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:58.956 | INFO     | src.policies:train:121 - Mean episode return: 88.0\n",
      "2021-08-25 11:17:58.956 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 138.77\n",
      "2021-08-25 11:17:58.958 | WARNING  | src.policies:train:131 - The actual batch size is 281, instead of 200\n",
      "2021-08-25 11:17:58.963 | INFO     | src.policies:train:157 - Total loss: 0.9964408874511719\n",
      "2021-08-25 11:17:58.966 | INFO     | src.policies:train:103 - Epoch 265 / 800\n",
      "2021-08-25 11:17:58.967 | INFO     | src.policies:train:109 - Episode 1394\n",
      "2021-08-25 11:17:59.034 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:59.035 | INFO     | src.policies:train:121 - Mean episode return: 198.0\n",
      "2021-08-25 11:17:59.036 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 138.75\n",
      "2021-08-25 11:17:59.037 | INFO     | src.policies:train:109 - Episode 1395\n",
      "2021-08-25 11:17:59.097 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:59.098 | INFO     | src.policies:train:121 - Mean episode return: 174.0\n",
      "2021-08-25 11:17:59.099 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 138.83\n",
      "2021-08-25 11:17:59.100 | WARNING  | src.policies:train:131 - The actual batch size is 372, instead of 200\n",
      "2021-08-25 11:17:59.106 | INFO     | src.policies:train:157 - Total loss: 0.9973117113113403\n",
      "2021-08-25 11:17:59.109 | INFO     | src.policies:train:103 - Epoch 266 / 800\n",
      "2021-08-25 11:17:59.110 | INFO     | src.policies:train:109 - Episode 1396\n",
      "2021-08-25 11:17:59.159 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:59.160 | INFO     | src.policies:train:121 - Mean episode return: 141.0\n",
      "2021-08-25 11:17:59.161 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 138.69\n",
      "2021-08-25 11:17:59.162 | INFO     | src.policies:train:109 - Episode 1397\n",
      "2021-08-25 11:17:59.201 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:59.202 | INFO     | src.policies:train:121 - Mean episode return: 109.0\n",
      "2021-08-25 11:17:59.203 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 138.06\n",
      "2021-08-25 11:17:59.204 | WARNING  | src.policies:train:131 - The actual batch size is 250, instead of 200\n",
      "2021-08-25 11:17:59.209 | INFO     | src.policies:train:157 - Total loss: 0.9959998726844788\n",
      "2021-08-25 11:17:59.212 | INFO     | src.policies:train:103 - Epoch 267 / 800\n",
      "2021-08-25 11:17:59.213 | INFO     | src.policies:train:109 - Episode 1398\n",
      "2021-08-25 11:17:59.282 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:59.283 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:17:59.285 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 138.06\n",
      "2021-08-25 11:17:59.289 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:17:59.292 | INFO     | src.policies:train:103 - Epoch 268 / 800\n",
      "2021-08-25 11:17:59.293 | INFO     | src.policies:train:109 - Episode 1399\n",
      "2021-08-25 11:17:59.348 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:59.349 | INFO     | src.policies:train:121 - Mean episode return: 156.0\n",
      "2021-08-25 11:17:59.350 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 138.53\n",
      "2021-08-25 11:17:59.351 | INFO     | src.policies:train:109 - Episode 1400\n",
      "2021-08-25 11:17:59.417 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:59.418 | INFO     | src.policies:train:121 - Mean episode return: 185.0\n",
      "2021-08-25 11:17:59.419 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 138.47\n",
      "2021-08-25 11:17:59.420 | WARNING  | src.policies:train:131 - The actual batch size is 341, instead of 200\n",
      "2021-08-25 11:17:59.425 | INFO     | src.policies:train:157 - Total loss: 0.9970671534538269\n",
      "2021-08-25 11:17:59.428 | INFO     | src.policies:train:103 - Epoch 269 / 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:17:59.429 | INFO     | src.policies:train:109 - Episode 1401\n",
      "2021-08-25 11:17:59.452 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:59.453 | INFO     | src.policies:train:121 - Mean episode return: 63.0\n",
      "2021-08-25 11:17:59.455 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 137.1\n",
      "2021-08-25 11:17:59.455 | INFO     | src.policies:train:109 - Episode 1402\n",
      "2021-08-25 11:17:59.507 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:59.508 | INFO     | src.policies:train:121 - Mean episode return: 145.0\n",
      "2021-08-25 11:17:59.510 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 137.29\n",
      "2021-08-25 11:17:59.511 | WARNING  | src.policies:train:131 - The actual batch size is 208, instead of 200\n",
      "2021-08-25 11:17:59.516 | INFO     | src.policies:train:157 - Total loss: 0.9951922297477722\n",
      "2021-08-25 11:17:59.518 | INFO     | src.policies:train:103 - Epoch 270 / 800\n",
      "2021-08-25 11:17:59.519 | INFO     | src.policies:train:109 - Episode 1403\n",
      "2021-08-25 11:17:59.561 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:59.563 | INFO     | src.policies:train:121 - Mean episode return: 122.0\n",
      "2021-08-25 11:17:59.564 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 136.65\n",
      "2021-08-25 11:17:59.564 | INFO     | src.policies:train:109 - Episode 1404\n",
      "2021-08-25 11:17:59.601 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:59.602 | INFO     | src.policies:train:121 - Mean episode return: 104.0\n",
      "2021-08-25 11:17:59.603 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 135.69\n",
      "2021-08-25 11:17:59.604 | WARNING  | src.policies:train:131 - The actual batch size is 226, instead of 200\n",
      "2021-08-25 11:17:59.609 | INFO     | src.policies:train:157 - Total loss: 0.9955750703811646\n",
      "2021-08-25 11:17:59.612 | INFO     | src.policies:train:103 - Epoch 271 / 800\n",
      "2021-08-25 11:17:59.613 | INFO     | src.policies:train:109 - Episode 1405\n",
      "2021-08-25 11:17:59.683 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:59.684 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:17:59.685 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 136.35\n",
      "2021-08-25 11:17:59.689 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:17:59.692 | INFO     | src.policies:train:103 - Epoch 272 / 800\n",
      "2021-08-25 11:17:59.693 | INFO     | src.policies:train:109 - Episode 1406\n",
      "2021-08-25 11:17:59.737 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:59.739 | INFO     | src.policies:train:121 - Mean episode return: 125.0\n",
      "2021-08-25 11:17:59.740 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 135.6\n",
      "2021-08-25 11:17:59.740 | INFO     | src.policies:train:109 - Episode 1407\n",
      "2021-08-25 11:17:59.794 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:59.795 | INFO     | src.policies:train:121 - Mean episode return: 151.0\n",
      "2021-08-25 11:17:59.796 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 135.81\n",
      "2021-08-25 11:17:59.797 | WARNING  | src.policies:train:131 - The actual batch size is 276, instead of 200\n",
      "2021-08-25 11:17:59.802 | INFO     | src.policies:train:157 - Total loss: 0.9963766932487488\n",
      "2021-08-25 11:17:59.805 | INFO     | src.policies:train:103 - Epoch 273 / 800\n",
      "2021-08-25 11:17:59.806 | INFO     | src.policies:train:109 - Episode 1408\n",
      "2021-08-25 11:17:59.874 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:59.875 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:17:59.876 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 136.26\n",
      "2021-08-25 11:17:59.880 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:17:59.883 | INFO     | src.policies:train:103 - Epoch 274 / 800\n",
      "2021-08-25 11:17:59.884 | INFO     | src.policies:train:109 - Episode 1409\n",
      "2021-08-25 11:17:59.908 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:59.909 | INFO     | src.policies:train:121 - Mean episode return: 68.0\n",
      "2021-08-25 11:17:59.911 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 134.94\n",
      "2021-08-25 11:17:59.911 | INFO     | src.policies:train:109 - Episode 1410\n",
      "2021-08-25 11:17:59.973 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:17:59.974 | INFO     | src.policies:train:121 - Mean episode return: 176.0\n",
      "2021-08-25 11:17:59.975 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 134.7\n",
      "2021-08-25 11:17:59.976 | WARNING  | src.policies:train:131 - The actual batch size is 244, instead of 200\n",
      "2021-08-25 11:17:59.981 | INFO     | src.policies:train:157 - Total loss: 0.9959014058113098\n",
      "2021-08-25 11:17:59.983 | INFO     | src.policies:train:103 - Epoch 275 / 800\n",
      "2021-08-25 11:17:59.984 | INFO     | src.policies:train:109 - Episode 1411\n",
      "2021-08-25 11:18:00.052 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:00.053 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:00.054 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 135.41\n",
      "2021-08-25 11:18:00.059 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:00.062 | INFO     | src.policies:train:103 - Epoch 276 / 800\n",
      "2021-08-25 11:18:00.062 | INFO     | src.policies:train:109 - Episode 1412\n",
      "2021-08-25 11:18:00.121 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:00.122 | INFO     | src.policies:train:121 - Mean episode return: 169.0\n",
      "2021-08-25 11:18:00.123 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 135.1\n",
      "2021-08-25 11:18:00.124 | INFO     | src.policies:train:109 - Episode 1413\n",
      "2021-08-25 11:18:00.188 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:00.189 | INFO     | src.policies:train:121 - Mean episode return: 186.0\n",
      "2021-08-25 11:18:00.190 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 134.96\n",
      "2021-08-25 11:18:00.191 | WARNING  | src.policies:train:131 - The actual batch size is 355, instead of 200\n",
      "2021-08-25 11:18:00.197 | INFO     | src.policies:train:157 - Total loss: 0.9971830248832703\n",
      "2021-08-25 11:18:00.200 | INFO     | src.policies:train:103 - Epoch 277 / 800\n",
      "2021-08-25 11:18:00.201 | INFO     | src.policies:train:109 - Episode 1414\n",
      "2021-08-25 11:18:00.254 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:00.255 | INFO     | src.policies:train:121 - Mean episode return: 160.0\n",
      "2021-08-25 11:18:00.256 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 134.56\n",
      "2021-08-25 11:18:00.257 | INFO     | src.policies:train:109 - Episode 1415\n",
      "2021-08-25 11:18:00.316 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:00.317 | INFO     | src.policies:train:121 - Mean episode return: 173.0\n",
      "2021-08-25 11:18:00.318 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 134.68\n",
      "2021-08-25 11:18:00.319 | WARNING  | src.policies:train:131 - The actual batch size is 333, instead of 200\n",
      "2021-08-25 11:18:00.324 | INFO     | src.policies:train:157 - Total loss: 0.9969968199729919\n",
      "2021-08-25 11:18:00.327 | INFO     | src.policies:train:103 - Epoch 278 / 800\n",
      "2021-08-25 11:18:00.328 | INFO     | src.policies:train:109 - Episode 1416\n",
      "2021-08-25 11:18:00.396 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:00.398 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:00.399 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 134.98\n",
      "2021-08-25 11:18:00.403 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:00.406 | INFO     | src.policies:train:103 - Epoch 279 / 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:18:00.407 | INFO     | src.policies:train:109 - Episode 1417\n",
      "2021-08-25 11:18:00.449 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:00.450 | INFO     | src.policies:train:121 - Mean episode return: 126.0\n",
      "2021-08-25 11:18:00.451 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 135.04\n",
      "2021-08-25 11:18:00.452 | INFO     | src.policies:train:109 - Episode 1418\n",
      "2021-08-25 11:18:00.522 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:00.523 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:00.524 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 135.56\n",
      "2021-08-25 11:18:00.525 | WARNING  | src.policies:train:131 - The actual batch size is 326, instead of 200\n",
      "2021-08-25 11:18:00.531 | INFO     | src.policies:train:157 - Total loss: 0.9969323873519897\n",
      "2021-08-25 11:18:00.534 | INFO     | src.policies:train:103 - Epoch 280 / 800\n",
      "2021-08-25 11:18:00.535 | INFO     | src.policies:train:109 - Episode 1419\n",
      "2021-08-25 11:18:00.593 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:00.594 | INFO     | src.policies:train:121 - Mean episode return: 167.0\n",
      "2021-08-25 11:18:00.595 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 136.45\n",
      "2021-08-25 11:18:00.596 | INFO     | src.policies:train:109 - Episode 1420\n",
      "2021-08-25 11:18:00.667 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:00.668 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:00.669 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 137.35\n",
      "2021-08-25 11:18:00.670 | WARNING  | src.policies:train:131 - The actual batch size is 367, instead of 200\n",
      "2021-08-25 11:18:00.675 | INFO     | src.policies:train:157 - Total loss: 0.9972749352455139\n",
      "2021-08-25 11:18:00.679 | INFO     | src.policies:train:103 - Epoch 281 / 800\n",
      "2021-08-25 11:18:00.680 | INFO     | src.policies:train:109 - Episode 1421\n",
      "2021-08-25 11:18:00.734 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:00.735 | INFO     | src.policies:train:121 - Mean episode return: 161.0\n",
      "2021-08-25 11:18:00.736 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 136.96\n",
      "2021-08-25 11:18:00.737 | INFO     | src.policies:train:109 - Episode 1422\n",
      "2021-08-25 11:18:00.805 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:00.806 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:00.807 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 138.01\n",
      "2021-08-25 11:18:00.808 | WARNING  | src.policies:train:131 - The actual batch size is 361, instead of 200\n",
      "2021-08-25 11:18:00.814 | INFO     | src.policies:train:157 - Total loss: 0.9972296953201294\n",
      "2021-08-25 11:18:00.817 | INFO     | src.policies:train:103 - Epoch 282 / 800\n",
      "2021-08-25 11:18:00.818 | INFO     | src.policies:train:109 - Episode 1423\n",
      "2021-08-25 11:18:00.887 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:00.889 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:00.890 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 138.01\n",
      "2021-08-25 11:18:00.894 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:00.897 | INFO     | src.policies:train:103 - Epoch 283 / 800\n",
      "2021-08-25 11:18:00.898 | INFO     | src.policies:train:109 - Episode 1424\n",
      "2021-08-25 11:18:00.949 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:00.951 | INFO     | src.policies:train:121 - Mean episode return: 152.0\n",
      "2021-08-25 11:18:00.952 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 138.31\n",
      "2021-08-25 11:18:00.952 | INFO     | src.policies:train:109 - Episode 1425\n",
      "2021-08-25 11:18:01.014 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:01.015 | INFO     | src.policies:train:121 - Mean episode return: 171.0\n",
      "2021-08-25 11:18:01.016 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 138.69\n",
      "2021-08-25 11:18:01.017 | WARNING  | src.policies:train:131 - The actual batch size is 323, instead of 200\n",
      "2021-08-25 11:18:01.022 | INFO     | src.policies:train:157 - Total loss: 0.9969038367271423\n",
      "2021-08-25 11:18:01.025 | INFO     | src.policies:train:103 - Epoch 284 / 800\n",
      "2021-08-25 11:18:01.026 | INFO     | src.policies:train:109 - Episode 1426\n",
      "2021-08-25 11:18:01.084 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:01.085 | INFO     | src.policies:train:121 - Mean episode return: 176.0\n",
      "2021-08-25 11:18:01.086 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 138.89\n",
      "2021-08-25 11:18:01.087 | INFO     | src.policies:train:109 - Episode 1427\n",
      "2021-08-25 11:18:01.143 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:01.145 | INFO     | src.policies:train:121 - Mean episode return: 157.0\n",
      "2021-08-25 11:18:01.145 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 139.06\n",
      "2021-08-25 11:18:01.146 | WARNING  | src.policies:train:131 - The actual batch size is 333, instead of 200\n",
      "2021-08-25 11:18:01.152 | INFO     | src.policies:train:157 - Total loss: 0.9969968795776367\n",
      "2021-08-25 11:18:01.155 | INFO     | src.policies:train:103 - Epoch 285 / 800\n",
      "2021-08-25 11:18:01.156 | INFO     | src.policies:train:109 - Episode 1428\n",
      "2021-08-25 11:18:01.223 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:01.225 | INFO     | src.policies:train:121 - Mean episode return: 198.0\n",
      "2021-08-25 11:18:01.226 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 139.86\n",
      "2021-08-25 11:18:01.226 | INFO     | src.policies:train:109 - Episode 1429\n",
      "2021-08-25 11:18:01.292 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:01.294 | INFO     | src.policies:train:121 - Mean episode return: 190.0\n",
      "2021-08-25 11:18:01.294 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 140.5\n",
      "2021-08-25 11:18:01.295 | WARNING  | src.policies:train:131 - The actual batch size is 388, instead of 200\n",
      "2021-08-25 11:18:01.301 | INFO     | src.policies:train:157 - Total loss: 0.9974225759506226\n",
      "2021-08-25 11:18:01.304 | INFO     | src.policies:train:103 - Epoch 286 / 800\n",
      "2021-08-25 11:18:01.305 | INFO     | src.policies:train:109 - Episode 1430\n",
      "2021-08-25 11:18:01.366 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:01.367 | INFO     | src.policies:train:121 - Mean episode return: 177.0\n",
      "2021-08-25 11:18:01.368 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 141.18\n",
      "2021-08-25 11:18:01.369 | INFO     | src.policies:train:109 - Episode 1431\n",
      "2021-08-25 11:18:01.424 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:01.425 | INFO     | src.policies:train:121 - Mean episode return: 164.0\n",
      "2021-08-25 11:18:01.426 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 141.31\n",
      "2021-08-25 11:18:01.427 | WARNING  | src.policies:train:131 - The actual batch size is 341, instead of 200\n",
      "2021-08-25 11:18:01.433 | INFO     | src.policies:train:157 - Total loss: 0.9970671534538269\n",
      "2021-08-25 11:18:01.436 | INFO     | src.policies:train:103 - Epoch 287 / 800\n",
      "2021-08-25 11:18:01.437 | INFO     | src.policies:train:109 - Episode 1432\n",
      "2021-08-25 11:18:01.486 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:01.488 | INFO     | src.policies:train:121 - Mean episode return: 149.0\n",
      "2021-08-25 11:18:01.489 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 141.75\n",
      "2021-08-25 11:18:01.489 | INFO     | src.policies:train:109 - Episode 1433\n",
      "2021-08-25 11:18:01.532 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:01.533 | INFO     | src.policies:train:121 - Mean episode return: 113.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:18:01.534 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 141.57\n",
      "2021-08-25 11:18:01.535 | WARNING  | src.policies:train:131 - The actual batch size is 262, instead of 200\n",
      "2021-08-25 11:18:01.540 | INFO     | src.policies:train:157 - Total loss: 0.9961829781532288\n",
      "2021-08-25 11:18:01.542 | INFO     | src.policies:train:103 - Epoch 288 / 800\n",
      "2021-08-25 11:18:01.543 | INFO     | src.policies:train:109 - Episode 1434\n",
      "2021-08-25 11:18:01.610 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:01.611 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:01.612 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 142.02\n",
      "2021-08-25 11:18:01.617 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:01.621 | INFO     | src.policies:train:103 - Epoch 289 / 800\n",
      "2021-08-25 11:18:01.622 | INFO     | src.policies:train:109 - Episode 1435\n",
      "2021-08-25 11:18:01.686 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:01.687 | INFO     | src.policies:train:121 - Mean episode return: 173.0\n",
      "2021-08-25 11:18:01.689 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 142.81\n",
      "2021-08-25 11:18:01.690 | INFO     | src.policies:train:109 - Episode 1436\n",
      "2021-08-25 11:18:01.746 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:01.747 | INFO     | src.policies:train:121 - Mean episode return: 145.0\n",
      "2021-08-25 11:18:01.748 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 143.56\n",
      "2021-08-25 11:18:01.749 | WARNING  | src.policies:train:131 - The actual batch size is 318, instead of 200\n",
      "2021-08-25 11:18:01.757 | INFO     | src.policies:train:157 - Total loss: 0.9968552589416504\n",
      "2021-08-25 11:18:01.762 | INFO     | src.policies:train:103 - Epoch 290 / 800\n",
      "2021-08-25 11:18:01.763 | INFO     | src.policies:train:109 - Episode 1437\n",
      "2021-08-25 11:18:01.799 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:01.800 | INFO     | src.policies:train:121 - Mean episode return: 97.0\n",
      "2021-08-25 11:18:01.801 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 143.45\n",
      "2021-08-25 11:18:01.802 | INFO     | src.policies:train:109 - Episode 1438\n",
      "2021-08-25 11:18:01.861 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:01.862 | INFO     | src.policies:train:121 - Mean episode return: 172.0\n",
      "2021-08-25 11:18:01.863 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 144.28\n",
      "2021-08-25 11:18:01.864 | WARNING  | src.policies:train:131 - The actual batch size is 269, instead of 200\n",
      "2021-08-25 11:18:01.869 | INFO     | src.policies:train:157 - Total loss: 0.9962825179100037\n",
      "2021-08-25 11:18:01.872 | INFO     | src.policies:train:103 - Epoch 291 / 800\n",
      "2021-08-25 11:18:01.873 | INFO     | src.policies:train:109 - Episode 1439\n",
      "2021-08-25 11:18:01.925 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:01.926 | INFO     | src.policies:train:121 - Mean episode return: 154.0\n",
      "2021-08-25 11:18:01.927 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 144.53\n",
      "2021-08-25 11:18:01.928 | INFO     | src.policies:train:109 - Episode 1440\n",
      "2021-08-25 11:18:01.997 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:01.998 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:01.999 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 145.8\n",
      "2021-08-25 11:18:02.000 | WARNING  | src.policies:train:131 - The actual batch size is 354, instead of 200\n",
      "2021-08-25 11:18:02.006 | INFO     | src.policies:train:157 - Total loss: 0.9971749186515808\n",
      "2021-08-25 11:18:02.008 | INFO     | src.policies:train:103 - Epoch 292 / 800\n",
      "2021-08-25 11:18:02.010 | INFO     | src.policies:train:109 - Episode 1441\n",
      "2021-08-25 11:18:02.055 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:02.057 | INFO     | src.policies:train:121 - Mean episode return: 132.0\n",
      "2021-08-25 11:18:02.058 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 145.79\n",
      "2021-08-25 11:18:02.058 | INFO     | src.policies:train:109 - Episode 1442\n",
      "2021-08-25 11:18:02.118 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:02.119 | INFO     | src.policies:train:121 - Mean episode return: 169.0\n",
      "2021-08-25 11:18:02.120 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 145.83\n",
      "2021-08-25 11:18:02.121 | WARNING  | src.policies:train:131 - The actual batch size is 301, instead of 200\n",
      "2021-08-25 11:18:02.127 | INFO     | src.policies:train:157 - Total loss: 0.9966776967048645\n",
      "2021-08-25 11:18:02.129 | INFO     | src.policies:train:103 - Epoch 293 / 800\n",
      "2021-08-25 11:18:02.130 | INFO     | src.policies:train:109 - Episode 1443\n",
      "2021-08-25 11:18:02.174 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:02.176 | INFO     | src.policies:train:121 - Mean episode return: 130.0\n",
      "2021-08-25 11:18:02.177 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 145.13\n",
      "2021-08-25 11:18:02.177 | INFO     | src.policies:train:109 - Episode 1444\n",
      "2021-08-25 11:18:02.247 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:02.249 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:02.249 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 146.05\n",
      "2021-08-25 11:18:02.250 | WARNING  | src.policies:train:131 - The actual batch size is 330, instead of 200\n",
      "2021-08-25 11:18:02.256 | INFO     | src.policies:train:157 - Total loss: 0.9969694018363953\n",
      "2021-08-25 11:18:02.259 | INFO     | src.policies:train:103 - Epoch 294 / 800\n",
      "2021-08-25 11:18:02.260 | INFO     | src.policies:train:109 - Episode 1445\n",
      "2021-08-25 11:18:02.310 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:02.311 | INFO     | src.policies:train:121 - Mean episode return: 149.0\n",
      "2021-08-25 11:18:02.312 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 146.28\n",
      "2021-08-25 11:18:02.313 | INFO     | src.policies:train:109 - Episode 1446\n",
      "2021-08-25 11:18:02.382 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:02.384 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:02.384 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 147.47\n",
      "2021-08-25 11:18:02.385 | WARNING  | src.policies:train:131 - The actual batch size is 349, instead of 200\n",
      "2021-08-25 11:18:02.392 | INFO     | src.policies:train:157 - Total loss: 0.997134804725647\n",
      "2021-08-25 11:18:02.394 | INFO     | src.policies:train:103 - Epoch 295 / 800\n",
      "2021-08-25 11:18:02.395 | INFO     | src.policies:train:109 - Episode 1447\n",
      "2021-08-25 11:18:02.464 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:02.465 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:02.466 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 148.59\n",
      "2021-08-25 11:18:02.471 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:02.474 | INFO     | src.policies:train:103 - Epoch 296 / 800\n",
      "2021-08-25 11:18:02.475 | INFO     | src.policies:train:109 - Episode 1448\n",
      "2021-08-25 11:18:02.543 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:02.545 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:02.546 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 149.55\n",
      "2021-08-25 11:18:02.551 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:02.553 | INFO     | src.policies:train:103 - Epoch 297 / 800\n",
      "2021-08-25 11:18:02.554 | INFO     | src.policies:train:109 - Episode 1449\n",
      "2021-08-25 11:18:02.622 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:18:02.624 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:02.625 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 151.04\n",
      "2021-08-25 11:18:02.630 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:02.632 | INFO     | src.policies:train:103 - Epoch 298 / 800\n",
      "2021-08-25 11:18:02.633 | INFO     | src.policies:train:109 - Episode 1450\n",
      "2021-08-25 11:18:02.675 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:02.677 | INFO     | src.policies:train:121 - Mean episode return: 123.0\n",
      "2021-08-25 11:18:02.678 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 151.53\n",
      "2021-08-25 11:18:02.678 | INFO     | src.policies:train:109 - Episode 1451\n",
      "2021-08-25 11:18:02.721 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:02.722 | INFO     | src.policies:train:121 - Mean episode return: 123.0\n",
      "2021-08-25 11:18:02.723 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 152.05\n",
      "2021-08-25 11:18:02.724 | WARNING  | src.policies:train:131 - The actual batch size is 246, instead of 200\n",
      "2021-08-25 11:18:02.729 | INFO     | src.policies:train:157 - Total loss: 0.995934784412384\n",
      "2021-08-25 11:18:02.732 | INFO     | src.policies:train:103 - Epoch 299 / 800\n",
      "2021-08-25 11:18:02.733 | INFO     | src.policies:train:109 - Episode 1452\n",
      "2021-08-25 11:18:02.800 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:02.802 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:02.803 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 152.74\n",
      "2021-08-25 11:18:02.808 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:02.810 | INFO     | src.policies:train:103 - Epoch 300 / 800\n",
      "2021-08-25 11:18:02.811 | INFO     | src.policies:train:109 - Episode 1453\n",
      "2021-08-25 11:18:02.873 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:02.875 | INFO     | src.policies:train:121 - Mean episode return: 182.0\n",
      "2021-08-25 11:18:02.876 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 153.64\n",
      "2021-08-25 11:18:02.876 | INFO     | src.policies:train:109 - Episode 1454\n",
      "2021-08-25 11:18:02.936 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:02.937 | INFO     | src.policies:train:121 - Mean episode return: 175.0\n",
      "2021-08-25 11:18:02.938 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 154.31\n",
      "2021-08-25 11:18:02.939 | WARNING  | src.policies:train:131 - The actual batch size is 357, instead of 200\n",
      "2021-08-25 11:18:02.945 | INFO     | src.policies:train:157 - Total loss: 0.997198760509491\n",
      "2021-08-25 11:18:02.947 | INFO     | src.policies:train:103 - Epoch 301 / 800\n",
      "2021-08-25 11:18:02.949 | INFO     | src.policies:train:109 - Episode 1455\n",
      "2021-08-25 11:18:03.017 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:03.018 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:03.019 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 155.25\n",
      "2021-08-25 11:18:03.024 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:03.027 | INFO     | src.policies:train:103 - Epoch 302 / 800\n",
      "2021-08-25 11:18:03.028 | INFO     | src.policies:train:109 - Episode 1456\n",
      "2021-08-25 11:18:03.083 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:03.084 | INFO     | src.policies:train:121 - Mean episode return: 152.0\n",
      "2021-08-25 11:18:03.085 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 154.77\n",
      "2021-08-25 11:18:03.086 | INFO     | src.policies:train:109 - Episode 1457\n",
      "2021-08-25 11:18:03.150 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:03.151 | INFO     | src.policies:train:121 - Mean episode return: 182.0\n",
      "2021-08-25 11:18:03.152 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 155.46\n",
      "2021-08-25 11:18:03.153 | WARNING  | src.policies:train:131 - The actual batch size is 334, instead of 200\n",
      "2021-08-25 11:18:03.159 | INFO     | src.policies:train:157 - Total loss: 0.9970057010650635\n",
      "2021-08-25 11:18:03.161 | INFO     | src.policies:train:103 - Epoch 303 / 800\n",
      "2021-08-25 11:18:03.162 | INFO     | src.policies:train:109 - Episode 1458\n",
      "2021-08-25 11:18:03.221 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:03.223 | INFO     | src.policies:train:121 - Mean episode return: 180.0\n",
      "2021-08-25 11:18:03.224 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 156.79\n",
      "2021-08-25 11:18:03.225 | INFO     | src.policies:train:109 - Episode 1459\n",
      "2021-08-25 11:18:03.294 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:03.295 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:03.296 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 157.87\n",
      "2021-08-25 11:18:03.297 | WARNING  | src.policies:train:131 - The actual batch size is 380, instead of 200\n",
      "2021-08-25 11:18:03.303 | INFO     | src.policies:train:157 - Total loss: 0.9973682165145874\n",
      "2021-08-25 11:18:03.306 | INFO     | src.policies:train:103 - Epoch 304 / 800\n",
      "2021-08-25 11:18:03.307 | INFO     | src.policies:train:109 - Episode 1460\n",
      "2021-08-25 11:18:03.371 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:03.373 | INFO     | src.policies:train:121 - Mean episode return: 182.0\n",
      "2021-08-25 11:18:03.373 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 158.24\n",
      "2021-08-25 11:18:03.374 | INFO     | src.policies:train:109 - Episode 1461\n",
      "2021-08-25 11:18:03.426 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:03.428 | INFO     | src.policies:train:121 - Mean episode return: 150.0\n",
      "2021-08-25 11:18:03.428 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 159.05\n",
      "2021-08-25 11:18:03.430 | WARNING  | src.policies:train:131 - The actual batch size is 332, instead of 200\n",
      "2021-08-25 11:18:03.436 | INFO     | src.policies:train:157 - Total loss: 0.9969877600669861\n",
      "2021-08-25 11:18:03.438 | INFO     | src.policies:train:103 - Epoch 305 / 800\n",
      "2021-08-25 11:18:03.439 | INFO     | src.policies:train:109 - Episode 1462\n",
      "2021-08-25 11:18:03.508 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:03.510 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:03.511 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 160.79\n",
      "2021-08-25 11:18:03.516 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:03.518 | INFO     | src.policies:train:103 - Epoch 306 / 800\n",
      "2021-08-25 11:18:03.519 | INFO     | src.policies:train:109 - Episode 1463\n",
      "2021-08-25 11:18:03.573 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:03.575 | INFO     | src.policies:train:121 - Mean episode return: 160.0\n",
      "2021-08-25 11:18:03.576 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 161.31\n",
      "2021-08-25 11:18:03.577 | INFO     | src.policies:train:109 - Episode 1464\n",
      "2021-08-25 11:18:03.634 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:03.635 | INFO     | src.policies:train:121 - Mean episode return: 160.0\n",
      "2021-08-25 11:18:03.636 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 161.66\n",
      "2021-08-25 11:18:03.637 | WARNING  | src.policies:train:131 - The actual batch size is 320, instead of 200\n",
      "2021-08-25 11:18:03.643 | INFO     | src.policies:train:157 - Total loss: 0.9968748092651367\n",
      "2021-08-25 11:18:03.645 | INFO     | src.policies:train:103 - Epoch 307 / 800\n",
      "2021-08-25 11:18:03.646 | INFO     | src.policies:train:109 - Episode 1465\n",
      "2021-08-25 11:18:03.684 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:18:03.685 | INFO     | src.policies:train:121 - Mean episode return: 104.0\n",
      "2021-08-25 11:18:03.686 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 162.47\n",
      "2021-08-25 11:18:03.687 | INFO     | src.policies:train:109 - Episode 1466\n",
      "2021-08-25 11:18:03.742 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:03.744 | INFO     | src.policies:train:121 - Mean episode return: 156.0\n",
      "2021-08-25 11:18:03.745 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 162.03\n",
      "2021-08-25 11:18:03.745 | WARNING  | src.policies:train:131 - The actual batch size is 260, instead of 200\n",
      "2021-08-25 11:18:03.751 | INFO     | src.policies:train:157 - Total loss: 0.996153712272644\n",
      "2021-08-25 11:18:03.754 | INFO     | src.policies:train:103 - Epoch 308 / 800\n",
      "2021-08-25 11:18:03.755 | INFO     | src.policies:train:109 - Episode 1467\n",
      "2021-08-25 11:18:03.815 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:03.817 | INFO     | src.policies:train:121 - Mean episode return: 175.0\n",
      "2021-08-25 11:18:03.818 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 162.68\n",
      "2021-08-25 11:18:03.818 | INFO     | src.policies:train:109 - Episode 1468\n",
      "2021-08-25 11:18:03.869 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:03.871 | INFO     | src.policies:train:121 - Mean episode return: 144.0\n",
      "2021-08-25 11:18:03.872 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 162.4\n",
      "2021-08-25 11:18:03.872 | WARNING  | src.policies:train:131 - The actual batch size is 319, instead of 200\n",
      "2021-08-25 11:18:03.878 | INFO     | src.policies:train:157 - Total loss: 0.9968652725219727\n",
      "2021-08-25 11:18:03.881 | INFO     | src.policies:train:103 - Epoch 309 / 800\n",
      "2021-08-25 11:18:03.882 | INFO     | src.policies:train:109 - Episode 1469\n",
      "2021-08-25 11:18:03.933 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:03.935 | INFO     | src.policies:train:121 - Mean episode return: 155.0\n",
      "2021-08-25 11:18:03.936 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 161.95\n",
      "2021-08-25 11:18:03.937 | INFO     | src.policies:train:109 - Episode 1470\n",
      "2021-08-25 11:18:04.007 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:04.008 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:04.009 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 162.33\n",
      "2021-08-25 11:18:04.010 | WARNING  | src.policies:train:131 - The actual batch size is 355, instead of 200\n",
      "2021-08-25 11:18:04.016 | INFO     | src.policies:train:157 - Total loss: 0.9971829056739807\n",
      "2021-08-25 11:18:04.019 | INFO     | src.policies:train:103 - Epoch 310 / 800\n",
      "2021-08-25 11:18:04.020 | INFO     | src.policies:train:109 - Episode 1471\n",
      "2021-08-25 11:18:04.082 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:04.083 | INFO     | src.policies:train:121 - Mean episode return: 184.0\n",
      "2021-08-25 11:18:04.084 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 162.53\n",
      "2021-08-25 11:18:04.085 | INFO     | src.policies:train:109 - Episode 1472\n",
      "2021-08-25 11:18:04.147 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:04.149 | INFO     | src.policies:train:121 - Mean episode return: 174.0\n",
      "2021-08-25 11:18:04.150 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 162.87\n",
      "2021-08-25 11:18:04.151 | WARNING  | src.policies:train:131 - The actual batch size is 358, instead of 200\n",
      "2021-08-25 11:18:04.157 | INFO     | src.policies:train:157 - Total loss: 0.9972065687179565\n",
      "2021-08-25 11:18:04.160 | INFO     | src.policies:train:103 - Epoch 311 / 800\n",
      "2021-08-25 11:18:04.161 | INFO     | src.policies:train:109 - Episode 1473\n",
      "2021-08-25 11:18:04.230 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:04.232 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:04.233 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 164.03\n",
      "2021-08-25 11:18:04.239 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:04.242 | INFO     | src.policies:train:103 - Epoch 312 / 800\n",
      "2021-08-25 11:18:04.243 | INFO     | src.policies:train:109 - Episode 1474\n",
      "2021-08-25 11:18:04.291 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:04.292 | INFO     | src.policies:train:121 - Mean episode return: 129.0\n",
      "2021-08-25 11:18:04.294 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 163.94\n",
      "2021-08-25 11:18:04.295 | INFO     | src.policies:train:109 - Episode 1475\n",
      "2021-08-25 11:18:04.355 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:04.356 | INFO     | src.policies:train:121 - Mean episode return: 165.0\n",
      "2021-08-25 11:18:04.357 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 164.21\n",
      "2021-08-25 11:18:04.358 | WARNING  | src.policies:train:131 - The actual batch size is 294, instead of 200\n",
      "2021-08-25 11:18:04.365 | INFO     | src.policies:train:157 - Total loss: 0.996598482131958\n",
      "2021-08-25 11:18:04.369 | INFO     | src.policies:train:103 - Epoch 313 / 800\n",
      "2021-08-25 11:18:04.370 | INFO     | src.policies:train:109 - Episode 1476\n",
      "2021-08-25 11:18:04.439 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:04.440 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:04.441 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 165.16\n",
      "2021-08-25 11:18:04.447 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:04.450 | INFO     | src.policies:train:103 - Epoch 314 / 800\n",
      "2021-08-25 11:18:04.451 | INFO     | src.policies:train:109 - Episode 1477\n",
      "2021-08-25 11:18:04.520 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:04.521 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:04.522 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 165.16\n",
      "2021-08-25 11:18:04.528 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:04.531 | INFO     | src.policies:train:103 - Epoch 315 / 800\n",
      "2021-08-25 11:18:04.532 | INFO     | src.policies:train:109 - Episode 1478\n",
      "2021-08-25 11:18:04.589 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:04.590 | INFO     | src.policies:train:121 - Mean episode return: 159.0\n",
      "2021-08-25 11:18:04.592 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 164.75\n",
      "2021-08-25 11:18:04.593 | INFO     | src.policies:train:109 - Episode 1479\n",
      "2021-08-25 11:18:04.617 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:04.618 | INFO     | src.policies:train:121 - Mean episode return: 57.0\n",
      "2021-08-25 11:18:04.619 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 163.69\n",
      "2021-08-25 11:18:04.620 | WARNING  | src.policies:train:131 - The actual batch size is 216, instead of 200\n",
      "2021-08-25 11:18:04.626 | INFO     | src.policies:train:157 - Total loss: 0.9953701496124268\n",
      "2021-08-25 11:18:04.629 | INFO     | src.policies:train:103 - Epoch 316 / 800\n",
      "2021-08-25 11:18:04.630 | INFO     | src.policies:train:109 - Episode 1480\n",
      "2021-08-25 11:18:04.648 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:04.650 | INFO     | src.policies:train:121 - Mean episode return: 44.0\n",
      "2021-08-25 11:18:04.651 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 163.01\n",
      "2021-08-25 11:18:04.652 | INFO     | src.policies:train:109 - Episode 1481\n",
      "2021-08-25 11:18:04.705 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:04.706 | INFO     | src.policies:train:121 - Mean episode return: 150.0\n",
      "2021-08-25 11:18:04.707 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 162.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:18:04.708 | INFO     | src.policies:train:109 - Episode 1482\n",
      "2021-08-25 11:18:04.777 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:04.778 | INFO     | src.policies:train:121 - Mean episode return: 190.0\n",
      "2021-08-25 11:18:04.779 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 162.75\n",
      "2021-08-25 11:18:04.780 | WARNING  | src.policies:train:131 - The actual batch size is 384, instead of 200\n",
      "2021-08-25 11:18:04.787 | INFO     | src.policies:train:157 - Total loss: 0.9973956346511841\n",
      "2021-08-25 11:18:04.789 | INFO     | src.policies:train:103 - Epoch 317 / 800\n",
      "2021-08-25 11:18:04.791 | INFO     | src.policies:train:109 - Episode 1483\n",
      "2021-08-25 11:18:04.842 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:04.844 | INFO     | src.policies:train:121 - Mean episode return: 144.0\n",
      "2021-08-25 11:18:04.845 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 162.59\n",
      "2021-08-25 11:18:04.845 | INFO     | src.policies:train:109 - Episode 1484\n",
      "2021-08-25 11:18:04.914 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:04.916 | INFO     | src.policies:train:121 - Mean episode return: 198.0\n",
      "2021-08-25 11:18:04.916 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 163.32\n",
      "2021-08-25 11:18:04.918 | WARNING  | src.policies:train:131 - The actual batch size is 342, instead of 200\n",
      "2021-08-25 11:18:04.924 | INFO     | src.policies:train:157 - Total loss: 0.9970759153366089\n",
      "2021-08-25 11:18:04.927 | INFO     | src.policies:train:103 - Epoch 318 / 800\n",
      "2021-08-25 11:18:04.928 | INFO     | src.policies:train:109 - Episode 1485\n",
      "2021-08-25 11:18:04.983 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:04.985 | INFO     | src.policies:train:121 - Mean episode return: 149.0\n",
      "2021-08-25 11:18:04.986 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 162.81\n",
      "2021-08-25 11:18:04.987 | INFO     | src.policies:train:109 - Episode 1486\n",
      "2021-08-25 11:18:05.038 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:05.039 | INFO     | src.policies:train:121 - Mean episode return: 137.0\n",
      "2021-08-25 11:18:05.040 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 162.18\n",
      "2021-08-25 11:18:05.041 | WARNING  | src.policies:train:131 - The actual batch size is 286, instead of 200\n",
      "2021-08-25 11:18:05.048 | INFO     | src.policies:train:157 - Total loss: 0.9965033531188965\n",
      "2021-08-25 11:18:05.051 | INFO     | src.policies:train:103 - Epoch 319 / 800\n",
      "2021-08-25 11:18:05.052 | INFO     | src.policies:train:109 - Episode 1487\n",
      "2021-08-25 11:18:05.104 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:05.106 | INFO     | src.policies:train:121 - Mean episode return: 147.0\n",
      "2021-08-25 11:18:05.106 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 161.65\n",
      "2021-08-25 11:18:05.107 | INFO     | src.policies:train:109 - Episode 1488\n",
      "2021-08-25 11:18:05.169 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:05.170 | INFO     | src.policies:train:121 - Mean episode return: 170.0\n",
      "2021-08-25 11:18:05.171 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 161.38\n",
      "2021-08-25 11:18:05.172 | WARNING  | src.policies:train:131 - The actual batch size is 317, instead of 200\n",
      "2021-08-25 11:18:05.180 | INFO     | src.policies:train:157 - Total loss: 0.9968451261520386\n",
      "2021-08-25 11:18:05.182 | INFO     | src.policies:train:103 - Epoch 320 / 800\n",
      "2021-08-25 11:18:05.183 | INFO     | src.policies:train:109 - Episode 1489\n",
      "2021-08-25 11:18:05.230 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:05.231 | INFO     | src.policies:train:121 - Mean episode return: 133.0\n",
      "2021-08-25 11:18:05.233 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 162.43\n",
      "2021-08-25 11:18:05.233 | INFO     | src.policies:train:109 - Episode 1490\n",
      "2021-08-25 11:18:05.300 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:05.301 | INFO     | src.policies:train:121 - Mean episode return: 187.0\n",
      "2021-08-25 11:18:05.302 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 162.88\n",
      "2021-08-25 11:18:05.303 | WARNING  | src.policies:train:131 - The actual batch size is 320, instead of 200\n",
      "2021-08-25 11:18:05.311 | INFO     | src.policies:train:157 - Total loss: 0.9968748092651367\n",
      "2021-08-25 11:18:05.314 | INFO     | src.policies:train:103 - Epoch 321 / 800\n",
      "2021-08-25 11:18:05.316 | INFO     | src.policies:train:109 - Episode 1491\n",
      "2021-08-25 11:18:05.385 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:05.386 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:05.387 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 163.28\n",
      "2021-08-25 11:18:05.393 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:05.396 | INFO     | src.policies:train:103 - Epoch 322 / 800\n",
      "2021-08-25 11:18:05.397 | INFO     | src.policies:train:109 - Episode 1492\n",
      "2021-08-25 11:18:05.452 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:05.453 | INFO     | src.policies:train:121 - Mean episode return: 156.0\n",
      "2021-08-25 11:18:05.455 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 162.91\n",
      "2021-08-25 11:18:05.456 | INFO     | src.policies:train:109 - Episode 1493\n",
      "2021-08-25 11:18:05.505 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:05.506 | INFO     | src.policies:train:121 - Mean episode return: 135.0\n",
      "2021-08-25 11:18:05.507 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 163.38\n",
      "2021-08-25 11:18:05.508 | WARNING  | src.policies:train:131 - The actual batch size is 291, instead of 200\n",
      "2021-08-25 11:18:05.516 | INFO     | src.policies:train:157 - Total loss: 0.9965634942054749\n",
      "2021-08-25 11:18:05.518 | INFO     | src.policies:train:103 - Epoch 323 / 800\n",
      "2021-08-25 11:18:05.520 | INFO     | src.policies:train:109 - Episode 1494\n",
      "2021-08-25 11:18:05.568 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:05.569 | INFO     | src.policies:train:121 - Mean episode return: 134.0\n",
      "2021-08-25 11:18:05.570 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 162.74\n",
      "2021-08-25 11:18:05.571 | INFO     | src.policies:train:109 - Episode 1495\n",
      "2021-08-25 11:18:05.633 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:05.634 | INFO     | src.policies:train:121 - Mean episode return: 166.0\n",
      "2021-08-25 11:18:05.635 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 162.66\n",
      "2021-08-25 11:18:05.636 | WARNING  | src.policies:train:131 - The actual batch size is 300, instead of 200\n",
      "2021-08-25 11:18:05.641 | INFO     | src.policies:train:157 - Total loss: 0.9966664910316467\n",
      "2021-08-25 11:18:05.644 | INFO     | src.policies:train:103 - Epoch 324 / 800\n",
      "2021-08-25 11:18:05.645 | INFO     | src.policies:train:109 - Episode 1496\n",
      "2021-08-25 11:18:05.713 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:05.714 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:05.715 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 163.25\n",
      "2021-08-25 11:18:05.720 | INFO     | src.policies:train:157 - Total loss: 0.9950000047683716\n",
      "2021-08-25 11:18:05.722 | INFO     | src.policies:train:103 - Epoch 325 / 800\n",
      "2021-08-25 11:18:05.723 | INFO     | src.policies:train:109 - Episode 1497\n",
      "2021-08-25 11:18:05.778 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:05.780 | INFO     | src.policies:train:121 - Mean episode return: 162.0\n",
      "2021-08-25 11:18:05.781 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 163.78\n",
      "2021-08-25 11:18:05.782 | INFO     | src.policies:train:109 - Episode 1498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:18:05.830 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:05.831 | INFO     | src.policies:train:121 - Mean episode return: 134.0\n",
      "2021-08-25 11:18:05.832 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 163.12\n",
      "2021-08-25 11:18:05.833 | WARNING  | src.policies:train:131 - The actual batch size is 296, instead of 200\n",
      "2021-08-25 11:18:05.839 | INFO     | src.policies:train:157 - Total loss: 0.9966213703155518\n",
      "2021-08-25 11:18:05.842 | INFO     | src.policies:train:103 - Epoch 326 / 800\n",
      "2021-08-25 11:18:05.843 | INFO     | src.policies:train:109 - Episode 1499\n",
      "2021-08-25 11:18:05.891 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:05.893 | INFO     | src.policies:train:121 - Mean episode return: 143.0\n",
      "2021-08-25 11:18:05.894 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 162.99\n",
      "2021-08-25 11:18:05.894 | INFO     | src.policies:train:109 - Episode 1500\n",
      "2021-08-25 11:18:05.951 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:05.952 | INFO     | src.policies:train:121 - Mean episode return: 167.0\n",
      "2021-08-25 11:18:05.953 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 162.81\n",
      "2021-08-25 11:18:05.954 | WARNING  | src.policies:train:131 - The actual batch size is 310, instead of 200\n",
      "2021-08-25 11:18:05.961 | INFO     | src.policies:train:157 - Total loss: 0.9967740774154663\n",
      "2021-08-25 11:18:05.963 | INFO     | src.policies:train:103 - Epoch 327 / 800\n",
      "2021-08-25 11:18:05.964 | INFO     | src.policies:train:109 - Episode 1501\n",
      "2021-08-25 11:18:06.024 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:06.026 | INFO     | src.policies:train:121 - Mean episode return: 176.0\n",
      "2021-08-25 11:18:06.027 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 163.94\n",
      "2021-08-25 11:18:06.028 | INFO     | src.policies:train:109 - Episode 1502\n",
      "2021-08-25 11:18:06.085 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:06.086 | INFO     | src.policies:train:121 - Mean episode return: 167.0\n",
      "2021-08-25 11:18:06.087 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 164.16\n",
      "2021-08-25 11:18:06.088 | WARNING  | src.policies:train:131 - The actual batch size is 343, instead of 200\n",
      "2021-08-25 11:18:06.094 | INFO     | src.policies:train:157 - Total loss: 0.9970843195915222\n",
      "2021-08-25 11:18:06.097 | INFO     | src.policies:train:103 - Epoch 328 / 800\n",
      "2021-08-25 11:18:06.098 | INFO     | src.policies:train:109 - Episode 1503\n",
      "2021-08-25 11:18:06.151 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:06.153 | INFO     | src.policies:train:121 - Mean episode return: 160.0\n",
      "2021-08-25 11:18:06.154 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 164.54\n",
      "2021-08-25 11:18:06.154 | INFO     | src.policies:train:109 - Episode 1504\n",
      "2021-08-25 11:18:06.201 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:06.202 | INFO     | src.policies:train:121 - Mean episode return: 135.0\n",
      "2021-08-25 11:18:06.203 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 164.85\n",
      "2021-08-25 11:18:06.204 | WARNING  | src.policies:train:131 - The actual batch size is 295, instead of 200\n",
      "2021-08-25 11:18:06.210 | INFO     | src.policies:train:157 - Total loss: 0.9966100454330444\n",
      "2021-08-25 11:18:06.213 | INFO     | src.policies:train:103 - Epoch 329 / 800\n",
      "2021-08-25 11:18:06.214 | INFO     | src.policies:train:109 - Episode 1505\n",
      "2021-08-25 11:18:06.283 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:06.284 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:06.286 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 164.85\n",
      "2021-08-25 11:18:06.291 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:06.293 | INFO     | src.policies:train:103 - Epoch 330 / 800\n",
      "2021-08-25 11:18:06.294 | INFO     | src.policies:train:109 - Episode 1506\n",
      "2021-08-25 11:18:06.341 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:06.342 | INFO     | src.policies:train:121 - Mean episode return: 137.0\n",
      "2021-08-25 11:18:06.343 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 164.97\n",
      "2021-08-25 11:18:06.344 | INFO     | src.policies:train:109 - Episode 1507\n",
      "2021-08-25 11:18:06.384 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:06.385 | INFO     | src.policies:train:121 - Mean episode return: 109.0\n",
      "2021-08-25 11:18:06.385 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 164.55\n",
      "2021-08-25 11:18:06.386 | WARNING  | src.policies:train:131 - The actual batch size is 246, instead of 200\n",
      "2021-08-25 11:18:06.392 | INFO     | src.policies:train:157 - Total loss: 0.995934784412384\n",
      "2021-08-25 11:18:06.395 | INFO     | src.policies:train:103 - Epoch 331 / 800\n",
      "2021-08-25 11:18:06.395 | INFO     | src.policies:train:109 - Episode 1508\n",
      "2021-08-25 11:18:06.441 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:06.442 | INFO     | src.policies:train:121 - Mean episode return: 130.0\n",
      "2021-08-25 11:18:06.443 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 163.85\n",
      "2021-08-25 11:18:06.444 | INFO     | src.policies:train:109 - Episode 1509\n",
      "2021-08-25 11:18:06.481 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:06.482 | INFO     | src.policies:train:121 - Mean episode return: 105.0\n",
      "2021-08-25 11:18:06.483 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 164.22\n",
      "2021-08-25 11:18:06.484 | WARNING  | src.policies:train:131 - The actual batch size is 235, instead of 200\n",
      "2021-08-25 11:18:06.490 | INFO     | src.policies:train:157 - Total loss: 0.995744526386261\n",
      "2021-08-25 11:18:06.493 | INFO     | src.policies:train:103 - Epoch 332 / 800\n",
      "2021-08-25 11:18:06.494 | INFO     | src.policies:train:109 - Episode 1510\n",
      "2021-08-25 11:18:06.545 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:06.546 | INFO     | src.policies:train:121 - Mean episode return: 149.0\n",
      "2021-08-25 11:18:06.547 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 163.95\n",
      "2021-08-25 11:18:06.548 | INFO     | src.policies:train:109 - Episode 1511\n",
      "2021-08-25 11:18:06.596 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:06.597 | INFO     | src.policies:train:121 - Mean episode return: 135.0\n",
      "2021-08-25 11:18:06.597 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 163.3\n",
      "2021-08-25 11:18:06.598 | WARNING  | src.policies:train:131 - The actual batch size is 284, instead of 200\n",
      "2021-08-25 11:18:06.604 | INFO     | src.policies:train:157 - Total loss: 0.9964788556098938\n",
      "2021-08-25 11:18:06.606 | INFO     | src.policies:train:103 - Epoch 333 / 800\n",
      "2021-08-25 11:18:06.607 | INFO     | src.policies:train:109 - Episode 1512\n",
      "2021-08-25 11:18:06.647 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:06.648 | INFO     | src.policies:train:121 - Mean episode return: 113.0\n",
      "2021-08-25 11:18:06.649 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 162.74\n",
      "2021-08-25 11:18:06.650 | INFO     | src.policies:train:109 - Episode 1513\n",
      "2021-08-25 11:18:06.718 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:06.719 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:06.720 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 162.88\n",
      "2021-08-25 11:18:06.721 | WARNING  | src.policies:train:131 - The actual batch size is 313, instead of 200\n",
      "2021-08-25 11:18:06.727 | INFO     | src.policies:train:157 - Total loss: 0.9968048930168152\n",
      "2021-08-25 11:18:06.729 | INFO     | src.policies:train:103 - Epoch 334 / 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:18:06.730 | INFO     | src.policies:train:109 - Episode 1514\n",
      "2021-08-25 11:18:06.797 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:06.799 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:06.800 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 163.28\n",
      "2021-08-25 11:18:06.804 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:06.807 | INFO     | src.policies:train:103 - Epoch 335 / 800\n",
      "2021-08-25 11:18:06.807 | INFO     | src.policies:train:109 - Episode 1515\n",
      "2021-08-25 11:18:06.857 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:06.859 | INFO     | src.policies:train:121 - Mean episode return: 145.0\n",
      "2021-08-25 11:18:06.860 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 163.0\n",
      "2021-08-25 11:18:06.860 | INFO     | src.policies:train:109 - Episode 1516\n",
      "2021-08-25 11:18:06.911 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:06.913 | INFO     | src.policies:train:121 - Mean episode return: 149.0\n",
      "2021-08-25 11:18:06.914 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 162.49\n",
      "2021-08-25 11:18:06.914 | WARNING  | src.policies:train:131 - The actual batch size is 294, instead of 200\n",
      "2021-08-25 11:18:06.920 | INFO     | src.policies:train:157 - Total loss: 0.9965985417366028\n",
      "2021-08-25 11:18:06.923 | INFO     | src.policies:train:103 - Epoch 336 / 800\n",
      "2021-08-25 11:18:06.924 | INFO     | src.policies:train:109 - Episode 1517\n",
      "2021-08-25 11:18:06.965 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:06.966 | INFO     | src.policies:train:121 - Mean episode return: 117.0\n",
      "2021-08-25 11:18:06.967 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 162.4\n",
      "2021-08-25 11:18:06.968 | INFO     | src.policies:train:109 - Episode 1518\n",
      "2021-08-25 11:18:07.039 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:07.040 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:07.041 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 162.4\n",
      "2021-08-25 11:18:07.042 | WARNING  | src.policies:train:131 - The actual batch size is 317, instead of 200\n",
      "2021-08-25 11:18:07.048 | INFO     | src.policies:train:157 - Total loss: 0.9968452453613281\n",
      "2021-08-25 11:18:07.050 | INFO     | src.policies:train:103 - Epoch 337 / 800\n",
      "2021-08-25 11:18:07.051 | INFO     | src.policies:train:109 - Episode 1519\n",
      "2021-08-25 11:18:07.117 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:07.119 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:07.120 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 162.73\n",
      "2021-08-25 11:18:07.125 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:07.127 | INFO     | src.policies:train:103 - Epoch 338 / 800\n",
      "2021-08-25 11:18:07.128 | INFO     | src.policies:train:109 - Episode 1520\n",
      "2021-08-25 11:18:07.195 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:07.196 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:07.197 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 162.73\n",
      "2021-08-25 11:18:07.202 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:07.204 | INFO     | src.policies:train:103 - Epoch 339 / 800\n",
      "2021-08-25 11:18:07.205 | INFO     | src.policies:train:109 - Episode 1521\n",
      "2021-08-25 11:18:07.239 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:07.240 | INFO     | src.policies:train:121 - Mean episode return: 101.0\n",
      "2021-08-25 11:18:07.241 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 162.13\n",
      "2021-08-25 11:18:07.242 | INFO     | src.policies:train:109 - Episode 1522\n",
      "2021-08-25 11:18:07.281 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:07.282 | INFO     | src.policies:train:121 - Mean episode return: 106.0\n",
      "2021-08-25 11:18:07.283 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 161.19\n",
      "2021-08-25 11:18:07.283 | WARNING  | src.policies:train:131 - The actual batch size is 207, instead of 200\n",
      "2021-08-25 11:18:07.289 | INFO     | src.policies:train:157 - Total loss: 0.9951688051223755\n",
      "2021-08-25 11:18:07.292 | INFO     | src.policies:train:103 - Epoch 340 / 800\n",
      "2021-08-25 11:18:07.293 | INFO     | src.policies:train:109 - Episode 1523\n",
      "2021-08-25 11:18:07.340 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:07.341 | INFO     | src.policies:train:121 - Mean episode return: 136.0\n",
      "2021-08-25 11:18:07.342 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 160.55\n",
      "2021-08-25 11:18:07.343 | INFO     | src.policies:train:109 - Episode 1524\n",
      "2021-08-25 11:18:07.411 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:07.412 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:07.413 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 161.03\n",
      "2021-08-25 11:18:07.414 | WARNING  | src.policies:train:131 - The actual batch size is 336, instead of 200\n",
      "2021-08-25 11:18:07.419 | INFO     | src.policies:train:157 - Total loss: 0.9970236420631409\n",
      "2021-08-25 11:18:07.422 | INFO     | src.policies:train:103 - Epoch 341 / 800\n",
      "2021-08-25 11:18:07.423 | INFO     | src.policies:train:109 - Episode 1525\n",
      "2021-08-25 11:18:07.490 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:07.491 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:07.492 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 161.32\n",
      "2021-08-25 11:18:07.497 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:07.499 | INFO     | src.policies:train:103 - Epoch 342 / 800\n",
      "2021-08-25 11:18:07.500 | INFO     | src.policies:train:109 - Episode 1526\n",
      "2021-08-25 11:18:07.566 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:07.568 | INFO     | src.policies:train:121 - Mean episode return: 199.0\n",
      "2021-08-25 11:18:07.569 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 161.55\n",
      "2021-08-25 11:18:07.569 | INFO     | src.policies:train:109 - Episode 1527\n",
      "2021-08-25 11:18:07.640 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:07.642 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:07.643 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 161.98\n",
      "2021-08-25 11:18:07.643 | WARNING  | src.policies:train:131 - The actual batch size is 399, instead of 200\n",
      "2021-08-25 11:18:07.650 | INFO     | src.policies:train:157 - Total loss: 0.99749356508255\n",
      "2021-08-25 11:18:07.652 | INFO     | src.policies:train:103 - Epoch 343 / 800\n",
      "2021-08-25 11:18:07.653 | INFO     | src.policies:train:109 - Episode 1528\n",
      "2021-08-25 11:18:07.721 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:07.722 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:07.723 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 162.0\n",
      "2021-08-25 11:18:07.728 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:07.730 | INFO     | src.policies:train:103 - Epoch 344 / 800\n",
      "2021-08-25 11:18:07.731 | INFO     | src.policies:train:109 - Episode 1529\n",
      "2021-08-25 11:18:07.781 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:07.782 | INFO     | src.policies:train:121 - Mean episode return: 146.0\n",
      "2021-08-25 11:18:07.783 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 161.56\n",
      "2021-08-25 11:18:07.784 | INFO     | src.policies:train:109 - Episode 1530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:18:07.832 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:07.834 | INFO     | src.policies:train:121 - Mean episode return: 139.0\n",
      "2021-08-25 11:18:07.834 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 161.18\n",
      "2021-08-25 11:18:07.836 | WARNING  | src.policies:train:131 - The actual batch size is 285, instead of 200\n",
      "2021-08-25 11:18:07.841 | INFO     | src.policies:train:157 - Total loss: 0.996491014957428\n",
      "2021-08-25 11:18:07.843 | INFO     | src.policies:train:103 - Epoch 345 / 800\n",
      "2021-08-25 11:18:07.844 | INFO     | src.policies:train:109 - Episode 1531\n",
      "2021-08-25 11:18:07.874 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:07.876 | INFO     | src.policies:train:121 - Mean episode return: 83.0\n",
      "2021-08-25 11:18:07.877 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 160.37\n",
      "2021-08-25 11:18:07.878 | INFO     | src.policies:train:109 - Episode 1532\n",
      "2021-08-25 11:18:07.945 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:07.946 | INFO     | src.policies:train:121 - Mean episode return: 189.0\n",
      "2021-08-25 11:18:07.947 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 160.77\n",
      "2021-08-25 11:18:07.948 | WARNING  | src.policies:train:131 - The actual batch size is 272, instead of 200\n",
      "2021-08-25 11:18:07.954 | INFO     | src.policies:train:157 - Total loss: 0.99632328748703\n",
      "2021-08-25 11:18:07.956 | INFO     | src.policies:train:103 - Epoch 346 / 800\n",
      "2021-08-25 11:18:07.957 | INFO     | src.policies:train:109 - Episode 1533\n",
      "2021-08-25 11:18:08.024 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:08.025 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:08.026 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 161.64\n",
      "2021-08-25 11:18:08.031 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:08.034 | INFO     | src.policies:train:103 - Epoch 347 / 800\n",
      "2021-08-25 11:18:08.035 | INFO     | src.policies:train:109 - Episode 1534\n",
      "2021-08-25 11:18:08.102 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:08.104 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:08.105 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 161.64\n",
      "2021-08-25 11:18:08.110 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:08.112 | INFO     | src.policies:train:103 - Epoch 348 / 800\n",
      "2021-08-25 11:18:08.113 | INFO     | src.policies:train:109 - Episode 1535\n",
      "2021-08-25 11:18:08.170 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:08.171 | INFO     | src.policies:train:121 - Mean episode return: 168.0\n",
      "2021-08-25 11:18:08.172 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 161.59\n",
      "2021-08-25 11:18:08.173 | INFO     | src.policies:train:109 - Episode 1536\n",
      "2021-08-25 11:18:08.243 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:08.244 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:08.245 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 162.14\n",
      "2021-08-25 11:18:08.245 | WARNING  | src.policies:train:131 - The actual batch size is 368, instead of 200\n",
      "2021-08-25 11:18:08.252 | INFO     | src.policies:train:157 - Total loss: 0.9972825050354004\n",
      "2021-08-25 11:18:08.255 | INFO     | src.policies:train:103 - Epoch 349 / 800\n",
      "2021-08-25 11:18:08.256 | INFO     | src.policies:train:109 - Episode 1537\n",
      "2021-08-25 11:18:08.316 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:08.317 | INFO     | src.policies:train:121 - Mean episode return: 172.0\n",
      "2021-08-25 11:18:08.318 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 162.89\n",
      "2021-08-25 11:18:08.319 | INFO     | src.policies:train:109 - Episode 1538\n",
      "2021-08-25 11:18:08.370 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:08.371 | INFO     | src.policies:train:121 - Mean episode return: 148.0\n",
      "2021-08-25 11:18:08.372 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 162.65\n",
      "2021-08-25 11:18:08.373 | WARNING  | src.policies:train:131 - The actual batch size is 320, instead of 200\n",
      "2021-08-25 11:18:08.378 | INFO     | src.policies:train:157 - Total loss: 0.9968748092651367\n",
      "2021-08-25 11:18:08.381 | INFO     | src.policies:train:103 - Epoch 350 / 800\n",
      "2021-08-25 11:18:08.382 | INFO     | src.policies:train:109 - Episode 1539\n",
      "2021-08-25 11:18:08.448 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:08.449 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:08.450 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 163.11\n",
      "2021-08-25 11:18:08.455 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:08.458 | INFO     | src.policies:train:103 - Epoch 351 / 800\n",
      "2021-08-25 11:18:08.458 | INFO     | src.policies:train:109 - Episode 1540\n",
      "2021-08-25 11:18:08.525 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:08.527 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:08.528 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 163.11\n",
      "2021-08-25 11:18:08.533 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:08.535 | INFO     | src.policies:train:103 - Epoch 352 / 800\n",
      "2021-08-25 11:18:08.536 | INFO     | src.policies:train:109 - Episode 1541\n",
      "2021-08-25 11:18:08.578 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:08.579 | INFO     | src.policies:train:121 - Mean episode return: 118.0\n",
      "2021-08-25 11:18:08.580 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 162.97\n",
      "2021-08-25 11:18:08.581 | INFO     | src.policies:train:109 - Episode 1542\n",
      "2021-08-25 11:18:08.639 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:08.640 | INFO     | src.policies:train:121 - Mean episode return: 163.0\n",
      "2021-08-25 11:18:08.641 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 162.91\n",
      "2021-08-25 11:18:08.642 | WARNING  | src.policies:train:131 - The actual batch size is 281, instead of 200\n",
      "2021-08-25 11:18:08.647 | INFO     | src.policies:train:157 - Total loss: 0.9964409470558167\n",
      "2021-08-25 11:18:08.650 | INFO     | src.policies:train:103 - Epoch 353 / 800\n",
      "2021-08-25 11:18:08.651 | INFO     | src.policies:train:109 - Episode 1543\n",
      "2021-08-25 11:18:08.719 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:08.720 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:08.721 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 163.61\n",
      "2021-08-25 11:18:08.726 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:08.729 | INFO     | src.policies:train:103 - Epoch 354 / 800\n",
      "2021-08-25 11:18:08.730 | INFO     | src.policies:train:109 - Episode 1544\n",
      "2021-08-25 11:18:08.769 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:08.771 | INFO     | src.policies:train:121 - Mean episode return: 113.0\n",
      "2021-08-25 11:18:08.772 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 162.74\n",
      "2021-08-25 11:18:08.773 | INFO     | src.policies:train:109 - Episode 1545\n",
      "2021-08-25 11:18:08.816 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:08.817 | INFO     | src.policies:train:121 - Mean episode return: 119.0\n",
      "2021-08-25 11:18:08.818 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 162.44\n",
      "2021-08-25 11:18:08.819 | WARNING  | src.policies:train:131 - The actual batch size is 232, instead of 200\n",
      "2021-08-25 11:18:08.824 | INFO     | src.policies:train:157 - Total loss: 0.9956895112991333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:18:08.827 | INFO     | src.policies:train:103 - Epoch 355 / 800\n",
      "2021-08-25 11:18:08.828 | INFO     | src.policies:train:109 - Episode 1546\n",
      "2021-08-25 11:18:08.885 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:08.886 | INFO     | src.policies:train:121 - Mean episode return: 160.0\n",
      "2021-08-25 11:18:08.887 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 162.04\n",
      "2021-08-25 11:18:08.888 | INFO     | src.policies:train:109 - Episode 1547\n",
      "2021-08-25 11:18:08.938 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:08.940 | INFO     | src.policies:train:121 - Mean episode return: 138.0\n",
      "2021-08-25 11:18:08.940 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 161.42\n",
      "2021-08-25 11:18:08.941 | WARNING  | src.policies:train:131 - The actual batch size is 298, instead of 200\n",
      "2021-08-25 11:18:08.947 | INFO     | src.policies:train:157 - Total loss: 0.9966440200805664\n",
      "2021-08-25 11:18:08.950 | INFO     | src.policies:train:103 - Epoch 356 / 800\n",
      "2021-08-25 11:18:08.951 | INFO     | src.policies:train:109 - Episode 1548\n",
      "2021-08-25 11:18:09.017 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:09.018 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:09.019 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 161.42\n",
      "2021-08-25 11:18:09.024 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:09.027 | INFO     | src.policies:train:103 - Epoch 357 / 800\n",
      "2021-08-25 11:18:09.028 | INFO     | src.policies:train:109 - Episode 1549\n",
      "2021-08-25 11:18:09.068 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:09.070 | INFO     | src.policies:train:121 - Mean episode return: 122.0\n",
      "2021-08-25 11:18:09.071 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 160.64\n",
      "2021-08-25 11:18:09.072 | INFO     | src.policies:train:109 - Episode 1550\n",
      "2021-08-25 11:18:09.138 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:09.139 | INFO     | src.policies:train:121 - Mean episode return: 186.0\n",
      "2021-08-25 11:18:09.140 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 161.27\n",
      "2021-08-25 11:18:09.141 | WARNING  | src.policies:train:131 - The actual batch size is 308, instead of 200\n",
      "2021-08-25 11:18:09.146 | INFO     | src.policies:train:157 - Total loss: 0.996752917766571\n",
      "2021-08-25 11:18:09.149 | INFO     | src.policies:train:103 - Epoch 358 / 800\n",
      "2021-08-25 11:18:09.150 | INFO     | src.policies:train:109 - Episode 1551\n",
      "2021-08-25 11:18:09.219 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:09.221 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:09.222 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 162.04\n",
      "2021-08-25 11:18:09.226 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:09.229 | INFO     | src.policies:train:103 - Epoch 359 / 800\n",
      "2021-08-25 11:18:09.230 | INFO     | src.policies:train:109 - Episode 1552\n",
      "2021-08-25 11:18:09.269 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:09.270 | INFO     | src.policies:train:121 - Mean episode return: 112.0\n",
      "2021-08-25 11:18:09.271 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 161.16\n",
      "2021-08-25 11:18:09.272 | INFO     | src.policies:train:109 - Episode 1553\n",
      "2021-08-25 11:18:09.344 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:09.345 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:09.345 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 161.34\n",
      "2021-08-25 11:18:09.346 | WARNING  | src.policies:train:131 - The actual batch size is 312, instead of 200\n",
      "2021-08-25 11:18:09.353 | INFO     | src.policies:train:157 - Total loss: 0.9967948198318481\n",
      "2021-08-25 11:18:09.356 | INFO     | src.policies:train:103 - Epoch 360 / 800\n",
      "2021-08-25 11:18:09.357 | INFO     | src.policies:train:109 - Episode 1554\n",
      "2021-08-25 11:18:09.423 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:09.425 | INFO     | src.policies:train:121 - Mean episode return: 198.0\n",
      "2021-08-25 11:18:09.426 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 161.57\n",
      "2021-08-25 11:18:09.426 | INFO     | src.policies:train:109 - Episode 1555\n",
      "2021-08-25 11:18:09.485 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:09.486 | INFO     | src.policies:train:121 - Mean episode return: 169.0\n",
      "2021-08-25 11:18:09.487 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 161.26\n",
      "2021-08-25 11:18:09.488 | WARNING  | src.policies:train:131 - The actual batch size is 367, instead of 200\n",
      "2021-08-25 11:18:09.494 | INFO     | src.policies:train:157 - Total loss: 0.9972752332687378\n",
      "2021-08-25 11:18:09.497 | INFO     | src.policies:train:103 - Epoch 361 / 800\n",
      "2021-08-25 11:18:09.498 | INFO     | src.policies:train:109 - Episode 1556\n",
      "2021-08-25 11:18:09.538 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:09.540 | INFO     | src.policies:train:121 - Mean episode return: 116.0\n",
      "2021-08-25 11:18:09.540 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 160.9\n",
      "2021-08-25 11:18:09.541 | INFO     | src.policies:train:109 - Episode 1557\n",
      "2021-08-25 11:18:09.612 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:09.613 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:09.614 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 161.08\n",
      "2021-08-25 11:18:09.615 | WARNING  | src.policies:train:131 - The actual batch size is 316, instead of 200\n",
      "2021-08-25 11:18:09.620 | INFO     | src.policies:train:157 - Total loss: 0.9968352913856506\n",
      "2021-08-25 11:18:09.623 | INFO     | src.policies:train:103 - Epoch 362 / 800\n",
      "2021-08-25 11:18:09.624 | INFO     | src.policies:train:109 - Episode 1558\n",
      "2021-08-25 11:18:09.658 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:09.659 | INFO     | src.policies:train:121 - Mean episode return: 100.0\n",
      "2021-08-25 11:18:09.660 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 160.28\n",
      "2021-08-25 11:18:09.661 | INFO     | src.policies:train:109 - Episode 1559\n",
      "2021-08-25 11:18:09.702 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:09.704 | INFO     | src.policies:train:121 - Mean episode return: 110.0\n",
      "2021-08-25 11:18:09.704 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 159.38\n",
      "2021-08-25 11:18:09.705 | WARNING  | src.policies:train:131 - The actual batch size is 210, instead of 200\n",
      "2021-08-25 11:18:09.711 | INFO     | src.policies:train:157 - Total loss: 0.9952378869056702\n",
      "2021-08-25 11:18:09.713 | INFO     | src.policies:train:103 - Epoch 363 / 800\n",
      "2021-08-25 11:18:09.714 | INFO     | src.policies:train:109 - Episode 1560\n",
      "2021-08-25 11:18:09.752 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:09.753 | INFO     | src.policies:train:121 - Mean episode return: 112.0\n",
      "2021-08-25 11:18:09.754 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 158.68\n",
      "2021-08-25 11:18:09.755 | INFO     | src.policies:train:109 - Episode 1561\n",
      "2021-08-25 11:18:09.806 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:09.807 | INFO     | src.policies:train:121 - Mean episode return: 152.0\n",
      "2021-08-25 11:18:09.808 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 158.7\n",
      "2021-08-25 11:18:09.809 | WARNING  | src.policies:train:131 - The actual batch size is 264, instead of 200\n",
      "2021-08-25 11:18:09.814 | INFO     | src.policies:train:157 - Total loss: 0.9962120652198792\n",
      "2021-08-25 11:18:09.817 | INFO     | src.policies:train:103 - Epoch 364 / 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:18:09.818 | INFO     | src.policies:train:109 - Episode 1562\n",
      "2021-08-25 11:18:09.861 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:09.863 | INFO     | src.policies:train:121 - Mean episode return: 120.0\n",
      "2021-08-25 11:18:09.863 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 157.9\n",
      "2021-08-25 11:18:09.864 | INFO     | src.policies:train:109 - Episode 1563\n",
      "2021-08-25 11:18:09.907 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:09.908 | INFO     | src.policies:train:121 - Mean episode return: 120.0\n",
      "2021-08-25 11:18:09.909 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 157.5\n",
      "2021-08-25 11:18:09.910 | WARNING  | src.policies:train:131 - The actual batch size is 240, instead of 200\n",
      "2021-08-25 11:18:09.916 | INFO     | src.policies:train:157 - Total loss: 0.9958332777023315\n",
      "2021-08-25 11:18:09.919 | INFO     | src.policies:train:103 - Epoch 365 / 800\n",
      "2021-08-25 11:18:09.920 | INFO     | src.policies:train:109 - Episode 1564\n",
      "2021-08-25 11:18:09.973 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:09.974 | INFO     | src.policies:train:121 - Mean episode return: 156.0\n",
      "2021-08-25 11:18:09.975 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 157.46\n",
      "2021-08-25 11:18:09.976 | INFO     | src.policies:train:109 - Episode 1565\n",
      "2021-08-25 11:18:10.044 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:10.045 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:10.046 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 158.42\n",
      "2021-08-25 11:18:10.047 | WARNING  | src.policies:train:131 - The actual batch size is 356, instead of 200\n",
      "2021-08-25 11:18:10.053 | INFO     | src.policies:train:157 - Total loss: 0.9971907734870911\n",
      "2021-08-25 11:18:10.055 | INFO     | src.policies:train:103 - Epoch 366 / 800\n",
      "2021-08-25 11:18:10.056 | INFO     | src.policies:train:109 - Episode 1566\n",
      "2021-08-25 11:18:10.113 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:10.115 | INFO     | src.policies:train:121 - Mean episode return: 167.0\n",
      "2021-08-25 11:18:10.116 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 158.53\n",
      "2021-08-25 11:18:10.116 | INFO     | src.policies:train:109 - Episode 1567\n",
      "2021-08-25 11:18:10.161 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:10.162 | INFO     | src.policies:train:121 - Mean episode return: 132.0\n",
      "2021-08-25 11:18:10.163 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 158.1\n",
      "2021-08-25 11:18:10.164 | WARNING  | src.policies:train:131 - The actual batch size is 299, instead of 200\n",
      "2021-08-25 11:18:10.170 | INFO     | src.policies:train:157 - Total loss: 0.9966555833816528\n",
      "2021-08-25 11:18:10.173 | INFO     | src.policies:train:103 - Epoch 367 / 800\n",
      "2021-08-25 11:18:10.174 | INFO     | src.policies:train:109 - Episode 1568\n",
      "2021-08-25 11:18:10.240 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:10.242 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:10.243 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 158.66\n",
      "2021-08-25 11:18:10.248 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:10.250 | INFO     | src.policies:train:103 - Epoch 368 / 800\n",
      "2021-08-25 11:18:10.251 | INFO     | src.policies:train:109 - Episode 1569\n",
      "2021-08-25 11:18:10.293 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:10.294 | INFO     | src.policies:train:121 - Mean episode return: 121.0\n",
      "2021-08-25 11:18:10.295 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 158.32\n",
      "2021-08-25 11:18:10.296 | INFO     | src.policies:train:109 - Episode 1570\n",
      "2021-08-25 11:18:10.365 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:10.366 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:10.367 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 158.32\n",
      "2021-08-25 11:18:10.368 | WARNING  | src.policies:train:131 - The actual batch size is 321, instead of 200\n",
      "2021-08-25 11:18:10.374 | INFO     | src.policies:train:157 - Total loss: 0.9968845844268799\n",
      "2021-08-25 11:18:10.377 | INFO     | src.policies:train:103 - Epoch 369 / 800\n",
      "2021-08-25 11:18:10.378 | INFO     | src.policies:train:109 - Episode 1571\n",
      "2021-08-25 11:18:10.422 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:10.423 | INFO     | src.policies:train:121 - Mean episode return: 128.0\n",
      "2021-08-25 11:18:10.424 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 157.76\n",
      "2021-08-25 11:18:10.425 | INFO     | src.policies:train:109 - Episode 1572\n",
      "2021-08-25 11:18:10.474 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:10.475 | INFO     | src.policies:train:121 - Mean episode return: 129.0\n",
      "2021-08-25 11:18:10.475 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 157.31\n",
      "2021-08-25 11:18:10.476 | WARNING  | src.policies:train:131 - The actual batch size is 257, instead of 200\n",
      "2021-08-25 11:18:10.482 | INFO     | src.policies:train:157 - Total loss: 0.9961089491844177\n",
      "2021-08-25 11:18:10.485 | INFO     | src.policies:train:103 - Epoch 370 / 800\n",
      "2021-08-25 11:18:10.486 | INFO     | src.policies:train:109 - Episode 1573\n",
      "2021-08-25 11:18:10.534 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:10.536 | INFO     | src.policies:train:121 - Mean episode return: 144.0\n",
      "2021-08-25 11:18:10.537 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 156.75\n",
      "2021-08-25 11:18:10.537 | INFO     | src.policies:train:109 - Episode 1574\n",
      "2021-08-25 11:18:10.583 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:10.584 | INFO     | src.policies:train:121 - Mean episode return: 130.0\n",
      "2021-08-25 11:18:10.585 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 156.76\n",
      "2021-08-25 11:18:10.586 | WARNING  | src.policies:train:131 - The actual batch size is 274, instead of 200\n",
      "2021-08-25 11:18:10.591 | INFO     | src.policies:train:157 - Total loss: 0.9963499903678894\n",
      "2021-08-25 11:18:10.594 | INFO     | src.policies:train:103 - Epoch 371 / 800\n",
      "2021-08-25 11:18:10.595 | INFO     | src.policies:train:109 - Episode 1575\n",
      "2021-08-25 11:18:10.646 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:10.647 | INFO     | src.policies:train:121 - Mean episode return: 148.0\n",
      "2021-08-25 11:18:10.648 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 156.59\n",
      "2021-08-25 11:18:10.649 | INFO     | src.policies:train:109 - Episode 1576\n",
      "2021-08-25 11:18:10.702 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:10.703 | INFO     | src.policies:train:121 - Mean episode return: 150.0\n",
      "2021-08-25 11:18:10.704 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 156.09\n",
      "2021-08-25 11:18:10.705 | WARNING  | src.policies:train:131 - The actual batch size is 298, instead of 200\n",
      "2021-08-25 11:18:10.711 | INFO     | src.policies:train:157 - Total loss: 0.9966441988945007\n",
      "2021-08-25 11:18:10.714 | INFO     | src.policies:train:103 - Epoch 372 / 800\n",
      "2021-08-25 11:18:10.715 | INFO     | src.policies:train:109 - Episode 1577\n",
      "2021-08-25 11:18:10.757 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:10.759 | INFO     | src.policies:train:121 - Mean episode return: 119.0\n",
      "2021-08-25 11:18:10.760 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 155.28\n",
      "2021-08-25 11:18:10.760 | INFO     | src.policies:train:109 - Episode 1578\n",
      "2021-08-25 11:18:10.817 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:10.818 | INFO     | src.policies:train:121 - Mean episode return: 160.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:18:10.819 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 155.29\n",
      "2021-08-25 11:18:10.820 | WARNING  | src.policies:train:131 - The actual batch size is 279, instead of 200\n",
      "2021-08-25 11:18:10.826 | INFO     | src.policies:train:157 - Total loss: 0.9964156746864319\n",
      "2021-08-25 11:18:10.828 | INFO     | src.policies:train:103 - Epoch 373 / 800\n",
      "2021-08-25 11:18:10.829 | INFO     | src.policies:train:109 - Episode 1579\n",
      "2021-08-25 11:18:10.895 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:10.897 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:10.898 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 156.72\n",
      "2021-08-25 11:18:10.902 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:10.905 | INFO     | src.policies:train:103 - Epoch 374 / 800\n",
      "2021-08-25 11:18:10.906 | INFO     | src.policies:train:109 - Episode 1580\n",
      "2021-08-25 11:18:10.955 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:10.956 | INFO     | src.policies:train:121 - Mean episode return: 141.0\n",
      "2021-08-25 11:18:10.957 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 157.69\n",
      "2021-08-25 11:18:10.958 | INFO     | src.policies:train:109 - Episode 1581\n",
      "2021-08-25 11:18:11.024 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:11.025 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:11.026 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 158.19\n",
      "2021-08-25 11:18:11.027 | WARNING  | src.policies:train:131 - The actual batch size is 341, instead of 200\n",
      "2021-08-25 11:18:11.034 | INFO     | src.policies:train:157 - Total loss: 0.9970670342445374\n",
      "2021-08-25 11:18:11.036 | INFO     | src.policies:train:103 - Epoch 375 / 800\n",
      "2021-08-25 11:18:11.037 | INFO     | src.policies:train:109 - Episode 1582\n",
      "2021-08-25 11:18:11.091 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:11.092 | INFO     | src.policies:train:121 - Mean episode return: 159.0\n",
      "2021-08-25 11:18:11.093 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 157.88\n",
      "2021-08-25 11:18:11.094 | INFO     | src.policies:train:109 - Episode 1583\n",
      "2021-08-25 11:18:11.164 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:11.165 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:11.166 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 158.44\n",
      "2021-08-25 11:18:11.167 | WARNING  | src.policies:train:131 - The actual batch size is 359, instead of 200\n",
      "2021-08-25 11:18:11.173 | INFO     | src.policies:train:157 - Total loss: 0.9972143769264221\n",
      "2021-08-25 11:18:11.175 | INFO     | src.policies:train:103 - Epoch 376 / 800\n",
      "2021-08-25 11:18:11.176 | INFO     | src.policies:train:109 - Episode 1584\n",
      "2021-08-25 11:18:11.245 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:11.246 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:11.247 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 158.46\n",
      "2021-08-25 11:18:11.252 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:11.254 | INFO     | src.policies:train:103 - Epoch 377 / 800\n",
      "2021-08-25 11:18:11.255 | INFO     | src.policies:train:109 - Episode 1585\n",
      "2021-08-25 11:18:11.319 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:11.320 | INFO     | src.policies:train:121 - Mean episode return: 181.0\n",
      "2021-08-25 11:18:11.321 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 158.78\n",
      "2021-08-25 11:18:11.322 | INFO     | src.policies:train:109 - Episode 1586\n",
      "2021-08-25 11:18:11.371 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:11.372 | INFO     | src.policies:train:121 - Mean episode return: 143.0\n",
      "2021-08-25 11:18:11.373 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 158.84\n",
      "2021-08-25 11:18:11.374 | WARNING  | src.policies:train:131 - The actual batch size is 324, instead of 200\n",
      "2021-08-25 11:18:11.380 | INFO     | src.policies:train:157 - Total loss: 0.9969134330749512\n",
      "2021-08-25 11:18:11.382 | INFO     | src.policies:train:103 - Epoch 378 / 800\n",
      "2021-08-25 11:18:11.383 | INFO     | src.policies:train:109 - Episode 1587\n",
      "2021-08-25 11:18:11.442 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:11.444 | INFO     | src.policies:train:121 - Mean episode return: 174.0\n",
      "2021-08-25 11:18:11.445 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 159.11\n",
      "2021-08-25 11:18:11.445 | INFO     | src.policies:train:109 - Episode 1588\n",
      "2021-08-25 11:18:11.511 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:11.512 | INFO     | src.policies:train:121 - Mean episode return: 196.0\n",
      "2021-08-25 11:18:11.513 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 159.37\n",
      "2021-08-25 11:18:11.514 | WARNING  | src.policies:train:131 - The actual batch size is 370, instead of 200\n",
      "2021-08-25 11:18:11.520 | INFO     | src.policies:train:157 - Total loss: 0.9972971677780151\n",
      "2021-08-25 11:18:11.523 | INFO     | src.policies:train:103 - Epoch 379 / 800\n",
      "2021-08-25 11:18:11.524 | INFO     | src.policies:train:109 - Episode 1589\n",
      "2021-08-25 11:18:11.591 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:11.593 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:11.594 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 160.04\n",
      "2021-08-25 11:18:11.599 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:11.601 | INFO     | src.policies:train:103 - Epoch 380 / 800\n",
      "2021-08-25 11:18:11.602 | INFO     | src.policies:train:109 - Episode 1590\n",
      "2021-08-25 11:18:11.644 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:11.646 | INFO     | src.policies:train:121 - Mean episode return: 125.0\n",
      "2021-08-25 11:18:11.647 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 159.42\n",
      "2021-08-25 11:18:11.647 | INFO     | src.policies:train:109 - Episode 1591\n",
      "2021-08-25 11:18:11.712 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:11.713 | INFO     | src.policies:train:121 - Mean episode return: 182.0\n",
      "2021-08-25 11:18:11.714 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 159.24\n",
      "2021-08-25 11:18:11.715 | WARNING  | src.policies:train:131 - The actual batch size is 307, instead of 200\n",
      "2021-08-25 11:18:11.720 | INFO     | src.policies:train:157 - Total loss: 0.996742308139801\n",
      "2021-08-25 11:18:11.723 | INFO     | src.policies:train:103 - Epoch 381 / 800\n",
      "2021-08-25 11:18:11.724 | INFO     | src.policies:train:109 - Episode 1592\n",
      "2021-08-25 11:18:11.790 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:11.791 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:11.792 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 159.68\n",
      "2021-08-25 11:18:11.797 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:11.799 | INFO     | src.policies:train:103 - Epoch 382 / 800\n",
      "2021-08-25 11:18:11.800 | INFO     | src.policies:train:109 - Episode 1593\n",
      "2021-08-25 11:18:11.850 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:11.852 | INFO     | src.policies:train:121 - Mean episode return: 149.0\n",
      "2021-08-25 11:18:11.853 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 159.82\n",
      "2021-08-25 11:18:11.853 | INFO     | src.policies:train:109 - Episode 1594\n",
      "2021-08-25 11:18:11.901 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:11.903 | INFO     | src.policies:train:121 - Mean episode return: 142.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:18:11.903 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 159.9\n",
      "2021-08-25 11:18:11.904 | WARNING  | src.policies:train:131 - The actual batch size is 291, instead of 200\n",
      "2021-08-25 11:18:11.910 | INFO     | src.policies:train:157 - Total loss: 0.9965635538101196\n",
      "2021-08-25 11:18:11.913 | INFO     | src.policies:train:103 - Epoch 383 / 800\n",
      "2021-08-25 11:18:11.914 | INFO     | src.policies:train:109 - Episode 1595\n",
      "2021-08-25 11:18:11.981 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:11.982 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:11.983 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 160.24\n",
      "2021-08-25 11:18:11.988 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:11.991 | INFO     | src.policies:train:103 - Epoch 384 / 800\n",
      "2021-08-25 11:18:11.991 | INFO     | src.policies:train:109 - Episode 1596\n",
      "2021-08-25 11:18:12.054 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:12.055 | INFO     | src.policies:train:121 - Mean episode return: 178.0\n",
      "2021-08-25 11:18:12.056 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 160.02\n",
      "2021-08-25 11:18:12.057 | INFO     | src.policies:train:109 - Episode 1597\n",
      "2021-08-25 11:18:12.126 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:12.127 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:12.128 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 160.4\n",
      "2021-08-25 11:18:12.129 | WARNING  | src.policies:train:131 - The actual batch size is 378, instead of 200\n",
      "2021-08-25 11:18:12.136 | INFO     | src.policies:train:157 - Total loss: 0.9973541498184204\n",
      "2021-08-25 11:18:12.138 | INFO     | src.policies:train:103 - Epoch 385 / 800\n",
      "2021-08-25 11:18:12.140 | INFO     | src.policies:train:109 - Episode 1598\n",
      "2021-08-25 11:18:12.210 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:12.212 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:12.213 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 161.06\n",
      "2021-08-25 11:18:12.219 | INFO     | src.policies:train:157 - Total loss: 0.9950000047683716\n",
      "2021-08-25 11:18:12.222 | INFO     | src.policies:train:103 - Epoch 386 / 800\n",
      "2021-08-25 11:18:12.223 | INFO     | src.policies:train:109 - Episode 1599\n",
      "2021-08-25 11:18:12.278 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:12.279 | INFO     | src.policies:train:121 - Mean episode return: 157.0\n",
      "2021-08-25 11:18:12.281 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 161.2\n",
      "2021-08-25 11:18:12.281 | INFO     | src.policies:train:109 - Episode 1600\n",
      "2021-08-25 11:18:12.343 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:12.344 | INFO     | src.policies:train:121 - Mean episode return: 172.0\n",
      "2021-08-25 11:18:12.345 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 161.25\n",
      "2021-08-25 11:18:12.346 | WARNING  | src.policies:train:131 - The actual batch size is 329, instead of 200\n",
      "2021-08-25 11:18:12.352 | INFO     | src.policies:train:157 - Total loss: 0.9969603419303894\n",
      "2021-08-25 11:18:12.354 | INFO     | src.policies:train:103 - Epoch 387 / 800\n",
      "2021-08-25 11:18:12.355 | INFO     | src.policies:train:109 - Episode 1601\n",
      "2021-08-25 11:18:12.420 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:12.422 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:12.423 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 161.49\n",
      "2021-08-25 11:18:12.427 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:12.430 | INFO     | src.policies:train:103 - Epoch 388 / 800\n",
      "2021-08-25 11:18:12.431 | INFO     | src.policies:train:109 - Episode 1602\n",
      "2021-08-25 11:18:12.490 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:12.491 | INFO     | src.policies:train:121 - Mean episode return: 171.0\n",
      "2021-08-25 11:18:12.492 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 161.53\n",
      "2021-08-25 11:18:12.493 | INFO     | src.policies:train:109 - Episode 1603\n",
      "2021-08-25 11:18:12.551 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:12.552 | INFO     | src.policies:train:121 - Mean episode return: 169.0\n",
      "2021-08-25 11:18:12.552 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 161.62\n",
      "2021-08-25 11:18:12.554 | WARNING  | src.policies:train:131 - The actual batch size is 340, instead of 200\n",
      "2021-08-25 11:18:12.559 | INFO     | src.policies:train:157 - Total loss: 0.9970587491989136\n",
      "2021-08-25 11:18:12.562 | INFO     | src.policies:train:103 - Epoch 389 / 800\n",
      "2021-08-25 11:18:12.563 | INFO     | src.policies:train:109 - Episode 1604\n",
      "2021-08-25 11:18:12.632 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:12.634 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:12.635 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 162.27\n",
      "2021-08-25 11:18:12.639 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:12.642 | INFO     | src.policies:train:103 - Epoch 390 / 800\n",
      "2021-08-25 11:18:12.642 | INFO     | src.policies:train:109 - Episode 1605\n",
      "2021-08-25 11:18:12.688 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:12.690 | INFO     | src.policies:train:121 - Mean episode return: 136.0\n",
      "2021-08-25 11:18:12.691 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 161.63\n",
      "2021-08-25 11:18:12.692 | INFO     | src.policies:train:109 - Episode 1606\n",
      "2021-08-25 11:18:12.743 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:12.745 | INFO     | src.policies:train:121 - Mean episode return: 149.0\n",
      "2021-08-25 11:18:12.746 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 161.75\n",
      "2021-08-25 11:18:12.747 | WARNING  | src.policies:train:131 - The actual batch size is 285, instead of 200\n",
      "2021-08-25 11:18:12.753 | INFO     | src.policies:train:157 - Total loss: 0.9964911341667175\n",
      "2021-08-25 11:18:12.755 | INFO     | src.policies:train:103 - Epoch 391 / 800\n",
      "2021-08-25 11:18:12.756 | INFO     | src.policies:train:109 - Episode 1607\n",
      "2021-08-25 11:18:12.806 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:12.807 | INFO     | src.policies:train:121 - Mean episode return: 144.0\n",
      "2021-08-25 11:18:12.808 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 162.1\n",
      "2021-08-25 11:18:12.809 | INFO     | src.policies:train:109 - Episode 1608\n",
      "2021-08-25 11:18:12.835 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:12.836 | INFO     | src.policies:train:121 - Mean episode return: 68.0\n",
      "2021-08-25 11:18:12.837 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 161.48\n",
      "2021-08-25 11:18:12.838 | WARNING  | src.policies:train:131 - The actual batch size is 212, instead of 200\n",
      "2021-08-25 11:18:12.844 | INFO     | src.policies:train:157 - Total loss: 0.9952828288078308\n",
      "2021-08-25 11:18:12.847 | INFO     | src.policies:train:103 - Epoch 392 / 800\n",
      "2021-08-25 11:18:12.848 | INFO     | src.policies:train:109 - Episode 1609\n",
      "2021-08-25 11:18:12.917 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:12.918 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:12.919 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 162.43\n",
      "2021-08-25 11:18:12.923 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:12.926 | INFO     | src.policies:train:103 - Epoch 393 / 800\n",
      "2021-08-25 11:18:12.927 | INFO     | src.policies:train:109 - Episode 1610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:18:12.994 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:12.996 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:12.997 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 162.94\n",
      "2021-08-25 11:18:13.002 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:13.004 | INFO     | src.policies:train:103 - Epoch 394 / 800\n",
      "2021-08-25 11:18:13.005 | INFO     | src.policies:train:109 - Episode 1611\n",
      "2021-08-25 11:18:13.076 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:13.077 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:13.078 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 163.59\n",
      "2021-08-25 11:18:13.083 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:13.085 | INFO     | src.policies:train:103 - Epoch 395 / 800\n",
      "2021-08-25 11:18:13.086 | INFO     | src.policies:train:109 - Episode 1612\n",
      "2021-08-25 11:18:13.132 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:13.133 | INFO     | src.policies:train:121 - Mean episode return: 134.0\n",
      "2021-08-25 11:18:13.134 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 163.8\n",
      "2021-08-25 11:18:13.135 | INFO     | src.policies:train:109 - Episode 1613\n",
      "2021-08-25 11:18:13.206 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:13.207 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:13.208 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 163.8\n",
      "2021-08-25 11:18:13.209 | WARNING  | src.policies:train:131 - The actual batch size is 334, instead of 200\n",
      "2021-08-25 11:18:13.215 | INFO     | src.policies:train:157 - Total loss: 0.9970058798789978\n",
      "2021-08-25 11:18:13.217 | INFO     | src.policies:train:103 - Epoch 396 / 800\n",
      "2021-08-25 11:18:13.218 | INFO     | src.policies:train:109 - Episode 1614\n",
      "2021-08-25 11:18:13.286 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:13.288 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:13.288 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 163.8\n",
      "2021-08-25 11:18:13.293 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:13.296 | INFO     | src.policies:train:103 - Epoch 397 / 800\n",
      "2021-08-25 11:18:13.297 | INFO     | src.policies:train:109 - Episode 1615\n",
      "2021-08-25 11:18:13.353 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:13.355 | INFO     | src.policies:train:121 - Mean episode return: 166.0\n",
      "2021-08-25 11:18:13.356 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 164.01\n",
      "2021-08-25 11:18:13.357 | INFO     | src.policies:train:109 - Episode 1616\n",
      "2021-08-25 11:18:13.425 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:13.426 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:13.427 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 164.52\n",
      "2021-08-25 11:18:13.428 | WARNING  | src.policies:train:131 - The actual batch size is 366, instead of 200\n",
      "2021-08-25 11:18:13.433 | INFO     | src.policies:train:157 - Total loss: 0.9972677230834961\n",
      "2021-08-25 11:18:13.436 | INFO     | src.policies:train:103 - Epoch 398 / 800\n",
      "2021-08-25 11:18:13.437 | INFO     | src.policies:train:109 - Episode 1617\n",
      "2021-08-25 11:18:13.506 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:13.507 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:13.508 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 165.35\n",
      "2021-08-25 11:18:13.513 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:13.515 | INFO     | src.policies:train:103 - Epoch 399 / 800\n",
      "2021-08-25 11:18:13.516 | INFO     | src.policies:train:109 - Episode 1618\n",
      "2021-08-25 11:18:13.583 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:13.585 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:13.586 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 165.35\n",
      "2021-08-25 11:18:13.591 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:13.594 | INFO     | src.policies:train:103 - Epoch 400 / 800\n",
      "2021-08-25 11:18:13.594 | INFO     | src.policies:train:109 - Episode 1619\n",
      "2021-08-25 11:18:13.663 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:13.665 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:13.666 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 165.35\n",
      "2021-08-25 11:18:13.671 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:13.673 | INFO     | src.policies:train:103 - Epoch 401 / 800\n",
      "2021-08-25 11:18:13.674 | INFO     | src.policies:train:109 - Episode 1620\n",
      "2021-08-25 11:18:13.731 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:13.733 | INFO     | src.policies:train:121 - Mean episode return: 165.0\n",
      "2021-08-25 11:18:13.734 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 165.0\n",
      "2021-08-25 11:18:13.734 | INFO     | src.policies:train:109 - Episode 1621\n",
      "2021-08-25 11:18:13.798 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:13.799 | INFO     | src.policies:train:121 - Mean episode return: 182.0\n",
      "2021-08-25 11:18:13.800 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 165.81\n",
      "2021-08-25 11:18:13.801 | WARNING  | src.policies:train:131 - The actual batch size is 347, instead of 200\n",
      "2021-08-25 11:18:13.807 | INFO     | src.policies:train:157 - Total loss: 0.9971176981925964\n",
      "2021-08-25 11:18:13.810 | INFO     | src.policies:train:103 - Epoch 402 / 800\n",
      "2021-08-25 11:18:13.811 | INFO     | src.policies:train:109 - Episode 1622\n",
      "2021-08-25 11:18:13.868 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:13.870 | INFO     | src.policies:train:121 - Mean episode return: 171.0\n",
      "2021-08-25 11:18:13.871 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 166.46\n",
      "2021-08-25 11:18:13.871 | INFO     | src.policies:train:109 - Episode 1623\n",
      "2021-08-25 11:18:13.940 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:13.942 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:13.943 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 167.1\n",
      "2021-08-25 11:18:13.943 | WARNING  | src.policies:train:131 - The actual batch size is 371, instead of 200\n",
      "2021-08-25 11:18:13.949 | INFO     | src.policies:train:157 - Total loss: 0.9973043203353882\n",
      "2021-08-25 11:18:13.952 | INFO     | src.policies:train:103 - Epoch 403 / 800\n",
      "2021-08-25 11:18:13.953 | INFO     | src.policies:train:109 - Episode 1624\n",
      "2021-08-25 11:18:14.021 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:14.023 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:14.024 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 167.1\n",
      "2021-08-25 11:18:14.029 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:14.031 | INFO     | src.policies:train:103 - Epoch 404 / 800\n",
      "2021-08-25 11:18:14.032 | INFO     | src.policies:train:109 - Episode 1625\n",
      "2021-08-25 11:18:14.089 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:14.091 | INFO     | src.policies:train:121 - Mean episode return: 168.0\n",
      "2021-08-25 11:18:14.092 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 166.78\n",
      "2021-08-25 11:18:14.093 | INFO     | src.policies:train:109 - Episode 1626\n",
      "2021-08-25 11:18:14.162 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:18:14.164 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:14.165 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 166.79\n",
      "2021-08-25 11:18:14.165 | WARNING  | src.policies:train:131 - The actual batch size is 368, instead of 200\n",
      "2021-08-25 11:18:14.172 | INFO     | src.policies:train:157 - Total loss: 0.9972824454307556\n",
      "2021-08-25 11:18:14.174 | INFO     | src.policies:train:103 - Epoch 405 / 800\n",
      "2021-08-25 11:18:14.175 | INFO     | src.policies:train:109 - Episode 1627\n",
      "2021-08-25 11:18:14.244 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:14.245 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:14.246 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 166.79\n",
      "2021-08-25 11:18:14.252 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:14.254 | INFO     | src.policies:train:103 - Epoch 406 / 800\n",
      "2021-08-25 11:18:14.255 | INFO     | src.policies:train:109 - Episode 1628\n",
      "2021-08-25 11:18:14.308 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:14.310 | INFO     | src.policies:train:121 - Mean episode return: 154.0\n",
      "2021-08-25 11:18:14.311 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 166.33\n",
      "2021-08-25 11:18:14.312 | INFO     | src.policies:train:109 - Episode 1629\n",
      "2021-08-25 11:18:14.382 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:14.383 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:14.384 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 166.87\n",
      "2021-08-25 11:18:14.384 | WARNING  | src.policies:train:131 - The actual batch size is 354, instead of 200\n",
      "2021-08-25 11:18:14.391 | INFO     | src.policies:train:157 - Total loss: 0.997174859046936\n",
      "2021-08-25 11:18:14.393 | INFO     | src.policies:train:103 - Epoch 407 / 800\n",
      "2021-08-25 11:18:14.394 | INFO     | src.policies:train:109 - Episode 1630\n",
      "2021-08-25 11:18:14.464 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:14.465 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:14.466 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 167.48\n",
      "2021-08-25 11:18:14.471 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:14.474 | INFO     | src.policies:train:103 - Epoch 408 / 800\n",
      "2021-08-25 11:18:14.475 | INFO     | src.policies:train:109 - Episode 1631\n",
      "2021-08-25 11:18:14.532 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:14.534 | INFO     | src.policies:train:121 - Mean episode return: 169.0\n",
      "2021-08-25 11:18:14.535 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 168.34\n",
      "2021-08-25 11:18:14.535 | INFO     | src.policies:train:109 - Episode 1632\n",
      "2021-08-25 11:18:14.605 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:14.607 | INFO     | src.policies:train:121 - Mean episode return: 199.0\n",
      "2021-08-25 11:18:14.607 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 168.44\n",
      "2021-08-25 11:18:14.608 | WARNING  | src.policies:train:131 - The actual batch size is 368, instead of 200\n",
      "2021-08-25 11:18:14.614 | INFO     | src.policies:train:157 - Total loss: 0.9972825050354004\n",
      "2021-08-25 11:18:14.617 | INFO     | src.policies:train:103 - Epoch 409 / 800\n",
      "2021-08-25 11:18:14.618 | INFO     | src.policies:train:109 - Episode 1633\n",
      "2021-08-25 11:18:14.690 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:14.691 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:14.692 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 168.44\n",
      "2021-08-25 11:18:14.697 | INFO     | src.policies:train:157 - Total loss: 0.9950000047683716\n",
      "2021-08-25 11:18:14.699 | INFO     | src.policies:train:103 - Epoch 410 / 800\n",
      "2021-08-25 11:18:14.700 | INFO     | src.policies:train:109 - Episode 1634\n",
      "2021-08-25 11:18:14.769 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:14.770 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:14.771 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 168.44\n",
      "2021-08-25 11:18:14.777 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:14.781 | INFO     | src.policies:train:103 - Epoch 411 / 800\n",
      "2021-08-25 11:18:14.782 | INFO     | src.policies:train:109 - Episode 1635\n",
      "2021-08-25 11:18:14.851 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:14.853 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:14.854 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 168.76\n",
      "2021-08-25 11:18:14.860 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:14.864 | INFO     | src.policies:train:103 - Epoch 412 / 800\n",
      "2021-08-25 11:18:14.865 | INFO     | src.policies:train:109 - Episode 1636\n",
      "2021-08-25 11:18:14.935 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:14.937 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:14.937 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 168.76\n",
      "2021-08-25 11:18:14.943 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:14.945 | INFO     | src.policies:train:103 - Epoch 413 / 800\n",
      "2021-08-25 11:18:14.946 | INFO     | src.policies:train:109 - Episode 1637\n",
      "2021-08-25 11:18:15.017 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:15.019 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:15.020 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 169.04\n",
      "2021-08-25 11:18:15.025 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:15.028 | INFO     | src.policies:train:103 - Epoch 414 / 800\n",
      "2021-08-25 11:18:15.029 | INFO     | src.policies:train:109 - Episode 1638\n",
      "2021-08-25 11:18:15.101 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:15.103 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:15.104 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 169.56\n",
      "2021-08-25 11:18:15.109 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:15.112 | INFO     | src.policies:train:103 - Epoch 415 / 800\n",
      "2021-08-25 11:18:15.113 | INFO     | src.policies:train:109 - Episode 1639\n",
      "2021-08-25 11:18:15.174 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:15.175 | INFO     | src.policies:train:121 - Mean episode return: 171.0\n",
      "2021-08-25 11:18:15.176 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 169.27\n",
      "2021-08-25 11:18:15.177 | INFO     | src.policies:train:109 - Episode 1640\n",
      "2021-08-25 11:18:15.228 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:15.229 | INFO     | src.policies:train:121 - Mean episode return: 143.0\n",
      "2021-08-25 11:18:15.230 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 168.7\n",
      "2021-08-25 11:18:15.231 | WARNING  | src.policies:train:131 - The actual batch size is 314, instead of 200\n",
      "2021-08-25 11:18:15.239 | INFO     | src.policies:train:157 - Total loss: 0.9968152046203613\n",
      "2021-08-25 11:18:15.242 | INFO     | src.policies:train:103 - Epoch 416 / 800\n",
      "2021-08-25 11:18:15.243 | INFO     | src.policies:train:109 - Episode 1641\n",
      "2021-08-25 11:18:15.314 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:15.316 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:15.317 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 169.52\n",
      "2021-08-25 11:18:15.323 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:18:15.326 | INFO     | src.policies:train:103 - Epoch 417 / 800\n",
      "2021-08-25 11:18:15.327 | INFO     | src.policies:train:109 - Episode 1642\n",
      "2021-08-25 11:18:15.386 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:15.388 | INFO     | src.policies:train:121 - Mean episode return: 164.0\n",
      "2021-08-25 11:18:15.389 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 169.53\n",
      "2021-08-25 11:18:15.390 | INFO     | src.policies:train:109 - Episode 1643\n",
      "2021-08-25 11:18:15.464 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:15.465 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:15.466 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 169.53\n",
      "2021-08-25 11:18:15.467 | WARNING  | src.policies:train:131 - The actual batch size is 364, instead of 200\n",
      "2021-08-25 11:18:15.475 | INFO     | src.policies:train:157 - Total loss: 0.9972527623176575\n",
      "2021-08-25 11:18:15.478 | INFO     | src.policies:train:103 - Epoch 418 / 800\n",
      "2021-08-25 11:18:15.479 | INFO     | src.policies:train:109 - Episode 1644\n",
      "2021-08-25 11:18:15.550 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:15.551 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:15.552 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 170.4\n",
      "2021-08-25 11:18:15.557 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:15.560 | INFO     | src.policies:train:103 - Epoch 419 / 800\n",
      "2021-08-25 11:18:15.561 | INFO     | src.policies:train:109 - Episode 1645\n",
      "2021-08-25 11:18:15.629 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:15.631 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:15.631 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 171.21\n",
      "2021-08-25 11:18:15.636 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:15.639 | INFO     | src.policies:train:103 - Epoch 420 / 800\n",
      "2021-08-25 11:18:15.640 | INFO     | src.policies:train:109 - Episode 1646\n",
      "2021-08-25 11:18:15.708 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:15.710 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:15.711 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 171.61\n",
      "2021-08-25 11:18:15.716 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:15.719 | INFO     | src.policies:train:103 - Epoch 421 / 800\n",
      "2021-08-25 11:18:15.720 | INFO     | src.policies:train:109 - Episode 1647\n",
      "2021-08-25 11:18:15.789 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:15.791 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:15.793 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.23\n",
      "2021-08-25 11:18:15.798 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:15.801 | INFO     | src.policies:train:103 - Epoch 422 / 800\n",
      "2021-08-25 11:18:15.801 | INFO     | src.policies:train:109 - Episode 1648\n",
      "2021-08-25 11:18:15.826 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:15.827 | INFO     | src.policies:train:121 - Mean episode return: 68.0\n",
      "2021-08-25 11:18:15.828 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 170.91\n",
      "2021-08-25 11:18:15.829 | INFO     | src.policies:train:109 - Episode 1649\n",
      "2021-08-25 11:18:15.901 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:15.902 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:15.903 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 171.69\n",
      "2021-08-25 11:18:15.904 | WARNING  | src.policies:train:131 - The actual batch size is 268, instead of 200\n",
      "2021-08-25 11:18:15.912 | INFO     | src.policies:train:157 - Total loss: 0.9962685108184814\n",
      "2021-08-25 11:18:15.916 | INFO     | src.policies:train:103 - Epoch 423 / 800\n",
      "2021-08-25 11:18:15.917 | INFO     | src.policies:train:109 - Episode 1650\n",
      "2021-08-25 11:18:15.985 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:15.987 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:15.988 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 171.83\n",
      "2021-08-25 11:18:15.994 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:15.997 | INFO     | src.policies:train:103 - Epoch 424 / 800\n",
      "2021-08-25 11:18:15.998 | INFO     | src.policies:train:109 - Episode 1651\n",
      "2021-08-25 11:18:16.068 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:16.069 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:16.070 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 171.83\n",
      "2021-08-25 11:18:16.075 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:16.078 | INFO     | src.policies:train:103 - Epoch 425 / 800\n",
      "2021-08-25 11:18:16.079 | INFO     | src.policies:train:109 - Episode 1652\n",
      "2021-08-25 11:18:16.148 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:16.150 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:16.151 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.71\n",
      "2021-08-25 11:18:16.155 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:16.158 | INFO     | src.policies:train:103 - Epoch 426 / 800\n",
      "2021-08-25 11:18:16.159 | INFO     | src.policies:train:109 - Episode 1653\n",
      "2021-08-25 11:18:16.226 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:16.228 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:16.229 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.71\n",
      "2021-08-25 11:18:16.233 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:16.236 | INFO     | src.policies:train:103 - Epoch 427 / 800\n",
      "2021-08-25 11:18:16.236 | INFO     | src.policies:train:109 - Episode 1654\n",
      "2021-08-25 11:18:16.305 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:16.306 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:16.307 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.73\n",
      "2021-08-25 11:18:16.311 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:16.314 | INFO     | src.policies:train:103 - Epoch 428 / 800\n",
      "2021-08-25 11:18:16.315 | INFO     | src.policies:train:109 - Episode 1655\n",
      "2021-08-25 11:18:16.383 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:16.384 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:16.385 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 173.04\n",
      "2021-08-25 11:18:16.390 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:16.393 | INFO     | src.policies:train:103 - Epoch 429 / 800\n",
      "2021-08-25 11:18:16.394 | INFO     | src.policies:train:109 - Episode 1656\n",
      "2021-08-25 11:18:16.461 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:16.463 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:16.464 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 173.88\n",
      "2021-08-25 11:18:16.468 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:16.471 | INFO     | src.policies:train:103 - Epoch 430 / 800\n",
      "2021-08-25 11:18:16.471 | INFO     | src.policies:train:109 - Episode 1657\n",
      "2021-08-25 11:18:16.540 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:18:16.541 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:16.542 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 173.88\n",
      "2021-08-25 11:18:16.547 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:16.550 | INFO     | src.policies:train:103 - Epoch 431 / 800\n",
      "2021-08-25 11:18:16.550 | INFO     | src.policies:train:109 - Episode 1658\n",
      "2021-08-25 11:18:16.617 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:16.618 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:16.619 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.88\n",
      "2021-08-25 11:18:16.624 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:16.627 | INFO     | src.policies:train:103 - Epoch 432 / 800\n",
      "2021-08-25 11:18:16.627 | INFO     | src.policies:train:109 - Episode 1659\n",
      "2021-08-25 11:18:16.693 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:16.695 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:16.696 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.78\n",
      "2021-08-25 11:18:16.700 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:16.703 | INFO     | src.policies:train:103 - Epoch 433 / 800\n",
      "2021-08-25 11:18:16.704 | INFO     | src.policies:train:109 - Episode 1660\n",
      "2021-08-25 11:18:16.770 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:16.771 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:16.772 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.66\n",
      "2021-08-25 11:18:16.777 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:16.780 | INFO     | src.policies:train:103 - Epoch 434 / 800\n",
      "2021-08-25 11:18:16.780 | INFO     | src.policies:train:109 - Episode 1661\n",
      "2021-08-25 11:18:16.844 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:16.845 | INFO     | src.policies:train:121 - Mean episode return: 185.0\n",
      "2021-08-25 11:18:16.846 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.99\n",
      "2021-08-25 11:18:16.847 | INFO     | src.policies:train:109 - Episode 1662\n",
      "2021-08-25 11:18:16.914 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:16.915 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:16.916 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 177.79\n",
      "2021-08-25 11:18:16.917 | WARNING  | src.policies:train:131 - The actual batch size is 385, instead of 200\n",
      "2021-08-25 11:18:16.923 | INFO     | src.policies:train:157 - Total loss: 0.9974024891853333\n",
      "2021-08-25 11:18:16.926 | INFO     | src.policies:train:103 - Epoch 435 / 800\n",
      "2021-08-25 11:18:16.927 | INFO     | src.policies:train:109 - Episode 1663\n",
      "2021-08-25 11:18:16.993 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:16.995 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:16.996 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 178.59\n",
      "2021-08-25 11:18:17.000 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:17.003 | INFO     | src.policies:train:103 - Epoch 436 / 800\n",
      "2021-08-25 11:18:17.004 | INFO     | src.policies:train:109 - Episode 1664\n",
      "2021-08-25 11:18:17.072 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:17.073 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:17.074 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 179.03\n",
      "2021-08-25 11:18:17.079 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:17.081 | INFO     | src.policies:train:103 - Epoch 437 / 800\n",
      "2021-08-25 11:18:17.082 | INFO     | src.policies:train:109 - Episode 1665\n",
      "2021-08-25 11:18:17.149 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:17.151 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:17.152 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 179.03\n",
      "2021-08-25 11:18:17.156 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:17.159 | INFO     | src.policies:train:103 - Epoch 438 / 800\n",
      "2021-08-25 11:18:17.160 | INFO     | src.policies:train:109 - Episode 1666\n",
      "2021-08-25 11:18:17.207 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:17.209 | INFO     | src.policies:train:121 - Mean episode return: 138.0\n",
      "2021-08-25 11:18:17.210 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 178.74\n",
      "2021-08-25 11:18:17.210 | INFO     | src.policies:train:109 - Episode 1667\n",
      "2021-08-25 11:18:17.279 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:17.280 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:17.281 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 179.42\n",
      "2021-08-25 11:18:17.282 | WARNING  | src.policies:train:131 - The actual batch size is 338, instead of 200\n",
      "2021-08-25 11:18:17.288 | INFO     | src.policies:train:157 - Total loss: 0.9970413446426392\n",
      "2021-08-25 11:18:17.290 | INFO     | src.policies:train:103 - Epoch 439 / 800\n",
      "2021-08-25 11:18:17.291 | INFO     | src.policies:train:109 - Episode 1668\n",
      "2021-08-25 11:18:17.351 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:17.353 | INFO     | src.policies:train:121 - Mean episode return: 179.0\n",
      "2021-08-25 11:18:17.353 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 179.21\n",
      "2021-08-25 11:18:17.354 | INFO     | src.policies:train:109 - Episode 1669\n",
      "2021-08-25 11:18:17.422 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:17.423 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:17.424 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 180.0\n",
      "2021-08-25 11:18:17.425 | WARNING  | src.policies:train:131 - The actual batch size is 379, instead of 200\n",
      "2021-08-25 11:18:17.431 | INFO     | src.policies:train:157 - Total loss: 0.9973615407943726\n",
      "2021-08-25 11:18:17.434 | INFO     | src.policies:train:103 - Epoch 440 / 800\n",
      "2021-08-25 11:18:17.435 | INFO     | src.policies:train:109 - Episode 1670\n",
      "2021-08-25 11:18:17.502 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:17.503 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:17.504 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 180.0\n",
      "2021-08-25 11:18:17.509 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:17.512 | INFO     | src.policies:train:103 - Epoch 441 / 800\n",
      "2021-08-25 11:18:17.512 | INFO     | src.policies:train:109 - Episode 1671\n",
      "2021-08-25 11:18:17.580 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:17.581 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:17.582 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 180.72\n",
      "2021-08-25 11:18:17.587 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:17.589 | INFO     | src.policies:train:103 - Epoch 442 / 800\n",
      "2021-08-25 11:18:17.590 | INFO     | src.policies:train:109 - Episode 1672\n",
      "2021-08-25 11:18:17.658 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:17.659 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:17.660 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.43\n",
      "2021-08-25 11:18:17.665 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:17.667 | INFO     | src.policies:train:103 - Epoch 443 / 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:18:17.668 | INFO     | src.policies:train:109 - Episode 1673\n",
      "2021-08-25 11:18:17.738 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:17.740 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:17.741 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.99\n",
      "2021-08-25 11:18:17.745 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:17.748 | INFO     | src.policies:train:103 - Epoch 444 / 800\n",
      "2021-08-25 11:18:17.749 | INFO     | src.policies:train:109 - Episode 1674\n",
      "2021-08-25 11:18:17.815 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:17.817 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:17.818 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.69\n",
      "2021-08-25 11:18:17.822 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:17.825 | INFO     | src.policies:train:103 - Epoch 445 / 800\n",
      "2021-08-25 11:18:17.826 | INFO     | src.policies:train:109 - Episode 1675\n",
      "2021-08-25 11:18:17.893 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:17.894 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:17.895 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 183.21\n",
      "2021-08-25 11:18:17.900 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:17.902 | INFO     | src.policies:train:103 - Epoch 446 / 800\n",
      "2021-08-25 11:18:17.903 | INFO     | src.policies:train:109 - Episode 1676\n",
      "2021-08-25 11:18:17.965 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:17.967 | INFO     | src.policies:train:121 - Mean episode return: 180.0\n",
      "2021-08-25 11:18:17.968 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 183.51\n",
      "2021-08-25 11:18:17.969 | INFO     | src.policies:train:109 - Episode 1677\n",
      "2021-08-25 11:18:18.037 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:18.038 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:18.039 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 184.32\n",
      "2021-08-25 11:18:18.040 | WARNING  | src.policies:train:131 - The actual batch size is 380, instead of 200\n",
      "2021-08-25 11:18:18.046 | INFO     | src.policies:train:157 - Total loss: 0.9973682165145874\n",
      "2021-08-25 11:18:18.049 | INFO     | src.policies:train:103 - Epoch 447 / 800\n",
      "2021-08-25 11:18:18.050 | INFO     | src.policies:train:109 - Episode 1678\n",
      "2021-08-25 11:18:18.117 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:18.118 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:18.120 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 184.72\n",
      "2021-08-25 11:18:18.124 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:18.127 | INFO     | src.policies:train:103 - Epoch 448 / 800\n",
      "2021-08-25 11:18:18.128 | INFO     | src.policies:train:109 - Episode 1679\n",
      "2021-08-25 11:18:18.170 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:18.172 | INFO     | src.policies:train:121 - Mean episode return: 125.0\n",
      "2021-08-25 11:18:18.173 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 183.97\n",
      "2021-08-25 11:18:18.174 | INFO     | src.policies:train:109 - Episode 1680\n",
      "2021-08-25 11:18:18.241 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:18.243 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:18.244 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 184.56\n",
      "2021-08-25 11:18:18.245 | WARNING  | src.policies:train:131 - The actual batch size is 325, instead of 200\n",
      "2021-08-25 11:18:18.251 | INFO     | src.policies:train:157 - Total loss: 0.9969230890274048\n",
      "2021-08-25 11:18:18.254 | INFO     | src.policies:train:103 - Epoch 449 / 800\n",
      "2021-08-25 11:18:18.255 | INFO     | src.policies:train:109 - Episode 1681\n",
      "2021-08-25 11:18:18.323 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:18.325 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:18.326 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 184.56\n",
      "2021-08-25 11:18:18.331 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:18.334 | INFO     | src.policies:train:103 - Epoch 450 / 800\n",
      "2021-08-25 11:18:18.335 | INFO     | src.policies:train:109 - Episode 1682\n",
      "2021-08-25 11:18:18.404 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:18.405 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:18.406 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 184.97\n",
      "2021-08-25 11:18:18.411 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:18.414 | INFO     | src.policies:train:103 - Epoch 451 / 800\n",
      "2021-08-25 11:18:18.415 | INFO     | src.policies:train:109 - Episode 1683\n",
      "2021-08-25 11:18:18.485 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:18.487 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:18.488 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 184.97\n",
      "2021-08-25 11:18:18.492 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:18.495 | INFO     | src.policies:train:103 - Epoch 452 / 800\n",
      "2021-08-25 11:18:18.496 | INFO     | src.policies:train:109 - Episode 1684\n",
      "2021-08-25 11:18:18.556 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:18.557 | INFO     | src.policies:train:121 - Mean episode return: 170.0\n",
      "2021-08-25 11:18:18.558 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 184.67\n",
      "2021-08-25 11:18:18.559 | INFO     | src.policies:train:109 - Episode 1685\n",
      "2021-08-25 11:18:18.627 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:18.628 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:18.629 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 184.86\n",
      "2021-08-25 11:18:18.630 | WARNING  | src.policies:train:131 - The actual batch size is 370, instead of 200\n",
      "2021-08-25 11:18:18.636 | INFO     | src.policies:train:157 - Total loss: 0.9972969889640808\n",
      "2021-08-25 11:18:18.639 | INFO     | src.policies:train:103 - Epoch 453 / 800\n",
      "2021-08-25 11:18:18.640 | INFO     | src.policies:train:109 - Episode 1686\n",
      "2021-08-25 11:18:18.705 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:18.706 | INFO     | src.policies:train:121 - Mean episode return: 194.0\n",
      "2021-08-25 11:18:18.708 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 185.37\n",
      "2021-08-25 11:18:18.708 | INFO     | src.policies:train:109 - Episode 1687\n",
      "2021-08-25 11:18:18.776 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:18.777 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:18.778 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 185.63\n",
      "2021-08-25 11:18:18.779 | WARNING  | src.policies:train:131 - The actual batch size is 394, instead of 200\n",
      "2021-08-25 11:18:18.784 | INFO     | src.policies:train:157 - Total loss: 0.9974617958068848\n",
      "2021-08-25 11:18:18.787 | INFO     | src.policies:train:103 - Epoch 454 / 800\n",
      "2021-08-25 11:18:18.788 | INFO     | src.policies:train:109 - Episode 1688\n",
      "2021-08-25 11:18:18.851 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:18.852 | INFO     | src.policies:train:121 - Mean episode return: 184.0\n",
      "2021-08-25 11:18:18.853 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 185.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:18:18.854 | INFO     | src.policies:train:109 - Episode 1689\n",
      "2021-08-25 11:18:18.922 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:18.924 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:18.925 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 185.51\n",
      "2021-08-25 11:18:18.925 | WARNING  | src.policies:train:131 - The actual batch size is 384, instead of 200\n",
      "2021-08-25 11:18:18.932 | INFO     | src.policies:train:157 - Total loss: 0.9973956942558289\n",
      "2021-08-25 11:18:18.935 | INFO     | src.policies:train:103 - Epoch 455 / 800\n",
      "2021-08-25 11:18:18.936 | INFO     | src.policies:train:109 - Episode 1690\n",
      "2021-08-25 11:18:19.004 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:19.005 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:19.006 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 186.26\n",
      "2021-08-25 11:18:19.011 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:19.014 | INFO     | src.policies:train:103 - Epoch 456 / 800\n",
      "2021-08-25 11:18:19.015 | INFO     | src.policies:train:109 - Episode 1691\n",
      "2021-08-25 11:18:19.073 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:19.075 | INFO     | src.policies:train:121 - Mean episode return: 171.0\n",
      "2021-08-25 11:18:19.076 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 186.15\n",
      "2021-08-25 11:18:19.076 | INFO     | src.policies:train:109 - Episode 1692\n",
      "2021-08-25 11:18:19.145 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:19.146 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:19.147 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 186.15\n",
      "2021-08-25 11:18:19.148 | WARNING  | src.policies:train:131 - The actual batch size is 371, instead of 200\n",
      "2021-08-25 11:18:19.153 | INFO     | src.policies:train:157 - Total loss: 0.9973043203353882\n",
      "2021-08-25 11:18:19.156 | INFO     | src.policies:train:103 - Epoch 457 / 800\n",
      "2021-08-25 11:18:19.157 | INFO     | src.policies:train:109 - Episode 1693\n",
      "2021-08-25 11:18:19.224 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:19.225 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:19.226 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 186.66\n",
      "2021-08-25 11:18:19.231 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:19.233 | INFO     | src.policies:train:103 - Epoch 458 / 800\n",
      "2021-08-25 11:18:19.234 | INFO     | src.policies:train:109 - Episode 1694\n",
      "2021-08-25 11:18:19.303 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:19.305 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:19.306 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 187.24\n",
      "2021-08-25 11:18:19.311 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:19.313 | INFO     | src.policies:train:103 - Epoch 459 / 800\n",
      "2021-08-25 11:18:19.314 | INFO     | src.policies:train:109 - Episode 1695\n",
      "2021-08-25 11:18:19.382 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:19.383 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:19.384 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 187.24\n",
      "2021-08-25 11:18:19.388 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:19.391 | INFO     | src.policies:train:103 - Epoch 460 / 800\n",
      "2021-08-25 11:18:19.392 | INFO     | src.policies:train:109 - Episode 1696\n",
      "2021-08-25 11:18:19.461 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:19.462 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:19.463 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 187.46\n",
      "2021-08-25 11:18:19.468 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:19.470 | INFO     | src.policies:train:103 - Epoch 461 / 800\n",
      "2021-08-25 11:18:19.471 | INFO     | src.policies:train:109 - Episode 1697\n",
      "2021-08-25 11:18:19.541 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:19.542 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:19.543 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 187.46\n",
      "2021-08-25 11:18:19.548 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:19.551 | INFO     | src.policies:train:103 - Epoch 462 / 800\n",
      "2021-08-25 11:18:19.552 | INFO     | src.policies:train:109 - Episode 1698\n",
      "2021-08-25 11:18:19.621 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:19.623 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:19.624 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 187.46\n",
      "2021-08-25 11:18:19.628 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:19.630 | INFO     | src.policies:train:103 - Epoch 463 / 800\n",
      "2021-08-25 11:18:19.631 | INFO     | src.policies:train:109 - Episode 1699\n",
      "2021-08-25 11:18:19.699 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:19.700 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:19.701 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 187.89\n",
      "2021-08-25 11:18:19.706 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:19.708 | INFO     | src.policies:train:103 - Epoch 464 / 800\n",
      "2021-08-25 11:18:19.709 | INFO     | src.policies:train:109 - Episode 1700\n",
      "2021-08-25 11:18:19.779 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:19.780 | INFO     | src.policies:train:121 - Mean episode return: 198.0\n",
      "2021-08-25 11:18:19.781 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 188.15\n",
      "2021-08-25 11:18:19.782 | INFO     | src.policies:train:109 - Episode 1701\n",
      "2021-08-25 11:18:19.852 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:19.853 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:19.854 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 188.15\n",
      "2021-08-25 11:18:19.855 | WARNING  | src.policies:train:131 - The actual batch size is 398, instead of 200\n",
      "2021-08-25 11:18:19.861 | INFO     | src.policies:train:157 - Total loss: 0.9974871873855591\n",
      "2021-08-25 11:18:19.863 | INFO     | src.policies:train:103 - Epoch 465 / 800\n",
      "2021-08-25 11:18:19.864 | INFO     | src.policies:train:109 - Episode 1702\n",
      "2021-08-25 11:18:19.926 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:19.927 | INFO     | src.policies:train:121 - Mean episode return: 177.0\n",
      "2021-08-25 11:18:19.928 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 188.21\n",
      "2021-08-25 11:18:19.929 | INFO     | src.policies:train:109 - Episode 1703\n",
      "2021-08-25 11:18:19.997 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:19.998 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:19.999 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 188.52\n",
      "2021-08-25 11:18:20.000 | WARNING  | src.policies:train:131 - The actual batch size is 377, instead of 200\n",
      "2021-08-25 11:18:20.006 | INFO     | src.policies:train:157 - Total loss: 0.9973474144935608\n",
      "2021-08-25 11:18:20.009 | INFO     | src.policies:train:103 - Epoch 466 / 800\n",
      "2021-08-25 11:18:20.010 | INFO     | src.policies:train:109 - Episode 1704\n",
      "2021-08-25 11:18:20.078 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:20.080 | INFO     | src.policies:train:121 - Mean episode return: 197.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:18:20.081 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 188.49\n",
      "2021-08-25 11:18:20.081 | INFO     | src.policies:train:109 - Episode 1705\n",
      "2021-08-25 11:18:20.151 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:20.153 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:20.154 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 189.13\n",
      "2021-08-25 11:18:20.155 | WARNING  | src.policies:train:131 - The actual batch size is 397, instead of 200\n",
      "2021-08-25 11:18:20.161 | INFO     | src.policies:train:157 - Total loss: 0.9974811673164368\n",
      "2021-08-25 11:18:20.163 | INFO     | src.policies:train:103 - Epoch 467 / 800\n",
      "2021-08-25 11:18:20.164 | INFO     | src.policies:train:109 - Episode 1706\n",
      "2021-08-25 11:18:20.231 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:20.233 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:20.234 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 189.64\n",
      "2021-08-25 11:18:20.238 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:20.241 | INFO     | src.policies:train:103 - Epoch 468 / 800\n",
      "2021-08-25 11:18:20.241 | INFO     | src.policies:train:109 - Episode 1707\n",
      "2021-08-25 11:18:20.295 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:20.297 | INFO     | src.policies:train:121 - Mean episode return: 156.0\n",
      "2021-08-25 11:18:20.298 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 189.76\n",
      "2021-08-25 11:18:20.299 | INFO     | src.policies:train:109 - Episode 1708\n",
      "2021-08-25 11:18:20.366 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:20.367 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:20.368 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 191.08\n",
      "2021-08-25 11:18:20.369 | WARNING  | src.policies:train:131 - The actual batch size is 356, instead of 200\n",
      "2021-08-25 11:18:20.375 | INFO     | src.policies:train:157 - Total loss: 0.9971907734870911\n",
      "2021-08-25 11:18:20.378 | INFO     | src.policies:train:103 - Epoch 469 / 800\n",
      "2021-08-25 11:18:20.379 | INFO     | src.policies:train:109 - Episode 1709\n",
      "2021-08-25 11:18:20.433 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:20.434 | INFO     | src.policies:train:121 - Mean episode return: 156.0\n",
      "2021-08-25 11:18:20.435 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 190.64\n",
      "2021-08-25 11:18:20.436 | INFO     | src.policies:train:109 - Episode 1710\n",
      "2021-08-25 11:18:20.504 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:20.505 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:20.506 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 190.64\n",
      "2021-08-25 11:18:20.507 | WARNING  | src.policies:train:131 - The actual batch size is 356, instead of 200\n",
      "2021-08-25 11:18:20.512 | INFO     | src.policies:train:157 - Total loss: 0.9971907734870911\n",
      "2021-08-25 11:18:20.515 | INFO     | src.policies:train:103 - Epoch 470 / 800\n",
      "2021-08-25 11:18:20.516 | INFO     | src.policies:train:109 - Episode 1711\n",
      "2021-08-25 11:18:20.584 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:20.585 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:20.586 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 190.64\n",
      "2021-08-25 11:18:20.591 | INFO     | src.policies:train:157 - Total loss: 0.9949998259544373\n",
      "2021-08-25 11:18:20.594 | INFO     | src.policies:train:103 - Epoch 471 / 800\n",
      "2021-08-25 11:18:20.595 | INFO     | src.policies:train:109 - Episode 1712\n",
      "2021-08-25 11:18:20.661 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:20.662 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:20.663 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 191.3\n",
      "2021-08-25 11:18:20.668 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:20.670 | INFO     | src.policies:train:103 - Epoch 472 / 800\n",
      "2021-08-25 11:18:20.671 | INFO     | src.policies:train:109 - Episode 1713\n",
      "2021-08-25 11:18:20.738 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:20.739 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:20.740 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 191.3\n",
      "2021-08-25 11:18:20.744 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:20.747 | INFO     | src.policies:train:103 - Epoch 473 / 800\n",
      "2021-08-25 11:18:20.748 | INFO     | src.policies:train:109 - Episode 1714\n",
      "2021-08-25 11:18:20.805 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:20.806 | INFO     | src.policies:train:121 - Mean episode return: 164.0\n",
      "2021-08-25 11:18:20.807 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 190.94\n",
      "2021-08-25 11:18:20.808 | INFO     | src.policies:train:109 - Episode 1715\n",
      "2021-08-25 11:18:20.846 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:20.847 | INFO     | src.policies:train:121 - Mean episode return: 108.0\n",
      "2021-08-25 11:18:20.848 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 190.36\n",
      "2021-08-25 11:18:20.849 | WARNING  | src.policies:train:131 - The actual batch size is 272, instead of 200\n",
      "2021-08-25 11:18:20.855 | INFO     | src.policies:train:157 - Total loss: 0.9963230490684509\n",
      "2021-08-25 11:18:20.857 | INFO     | src.policies:train:103 - Epoch 474 / 800\n",
      "2021-08-25 11:18:20.858 | INFO     | src.policies:train:109 - Episode 1716\n",
      "2021-08-25 11:18:20.924 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:20.926 | INFO     | src.policies:train:121 - Mean episode return: 196.0\n",
      "2021-08-25 11:18:20.927 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 190.32\n",
      "2021-08-25 11:18:20.928 | INFO     | src.policies:train:109 - Episode 1717\n",
      "2021-08-25 11:18:20.989 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:20.991 | INFO     | src.policies:train:121 - Mean episode return: 181.0\n",
      "2021-08-25 11:18:20.992 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 190.13\n",
      "2021-08-25 11:18:20.992 | WARNING  | src.policies:train:131 - The actual batch size is 377, instead of 200\n",
      "2021-08-25 11:18:20.998 | INFO     | src.policies:train:157 - Total loss: 0.997347354888916\n",
      "2021-08-25 11:18:21.001 | INFO     | src.policies:train:103 - Epoch 475 / 800\n",
      "2021-08-25 11:18:21.002 | INFO     | src.policies:train:109 - Episode 1718\n",
      "2021-08-25 11:18:21.062 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:21.064 | INFO     | src.policies:train:121 - Mean episode return: 170.0\n",
      "2021-08-25 11:18:21.065 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 189.83\n",
      "2021-08-25 11:18:21.065 | INFO     | src.policies:train:109 - Episode 1719\n",
      "2021-08-25 11:18:21.115 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:21.116 | INFO     | src.policies:train:121 - Mean episode return: 142.0\n",
      "2021-08-25 11:18:21.117 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 189.25\n",
      "2021-08-25 11:18:21.118 | WARNING  | src.policies:train:131 - The actual batch size is 312, instead of 200\n",
      "2021-08-25 11:18:21.124 | INFO     | src.policies:train:157 - Total loss: 0.9967947006225586\n",
      "2021-08-25 11:18:21.127 | INFO     | src.policies:train:103 - Epoch 476 / 800\n",
      "2021-08-25 11:18:21.128 | INFO     | src.policies:train:109 - Episode 1720\n",
      "2021-08-25 11:18:21.194 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:21.196 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:18:21.196 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 189.6\n",
      "2021-08-25 11:18:21.201 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:21.203 | INFO     | src.policies:train:103 - Epoch 477 / 800\n",
      "2021-08-25 11:18:21.204 | INFO     | src.policies:train:109 - Episode 1721\n",
      "2021-08-25 11:18:21.274 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:21.276 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:21.277 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 189.78\n",
      "2021-08-25 11:18:21.281 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:21.283 | INFO     | src.policies:train:103 - Epoch 478 / 800\n",
      "2021-08-25 11:18:21.284 | INFO     | src.policies:train:109 - Episode 1722\n",
      "2021-08-25 11:18:21.335 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:21.337 | INFO     | src.policies:train:121 - Mean episode return: 148.0\n",
      "2021-08-25 11:18:21.338 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 189.55\n",
      "2021-08-25 11:18:21.338 | INFO     | src.policies:train:109 - Episode 1723\n",
      "2021-08-25 11:18:21.394 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:21.395 | INFO     | src.policies:train:121 - Mean episode return: 162.0\n",
      "2021-08-25 11:18:21.395 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 189.17\n",
      "2021-08-25 11:18:21.396 | WARNING  | src.policies:train:131 - The actual batch size is 310, instead of 200\n",
      "2021-08-25 11:18:21.402 | INFO     | src.policies:train:157 - Total loss: 0.9967740774154663\n",
      "2021-08-25 11:18:21.405 | INFO     | src.policies:train:103 - Epoch 479 / 800\n",
      "2021-08-25 11:18:21.405 | INFO     | src.policies:train:109 - Episode 1724\n",
      "2021-08-25 11:18:21.472 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:21.474 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:21.475 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 189.17\n",
      "2021-08-25 11:18:21.479 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:21.482 | INFO     | src.policies:train:103 - Epoch 480 / 800\n",
      "2021-08-25 11:18:21.483 | INFO     | src.policies:train:109 - Episode 1725\n",
      "2021-08-25 11:18:21.548 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:21.550 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:21.551 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 189.49\n",
      "2021-08-25 11:18:21.555 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:21.558 | INFO     | src.policies:train:103 - Epoch 481 / 800\n",
      "2021-08-25 11:18:21.558 | INFO     | src.policies:train:109 - Episode 1726\n",
      "2021-08-25 11:18:21.626 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:21.628 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:21.629 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 189.49\n",
      "2021-08-25 11:18:21.634 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:21.636 | INFO     | src.policies:train:103 - Epoch 482 / 800\n",
      "2021-08-25 11:18:21.637 | INFO     | src.policies:train:109 - Episode 1727\n",
      "2021-08-25 11:18:21.706 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:21.707 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:21.708 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 189.49\n",
      "2021-08-25 11:18:21.713 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:21.716 | INFO     | src.policies:train:103 - Epoch 483 / 800\n",
      "2021-08-25 11:18:21.716 | INFO     | src.policies:train:109 - Episode 1728\n",
      "2021-08-25 11:18:21.784 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:21.785 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:21.786 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 189.95\n",
      "2021-08-25 11:18:21.791 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:21.793 | INFO     | src.policies:train:103 - Epoch 484 / 800\n",
      "2021-08-25 11:18:21.794 | INFO     | src.policies:train:109 - Episode 1729\n",
      "2021-08-25 11:18:21.846 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:21.847 | INFO     | src.policies:train:121 - Mean episode return: 151.0\n",
      "2021-08-25 11:18:21.848 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 189.46\n",
      "2021-08-25 11:18:21.849 | INFO     | src.policies:train:109 - Episode 1730\n",
      "2021-08-25 11:18:21.904 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:21.905 | INFO     | src.policies:train:121 - Mean episode return: 159.0\n",
      "2021-08-25 11:18:21.906 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 189.05\n",
      "2021-08-25 11:18:21.907 | WARNING  | src.policies:train:131 - The actual batch size is 310, instead of 200\n",
      "2021-08-25 11:18:21.913 | INFO     | src.policies:train:157 - Total loss: 0.9967740774154663\n",
      "2021-08-25 11:18:21.915 | INFO     | src.policies:train:103 - Epoch 485 / 800\n",
      "2021-08-25 11:18:21.916 | INFO     | src.policies:train:109 - Episode 1731\n",
      "2021-08-25 11:18:21.982 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:21.984 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:21.985 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 189.36\n",
      "2021-08-25 11:18:21.990 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:21.992 | INFO     | src.policies:train:103 - Epoch 486 / 800\n",
      "2021-08-25 11:18:21.993 | INFO     | src.policies:train:109 - Episode 1732\n",
      "2021-08-25 11:18:22.057 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:22.058 | INFO     | src.policies:train:121 - Mean episode return: 183.0\n",
      "2021-08-25 11:18:22.059 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 189.2\n",
      "2021-08-25 11:18:22.060 | INFO     | src.policies:train:109 - Episode 1733\n",
      "2021-08-25 11:18:22.129 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:22.130 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:22.131 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 189.2\n",
      "2021-08-25 11:18:22.132 | WARNING  | src.policies:train:131 - The actual batch size is 383, instead of 200\n",
      "2021-08-25 11:18:22.138 | INFO     | src.policies:train:157 - Total loss: 0.9973888993263245\n",
      "2021-08-25 11:18:22.140 | INFO     | src.policies:train:103 - Epoch 487 / 800\n",
      "2021-08-25 11:18:22.142 | INFO     | src.policies:train:109 - Episode 1734\n",
      "2021-08-25 11:18:22.190 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:22.191 | INFO     | src.policies:train:121 - Mean episode return: 138.0\n",
      "2021-08-25 11:18:22.192 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 188.58\n",
      "2021-08-25 11:18:22.193 | INFO     | src.policies:train:109 - Episode 1735\n",
      "2021-08-25 11:18:22.258 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:22.259 | INFO     | src.policies:train:121 - Mean episode return: 195.0\n",
      "2021-08-25 11:18:22.260 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 188.53\n",
      "2021-08-25 11:18:22.261 | WARNING  | src.policies:train:131 - The actual batch size is 333, instead of 200\n",
      "2021-08-25 11:18:22.267 | INFO     | src.policies:train:157 - Total loss: 0.996997058391571\n",
      "2021-08-25 11:18:22.269 | INFO     | src.policies:train:103 - Epoch 488 / 800\n",
      "2021-08-25 11:18:22.270 | INFO     | src.policies:train:109 - Episode 1736\n",
      "2021-08-25 11:18:22.341 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:18:22.342 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:22.343 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 188.53\n",
      "2021-08-25 11:18:22.348 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:22.350 | INFO     | src.policies:train:103 - Epoch 489 / 800\n",
      "2021-08-25 11:18:22.351 | INFO     | src.policies:train:109 - Episode 1737\n",
      "2021-08-25 11:18:22.418 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:22.420 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:22.421 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 188.53\n",
      "2021-08-25 11:18:22.426 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:22.428 | INFO     | src.policies:train:103 - Epoch 490 / 800\n",
      "2021-08-25 11:18:22.429 | INFO     | src.policies:train:109 - Episode 1738\n",
      "2021-08-25 11:18:22.476 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:22.478 | INFO     | src.policies:train:121 - Mean episode return: 134.0\n",
      "2021-08-25 11:18:22.479 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 187.87\n",
      "2021-08-25 11:18:22.479 | INFO     | src.policies:train:109 - Episode 1739\n",
      "2021-08-25 11:18:22.550 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:22.551 | INFO     | src.policies:train:121 - Mean episode return: 199.0\n",
      "2021-08-25 11:18:22.552 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 188.15\n",
      "2021-08-25 11:18:22.553 | WARNING  | src.policies:train:131 - The actual batch size is 333, instead of 200\n",
      "2021-08-25 11:18:22.558 | INFO     | src.policies:train:157 - Total loss: 0.9969967007637024\n",
      "2021-08-25 11:18:22.561 | INFO     | src.policies:train:103 - Epoch 491 / 800\n",
      "2021-08-25 11:18:22.562 | INFO     | src.policies:train:109 - Episode 1740\n",
      "2021-08-25 11:18:22.627 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:22.629 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:22.630 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 188.72\n",
      "2021-08-25 11:18:22.635 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:22.637 | INFO     | src.policies:train:103 - Epoch 492 / 800\n",
      "2021-08-25 11:18:22.638 | INFO     | src.policies:train:109 - Episode 1741\n",
      "2021-08-25 11:18:22.683 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:22.685 | INFO     | src.policies:train:121 - Mean episode return: 129.0\n",
      "2021-08-25 11:18:22.686 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 188.01\n",
      "2021-08-25 11:18:22.687 | INFO     | src.policies:train:109 - Episode 1742\n",
      "2021-08-25 11:18:22.754 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:22.756 | INFO     | src.policies:train:121 - Mean episode return: 189.0\n",
      "2021-08-25 11:18:22.757 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 188.26\n",
      "2021-08-25 11:18:22.758 | WARNING  | src.policies:train:131 - The actual batch size is 318, instead of 200\n",
      "2021-08-25 11:18:22.765 | INFO     | src.policies:train:157 - Total loss: 0.9968551397323608\n",
      "2021-08-25 11:18:22.768 | INFO     | src.policies:train:103 - Epoch 493 / 800\n",
      "2021-08-25 11:18:22.770 | INFO     | src.policies:train:109 - Episode 1743\n",
      "2021-08-25 11:18:22.834 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:22.836 | INFO     | src.policies:train:121 - Mean episode return: 186.0\n",
      "2021-08-25 11:18:22.837 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 188.12\n",
      "2021-08-25 11:18:22.838 | INFO     | src.policies:train:109 - Episode 1744\n",
      "2021-08-25 11:18:22.908 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:22.909 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:22.910 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 188.12\n",
      "2021-08-25 11:18:22.911 | WARNING  | src.policies:train:131 - The actual batch size is 386, instead of 200\n",
      "2021-08-25 11:18:22.917 | INFO     | src.policies:train:157 - Total loss: 0.9974091053009033\n",
      "2021-08-25 11:18:22.919 | INFO     | src.policies:train:103 - Epoch 494 / 800\n",
      "2021-08-25 11:18:22.920 | INFO     | src.policies:train:109 - Episode 1745\n",
      "2021-08-25 11:18:22.988 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:22.989 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:22.990 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 188.12\n",
      "2021-08-25 11:18:22.995 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:22.998 | INFO     | src.policies:train:103 - Epoch 495 / 800\n",
      "2021-08-25 11:18:22.998 | INFO     | src.policies:train:109 - Episode 1746\n",
      "2021-08-25 11:18:23.068 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:23.070 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:23.071 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 188.12\n",
      "2021-08-25 11:18:23.075 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:23.078 | INFO     | src.policies:train:103 - Epoch 496 / 800\n",
      "2021-08-25 11:18:23.079 | INFO     | src.policies:train:109 - Episode 1747\n",
      "2021-08-25 11:18:23.131 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:23.133 | INFO     | src.policies:train:121 - Mean episode return: 155.0\n",
      "2021-08-25 11:18:23.134 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 187.67\n",
      "2021-08-25 11:18:23.135 | INFO     | src.policies:train:109 - Episode 1748\n",
      "2021-08-25 11:18:23.194 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:23.195 | INFO     | src.policies:train:121 - Mean episode return: 173.0\n",
      "2021-08-25 11:18:23.195 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 188.72\n",
      "2021-08-25 11:18:23.196 | WARNING  | src.policies:train:131 - The actual batch size is 328, instead of 200\n",
      "2021-08-25 11:18:23.202 | INFO     | src.policies:train:157 - Total loss: 0.9969509840011597\n",
      "2021-08-25 11:18:23.204 | INFO     | src.policies:train:103 - Epoch 497 / 800\n",
      "2021-08-25 11:18:23.205 | INFO     | src.policies:train:109 - Episode 1749\n",
      "2021-08-25 11:18:23.255 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:23.256 | INFO     | src.policies:train:121 - Mean episode return: 150.0\n",
      "2021-08-25 11:18:23.257 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 188.22\n",
      "2021-08-25 11:18:23.258 | INFO     | src.policies:train:109 - Episode 1750\n",
      "2021-08-25 11:18:23.326 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:23.327 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:23.328 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 188.22\n",
      "2021-08-25 11:18:23.329 | WARNING  | src.policies:train:131 - The actual batch size is 350, instead of 200\n",
      "2021-08-25 11:18:23.335 | INFO     | src.policies:train:157 - Total loss: 0.9971429705619812\n",
      "2021-08-25 11:18:23.337 | INFO     | src.policies:train:103 - Epoch 498 / 800\n",
      "2021-08-25 11:18:23.338 | INFO     | src.policies:train:109 - Episode 1751\n",
      "2021-08-25 11:18:23.387 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:23.389 | INFO     | src.policies:train:121 - Mean episode return: 137.0\n",
      "2021-08-25 11:18:23.389 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 187.59\n",
      "2021-08-25 11:18:23.390 | INFO     | src.policies:train:109 - Episode 1752\n",
      "2021-08-25 11:18:23.460 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:23.462 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:18:23.462 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 187.59\n",
      "2021-08-25 11:18:23.463 | WARNING  | src.policies:train:131 - The actual batch size is 337, instead of 200\n",
      "2021-08-25 11:18:23.469 | INFO     | src.policies:train:157 - Total loss: 0.9970325827598572\n",
      "2021-08-25 11:18:23.471 | INFO     | src.policies:train:103 - Epoch 499 / 800\n",
      "2021-08-25 11:18:23.472 | INFO     | src.policies:train:109 - Episode 1753\n",
      "2021-08-25 11:18:23.541 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:23.542 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:23.543 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 187.59\n",
      "2021-08-25 11:18:23.548 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:23.550 | INFO     | src.policies:train:103 - Epoch 500 / 800\n",
      "2021-08-25 11:18:23.551 | INFO     | src.policies:train:109 - Episode 1754\n",
      "2021-08-25 11:18:23.620 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:23.621 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:23.622 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 187.59\n",
      "2021-08-25 11:18:23.627 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:23.630 | INFO     | src.policies:train:103 - Epoch 501 / 800\n",
      "2021-08-25 11:18:23.630 | INFO     | src.policies:train:109 - Episode 1755\n",
      "2021-08-25 11:18:23.681 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:23.683 | INFO     | src.policies:train:121 - Mean episode return: 147.0\n",
      "2021-08-25 11:18:23.683 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 187.06\n",
      "2021-08-25 11:18:23.684 | INFO     | src.policies:train:109 - Episode 1756\n",
      "2021-08-25 11:18:23.732 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:23.733 | INFO     | src.policies:train:121 - Mean episode return: 137.0\n",
      "2021-08-25 11:18:23.734 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 186.43\n",
      "2021-08-25 11:18:23.735 | WARNING  | src.policies:train:131 - The actual batch size is 284, instead of 200\n",
      "2021-08-25 11:18:23.740 | INFO     | src.policies:train:157 - Total loss: 0.9964788556098938\n",
      "2021-08-25 11:18:23.743 | INFO     | src.policies:train:103 - Epoch 502 / 800\n",
      "2021-08-25 11:18:23.745 | INFO     | src.policies:train:109 - Episode 1757\n",
      "2021-08-25 11:18:23.788 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:23.789 | INFO     | src.policies:train:121 - Mean episode return: 126.0\n",
      "2021-08-25 11:18:23.790 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 185.69\n",
      "2021-08-25 11:18:23.791 | INFO     | src.policies:train:109 - Episode 1758\n",
      "2021-08-25 11:18:23.856 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:23.857 | INFO     | src.policies:train:121 - Mean episode return: 191.0\n",
      "2021-08-25 11:18:23.858 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 185.6\n",
      "2021-08-25 11:18:23.859 | WARNING  | src.policies:train:131 - The actual batch size is 317, instead of 200\n",
      "2021-08-25 11:18:23.865 | INFO     | src.policies:train:157 - Total loss: 0.9968451261520386\n",
      "2021-08-25 11:18:23.868 | INFO     | src.policies:train:103 - Epoch 503 / 800\n",
      "2021-08-25 11:18:23.869 | INFO     | src.policies:train:109 - Episode 1759\n",
      "2021-08-25 11:18:23.927 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:23.928 | INFO     | src.policies:train:121 - Mean episode return: 174.0\n",
      "2021-08-25 11:18:23.929 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 185.34\n",
      "2021-08-25 11:18:23.930 | INFO     | src.policies:train:109 - Episode 1760\n",
      "2021-08-25 11:18:23.991 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:23.992 | INFO     | src.policies:train:121 - Mean episode return: 172.0\n",
      "2021-08-25 11:18:23.993 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 185.06\n",
      "2021-08-25 11:18:23.994 | WARNING  | src.policies:train:131 - The actual batch size is 346, instead of 200\n",
      "2021-08-25 11:18:24.000 | INFO     | src.policies:train:157 - Total loss: 0.997109591960907\n",
      "2021-08-25 11:18:24.002 | INFO     | src.policies:train:103 - Epoch 504 / 800\n",
      "2021-08-25 11:18:24.003 | INFO     | src.policies:train:109 - Episode 1761\n",
      "2021-08-25 11:18:24.067 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:24.068 | INFO     | src.policies:train:121 - Mean episode return: 189.0\n",
      "2021-08-25 11:18:24.069 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 185.1\n",
      "2021-08-25 11:18:24.070 | INFO     | src.policies:train:109 - Episode 1762\n",
      "2021-08-25 11:18:24.138 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:24.139 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:24.140 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 185.1\n",
      "2021-08-25 11:18:24.141 | WARNING  | src.policies:train:131 - The actual batch size is 389, instead of 200\n",
      "2021-08-25 11:18:24.147 | INFO     | src.policies:train:157 - Total loss: 0.9974290728569031\n",
      "2021-08-25 11:18:24.149 | INFO     | src.policies:train:103 - Epoch 505 / 800\n",
      "2021-08-25 11:18:24.150 | INFO     | src.policies:train:109 - Episode 1763\n",
      "2021-08-25 11:18:24.193 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:24.194 | INFO     | src.policies:train:121 - Mean episode return: 121.0\n",
      "2021-08-25 11:18:24.195 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 184.31\n",
      "2021-08-25 11:18:24.196 | INFO     | src.policies:train:109 - Episode 1764\n",
      "2021-08-25 11:18:24.250 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:24.252 | INFO     | src.policies:train:121 - Mean episode return: 152.0\n",
      "2021-08-25 11:18:24.252 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 183.83\n",
      "2021-08-25 11:18:24.253 | WARNING  | src.policies:train:131 - The actual batch size is 273, instead of 200\n",
      "2021-08-25 11:18:24.259 | INFO     | src.policies:train:157 - Total loss: 0.9963369369506836\n",
      "2021-08-25 11:18:24.262 | INFO     | src.policies:train:103 - Epoch 506 / 800\n",
      "2021-08-25 11:18:24.263 | INFO     | src.policies:train:109 - Episode 1765\n",
      "2021-08-25 11:18:24.312 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:24.313 | INFO     | src.policies:train:121 - Mean episode return: 144.0\n",
      "2021-08-25 11:18:24.314 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 183.27\n",
      "2021-08-25 11:18:24.315 | INFO     | src.policies:train:109 - Episode 1766\n",
      "2021-08-25 11:18:24.369 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:24.371 | INFO     | src.policies:train:121 - Mean episode return: 153.0\n",
      "2021-08-25 11:18:24.371 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 183.42\n",
      "2021-08-25 11:18:24.372 | WARNING  | src.policies:train:131 - The actual batch size is 297, instead of 200\n",
      "2021-08-25 11:18:24.378 | INFO     | src.policies:train:157 - Total loss: 0.9966328144073486\n",
      "2021-08-25 11:18:24.381 | INFO     | src.policies:train:103 - Epoch 507 / 800\n",
      "2021-08-25 11:18:24.382 | INFO     | src.policies:train:109 - Episode 1767\n",
      "2021-08-25 11:18:24.450 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:24.451 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:24.452 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 183.42\n",
      "2021-08-25 11:18:24.458 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:24.460 | INFO     | src.policies:train:103 - Epoch 508 / 800\n",
      "2021-08-25 11:18:24.461 | INFO     | src.policies:train:109 - Episode 1768\n",
      "2021-08-25 11:18:24.528 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:18:24.529 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:24.530 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 183.63\n",
      "2021-08-25 11:18:24.535 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:24.538 | INFO     | src.policies:train:103 - Epoch 509 / 800\n",
      "2021-08-25 11:18:24.539 | INFO     | src.policies:train:109 - Episode 1769\n",
      "2021-08-25 11:18:24.608 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:24.610 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:24.611 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 183.63\n",
      "2021-08-25 11:18:24.616 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:24.619 | INFO     | src.policies:train:103 - Epoch 510 / 800\n",
      "2021-08-25 11:18:24.619 | INFO     | src.policies:train:109 - Episode 1770\n",
      "2021-08-25 11:18:24.687 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:24.689 | INFO     | src.policies:train:121 - Mean episode return: 194.0\n",
      "2021-08-25 11:18:24.690 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 183.57\n",
      "2021-08-25 11:18:24.690 | INFO     | src.policies:train:109 - Episode 1771\n",
      "2021-08-25 11:18:24.759 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:24.760 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:24.761 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 183.57\n",
      "2021-08-25 11:18:24.762 | WARNING  | src.policies:train:131 - The actual batch size is 394, instead of 200\n",
      "2021-08-25 11:18:24.768 | INFO     | src.policies:train:157 - Total loss: 0.99746173620224\n",
      "2021-08-25 11:18:24.770 | INFO     | src.policies:train:103 - Epoch 511 / 800\n",
      "2021-08-25 11:18:24.772 | INFO     | src.policies:train:109 - Episode 1772\n",
      "2021-08-25 11:18:24.841 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:24.843 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:24.844 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 183.57\n",
      "2021-08-25 11:18:24.848 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:24.851 | INFO     | src.policies:train:103 - Epoch 512 / 800\n",
      "2021-08-25 11:18:24.852 | INFO     | src.policies:train:109 - Episode 1773\n",
      "2021-08-25 11:18:24.915 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:24.917 | INFO     | src.policies:train:121 - Mean episode return: 185.0\n",
      "2021-08-25 11:18:24.918 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 183.42\n",
      "2021-08-25 11:18:24.919 | INFO     | src.policies:train:109 - Episode 1774\n",
      "2021-08-25 11:18:24.988 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:24.990 | INFO     | src.policies:train:121 - Mean episode return: 198.0\n",
      "2021-08-25 11:18:24.991 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 183.4\n",
      "2021-08-25 11:18:24.992 | WARNING  | src.policies:train:131 - The actual batch size is 383, instead of 200\n",
      "2021-08-25 11:18:24.998 | INFO     | src.policies:train:157 - Total loss: 0.9973888993263245\n",
      "2021-08-25 11:18:25.001 | INFO     | src.policies:train:103 - Epoch 513 / 800\n",
      "2021-08-25 11:18:25.002 | INFO     | src.policies:train:109 - Episode 1775\n",
      "2021-08-25 11:18:25.047 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:25.048 | INFO     | src.policies:train:121 - Mean episode return: 131.0\n",
      "2021-08-25 11:18:25.049 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.71\n",
      "2021-08-25 11:18:25.050 | INFO     | src.policies:train:109 - Episode 1776\n",
      "2021-08-25 11:18:25.117 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:25.118 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:25.119 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.91\n",
      "2021-08-25 11:18:25.120 | WARNING  | src.policies:train:131 - The actual batch size is 331, instead of 200\n",
      "2021-08-25 11:18:25.126 | INFO     | src.policies:train:157 - Total loss: 0.9969786405563354\n",
      "2021-08-25 11:18:25.129 | INFO     | src.policies:train:103 - Epoch 514 / 800\n",
      "2021-08-25 11:18:25.130 | INFO     | src.policies:train:109 - Episode 1777\n",
      "2021-08-25 11:18:25.195 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:25.196 | INFO     | src.policies:train:121 - Mean episode return: 185.0\n",
      "2021-08-25 11:18:25.197 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.76\n",
      "2021-08-25 11:18:25.198 | INFO     | src.policies:train:109 - Episode 1778\n",
      "2021-08-25 11:18:25.268 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:25.269 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:25.270 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.76\n",
      "2021-08-25 11:18:25.272 | WARNING  | src.policies:train:131 - The actual batch size is 385, instead of 200\n",
      "2021-08-25 11:18:25.281 | INFO     | src.policies:train:157 - Total loss: 0.9974024295806885\n",
      "2021-08-25 11:18:25.283 | INFO     | src.policies:train:103 - Epoch 515 / 800\n",
      "2021-08-25 11:18:25.285 | INFO     | src.policies:train:109 - Episode 1779\n",
      "2021-08-25 11:18:25.341 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:25.343 | INFO     | src.policies:train:121 - Mean episode return: 156.0\n",
      "2021-08-25 11:18:25.344 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 183.07\n",
      "2021-08-25 11:18:25.345 | INFO     | src.policies:train:109 - Episode 1780\n",
      "2021-08-25 11:18:25.417 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:25.418 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:25.419 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 183.07\n",
      "2021-08-25 11:18:25.420 | WARNING  | src.policies:train:131 - The actual batch size is 356, instead of 200\n",
      "2021-08-25 11:18:25.427 | INFO     | src.policies:train:157 - Total loss: 0.9971907734870911\n",
      "2021-08-25 11:18:25.430 | INFO     | src.policies:train:103 - Epoch 516 / 800\n",
      "2021-08-25 11:18:25.431 | INFO     | src.policies:train:109 - Episode 1781\n",
      "2021-08-25 11:18:25.485 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:25.487 | INFO     | src.policies:train:121 - Mean episode return: 148.0\n",
      "2021-08-25 11:18:25.488 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.55\n",
      "2021-08-25 11:18:25.489 | INFO     | src.policies:train:109 - Episode 1782\n",
      "2021-08-25 11:18:25.561 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:25.562 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:25.563 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.55\n",
      "2021-08-25 11:18:25.564 | WARNING  | src.policies:train:131 - The actual batch size is 348, instead of 200\n",
      "2021-08-25 11:18:25.571 | INFO     | src.policies:train:157 - Total loss: 0.9971262812614441\n",
      "2021-08-25 11:18:25.574 | INFO     | src.policies:train:103 - Epoch 517 / 800\n",
      "2021-08-25 11:18:25.575 | INFO     | src.policies:train:109 - Episode 1783\n",
      "2021-08-25 11:18:25.644 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:25.646 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:25.647 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.55\n",
      "2021-08-25 11:18:25.653 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:25.656 | INFO     | src.policies:train:103 - Epoch 518 / 800\n",
      "2021-08-25 11:18:25.657 | INFO     | src.policies:train:109 - Episode 1784\n",
      "2021-08-25 11:18:25.727 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:18:25.728 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:25.729 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.85\n",
      "2021-08-25 11:18:25.736 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:25.739 | INFO     | src.policies:train:103 - Epoch 519 / 800\n",
      "2021-08-25 11:18:25.740 | INFO     | src.policies:train:109 - Episode 1785\n",
      "2021-08-25 11:18:25.811 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:25.812 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:25.813 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.85\n",
      "2021-08-25 11:18:25.819 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:25.822 | INFO     | src.policies:train:103 - Epoch 520 / 800\n",
      "2021-08-25 11:18:25.822 | INFO     | src.policies:train:109 - Episode 1786\n",
      "2021-08-25 11:18:25.883 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:25.884 | INFO     | src.policies:train:121 - Mean episode return: 172.0\n",
      "2021-08-25 11:18:25.886 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.63\n",
      "2021-08-25 11:18:25.887 | INFO     | src.policies:train:109 - Episode 1787\n",
      "2021-08-25 11:18:25.957 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:25.958 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:25.959 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.63\n",
      "2021-08-25 11:18:25.960 | WARNING  | src.policies:train:131 - The actual batch size is 372, instead of 200\n",
      "2021-08-25 11:18:25.967 | INFO     | src.policies:train:157 - Total loss: 0.9973116517066956\n",
      "2021-08-25 11:18:25.970 | INFO     | src.policies:train:103 - Epoch 521 / 800\n",
      "2021-08-25 11:18:25.971 | INFO     | src.policies:train:109 - Episode 1788\n",
      "2021-08-25 11:18:26.043 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:26.045 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:26.046 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.79\n",
      "2021-08-25 11:18:26.051 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:26.054 | INFO     | src.policies:train:103 - Epoch 522 / 800\n",
      "2021-08-25 11:18:26.055 | INFO     | src.policies:train:109 - Episode 1789\n",
      "2021-08-25 11:18:26.124 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:26.126 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:26.127 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.79\n",
      "2021-08-25 11:18:26.132 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:26.135 | INFO     | src.policies:train:103 - Epoch 523 / 800\n",
      "2021-08-25 11:18:26.136 | INFO     | src.policies:train:109 - Episode 1790\n",
      "2021-08-25 11:18:26.201 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:26.202 | INFO     | src.policies:train:121 - Mean episode return: 189.0\n",
      "2021-08-25 11:18:26.203 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.68\n",
      "2021-08-25 11:18:26.204 | INFO     | src.policies:train:109 - Episode 1791\n",
      "2021-08-25 11:18:26.274 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:26.275 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:26.276 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.97\n",
      "2021-08-25 11:18:26.277 | WARNING  | src.policies:train:131 - The actual batch size is 389, instead of 200\n",
      "2021-08-25 11:18:26.284 | INFO     | src.policies:train:157 - Total loss: 0.9974290132522583\n",
      "2021-08-25 11:18:26.286 | INFO     | src.policies:train:103 - Epoch 524 / 800\n",
      "2021-08-25 11:18:26.287 | INFO     | src.policies:train:109 - Episode 1792\n",
      "2021-08-25 11:18:26.357 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:26.359 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:26.360 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.97\n",
      "2021-08-25 11:18:26.365 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:26.367 | INFO     | src.policies:train:103 - Epoch 525 / 800\n",
      "2021-08-25 11:18:26.368 | INFO     | src.policies:train:109 - Episode 1793\n",
      "2021-08-25 11:18:26.439 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:26.441 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:26.442 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.97\n",
      "2021-08-25 11:18:26.447 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:26.450 | INFO     | src.policies:train:103 - Epoch 526 / 800\n",
      "2021-08-25 11:18:26.451 | INFO     | src.policies:train:109 - Episode 1794\n",
      "2021-08-25 11:18:26.523 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:26.525 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:26.526 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.97\n",
      "2021-08-25 11:18:26.532 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:26.536 | INFO     | src.policies:train:103 - Epoch 527 / 800\n",
      "2021-08-25 11:18:26.537 | INFO     | src.policies:train:109 - Episode 1795\n",
      "2021-08-25 11:18:26.611 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:26.612 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:26.613 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.97\n",
      "2021-08-25 11:18:26.619 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:26.621 | INFO     | src.policies:train:103 - Epoch 528 / 800\n",
      "2021-08-25 11:18:26.622 | INFO     | src.policies:train:109 - Episode 1796\n",
      "2021-08-25 11:18:26.691 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:26.693 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:26.694 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.97\n",
      "2021-08-25 11:18:26.699 | INFO     | src.policies:train:157 - Total loss: 0.9950000047683716\n",
      "2021-08-25 11:18:26.702 | INFO     | src.policies:train:103 - Epoch 529 / 800\n",
      "2021-08-25 11:18:26.702 | INFO     | src.policies:train:109 - Episode 1797\n",
      "2021-08-25 11:18:26.770 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:26.772 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:26.773 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.97\n",
      "2021-08-25 11:18:26.778 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:26.780 | INFO     | src.policies:train:103 - Epoch 530 / 800\n",
      "2021-08-25 11:18:26.781 | INFO     | src.policies:train:109 - Episode 1798\n",
      "2021-08-25 11:18:26.848 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:26.850 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:26.851 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.97\n",
      "2021-08-25 11:18:26.856 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:26.859 | INFO     | src.policies:train:103 - Epoch 531 / 800\n",
      "2021-08-25 11:18:26.859 | INFO     | src.policies:train:109 - Episode 1799\n",
      "2021-08-25 11:18:26.911 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:26.913 | INFO     | src.policies:train:121 - Mean episode return: 153.0\n",
      "2021-08-25 11:18:26.914 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.5\n",
      "2021-08-25 11:18:26.915 | INFO     | src.policies:train:109 - Episode 1800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:18:26.978 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:26.979 | INFO     | src.policies:train:121 - Mean episode return: 190.0\n",
      "2021-08-25 11:18:26.980 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.42\n",
      "2021-08-25 11:18:26.981 | WARNING  | src.policies:train:131 - The actual batch size is 343, instead of 200\n",
      "2021-08-25 11:18:26.987 | INFO     | src.policies:train:157 - Total loss: 0.9970844388008118\n",
      "2021-08-25 11:18:26.990 | INFO     | src.policies:train:103 - Epoch 532 / 800\n",
      "2021-08-25 11:18:26.992 | INFO     | src.policies:train:109 - Episode 1801\n",
      "2021-08-25 11:18:27.033 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:27.035 | INFO     | src.policies:train:121 - Mean episode return: 123.0\n",
      "2021-08-25 11:18:27.036 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.65\n",
      "2021-08-25 11:18:27.036 | INFO     | src.policies:train:109 - Episode 1802\n",
      "2021-08-25 11:18:27.105 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:27.106 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:27.107 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.88\n",
      "2021-08-25 11:18:27.108 | WARNING  | src.policies:train:131 - The actual batch size is 323, instead of 200\n",
      "2021-08-25 11:18:27.114 | INFO     | src.policies:train:157 - Total loss: 0.9969040155410767\n",
      "2021-08-25 11:18:27.117 | INFO     | src.policies:train:103 - Epoch 533 / 800\n",
      "2021-08-25 11:18:27.118 | INFO     | src.policies:train:109 - Episode 1803\n",
      "2021-08-25 11:18:27.185 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:27.186 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:27.187 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.88\n",
      "2021-08-25 11:18:27.192 | INFO     | src.policies:train:157 - Total loss: 0.994999885559082\n",
      "2021-08-25 11:18:27.195 | INFO     | src.policies:train:103 - Epoch 534 / 800\n",
      "2021-08-25 11:18:27.196 | INFO     | src.policies:train:109 - Episode 1804\n",
      "2021-08-25 11:18:27.260 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:27.262 | INFO     | src.policies:train:121 - Mean episode return: 188.0\n",
      "2021-08-25 11:18:27.263 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.79\n",
      "2021-08-25 11:18:27.264 | INFO     | src.policies:train:109 - Episode 1805\n",
      "2021-08-25 11:18:27.334 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:27.335 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:27.336 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.79\n",
      "2021-08-25 11:18:27.337 | WARNING  | src.policies:train:131 - The actual batch size is 388, instead of 200\n",
      "2021-08-25 11:18:27.343 | INFO     | src.policies:train:157 - Total loss: 0.9974223971366882\n",
      "2021-08-25 11:18:27.345 | INFO     | src.policies:train:103 - Epoch 535 / 800\n",
      "2021-08-25 11:18:27.346 | INFO     | src.policies:train:109 - Episode 1806\n",
      "2021-08-25 11:18:27.411 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:27.413 | INFO     | src.policies:train:121 - Mean episode return: 190.0\n",
      "2021-08-25 11:18:27.414 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.69\n",
      "2021-08-25 11:18:27.414 | INFO     | src.policies:train:109 - Episode 1807\n",
      "2021-08-25 11:18:27.478 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:27.479 | INFO     | src.policies:train:121 - Mean episode return: 185.0\n",
      "2021-08-25 11:18:27.480 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.98\n",
      "2021-08-25 11:18:27.481 | WARNING  | src.policies:train:131 - The actual batch size is 375, instead of 200\n",
      "2021-08-25 11:18:27.487 | INFO     | src.policies:train:157 - Total loss: 0.9973330497741699\n",
      "2021-08-25 11:18:27.489 | INFO     | src.policies:train:103 - Epoch 536 / 800\n",
      "2021-08-25 11:18:27.490 | INFO     | src.policies:train:109 - Episode 1808\n",
      "2021-08-25 11:18:27.542 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:27.543 | INFO     | src.policies:train:121 - Mean episode return: 152.0\n",
      "2021-08-25 11:18:27.544 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.5\n",
      "2021-08-25 11:18:27.545 | INFO     | src.policies:train:109 - Episode 1809\n",
      "2021-08-25 11:18:27.612 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:27.613 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:27.614 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.94\n",
      "2021-08-25 11:18:27.615 | WARNING  | src.policies:train:131 - The actual batch size is 352, instead of 200\n",
      "2021-08-25 11:18:27.621 | INFO     | src.policies:train:157 - Total loss: 0.9971590638160706\n",
      "2021-08-25 11:18:27.624 | INFO     | src.policies:train:103 - Epoch 537 / 800\n",
      "2021-08-25 11:18:27.625 | INFO     | src.policies:train:109 - Episode 1810\n",
      "2021-08-25 11:18:27.691 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:27.692 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:27.693 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.94\n",
      "2021-08-25 11:18:27.698 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:27.701 | INFO     | src.policies:train:103 - Epoch 538 / 800\n",
      "2021-08-25 11:18:27.701 | INFO     | src.policies:train:109 - Episode 1811\n",
      "2021-08-25 11:18:27.770 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:27.771 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:27.772 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.94\n",
      "2021-08-25 11:18:27.777 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:27.779 | INFO     | src.policies:train:103 - Epoch 539 / 800\n",
      "2021-08-25 11:18:27.780 | INFO     | src.policies:train:109 - Episode 1812\n",
      "2021-08-25 11:18:27.849 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:27.851 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:27.852 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.94\n",
      "2021-08-25 11:18:27.857 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:27.859 | INFO     | src.policies:train:103 - Epoch 540 / 800\n",
      "2021-08-25 11:18:27.860 | INFO     | src.policies:train:109 - Episode 1813\n",
      "2021-08-25 11:18:27.926 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:27.927 | INFO     | src.policies:train:121 - Mean episode return: 196.0\n",
      "2021-08-25 11:18:27.928 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.9\n",
      "2021-08-25 11:18:27.929 | INFO     | src.policies:train:109 - Episode 1814\n",
      "2021-08-25 11:18:27.999 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:28.000 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:28.000 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.26\n",
      "2021-08-25 11:18:28.001 | WARNING  | src.policies:train:131 - The actual batch size is 396, instead of 200\n",
      "2021-08-25 11:18:28.008 | INFO     | src.policies:train:157 - Total loss: 0.9974746108055115\n",
      "2021-08-25 11:18:28.011 | INFO     | src.policies:train:103 - Epoch 541 / 800\n",
      "2021-08-25 11:18:28.012 | INFO     | src.policies:train:109 - Episode 1815\n",
      "2021-08-25 11:18:28.069 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:28.070 | INFO     | src.policies:train:121 - Mean episode return: 165.0\n",
      "2021-08-25 11:18:28.071 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.83\n",
      "2021-08-25 11:18:28.072 | INFO     | src.policies:train:109 - Episode 1816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:18:28.133 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:28.134 | INFO     | src.policies:train:121 - Mean episode return: 180.0\n",
      "2021-08-25 11:18:28.134 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.67\n",
      "2021-08-25 11:18:28.135 | WARNING  | src.policies:train:131 - The actual batch size is 345, instead of 200\n",
      "2021-08-25 11:18:28.141 | INFO     | src.policies:train:157 - Total loss: 0.9971012473106384\n",
      "2021-08-25 11:18:28.143 | INFO     | src.policies:train:103 - Epoch 542 / 800\n",
      "2021-08-25 11:18:28.145 | INFO     | src.policies:train:109 - Episode 1817\n",
      "2021-08-25 11:18:28.203 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:28.205 | INFO     | src.policies:train:121 - Mean episode return: 178.0\n",
      "2021-08-25 11:18:28.206 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.64\n",
      "2021-08-25 11:18:28.207 | INFO     | src.policies:train:109 - Episode 1818\n",
      "2021-08-25 11:18:28.247 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:28.249 | INFO     | src.policies:train:121 - Mean episode return: 118.0\n",
      "2021-08-25 11:18:28.249 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.12\n",
      "2021-08-25 11:18:28.250 | WARNING  | src.policies:train:131 - The actual batch size is 296, instead of 200\n",
      "2021-08-25 11:18:28.257 | INFO     | src.policies:train:157 - Total loss: 0.9966211915016174\n",
      "2021-08-25 11:18:28.259 | INFO     | src.policies:train:103 - Epoch 543 / 800\n",
      "2021-08-25 11:18:28.261 | INFO     | src.policies:train:109 - Episode 1819\n",
      "2021-08-25 11:18:28.330 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:28.331 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:28.332 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.7\n",
      "2021-08-25 11:18:28.337 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:28.340 | INFO     | src.policies:train:103 - Epoch 544 / 800\n",
      "2021-08-25 11:18:28.341 | INFO     | src.policies:train:109 - Episode 1820\n",
      "2021-08-25 11:18:28.385 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:28.386 | INFO     | src.policies:train:121 - Mean episode return: 123.0\n",
      "2021-08-25 11:18:28.387 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.93\n",
      "2021-08-25 11:18:28.388 | INFO     | src.policies:train:109 - Episode 1821\n",
      "2021-08-25 11:18:28.443 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:28.444 | INFO     | src.policies:train:121 - Mean episode return: 151.0\n",
      "2021-08-25 11:18:28.445 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.44\n",
      "2021-08-25 11:18:28.446 | WARNING  | src.policies:train:131 - The actual batch size is 274, instead of 200\n",
      "2021-08-25 11:18:28.452 | INFO     | src.policies:train:157 - Total loss: 0.9963502287864685\n",
      "2021-08-25 11:18:28.455 | INFO     | src.policies:train:103 - Epoch 545 / 800\n",
      "2021-08-25 11:18:28.456 | INFO     | src.policies:train:109 - Episode 1822\n",
      "2021-08-25 11:18:28.520 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:28.521 | INFO     | src.policies:train:121 - Mean episode return: 193.0\n",
      "2021-08-25 11:18:28.522 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.89\n",
      "2021-08-25 11:18:28.523 | INFO     | src.policies:train:109 - Episode 1823\n",
      "2021-08-25 11:18:28.582 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:28.583 | INFO     | src.policies:train:121 - Mean episode return: 164.0\n",
      "2021-08-25 11:18:28.584 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.91\n",
      "2021-08-25 11:18:28.585 | WARNING  | src.policies:train:131 - The actual batch size is 357, instead of 200\n",
      "2021-08-25 11:18:28.591 | INFO     | src.policies:train:157 - Total loss: 0.9971986413002014\n",
      "2021-08-25 11:18:28.594 | INFO     | src.policies:train:103 - Epoch 546 / 800\n",
      "2021-08-25 11:18:28.595 | INFO     | src.policies:train:109 - Episode 1824\n",
      "2021-08-25 11:18:28.643 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:28.645 | INFO     | src.policies:train:121 - Mean episode return: 145.0\n",
      "2021-08-25 11:18:28.646 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.36\n",
      "2021-08-25 11:18:28.646 | INFO     | src.policies:train:109 - Episode 1825\n",
      "2021-08-25 11:18:28.717 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:28.719 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:28.719 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.36\n",
      "2021-08-25 11:18:28.720 | WARNING  | src.policies:train:131 - The actual batch size is 345, instead of 200\n",
      "2021-08-25 11:18:28.726 | INFO     | src.policies:train:157 - Total loss: 0.9971013069152832\n",
      "2021-08-25 11:18:28.729 | INFO     | src.policies:train:103 - Epoch 547 / 800\n",
      "2021-08-25 11:18:28.730 | INFO     | src.policies:train:109 - Episode 1826\n",
      "2021-08-25 11:18:28.800 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:28.802 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:28.803 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.36\n",
      "2021-08-25 11:18:28.807 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:28.810 | INFO     | src.policies:train:103 - Epoch 548 / 800\n",
      "2021-08-25 11:18:28.810 | INFO     | src.policies:train:109 - Episode 1827\n",
      "2021-08-25 11:18:28.878 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:28.879 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:28.880 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.36\n",
      "2021-08-25 11:18:28.884 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:28.887 | INFO     | src.policies:train:103 - Epoch 549 / 800\n",
      "2021-08-25 11:18:28.887 | INFO     | src.policies:train:109 - Episode 1828\n",
      "2021-08-25 11:18:28.955 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:28.956 | INFO     | src.policies:train:121 - Mean episode return: 198.0\n",
      "2021-08-25 11:18:28.957 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.34\n",
      "2021-08-25 11:18:28.958 | INFO     | src.policies:train:109 - Episode 1829\n",
      "2021-08-25 11:18:29.014 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:29.015 | INFO     | src.policies:train:121 - Mean episode return: 160.0\n",
      "2021-08-25 11:18:29.016 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.43\n",
      "2021-08-25 11:18:29.016 | WARNING  | src.policies:train:131 - The actual batch size is 358, instead of 200\n",
      "2021-08-25 11:18:29.023 | INFO     | src.policies:train:157 - Total loss: 0.9972065091133118\n",
      "2021-08-25 11:18:29.025 | INFO     | src.policies:train:103 - Epoch 550 / 800\n",
      "2021-08-25 11:18:29.026 | INFO     | src.policies:train:109 - Episode 1830\n",
      "2021-08-25 11:18:29.082 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:29.083 | INFO     | src.policies:train:121 - Mean episode return: 163.0\n",
      "2021-08-25 11:18:29.084 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.47\n",
      "2021-08-25 11:18:29.085 | INFO     | src.policies:train:109 - Episode 1831\n",
      "2021-08-25 11:18:29.152 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:29.153 | INFO     | src.policies:train:121 - Mean episode return: 192.0\n",
      "2021-08-25 11:18:29.154 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.39\n",
      "2021-08-25 11:18:29.155 | WARNING  | src.policies:train:131 - The actual batch size is 355, instead of 200\n",
      "2021-08-25 11:18:29.161 | INFO     | src.policies:train:157 - Total loss: 0.9971829056739807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:18:29.164 | INFO     | src.policies:train:103 - Epoch 551 / 800\n",
      "2021-08-25 11:18:29.165 | INFO     | src.policies:train:109 - Episode 1832\n",
      "2021-08-25 11:18:29.218 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:29.219 | INFO     | src.policies:train:121 - Mean episode return: 154.0\n",
      "2021-08-25 11:18:29.220 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.1\n",
      "2021-08-25 11:18:29.221 | INFO     | src.policies:train:109 - Episode 1833\n",
      "2021-08-25 11:18:29.288 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:29.289 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:29.290 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.1\n",
      "2021-08-25 11:18:29.291 | WARNING  | src.policies:train:131 - The actual batch size is 354, instead of 200\n",
      "2021-08-25 11:18:29.297 | INFO     | src.policies:train:157 - Total loss: 0.997174859046936\n",
      "2021-08-25 11:18:29.299 | INFO     | src.policies:train:103 - Epoch 552 / 800\n",
      "2021-08-25 11:18:29.300 | INFO     | src.policies:train:109 - Episode 1834\n",
      "2021-08-25 11:18:29.370 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:29.372 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:29.373 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.72\n",
      "2021-08-25 11:18:29.377 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:29.380 | INFO     | src.policies:train:103 - Epoch 553 / 800\n",
      "2021-08-25 11:18:29.380 | INFO     | src.policies:train:109 - Episode 1835\n",
      "2021-08-25 11:18:29.441 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:29.442 | INFO     | src.policies:train:121 - Mean episode return: 175.0\n",
      "2021-08-25 11:18:29.443 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.52\n",
      "2021-08-25 11:18:29.444 | INFO     | src.policies:train:109 - Episode 1836\n",
      "2021-08-25 11:18:29.513 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:29.514 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:29.515 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.52\n",
      "2021-08-25 11:18:29.515 | WARNING  | src.policies:train:131 - The actual batch size is 375, instead of 200\n",
      "2021-08-25 11:18:29.521 | INFO     | src.policies:train:157 - Total loss: 0.9973331689834595\n",
      "2021-08-25 11:18:29.524 | INFO     | src.policies:train:103 - Epoch 554 / 800\n",
      "2021-08-25 11:18:29.525 | INFO     | src.policies:train:109 - Episode 1837\n",
      "2021-08-25 11:18:29.572 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:29.573 | INFO     | src.policies:train:121 - Mean episode return: 139.0\n",
      "2021-08-25 11:18:29.574 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 180.91\n",
      "2021-08-25 11:18:29.575 | INFO     | src.policies:train:109 - Episode 1838\n",
      "2021-08-25 11:18:29.646 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:29.647 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:29.648 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.57\n",
      "2021-08-25 11:18:29.649 | WARNING  | src.policies:train:131 - The actual batch size is 339, instead of 200\n",
      "2021-08-25 11:18:29.655 | INFO     | src.policies:train:157 - Total loss: 0.997049868106842\n",
      "2021-08-25 11:18:29.657 | INFO     | src.policies:train:103 - Epoch 555 / 800\n",
      "2021-08-25 11:18:29.658 | INFO     | src.policies:train:109 - Episode 1839\n",
      "2021-08-25 11:18:29.729 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:29.731 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:29.732 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.58\n",
      "2021-08-25 11:18:29.736 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:29.738 | INFO     | src.policies:train:103 - Epoch 556 / 800\n",
      "2021-08-25 11:18:29.739 | INFO     | src.policies:train:109 - Episode 1840\n",
      "2021-08-25 11:18:29.807 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:29.809 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:29.810 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.58\n",
      "2021-08-25 11:18:29.815 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:29.818 | INFO     | src.policies:train:103 - Epoch 557 / 800\n",
      "2021-08-25 11:18:29.818 | INFO     | src.policies:train:109 - Episode 1841\n",
      "2021-08-25 11:18:29.887 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:29.888 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:29.890 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.29\n",
      "2021-08-25 11:18:29.895 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:29.898 | INFO     | src.policies:train:103 - Epoch 558 / 800\n",
      "2021-08-25 11:18:29.899 | INFO     | src.policies:train:109 - Episode 1842\n",
      "2021-08-25 11:18:29.966 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:29.968 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:29.969 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.4\n",
      "2021-08-25 11:18:29.973 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:29.975 | INFO     | src.policies:train:103 - Epoch 559 / 800\n",
      "2021-08-25 11:18:29.976 | INFO     | src.policies:train:109 - Episode 1843\n",
      "2021-08-25 11:18:30.038 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:30.040 | INFO     | src.policies:train:121 - Mean episode return: 180.0\n",
      "2021-08-25 11:18:30.041 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.34\n",
      "2021-08-25 11:18:30.041 | INFO     | src.policies:train:109 - Episode 1844\n",
      "2021-08-25 11:18:30.109 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:30.111 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:30.112 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.34\n",
      "2021-08-25 11:18:30.113 | WARNING  | src.policies:train:131 - The actual batch size is 380, instead of 200\n",
      "2021-08-25 11:18:30.119 | INFO     | src.policies:train:157 - Total loss: 0.9973682165145874\n",
      "2021-08-25 11:18:30.122 | INFO     | src.policies:train:103 - Epoch 560 / 800\n",
      "2021-08-25 11:18:30.123 | INFO     | src.policies:train:109 - Episode 1845\n",
      "2021-08-25 11:18:30.190 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:30.191 | INFO     | src.policies:train:121 - Mean episode return: 196.0\n",
      "2021-08-25 11:18:30.192 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.3\n",
      "2021-08-25 11:18:30.193 | INFO     | src.policies:train:109 - Episode 1846\n",
      "2021-08-25 11:18:30.260 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:30.261 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:30.262 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.3\n",
      "2021-08-25 11:18:30.263 | WARNING  | src.policies:train:131 - The actual batch size is 396, instead of 200\n",
      "2021-08-25 11:18:30.269 | INFO     | src.policies:train:157 - Total loss: 0.9974746108055115\n",
      "2021-08-25 11:18:30.271 | INFO     | src.policies:train:103 - Epoch 561 / 800\n",
      "2021-08-25 11:18:30.272 | INFO     | src.policies:train:109 - Episode 1847\n",
      "2021-08-25 11:18:30.343 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:30.344 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:30.345 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:18:30.350 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:30.352 | INFO     | src.policies:train:103 - Epoch 562 / 800\n",
      "2021-08-25 11:18:30.353 | INFO     | src.policies:train:109 - Episode 1848\n",
      "2021-08-25 11:18:30.420 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:30.421 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:30.422 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 183.02\n",
      "2021-08-25 11:18:30.427 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:30.429 | INFO     | src.policies:train:103 - Epoch 563 / 800\n",
      "2021-08-25 11:18:30.430 | INFO     | src.policies:train:109 - Episode 1849\n",
      "2021-08-25 11:18:30.479 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:30.480 | INFO     | src.policies:train:121 - Mean episode return: 141.0\n",
      "2021-08-25 11:18:30.481 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.93\n",
      "2021-08-25 11:18:30.482 | INFO     | src.policies:train:109 - Episode 1850\n",
      "2021-08-25 11:18:30.554 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:30.555 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:30.556 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.93\n",
      "2021-08-25 11:18:30.557 | WARNING  | src.policies:train:131 - The actual batch size is 341, instead of 200\n",
      "2021-08-25 11:18:30.563 | INFO     | src.policies:train:157 - Total loss: 0.9970670342445374\n",
      "2021-08-25 11:18:30.565 | INFO     | src.policies:train:103 - Epoch 564 / 800\n",
      "2021-08-25 11:18:30.566 | INFO     | src.policies:train:109 - Episode 1851\n",
      "2021-08-25 11:18:30.635 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:30.637 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:30.638 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 183.56\n",
      "2021-08-25 11:18:30.643 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:30.645 | INFO     | src.policies:train:103 - Epoch 565 / 800\n",
      "2021-08-25 11:18:30.646 | INFO     | src.policies:train:109 - Episode 1852\n",
      "2021-08-25 11:18:30.711 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:30.713 | INFO     | src.policies:train:121 - Mean episode return: 196.0\n",
      "2021-08-25 11:18:30.714 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 183.52\n",
      "2021-08-25 11:18:30.714 | INFO     | src.policies:train:109 - Episode 1853\n",
      "2021-08-25 11:18:30.783 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:30.784 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:30.784 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 183.52\n",
      "2021-08-25 11:18:30.785 | WARNING  | src.policies:train:131 - The actual batch size is 396, instead of 200\n",
      "2021-08-25 11:18:30.792 | INFO     | src.policies:train:157 - Total loss: 0.9974746108055115\n",
      "2021-08-25 11:18:30.794 | INFO     | src.policies:train:103 - Epoch 566 / 800\n",
      "2021-08-25 11:18:30.795 | INFO     | src.policies:train:109 - Episode 1854\n",
      "2021-08-25 11:18:30.838 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:30.839 | INFO     | src.policies:train:121 - Mean episode return: 123.0\n",
      "2021-08-25 11:18:30.840 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.75\n",
      "2021-08-25 11:18:30.841 | INFO     | src.policies:train:109 - Episode 1855\n",
      "2021-08-25 11:18:30.886 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:30.887 | INFO     | src.policies:train:121 - Mean episode return: 131.0\n",
      "2021-08-25 11:18:30.888 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.59\n",
      "2021-08-25 11:18:30.889 | WARNING  | src.policies:train:131 - The actual batch size is 254, instead of 200\n",
      "2021-08-25 11:18:30.895 | INFO     | src.policies:train:157 - Total loss: 0.9960628151893616\n",
      "2021-08-25 11:18:30.898 | INFO     | src.policies:train:103 - Epoch 567 / 800\n",
      "2021-08-25 11:18:30.899 | INFO     | src.policies:train:109 - Episode 1856\n",
      "2021-08-25 11:18:30.967 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:30.968 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:30.969 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 183.22\n",
      "2021-08-25 11:18:30.973 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:30.976 | INFO     | src.policies:train:103 - Epoch 568 / 800\n",
      "2021-08-25 11:18:30.977 | INFO     | src.policies:train:109 - Episode 1857\n",
      "2021-08-25 11:18:31.018 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:31.019 | INFO     | src.policies:train:121 - Mean episode return: 115.0\n",
      "2021-08-25 11:18:31.020 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 183.11\n",
      "2021-08-25 11:18:31.021 | INFO     | src.policies:train:109 - Episode 1858\n",
      "2021-08-25 11:18:31.085 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:31.086 | INFO     | src.policies:train:121 - Mean episode return: 186.0\n",
      "2021-08-25 11:18:31.087 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 183.06\n",
      "2021-08-25 11:18:31.088 | WARNING  | src.policies:train:131 - The actual batch size is 301, instead of 200\n",
      "2021-08-25 11:18:31.094 | INFO     | src.policies:train:157 - Total loss: 0.996677577495575\n",
      "2021-08-25 11:18:31.096 | INFO     | src.policies:train:103 - Epoch 569 / 800\n",
      "2021-08-25 11:18:31.097 | INFO     | src.policies:train:109 - Episode 1859\n",
      "2021-08-25 11:18:31.165 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:31.166 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:31.167 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 183.32\n",
      "2021-08-25 11:18:31.172 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:31.175 | INFO     | src.policies:train:103 - Epoch 570 / 800\n",
      "2021-08-25 11:18:31.175 | INFO     | src.policies:train:109 - Episode 1860\n",
      "2021-08-25 11:18:31.238 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:31.240 | INFO     | src.policies:train:121 - Mean episode return: 189.0\n",
      "2021-08-25 11:18:31.241 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 183.49\n",
      "2021-08-25 11:18:31.242 | INFO     | src.policies:train:109 - Episode 1861\n",
      "2021-08-25 11:18:31.312 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:31.313 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:31.314 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 183.6\n",
      "2021-08-25 11:18:31.315 | WARNING  | src.policies:train:131 - The actual batch size is 389, instead of 200\n",
      "2021-08-25 11:18:31.320 | INFO     | src.policies:train:157 - Total loss: 0.9974290728569031\n",
      "2021-08-25 11:18:31.323 | INFO     | src.policies:train:103 - Epoch 571 / 800\n",
      "2021-08-25 11:18:31.324 | INFO     | src.policies:train:109 - Episode 1862\n",
      "2021-08-25 11:18:31.392 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:31.393 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:31.394 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 183.6\n",
      "2021-08-25 11:18:31.399 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:31.402 | INFO     | src.policies:train:103 - Epoch 572 / 800\n",
      "2021-08-25 11:18:31.402 | INFO     | src.policies:train:109 - Episode 1863\n",
      "2021-08-25 11:18:31.469 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:31.470 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:18:31.471 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 184.39\n",
      "2021-08-25 11:18:31.476 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:31.479 | INFO     | src.policies:train:103 - Epoch 573 / 800\n",
      "2021-08-25 11:18:31.479 | INFO     | src.policies:train:109 - Episode 1864\n",
      "2021-08-25 11:18:31.546 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:31.547 | INFO     | src.policies:train:121 - Mean episode return: 197.0\n",
      "2021-08-25 11:18:31.548 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 184.84\n",
      "2021-08-25 11:18:31.549 | INFO     | src.policies:train:109 - Episode 1865\n",
      "2021-08-25 11:18:31.598 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:31.599 | INFO     | src.policies:train:121 - Mean episode return: 143.0\n",
      "2021-08-25 11:18:31.600 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 184.83\n",
      "2021-08-25 11:18:31.601 | WARNING  | src.policies:train:131 - The actual batch size is 340, instead of 200\n",
      "2021-08-25 11:18:31.607 | INFO     | src.policies:train:157 - Total loss: 0.9970588088035583\n",
      "2021-08-25 11:18:31.609 | INFO     | src.policies:train:103 - Epoch 574 / 800\n",
      "2021-08-25 11:18:31.610 | INFO     | src.policies:train:109 - Episode 1866\n",
      "2021-08-25 11:18:31.679 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:31.681 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:31.682 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 185.3\n",
      "2021-08-25 11:18:31.687 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:31.689 | INFO     | src.policies:train:103 - Epoch 575 / 800\n",
      "2021-08-25 11:18:31.690 | INFO     | src.policies:train:109 - Episode 1867\n",
      "2021-08-25 11:18:31.757 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:31.759 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:31.760 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 185.3\n",
      "2021-08-25 11:18:31.764 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:31.767 | INFO     | src.policies:train:103 - Epoch 576 / 800\n",
      "2021-08-25 11:18:31.767 | INFO     | src.policies:train:109 - Episode 1868\n",
      "2021-08-25 11:18:31.837 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:31.838 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:31.839 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 185.3\n",
      "2021-08-25 11:18:31.844 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:31.847 | INFO     | src.policies:train:103 - Epoch 577 / 800\n",
      "2021-08-25 11:18:31.847 | INFO     | src.policies:train:109 - Episode 1869\n",
      "2021-08-25 11:18:31.916 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:31.918 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:31.919 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 185.3\n",
      "2021-08-25 11:18:31.923 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:31.926 | INFO     | src.policies:train:103 - Epoch 578 / 800\n",
      "2021-08-25 11:18:31.927 | INFO     | src.policies:train:109 - Episode 1870\n",
      "2021-08-25 11:18:31.995 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:31.997 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:31.998 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 185.36\n",
      "2021-08-25 11:18:32.003 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:32.005 | INFO     | src.policies:train:103 - Epoch 579 / 800\n",
      "2021-08-25 11:18:32.006 | INFO     | src.policies:train:109 - Episode 1871\n",
      "2021-08-25 11:18:32.075 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:32.076 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:32.077 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 185.36\n",
      "2021-08-25 11:18:32.082 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:32.084 | INFO     | src.policies:train:103 - Epoch 580 / 800\n",
      "2021-08-25 11:18:32.085 | INFO     | src.policies:train:109 - Episode 1872\n",
      "2021-08-25 11:18:32.153 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:32.154 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:32.155 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 185.36\n",
      "2021-08-25 11:18:32.160 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:32.163 | INFO     | src.policies:train:103 - Epoch 581 / 800\n",
      "2021-08-25 11:18:32.163 | INFO     | src.policies:train:109 - Episode 1873\n",
      "2021-08-25 11:18:32.230 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:32.232 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:32.233 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 185.51\n",
      "2021-08-25 11:18:32.237 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:32.239 | INFO     | src.policies:train:103 - Epoch 582 / 800\n",
      "2021-08-25 11:18:32.240 | INFO     | src.policies:train:109 - Episode 1874\n",
      "2021-08-25 11:18:32.299 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:32.301 | INFO     | src.policies:train:121 - Mean episode return: 173.0\n",
      "2021-08-25 11:18:32.302 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 185.26\n",
      "2021-08-25 11:18:32.302 | INFO     | src.policies:train:109 - Episode 1875\n",
      "2021-08-25 11:18:32.358 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:32.359 | INFO     | src.policies:train:121 - Mean episode return: 165.0\n",
      "2021-08-25 11:18:32.360 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 185.6\n",
      "2021-08-25 11:18:32.361 | WARNING  | src.policies:train:131 - The actual batch size is 338, instead of 200\n",
      "2021-08-25 11:18:32.367 | INFO     | src.policies:train:157 - Total loss: 0.9970411062240601\n",
      "2021-08-25 11:18:32.370 | INFO     | src.policies:train:103 - Epoch 583 / 800\n",
      "2021-08-25 11:18:32.371 | INFO     | src.policies:train:109 - Episode 1876\n",
      "2021-08-25 11:18:32.439 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:32.441 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:32.442 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 185.6\n",
      "2021-08-25 11:18:32.447 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:32.449 | INFO     | src.policies:train:103 - Epoch 584 / 800\n",
      "2021-08-25 11:18:32.450 | INFO     | src.policies:train:109 - Episode 1877\n",
      "2021-08-25 11:18:32.516 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:32.518 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:32.519 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 185.75\n",
      "2021-08-25 11:18:32.524 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:32.526 | INFO     | src.policies:train:103 - Epoch 585 / 800\n",
      "2021-08-25 11:18:32.527 | INFO     | src.policies:train:109 - Episode 1878\n",
      "2021-08-25 11:18:32.595 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:32.596 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:32.597 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 185.75\n",
      "2021-08-25 11:18:32.602 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:32.605 | INFO     | src.policies:train:103 - Epoch 586 / 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:18:32.605 | INFO     | src.policies:train:109 - Episode 1879\n",
      "2021-08-25 11:18:32.662 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:32.664 | INFO     | src.policies:train:121 - Mean episode return: 166.0\n",
      "2021-08-25 11:18:32.665 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 185.85\n",
      "2021-08-25 11:18:32.666 | INFO     | src.policies:train:109 - Episode 1880\n",
      "2021-08-25 11:18:32.736 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:32.737 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:32.738 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 185.85\n",
      "2021-08-25 11:18:32.739 | WARNING  | src.policies:train:131 - The actual batch size is 366, instead of 200\n",
      "2021-08-25 11:18:32.745 | INFO     | src.policies:train:157 - Total loss: 0.9972677230834961\n",
      "2021-08-25 11:18:32.747 | INFO     | src.policies:train:103 - Epoch 587 / 800\n",
      "2021-08-25 11:18:32.748 | INFO     | src.policies:train:109 - Episode 1881\n",
      "2021-08-25 11:18:32.815 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:32.817 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:32.818 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 186.37\n",
      "2021-08-25 11:18:32.822 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:32.825 | INFO     | src.policies:train:103 - Epoch 588 / 800\n",
      "2021-08-25 11:18:32.826 | INFO     | src.policies:train:109 - Episode 1882\n",
      "2021-08-25 11:18:32.896 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:32.898 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:32.899 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 186.37\n",
      "2021-08-25 11:18:32.903 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:32.905 | INFO     | src.policies:train:103 - Epoch 589 / 800\n",
      "2021-08-25 11:18:32.906 | INFO     | src.policies:train:109 - Episode 1883\n",
      "2021-08-25 11:18:32.956 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:32.957 | INFO     | src.policies:train:121 - Mean episode return: 142.0\n",
      "2021-08-25 11:18:32.958 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 185.79\n",
      "2021-08-25 11:18:32.959 | INFO     | src.policies:train:109 - Episode 1884\n",
      "2021-08-25 11:18:33.026 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:33.027 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:33.027 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 185.79\n",
      "2021-08-25 11:18:33.028 | WARNING  | src.policies:train:131 - The actual batch size is 342, instead of 200\n",
      "2021-08-25 11:18:33.034 | INFO     | src.policies:train:157 - Total loss: 0.9970759749412537\n",
      "2021-08-25 11:18:33.037 | INFO     | src.policies:train:103 - Epoch 590 / 800\n",
      "2021-08-25 11:18:33.038 | INFO     | src.policies:train:109 - Episode 1885\n",
      "2021-08-25 11:18:33.105 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:33.107 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:33.108 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 185.79\n",
      "2021-08-25 11:18:33.113 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:33.115 | INFO     | src.policies:train:103 - Epoch 591 / 800\n",
      "2021-08-25 11:18:33.116 | INFO     | src.policies:train:109 - Episode 1886\n",
      "2021-08-25 11:18:33.185 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:33.187 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:33.188 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 186.07\n",
      "2021-08-25 11:18:33.193 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:33.195 | INFO     | src.policies:train:103 - Epoch 592 / 800\n",
      "2021-08-25 11:18:33.196 | INFO     | src.policies:train:109 - Episode 1887\n",
      "2021-08-25 11:18:33.262 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:33.264 | INFO     | src.policies:train:121 - Mean episode return: 186.0\n",
      "2021-08-25 11:18:33.265 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 185.93\n",
      "2021-08-25 11:18:33.266 | INFO     | src.policies:train:109 - Episode 1888\n",
      "2021-08-25 11:18:33.339 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:33.340 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:33.342 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 185.93\n",
      "2021-08-25 11:18:33.342 | WARNING  | src.policies:train:131 - The actual batch size is 386, instead of 200\n",
      "2021-08-25 11:18:33.350 | INFO     | src.policies:train:157 - Total loss: 0.9974091053009033\n",
      "2021-08-25 11:18:33.354 | INFO     | src.policies:train:103 - Epoch 593 / 800\n",
      "2021-08-25 11:18:33.355 | INFO     | src.policies:train:109 - Episode 1889\n",
      "2021-08-25 11:18:33.426 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:33.428 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:33.429 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 185.93\n",
      "2021-08-25 11:18:33.434 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:33.436 | INFO     | src.policies:train:103 - Epoch 594 / 800\n",
      "2021-08-25 11:18:33.437 | INFO     | src.policies:train:109 - Episode 1890\n",
      "2021-08-25 11:18:33.504 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:33.505 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:33.506 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 186.04\n",
      "2021-08-25 11:18:33.512 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:33.515 | INFO     | src.policies:train:103 - Epoch 595 / 800\n",
      "2021-08-25 11:18:33.516 | INFO     | src.policies:train:109 - Episode 1891\n",
      "2021-08-25 11:18:33.584 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:33.586 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:33.587 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 186.04\n",
      "2021-08-25 11:18:33.592 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:33.595 | INFO     | src.policies:train:103 - Epoch 596 / 800\n",
      "2021-08-25 11:18:33.595 | INFO     | src.policies:train:109 - Episode 1892\n",
      "2021-08-25 11:18:33.664 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:33.666 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:33.667 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 186.04\n",
      "2021-08-25 11:18:33.672 | INFO     | src.policies:train:157 - Total loss: 0.994999885559082\n",
      "2021-08-25 11:18:33.674 | INFO     | src.policies:train:103 - Epoch 597 / 800\n",
      "2021-08-25 11:18:33.675 | INFO     | src.policies:train:109 - Episode 1893\n",
      "2021-08-25 11:18:33.730 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:33.732 | INFO     | src.policies:train:121 - Mean episode return: 159.0\n",
      "2021-08-25 11:18:33.733 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 185.63\n",
      "2021-08-25 11:18:33.734 | INFO     | src.policies:train:109 - Episode 1894\n",
      "2021-08-25 11:18:33.802 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:33.803 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:33.804 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 185.63\n",
      "2021-08-25 11:18:33.805 | WARNING  | src.policies:train:131 - The actual batch size is 359, instead of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:18:33.811 | INFO     | src.policies:train:157 - Total loss: 0.9972143769264221\n",
      "2021-08-25 11:18:33.814 | INFO     | src.policies:train:103 - Epoch 598 / 800\n",
      "2021-08-25 11:18:33.815 | INFO     | src.policies:train:109 - Episode 1895\n",
      "2021-08-25 11:18:33.882 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:33.884 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:33.885 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 185.63\n",
      "2021-08-25 11:18:33.890 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:33.892 | INFO     | src.policies:train:103 - Epoch 599 / 800\n",
      "2021-08-25 11:18:33.893 | INFO     | src.policies:train:109 - Episode 1896\n",
      "2021-08-25 11:18:33.952 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:33.954 | INFO     | src.policies:train:121 - Mean episode return: 172.0\n",
      "2021-08-25 11:18:33.955 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 185.35\n",
      "2021-08-25 11:18:33.956 | INFO     | src.policies:train:109 - Episode 1897\n",
      "2021-08-25 11:18:34.021 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:34.022 | INFO     | src.policies:train:121 - Mean episode return: 187.0\n",
      "2021-08-25 11:18:34.023 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 185.22\n",
      "2021-08-25 11:18:34.024 | WARNING  | src.policies:train:131 - The actual batch size is 359, instead of 200\n",
      "2021-08-25 11:18:34.030 | INFO     | src.policies:train:157 - Total loss: 0.9972142577171326\n",
      "2021-08-25 11:18:34.033 | INFO     | src.policies:train:103 - Epoch 600 / 800\n",
      "2021-08-25 11:18:34.034 | INFO     | src.policies:train:109 - Episode 1898\n",
      "2021-08-25 11:18:34.102 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:34.104 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:34.105 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 185.22\n",
      "2021-08-25 11:18:34.109 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:34.112 | INFO     | src.policies:train:103 - Epoch 601 / 800\n",
      "2021-08-25 11:18:34.112 | INFO     | src.policies:train:109 - Episode 1899\n",
      "2021-08-25 11:18:34.171 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:34.173 | INFO     | src.policies:train:121 - Mean episode return: 173.0\n",
      "2021-08-25 11:18:34.174 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 185.42\n",
      "2021-08-25 11:18:34.174 | INFO     | src.policies:train:109 - Episode 1900\n",
      "2021-08-25 11:18:34.215 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:34.217 | INFO     | src.policies:train:121 - Mean episode return: 117.0\n",
      "2021-08-25 11:18:34.217 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 184.69\n",
      "2021-08-25 11:18:34.218 | WARNING  | src.policies:train:131 - The actual batch size is 290, instead of 200\n",
      "2021-08-25 11:18:34.224 | INFO     | src.policies:train:157 - Total loss: 0.9965516924858093\n",
      "2021-08-25 11:18:34.226 | INFO     | src.policies:train:103 - Epoch 602 / 800\n",
      "2021-08-25 11:18:34.227 | INFO     | src.policies:train:109 - Episode 1901\n",
      "2021-08-25 11:18:34.281 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:34.283 | INFO     | src.policies:train:121 - Mean episode return: 162.0\n",
      "2021-08-25 11:18:34.284 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 185.08\n",
      "2021-08-25 11:18:34.285 | INFO     | src.policies:train:109 - Episode 1902\n",
      "2021-08-25 11:18:34.354 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:34.355 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:34.356 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 185.08\n",
      "2021-08-25 11:18:34.357 | WARNING  | src.policies:train:131 - The actual batch size is 362, instead of 200\n",
      "2021-08-25 11:18:34.363 | INFO     | src.policies:train:157 - Total loss: 0.997237503528595\n",
      "2021-08-25 11:18:34.365 | INFO     | src.policies:train:103 - Epoch 603 / 800\n",
      "2021-08-25 11:18:34.366 | INFO     | src.policies:train:109 - Episode 1903\n",
      "2021-08-25 11:18:34.415 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:34.417 | INFO     | src.policies:train:121 - Mean episode return: 145.0\n",
      "2021-08-25 11:18:34.418 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 184.53\n",
      "2021-08-25 11:18:34.419 | INFO     | src.policies:train:109 - Episode 1904\n",
      "2021-08-25 11:18:34.485 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:34.486 | INFO     | src.policies:train:121 - Mean episode return: 188.0\n",
      "2021-08-25 11:18:34.487 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 184.53\n",
      "2021-08-25 11:18:34.488 | WARNING  | src.policies:train:131 - The actual batch size is 333, instead of 200\n",
      "2021-08-25 11:18:34.494 | INFO     | src.policies:train:157 - Total loss: 0.9969968795776367\n",
      "2021-08-25 11:18:34.497 | INFO     | src.policies:train:103 - Epoch 604 / 800\n",
      "2021-08-25 11:18:34.498 | INFO     | src.policies:train:109 - Episode 1905\n",
      "2021-08-25 11:18:34.566 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:34.567 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:34.568 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 184.53\n",
      "2021-08-25 11:18:34.573 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:34.575 | INFO     | src.policies:train:103 - Epoch 605 / 800\n",
      "2021-08-25 11:18:34.576 | INFO     | src.policies:train:109 - Episode 1906\n",
      "2021-08-25 11:18:34.625 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:34.627 | INFO     | src.policies:train:121 - Mean episode return: 144.0\n",
      "2021-08-25 11:18:34.628 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 184.07\n",
      "2021-08-25 11:18:34.628 | INFO     | src.policies:train:109 - Episode 1907\n",
      "2021-08-25 11:18:34.690 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:34.692 | INFO     | src.policies:train:121 - Mean episode return: 179.0\n",
      "2021-08-25 11:18:34.693 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 184.01\n",
      "2021-08-25 11:18:34.694 | WARNING  | src.policies:train:131 - The actual batch size is 323, instead of 200\n",
      "2021-08-25 11:18:34.699 | INFO     | src.policies:train:157 - Total loss: 0.9969038963317871\n",
      "2021-08-25 11:18:34.701 | INFO     | src.policies:train:103 - Epoch 606 / 800\n",
      "2021-08-25 11:18:34.702 | INFO     | src.policies:train:109 - Episode 1908\n",
      "2021-08-25 11:18:34.759 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:34.760 | INFO     | src.policies:train:121 - Mean episode return: 172.0\n",
      "2021-08-25 11:18:34.761 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 184.21\n",
      "2021-08-25 11:18:34.762 | INFO     | src.policies:train:109 - Episode 1909\n",
      "2021-08-25 11:18:34.832 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:34.834 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:34.834 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 184.21\n",
      "2021-08-25 11:18:34.835 | WARNING  | src.policies:train:131 - The actual batch size is 372, instead of 200\n",
      "2021-08-25 11:18:34.841 | INFO     | src.policies:train:157 - Total loss: 0.9973116517066956\n",
      "2021-08-25 11:18:34.844 | INFO     | src.policies:train:103 - Epoch 607 / 800\n",
      "2021-08-25 11:18:34.845 | INFO     | src.policies:train:109 - Episode 1910\n",
      "2021-08-25 11:18:34.904 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:34.906 | INFO     | src.policies:train:121 - Mean episode return: 176.0\n",
      "2021-08-25 11:18:34.907 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 183.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:18:34.907 | INFO     | src.policies:train:109 - Episode 1911\n",
      "2021-08-25 11:18:34.958 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:34.959 | INFO     | src.policies:train:121 - Mean episode return: 142.0\n",
      "2021-08-25 11:18:34.960 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 183.39\n",
      "2021-08-25 11:18:34.961 | WARNING  | src.policies:train:131 - The actual batch size is 318, instead of 200\n",
      "2021-08-25 11:18:34.967 | INFO     | src.policies:train:157 - Total loss: 0.9968552589416504\n",
      "2021-08-25 11:18:34.969 | INFO     | src.policies:train:103 - Epoch 608 / 800\n",
      "2021-08-25 11:18:34.970 | INFO     | src.policies:train:109 - Episode 1912\n",
      "2021-08-25 11:18:35.022 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:35.023 | INFO     | src.policies:train:121 - Mean episode return: 152.0\n",
      "2021-08-25 11:18:35.024 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.91\n",
      "2021-08-25 11:18:35.025 | INFO     | src.policies:train:109 - Episode 1913\n",
      "2021-08-25 11:18:35.085 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:35.086 | INFO     | src.policies:train:121 - Mean episode return: 168.0\n",
      "2021-08-25 11:18:35.087 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.63\n",
      "2021-08-25 11:18:35.088 | WARNING  | src.policies:train:131 - The actual batch size is 320, instead of 200\n",
      "2021-08-25 11:18:35.094 | INFO     | src.policies:train:157 - Total loss: 0.9968747496604919\n",
      "2021-08-25 11:18:35.097 | INFO     | src.policies:train:103 - Epoch 609 / 800\n",
      "2021-08-25 11:18:35.098 | INFO     | src.policies:train:109 - Episode 1914\n",
      "2021-08-25 11:18:35.142 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:35.143 | INFO     | src.policies:train:121 - Mean episode return: 127.0\n",
      "2021-08-25 11:18:35.144 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.9\n",
      "2021-08-25 11:18:35.145 | INFO     | src.policies:train:109 - Episode 1915\n",
      "2021-08-25 11:18:35.217 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:35.218 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:35.219 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.25\n",
      "2021-08-25 11:18:35.220 | WARNING  | src.policies:train:131 - The actual batch size is 327, instead of 200\n",
      "2021-08-25 11:18:35.225 | INFO     | src.policies:train:157 - Total loss: 0.9969415664672852\n",
      "2021-08-25 11:18:35.228 | INFO     | src.policies:train:103 - Epoch 610 / 800\n",
      "2021-08-25 11:18:35.229 | INFO     | src.policies:train:109 - Episode 1916\n",
      "2021-08-25 11:18:35.272 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:35.274 | INFO     | src.policies:train:121 - Mean episode return: 126.0\n",
      "2021-08-25 11:18:35.275 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.71\n",
      "2021-08-25 11:18:35.276 | INFO     | src.policies:train:109 - Episode 1917\n",
      "2021-08-25 11:18:35.326 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:35.327 | INFO     | src.policies:train:121 - Mean episode return: 135.0\n",
      "2021-08-25 11:18:35.327 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.28\n",
      "2021-08-25 11:18:35.328 | WARNING  | src.policies:train:131 - The actual batch size is 261, instead of 200\n",
      "2021-08-25 11:18:35.335 | INFO     | src.policies:train:157 - Total loss: 0.996168315410614\n",
      "2021-08-25 11:18:35.338 | INFO     | src.policies:train:103 - Epoch 611 / 800\n",
      "2021-08-25 11:18:35.339 | INFO     | src.policies:train:109 - Episode 1918\n",
      "2021-08-25 11:18:35.390 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:35.391 | INFO     | src.policies:train:121 - Mean episode return: 149.0\n",
      "2021-08-25 11:18:35.392 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.59\n",
      "2021-08-25 11:18:35.393 | INFO     | src.policies:train:109 - Episode 1919\n",
      "2021-08-25 11:18:35.463 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:35.464 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:35.465 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.59\n",
      "2021-08-25 11:18:35.466 | WARNING  | src.policies:train:131 - The actual batch size is 349, instead of 200\n",
      "2021-08-25 11:18:35.472 | INFO     | src.policies:train:157 - Total loss: 0.997134804725647\n",
      "2021-08-25 11:18:35.475 | INFO     | src.policies:train:103 - Epoch 612 / 800\n",
      "2021-08-25 11:18:35.476 | INFO     | src.policies:train:109 - Episode 1920\n",
      "2021-08-25 11:18:35.527 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:35.529 | INFO     | src.policies:train:121 - Mean episode return: 145.0\n",
      "2021-08-25 11:18:35.530 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.81\n",
      "2021-08-25 11:18:35.531 | INFO     | src.policies:train:109 - Episode 1921\n",
      "2021-08-25 11:18:35.601 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:35.602 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:35.603 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.3\n",
      "2021-08-25 11:18:35.604 | WARNING  | src.policies:train:131 - The actual batch size is 345, instead of 200\n",
      "2021-08-25 11:18:35.610 | INFO     | src.policies:train:157 - Total loss: 0.9971013069152832\n",
      "2021-08-25 11:18:35.612 | INFO     | src.policies:train:103 - Epoch 613 / 800\n",
      "2021-08-25 11:18:35.613 | INFO     | src.policies:train:109 - Episode 1922\n",
      "2021-08-25 11:18:35.666 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:35.667 | INFO     | src.policies:train:121 - Mean episode return: 158.0\n",
      "2021-08-25 11:18:35.669 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.95\n",
      "2021-08-25 11:18:35.669 | INFO     | src.policies:train:109 - Episode 1923\n",
      "2021-08-25 11:18:35.738 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:35.739 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:35.740 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.31\n",
      "2021-08-25 11:18:35.741 | WARNING  | src.policies:train:131 - The actual batch size is 358, instead of 200\n",
      "2021-08-25 11:18:35.747 | INFO     | src.policies:train:157 - Total loss: 0.9972065687179565\n",
      "2021-08-25 11:18:35.750 | INFO     | src.policies:train:103 - Epoch 614 / 800\n",
      "2021-08-25 11:18:35.751 | INFO     | src.policies:train:109 - Episode 1924\n",
      "2021-08-25 11:18:35.818 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:35.819 | INFO     | src.policies:train:121 - Mean episode return: 181.0\n",
      "2021-08-25 11:18:35.821 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.67\n",
      "2021-08-25 11:18:35.822 | INFO     | src.policies:train:109 - Episode 1925\n",
      "2021-08-25 11:18:35.873 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:35.875 | INFO     | src.policies:train:121 - Mean episode return: 134.0\n",
      "2021-08-25 11:18:35.876 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.01\n",
      "2021-08-25 11:18:35.877 | WARNING  | src.policies:train:131 - The actual batch size is 315, instead of 200\n",
      "2021-08-25 11:18:35.885 | INFO     | src.policies:train:157 - Total loss: 0.9968252182006836\n",
      "2021-08-25 11:18:35.888 | INFO     | src.policies:train:103 - Epoch 615 / 800\n",
      "2021-08-25 11:18:35.889 | INFO     | src.policies:train:109 - Episode 1926\n",
      "2021-08-25 11:18:35.945 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:35.947 | INFO     | src.policies:train:121 - Mean episode return: 156.0\n",
      "2021-08-25 11:18:35.947 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.57\n",
      "2021-08-25 11:18:35.948 | INFO     | src.policies:train:109 - Episode 1927\n",
      "2021-08-25 11:18:35.999 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:18:36.000 | INFO     | src.policies:train:121 - Mean episode return: 138.0\n",
      "2021-08-25 11:18:36.001 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 180.95\n",
      "2021-08-25 11:18:36.001 | WARNING  | src.policies:train:131 - The actual batch size is 294, instead of 200\n",
      "2021-08-25 11:18:36.007 | INFO     | src.policies:train:157 - Total loss: 0.9965985417366028\n",
      "2021-08-25 11:18:36.010 | INFO     | src.policies:train:103 - Epoch 616 / 800\n",
      "2021-08-25 11:18:36.011 | INFO     | src.policies:train:109 - Episode 1928\n",
      "2021-08-25 11:18:36.068 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:36.069 | INFO     | src.policies:train:121 - Mean episode return: 158.0\n",
      "2021-08-25 11:18:36.071 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 180.55\n",
      "2021-08-25 11:18:36.072 | INFO     | src.policies:train:109 - Episode 1929\n",
      "2021-08-25 11:18:36.121 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:36.123 | INFO     | src.policies:train:121 - Mean episode return: 130.0\n",
      "2021-08-25 11:18:36.123 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 180.25\n",
      "2021-08-25 11:18:36.125 | WARNING  | src.policies:train:131 - The actual batch size is 288, instead of 200\n",
      "2021-08-25 11:18:36.132 | INFO     | src.policies:train:157 - Total loss: 0.9965274930000305\n",
      "2021-08-25 11:18:36.135 | INFO     | src.policies:train:103 - Epoch 617 / 800\n",
      "2021-08-25 11:18:36.136 | INFO     | src.policies:train:109 - Episode 1930\n",
      "2021-08-25 11:18:36.187 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:36.188 | INFO     | src.policies:train:121 - Mean episode return: 142.0\n",
      "2021-08-25 11:18:36.190 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 180.04\n",
      "2021-08-25 11:18:36.191 | INFO     | src.policies:train:109 - Episode 1931\n",
      "2021-08-25 11:18:36.264 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:36.265 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:36.266 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 180.12\n",
      "2021-08-25 11:18:36.267 | WARNING  | src.policies:train:131 - The actual batch size is 342, instead of 200\n",
      "2021-08-25 11:18:36.276 | INFO     | src.policies:train:157 - Total loss: 0.9970759749412537\n",
      "2021-08-25 11:18:36.279 | INFO     | src.policies:train:103 - Epoch 618 / 800\n",
      "2021-08-25 11:18:36.280 | INFO     | src.policies:train:109 - Episode 1932\n",
      "2021-08-25 11:18:36.351 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:36.353 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:36.354 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 180.58\n",
      "2021-08-25 11:18:36.359 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:36.362 | INFO     | src.policies:train:103 - Epoch 619 / 800\n",
      "2021-08-25 11:18:36.363 | INFO     | src.policies:train:109 - Episode 1933\n",
      "2021-08-25 11:18:36.427 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:36.428 | INFO     | src.policies:train:121 - Mean episode return: 184.0\n",
      "2021-08-25 11:18:36.429 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 180.42\n",
      "2021-08-25 11:18:36.430 | INFO     | src.policies:train:109 - Episode 1934\n",
      "2021-08-25 11:18:36.499 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:36.501 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:36.502 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 180.42\n",
      "2021-08-25 11:18:36.503 | WARNING  | src.policies:train:131 - The actual batch size is 384, instead of 200\n",
      "2021-08-25 11:18:36.511 | INFO     | src.policies:train:157 - Total loss: 0.9973956942558289\n",
      "2021-08-25 11:18:36.514 | INFO     | src.policies:train:103 - Epoch 620 / 800\n",
      "2021-08-25 11:18:36.515 | INFO     | src.policies:train:109 - Episode 1935\n",
      "2021-08-25 11:18:36.586 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:36.588 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:36.589 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 180.67\n",
      "2021-08-25 11:18:36.595 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:36.598 | INFO     | src.policies:train:103 - Epoch 621 / 800\n",
      "2021-08-25 11:18:36.599 | INFO     | src.policies:train:109 - Episode 1936\n",
      "2021-08-25 11:18:36.646 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:36.648 | INFO     | src.policies:train:121 - Mean episode return: 129.0\n",
      "2021-08-25 11:18:36.649 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 179.96\n",
      "2021-08-25 11:18:36.650 | INFO     | src.policies:train:109 - Episode 1937\n",
      "2021-08-25 11:18:36.718 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:36.720 | INFO     | src.policies:train:121 - Mean episode return: 188.0\n",
      "2021-08-25 11:18:36.721 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 180.45\n",
      "2021-08-25 11:18:36.722 | WARNING  | src.policies:train:131 - The actual batch size is 317, instead of 200\n",
      "2021-08-25 11:18:36.729 | INFO     | src.policies:train:157 - Total loss: 0.9968452453613281\n",
      "2021-08-25 11:18:36.732 | INFO     | src.policies:train:103 - Epoch 622 / 800\n",
      "2021-08-25 11:18:36.733 | INFO     | src.policies:train:109 - Episode 1938\n",
      "2021-08-25 11:18:36.803 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:36.804 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:36.805 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 180.45\n",
      "2021-08-25 11:18:36.811 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:36.814 | INFO     | src.policies:train:103 - Epoch 623 / 800\n",
      "2021-08-25 11:18:36.815 | INFO     | src.policies:train:109 - Episode 1939\n",
      "2021-08-25 11:18:36.857 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:36.858 | INFO     | src.policies:train:121 - Mean episode return: 115.0\n",
      "2021-08-25 11:18:36.859 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 179.6\n",
      "2021-08-25 11:18:36.860 | INFO     | src.policies:train:109 - Episode 1940\n",
      "2021-08-25 11:18:36.924 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:36.925 | INFO     | src.policies:train:121 - Mean episode return: 182.0\n",
      "2021-08-25 11:18:36.926 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 179.42\n",
      "2021-08-25 11:18:36.927 | WARNING  | src.policies:train:131 - The actual batch size is 297, instead of 200\n",
      "2021-08-25 11:18:36.932 | INFO     | src.policies:train:157 - Total loss: 0.9966328740119934\n",
      "2021-08-25 11:18:36.935 | INFO     | src.policies:train:103 - Epoch 624 / 800\n",
      "2021-08-25 11:18:36.936 | INFO     | src.policies:train:109 - Episode 1941\n",
      "2021-08-25 11:18:37.005 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:37.007 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:37.008 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 179.42\n",
      "2021-08-25 11:18:37.014 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:37.017 | INFO     | src.policies:train:103 - Epoch 625 / 800\n",
      "2021-08-25 11:18:37.018 | INFO     | src.policies:train:109 - Episode 1942\n",
      "2021-08-25 11:18:37.087 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:37.089 | INFO     | src.policies:train:121 - Mean episode return: 193.0\n",
      "2021-08-25 11:18:37.090 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 179.35\n",
      "2021-08-25 11:18:37.091 | INFO     | src.policies:train:109 - Episode 1943\n",
      "2021-08-25 11:18:37.163 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:18:37.164 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:37.165 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 179.55\n",
      "2021-08-25 11:18:37.166 | WARNING  | src.policies:train:131 - The actual batch size is 393, instead of 200\n",
      "2021-08-25 11:18:37.172 | INFO     | src.policies:train:157 - Total loss: 0.9974552392959595\n",
      "2021-08-25 11:18:37.175 | INFO     | src.policies:train:103 - Epoch 626 / 800\n",
      "2021-08-25 11:18:37.176 | INFO     | src.policies:train:109 - Episode 1944\n",
      "2021-08-25 11:18:37.235 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:37.236 | INFO     | src.policies:train:121 - Mean episode return: 166.0\n",
      "2021-08-25 11:18:37.237 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 179.21\n",
      "2021-08-25 11:18:37.238 | INFO     | src.policies:train:109 - Episode 1945\n",
      "2021-08-25 11:18:37.284 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:37.285 | INFO     | src.policies:train:121 - Mean episode return: 136.0\n",
      "2021-08-25 11:18:37.286 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 178.61\n",
      "2021-08-25 11:18:37.287 | WARNING  | src.policies:train:131 - The actual batch size is 302, instead of 200\n",
      "2021-08-25 11:18:37.293 | INFO     | src.policies:train:157 - Total loss: 0.9966886043548584\n",
      "2021-08-25 11:18:37.296 | INFO     | src.policies:train:103 - Epoch 627 / 800\n",
      "2021-08-25 11:18:37.297 | INFO     | src.policies:train:109 - Episode 1946\n",
      "2021-08-25 11:18:37.352 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:37.354 | INFO     | src.policies:train:121 - Mean episode return: 164.0\n",
      "2021-08-25 11:18:37.355 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 178.25\n",
      "2021-08-25 11:18:37.355 | INFO     | src.policies:train:109 - Episode 1947\n",
      "2021-08-25 11:18:37.424 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:37.425 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:37.426 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 178.25\n",
      "2021-08-25 11:18:37.427 | WARNING  | src.policies:train:131 - The actual batch size is 364, instead of 200\n",
      "2021-08-25 11:18:37.433 | INFO     | src.policies:train:157 - Total loss: 0.9972527027130127\n",
      "2021-08-25 11:18:37.436 | INFO     | src.policies:train:103 - Epoch 628 / 800\n",
      "2021-08-25 11:18:37.437 | INFO     | src.policies:train:109 - Episode 1948\n",
      "2021-08-25 11:18:37.494 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:37.495 | INFO     | src.policies:train:121 - Mean episode return: 170.0\n",
      "2021-08-25 11:18:37.496 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 177.95\n",
      "2021-08-25 11:18:37.497 | INFO     | src.policies:train:109 - Episode 1949\n",
      "2021-08-25 11:18:37.542 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:37.543 | INFO     | src.policies:train:121 - Mean episode return: 130.0\n",
      "2021-08-25 11:18:37.544 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 177.84\n",
      "2021-08-25 11:18:37.545 | WARNING  | src.policies:train:131 - The actual batch size is 300, instead of 200\n",
      "2021-08-25 11:18:37.551 | INFO     | src.policies:train:157 - Total loss: 0.9966663718223572\n",
      "2021-08-25 11:18:37.554 | INFO     | src.policies:train:103 - Epoch 629 / 800\n",
      "2021-08-25 11:18:37.555 | INFO     | src.policies:train:109 - Episode 1950\n",
      "2021-08-25 11:18:37.610 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:37.611 | INFO     | src.policies:train:121 - Mean episode return: 158.0\n",
      "2021-08-25 11:18:37.612 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 177.42\n",
      "2021-08-25 11:18:37.613 | INFO     | src.policies:train:109 - Episode 1951\n",
      "2021-08-25 11:18:37.674 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:37.675 | INFO     | src.policies:train:121 - Mean episode return: 172.0\n",
      "2021-08-25 11:18:37.676 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 177.14\n",
      "2021-08-25 11:18:37.677 | WARNING  | src.policies:train:131 - The actual batch size is 330, instead of 200\n",
      "2021-08-25 11:18:37.683 | INFO     | src.policies:train:157 - Total loss: 0.9969695210456848\n",
      "2021-08-25 11:18:37.685 | INFO     | src.policies:train:103 - Epoch 630 / 800\n",
      "2021-08-25 11:18:37.686 | INFO     | src.policies:train:109 - Episode 1952\n",
      "2021-08-25 11:18:37.732 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:37.734 | INFO     | src.policies:train:121 - Mean episode return: 131.0\n",
      "2021-08-25 11:18:37.735 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.49\n",
      "2021-08-25 11:18:37.735 | INFO     | src.policies:train:109 - Episode 1953\n",
      "2021-08-25 11:18:37.788 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:37.789 | INFO     | src.policies:train:121 - Mean episode return: 151.0\n",
      "2021-08-25 11:18:37.790 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.0\n",
      "2021-08-25 11:18:37.791 | WARNING  | src.policies:train:131 - The actual batch size is 282, instead of 200\n",
      "2021-08-25 11:18:37.797 | INFO     | src.policies:train:157 - Total loss: 0.9964538812637329\n",
      "2021-08-25 11:18:37.799 | INFO     | src.policies:train:103 - Epoch 631 / 800\n",
      "2021-08-25 11:18:37.800 | INFO     | src.policies:train:109 - Episode 1954\n",
      "2021-08-25 11:18:37.867 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:37.869 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:37.870 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.77\n",
      "2021-08-25 11:18:37.875 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:37.878 | INFO     | src.policies:train:103 - Epoch 632 / 800\n",
      "2021-08-25 11:18:37.878 | INFO     | src.policies:train:109 - Episode 1955\n",
      "2021-08-25 11:18:37.947 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:37.949 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:37.950 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 177.46\n",
      "2021-08-25 11:18:37.955 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:37.957 | INFO     | src.policies:train:103 - Epoch 633 / 800\n",
      "2021-08-25 11:18:37.958 | INFO     | src.policies:train:109 - Episode 1956\n",
      "2021-08-25 11:18:38.014 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:38.016 | INFO     | src.policies:train:121 - Mean episode return: 160.0\n",
      "2021-08-25 11:18:38.017 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 177.06\n",
      "2021-08-25 11:18:38.018 | INFO     | src.policies:train:109 - Episode 1957\n",
      "2021-08-25 11:18:38.074 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:38.075 | INFO     | src.policies:train:121 - Mean episode return: 164.0\n",
      "2021-08-25 11:18:38.076 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 177.55\n",
      "2021-08-25 11:18:38.077 | WARNING  | src.policies:train:131 - The actual batch size is 324, instead of 200\n",
      "2021-08-25 11:18:38.083 | INFO     | src.policies:train:157 - Total loss: 0.9969133138656616\n",
      "2021-08-25 11:18:38.085 | INFO     | src.policies:train:103 - Epoch 634 / 800\n",
      "2021-08-25 11:18:38.086 | INFO     | src.policies:train:109 - Episode 1958\n",
      "2021-08-25 11:18:38.131 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:38.133 | INFO     | src.policies:train:121 - Mean episode return: 132.0\n",
      "2021-08-25 11:18:38.134 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 177.01\n",
      "2021-08-25 11:18:38.134 | INFO     | src.policies:train:109 - Episode 1959\n",
      "2021-08-25 11:18:38.200 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:38.201 | INFO     | src.policies:train:121 - Mean episode return: 187.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:18:38.202 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.88\n",
      "2021-08-25 11:18:38.203 | WARNING  | src.policies:train:131 - The actual batch size is 319, instead of 200\n",
      "2021-08-25 11:18:38.208 | INFO     | src.policies:train:157 - Total loss: 0.9968650341033936\n",
      "2021-08-25 11:18:38.211 | INFO     | src.policies:train:103 - Epoch 635 / 800\n",
      "2021-08-25 11:18:38.212 | INFO     | src.policies:train:109 - Episode 1960\n",
      "2021-08-25 11:18:38.256 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:38.257 | INFO     | src.policies:train:121 - Mean episode return: 127.0\n",
      "2021-08-25 11:18:38.258 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.26\n",
      "2021-08-25 11:18:38.259 | INFO     | src.policies:train:109 - Episode 1961\n",
      "2021-08-25 11:18:38.316 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:38.317 | INFO     | src.policies:train:121 - Mean episode return: 165.0\n",
      "2021-08-25 11:18:38.318 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.91\n",
      "2021-08-25 11:18:38.319 | WARNING  | src.policies:train:131 - The actual batch size is 292, instead of 200\n",
      "2021-08-25 11:18:38.325 | INFO     | src.policies:train:157 - Total loss: 0.9965750575065613\n",
      "2021-08-25 11:18:38.328 | INFO     | src.policies:train:103 - Epoch 636 / 800\n",
      "2021-08-25 11:18:38.329 | INFO     | src.policies:train:109 - Episode 1962\n",
      "2021-08-25 11:18:38.380 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:38.382 | INFO     | src.policies:train:121 - Mean episode return: 154.0\n",
      "2021-08-25 11:18:38.383 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.45\n",
      "2021-08-25 11:18:38.383 | INFO     | src.policies:train:109 - Episode 1963\n",
      "2021-08-25 11:18:38.443 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:38.444 | INFO     | src.policies:train:121 - Mean episode return: 170.0\n",
      "2021-08-25 11:18:38.445 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.15\n",
      "2021-08-25 11:18:38.445 | WARNING  | src.policies:train:131 - The actual batch size is 324, instead of 200\n",
      "2021-08-25 11:18:38.451 | INFO     | src.policies:train:157 - Total loss: 0.9969132542610168\n",
      "2021-08-25 11:18:38.454 | INFO     | src.policies:train:103 - Epoch 637 / 800\n",
      "2021-08-25 11:18:38.455 | INFO     | src.policies:train:109 - Episode 1964\n",
      "2021-08-25 11:18:38.516 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:38.518 | INFO     | src.policies:train:121 - Mean episode return: 181.0\n",
      "2021-08-25 11:18:38.518 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.99\n",
      "2021-08-25 11:18:38.519 | INFO     | src.policies:train:109 - Episode 1965\n",
      "2021-08-25 11:18:38.568 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:38.569 | INFO     | src.policies:train:121 - Mean episode return: 141.0\n",
      "2021-08-25 11:18:38.570 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.97\n",
      "2021-08-25 11:18:38.571 | WARNING  | src.policies:train:131 - The actual batch size is 322, instead of 200\n",
      "2021-08-25 11:18:38.577 | INFO     | src.policies:train:157 - Total loss: 0.9968944191932678\n",
      "2021-08-25 11:18:38.580 | INFO     | src.policies:train:103 - Epoch 638 / 800\n",
      "2021-08-25 11:18:38.581 | INFO     | src.policies:train:109 - Episode 1966\n",
      "2021-08-25 11:18:38.647 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:38.648 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:38.650 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.97\n",
      "2021-08-25 11:18:38.654 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:38.657 | INFO     | src.policies:train:103 - Epoch 639 / 800\n",
      "2021-08-25 11:18:38.658 | INFO     | src.policies:train:109 - Episode 1967\n",
      "2021-08-25 11:18:38.711 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:38.713 | INFO     | src.policies:train:121 - Mean episode return: 163.0\n",
      "2021-08-25 11:18:38.714 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.6\n",
      "2021-08-25 11:18:38.715 | INFO     | src.policies:train:109 - Episode 1968\n",
      "2021-08-25 11:18:38.774 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:38.775 | INFO     | src.policies:train:121 - Mean episode return: 170.0\n",
      "2021-08-25 11:18:38.776 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.3\n",
      "2021-08-25 11:18:38.777 | WARNING  | src.policies:train:131 - The actual batch size is 333, instead of 200\n",
      "2021-08-25 11:18:38.783 | INFO     | src.policies:train:157 - Total loss: 0.996997058391571\n",
      "2021-08-25 11:18:38.786 | INFO     | src.policies:train:103 - Epoch 640 / 800\n",
      "2021-08-25 11:18:38.787 | INFO     | src.policies:train:109 - Episode 1969\n",
      "2021-08-25 11:18:38.834 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:38.835 | INFO     | src.policies:train:121 - Mean episode return: 140.0\n",
      "2021-08-25 11:18:38.836 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 173.7\n",
      "2021-08-25 11:18:38.837 | INFO     | src.policies:train:109 - Episode 1970\n",
      "2021-08-25 11:18:38.905 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:38.906 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:38.907 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 173.7\n",
      "2021-08-25 11:18:38.908 | WARNING  | src.policies:train:131 - The actual batch size is 340, instead of 200\n",
      "2021-08-25 11:18:38.914 | INFO     | src.policies:train:157 - Total loss: 0.997058629989624\n",
      "2021-08-25 11:18:38.918 | INFO     | src.policies:train:103 - Epoch 641 / 800\n",
      "2021-08-25 11:18:38.919 | INFO     | src.policies:train:109 - Episode 1971\n",
      "2021-08-25 11:18:38.971 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:38.972 | INFO     | src.policies:train:121 - Mean episode return: 152.0\n",
      "2021-08-25 11:18:38.973 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 173.22\n",
      "2021-08-25 11:18:38.974 | INFO     | src.policies:train:109 - Episode 1972\n",
      "2021-08-25 11:18:39.036 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:39.037 | INFO     | src.policies:train:121 - Mean episode return: 179.0\n",
      "2021-08-25 11:18:39.038 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 173.01\n",
      "2021-08-25 11:18:39.039 | WARNING  | src.policies:train:131 - The actual batch size is 331, instead of 200\n",
      "2021-08-25 11:18:39.044 | INFO     | src.policies:train:157 - Total loss: 0.9969787001609802\n",
      "2021-08-25 11:18:39.047 | INFO     | src.policies:train:103 - Epoch 642 / 800\n",
      "2021-08-25 11:18:39.048 | INFO     | src.policies:train:109 - Episode 1973\n",
      "2021-08-25 11:18:39.115 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:39.116 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:39.117 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 173.01\n",
      "2021-08-25 11:18:39.122 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:39.125 | INFO     | src.policies:train:103 - Epoch 643 / 800\n",
      "2021-08-25 11:18:39.126 | INFO     | src.policies:train:109 - Episode 1974\n",
      "2021-08-25 11:18:39.172 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:39.173 | INFO     | src.policies:train:121 - Mean episode return: 133.0\n",
      "2021-08-25 11:18:39.174 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.61\n",
      "2021-08-25 11:18:39.175 | INFO     | src.policies:train:109 - Episode 1975\n",
      "2021-08-25 11:18:39.219 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:39.220 | INFO     | src.policies:train:121 - Mean episode return: 124.0\n",
      "2021-08-25 11:18:39.221 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:18:39.222 | WARNING  | src.policies:train:131 - The actual batch size is 257, instead of 200\n",
      "2021-08-25 11:18:39.228 | INFO     | src.policies:train:157 - Total loss: 0.9961086511611938\n",
      "2021-08-25 11:18:39.231 | INFO     | src.policies:train:103 - Epoch 644 / 800\n",
      "2021-08-25 11:18:39.232 | INFO     | src.policies:train:109 - Episode 1976\n",
      "2021-08-25 11:18:39.296 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:39.298 | INFO     | src.policies:train:121 - Mean episode return: 189.0\n",
      "2021-08-25 11:18:39.298 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.09\n",
      "2021-08-25 11:18:39.299 | INFO     | src.policies:train:109 - Episode 1977\n",
      "2021-08-25 11:18:39.351 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:39.353 | INFO     | src.policies:train:121 - Mean episode return: 148.0\n",
      "2021-08-25 11:18:39.354 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 171.57\n",
      "2021-08-25 11:18:39.355 | WARNING  | src.policies:train:131 - The actual batch size is 337, instead of 200\n",
      "2021-08-25 11:18:39.360 | INFO     | src.policies:train:157 - Total loss: 0.9970322847366333\n",
      "2021-08-25 11:18:39.363 | INFO     | src.policies:train:103 - Epoch 645 / 800\n",
      "2021-08-25 11:18:39.364 | INFO     | src.policies:train:109 - Episode 1978\n",
      "2021-08-25 11:18:39.432 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:39.434 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:39.435 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 171.57\n",
      "2021-08-25 11:18:39.439 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:39.442 | INFO     | src.policies:train:103 - Epoch 646 / 800\n",
      "2021-08-25 11:18:39.442 | INFO     | src.policies:train:109 - Episode 1979\n",
      "2021-08-25 11:18:39.495 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:39.496 | INFO     | src.policies:train:121 - Mean episode return: 151.0\n",
      "2021-08-25 11:18:39.497 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 171.42\n",
      "2021-08-25 11:18:39.498 | INFO     | src.policies:train:109 - Episode 1980\n",
      "2021-08-25 11:18:39.567 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:39.568 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:39.569 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 171.42\n",
      "2021-08-25 11:18:39.570 | WARNING  | src.policies:train:131 - The actual batch size is 351, instead of 200\n",
      "2021-08-25 11:18:39.576 | INFO     | src.policies:train:157 - Total loss: 0.9971506595611572\n",
      "2021-08-25 11:18:39.579 | INFO     | src.policies:train:103 - Epoch 647 / 800\n",
      "2021-08-25 11:18:39.580 | INFO     | src.policies:train:109 - Episode 1981\n",
      "2021-08-25 11:18:39.637 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:39.638 | INFO     | src.policies:train:121 - Mean episode return: 162.0\n",
      "2021-08-25 11:18:39.639 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 171.04\n",
      "2021-08-25 11:18:39.640 | INFO     | src.policies:train:109 - Episode 1982\n",
      "2021-08-25 11:18:39.706 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:39.707 | INFO     | src.policies:train:121 - Mean episode return: 193.0\n",
      "2021-08-25 11:18:39.708 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 170.97\n",
      "2021-08-25 11:18:39.708 | WARNING  | src.policies:train:131 - The actual batch size is 355, instead of 200\n",
      "2021-08-25 11:18:39.715 | INFO     | src.policies:train:157 - Total loss: 0.9971829056739807\n",
      "2021-08-25 11:18:39.718 | INFO     | src.policies:train:103 - Epoch 648 / 800\n",
      "2021-08-25 11:18:39.719 | INFO     | src.policies:train:109 - Episode 1983\n",
      "2021-08-25 11:18:39.767 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:39.769 | INFO     | src.policies:train:121 - Mean episode return: 138.0\n",
      "2021-08-25 11:18:39.770 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 170.93\n",
      "2021-08-25 11:18:39.771 | INFO     | src.policies:train:109 - Episode 1984\n",
      "2021-08-25 11:18:39.840 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:39.841 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:39.842 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 170.93\n",
      "2021-08-25 11:18:39.843 | WARNING  | src.policies:train:131 - The actual batch size is 338, instead of 200\n",
      "2021-08-25 11:18:39.849 | INFO     | src.policies:train:157 - Total loss: 0.9970413446426392\n",
      "2021-08-25 11:18:39.852 | INFO     | src.policies:train:103 - Epoch 649 / 800\n",
      "2021-08-25 11:18:39.853 | INFO     | src.policies:train:109 - Episode 1985\n",
      "2021-08-25 11:18:39.919 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:39.920 | INFO     | src.policies:train:121 - Mean episode return: 194.0\n",
      "2021-08-25 11:18:39.921 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 170.87\n",
      "2021-08-25 11:18:39.922 | INFO     | src.policies:train:109 - Episode 1986\n",
      "2021-08-25 11:18:39.944 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:39.946 | INFO     | src.policies:train:121 - Mean episode return: 58.0\n",
      "2021-08-25 11:18:39.946 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 169.45\n",
      "2021-08-25 11:18:39.947 | WARNING  | src.policies:train:131 - The actual batch size is 252, instead of 200\n",
      "2021-08-25 11:18:39.953 | INFO     | src.policies:train:157 - Total loss: 0.9960315227508545\n",
      "2021-08-25 11:18:39.956 | INFO     | src.policies:train:103 - Epoch 650 / 800\n",
      "2021-08-25 11:18:39.957 | INFO     | src.policies:train:109 - Episode 1987\n",
      "2021-08-25 11:18:40.015 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:40.016 | INFO     | src.policies:train:121 - Mean episode return: 166.0\n",
      "2021-08-25 11:18:40.017 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 169.25\n",
      "2021-08-25 11:18:40.018 | INFO     | src.policies:train:109 - Episode 1988\n",
      "2021-08-25 11:18:40.086 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:40.088 | INFO     | src.policies:train:121 - Mean episode return: 196.0\n",
      "2021-08-25 11:18:40.089 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 169.21\n",
      "2021-08-25 11:18:40.089 | WARNING  | src.policies:train:131 - The actual batch size is 362, instead of 200\n",
      "2021-08-25 11:18:40.095 | INFO     | src.policies:train:157 - Total loss: 0.9972373247146606\n",
      "2021-08-25 11:18:40.098 | INFO     | src.policies:train:103 - Epoch 651 / 800\n",
      "2021-08-25 11:18:40.100 | INFO     | src.policies:train:109 - Episode 1989\n",
      "2021-08-25 11:18:40.148 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:40.150 | INFO     | src.policies:train:121 - Mean episode return: 134.0\n",
      "2021-08-25 11:18:40.151 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 168.55\n",
      "2021-08-25 11:18:40.152 | INFO     | src.policies:train:109 - Episode 1990\n",
      "2021-08-25 11:18:40.214 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:40.215 | INFO     | src.policies:train:121 - Mean episode return: 177.0\n",
      "2021-08-25 11:18:40.216 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 168.32\n",
      "2021-08-25 11:18:40.217 | WARNING  | src.policies:train:131 - The actual batch size is 311, instead of 200\n",
      "2021-08-25 11:18:40.223 | INFO     | src.policies:train:157 - Total loss: 0.9967843890190125\n",
      "2021-08-25 11:18:40.225 | INFO     | src.policies:train:103 - Epoch 652 / 800\n",
      "2021-08-25 11:18:40.226 | INFO     | src.policies:train:109 - Episode 1991\n",
      "2021-08-25 11:18:40.293 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:40.295 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:40.296 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 168.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:18:40.300 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:40.303 | INFO     | src.policies:train:103 - Epoch 653 / 800\n",
      "2021-08-25 11:18:40.304 | INFO     | src.policies:train:109 - Episode 1992\n",
      "2021-08-25 11:18:40.357 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:40.359 | INFO     | src.policies:train:121 - Mean episode return: 157.0\n",
      "2021-08-25 11:18:40.360 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 167.89\n",
      "2021-08-25 11:18:40.361 | INFO     | src.policies:train:109 - Episode 1993\n",
      "2021-08-25 11:18:40.427 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:40.428 | INFO     | src.policies:train:121 - Mean episode return: 193.0\n",
      "2021-08-25 11:18:40.429 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 168.23\n",
      "2021-08-25 11:18:40.430 | WARNING  | src.policies:train:131 - The actual batch size is 350, instead of 200\n",
      "2021-08-25 11:18:40.436 | INFO     | src.policies:train:157 - Total loss: 0.9971426129341125\n",
      "2021-08-25 11:18:40.439 | INFO     | src.policies:train:103 - Epoch 654 / 800\n",
      "2021-08-25 11:18:40.440 | INFO     | src.policies:train:109 - Episode 1994\n",
      "2021-08-25 11:18:40.506 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:40.507 | INFO     | src.policies:train:121 - Mean episode return: 193.0\n",
      "2021-08-25 11:18:40.508 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 168.16\n",
      "2021-08-25 11:18:40.509 | INFO     | src.policies:train:109 - Episode 1995\n",
      "2021-08-25 11:18:40.550 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:40.552 | INFO     | src.policies:train:121 - Mean episode return: 117.0\n",
      "2021-08-25 11:18:40.553 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 167.33\n",
      "2021-08-25 11:18:40.554 | WARNING  | src.policies:train:131 - The actual batch size is 310, instead of 200\n",
      "2021-08-25 11:18:40.560 | INFO     | src.policies:train:157 - Total loss: 0.9967740178108215\n",
      "2021-08-25 11:18:40.563 | INFO     | src.policies:train:103 - Epoch 655 / 800\n",
      "2021-08-25 11:18:40.564 | INFO     | src.policies:train:109 - Episode 1996\n",
      "2021-08-25 11:18:40.613 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:40.614 | INFO     | src.policies:train:121 - Mean episode return: 147.0\n",
      "2021-08-25 11:18:40.615 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 167.08\n",
      "2021-08-25 11:18:40.616 | INFO     | src.policies:train:109 - Episode 1997\n",
      "2021-08-25 11:18:40.686 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:40.687 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:40.688 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 167.21\n",
      "2021-08-25 11:18:40.689 | WARNING  | src.policies:train:131 - The actual batch size is 347, instead of 200\n",
      "2021-08-25 11:18:40.694 | INFO     | src.policies:train:157 - Total loss: 0.9971179366111755\n",
      "2021-08-25 11:18:40.697 | INFO     | src.policies:train:103 - Epoch 656 / 800\n",
      "2021-08-25 11:18:40.698 | INFO     | src.policies:train:109 - Episode 1998\n",
      "2021-08-25 11:18:40.766 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:40.768 | INFO     | src.policies:train:121 - Mean episode return: 198.0\n",
      "2021-08-25 11:18:40.769 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 167.19\n",
      "2021-08-25 11:18:40.770 | INFO     | src.policies:train:109 - Episode 1999\n",
      "2021-08-25 11:18:40.839 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:40.840 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:40.841 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 167.46\n",
      "2021-08-25 11:18:40.842 | WARNING  | src.policies:train:131 - The actual batch size is 398, instead of 200\n",
      "2021-08-25 11:18:40.848 | INFO     | src.policies:train:157 - Total loss: 0.9974871873855591\n",
      "2021-08-25 11:18:40.851 | INFO     | src.policies:train:103 - Epoch 657 / 800\n",
      "2021-08-25 11:18:40.852 | INFO     | src.policies:train:109 - Episode 2000\n",
      "2021-08-25 11:18:40.902 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:40.903 | INFO     | src.policies:train:121 - Mean episode return: 142.0\n",
      "2021-08-25 11:18:40.904 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 167.71\n",
      "2021-08-25 11:18:40.905 | INFO     | src.policies:train:109 - Episode 2001\n",
      "2021-08-25 11:18:40.973 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:40.974 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:40.975 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 168.09\n",
      "2021-08-25 11:18:40.976 | WARNING  | src.policies:train:131 - The actual batch size is 342, instead of 200\n",
      "2021-08-25 11:18:40.982 | INFO     | src.policies:train:157 - Total loss: 0.9970759749412537\n",
      "2021-08-25 11:18:40.984 | INFO     | src.policies:train:103 - Epoch 658 / 800\n",
      "2021-08-25 11:18:40.985 | INFO     | src.policies:train:109 - Episode 2002\n",
      "2021-08-25 11:18:41.054 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:41.056 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:41.057 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 168.09\n",
      "2021-08-25 11:18:41.061 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:41.063 | INFO     | src.policies:train:103 - Epoch 659 / 800\n",
      "2021-08-25 11:18:41.064 | INFO     | src.policies:train:109 - Episode 2003\n",
      "2021-08-25 11:18:41.131 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:41.133 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:41.134 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 168.64\n",
      "2021-08-25 11:18:41.139 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:41.141 | INFO     | src.policies:train:103 - Epoch 660 / 800\n",
      "2021-08-25 11:18:41.142 | INFO     | src.policies:train:109 - Episode 2004\n",
      "2021-08-25 11:18:41.211 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:41.213 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:41.214 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 168.76\n",
      "2021-08-25 11:18:41.218 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:41.221 | INFO     | src.policies:train:103 - Epoch 661 / 800\n",
      "2021-08-25 11:18:41.222 | INFO     | src.policies:train:109 - Episode 2005\n",
      "2021-08-25 11:18:41.283 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:41.284 | INFO     | src.policies:train:121 - Mean episode return: 178.0\n",
      "2021-08-25 11:18:41.285 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 168.54\n",
      "2021-08-25 11:18:41.286 | INFO     | src.policies:train:109 - Episode 2006\n",
      "2021-08-25 11:18:41.358 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:41.359 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:41.360 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 169.1\n",
      "2021-08-25 11:18:41.361 | WARNING  | src.policies:train:131 - The actual batch size is 378, instead of 200\n",
      "2021-08-25 11:18:41.367 | INFO     | src.policies:train:157 - Total loss: 0.9973540902137756\n",
      "2021-08-25 11:18:41.370 | INFO     | src.policies:train:103 - Epoch 662 / 800\n",
      "2021-08-25 11:18:41.371 | INFO     | src.policies:train:109 - Episode 2007\n",
      "2021-08-25 11:18:41.430 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:41.431 | INFO     | src.policies:train:121 - Mean episode return: 172.0\n",
      "2021-08-25 11:18:41.432 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 169.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:18:41.433 | INFO     | src.policies:train:109 - Episode 2008\n",
      "2021-08-25 11:18:41.500 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:41.501 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:41.502 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 169.31\n",
      "2021-08-25 11:18:41.503 | WARNING  | src.policies:train:131 - The actual batch size is 372, instead of 200\n",
      "2021-08-25 11:18:41.509 | INFO     | src.policies:train:157 - Total loss: 0.9973116517066956\n",
      "2021-08-25 11:18:41.512 | INFO     | src.policies:train:103 - Epoch 663 / 800\n",
      "2021-08-25 11:18:41.513 | INFO     | src.policies:train:109 - Episode 2009\n",
      "2021-08-25 11:18:41.574 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:41.576 | INFO     | src.policies:train:121 - Mean episode return: 173.0\n",
      "2021-08-25 11:18:41.577 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 169.04\n",
      "2021-08-25 11:18:41.577 | INFO     | src.policies:train:109 - Episode 2010\n",
      "2021-08-25 11:18:41.644 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:41.645 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:41.646 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 169.28\n",
      "2021-08-25 11:18:41.647 | WARNING  | src.policies:train:131 - The actual batch size is 373, instead of 200\n",
      "2021-08-25 11:18:41.653 | INFO     | src.policies:train:157 - Total loss: 0.9973188638687134\n",
      "2021-08-25 11:18:41.656 | INFO     | src.policies:train:103 - Epoch 664 / 800\n",
      "2021-08-25 11:18:41.657 | INFO     | src.policies:train:109 - Episode 2011\n",
      "2021-08-25 11:18:41.725 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:41.726 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:41.727 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 169.86\n",
      "2021-08-25 11:18:41.732 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:41.735 | INFO     | src.policies:train:103 - Epoch 665 / 800\n",
      "2021-08-25 11:18:41.735 | INFO     | src.policies:train:109 - Episode 2012\n",
      "2021-08-25 11:18:41.803 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:41.805 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:41.806 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 170.34\n",
      "2021-08-25 11:18:41.811 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:41.814 | INFO     | src.policies:train:103 - Epoch 666 / 800\n",
      "2021-08-25 11:18:41.815 | INFO     | src.policies:train:109 - Episode 2013\n",
      "2021-08-25 11:18:41.885 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:41.887 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:41.891 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 170.66\n",
      "2021-08-25 11:18:41.899 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:41.904 | INFO     | src.policies:train:103 - Epoch 667 / 800\n",
      "2021-08-25 11:18:41.907 | INFO     | src.policies:train:109 - Episode 2014\n",
      "2021-08-25 11:18:41.990 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:41.992 | INFO     | src.policies:train:121 - Mean episode return: 197.0\n",
      "2021-08-25 11:18:41.994 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 171.36\n",
      "2021-08-25 11:18:41.995 | INFO     | src.policies:train:109 - Episode 2015\n",
      "2021-08-25 11:18:42.072 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:42.074 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:42.075 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 171.36\n",
      "2021-08-25 11:18:42.075 | WARNING  | src.policies:train:131 - The actual batch size is 397, instead of 200\n",
      "2021-08-25 11:18:42.082 | INFO     | src.policies:train:157 - Total loss: 0.9974811673164368\n",
      "2021-08-25 11:18:42.085 | INFO     | src.policies:train:103 - Epoch 668 / 800\n",
      "2021-08-25 11:18:42.086 | INFO     | src.policies:train:109 - Episode 2016\n",
      "2021-08-25 11:18:42.153 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:42.155 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:42.156 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.1\n",
      "2021-08-25 11:18:42.161 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:42.163 | INFO     | src.policies:train:103 - Epoch 669 / 800\n",
      "2021-08-25 11:18:42.164 | INFO     | src.policies:train:109 - Episode 2017\n",
      "2021-08-25 11:18:42.233 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:42.234 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:42.235 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.75\n",
      "2021-08-25 11:18:42.240 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:42.243 | INFO     | src.policies:train:103 - Epoch 670 / 800\n",
      "2021-08-25 11:18:42.244 | INFO     | src.policies:train:109 - Episode 2018\n",
      "2021-08-25 11:18:42.312 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:42.313 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:42.314 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 173.26\n",
      "2021-08-25 11:18:42.319 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:42.321 | INFO     | src.policies:train:103 - Epoch 671 / 800\n",
      "2021-08-25 11:18:42.322 | INFO     | src.policies:train:109 - Episode 2019\n",
      "2021-08-25 11:18:42.390 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:42.392 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:42.393 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 173.26\n",
      "2021-08-25 11:18:42.398 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:42.400 | INFO     | src.policies:train:103 - Epoch 672 / 800\n",
      "2021-08-25 11:18:42.401 | INFO     | src.policies:train:109 - Episode 2020\n",
      "2021-08-25 11:18:42.470 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:42.471 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:42.472 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 173.81\n",
      "2021-08-25 11:18:42.477 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:42.480 | INFO     | src.policies:train:103 - Epoch 673 / 800\n",
      "2021-08-25 11:18:42.481 | INFO     | src.policies:train:109 - Episode 2021\n",
      "2021-08-25 11:18:42.549 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:42.550 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:42.551 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 173.81\n",
      "2021-08-25 11:18:42.556 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:42.559 | INFO     | src.policies:train:103 - Epoch 674 / 800\n",
      "2021-08-25 11:18:42.560 | INFO     | src.policies:train:109 - Episode 2022\n",
      "2021-08-25 11:18:42.627 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:42.628 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:42.629 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.23\n",
      "2021-08-25 11:18:42.634 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:42.637 | INFO     | src.policies:train:103 - Epoch 675 / 800\n",
      "2021-08-25 11:18:42.638 | INFO     | src.policies:train:109 - Episode 2023\n",
      "2021-08-25 11:18:42.706 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:18:42.708 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:42.709 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.23\n",
      "2021-08-25 11:18:42.714 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:42.716 | INFO     | src.policies:train:103 - Epoch 676 / 800\n",
      "2021-08-25 11:18:42.717 | INFO     | src.policies:train:109 - Episode 2024\n",
      "2021-08-25 11:18:42.784 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:42.785 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:42.786 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.42\n",
      "2021-08-25 11:18:42.791 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:42.794 | INFO     | src.policies:train:103 - Epoch 677 / 800\n",
      "2021-08-25 11:18:42.795 | INFO     | src.policies:train:109 - Episode 2025\n",
      "2021-08-25 11:18:42.863 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:42.865 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:42.866 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.08\n",
      "2021-08-25 11:18:42.871 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:42.873 | INFO     | src.policies:train:103 - Epoch 678 / 800\n",
      "2021-08-25 11:18:42.874 | INFO     | src.policies:train:109 - Episode 2026\n",
      "2021-08-25 11:18:42.944 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:42.945 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:42.946 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.52\n",
      "2021-08-25 11:18:42.951 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:42.954 | INFO     | src.policies:train:103 - Epoch 679 / 800\n",
      "2021-08-25 11:18:42.955 | INFO     | src.policies:train:109 - Episode 2027\n",
      "2021-08-25 11:18:43.022 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:43.023 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:43.024 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.14\n",
      "2021-08-25 11:18:43.029 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:43.032 | INFO     | src.policies:train:103 - Epoch 680 / 800\n",
      "2021-08-25 11:18:43.032 | INFO     | src.policies:train:109 - Episode 2028\n",
      "2021-08-25 11:18:43.100 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:43.102 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:43.103 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.56\n",
      "2021-08-25 11:18:43.107 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:43.110 | INFO     | src.policies:train:103 - Epoch 681 / 800\n",
      "2021-08-25 11:18:43.111 | INFO     | src.policies:train:109 - Episode 2029\n",
      "2021-08-25 11:18:43.178 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:43.180 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:43.181 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 177.26\n",
      "2021-08-25 11:18:43.186 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:43.188 | INFO     | src.policies:train:103 - Epoch 682 / 800\n",
      "2021-08-25 11:18:43.189 | INFO     | src.policies:train:109 - Episode 2030\n",
      "2021-08-25 11:18:43.256 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:43.258 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:43.259 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 177.84\n",
      "2021-08-25 11:18:43.264 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:43.266 | INFO     | src.policies:train:103 - Epoch 683 / 800\n",
      "2021-08-25 11:18:43.267 | INFO     | src.policies:train:109 - Episode 2031\n",
      "2021-08-25 11:18:43.334 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:43.335 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:43.336 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 177.84\n",
      "2021-08-25 11:18:43.341 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:43.343 | INFO     | src.policies:train:103 - Epoch 684 / 800\n",
      "2021-08-25 11:18:43.344 | INFO     | src.policies:train:109 - Episode 2032\n",
      "2021-08-25 11:18:43.413 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:43.415 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:43.416 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 177.84\n",
      "2021-08-25 11:18:43.420 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:43.423 | INFO     | src.policies:train:103 - Epoch 685 / 800\n",
      "2021-08-25 11:18:43.423 | INFO     | src.policies:train:109 - Episode 2033\n",
      "2021-08-25 11:18:43.493 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:43.495 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:43.496 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 178.0\n",
      "2021-08-25 11:18:43.500 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:43.503 | INFO     | src.policies:train:103 - Epoch 686 / 800\n",
      "2021-08-25 11:18:43.503 | INFO     | src.policies:train:109 - Episode 2034\n",
      "2021-08-25 11:18:43.573 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:43.574 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:43.575 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 178.0\n",
      "2021-08-25 11:18:43.580 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:43.582 | INFO     | src.policies:train:103 - Epoch 687 / 800\n",
      "2021-08-25 11:18:43.583 | INFO     | src.policies:train:109 - Episode 2035\n",
      "2021-08-25 11:18:43.650 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:43.652 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:43.653 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 178.0\n",
      "2021-08-25 11:18:43.658 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:43.660 | INFO     | src.policies:train:103 - Epoch 688 / 800\n",
      "2021-08-25 11:18:43.661 | INFO     | src.policies:train:109 - Episode 2036\n",
      "2021-08-25 11:18:43.729 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:43.730 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:43.731 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 178.71\n",
      "2021-08-25 11:18:43.736 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:43.738 | INFO     | src.policies:train:103 - Epoch 689 / 800\n",
      "2021-08-25 11:18:43.739 | INFO     | src.policies:train:109 - Episode 2037\n",
      "2021-08-25 11:18:43.808 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:43.810 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:43.811 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 178.83\n",
      "2021-08-25 11:18:43.816 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:43.818 | INFO     | src.policies:train:103 - Epoch 690 / 800\n",
      "2021-08-25 11:18:43.819 | INFO     | src.policies:train:109 - Episode 2038\n",
      "2021-08-25 11:18:43.888 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:43.889 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:43.890 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 178.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:18:43.895 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:43.897 | INFO     | src.policies:train:103 - Epoch 691 / 800\n",
      "2021-08-25 11:18:43.898 | INFO     | src.policies:train:109 - Episode 2039\n",
      "2021-08-25 11:18:43.967 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:43.968 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:43.970 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 179.68\n",
      "2021-08-25 11:18:43.974 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:43.977 | INFO     | src.policies:train:103 - Epoch 692 / 800\n",
      "2021-08-25 11:18:43.978 | INFO     | src.policies:train:109 - Episode 2040\n",
      "2021-08-25 11:18:44.049 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:44.051 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:44.052 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 179.86\n",
      "2021-08-25 11:18:44.058 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:44.062 | INFO     | src.policies:train:103 - Epoch 693 / 800\n",
      "2021-08-25 11:18:44.063 | INFO     | src.policies:train:109 - Episode 2041\n",
      "2021-08-25 11:18:44.131 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:44.133 | INFO     | src.policies:train:121 - Mean episode return: 192.0\n",
      "2021-08-25 11:18:44.134 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 179.78\n",
      "2021-08-25 11:18:44.135 | INFO     | src.policies:train:109 - Episode 2042\n",
      "2021-08-25 11:18:44.203 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:44.205 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:44.205 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 179.85\n",
      "2021-08-25 11:18:44.206 | WARNING  | src.policies:train:131 - The actual batch size is 392, instead of 200\n",
      "2021-08-25 11:18:44.213 | INFO     | src.policies:train:157 - Total loss: 0.9974488019943237\n",
      "2021-08-25 11:18:44.216 | INFO     | src.policies:train:103 - Epoch 694 / 800\n",
      "2021-08-25 11:18:44.217 | INFO     | src.policies:train:109 - Episode 2043\n",
      "2021-08-25 11:18:44.285 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:44.286 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:44.287 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 179.85\n",
      "2021-08-25 11:18:44.292 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:44.295 | INFO     | src.policies:train:103 - Epoch 695 / 800\n",
      "2021-08-25 11:18:44.295 | INFO     | src.policies:train:109 - Episode 2044\n",
      "2021-08-25 11:18:44.364 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:44.366 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:44.367 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 180.19\n",
      "2021-08-25 11:18:44.371 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:44.374 | INFO     | src.policies:train:103 - Epoch 696 / 800\n",
      "2021-08-25 11:18:44.375 | INFO     | src.policies:train:109 - Episode 2045\n",
      "2021-08-25 11:18:44.442 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:44.443 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:44.444 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 180.83\n",
      "2021-08-25 11:18:44.448 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:44.451 | INFO     | src.policies:train:103 - Epoch 697 / 800\n",
      "2021-08-25 11:18:44.451 | INFO     | src.policies:train:109 - Episode 2046\n",
      "2021-08-25 11:18:44.519 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:44.521 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:44.522 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.19\n",
      "2021-08-25 11:18:44.526 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:44.529 | INFO     | src.policies:train:103 - Epoch 698 / 800\n",
      "2021-08-25 11:18:44.530 | INFO     | src.policies:train:109 - Episode 2047\n",
      "2021-08-25 11:18:44.597 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:44.599 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:44.600 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.19\n",
      "2021-08-25 11:18:44.605 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:44.607 | INFO     | src.policies:train:103 - Epoch 699 / 800\n",
      "2021-08-25 11:18:44.608 | INFO     | src.policies:train:109 - Episode 2048\n",
      "2021-08-25 11:18:44.675 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:44.676 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:44.677 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.49\n",
      "2021-08-25 11:18:44.682 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:44.685 | INFO     | src.policies:train:103 - Epoch 700 / 800\n",
      "2021-08-25 11:18:44.685 | INFO     | src.policies:train:109 - Episode 2049\n",
      "2021-08-25 11:18:44.754 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:44.755 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:44.756 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.19\n",
      "2021-08-25 11:18:44.761 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:44.763 | INFO     | src.policies:train:103 - Epoch 701 / 800\n",
      "2021-08-25 11:18:44.764 | INFO     | src.policies:train:109 - Episode 2050\n",
      "2021-08-25 11:18:44.830 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:44.832 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:44.833 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.61\n",
      "2021-08-25 11:18:44.837 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:44.840 | INFO     | src.policies:train:103 - Epoch 702 / 800\n",
      "2021-08-25 11:18:44.841 | INFO     | src.policies:train:109 - Episode 2051\n",
      "2021-08-25 11:18:44.906 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:44.907 | INFO     | src.policies:train:121 - Mean episode return: 195.0\n",
      "2021-08-25 11:18:44.908 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.84\n",
      "2021-08-25 11:18:44.909 | INFO     | src.policies:train:109 - Episode 2052\n",
      "2021-08-25 11:18:44.978 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:44.979 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:44.980 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 183.53\n",
      "2021-08-25 11:18:44.981 | WARNING  | src.policies:train:131 - The actual batch size is 395, instead of 200\n",
      "2021-08-25 11:18:44.987 | INFO     | src.policies:train:157 - Total loss: 0.9974682331085205\n",
      "2021-08-25 11:18:44.989 | INFO     | src.policies:train:103 - Epoch 703 / 800\n",
      "2021-08-25 11:18:44.990 | INFO     | src.policies:train:109 - Episode 2053\n",
      "2021-08-25 11:18:45.058 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:45.059 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:45.060 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 184.02\n",
      "2021-08-25 11:18:45.065 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:45.067 | INFO     | src.policies:train:103 - Epoch 704 / 800\n",
      "2021-08-25 11:18:45.068 | INFO     | src.policies:train:109 - Episode 2054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:18:45.135 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:45.137 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:45.138 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 184.02\n",
      "2021-08-25 11:18:45.143 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:45.145 | INFO     | src.policies:train:103 - Epoch 705 / 800\n",
      "2021-08-25 11:18:45.146 | INFO     | src.policies:train:109 - Episode 2055\n",
      "2021-08-25 11:18:45.213 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:45.215 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:45.216 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 184.02\n",
      "2021-08-25 11:18:45.220 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:45.223 | INFO     | src.policies:train:103 - Epoch 706 / 800\n",
      "2021-08-25 11:18:45.223 | INFO     | src.policies:train:109 - Episode 2056\n",
      "2021-08-25 11:18:45.291 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:45.293 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:45.294 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 184.42\n",
      "2021-08-25 11:18:45.299 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:45.301 | INFO     | src.policies:train:103 - Epoch 707 / 800\n",
      "2021-08-25 11:18:45.302 | INFO     | src.policies:train:109 - Episode 2057\n",
      "2021-08-25 11:18:45.370 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:45.372 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:45.373 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 184.78\n",
      "2021-08-25 11:18:45.377 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:45.380 | INFO     | src.policies:train:103 - Epoch 708 / 800\n",
      "2021-08-25 11:18:45.380 | INFO     | src.policies:train:109 - Episode 2058\n",
      "2021-08-25 11:18:45.447 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:45.449 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:45.450 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 185.46\n",
      "2021-08-25 11:18:45.455 | INFO     | src.policies:train:157 - Total loss: 0.9950000047683716\n",
      "2021-08-25 11:18:45.458 | INFO     | src.policies:train:103 - Epoch 709 / 800\n",
      "2021-08-25 11:18:45.459 | INFO     | src.policies:train:109 - Episode 2059\n",
      "2021-08-25 11:18:45.528 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:45.530 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:45.531 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 185.59\n",
      "2021-08-25 11:18:45.535 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:45.538 | INFO     | src.policies:train:103 - Epoch 710 / 800\n",
      "2021-08-25 11:18:45.538 | INFO     | src.policies:train:109 - Episode 2060\n",
      "2021-08-25 11:18:45.606 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:45.608 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:45.609 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 186.32\n",
      "2021-08-25 11:18:45.613 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:45.616 | INFO     | src.policies:train:103 - Epoch 711 / 800\n",
      "2021-08-25 11:18:45.617 | INFO     | src.policies:train:109 - Episode 2061\n",
      "2021-08-25 11:18:45.684 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:45.686 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:45.687 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 186.67\n",
      "2021-08-25 11:18:45.692 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:45.695 | INFO     | src.policies:train:103 - Epoch 712 / 800\n",
      "2021-08-25 11:18:45.696 | INFO     | src.policies:train:109 - Episode 2062\n",
      "2021-08-25 11:18:45.765 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:45.766 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:45.767 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 187.13\n",
      "2021-08-25 11:18:45.773 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:45.775 | INFO     | src.policies:train:103 - Epoch 713 / 800\n",
      "2021-08-25 11:18:45.776 | INFO     | src.policies:train:109 - Episode 2063\n",
      "2021-08-25 11:18:45.843 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:45.845 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:45.846 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 187.43\n",
      "2021-08-25 11:18:45.851 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:45.854 | INFO     | src.policies:train:103 - Epoch 714 / 800\n",
      "2021-08-25 11:18:45.854 | INFO     | src.policies:train:109 - Episode 2064\n",
      "2021-08-25 11:18:45.925 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:45.926 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:45.927 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 187.62\n",
      "2021-08-25 11:18:45.932 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:45.935 | INFO     | src.policies:train:103 - Epoch 715 / 800\n",
      "2021-08-25 11:18:45.935 | INFO     | src.policies:train:109 - Episode 2065\n",
      "2021-08-25 11:18:46.004 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:46.006 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:46.006 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 188.21\n",
      "2021-08-25 11:18:46.012 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:46.015 | INFO     | src.policies:train:103 - Epoch 716 / 800\n",
      "2021-08-25 11:18:46.016 | INFO     | src.policies:train:109 - Episode 2066\n",
      "2021-08-25 11:18:46.083 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:46.084 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:46.085 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 188.21\n",
      "2021-08-25 11:18:46.090 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:46.093 | INFO     | src.policies:train:103 - Epoch 717 / 800\n",
      "2021-08-25 11:18:46.094 | INFO     | src.policies:train:109 - Episode 2067\n",
      "2021-08-25 11:18:46.165 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:46.167 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:46.167 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 188.58\n",
      "2021-08-25 11:18:46.173 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:46.175 | INFO     | src.policies:train:103 - Epoch 718 / 800\n",
      "2021-08-25 11:18:46.176 | INFO     | src.policies:train:109 - Episode 2068\n",
      "2021-08-25 11:18:46.243 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:46.245 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:46.246 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 188.88\n",
      "2021-08-25 11:18:46.251 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:46.253 | INFO     | src.policies:train:103 - Epoch 719 / 800\n",
      "2021-08-25 11:18:46.254 | INFO     | src.policies:train:109 - Episode 2069\n",
      "2021-08-25 11:18:46.321 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:46.323 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:18:46.324 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 189.48\n",
      "2021-08-25 11:18:46.329 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:46.331 | INFO     | src.policies:train:103 - Epoch 720 / 800\n",
      "2021-08-25 11:18:46.332 | INFO     | src.policies:train:109 - Episode 2070\n",
      "2021-08-25 11:18:46.401 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:46.403 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:46.403 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 189.48\n",
      "2021-08-25 11:18:46.408 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:46.411 | INFO     | src.policies:train:103 - Epoch 721 / 800\n",
      "2021-08-25 11:18:46.412 | INFO     | src.policies:train:109 - Episode 2071\n",
      "2021-08-25 11:18:46.480 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:46.481 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:46.482 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 189.96\n",
      "2021-08-25 11:18:46.487 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:46.490 | INFO     | src.policies:train:103 - Epoch 722 / 800\n",
      "2021-08-25 11:18:46.491 | INFO     | src.policies:train:109 - Episode 2072\n",
      "2021-08-25 11:18:46.562 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:46.563 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:46.565 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 190.17\n",
      "2021-08-25 11:18:46.571 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:46.575 | INFO     | src.policies:train:103 - Epoch 723 / 800\n",
      "2021-08-25 11:18:46.576 | INFO     | src.policies:train:109 - Episode 2073\n",
      "2021-08-25 11:18:46.647 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:46.649 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:46.650 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 190.17\n",
      "2021-08-25 11:18:46.657 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:46.660 | INFO     | src.policies:train:103 - Epoch 724 / 800\n",
      "2021-08-25 11:18:46.661 | INFO     | src.policies:train:109 - Episode 2074\n",
      "2021-08-25 11:18:46.730 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:46.732 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:46.733 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 190.84\n",
      "2021-08-25 11:18:46.738 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:46.741 | INFO     | src.policies:train:103 - Epoch 725 / 800\n",
      "2021-08-25 11:18:46.742 | INFO     | src.policies:train:109 - Episode 2075\n",
      "2021-08-25 11:18:46.810 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:46.812 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:46.813 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 191.6\n",
      "2021-08-25 11:18:46.818 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:46.821 | INFO     | src.policies:train:103 - Epoch 726 / 800\n",
      "2021-08-25 11:18:46.822 | INFO     | src.policies:train:109 - Episode 2076\n",
      "2021-08-25 11:18:46.890 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:46.892 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:46.893 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 191.71\n",
      "2021-08-25 11:18:46.899 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:46.901 | INFO     | src.policies:train:103 - Epoch 727 / 800\n",
      "2021-08-25 11:18:46.902 | INFO     | src.policies:train:109 - Episode 2077\n",
      "2021-08-25 11:18:46.972 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:46.973 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:46.974 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 192.23\n",
      "2021-08-25 11:18:46.979 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:46.982 | INFO     | src.policies:train:103 - Epoch 728 / 800\n",
      "2021-08-25 11:18:46.983 | INFO     | src.policies:train:109 - Episode 2078\n",
      "2021-08-25 11:18:47.052 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:47.053 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:47.054 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 192.23\n",
      "2021-08-25 11:18:47.060 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:47.063 | INFO     | src.policies:train:103 - Epoch 729 / 800\n",
      "2021-08-25 11:18:47.063 | INFO     | src.policies:train:109 - Episode 2079\n",
      "2021-08-25 11:18:47.132 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:47.134 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:47.135 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 192.72\n",
      "2021-08-25 11:18:47.140 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:47.143 | INFO     | src.policies:train:103 - Epoch 730 / 800\n",
      "2021-08-25 11:18:47.144 | INFO     | src.policies:train:109 - Episode 2080\n",
      "2021-08-25 11:18:47.217 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:47.218 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:47.219 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 192.72\n",
      "2021-08-25 11:18:47.224 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:47.227 | INFO     | src.policies:train:103 - Epoch 731 / 800\n",
      "2021-08-25 11:18:47.228 | INFO     | src.policies:train:109 - Episode 2081\n",
      "2021-08-25 11:18:47.299 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:47.301 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:47.302 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 193.1\n",
      "2021-08-25 11:18:47.307 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:47.310 | INFO     | src.policies:train:103 - Epoch 732 / 800\n",
      "2021-08-25 11:18:47.311 | INFO     | src.policies:train:109 - Episode 2082\n",
      "2021-08-25 11:18:47.381 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:47.383 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:47.384 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 193.17\n",
      "2021-08-25 11:18:47.389 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:47.392 | INFO     | src.policies:train:103 - Epoch 733 / 800\n",
      "2021-08-25 11:18:47.393 | INFO     | src.policies:train:109 - Episode 2083\n",
      "2021-08-25 11:18:47.464 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:47.465 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:47.466 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 193.79\n",
      "2021-08-25 11:18:47.473 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:47.476 | INFO     | src.policies:train:103 - Epoch 734 / 800\n",
      "2021-08-25 11:18:47.477 | INFO     | src.policies:train:109 - Episode 2084\n",
      "2021-08-25 11:18:47.548 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:47.549 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:47.550 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 193.79\n",
      "2021-08-25 11:18:47.556 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:18:47.559 | INFO     | src.policies:train:103 - Epoch 735 / 800\n",
      "2021-08-25 11:18:47.560 | INFO     | src.policies:train:109 - Episode 2085\n",
      "2021-08-25 11:18:47.620 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:47.621 | INFO     | src.policies:train:121 - Mean episode return: 165.0\n",
      "2021-08-25 11:18:47.622 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 193.5\n",
      "2021-08-25 11:18:47.623 | INFO     | src.policies:train:109 - Episode 2086\n",
      "2021-08-25 11:18:47.695 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:47.696 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:47.697 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 194.92\n",
      "2021-08-25 11:18:47.698 | WARNING  | src.policies:train:131 - The actual batch size is 365, instead of 200\n",
      "2021-08-25 11:18:47.706 | INFO     | src.policies:train:157 - Total loss: 0.9972601532936096\n",
      "2021-08-25 11:18:47.709 | INFO     | src.policies:train:103 - Epoch 736 / 800\n",
      "2021-08-25 11:18:47.710 | INFO     | src.policies:train:109 - Episode 2087\n",
      "2021-08-25 11:18:47.781 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:47.783 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:47.784 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 195.26\n",
      "2021-08-25 11:18:47.789 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:47.792 | INFO     | src.policies:train:103 - Epoch 737 / 800\n",
      "2021-08-25 11:18:47.793 | INFO     | src.policies:train:109 - Episode 2088\n",
      "2021-08-25 11:18:47.864 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:47.866 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:47.867 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 195.3\n",
      "2021-08-25 11:18:47.872 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:47.875 | INFO     | src.policies:train:103 - Epoch 738 / 800\n",
      "2021-08-25 11:18:47.876 | INFO     | src.policies:train:109 - Episode 2089\n",
      "2021-08-25 11:18:47.946 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:47.948 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:47.949 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 195.96\n",
      "2021-08-25 11:18:47.954 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:47.957 | INFO     | src.policies:train:103 - Epoch 739 / 800\n",
      "2021-08-25 11:18:47.958 | INFO     | src.policies:train:109 - Episode 2090\n",
      "2021-08-25 11:18:48.028 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:48.030 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:48.031 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 196.19\n",
      "2021-08-25 11:18:48.035 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:48.038 | INFO     | src.policies:train:103 - Epoch 740 / 800\n",
      "2021-08-25 11:18:48.039 | INFO     | src.policies:train:109 - Episode 2091\n",
      "2021-08-25 11:18:48.105 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:48.107 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:48.108 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 196.19\n",
      "2021-08-25 11:18:48.113 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:48.115 | INFO     | src.policies:train:103 - Epoch 741 / 800\n",
      "2021-08-25 11:18:48.116 | INFO     | src.policies:train:109 - Episode 2092\n",
      "2021-08-25 11:18:48.178 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:48.180 | INFO     | src.policies:train:121 - Mean episode return: 176.0\n",
      "2021-08-25 11:18:48.180 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 196.38\n",
      "2021-08-25 11:18:48.181 | INFO     | src.policies:train:109 - Episode 2093\n",
      "2021-08-25 11:18:48.253 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:48.254 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:48.255 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 196.45\n",
      "2021-08-25 11:18:48.256 | WARNING  | src.policies:train:131 - The actual batch size is 376, instead of 200\n",
      "2021-08-25 11:18:48.262 | INFO     | src.policies:train:157 - Total loss: 0.9973403215408325\n",
      "2021-08-25 11:18:48.264 | INFO     | src.policies:train:103 - Epoch 742 / 800\n",
      "2021-08-25 11:18:48.265 | INFO     | src.policies:train:109 - Episode 2094\n",
      "2021-08-25 11:18:48.332 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:48.334 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:48.335 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 196.52\n",
      "2021-08-25 11:18:48.339 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:48.342 | INFO     | src.policies:train:103 - Epoch 743 / 800\n",
      "2021-08-25 11:18:48.343 | INFO     | src.policies:train:109 - Episode 2095\n",
      "2021-08-25 11:18:48.411 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:48.412 | INFO     | src.policies:train:121 - Mean episode return: 199.0\n",
      "2021-08-25 11:18:48.413 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 197.34\n",
      "2021-08-25 11:18:48.414 | INFO     | src.policies:train:109 - Episode 2096\n",
      "2021-08-25 11:18:48.485 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:48.486 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:48.487 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 197.87\n",
      "2021-08-25 11:18:48.488 | WARNING  | src.policies:train:131 - The actual batch size is 399, instead of 200\n",
      "2021-08-25 11:18:48.494 | INFO     | src.policies:train:157 - Total loss: 0.9974936246871948\n",
      "2021-08-25 11:18:48.497 | INFO     | src.policies:train:103 - Epoch 744 / 800\n",
      "2021-08-25 11:18:48.498 | INFO     | src.policies:train:109 - Episode 2097\n",
      "2021-08-25 11:18:48.554 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:48.555 | INFO     | src.policies:train:121 - Mean episode return: 163.0\n",
      "2021-08-25 11:18:48.556 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 197.5\n",
      "2021-08-25 11:18:48.557 | INFO     | src.policies:train:109 - Episode 2098\n",
      "2021-08-25 11:18:48.625 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:48.626 | INFO     | src.policies:train:121 - Mean episode return: 196.0\n",
      "2021-08-25 11:18:48.627 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 197.48\n",
      "2021-08-25 11:18:48.628 | WARNING  | src.policies:train:131 - The actual batch size is 359, instead of 200\n",
      "2021-08-25 11:18:48.634 | INFO     | src.policies:train:157 - Total loss: 0.9972142577171326\n",
      "2021-08-25 11:18:48.637 | INFO     | src.policies:train:103 - Epoch 745 / 800\n",
      "2021-08-25 11:18:48.638 | INFO     | src.policies:train:109 - Episode 2099\n",
      "2021-08-25 11:18:48.707 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:48.708 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:48.709 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 197.48\n",
      "2021-08-25 11:18:48.715 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:48.717 | INFO     | src.policies:train:103 - Epoch 746 / 800\n",
      "2021-08-25 11:18:48.718 | INFO     | src.policies:train:109 - Episode 2100\n",
      "2021-08-25 11:18:48.786 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:48.788 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:48.788 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 198.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:18:48.793 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:48.796 | INFO     | src.policies:train:103 - Epoch 747 / 800\n",
      "2021-08-25 11:18:48.797 | INFO     | src.policies:train:109 - Episode 2101\n",
      "2021-08-25 11:18:48.864 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:48.866 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:48.867 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 198.06\n",
      "2021-08-25 11:18:48.872 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:48.875 | INFO     | src.policies:train:103 - Epoch 748 / 800\n",
      "2021-08-25 11:18:48.876 | INFO     | src.policies:train:109 - Episode 2102\n",
      "2021-08-25 11:18:48.928 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:48.929 | INFO     | src.policies:train:121 - Mean episode return: 150.0\n",
      "2021-08-25 11:18:48.930 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 197.56\n",
      "2021-08-25 11:18:48.931 | INFO     | src.policies:train:109 - Episode 2103\n",
      "2021-08-25 11:18:48.948 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:48.949 | INFO     | src.policies:train:121 - Mean episode return: 41.0\n",
      "2021-08-25 11:18:48.949 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 195.97\n",
      "2021-08-25 11:18:48.950 | INFO     | src.policies:train:109 - Episode 2104\n",
      "2021-08-25 11:18:49.020 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:49.021 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:49.023 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 195.97\n",
      "2021-08-25 11:18:49.023 | WARNING  | src.policies:train:131 - The actual batch size is 391, instead of 200\n",
      "2021-08-25 11:18:49.029 | INFO     | src.policies:train:157 - Total loss: 0.997442364692688\n",
      "2021-08-25 11:18:49.032 | INFO     | src.policies:train:103 - Epoch 749 / 800\n",
      "2021-08-25 11:18:49.033 | INFO     | src.policies:train:109 - Episode 2105\n",
      "2021-08-25 11:18:49.101 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:49.102 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:49.103 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 196.19\n",
      "2021-08-25 11:18:49.108 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:49.111 | INFO     | src.policies:train:103 - Epoch 750 / 800\n",
      "2021-08-25 11:18:49.112 | INFO     | src.policies:train:109 - Episode 2106\n",
      "2021-08-25 11:18:49.179 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:49.180 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:49.181 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 196.19\n",
      "2021-08-25 11:18:49.186 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:49.188 | INFO     | src.policies:train:103 - Epoch 751 / 800\n",
      "2021-08-25 11:18:49.189 | INFO     | src.policies:train:109 - Episode 2107\n",
      "2021-08-25 11:18:49.258 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:49.260 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:49.261 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 196.47\n",
      "2021-08-25 11:18:49.265 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:49.268 | INFO     | src.policies:train:103 - Epoch 752 / 800\n",
      "2021-08-25 11:18:49.268 | INFO     | src.policies:train:109 - Episode 2108\n",
      "2021-08-25 11:18:49.337 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:49.339 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:49.339 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 196.47\n",
      "2021-08-25 11:18:49.344 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:49.347 | INFO     | src.policies:train:103 - Epoch 753 / 800\n",
      "2021-08-25 11:18:49.347 | INFO     | src.policies:train:109 - Episode 2109\n",
      "2021-08-25 11:18:49.414 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:49.415 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:49.416 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 196.74\n",
      "2021-08-25 11:18:49.421 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:49.423 | INFO     | src.policies:train:103 - Epoch 754 / 800\n",
      "2021-08-25 11:18:49.424 | INFO     | src.policies:train:109 - Episode 2110\n",
      "2021-08-25 11:18:49.492 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:49.494 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:49.495 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 196.74\n",
      "2021-08-25 11:18:49.500 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:49.502 | INFO     | src.policies:train:103 - Epoch 755 / 800\n",
      "2021-08-25 11:18:49.503 | INFO     | src.policies:train:109 - Episode 2111\n",
      "2021-08-25 11:18:49.571 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:49.573 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:49.574 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 196.74\n",
      "2021-08-25 11:18:49.578 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:49.581 | INFO     | src.policies:train:103 - Epoch 756 / 800\n",
      "2021-08-25 11:18:49.581 | INFO     | src.policies:train:109 - Episode 2112\n",
      "2021-08-25 11:18:49.649 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:49.651 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:49.652 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 196.74\n",
      "2021-08-25 11:18:49.657 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:49.659 | INFO     | src.policies:train:103 - Epoch 757 / 800\n",
      "2021-08-25 11:18:49.660 | INFO     | src.policies:train:109 - Episode 2113\n",
      "2021-08-25 11:18:49.728 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:49.730 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:49.731 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 196.74\n",
      "2021-08-25 11:18:49.736 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:49.739 | INFO     | src.policies:train:103 - Epoch 758 / 800\n",
      "2021-08-25 11:18:49.739 | INFO     | src.policies:train:109 - Episode 2114\n",
      "2021-08-25 11:18:49.808 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:49.810 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:49.811 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 196.77\n",
      "2021-08-25 11:18:49.816 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:49.818 | INFO     | src.policies:train:103 - Epoch 759 / 800\n",
      "2021-08-25 11:18:49.819 | INFO     | src.policies:train:109 - Episode 2115\n",
      "2021-08-25 11:18:49.884 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:49.885 | INFO     | src.policies:train:121 - Mean episode return: 190.0\n",
      "2021-08-25 11:18:49.886 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 196.67\n",
      "2021-08-25 11:18:49.887 | INFO     | src.policies:train:109 - Episode 2116\n",
      "2021-08-25 11:18:49.958 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:49.959 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:49.960 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 196.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:18:49.961 | WARNING  | src.policies:train:131 - The actual batch size is 390, instead of 200\n",
      "2021-08-25 11:18:49.967 | INFO     | src.policies:train:157 - Total loss: 0.9974357485771179\n",
      "2021-08-25 11:18:49.970 | INFO     | src.policies:train:103 - Epoch 760 / 800\n",
      "2021-08-25 11:18:49.971 | INFO     | src.policies:train:109 - Episode 2117\n",
      "2021-08-25 11:18:50.041 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:50.042 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:50.043 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 196.67\n",
      "2021-08-25 11:18:50.048 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:50.050 | INFO     | src.policies:train:103 - Epoch 761 / 800\n",
      "2021-08-25 11:18:50.051 | INFO     | src.policies:train:109 - Episode 2118\n",
      "2021-08-25 11:18:50.121 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:50.123 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:50.124 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 196.67\n",
      "2021-08-25 11:18:50.129 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:50.131 | INFO     | src.policies:train:103 - Epoch 762 / 800\n",
      "2021-08-25 11:18:50.132 | INFO     | src.policies:train:109 - Episode 2119\n",
      "2021-08-25 11:18:50.201 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:50.202 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:50.203 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 196.67\n",
      "2021-08-25 11:18:50.208 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:50.211 | INFO     | src.policies:train:103 - Epoch 763 / 800\n",
      "2021-08-25 11:18:50.212 | INFO     | src.policies:train:109 - Episode 2120\n",
      "2021-08-25 11:18:50.279 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:50.281 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:50.282 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 196.67\n",
      "2021-08-25 11:18:50.287 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:50.289 | INFO     | src.policies:train:103 - Epoch 764 / 800\n",
      "2021-08-25 11:18:50.290 | INFO     | src.policies:train:109 - Episode 2121\n",
      "2021-08-25 11:18:50.358 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:50.359 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:50.360 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 196.67\n",
      "2021-08-25 11:18:50.365 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:50.368 | INFO     | src.policies:train:103 - Epoch 765 / 800\n",
      "2021-08-25 11:18:50.369 | INFO     | src.policies:train:109 - Episode 2122\n",
      "2021-08-25 11:18:50.436 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:50.437 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:50.438 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 196.67\n",
      "2021-08-25 11:18:50.443 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:50.445 | INFO     | src.policies:train:103 - Epoch 766 / 800\n",
      "2021-08-25 11:18:50.446 | INFO     | src.policies:train:109 - Episode 2123\n",
      "2021-08-25 11:18:50.512 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:50.513 | INFO     | src.policies:train:121 - Mean episode return: 193.0\n",
      "2021-08-25 11:18:50.514 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 196.6\n",
      "2021-08-25 11:18:50.515 | INFO     | src.policies:train:109 - Episode 2124\n",
      "2021-08-25 11:18:50.583 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:50.584 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:50.585 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 196.6\n",
      "2021-08-25 11:18:50.586 | WARNING  | src.policies:train:131 - The actual batch size is 393, instead of 200\n",
      "2021-08-25 11:18:50.592 | INFO     | src.policies:train:157 - Total loss: 0.9974552392959595\n",
      "2021-08-25 11:18:50.595 | INFO     | src.policies:train:103 - Epoch 767 / 800\n",
      "2021-08-25 11:18:50.596 | INFO     | src.policies:train:109 - Episode 2125\n",
      "2021-08-25 11:18:50.666 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:50.667 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:50.668 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 196.6\n",
      "2021-08-25 11:18:50.673 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:50.676 | INFO     | src.policies:train:103 - Epoch 768 / 800\n",
      "2021-08-25 11:18:50.677 | INFO     | src.policies:train:109 - Episode 2126\n",
      "2021-08-25 11:18:50.746 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:50.747 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:50.748 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 196.6\n",
      "2021-08-25 11:18:50.753 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:50.756 | INFO     | src.policies:train:103 - Epoch 769 / 800\n",
      "2021-08-25 11:18:50.757 | INFO     | src.policies:train:109 - Episode 2127\n",
      "2021-08-25 11:18:50.825 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:50.827 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:50.828 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 196.6\n",
      "2021-08-25 11:18:50.833 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:50.836 | INFO     | src.policies:train:103 - Epoch 770 / 800\n",
      "2021-08-25 11:18:50.836 | INFO     | src.policies:train:109 - Episode 2128\n",
      "2021-08-25 11:18:50.904 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:50.906 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:50.907 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 196.6\n",
      "2021-08-25 11:18:50.912 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:50.914 | INFO     | src.policies:train:103 - Epoch 771 / 800\n",
      "2021-08-25 11:18:50.915 | INFO     | src.policies:train:109 - Episode 2129\n",
      "2021-08-25 11:18:50.983 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:50.984 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:50.985 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 196.6\n",
      "2021-08-25 11:18:50.990 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:50.992 | INFO     | src.policies:train:103 - Epoch 772 / 800\n",
      "2021-08-25 11:18:50.993 | INFO     | src.policies:train:109 - Episode 2130\n",
      "2021-08-25 11:18:51.061 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:51.063 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:51.064 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 196.6\n",
      "2021-08-25 11:18:51.068 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:51.071 | INFO     | src.policies:train:103 - Epoch 773 / 800\n",
      "2021-08-25 11:18:51.071 | INFO     | src.policies:train:109 - Episode 2131\n",
      "2021-08-25 11:18:51.138 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:51.140 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:51.141 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 196.6\n",
      "2021-08-25 11:18:51.146 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:18:51.148 | INFO     | src.policies:train:103 - Epoch 774 / 800\n",
      "2021-08-25 11:18:51.149 | INFO     | src.policies:train:109 - Episode 2132\n",
      "2021-08-25 11:18:51.218 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:51.219 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:51.221 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 196.6\n",
      "2021-08-25 11:18:51.226 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:51.229 | INFO     | src.policies:train:103 - Epoch 775 / 800\n",
      "2021-08-25 11:18:51.229 | INFO     | src.policies:train:109 - Episode 2133\n",
      "2021-08-25 11:18:51.297 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:51.299 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:51.300 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 196.6\n",
      "2021-08-25 11:18:51.305 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:51.308 | INFO     | src.policies:train:103 - Epoch 776 / 800\n",
      "2021-08-25 11:18:51.308 | INFO     | src.policies:train:109 - Episode 2134\n",
      "2021-08-25 11:18:51.375 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:51.376 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:51.377 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 196.6\n",
      "2021-08-25 11:18:51.382 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:51.384 | INFO     | src.policies:train:103 - Epoch 777 / 800\n",
      "2021-08-25 11:18:51.385 | INFO     | src.policies:train:109 - Episode 2135\n",
      "2021-08-25 11:18:51.452 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:51.454 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:51.455 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 196.6\n",
      "2021-08-25 11:18:51.460 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:51.463 | INFO     | src.policies:train:103 - Epoch 778 / 800\n",
      "2021-08-25 11:18:51.463 | INFO     | src.policies:train:109 - Episode 2136\n",
      "2021-08-25 11:18:51.531 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:51.533 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:51.534 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 196.6\n",
      "2021-08-25 11:18:51.538 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:51.541 | INFO     | src.policies:train:103 - Epoch 779 / 800\n",
      "2021-08-25 11:18:51.541 | INFO     | src.policies:train:109 - Episode 2137\n",
      "2021-08-25 11:18:51.607 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:51.608 | INFO     | src.policies:train:121 - Mean episode return: 191.0\n",
      "2021-08-25 11:18:51.609 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 196.51\n",
      "2021-08-25 11:18:51.610 | INFO     | src.policies:train:109 - Episode 2138\n",
      "2021-08-25 11:18:51.678 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:51.679 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:51.680 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 196.51\n",
      "2021-08-25 11:18:51.681 | WARNING  | src.policies:train:131 - The actual batch size is 391, instead of 200\n",
      "2021-08-25 11:18:51.687 | INFO     | src.policies:train:157 - Total loss: 0.997442364692688\n",
      "2021-08-25 11:18:51.690 | INFO     | src.policies:train:103 - Epoch 780 / 800\n",
      "2021-08-25 11:18:51.691 | INFO     | src.policies:train:109 - Episode 2139\n",
      "2021-08-25 11:18:51.760 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:51.761 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:51.762 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 196.51\n",
      "2021-08-25 11:18:51.767 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:51.769 | INFO     | src.policies:train:103 - Epoch 781 / 800\n",
      "2021-08-25 11:18:51.770 | INFO     | src.policies:train:109 - Episode 2140\n",
      "2021-08-25 11:18:51.837 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:51.839 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:51.840 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 196.51\n",
      "2021-08-25 11:18:51.844 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:51.847 | INFO     | src.policies:train:103 - Epoch 782 / 800\n",
      "2021-08-25 11:18:51.848 | INFO     | src.policies:train:109 - Episode 2141\n",
      "2021-08-25 11:18:51.916 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:51.918 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:51.919 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 196.59\n",
      "2021-08-25 11:18:51.923 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:51.926 | INFO     | src.policies:train:103 - Epoch 783 / 800\n",
      "2021-08-25 11:18:51.927 | INFO     | src.policies:train:109 - Episode 2142\n",
      "2021-08-25 11:18:51.995 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:51.996 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:51.997 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 196.59\n",
      "2021-08-25 11:18:52.002 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:52.005 | INFO     | src.policies:train:103 - Epoch 784 / 800\n",
      "2021-08-25 11:18:52.005 | INFO     | src.policies:train:109 - Episode 2143\n",
      "2021-08-25 11:18:52.074 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:52.076 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:52.077 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 196.59\n",
      "2021-08-25 11:18:52.081 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:52.084 | INFO     | src.policies:train:103 - Epoch 785 / 800\n",
      "2021-08-25 11:18:52.085 | INFO     | src.policies:train:109 - Episode 2144\n",
      "2021-08-25 11:18:52.151 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:52.153 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:52.154 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 196.59\n",
      "2021-08-25 11:18:52.158 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:52.161 | INFO     | src.policies:train:103 - Epoch 786 / 800\n",
      "2021-08-25 11:18:52.162 | INFO     | src.policies:train:109 - Episode 2145\n",
      "2021-08-25 11:18:52.229 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:52.231 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:52.232 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 196.59\n",
      "2021-08-25 11:18:52.236 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:52.238 | INFO     | src.policies:train:103 - Epoch 787 / 800\n",
      "2021-08-25 11:18:52.239 | INFO     | src.policies:train:109 - Episode 2146\n",
      "2021-08-25 11:18:52.306 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:52.308 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:52.309 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 196.59\n",
      "2021-08-25 11:18:52.313 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:52.316 | INFO     | src.policies:train:103 - Epoch 788 / 800\n",
      "2021-08-25 11:18:52.317 | INFO     | src.policies:train:109 - Episode 2147\n",
      "2021-08-25 11:18:52.384 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:18:52.385 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:52.386 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 196.59\n",
      "2021-08-25 11:18:52.392 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:52.394 | INFO     | src.policies:train:103 - Epoch 789 / 800\n",
      "2021-08-25 11:18:52.395 | INFO     | src.policies:train:109 - Episode 2148\n",
      "2021-08-25 11:18:52.463 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:52.465 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:52.466 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 196.59\n",
      "2021-08-25 11:18:52.470 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:52.473 | INFO     | src.policies:train:103 - Epoch 790 / 800\n",
      "2021-08-25 11:18:52.474 | INFO     | src.policies:train:109 - Episode 2149\n",
      "2021-08-25 11:18:52.542 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:52.544 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:52.545 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 196.59\n",
      "2021-08-25 11:18:52.550 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:52.552 | INFO     | src.policies:train:103 - Epoch 791 / 800\n",
      "2021-08-25 11:18:52.553 | INFO     | src.policies:train:109 - Episode 2150\n",
      "2021-08-25 11:18:52.620 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:52.622 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:52.623 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 196.59\n",
      "2021-08-25 11:18:52.628 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:52.630 | INFO     | src.policies:train:103 - Epoch 792 / 800\n",
      "2021-08-25 11:18:52.631 | INFO     | src.policies:train:109 - Episode 2151\n",
      "2021-08-25 11:18:52.698 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:52.700 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:52.701 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 196.64\n",
      "2021-08-25 11:18:52.705 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:52.708 | INFO     | src.policies:train:103 - Epoch 793 / 800\n",
      "2021-08-25 11:18:52.709 | INFO     | src.policies:train:109 - Episode 2152\n",
      "2021-08-25 11:18:52.776 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:52.778 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:52.779 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 196.64\n",
      "2021-08-25 11:18:52.784 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:52.786 | INFO     | src.policies:train:103 - Epoch 794 / 800\n",
      "2021-08-25 11:18:52.787 | INFO     | src.policies:train:109 - Episode 2153\n",
      "2021-08-25 11:18:52.854 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:52.856 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:52.857 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 196.64\n",
      "2021-08-25 11:18:52.862 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:52.864 | INFO     | src.policies:train:103 - Epoch 795 / 800\n",
      "2021-08-25 11:18:52.865 | INFO     | src.policies:train:109 - Episode 2154\n",
      "2021-08-25 11:18:52.935 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:52.937 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:52.938 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 196.64\n",
      "2021-08-25 11:18:52.942 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:52.945 | INFO     | src.policies:train:103 - Epoch 796 / 800\n",
      "2021-08-25 11:18:52.945 | INFO     | src.policies:train:109 - Episode 2155\n",
      "2021-08-25 11:18:53.013 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:53.015 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:53.016 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 196.64\n",
      "2021-08-25 11:18:53.020 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:53.023 | INFO     | src.policies:train:103 - Epoch 797 / 800\n",
      "2021-08-25 11:18:53.024 | INFO     | src.policies:train:109 - Episode 2156\n",
      "2021-08-25 11:18:53.094 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:53.095 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:53.096 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 196.64\n",
      "2021-08-25 11:18:53.101 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:53.104 | INFO     | src.policies:train:103 - Epoch 798 / 800\n",
      "2021-08-25 11:18:53.105 | INFO     | src.policies:train:109 - Episode 2157\n",
      "2021-08-25 11:18:53.176 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:53.177 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:53.178 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 196.64\n",
      "2021-08-25 11:18:53.183 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:53.185 | INFO     | src.policies:train:103 - Epoch 799 / 800\n",
      "2021-08-25 11:18:53.186 | INFO     | src.policies:train:109 - Episode 2158\n",
      "2021-08-25 11:18:53.254 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:53.255 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:53.256 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 196.64\n",
      "2021-08-25 11:18:53.261 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n",
      "2021-08-25 11:18:53.264 | INFO     | src.policies:train:103 - Epoch 800 / 800\n",
      "2021-08-25 11:18:53.264 | INFO     | src.policies:train:109 - Episode 2159\n",
      "2021-08-25 11:18:53.333 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:18:53.335 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:18:53.336 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 196.64\n",
      "2021-08-25 11:18:53.341 | INFO     | src.policies:train:157 - Total loss: 0.9949999451637268\n"
     ]
    }
   ],
   "source": [
    "trpo_policy_nn = models.MLP(observation_space_size, hidden_sizes, action_space_size)\n",
    "trpo_baseline_nn = models.MLP(observation_space_size, hidden_sizes, 1, log_softmax=False)\n",
    "trpo_policy = policies.TRPOPolicy(env, trpo_policy_nn, trpo_baseline_nn, beta=beta, kl_target=kl_target)\n",
    "trpo_policy.train(\n",
    "    epochs,\n",
    "    steps_per_epoch,\n",
    "    enable_wandb=False,\n",
    "    episodes_mean_reward=episodes_mean_reward\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34632f1f",
   "metadata": {},
   "source": [
    "## PPO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51893fe",
   "metadata": {},
   "source": [
    "This section deals with training a Cartpole agent using our custom Proximal Policy Optimization implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51783ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1=1.0\n",
    "c2=0.01\n",
    "eps=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4e1efc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:14.804 | INFO     | src.policies:train:103 - Epoch 1 / 800\n",
      "2021-08-25 11:21:14.805 | INFO     | src.policies:train:109 - Episode 1\n",
      "2021-08-25 11:21:14.826 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:14.828 | INFO     | src.policies:train:121 - Mean episode return: 45.0\n",
      "2021-08-25 11:21:14.829 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 45.0\n",
      "2021-08-25 11:21:14.831 | INFO     | src.policies:train:109 - Episode 2\n",
      "2021-08-25 11:21:14.841 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:14.843 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:21:14.844 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.5\n",
      "2021-08-25 11:21:14.846 | INFO     | src.policies:train:109 - Episode 3\n",
      "2021-08-25 11:21:14.856 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:14.857 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:21:14.858 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.333333333333332\n",
      "2021-08-25 11:21:14.860 | INFO     | src.policies:train:109 - Episode 4\n",
      "2021-08-25 11:21:14.879 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:14.881 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 11:21:14.882 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.5\n",
      "2021-08-25 11:21:14.882 | INFO     | src.policies:train:109 - Episode 5\n",
      "2021-08-25 11:21:14.899 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:14.900 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 11:21:14.901 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.0\n",
      "2021-08-25 11:21:14.902 | INFO     | src.policies:train:109 - Episode 6\n",
      "2021-08-25 11:21:14.924 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:14.925 | INFO     | src.policies:train:121 - Mean episode return: 41.0\n",
      "2021-08-25 11:21:14.926 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.166666666666668\n",
      "2021-08-25 11:21:14.928 | INFO     | src.policies:train:109 - Episode 7\n",
      "2021-08-25 11:21:14.939 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:14.941 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:14.942 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.285714285714285\n",
      "2021-08-25 11:21:14.944 | INFO     | src.policies:train:109 - Episode 8\n",
      "2021-08-25 11:21:14.956 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:14.958 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:21:14.959 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.0\n",
      "2021-08-25 11:21:14.961 | WARNING  | src.policies:train:131 - The actual batch size is 216, instead of 200\n",
      "2021-08-25 11:21:14.970 | INFO     | src.policies:train:157 - Total loss: 1.170069932937622\n",
      "2021-08-25 11:21:14.974 | INFO     | src.policies:train:103 - Epoch 2 / 800\n",
      "2021-08-25 11:21:14.975 | INFO     | src.policies:train:109 - Episode 9\n",
      "2021-08-25 11:21:14.984 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:14.986 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:14.987 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.77777777777778\n",
      "2021-08-25 11:21:14.989 | INFO     | src.policies:train:109 - Episode 10\n",
      "2021-08-25 11:21:15.013 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:15.015 | INFO     | src.policies:train:121 - Mean episode return: 49.0\n",
      "2021-08-25 11:21:15.016 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.1\n",
      "2021-08-25 11:21:15.018 | INFO     | src.policies:train:109 - Episode 11\n",
      "2021-08-25 11:21:15.030 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:15.031 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:21:15.032 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.818181818181817\n",
      "2021-08-25 11:21:15.034 | INFO     | src.policies:train:109 - Episode 12\n",
      "2021-08-25 11:21:15.047 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:15.048 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:15.049 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.0\n",
      "2021-08-25 11:21:15.050 | INFO     | src.policies:train:109 - Episode 13\n",
      "2021-08-25 11:21:15.070 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:15.072 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 11:21:15.073 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.76923076923077\n",
      "2021-08-25 11:21:15.074 | INFO     | src.policies:train:109 - Episode 14\n",
      "2021-08-25 11:21:15.086 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:15.088 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:15.089 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.928571428571427\n",
      "2021-08-25 11:21:15.091 | INFO     | src.policies:train:109 - Episode 15\n",
      "2021-08-25 11:21:15.115 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:15.116 | INFO     | src.policies:train:121 - Mean episode return: 45.0\n",
      "2021-08-25 11:21:15.117 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.2\n",
      "2021-08-25 11:21:15.118 | INFO     | src.policies:train:109 - Episode 16\n",
      "2021-08-25 11:21:15.137 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:15.139 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 11:21:15.140 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.5\n",
      "2021-08-25 11:21:15.141 | WARNING  | src.policies:train:131 - The actual batch size is 224, instead of 200\n",
      "2021-08-25 11:21:15.150 | INFO     | src.policies:train:157 - Total loss: 1.2263513803482056\n",
      "2021-08-25 11:21:15.154 | INFO     | src.policies:train:103 - Epoch 3 / 800\n",
      "2021-08-25 11:21:15.155 | INFO     | src.policies:train:109 - Episode 17\n",
      "2021-08-25 11:21:15.175 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:15.176 | INFO     | src.policies:train:121 - Mean episode return: 43.0\n",
      "2021-08-25 11:21:15.177 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.41176470588235\n",
      "2021-08-25 11:21:15.178 | INFO     | src.policies:train:109 - Episode 18\n",
      "2021-08-25 11:21:15.192 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:15.193 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:21:15.195 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.055555555555557\n",
      "2021-08-25 11:21:15.196 | INFO     | src.policies:train:109 - Episode 19\n",
      "2021-08-25 11:21:15.207 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:15.208 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:15.209 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.473684210526315\n",
      "2021-08-25 11:21:15.210 | INFO     | src.policies:train:109 - Episode 20\n",
      "2021-08-25 11:21:15.222 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:15.223 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:21:15.224 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.0\n",
      "2021-08-25 11:21:15.225 | INFO     | src.policies:train:109 - Episode 21\n",
      "2021-08-25 11:21:15.235 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:15.236 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:15.237 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.38095238095238\n",
      "2021-08-25 11:21:15.238 | INFO     | src.policies:train:109 - Episode 22\n",
      "2021-08-25 11:21:15.250 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:15.252 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:21:15.253 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.136363636363637\n",
      "2021-08-25 11:21:15.254 | INFO     | src.policies:train:109 - Episode 23\n",
      "2021-08-25 11:21:15.264 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:15.265 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:15.266 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.73913043478261\n",
      "2021-08-25 11:21:15.267 | INFO     | src.policies:train:109 - Episode 24\n",
      "2021-08-25 11:21:15.275 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:15.276 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:21:15.277 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.125\n",
      "2021-08-25 11:21:15.279 | INFO     | src.policies:train:109 - Episode 25\n",
      "2021-08-25 11:21:15.286 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:15.288 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:21:15.289 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.56\n",
      "2021-08-25 11:21:15.290 | INFO     | src.policies:train:109 - Episode 26\n",
      "2021-08-25 11:21:15.304 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:15.305 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 11:21:15.306 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.653846153846153\n",
      "2021-08-25 11:21:15.307 | WARNING  | src.policies:train:131 - The actual batch size is 201, instead of 200\n",
      "2021-08-25 11:21:15.318 | INFO     | src.policies:train:157 - Total loss: 1.1252681016921997\n",
      "2021-08-25 11:21:15.321 | INFO     | src.policies:train:103 - Epoch 4 / 800\n",
      "2021-08-25 11:21:15.323 | INFO     | src.policies:train:109 - Episode 27\n",
      "2021-08-25 11:21:15.338 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:15.339 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 11:21:15.340 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.0\n",
      "2021-08-25 11:21:15.341 | INFO     | src.policies:train:109 - Episode 28\n",
      "2021-08-25 11:21:15.354 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:15.355 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:21:15.356 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.928571428571427\n",
      "2021-08-25 11:21:15.357 | INFO     | src.policies:train:109 - Episode 29\n",
      "2021-08-25 11:21:15.365 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:15.366 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:21:15.367 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.448275862068964\n",
      "2021-08-25 11:21:15.368 | INFO     | src.policies:train:109 - Episode 30\n",
      "2021-08-25 11:21:15.377 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:15.378 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:21:15.379 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.1\n",
      "2021-08-25 11:21:15.380 | INFO     | src.policies:train:109 - Episode 31\n",
      "2021-08-25 11:21:15.392 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:15.393 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:21:15.394 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.06451612903226\n",
      "2021-08-25 11:21:15.395 | INFO     | src.policies:train:109 - Episode 32\n",
      "2021-08-25 11:21:15.406 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:15.407 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:21:15.408 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.875\n",
      "2021-08-25 11:21:15.409 | INFO     | src.policies:train:109 - Episode 33\n",
      "2021-08-25 11:21:15.421 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:15.422 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:21:15.423 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.78787878787879\n",
      "2021-08-25 11:21:15.424 | INFO     | src.policies:train:109 - Episode 34\n",
      "2021-08-25 11:21:15.433 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:15.434 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:21:15.435 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.5\n",
      "2021-08-25 11:21:15.436 | INFO     | src.policies:train:109 - Episode 35\n",
      "2021-08-25 11:21:15.445 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:15.446 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:15.447 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.257142857142856\n",
      "2021-08-25 11:21:15.448 | INFO     | src.policies:train:109 - Episode 36\n",
      "2021-08-25 11:21:15.461 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:15.463 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:21:15.463 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.27777777777778\n",
      "2021-08-25 11:21:15.464 | INFO     | src.policies:train:109 - Episode 37\n",
      "2021-08-25 11:21:15.486 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:15.487 | INFO     | src.policies:train:121 - Mean episode return: 46.0\n",
      "2021-08-25 11:21:15.488 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.89189189189189\n",
      "2021-08-25 11:21:15.489 | WARNING  | src.policies:train:131 - The actual batch size is 243, instead of 200\n",
      "2021-08-25 11:21:15.497 | INFO     | src.policies:train:157 - Total loss: 1.1237733364105225\n",
      "2021-08-25 11:21:15.501 | INFO     | src.policies:train:103 - Epoch 5 / 800\n",
      "2021-08-25 11:21:15.502 | INFO     | src.policies:train:109 - Episode 38\n",
      "2021-08-25 11:21:15.514 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:15.515 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 11:21:15.516 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.92105263157895\n",
      "2021-08-25 11:21:15.517 | INFO     | src.policies:train:109 - Episode 39\n",
      "2021-08-25 11:21:15.532 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:15.533 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 11:21:15.534 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.025641025641026\n",
      "2021-08-25 11:21:15.535 | INFO     | src.policies:train:109 - Episode 40\n",
      "2021-08-25 11:21:15.545 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:15.547 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:15.547 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.825\n",
      "2021-08-25 11:21:15.548 | INFO     | src.policies:train:109 - Episode 41\n",
      "2021-08-25 11:21:15.562 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:15.563 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:21:15.564 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.829268292682926\n",
      "2021-08-25 11:21:15.565 | INFO     | src.policies:train:109 - Episode 42\n",
      "2021-08-25 11:21:15.579 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:15.580 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 11:21:15.581 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.904761904761905\n",
      "2021-08-25 11:21:15.582 | INFO     | src.policies:train:109 - Episode 43\n",
      "2021-08-25 11:21:15.591 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:15.593 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:15.594 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.697674418604652\n",
      "2021-08-25 11:21:15.595 | INFO     | src.policies:train:109 - Episode 44\n",
      "2021-08-25 11:21:15.604 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:15.605 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:15.606 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.545454545454547\n",
      "2021-08-25 11:21:15.607 | INFO     | src.policies:train:109 - Episode 45\n",
      "2021-08-25 11:21:15.624 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:15.625 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 11:21:15.626 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.733333333333334\n",
      "2021-08-25 11:21:15.627 | INFO     | src.policies:train:109 - Episode 46\n",
      "2021-08-25 11:21:15.635 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:15.636 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 11:21:15.637 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.434782608695652\n",
      "2021-08-25 11:21:15.638 | INFO     | src.policies:train:109 - Episode 47\n",
      "2021-08-25 11:21:15.653 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:15.654 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 11:21:15.655 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.574468085106382\n",
      "2021-08-25 11:21:15.656 | WARNING  | src.policies:train:131 - The actual batch size is 224, instead of 200\n",
      "2021-08-25 11:21:15.665 | INFO     | src.policies:train:157 - Total loss: 1.119150996208191\n",
      "2021-08-25 11:21:15.668 | INFO     | src.policies:train:103 - Epoch 6 / 800\n",
      "2021-08-25 11:21:15.669 | INFO     | src.policies:train:109 - Episode 48\n",
      "2021-08-25 11:21:15.681 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:15.682 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 11:21:15.683 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.604166666666668\n",
      "2021-08-25 11:21:15.684 | INFO     | src.policies:train:109 - Episode 49\n",
      "2021-08-25 11:21:15.694 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:15.695 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:21:15.696 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.489795918367346\n",
      "2021-08-25 11:21:15.697 | INFO     | src.policies:train:109 - Episode 50\n",
      "2021-08-25 11:21:15.706 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:15.707 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:15.708 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.26\n",
      "2021-08-25 11:21:15.709 | INFO     | src.policies:train:109 - Episode 51\n",
      "2021-08-25 11:21:15.719 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:15.720 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:15.721 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.098039215686274\n",
      "2021-08-25 11:21:15.722 | INFO     | src.policies:train:109 - Episode 52\n",
      "2021-08-25 11:21:15.730 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:15.732 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:15.732 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.942307692307693\n",
      "2021-08-25 11:21:15.733 | INFO     | src.policies:train:109 - Episode 53\n",
      "2021-08-25 11:21:15.751 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:15.752 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 11:21:15.753 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.150943396226417\n",
      "2021-08-25 11:21:15.754 | INFO     | src.policies:train:109 - Episode 54\n",
      "2021-08-25 11:21:15.774 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:15.775 | INFO     | src.policies:train:121 - Mean episode return: 41.0\n",
      "2021-08-25 11:21:15.776 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.48148148148148\n",
      "2021-08-25 11:21:15.777 | INFO     | src.policies:train:109 - Episode 55\n",
      "2021-08-25 11:21:15.788 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:15.789 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:21:15.791 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.381818181818183\n",
      "2021-08-25 11:21:15.792 | INFO     | src.policies:train:109 - Episode 56\n",
      "2021-08-25 11:21:15.799 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:15.801 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 11:21:15.802 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.142857142857142\n",
      "2021-08-25 11:21:15.803 | INFO     | src.policies:train:109 - Episode 57\n",
      "2021-08-25 11:21:15.814 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:15.816 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:21:15.817 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.12280701754386\n",
      "2021-08-25 11:21:15.818 | WARNING  | src.policies:train:131 - The actual batch size is 210, instead of 200\n",
      "2021-08-25 11:21:15.825 | INFO     | src.policies:train:157 - Total loss: 1.1234792470932007\n",
      "2021-08-25 11:21:15.828 | INFO     | src.policies:train:103 - Epoch 7 / 800\n",
      "2021-08-25 11:21:15.829 | INFO     | src.policies:train:109 - Episode 58\n",
      "2021-08-25 11:21:15.835 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:15.837 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 11:21:15.838 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.896551724137932\n",
      "2021-08-25 11:21:15.839 | INFO     | src.policies:train:109 - Episode 59\n",
      "2021-08-25 11:21:15.846 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:15.848 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:21:15.849 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.694915254237287\n",
      "2021-08-25 11:21:15.849 | INFO     | src.policies:train:109 - Episode 60\n",
      "2021-08-25 11:21:15.860 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:15.862 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:21:15.863 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.616666666666667\n",
      "2021-08-25 11:21:15.863 | INFO     | src.policies:train:109 - Episode 61\n",
      "2021-08-25 11:21:15.883 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:15.884 | INFO     | src.policies:train:121 - Mean episode return: 42.0\n",
      "2021-08-25 11:21:15.885 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.934426229508198\n",
      "2021-08-25 11:21:15.886 | INFO     | src.policies:train:109 - Episode 62\n",
      "2021-08-25 11:21:15.901 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:15.903 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:21:15.903 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.032258064516128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:15.904 | INFO     | src.policies:train:109 - Episode 63\n",
      "2021-08-25 11:21:15.918 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:15.919 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:21:15.920 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.07936507936508\n",
      "2021-08-25 11:21:15.921 | INFO     | src.policies:train:109 - Episode 64\n",
      "2021-08-25 11:21:15.932 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:15.933 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:21:15.934 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.0\n",
      "2021-08-25 11:21:15.935 | INFO     | src.policies:train:109 - Episode 65\n",
      "2021-08-25 11:21:15.945 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:15.946 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:15.947 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.892307692307693\n",
      "2021-08-25 11:21:15.948 | INFO     | src.policies:train:109 - Episode 66\n",
      "2021-08-25 11:21:15.957 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:15.958 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 11:21:15.959 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.696969696969695\n",
      "2021-08-25 11:21:15.960 | INFO     | src.policies:train:109 - Episode 67\n",
      "2021-08-25 11:21:15.972 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:15.974 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 11:21:15.975 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.761194029850746\n",
      "2021-08-25 11:21:15.976 | WARNING  | src.policies:train:131 - The actual batch size is 207, instead of 200\n",
      "2021-08-25 11:21:15.983 | INFO     | src.policies:train:157 - Total loss: 1.0544229745864868\n",
      "2021-08-25 11:21:15.987 | INFO     | src.policies:train:103 - Epoch 8 / 800\n",
      "2021-08-25 11:21:15.988 | INFO     | src.policies:train:109 - Episode 68\n",
      "2021-08-25 11:21:15.998 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:15.999 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:16.001 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.676470588235293\n",
      "2021-08-25 11:21:16.002 | INFO     | src.policies:train:109 - Episode 69\n",
      "2021-08-25 11:21:16.012 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:16.014 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:16.015 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.594202898550726\n",
      "2021-08-25 11:21:16.015 | INFO     | src.policies:train:109 - Episode 70\n",
      "2021-08-25 11:21:16.032 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:16.033 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 11:21:16.034 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.728571428571428\n",
      "2021-08-25 11:21:16.035 | INFO     | src.policies:train:109 - Episode 71\n",
      "2021-08-25 11:21:16.046 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:16.047 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:21:16.048 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.661971830985916\n",
      "2021-08-25 11:21:16.049 | INFO     | src.policies:train:109 - Episode 72\n",
      "2021-08-25 11:21:16.058 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:16.059 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:21:16.060 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.5\n",
      "2021-08-25 11:21:16.061 | INFO     | src.policies:train:109 - Episode 73\n",
      "2021-08-25 11:21:16.072 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:16.073 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:21:16.074 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.45205479452055\n",
      "2021-08-25 11:21:16.075 | INFO     | src.policies:train:109 - Episode 74\n",
      "2021-08-25 11:21:16.083 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:16.084 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:21:16.085 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.2972972972973\n",
      "2021-08-25 11:21:16.086 | INFO     | src.policies:train:109 - Episode 75\n",
      "2021-08-25 11:21:16.094 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:16.096 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:16.097 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.16\n",
      "2021-08-25 11:21:16.098 | INFO     | src.policies:train:109 - Episode 76\n",
      "2021-08-25 11:21:16.107 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:16.108 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:21:16.109 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.039473684210527\n",
      "2021-08-25 11:21:16.110 | INFO     | src.policies:train:109 - Episode 77\n",
      "2021-08-25 11:21:16.122 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:16.123 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:21:16.124 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.051948051948052\n",
      "2021-08-25 11:21:16.125 | INFO     | src.policies:train:109 - Episode 78\n",
      "2021-08-25 11:21:16.135 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:16.136 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:16.137 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.987179487179485\n",
      "2021-08-25 11:21:16.139 | INFO     | src.policies:train:109 - Episode 79\n",
      "2021-08-25 11:21:16.154 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:16.156 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 11:21:16.157 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.088607594936708\n",
      "2021-08-25 11:21:16.157 | WARNING  | src.policies:train:131 - The actual batch size is 220, instead of 200\n",
      "2021-08-25 11:21:16.166 | INFO     | src.policies:train:157 - Total loss: 1.049791693687439\n",
      "2021-08-25 11:21:16.169 | INFO     | src.policies:train:103 - Epoch 9 / 800\n",
      "2021-08-25 11:21:16.171 | INFO     | src.policies:train:109 - Episode 80\n",
      "2021-08-25 11:21:16.179 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:16.180 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:16.182 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.0\n",
      "2021-08-25 11:21:16.182 | INFO     | src.policies:train:109 - Episode 81\n",
      "2021-08-25 11:21:16.192 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:16.193 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:16.194 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.925925925925927\n",
      "2021-08-25 11:21:16.195 | INFO     | src.policies:train:109 - Episode 82\n",
      "2021-08-25 11:21:16.205 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:16.206 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:21:16.207 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.878048780487806\n",
      "2021-08-25 11:21:16.208 | INFO     | src.policies:train:109 - Episode 83\n",
      "2021-08-25 11:21:16.217 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:16.218 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:16.219 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.759036144578314\n",
      "2021-08-25 11:21:16.220 | INFO     | src.policies:train:109 - Episode 84\n",
      "2021-08-25 11:21:16.246 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:16.247 | INFO     | src.policies:train:121 - Mean episode return: 60.0\n",
      "2021-08-25 11:21:16.248 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.214285714285715\n",
      "2021-08-25 11:21:16.249 | INFO     | src.policies:train:109 - Episode 85\n",
      "2021-08-25 11:21:16.264 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:16.265 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 11:21:16.266 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.24705882352941\n",
      "2021-08-25 11:21:16.267 | INFO     | src.policies:train:109 - Episode 86\n",
      "2021-08-25 11:21:16.279 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:16.280 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:21:16.281 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.22093023255814\n",
      "2021-08-25 11:21:16.282 | INFO     | src.policies:train:109 - Episode 87\n",
      "2021-08-25 11:21:16.292 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:16.293 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:21:16.294 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.17241379310345\n",
      "2021-08-25 11:21:16.295 | INFO     | src.policies:train:109 - Episode 88\n",
      "2021-08-25 11:21:16.304 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:16.305 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:16.306 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.056818181818183\n",
      "2021-08-25 11:21:16.307 | INFO     | src.policies:train:109 - Episode 89\n",
      "2021-08-25 11:21:16.328 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:16.329 | INFO     | src.policies:train:121 - Mean episode return: 48.0\n",
      "2021-08-25 11:21:16.330 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.348314606741575\n",
      "2021-08-25 11:21:16.332 | WARNING  | src.policies:train:131 - The actual batch size is 244, instead of 200\n",
      "2021-08-25 11:21:16.340 | INFO     | src.policies:train:157 - Total loss: 1.050323724746704\n",
      "2021-08-25 11:21:16.343 | INFO     | src.policies:train:103 - Epoch 10 / 800\n",
      "2021-08-25 11:21:16.344 | INFO     | src.policies:train:109 - Episode 90\n",
      "2021-08-25 11:21:16.364 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:16.365 | INFO     | src.policies:train:121 - Mean episode return: 48.0\n",
      "2021-08-25 11:21:16.366 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.633333333333333\n",
      "2021-08-25 11:21:16.367 | INFO     | src.policies:train:109 - Episode 91\n",
      "2021-08-25 11:21:16.386 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:16.387 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 11:21:16.388 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.791208791208792\n",
      "2021-08-25 11:21:16.389 | INFO     | src.policies:train:109 - Episode 92\n",
      "2021-08-25 11:21:16.402 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:16.403 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:21:16.404 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.793478260869566\n",
      "2021-08-25 11:21:16.405 | INFO     | src.policies:train:109 - Episode 93\n",
      "2021-08-25 11:21:16.413 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:16.414 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:16.415 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.677419354838708\n",
      "2021-08-25 11:21:16.416 | INFO     | src.policies:train:109 - Episode 94\n",
      "2021-08-25 11:21:16.433 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:16.434 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 11:21:16.435 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.77659574468085\n",
      "2021-08-25 11:21:16.436 | INFO     | src.policies:train:109 - Episode 95\n",
      "2021-08-25 11:21:16.453 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:16.454 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 11:21:16.455 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.88421052631579\n",
      "2021-08-25 11:21:16.456 | INFO     | src.policies:train:109 - Episode 96\n",
      "2021-08-25 11:21:16.470 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:16.471 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:21:16.472 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.885416666666668\n",
      "2021-08-25 11:21:16.473 | WARNING  | src.policies:train:131 - The actual batch size is 208, instead of 200\n",
      "2021-08-25 11:21:16.480 | INFO     | src.policies:train:157 - Total loss: 1.0291539430618286\n",
      "2021-08-25 11:21:16.484 | INFO     | src.policies:train:103 - Epoch 11 / 800\n",
      "2021-08-25 11:21:16.485 | INFO     | src.policies:train:109 - Episode 97\n",
      "2021-08-25 11:21:16.496 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:16.498 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 11:21:16.499 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.90721649484536\n",
      "2021-08-25 11:21:16.500 | INFO     | src.policies:train:109 - Episode 98\n",
      "2021-08-25 11:21:16.510 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:16.511 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:21:16.513 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.857142857142858\n",
      "2021-08-25 11:21:16.513 | INFO     | src.policies:train:109 - Episode 99\n",
      "2021-08-25 11:21:16.522 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:16.523 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:16.524 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.747474747474747\n",
      "2021-08-25 11:21:16.525 | INFO     | src.policies:train:109 - Episode 100\n",
      "2021-08-25 11:21:16.534 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:16.535 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:16.536 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.64\n",
      "2021-08-25 11:21:16.537 | INFO     | src.policies:train:109 - Episode 101\n",
      "2021-08-25 11:21:16.546 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:16.547 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:21:16.548 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.32\n",
      "2021-08-25 11:21:16.549 | INFO     | src.policies:train:109 - Episode 102\n",
      "2021-08-25 11:21:16.559 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:16.560 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:16.561 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.34\n",
      "2021-08-25 11:21:16.562 | INFO     | src.policies:train:109 - Episode 103\n",
      "2021-08-25 11:21:16.572 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:16.573 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:16.574 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:16.575 | INFO     | src.policies:train:109 - Episode 104\n",
      "2021-08-25 11:21:16.586 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:16.587 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:21:16.588 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.24\n",
      "2021-08-25 11:21:16.589 | INFO     | src.policies:train:109 - Episode 105\n",
      "2021-08-25 11:21:16.598 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:16.600 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:21:16.601 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.04\n",
      "2021-08-25 11:21:16.602 | INFO     | src.policies:train:109 - Episode 106\n",
      "2021-08-25 11:21:16.610 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:16.611 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:21:16.612 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.74\n",
      "2021-08-25 11:21:16.613 | INFO     | src.policies:train:109 - Episode 107\n",
      "2021-08-25 11:21:16.622 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:16.623 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:21:16.624 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.7\n",
      "2021-08-25 11:21:16.625 | INFO     | src.policies:train:109 - Episode 108\n",
      "2021-08-25 11:21:16.637 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:16.638 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:21:16.639 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.72\n",
      "2021-08-25 11:21:16.640 | INFO     | src.policies:train:109 - Episode 109\n",
      "2021-08-25 11:21:16.650 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:16.651 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:16.652 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.73\n",
      "2021-08-25 11:21:16.653 | WARNING  | src.policies:train:131 - The actual batch size is 208, instead of 200\n",
      "2021-08-25 11:21:16.662 | INFO     | src.policies:train:157 - Total loss: 1.000012755393982\n",
      "2021-08-25 11:21:16.665 | INFO     | src.policies:train:103 - Epoch 12 / 800\n",
      "2021-08-25 11:21:16.666 | INFO     | src.policies:train:109 - Episode 110\n",
      "2021-08-25 11:21:16.677 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:16.678 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:21:16.679 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.47\n",
      "2021-08-25 11:21:16.680 | INFO     | src.policies:train:109 - Episode 111\n",
      "2021-08-25 11:21:16.689 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:16.690 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:16.691 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.49\n",
      "2021-08-25 11:21:16.692 | INFO     | src.policies:train:109 - Episode 112\n",
      "2021-08-25 11:21:16.700 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:16.701 | INFO     | src.policies:train:121 - Mean episode return: 9.0\n",
      "2021-08-25 11:21:16.702 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.41\n",
      "2021-08-25 11:21:16.703 | INFO     | src.policies:train:109 - Episode 113\n",
      "2021-08-25 11:21:16.718 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:16.719 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:21:16.720 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.34\n",
      "2021-08-25 11:21:16.721 | INFO     | src.policies:train:109 - Episode 114\n",
      "2021-08-25 11:21:16.733 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:16.734 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:21:16.735 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.43\n",
      "2021-08-25 11:21:16.736 | INFO     | src.policies:train:109 - Episode 115\n",
      "2021-08-25 11:21:16.747 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:16.748 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:16.750 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.15\n",
      "2021-08-25 11:21:16.751 | INFO     | src.policies:train:109 - Episode 116\n",
      "2021-08-25 11:21:16.778 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:16.779 | INFO     | src.policies:train:121 - Mean episode return: 61.0\n",
      "2021-08-25 11:21:16.780 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.44\n",
      "2021-08-25 11:21:16.781 | INFO     | src.policies:train:109 - Episode 117\n",
      "2021-08-25 11:21:16.791 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:16.793 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:16.793 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.16\n",
      "2021-08-25 11:21:16.795 | INFO     | src.policies:train:109 - Episode 118\n",
      "2021-08-25 11:21:16.807 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:16.808 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:21:16.809 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.14\n",
      "2021-08-25 11:21:16.810 | WARNING  | src.policies:train:131 - The actual batch size is 214, instead of 200\n",
      "2021-08-25 11:21:16.818 | INFO     | src.policies:train:157 - Total loss: 1.014222502708435\n",
      "2021-08-25 11:21:16.821 | INFO     | src.policies:train:103 - Epoch 13 / 800\n",
      "2021-08-25 11:21:16.822 | INFO     | src.policies:train:109 - Episode 119\n",
      "2021-08-25 11:21:16.834 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:16.835 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:21:16.836 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.21\n",
      "2021-08-25 11:21:16.837 | INFO     | src.policies:train:109 - Episode 120\n",
      "2021-08-25 11:21:16.849 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:16.851 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:21:16.852 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.24\n",
      "2021-08-25 11:21:16.853 | INFO     | src.policies:train:109 - Episode 121\n",
      "2021-08-25 11:21:16.864 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:16.866 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:21:16.866 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.31\n",
      "2021-08-25 11:21:16.867 | INFO     | src.policies:train:109 - Episode 122\n",
      "2021-08-25 11:21:16.877 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:16.878 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:21:16.879 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.24\n",
      "2021-08-25 11:21:16.880 | INFO     | src.policies:train:109 - Episode 123\n",
      "2021-08-25 11:21:16.895 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:16.896 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:21:16.897 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.33\n",
      "2021-08-25 11:21:16.898 | INFO     | src.policies:train:109 - Episode 124\n",
      "2021-08-25 11:21:16.909 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:16.911 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:21:16.911 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:16.912 | INFO     | src.policies:train:109 - Episode 125\n",
      "2021-08-25 11:21:16.923 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:16.925 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:16.925 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.46\n",
      "2021-08-25 11:21:16.926 | INFO     | src.policies:train:109 - Episode 126\n",
      "2021-08-25 11:21:16.937 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:16.938 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:21:16.939 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.37\n",
      "2021-08-25 11:21:16.940 | INFO     | src.policies:train:109 - Episode 127\n",
      "2021-08-25 11:21:16.952 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:16.953 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:21:16.954 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.23\n",
      "2021-08-25 11:21:16.955 | INFO     | src.policies:train:109 - Episode 128\n",
      "2021-08-25 11:21:16.964 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:16.965 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:21:16.966 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.11\n",
      "2021-08-25 11:21:16.967 | INFO     | src.policies:train:109 - Episode 129\n",
      "2021-08-25 11:21:16.985 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:16.986 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 11:21:16.987 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.35\n",
      "2021-08-25 11:21:16.988 | WARNING  | src.policies:train:131 - The actual batch size is 225, instead of 200\n",
      "2021-08-25 11:21:16.996 | INFO     | src.policies:train:157 - Total loss: 1.002666711807251\n",
      "2021-08-25 11:21:16.999 | INFO     | src.policies:train:103 - Epoch 14 / 800\n",
      "2021-08-25 11:21:17.000 | INFO     | src.policies:train:109 - Episode 130\n",
      "2021-08-25 11:21:17.013 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:17.014 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:21:17.015 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.45\n",
      "2021-08-25 11:21:17.016 | INFO     | src.policies:train:109 - Episode 131\n",
      "2021-08-25 11:21:17.035 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:17.036 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 11:21:17.037 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.58\n",
      "2021-08-25 11:21:17.038 | INFO     | src.policies:train:109 - Episode 132\n",
      "2021-08-25 11:21:17.048 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:17.049 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:17.050 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.57\n",
      "2021-08-25 11:21:17.051 | INFO     | src.policies:train:109 - Episode 133\n",
      "2021-08-25 11:21:17.061 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:17.062 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:21:17.063 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.49\n",
      "2021-08-25 11:21:17.064 | INFO     | src.policies:train:109 - Episode 134\n",
      "2021-08-25 11:21:17.074 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:17.076 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:21:17.077 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.53\n",
      "2021-08-25 11:21:17.078 | INFO     | src.policies:train:109 - Episode 135\n",
      "2021-08-25 11:21:17.088 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:17.089 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:17.090 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.54\n",
      "2021-08-25 11:21:17.091 | INFO     | src.policies:train:109 - Episode 136\n",
      "2021-08-25 11:21:17.103 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:17.104 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:21:17.105 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.51\n",
      "2021-08-25 11:21:17.106 | INFO     | src.policies:train:109 - Episode 137\n",
      "2021-08-25 11:21:17.118 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:17.119 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:21:17.120 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.26\n",
      "2021-08-25 11:21:17.121 | INFO     | src.policies:train:109 - Episode 138\n",
      "2021-08-25 11:21:17.131 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:17.132 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:17.133 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.17\n",
      "2021-08-25 11:21:17.134 | INFO     | src.policies:train:109 - Episode 139\n",
      "2021-08-25 11:21:17.155 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:17.157 | INFO     | src.policies:train:121 - Mean episode return: 46.0\n",
      "2021-08-25 11:21:17.158 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.35\n",
      "2021-08-25 11:21:17.159 | WARNING  | src.policies:train:131 - The actual batch size is 228, instead of 200\n",
      "2021-08-25 11:21:17.167 | INFO     | src.policies:train:157 - Total loss: 1.00338876247406\n",
      "2021-08-25 11:21:17.171 | INFO     | src.policies:train:103 - Epoch 15 / 800\n",
      "2021-08-25 11:21:17.172 | INFO     | src.policies:train:109 - Episode 140\n",
      "2021-08-25 11:21:17.192 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:17.193 | INFO     | src.policies:train:121 - Mean episode return: 46.0\n",
      "2021-08-25 11:21:17.194 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.65\n",
      "2021-08-25 11:21:17.195 | INFO     | src.policies:train:109 - Episode 141\n",
      "2021-08-25 11:21:17.211 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:17.213 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:21:17.214 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.7\n",
      "2021-08-25 11:21:17.214 | INFO     | src.policies:train:109 - Episode 142\n",
      "2021-08-25 11:21:17.226 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:17.227 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:21:17.227 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.61\n",
      "2021-08-25 11:21:17.229 | INFO     | src.policies:train:109 - Episode 143\n",
      "2021-08-25 11:21:17.251 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:17.252 | INFO     | src.policies:train:121 - Mean episode return: 45.0\n",
      "2021-08-25 11:21:17.253 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.91\n",
      "2021-08-25 11:21:17.254 | INFO     | src.policies:train:109 - Episode 144\n",
      "2021-08-25 11:21:17.266 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:17.267 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:21:17.268 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.93\n",
      "2021-08-25 11:21:17.269 | INFO     | src.policies:train:109 - Episode 145\n",
      "2021-08-25 11:21:17.285 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:17.286 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 11:21:17.287 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:17.288 | INFO     | src.policies:train:109 - Episode 146\n",
      "2021-08-25 11:21:17.305 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:17.306 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 11:21:17.307 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.17\n",
      "2021-08-25 11:21:17.308 | WARNING  | src.policies:train:131 - The actual batch size is 223, instead of 200\n",
      "2021-08-25 11:21:17.315 | INFO     | src.policies:train:157 - Total loss: 1.003970742225647\n",
      "2021-08-25 11:21:17.318 | INFO     | src.policies:train:103 - Epoch 16 / 800\n",
      "2021-08-25 11:21:17.320 | INFO     | src.policies:train:109 - Episode 147\n",
      "2021-08-25 11:21:17.329 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:17.330 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:17.332 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.03\n",
      "2021-08-25 11:21:17.333 | INFO     | src.policies:train:109 - Episode 148\n",
      "2021-08-25 11:21:17.345 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:17.346 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:21:17.347 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.96\n",
      "2021-08-25 11:21:17.348 | INFO     | src.policies:train:109 - Episode 149\n",
      "2021-08-25 11:21:17.357 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:17.358 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:21:17.359 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.92\n",
      "2021-08-25 11:21:17.360 | INFO     | src.policies:train:109 - Episode 150\n",
      "2021-08-25 11:21:17.368 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:17.370 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:21:17.371 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.94\n",
      "2021-08-25 11:21:17.372 | INFO     | src.policies:train:109 - Episode 151\n",
      "2021-08-25 11:21:17.382 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:17.383 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:21:17.384 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.98\n",
      "2021-08-25 11:21:17.385 | INFO     | src.policies:train:109 - Episode 152\n",
      "2021-08-25 11:21:17.394 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:17.396 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:17.397 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.98\n",
      "2021-08-25 11:21:17.397 | INFO     | src.policies:train:109 - Episode 153\n",
      "2021-08-25 11:21:17.405 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:17.406 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 11:21:17.407 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.74\n",
      "2021-08-25 11:21:17.408 | INFO     | src.policies:train:109 - Episode 154\n",
      "2021-08-25 11:21:17.426 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:17.427 | INFO     | src.policies:train:121 - Mean episode return: 39.0\n",
      "2021-08-25 11:21:17.428 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.72\n",
      "2021-08-25 11:21:17.429 | INFO     | src.policies:train:109 - Episode 155\n",
      "2021-08-25 11:21:17.438 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:17.439 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:21:17.440 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.68\n",
      "2021-08-25 11:21:17.441 | INFO     | src.policies:train:109 - Episode 156\n",
      "2021-08-25 11:21:17.450 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:17.451 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:17.452 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.73\n",
      "2021-08-25 11:21:17.453 | INFO     | src.policies:train:109 - Episode 157\n",
      "2021-08-25 11:21:17.463 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:17.465 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:17.466 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.66\n",
      "2021-08-25 11:21:17.467 | INFO     | src.policies:train:109 - Episode 158\n",
      "2021-08-25 11:21:17.482 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:17.484 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 11:21:17.484 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.89\n",
      "2021-08-25 11:21:17.486 | WARNING  | src.policies:train:131 - The actual batch size is 222, instead of 200\n",
      "2021-08-25 11:21:17.494 | INFO     | src.policies:train:157 - Total loss: 1.0025535821914673\n",
      "2021-08-25 11:21:17.498 | INFO     | src.policies:train:103 - Epoch 17 / 800\n",
      "2021-08-25 11:21:17.499 | INFO     | src.policies:train:109 - Episode 159\n",
      "2021-08-25 11:21:17.506 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:17.508 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:21:17.509 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.89\n",
      "2021-08-25 11:21:17.510 | INFO     | src.policies:train:109 - Episode 160\n",
      "2021-08-25 11:21:17.519 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:17.521 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:21:17.522 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.84\n",
      "2021-08-25 11:21:17.523 | INFO     | src.policies:train:109 - Episode 161\n",
      "2021-08-25 11:21:17.546 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:17.548 | INFO     | src.policies:train:121 - Mean episode return: 53.0\n",
      "2021-08-25 11:21:17.549 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.95\n",
      "2021-08-25 11:21:17.550 | INFO     | src.policies:train:109 - Episode 162\n",
      "2021-08-25 11:21:17.568 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:17.569 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 11:21:17.570 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.03\n",
      "2021-08-25 11:21:17.571 | INFO     | src.policies:train:109 - Episode 163\n",
      "2021-08-25 11:21:17.579 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:17.581 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:17.582 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.89\n",
      "2021-08-25 11:21:17.583 | INFO     | src.policies:train:109 - Episode 164\n",
      "2021-08-25 11:21:17.595 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:17.596 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:21:17.597 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.95\n",
      "2021-08-25 11:21:17.598 | INFO     | src.policies:train:109 - Episode 165\n",
      "2021-08-25 11:21:17.606 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:17.608 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:21:17.608 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.9\n",
      "2021-08-25 11:21:17.609 | INFO     | src.policies:train:109 - Episode 166\n",
      "2021-08-25 11:21:17.621 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:17.622 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:21:17.623 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:17.624 | INFO     | src.policies:train:109 - Episode 167\n",
      "2021-08-25 11:21:17.633 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:17.634 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:21:17.635 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.85\n",
      "2021-08-25 11:21:17.636 | INFO     | src.policies:train:109 - Episode 168\n",
      "2021-08-25 11:21:17.647 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:17.648 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:21:17.649 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.89\n",
      "2021-08-25 11:21:17.650 | WARNING  | src.policies:train:131 - The actual batch size is 214, instead of 200\n",
      "2021-08-25 11:21:17.659 | INFO     | src.policies:train:157 - Total loss: 1.0021296739578247\n",
      "2021-08-25 11:21:17.662 | INFO     | src.policies:train:103 - Epoch 18 / 800\n",
      "2021-08-25 11:21:17.663 | INFO     | src.policies:train:109 - Episode 169\n",
      "2021-08-25 11:21:17.671 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:17.673 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:17.674 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.87\n",
      "2021-08-25 11:21:17.674 | INFO     | src.policies:train:109 - Episode 170\n",
      "2021-08-25 11:21:17.687 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:17.688 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:21:17.689 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.78\n",
      "2021-08-25 11:21:17.690 | INFO     | src.policies:train:109 - Episode 171\n",
      "2021-08-25 11:21:17.699 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:17.700 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:17.701 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.72\n",
      "2021-08-25 11:21:17.702 | INFO     | src.policies:train:109 - Episode 172\n",
      "2021-08-25 11:21:17.715 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:17.717 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:21:17.718 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.85\n",
      "2021-08-25 11:21:17.719 | INFO     | src.policies:train:109 - Episode 173\n",
      "2021-08-25 11:21:17.728 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:17.729 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:21:17.730 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.8\n",
      "2021-08-25 11:21:17.731 | INFO     | src.policies:train:109 - Episode 174\n",
      "2021-08-25 11:21:17.740 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:17.741 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:21:17.742 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.82\n",
      "2021-08-25 11:21:17.743 | INFO     | src.policies:train:109 - Episode 175\n",
      "2021-08-25 11:21:17.759 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:17.760 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 11:21:17.761 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.06\n",
      "2021-08-25 11:21:17.762 | INFO     | src.policies:train:109 - Episode 176\n",
      "2021-08-25 11:21:17.772 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:17.773 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:17.774 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.08\n",
      "2021-08-25 11:21:17.775 | INFO     | src.policies:train:109 - Episode 177\n",
      "2021-08-25 11:21:17.784 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:17.785 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:17.786 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.97\n",
      "2021-08-25 11:21:17.787 | INFO     | src.policies:train:109 - Episode 178\n",
      "2021-08-25 11:21:17.804 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:17.806 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 11:21:17.807 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.14\n",
      "2021-08-25 11:21:17.808 | INFO     | src.policies:train:109 - Episode 179\n",
      "2021-08-25 11:21:17.818 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:17.819 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:17.820 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.01\n",
      "2021-08-25 11:21:17.821 | WARNING  | src.policies:train:131 - The actual batch size is 215, instead of 200\n",
      "2021-08-25 11:21:17.829 | INFO     | src.policies:train:157 - Total loss: 1.0020955801010132\n",
      "2021-08-25 11:21:17.832 | INFO     | src.policies:train:103 - Epoch 19 / 800\n",
      "2021-08-25 11:21:17.833 | INFO     | src.policies:train:109 - Episode 180\n",
      "2021-08-25 11:21:17.850 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:17.852 | INFO     | src.policies:train:121 - Mean episode return: 39.0\n",
      "2021-08-25 11:21:17.853 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.25\n",
      "2021-08-25 11:21:17.854 | INFO     | src.policies:train:109 - Episode 181\n",
      "2021-08-25 11:21:17.865 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:17.867 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:21:17.868 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.27\n",
      "2021-08-25 11:21:17.868 | INFO     | src.policies:train:109 - Episode 182\n",
      "2021-08-25 11:21:17.877 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:17.878 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 11:21:17.880 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.19\n",
      "2021-08-25 11:21:17.881 | INFO     | src.policies:train:109 - Episode 183\n",
      "2021-08-25 11:21:17.898 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:17.899 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 11:21:17.900 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.42\n",
      "2021-08-25 11:21:17.901 | INFO     | src.policies:train:109 - Episode 184\n",
      "2021-08-25 11:21:17.910 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:17.911 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:21:17.912 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.95\n",
      "2021-08-25 11:21:17.913 | INFO     | src.policies:train:109 - Episode 185\n",
      "2021-08-25 11:21:17.926 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:17.927 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 11:21:17.928 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.95\n",
      "2021-08-25 11:21:17.929 | INFO     | src.policies:train:109 - Episode 186\n",
      "2021-08-25 11:21:17.940 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:17.941 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:17.942 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.92\n",
      "2021-08-25 11:21:17.943 | INFO     | src.policies:train:109 - Episode 187\n",
      "2021-08-25 11:21:17.958 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:17.959 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 11:21:17.960 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:17.961 | INFO     | src.policies:train:109 - Episode 188\n",
      "2021-08-25 11:21:17.979 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:17.980 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 11:21:17.982 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.3\n",
      "2021-08-25 11:21:17.982 | WARNING  | src.policies:train:131 - The actual batch size is 225, instead of 200\n",
      "2021-08-25 11:21:17.990 | INFO     | src.policies:train:157 - Total loss: 1.0024693012237549\n",
      "2021-08-25 11:21:17.993 | INFO     | src.policies:train:103 - Epoch 20 / 800\n",
      "2021-08-25 11:21:17.995 | INFO     | src.policies:train:109 - Episode 189\n",
      "2021-08-25 11:21:18.004 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:18.005 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:21:18.006 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.0\n",
      "2021-08-25 11:21:18.007 | INFO     | src.policies:train:109 - Episode 190\n",
      "2021-08-25 11:21:18.016 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:18.017 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:21:18.018 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.65\n",
      "2021-08-25 11:21:18.019 | INFO     | src.policies:train:109 - Episode 191\n",
      "2021-08-25 11:21:18.032 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:18.033 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:21:18.034 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.51\n",
      "2021-08-25 11:21:18.035 | INFO     | src.policies:train:109 - Episode 192\n",
      "2021-08-25 11:21:18.053 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:18.054 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 11:21:18.056 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.64\n",
      "2021-08-25 11:21:18.057 | INFO     | src.policies:train:109 - Episode 193\n",
      "2021-08-25 11:21:18.072 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:18.073 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 11:21:18.074 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.82\n",
      "2021-08-25 11:21:18.075 | INFO     | src.policies:train:109 - Episode 194\n",
      "2021-08-25 11:21:18.097 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:18.098 | INFO     | src.policies:train:121 - Mean episode return: 47.0\n",
      "2021-08-25 11:21:18.099 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.97\n",
      "2021-08-25 11:21:18.100 | INFO     | src.policies:train:109 - Episode 195\n",
      "2021-08-25 11:21:18.114 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:18.115 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 11:21:18.116 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.89\n",
      "2021-08-25 11:21:18.117 | INFO     | src.policies:train:109 - Episode 196\n",
      "2021-08-25 11:21:18.126 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:18.128 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:21:18.129 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.79\n",
      "2021-08-25 11:21:18.130 | WARNING  | src.policies:train:131 - The actual batch size is 205, instead of 200\n",
      "2021-08-25 11:21:18.137 | INFO     | src.policies:train:157 - Total loss: 1.0020408630371094\n",
      "2021-08-25 11:21:18.141 | INFO     | src.policies:train:103 - Epoch 21 / 800\n",
      "2021-08-25 11:21:18.142 | INFO     | src.policies:train:109 - Episode 197\n",
      "2021-08-25 11:21:18.153 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:18.154 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 11:21:18.156 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 21.79\n",
      "2021-08-25 11:21:18.157 | INFO     | src.policies:train:109 - Episode 198\n",
      "2021-08-25 11:21:18.178 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:18.179 | INFO     | src.policies:train:121 - Mean episode return: 44.0\n",
      "2021-08-25 11:21:18.180 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.05\n",
      "2021-08-25 11:21:18.181 | INFO     | src.policies:train:109 - Episode 199\n",
      "2021-08-25 11:21:18.193 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:18.194 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:21:18.195 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.14\n",
      "2021-08-25 11:21:18.196 | INFO     | src.policies:train:109 - Episode 200\n",
      "2021-08-25 11:21:18.214 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:18.215 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 11:21:18.216 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.38\n",
      "2021-08-25 11:21:18.217 | INFO     | src.policies:train:109 - Episode 201\n",
      "2021-08-25 11:21:18.231 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:18.232 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 11:21:18.234 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.53\n",
      "2021-08-25 11:21:18.235 | INFO     | src.policies:train:109 - Episode 202\n",
      "2021-08-25 11:21:18.244 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:18.246 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:18.246 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.52\n",
      "2021-08-25 11:21:18.247 | INFO     | src.policies:train:109 - Episode 203\n",
      "2021-08-25 11:21:18.258 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:18.259 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:18.260 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.51\n",
      "2021-08-25 11:21:18.262 | INFO     | src.policies:train:109 - Episode 204\n",
      "2021-08-25 11:21:18.273 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:18.274 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:21:18.275 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.51\n",
      "2021-08-25 11:21:18.276 | WARNING  | src.policies:train:131 - The actual batch size is 205, instead of 200\n",
      "2021-08-25 11:21:18.283 | INFO     | src.policies:train:157 - Total loss: 1.002036690711975\n",
      "2021-08-25 11:21:18.286 | INFO     | src.policies:train:103 - Epoch 22 / 800\n",
      "2021-08-25 11:21:18.287 | INFO     | src.policies:train:109 - Episode 205\n",
      "2021-08-25 11:21:18.299 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:18.300 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:21:18.301 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.59\n",
      "2021-08-25 11:21:18.302 | INFO     | src.policies:train:109 - Episode 206\n",
      "2021-08-25 11:21:18.319 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:18.320 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 11:21:18.321 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.8\n",
      "2021-08-25 11:21:18.322 | INFO     | src.policies:train:109 - Episode 207\n",
      "2021-08-25 11:21:18.332 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:18.333 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:18.334 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.82\n",
      "2021-08-25 11:21:18.335 | INFO     | src.policies:train:109 - Episode 208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:18.349 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:18.351 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 11:21:18.352 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 22.9\n",
      "2021-08-25 11:21:18.353 | INFO     | src.policies:train:109 - Episode 209\n",
      "2021-08-25 11:21:18.374 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:18.376 | INFO     | src.policies:train:121 - Mean episode return: 49.0\n",
      "2021-08-25 11:21:18.377 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.22\n",
      "2021-08-25 11:21:18.378 | INFO     | src.policies:train:109 - Episode 210\n",
      "2021-08-25 11:21:18.390 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:18.391 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:21:18.392 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.23\n",
      "2021-08-25 11:21:18.393 | INFO     | src.policies:train:109 - Episode 211\n",
      "2021-08-25 11:21:18.403 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:18.404 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:21:18.405 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.21\n",
      "2021-08-25 11:21:18.406 | INFO     | src.policies:train:109 - Episode 212\n",
      "2021-08-25 11:21:18.418 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:18.419 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:21:18.420 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.32\n",
      "2021-08-25 11:21:18.421 | WARNING  | src.policies:train:131 - The actual batch size is 204, instead of 200\n",
      "2021-08-25 11:21:18.427 | INFO     | src.policies:train:157 - Total loss: 1.0020124912261963\n",
      "2021-08-25 11:21:18.430 | INFO     | src.policies:train:103 - Epoch 23 / 800\n",
      "2021-08-25 11:21:18.431 | INFO     | src.policies:train:109 - Episode 213\n",
      "2021-08-25 11:21:18.442 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:18.444 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:21:18.445 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.24\n",
      "2021-08-25 11:21:18.445 | INFO     | src.policies:train:109 - Episode 214\n",
      "2021-08-25 11:21:18.470 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:18.472 | INFO     | src.policies:train:121 - Mean episode return: 54.0\n",
      "2021-08-25 11:21:18.473 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.54\n",
      "2021-08-25 11:21:18.474 | INFO     | src.policies:train:109 - Episode 215\n",
      "2021-08-25 11:21:18.488 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:18.489 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 11:21:18.490 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.62\n",
      "2021-08-25 11:21:18.491 | INFO     | src.policies:train:109 - Episode 216\n",
      "2021-08-25 11:21:18.501 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:18.502 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:18.504 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.18\n",
      "2021-08-25 11:21:18.504 | INFO     | src.policies:train:109 - Episode 217\n",
      "2021-08-25 11:21:18.527 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:18.529 | INFO     | src.policies:train:121 - Mean episode return: 51.0\n",
      "2021-08-25 11:21:18.529 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.54\n",
      "2021-08-25 11:21:18.530 | INFO     | src.policies:train:109 - Episode 218\n",
      "2021-08-25 11:21:18.550 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:18.551 | INFO     | src.policies:train:121 - Mean episode return: 44.0\n",
      "2021-08-25 11:21:18.552 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 23.78\n",
      "2021-08-25 11:21:18.553 | WARNING  | src.policies:train:131 - The actual batch size is 212, instead of 200\n",
      "2021-08-25 11:21:18.561 | INFO     | src.policies:train:157 - Total loss: 1.0021909475326538\n",
      "2021-08-25 11:21:18.564 | INFO     | src.policies:train:103 - Epoch 24 / 800\n",
      "2021-08-25 11:21:18.566 | INFO     | src.policies:train:109 - Episode 219\n",
      "2021-08-25 11:21:18.587 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:18.588 | INFO     | src.policies:train:121 - Mean episode return: 53.0\n",
      "2021-08-25 11:21:18.589 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.07\n",
      "2021-08-25 11:21:18.591 | INFO     | src.policies:train:109 - Episode 220\n",
      "2021-08-25 11:21:18.600 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:18.602 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:18.603 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.01\n",
      "2021-08-25 11:21:18.604 | INFO     | src.policies:train:109 - Episode 221\n",
      "2021-08-25 11:21:18.620 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:18.621 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 11:21:18.622 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.14\n",
      "2021-08-25 11:21:18.623 | INFO     | src.policies:train:109 - Episode 222\n",
      "2021-08-25 11:21:18.635 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:18.636 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:21:18.637 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.21\n",
      "2021-08-25 11:21:18.638 | INFO     | src.policies:train:109 - Episode 223\n",
      "2021-08-25 11:21:18.651 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:18.653 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:21:18.654 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.16\n",
      "2021-08-25 11:21:18.654 | INFO     | src.policies:train:109 - Episode 224\n",
      "2021-08-25 11:21:18.667 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:18.668 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:21:18.669 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.19\n",
      "2021-08-25 11:21:18.670 | INFO     | src.policies:train:109 - Episode 225\n",
      "2021-08-25 11:21:18.691 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:18.692 | INFO     | src.policies:train:121 - Mean episode return: 45.0\n",
      "2021-08-25 11:21:18.694 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.49\n",
      "2021-08-25 11:21:18.694 | WARNING  | src.policies:train:131 - The actual batch size is 212, instead of 200\n",
      "2021-08-25 11:21:18.702 | INFO     | src.policies:train:157 - Total loss: 1.0021908283233643\n",
      "2021-08-25 11:21:18.706 | INFO     | src.policies:train:103 - Epoch 25 / 800\n",
      "2021-08-25 11:21:18.707 | INFO     | src.policies:train:109 - Episode 226\n",
      "2021-08-25 11:21:18.716 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:18.717 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:21:18.718 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.5\n",
      "2021-08-25 11:21:18.719 | INFO     | src.policies:train:109 - Episode 227\n",
      "2021-08-25 11:21:18.731 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:18.733 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:21:18.734 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.51\n",
      "2021-08-25 11:21:18.735 | INFO     | src.policies:train:109 - Episode 228\n",
      "2021-08-25 11:21:18.749 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:18.751 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 11:21:18.752 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.73\n",
      "2021-08-25 11:21:18.753 | INFO     | src.policies:train:109 - Episode 229\n",
      "2021-08-25 11:21:18.765 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:18.766 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:21:18.767 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.59\n",
      "2021-08-25 11:21:18.768 | INFO     | src.policies:train:109 - Episode 230\n",
      "2021-08-25 11:21:18.788 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:18.789 | INFO     | src.policies:train:121 - Mean episode return: 44.0\n",
      "2021-08-25 11:21:18.790 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.79\n",
      "2021-08-25 11:21:18.791 | INFO     | src.policies:train:109 - Episode 231\n",
      "2021-08-25 11:21:18.804 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:18.806 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:21:18.807 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.66\n",
      "2021-08-25 11:21:18.808 | INFO     | src.policies:train:109 - Episode 232\n",
      "2021-08-25 11:21:18.832 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:18.834 | INFO     | src.policies:train:121 - Mean episode return: 56.0\n",
      "2021-08-25 11:21:18.835 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.05\n",
      "2021-08-25 11:21:18.835 | WARNING  | src.policies:train:131 - The actual batch size is 217, instead of 200\n",
      "2021-08-25 11:21:18.843 | INFO     | src.policies:train:157 - Total loss: 1.0022989511489868\n",
      "2021-08-25 11:21:18.846 | INFO     | src.policies:train:103 - Epoch 26 / 800\n",
      "2021-08-25 11:21:18.847 | INFO     | src.policies:train:109 - Episode 233\n",
      "2021-08-25 11:21:18.856 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:18.858 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:18.859 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.07\n",
      "2021-08-25 11:21:18.860 | INFO     | src.policies:train:109 - Episode 234\n",
      "2021-08-25 11:21:18.868 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:18.869 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:18.870 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.01\n",
      "2021-08-25 11:21:18.871 | INFO     | src.policies:train:109 - Episode 235\n",
      "2021-08-25 11:21:18.883 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:18.884 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 11:21:18.885 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.1\n",
      "2021-08-25 11:21:18.886 | INFO     | src.policies:train:109 - Episode 236\n",
      "2021-08-25 11:21:18.897 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:18.898 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:18.899 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.06\n",
      "2021-08-25 11:21:18.900 | INFO     | src.policies:train:109 - Episode 237\n",
      "2021-08-25 11:21:18.912 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:18.914 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:21:18.915 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.08\n",
      "2021-08-25 11:21:18.915 | INFO     | src.policies:train:109 - Episode 238\n",
      "2021-08-25 11:21:18.929 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:18.930 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 11:21:18.931 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.2\n",
      "2021-08-25 11:21:18.932 | INFO     | src.policies:train:109 - Episode 239\n",
      "2021-08-25 11:21:18.941 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:18.942 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:18.943 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.86\n",
      "2021-08-25 11:21:18.944 | INFO     | src.policies:train:109 - Episode 240\n",
      "2021-08-25 11:21:18.957 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:18.958 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:21:18.959 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.62\n",
      "2021-08-25 11:21:18.960 | INFO     | src.policies:train:109 - Episode 241\n",
      "2021-08-25 11:21:18.973 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:18.974 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:21:18.975 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.57\n",
      "2021-08-25 11:21:18.976 | INFO     | src.policies:train:109 - Episode 242\n",
      "2021-08-25 11:21:18.998 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:18.999 | INFO     | src.policies:train:121 - Mean episode return: 44.0\n",
      "2021-08-25 11:21:19.000 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.83\n",
      "2021-08-25 11:21:19.001 | WARNING  | src.policies:train:131 - The actual batch size is 222, instead of 200\n",
      "2021-08-25 11:21:19.009 | INFO     | src.policies:train:157 - Total loss: 1.0024049282073975\n",
      "2021-08-25 11:21:19.012 | INFO     | src.policies:train:103 - Epoch 27 / 800\n",
      "2021-08-25 11:21:19.013 | INFO     | src.policies:train:109 - Episode 243\n",
      "2021-08-25 11:21:19.022 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:19.023 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:19.024 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.54\n",
      "2021-08-25 11:21:19.025 | INFO     | src.policies:train:109 - Episode 244\n",
      "2021-08-25 11:21:19.033 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:19.035 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:19.035 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.47\n",
      "2021-08-25 11:21:19.036 | INFO     | src.policies:train:109 - Episode 245\n",
      "2021-08-25 11:21:19.055 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:19.056 | INFO     | src.policies:train:121 - Mean episode return: 42.0\n",
      "2021-08-25 11:21:19.057 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.58\n",
      "2021-08-25 11:21:19.058 | INFO     | src.policies:train:109 - Episode 246\n",
      "2021-08-25 11:21:19.067 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:19.068 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:19.069 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.35\n",
      "2021-08-25 11:21:19.070 | INFO     | src.policies:train:109 - Episode 247\n",
      "2021-08-25 11:21:19.080 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:19.081 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:19.082 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.35\n",
      "2021-08-25 11:21:19.083 | INFO     | src.policies:train:109 - Episode 248\n",
      "2021-08-25 11:21:19.091 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:19.093 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:21:19.094 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.28\n",
      "2021-08-25 11:21:19.094 | INFO     | src.policies:train:109 - Episode 249\n",
      "2021-08-25 11:21:19.106 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:19.107 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:21:19.108 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.36\n",
      "2021-08-25 11:21:19.109 | INFO     | src.policies:train:109 - Episode 250\n",
      "2021-08-25 11:21:19.126 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:19.127 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 11:21:19.128 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 24.56\n",
      "2021-08-25 11:21:19.129 | INFO     | src.policies:train:109 - Episode 251\n",
      "2021-08-25 11:21:19.161 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:19.162 | INFO     | src.policies:train:121 - Mean episode return: 69.0\n",
      "2021-08-25 11:21:19.163 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.06\n",
      "2021-08-25 11:21:19.164 | WARNING  | src.policies:train:131 - The actual batch size is 234, instead of 200\n",
      "2021-08-25 11:21:19.171 | INFO     | src.policies:train:157 - Total loss: 1.0026313066482544\n",
      "2021-08-25 11:21:19.175 | INFO     | src.policies:train:103 - Epoch 28 / 800\n",
      "2021-08-25 11:21:19.176 | INFO     | src.policies:train:109 - Episode 252\n",
      "2021-08-25 11:21:19.191 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:19.192 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 11:21:19.194 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.24\n",
      "2021-08-25 11:21:19.195 | INFO     | src.policies:train:109 - Episode 253\n",
      "2021-08-25 11:21:19.207 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:19.208 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:21:19.209 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.35\n",
      "2021-08-25 11:21:19.210 | INFO     | src.policies:train:109 - Episode 254\n",
      "2021-08-25 11:21:19.219 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:19.221 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:19.221 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.11\n",
      "2021-08-25 11:21:19.222 | INFO     | src.policies:train:109 - Episode 255\n",
      "2021-08-25 11:21:19.235 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:19.237 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 11:21:19.238 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.22\n",
      "2021-08-25 11:21:19.239 | INFO     | src.policies:train:109 - Episode 256\n",
      "2021-08-25 11:21:19.255 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:19.256 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 11:21:19.257 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.38\n",
      "2021-08-25 11:21:19.258 | INFO     | src.policies:train:109 - Episode 257\n",
      "2021-08-25 11:21:19.268 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:19.269 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:19.270 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.4\n",
      "2021-08-25 11:21:19.271 | INFO     | src.policies:train:109 - Episode 258\n",
      "2021-08-25 11:21:19.297 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:19.299 | INFO     | src.policies:train:121 - Mean episode return: 57.0\n",
      "2021-08-25 11:21:19.299 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.64\n",
      "2021-08-25 11:21:19.300 | INFO     | src.policies:train:109 - Episode 259\n",
      "2021-08-25 11:21:19.316 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:19.318 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 11:21:19.319 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.83\n",
      "2021-08-25 11:21:19.320 | WARNING  | src.policies:train:131 - The actual batch size is 229, instead of 200\n",
      "2021-08-25 11:21:19.327 | INFO     | src.policies:train:157 - Total loss: 1.002540946006775\n",
      "2021-08-25 11:21:19.330 | INFO     | src.policies:train:103 - Epoch 29 / 800\n",
      "2021-08-25 11:21:19.331 | INFO     | src.policies:train:109 - Episode 260\n",
      "2021-08-25 11:21:19.341 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:19.342 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:21:19.343 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.89\n",
      "2021-08-25 11:21:19.344 | INFO     | src.policies:train:109 - Episode 261\n",
      "2021-08-25 11:21:19.362 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:19.363 | INFO     | src.policies:train:121 - Mean episode return: 39.0\n",
      "2021-08-25 11:21:19.364 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.75\n",
      "2021-08-25 11:21:19.365 | INFO     | src.policies:train:109 - Episode 262\n",
      "2021-08-25 11:21:19.379 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:19.380 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:21:19.381 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.62\n",
      "2021-08-25 11:21:19.382 | INFO     | src.policies:train:109 - Episode 263\n",
      "2021-08-25 11:21:19.394 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:19.395 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:21:19.396 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.73\n",
      "2021-08-25 11:21:19.397 | INFO     | src.policies:train:109 - Episode 264\n",
      "2021-08-25 11:21:19.405 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:19.406 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:19.407 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.61\n",
      "2021-08-25 11:21:19.408 | INFO     | src.policies:train:109 - Episode 265\n",
      "2021-08-25 11:21:19.417 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:19.419 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:19.420 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.65\n",
      "2021-08-25 11:21:19.421 | INFO     | src.policies:train:109 - Episode 266\n",
      "2021-08-25 11:21:19.431 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:19.432 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:19.433 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.63\n",
      "2021-08-25 11:21:19.434 | INFO     | src.policies:train:109 - Episode 267\n",
      "2021-08-25 11:21:19.447 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:19.449 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:21:19.449 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.75\n",
      "2021-08-25 11:21:19.450 | INFO     | src.policies:train:109 - Episode 268\n",
      "2021-08-25 11:21:19.470 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:19.471 | INFO     | src.policies:train:121 - Mean episode return: 38.0\n",
      "2021-08-25 11:21:19.473 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.92\n",
      "2021-08-25 11:21:19.474 | WARNING  | src.policies:train:131 - The actual batch size is 212, instead of 200\n",
      "2021-08-25 11:21:19.482 | INFO     | src.policies:train:157 - Total loss: 1.0021858215332031\n",
      "2021-08-25 11:21:19.485 | INFO     | src.policies:train:103 - Epoch 30 / 800\n",
      "2021-08-25 11:21:19.486 | INFO     | src.policies:train:109 - Episode 269\n",
      "2021-08-25 11:21:19.495 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:19.496 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:19.497 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.95\n",
      "2021-08-25 11:21:19.499 | INFO     | src.policies:train:109 - Episode 270\n",
      "2021-08-25 11:21:19.510 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:19.512 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:21:19.513 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.9\n",
      "2021-08-25 11:21:19.514 | INFO     | src.policies:train:109 - Episode 271\n",
      "2021-08-25 11:21:19.531 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:19.533 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 11:21:19.534 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.14\n",
      "2021-08-25 11:21:19.534 | INFO     | src.policies:train:109 - Episode 272\n",
      "2021-08-25 11:21:19.552 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:19.553 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 11:21:19.554 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.24\n",
      "2021-08-25 11:21:19.555 | INFO     | src.policies:train:109 - Episode 273\n",
      "2021-08-25 11:21:19.563 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:19.564 | INFO     | src.policies:train:121 - Mean episode return: 9.0\n",
      "2021-08-25 11:21:19.565 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.19\n",
      "2021-08-25 11:21:19.566 | INFO     | src.policies:train:109 - Episode 274\n",
      "2021-08-25 11:21:19.583 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:19.585 | INFO     | src.policies:train:121 - Mean episode return: 39.0\n",
      "2021-08-25 11:21:19.586 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.45\n",
      "2021-08-25 11:21:19.587 | INFO     | src.policies:train:109 - Episode 275\n",
      "2021-08-25 11:21:19.602 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:19.604 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 11:21:19.604 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.41\n",
      "2021-08-25 11:21:19.605 | INFO     | src.policies:train:109 - Episode 276\n",
      "2021-08-25 11:21:19.614 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:19.616 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:21:19.616 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.4\n",
      "2021-08-25 11:21:19.623 | INFO     | src.policies:train:157 - Total loss: 1.0018999576568604\n",
      "2021-08-25 11:21:19.627 | INFO     | src.policies:train:103 - Epoch 31 / 800\n",
      "2021-08-25 11:21:19.628 | INFO     | src.policies:train:109 - Episode 277\n",
      "2021-08-25 11:21:19.643 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:19.644 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 11:21:19.645 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.61\n",
      "2021-08-25 11:21:19.646 | INFO     | src.policies:train:109 - Episode 278\n",
      "2021-08-25 11:21:19.657 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:19.658 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:21:19.659 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.45\n",
      "2021-08-25 11:21:19.660 | INFO     | src.policies:train:109 - Episode 279\n",
      "2021-08-25 11:21:19.676 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:19.677 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 11:21:19.678 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.6\n",
      "2021-08-25 11:21:19.679 | INFO     | src.policies:train:109 - Episode 280\n",
      "2021-08-25 11:21:19.697 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:19.699 | INFO     | src.policies:train:121 - Mean episode return: 38.0\n",
      "2021-08-25 11:21:19.700 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.59\n",
      "2021-08-25 11:21:19.700 | INFO     | src.policies:train:109 - Episode 281\n",
      "2021-08-25 11:21:19.710 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:19.711 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:21:19.712 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.59\n",
      "2021-08-25 11:21:19.713 | INFO     | src.policies:train:109 - Episode 282\n",
      "2021-08-25 11:21:19.736 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:19.738 | INFO     | src.policies:train:121 - Mean episode return: 54.0\n",
      "2021-08-25 11:21:19.739 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.03\n",
      "2021-08-25 11:21:19.740 | INFO     | src.policies:train:109 - Episode 283\n",
      "2021-08-25 11:21:19.748 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:19.749 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:21:19.750 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.79\n",
      "2021-08-25 11:21:19.751 | WARNING  | src.policies:train:131 - The actual batch size is 204, instead of 200\n",
      "2021-08-25 11:21:19.758 | INFO     | src.policies:train:157 - Total loss: 1.0019930601119995\n",
      "2021-08-25 11:21:19.762 | INFO     | src.policies:train:103 - Epoch 32 / 800\n",
      "2021-08-25 11:21:19.763 | INFO     | src.policies:train:109 - Episode 284\n",
      "2021-08-25 11:21:19.776 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:19.777 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:21:19.779 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.95\n",
      "2021-08-25 11:21:19.779 | INFO     | src.policies:train:109 - Episode 285\n",
      "2021-08-25 11:21:19.809 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:19.810 | INFO     | src.policies:train:121 - Mean episode return: 70.0\n",
      "2021-08-25 11:21:19.811 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.4\n",
      "2021-08-25 11:21:19.813 | INFO     | src.policies:train:109 - Episode 286\n",
      "2021-08-25 11:21:19.833 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:19.834 | INFO     | src.policies:train:121 - Mean episode return: 45.0\n",
      "2021-08-25 11:21:19.835 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.68\n",
      "2021-08-25 11:21:19.836 | INFO     | src.policies:train:109 - Episode 287\n",
      "2021-08-25 11:21:19.846 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:19.847 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:21:19.848 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.5\n",
      "2021-08-25 11:21:19.849 | INFO     | src.policies:train:109 - Episode 288\n",
      "2021-08-25 11:21:19.870 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:19.871 | INFO     | src.policies:train:121 - Mean episode return: 44.0\n",
      "2021-08-25 11:21:19.872 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.58\n",
      "2021-08-25 11:21:19.873 | WARNING  | src.policies:train:131 - The actual batch size is 202, instead of 200\n",
      "2021-08-25 11:21:19.880 | INFO     | src.policies:train:157 - Total loss: 1.0019357204437256\n",
      "2021-08-25 11:21:19.884 | INFO     | src.policies:train:103 - Epoch 33 / 800\n",
      "2021-08-25 11:21:19.885 | INFO     | src.policies:train:109 - Episode 289\n",
      "2021-08-25 11:21:19.904 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:19.905 | INFO     | src.policies:train:121 - Mean episode return: 43.0\n",
      "2021-08-25 11:21:19.906 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.83\n",
      "2021-08-25 11:21:19.907 | INFO     | src.policies:train:109 - Episode 290\n",
      "2021-08-25 11:21:19.926 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:19.927 | INFO     | src.policies:train:121 - Mean episode return: 41.0\n",
      "2021-08-25 11:21:19.928 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.11\n",
      "2021-08-25 11:21:19.929 | INFO     | src.policies:train:109 - Episode 291\n",
      "2021-08-25 11:21:19.944 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:19.945 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:21:19.946 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.17\n",
      "2021-08-25 11:21:19.947 | INFO     | src.policies:train:109 - Episode 292\n",
      "2021-08-25 11:21:19.959 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:19.960 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:21:19.961 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.0\n",
      "2021-08-25 11:21:19.962 | INFO     | src.policies:train:109 - Episode 293\n",
      "2021-08-25 11:21:19.979 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:19.980 | INFO     | src.policies:train:121 - Mean episode return: 38.0\n",
      "2021-08-25 11:21:19.981 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.08\n",
      "2021-08-25 11:21:19.982 | INFO     | src.policies:train:109 - Episode 294\n",
      "2021-08-25 11:21:20.002 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:20.003 | INFO     | src.policies:train:121 - Mean episode return: 46.0\n",
      "2021-08-25 11:21:20.004 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.07\n",
      "2021-08-25 11:21:20.005 | WARNING  | src.policies:train:131 - The actual batch size is 216, instead of 200\n",
      "2021-08-25 11:21:20.012 | INFO     | src.policies:train:157 - Total loss: 1.0022765398025513\n",
      "2021-08-25 11:21:20.015 | INFO     | src.policies:train:103 - Epoch 34 / 800\n",
      "2021-08-25 11:21:20.016 | INFO     | src.policies:train:109 - Episode 295\n",
      "2021-08-25 11:21:20.025 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:20.026 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:20.027 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.98\n",
      "2021-08-25 11:21:20.028 | INFO     | src.policies:train:109 - Episode 296\n",
      "2021-08-25 11:21:20.043 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:20.044 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:21:20.045 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.11\n",
      "2021-08-25 11:21:20.046 | INFO     | src.policies:train:109 - Episode 297\n",
      "2021-08-25 11:21:20.055 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:20.056 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:20.058 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.01\n",
      "2021-08-25 11:21:20.058 | INFO     | src.policies:train:109 - Episode 298\n",
      "2021-08-25 11:21:20.083 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:20.085 | INFO     | src.policies:train:121 - Mean episode return: 57.0\n",
      "2021-08-25 11:21:20.086 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.14\n",
      "2021-08-25 11:21:20.087 | INFO     | src.policies:train:109 - Episode 299\n",
      "2021-08-25 11:21:20.095 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:20.096 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:20.097 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.05\n",
      "2021-08-25 11:21:20.098 | INFO     | src.policies:train:109 - Episode 300\n",
      "2021-08-25 11:21:20.111 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:20.113 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:21:20.114 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.93\n",
      "2021-08-25 11:21:20.114 | INFO     | src.policies:train:109 - Episode 301\n",
      "2021-08-25 11:21:20.133 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:20.135 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 11:21:20.136 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.02\n",
      "2021-08-25 11:21:20.136 | INFO     | src.policies:train:109 - Episode 302\n",
      "2021-08-25 11:21:20.151 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:20.152 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 11:21:20.153 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.15\n",
      "2021-08-25 11:21:20.154 | WARNING  | src.policies:train:131 - The actual batch size is 215, instead of 200\n",
      "2021-08-25 11:21:20.162 | INFO     | src.policies:train:157 - Total loss: 1.0022495985031128\n",
      "2021-08-25 11:21:20.165 | INFO     | src.policies:train:103 - Epoch 35 / 800\n",
      "2021-08-25 11:21:20.167 | INFO     | src.policies:train:109 - Episode 303\n",
      "2021-08-25 11:21:20.175 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:20.176 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:20.177 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.14\n",
      "2021-08-25 11:21:20.178 | INFO     | src.policies:train:109 - Episode 304\n",
      "2021-08-25 11:21:20.189 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:20.190 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:21:20.191 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.12\n",
      "2021-08-25 11:21:20.192 | INFO     | src.policies:train:109 - Episode 305\n",
      "2021-08-25 11:21:20.209 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:20.210 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 11:21:20.211 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.26\n",
      "2021-08-25 11:21:20.212 | INFO     | src.policies:train:109 - Episode 306\n",
      "2021-08-25 11:21:20.221 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:20.222 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:21:20.223 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.08\n",
      "2021-08-25 11:21:20.224 | INFO     | src.policies:train:109 - Episode 307\n",
      "2021-08-25 11:21:20.240 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:20.241 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 11:21:20.242 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.28\n",
      "2021-08-25 11:21:20.243 | INFO     | src.policies:train:109 - Episode 308\n",
      "2021-08-25 11:21:20.263 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:20.264 | INFO     | src.policies:train:121 - Mean episode return: 43.0\n",
      "2021-08-25 11:21:20.265 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.43\n",
      "2021-08-25 11:21:20.266 | INFO     | src.policies:train:109 - Episode 309\n",
      "2021-08-25 11:21:20.274 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:20.276 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 11:21:20.277 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.04\n",
      "2021-08-25 11:21:20.278 | INFO     | src.policies:train:109 - Episode 310\n",
      "2021-08-25 11:21:20.303 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:20.304 | INFO     | src.policies:train:121 - Mean episode return: 51.0\n",
      "2021-08-25 11:21:20.305 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.31\n",
      "2021-08-25 11:21:20.306 | WARNING  | src.policies:train:131 - The actual batch size is 222, instead of 200\n",
      "2021-08-25 11:21:20.313 | INFO     | src.policies:train:157 - Total loss: 1.0023844242095947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:20.317 | INFO     | src.policies:train:103 - Epoch 36 / 800\n",
      "2021-08-25 11:21:20.318 | INFO     | src.policies:train:109 - Episode 311\n",
      "2021-08-25 11:21:20.332 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:20.333 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 11:21:20.334 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.47\n",
      "2021-08-25 11:21:20.335 | INFO     | src.policies:train:109 - Episode 312\n",
      "2021-08-25 11:21:20.355 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:20.356 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 11:21:20.358 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.67\n",
      "2021-08-25 11:21:20.359 | INFO     | src.policies:train:109 - Episode 313\n",
      "2021-08-25 11:21:20.368 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:20.370 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:21:20.371 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.59\n",
      "2021-08-25 11:21:20.373 | INFO     | src.policies:train:109 - Episode 314\n",
      "2021-08-25 11:21:20.383 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:20.384 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:21:20.385 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.19\n",
      "2021-08-25 11:21:20.386 | INFO     | src.policies:train:109 - Episode 315\n",
      "2021-08-25 11:21:20.398 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:20.399 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:21:20.401 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.16\n",
      "2021-08-25 11:21:20.401 | INFO     | src.policies:train:109 - Episode 316\n",
      "2021-08-25 11:21:20.416 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:20.418 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 11:21:20.419 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.26\n",
      "2021-08-25 11:21:20.419 | INFO     | src.policies:train:109 - Episode 317\n",
      "2021-08-25 11:21:20.429 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:20.430 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:21:20.431 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.89\n",
      "2021-08-25 11:21:20.432 | INFO     | src.policies:train:109 - Episode 318\n",
      "2021-08-25 11:21:20.443 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:20.444 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:21:20.445 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.65\n",
      "2021-08-25 11:21:20.446 | INFO     | src.policies:train:109 - Episode 319\n",
      "2021-08-25 11:21:20.463 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:20.465 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 11:21:20.466 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.48\n",
      "2021-08-25 11:21:20.467 | WARNING  | src.policies:train:131 - The actual batch size is 216, instead of 200\n",
      "2021-08-25 11:21:20.475 | INFO     | src.policies:train:157 - Total loss: 1.0022720098495483\n",
      "2021-08-25 11:21:20.478 | INFO     | src.policies:train:103 - Epoch 37 / 800\n",
      "2021-08-25 11:21:20.479 | INFO     | src.policies:train:109 - Episode 320\n",
      "2021-08-25 11:21:20.485 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:20.486 | INFO     | src.policies:train:121 - Mean episode return: 9.0\n",
      "2021-08-25 11:21:20.487 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.42\n",
      "2021-08-25 11:21:20.488 | INFO     | src.policies:train:109 - Episode 321\n",
      "2021-08-25 11:21:20.497 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:20.498 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:21:20.499 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.21\n",
      "2021-08-25 11:21:20.500 | INFO     | src.policies:train:109 - Episode 322\n",
      "2021-08-25 11:21:20.512 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:20.513 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:21:20.514 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.2\n",
      "2021-08-25 11:21:20.515 | INFO     | src.policies:train:109 - Episode 323\n",
      "2021-08-25 11:21:20.529 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:20.531 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:21:20.532 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.28\n",
      "2021-08-25 11:21:20.533 | INFO     | src.policies:train:109 - Episode 324\n",
      "2021-08-25 11:21:20.548 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:20.550 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 11:21:20.550 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.36\n",
      "2021-08-25 11:21:20.551 | INFO     | src.policies:train:109 - Episode 325\n",
      "2021-08-25 11:21:20.567 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:20.568 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 11:21:20.569 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.21\n",
      "2021-08-25 11:21:20.570 | INFO     | src.policies:train:109 - Episode 326\n",
      "2021-08-25 11:21:20.585 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:20.586 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:21:20.587 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.31\n",
      "2021-08-25 11:21:20.588 | INFO     | src.policies:train:109 - Episode 327\n",
      "2021-08-25 11:21:20.614 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:20.615 | INFO     | src.policies:train:121 - Mean episode return: 60.0\n",
      "2021-08-25 11:21:20.616 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.7\n",
      "2021-08-25 11:21:20.617 | WARNING  | src.policies:train:131 - The actual batch size is 221, instead of 200\n",
      "2021-08-25 11:21:20.625 | INFO     | src.policies:train:157 - Total loss: 1.0023516416549683\n",
      "2021-08-25 11:21:20.628 | INFO     | src.policies:train:103 - Epoch 38 / 800\n",
      "2021-08-25 11:21:20.629 | INFO     | src.policies:train:109 - Episode 328\n",
      "2021-08-25 11:21:20.637 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:20.638 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:20.639 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.49\n",
      "2021-08-25 11:21:20.640 | INFO     | src.policies:train:109 - Episode 329\n",
      "2021-08-25 11:21:20.655 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:20.656 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 11:21:20.657 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.56\n",
      "2021-08-25 11:21:20.658 | INFO     | src.policies:train:109 - Episode 330\n",
      "2021-08-25 11:21:20.684 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:20.685 | INFO     | src.policies:train:121 - Mean episode return: 58.0\n",
      "2021-08-25 11:21:20.686 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.7\n",
      "2021-08-25 11:21:20.687 | INFO     | src.policies:train:109 - Episode 331\n",
      "2021-08-25 11:21:20.699 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:20.700 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:20.701 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.66\n",
      "2021-08-25 11:21:20.702 | INFO     | src.policies:train:109 - Episode 332\n",
      "2021-08-25 11:21:20.718 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:20.719 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 11:21:20.720 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.41\n",
      "2021-08-25 11:21:20.721 | INFO     | src.policies:train:109 - Episode 333\n",
      "2021-08-25 11:21:20.734 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:20.735 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:21:20.737 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.48\n",
      "2021-08-25 11:21:20.738 | INFO     | src.policies:train:109 - Episode 334\n",
      "2021-08-25 11:21:20.745 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:20.746 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:20.747 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.48\n",
      "2021-08-25 11:21:20.748 | INFO     | src.policies:train:109 - Episode 335\n",
      "2021-08-25 11:21:20.757 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:20.758 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:20.759 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.35\n",
      "2021-08-25 11:21:20.760 | INFO     | src.policies:train:109 - Episode 336\n",
      "2021-08-25 11:21:20.771 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:20.773 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:21:20.773 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.39\n",
      "2021-08-25 11:21:20.774 | WARNING  | src.policies:train:131 - The actual batch size is 215, instead of 200\n",
      "2021-08-25 11:21:20.783 | INFO     | src.policies:train:157 - Total loss: 1.002211570739746\n",
      "2021-08-25 11:21:20.786 | INFO     | src.policies:train:103 - Epoch 39 / 800\n",
      "2021-08-25 11:21:20.787 | INFO     | src.policies:train:109 - Episode 337\n",
      "2021-08-25 11:21:20.797 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:20.798 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:21:20.799 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.36\n",
      "2021-08-25 11:21:20.800 | INFO     | src.policies:train:109 - Episode 338\n",
      "2021-08-25 11:21:20.825 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:20.826 | INFO     | src.policies:train:121 - Mean episode return: 58.0\n",
      "2021-08-25 11:21:20.827 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.66\n",
      "2021-08-25 11:21:20.828 | INFO     | src.policies:train:109 - Episode 339\n",
      "2021-08-25 11:21:20.844 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:20.845 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:21:20.846 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.83\n",
      "2021-08-25 11:21:20.847 | INFO     | src.policies:train:109 - Episode 340\n",
      "2021-08-25 11:21:20.857 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:20.859 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:20.859 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.77\n",
      "2021-08-25 11:21:20.860 | INFO     | src.policies:train:109 - Episode 341\n",
      "2021-08-25 11:21:20.882 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:20.883 | INFO     | src.policies:train:121 - Mean episode return: 48.0\n",
      "2021-08-25 11:21:20.884 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.01\n",
      "2021-08-25 11:21:20.885 | INFO     | src.policies:train:109 - Episode 342\n",
      "2021-08-25 11:21:20.896 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:20.898 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:21:20.898 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.76\n",
      "2021-08-25 11:21:20.900 | INFO     | src.policies:train:109 - Episode 343\n",
      "2021-08-25 11:21:20.908 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:20.910 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:20.911 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.72\n",
      "2021-08-25 11:21:20.912 | WARNING  | src.policies:train:131 - The actual batch size is 202, instead of 200\n",
      "2021-08-25 11:21:20.920 | INFO     | src.policies:train:157 - Total loss: 1.0019372701644897\n",
      "2021-08-25 11:21:20.923 | INFO     | src.policies:train:103 - Epoch 40 / 800\n",
      "2021-08-25 11:21:20.924 | INFO     | src.policies:train:109 - Episode 344\n",
      "2021-08-25 11:21:20.934 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:20.935 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:21:20.936 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.79\n",
      "2021-08-25 11:21:20.937 | INFO     | src.policies:train:109 - Episode 345\n",
      "2021-08-25 11:21:20.954 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:20.956 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 11:21:20.958 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.7\n",
      "2021-08-25 11:21:20.959 | INFO     | src.policies:train:109 - Episode 346\n",
      "2021-08-25 11:21:20.971 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:20.973 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:21:20.974 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.82\n",
      "2021-08-25 11:21:20.975 | INFO     | src.policies:train:109 - Episode 347\n",
      "2021-08-25 11:21:20.989 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:20.991 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 11:21:20.992 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.91\n",
      "2021-08-25 11:21:20.992 | INFO     | src.policies:train:109 - Episode 348\n",
      "2021-08-25 11:21:21.002 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:21.004 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:21:21.005 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.94\n",
      "2021-08-25 11:21:21.006 | INFO     | src.policies:train:109 - Episode 349\n",
      "2021-08-25 11:21:21.017 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:21.019 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:21:21.019 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.96\n",
      "2021-08-25 11:21:21.020 | INFO     | src.policies:train:109 - Episode 350\n",
      "2021-08-25 11:21:21.035 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:21.036 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 11:21:21.037 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.9\n",
      "2021-08-25 11:21:21.038 | INFO     | src.policies:train:109 - Episode 351\n",
      "2021-08-25 11:21:21.052 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:21.053 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:21:21.054 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.47\n",
      "2021-08-25 11:21:21.055 | INFO     | src.policies:train:109 - Episode 352\n",
      "2021-08-25 11:21:21.072 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:21.073 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:21.074 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.48\n",
      "2021-08-25 11:21:21.076 | WARNING  | src.policies:train:131 - The actual batch size is 227, instead of 200\n",
      "2021-08-25 11:21:21.084 | INFO     | src.policies:train:157 - Total loss: 1.0024771690368652\n",
      "2021-08-25 11:21:21.087 | INFO     | src.policies:train:103 - Epoch 41 / 800\n",
      "2021-08-25 11:21:21.088 | INFO     | src.policies:train:109 - Episode 353\n",
      "2021-08-25 11:21:21.100 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:21.102 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:21:21.103 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.53\n",
      "2021-08-25 11:21:21.104 | INFO     | src.policies:train:109 - Episode 354\n",
      "2021-08-25 11:21:21.117 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:21.119 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 11:21:21.119 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.65\n",
      "2021-08-25 11:21:21.120 | INFO     | src.policies:train:109 - Episode 355\n",
      "2021-08-25 11:21:21.139 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:21.141 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 11:21:21.142 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.8\n",
      "2021-08-25 11:21:21.143 | INFO     | src.policies:train:109 - Episode 356\n",
      "2021-08-25 11:21:21.154 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:21.155 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:21:21.156 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.69\n",
      "2021-08-25 11:21:21.157 | INFO     | src.policies:train:109 - Episode 357\n",
      "2021-08-25 11:21:21.189 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:21.191 | INFO     | src.policies:train:121 - Mean episode return: 77.0\n",
      "2021-08-25 11:21:21.192 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.29\n",
      "2021-08-25 11:21:21.193 | INFO     | src.policies:train:109 - Episode 358\n",
      "2021-08-25 11:21:21.204 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:21.206 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:21:21.207 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.92\n",
      "2021-08-25 11:21:21.208 | WARNING  | src.policies:train:131 - The actual batch size is 210, instead of 200\n",
      "2021-08-25 11:21:21.215 | INFO     | src.policies:train:157 - Total loss: 1.002119541168213\n",
      "2021-08-25 11:21:21.219 | INFO     | src.policies:train:103 - Epoch 42 / 800\n",
      "2021-08-25 11:21:21.220 | INFO     | src.policies:train:109 - Episode 359\n",
      "2021-08-25 11:21:21.229 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:21.230 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:21.231 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.79\n",
      "2021-08-25 11:21:21.232 | INFO     | src.policies:train:109 - Episode 360\n",
      "2021-08-25 11:21:21.246 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:21.247 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:21:21.248 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.84\n",
      "2021-08-25 11:21:21.249 | INFO     | src.policies:train:109 - Episode 361\n",
      "2021-08-25 11:21:21.260 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:21.261 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:21:21.262 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.63\n",
      "2021-08-25 11:21:21.263 | INFO     | src.policies:train:109 - Episode 362\n",
      "2021-08-25 11:21:21.277 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:21.278 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:21:21.280 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.65\n",
      "2021-08-25 11:21:21.280 | INFO     | src.policies:train:109 - Episode 363\n",
      "2021-08-25 11:21:21.290 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:21.292 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:21.293 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.57\n",
      "2021-08-25 11:21:21.294 | INFO     | src.policies:train:109 - Episode 364\n",
      "2021-08-25 11:21:21.306 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:21.307 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:21:21.308 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.66\n",
      "2021-08-25 11:21:21.309 | INFO     | src.policies:train:109 - Episode 365\n",
      "2021-08-25 11:21:21.333 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:21.334 | INFO     | src.policies:train:121 - Mean episode return: 52.0\n",
      "2021-08-25 11:21:21.335 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.03\n",
      "2021-08-25 11:21:21.336 | INFO     | src.policies:train:109 - Episode 366\n",
      "2021-08-25 11:21:21.346 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:21.347 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:21:21.348 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.0\n",
      "2021-08-25 11:21:21.349 | INFO     | src.policies:train:109 - Episode 367\n",
      "2021-08-25 11:21:21.379 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:21.381 | INFO     | src.policies:train:121 - Mean episode return: 71.0\n",
      "2021-08-25 11:21:21.382 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.45\n",
      "2021-08-25 11:21:21.382 | WARNING  | src.policies:train:131 - The actual batch size is 257, instead of 200\n",
      "2021-08-25 11:21:21.390 | INFO     | src.policies:train:157 - Total loss: 1.0030032396316528\n",
      "2021-08-25 11:21:21.394 | INFO     | src.policies:train:103 - Epoch 43 / 800\n",
      "2021-08-25 11:21:21.395 | INFO     | src.policies:train:109 - Episode 368\n",
      "2021-08-25 11:21:21.408 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:21.410 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 11:21:21.411 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.37\n",
      "2021-08-25 11:21:21.412 | INFO     | src.policies:train:109 - Episode 369\n",
      "2021-08-25 11:21:21.428 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:21.430 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 11:21:21.431 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.55\n",
      "2021-08-25 11:21:21.431 | INFO     | src.policies:train:109 - Episode 370\n",
      "2021-08-25 11:21:21.440 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:21.441 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:21:21.442 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.48\n",
      "2021-08-25 11:21:21.443 | INFO     | src.policies:train:109 - Episode 371\n",
      "2021-08-25 11:21:21.452 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:21.454 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:21.455 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.28\n",
      "2021-08-25 11:21:21.456 | INFO     | src.policies:train:109 - Episode 372\n",
      "2021-08-25 11:21:21.474 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:21.476 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 11:21:21.477 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:21.477 | INFO     | src.policies:train:109 - Episode 373\n",
      "2021-08-25 11:21:21.491 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:21.493 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:21:21.494 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.48\n",
      "2021-08-25 11:21:21.495 | INFO     | src.policies:train:109 - Episode 374\n",
      "2021-08-25 11:21:21.503 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:21.504 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:21.505 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.21\n",
      "2021-08-25 11:21:21.506 | INFO     | src.policies:train:109 - Episode 375\n",
      "2021-08-25 11:21:21.525 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:21.526 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 11:21:21.527 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.29\n",
      "2021-08-25 11:21:21.528 | WARNING  | src.policies:train:131 - The actual batch size is 208, instead of 200\n",
      "2021-08-25 11:21:21.535 | INFO     | src.policies:train:157 - Total loss: 1.002069115638733\n",
      "2021-08-25 11:21:21.538 | INFO     | src.policies:train:103 - Epoch 44 / 800\n",
      "2021-08-25 11:21:21.539 | INFO     | src.policies:train:109 - Episode 376\n",
      "2021-08-25 11:21:21.547 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:21.548 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:21:21.549 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.28\n",
      "2021-08-25 11:21:21.550 | INFO     | src.policies:train:109 - Episode 377\n",
      "2021-08-25 11:21:21.563 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:21.564 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:21:21.565 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.19\n",
      "2021-08-25 11:21:21.566 | INFO     | src.policies:train:109 - Episode 378\n",
      "2021-08-25 11:21:21.592 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:21.594 | INFO     | src.policies:train:121 - Mean episode return: 62.0\n",
      "2021-08-25 11:21:21.595 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.63\n",
      "2021-08-25 11:21:21.595 | INFO     | src.policies:train:109 - Episode 379\n",
      "2021-08-25 11:21:21.603 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:21.605 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:21.606 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.43\n",
      "2021-08-25 11:21:21.607 | INFO     | src.policies:train:109 - Episode 380\n",
      "2021-08-25 11:21:21.620 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:21.621 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:21:21.622 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.29\n",
      "2021-08-25 11:21:21.623 | INFO     | src.policies:train:109 - Episode 381\n",
      "2021-08-25 11:21:21.638 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:21.640 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 11:21:21.640 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.43\n",
      "2021-08-25 11:21:21.642 | INFO     | src.policies:train:109 - Episode 382\n",
      "2021-08-25 11:21:21.655 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:21.657 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:21:21.658 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.15\n",
      "2021-08-25 11:21:21.658 | INFO     | src.policies:train:109 - Episode 383\n",
      "2021-08-25 11:21:21.675 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:21.676 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 11:21:21.677 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.39\n",
      "2021-08-25 11:21:21.678 | WARNING  | src.policies:train:131 - The actual batch size is 228, instead of 200\n",
      "2021-08-25 11:21:21.685 | INFO     | src.policies:train:157 - Total loss: 1.002494215965271\n",
      "2021-08-25 11:21:21.689 | INFO     | src.policies:train:103 - Epoch 45 / 800\n",
      "2021-08-25 11:21:21.690 | INFO     | src.policies:train:109 - Episode 384\n",
      "2021-08-25 11:21:21.700 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:21.701 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:21:21.702 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.29\n",
      "2021-08-25 11:21:21.703 | INFO     | src.policies:train:109 - Episode 385\n",
      "2021-08-25 11:21:21.712 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:21.714 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:21.715 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.76\n",
      "2021-08-25 11:21:21.715 | INFO     | src.policies:train:109 - Episode 386\n",
      "2021-08-25 11:21:21.725 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:21.726 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:21.727 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.48\n",
      "2021-08-25 11:21:21.728 | INFO     | src.policies:train:109 - Episode 387\n",
      "2021-08-25 11:21:21.738 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:21.739 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:21.740 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.49\n",
      "2021-08-25 11:21:21.741 | INFO     | src.policies:train:109 - Episode 388\n",
      "2021-08-25 11:21:21.752 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:21.754 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:21:21.755 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.25\n",
      "2021-08-25 11:21:21.756 | INFO     | src.policies:train:109 - Episode 389\n",
      "2021-08-25 11:21:21.766 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:21.767 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:21.768 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.99\n",
      "2021-08-25 11:21:21.769 | INFO     | src.policies:train:109 - Episode 390\n",
      "2021-08-25 11:21:21.796 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:21.797 | INFO     | src.policies:train:121 - Mean episode return: 61.0\n",
      "2021-08-25 11:21:21.798 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.19\n",
      "2021-08-25 11:21:21.799 | INFO     | src.policies:train:109 - Episode 391\n",
      "2021-08-25 11:21:21.809 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:21.810 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:21.811 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.02\n",
      "2021-08-25 11:21:21.812 | INFO     | src.policies:train:109 - Episode 392\n",
      "2021-08-25 11:21:21.837 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:21.839 | INFO     | src.policies:train:121 - Mean episode return: 59.0\n",
      "2021-08-25 11:21:21.840 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.42\n",
      "2021-08-25 11:21:21.841 | WARNING  | src.policies:train:131 - The actual batch size is 237, instead of 200\n",
      "2021-08-25 11:21:21.849 | INFO     | src.policies:train:157 - Total loss: 1.002625823020935\n",
      "2021-08-25 11:21:21.852 | INFO     | src.policies:train:103 - Epoch 46 / 800\n",
      "2021-08-25 11:21:21.853 | INFO     | src.policies:train:109 - Episode 393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:21.860 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:21.861 | INFO     | src.policies:train:121 - Mean episode return: 9.0\n",
      "2021-08-25 11:21:21.862 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.13\n",
      "2021-08-25 11:21:21.863 | INFO     | src.policies:train:109 - Episode 394\n",
      "2021-08-25 11:21:21.873 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:21.874 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:21.875 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.84\n",
      "2021-08-25 11:21:21.876 | INFO     | src.policies:train:109 - Episode 395\n",
      "2021-08-25 11:21:21.886 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:21.887 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:21:21.888 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.87\n",
      "2021-08-25 11:21:21.890 | INFO     | src.policies:train:109 - Episode 396\n",
      "2021-08-25 11:21:21.898 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:21.900 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:21.901 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.76\n",
      "2021-08-25 11:21:21.901 | INFO     | src.policies:train:109 - Episode 397\n",
      "2021-08-25 11:21:21.927 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:21.929 | INFO     | src.policies:train:121 - Mean episode return: 58.0\n",
      "2021-08-25 11:21:21.930 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.19\n",
      "2021-08-25 11:21:21.931 | INFO     | src.policies:train:109 - Episode 398\n",
      "2021-08-25 11:21:21.940 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:21.941 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:21:21.942 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.73\n",
      "2021-08-25 11:21:21.943 | INFO     | src.policies:train:109 - Episode 399\n",
      "2021-08-25 11:21:21.955 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:21.956 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:21:21.957 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.81\n",
      "2021-08-25 11:21:21.958 | INFO     | src.policies:train:109 - Episode 400\n",
      "2021-08-25 11:21:21.979 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:21.980 | INFO     | src.policies:train:121 - Mean episode return: 45.0\n",
      "2021-08-25 11:21:21.981 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.02\n",
      "2021-08-25 11:21:21.982 | INFO     | src.policies:train:109 - Episode 401\n",
      "2021-08-25 11:21:21.997 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:21.998 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:21:21.999 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.94\n",
      "2021-08-25 11:21:22.000 | WARNING  | src.policies:train:131 - The actual batch size is 223, instead of 200\n",
      "2021-08-25 11:21:22.008 | INFO     | src.policies:train:157 - Total loss: 1.0023773908615112\n",
      "2021-08-25 11:21:22.011 | INFO     | src.policies:train:103 - Epoch 47 / 800\n",
      "2021-08-25 11:21:22.012 | INFO     | src.policies:train:109 - Episode 402\n",
      "2021-08-25 11:21:22.018 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:22.020 | INFO     | src.policies:train:121 - Mean episode return: 9.0\n",
      "2021-08-25 11:21:22.021 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.75\n",
      "2021-08-25 11:21:22.021 | INFO     | src.policies:train:109 - Episode 403\n",
      "2021-08-25 11:21:22.053 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:22.055 | INFO     | src.policies:train:121 - Mean episode return: 74.0\n",
      "2021-08-25 11:21:22.056 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.34\n",
      "2021-08-25 11:21:22.056 | INFO     | src.policies:train:109 - Episode 404\n",
      "2021-08-25 11:21:22.065 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:22.066 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:22.067 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.28\n",
      "2021-08-25 11:21:22.068 | INFO     | src.policies:train:109 - Episode 405\n",
      "2021-08-25 11:21:22.078 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:22.079 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:22.080 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.08\n",
      "2021-08-25 11:21:22.081 | INFO     | src.policies:train:109 - Episode 406\n",
      "2021-08-25 11:21:22.091 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:22.092 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:22.093 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.1\n",
      "2021-08-25 11:21:22.094 | INFO     | src.policies:train:109 - Episode 407\n",
      "2021-08-25 11:21:22.114 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:22.115 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 11:21:22.116 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.15\n",
      "2021-08-25 11:21:22.117 | INFO     | src.policies:train:109 - Episode 408\n",
      "2021-08-25 11:21:22.137 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:22.138 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 11:21:22.139 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.12\n",
      "2021-08-25 11:21:22.140 | WARNING  | src.policies:train:131 - The actual batch size is 207, instead of 200\n",
      "2021-08-25 11:21:22.147 | INFO     | src.policies:train:157 - Total loss: 1.0020315647125244\n",
      "2021-08-25 11:21:22.150 | INFO     | src.policies:train:103 - Epoch 48 / 800\n",
      "2021-08-25 11:21:22.151 | INFO     | src.policies:train:109 - Episode 409\n",
      "2021-08-25 11:21:22.161 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:22.162 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:22.163 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.19\n",
      "2021-08-25 11:21:22.164 | INFO     | src.policies:train:109 - Episode 410\n",
      "2021-08-25 11:21:22.184 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:22.185 | INFO     | src.policies:train:121 - Mean episode return: 45.0\n",
      "2021-08-25 11:21:22.186 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.13\n",
      "2021-08-25 11:21:22.187 | INFO     | src.policies:train:109 - Episode 411\n",
      "2021-08-25 11:21:22.198 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:22.199 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:21:22.200 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.01\n",
      "2021-08-25 11:21:22.201 | INFO     | src.policies:train:109 - Episode 412\n",
      "2021-08-25 11:21:22.216 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:22.217 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 11:21:22.218 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.89\n",
      "2021-08-25 11:21:22.219 | INFO     | src.policies:train:109 - Episode 413\n",
      "2021-08-25 11:21:22.228 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:22.229 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:22.230 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.91\n",
      "2021-08-25 11:21:22.231 | INFO     | src.policies:train:109 - Episode 414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:22.243 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:22.244 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:21:22.245 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.98\n",
      "2021-08-25 11:21:22.246 | INFO     | src.policies:train:109 - Episode 415\n",
      "2021-08-25 11:21:22.253 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:22.254 | INFO     | src.policies:train:121 - Mean episode return: 9.0\n",
      "2021-08-25 11:21:22.255 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.85\n",
      "2021-08-25 11:21:22.256 | INFO     | src.policies:train:109 - Episode 416\n",
      "2021-08-25 11:21:22.265 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:22.266 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:21:22.267 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.71\n",
      "2021-08-25 11:21:22.268 | INFO     | src.policies:train:109 - Episode 417\n",
      "2021-08-25 11:21:22.278 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:22.279 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:22.280 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.73\n",
      "2021-08-25 11:21:22.281 | INFO     | src.policies:train:109 - Episode 418\n",
      "2021-08-25 11:21:22.298 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:22.300 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 11:21:22.300 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.89\n",
      "2021-08-25 11:21:22.301 | WARNING  | src.policies:train:131 - The actual batch size is 218, instead of 200\n",
      "2021-08-25 11:21:22.309 | INFO     | src.policies:train:157 - Total loss: 1.0022927522659302\n",
      "2021-08-25 11:21:22.312 | INFO     | src.policies:train:103 - Epoch 49 / 800\n",
      "2021-08-25 11:21:22.314 | INFO     | src.policies:train:109 - Episode 419\n",
      "2021-08-25 11:21:22.322 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:22.324 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:22.325 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.68\n",
      "2021-08-25 11:21:22.326 | INFO     | src.policies:train:109 - Episode 420\n",
      "2021-08-25 11:21:22.345 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:22.346 | INFO     | src.policies:train:121 - Mean episode return: 42.0\n",
      "2021-08-25 11:21:22.347 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.01\n",
      "2021-08-25 11:21:22.348 | INFO     | src.policies:train:109 - Episode 421\n",
      "2021-08-25 11:21:22.358 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:22.359 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:22.360 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.04\n",
      "2021-08-25 11:21:22.361 | INFO     | src.policies:train:109 - Episode 422\n",
      "2021-08-25 11:21:22.375 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:22.376 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:21:22.377 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.1\n",
      "2021-08-25 11:21:22.378 | INFO     | src.policies:train:109 - Episode 423\n",
      "2021-08-25 11:21:22.391 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:22.392 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:21:22.393 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.03\n",
      "2021-08-25 11:21:22.395 | INFO     | src.policies:train:109 - Episode 424\n",
      "2021-08-25 11:21:22.406 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:22.408 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:21:22.409 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.92\n",
      "2021-08-25 11:21:22.410 | INFO     | src.policies:train:109 - Episode 425\n",
      "2021-08-25 11:21:22.433 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:22.434 | INFO     | src.policies:train:121 - Mean episode return: 48.0\n",
      "2021-08-25 11:21:22.435 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.1\n",
      "2021-08-25 11:21:22.436 | INFO     | src.policies:train:109 - Episode 426\n",
      "2021-08-25 11:21:22.445 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:22.446 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:21:22.447 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.94\n",
      "2021-08-25 11:21:22.448 | WARNING  | src.policies:train:131 - The actual batch size is 202, instead of 200\n",
      "2021-08-25 11:21:22.456 | INFO     | src.policies:train:157 - Total loss: 1.001937985420227\n",
      "2021-08-25 11:21:22.460 | INFO     | src.policies:train:103 - Epoch 50 / 800\n",
      "2021-08-25 11:21:22.461 | INFO     | src.policies:train:109 - Episode 427\n",
      "2021-08-25 11:21:22.473 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:22.474 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:21:22.475 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.57\n",
      "2021-08-25 11:21:22.476 | INFO     | src.policies:train:109 - Episode 428\n",
      "2021-08-25 11:21:22.496 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:22.497 | INFO     | src.policies:train:121 - Mean episode return: 41.0\n",
      "2021-08-25 11:21:22.499 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.86\n",
      "2021-08-25 11:21:22.500 | INFO     | src.policies:train:109 - Episode 429\n",
      "2021-08-25 11:21:22.512 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:22.513 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:22.514 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.74\n",
      "2021-08-25 11:21:22.515 | INFO     | src.policies:train:109 - Episode 430\n",
      "2021-08-25 11:21:22.535 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:22.536 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 11:21:22.538 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.5\n",
      "2021-08-25 11:21:22.539 | INFO     | src.policies:train:109 - Episode 431\n",
      "2021-08-25 11:21:22.557 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:22.559 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 11:21:22.560 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.63\n",
      "2021-08-25 11:21:22.561 | INFO     | src.policies:train:109 - Episode 432\n",
      "2021-08-25 11:21:22.584 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:22.586 | INFO     | src.policies:train:121 - Mean episode return: 43.0\n",
      "2021-08-25 11:21:22.587 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.75\n",
      "2021-08-25 11:21:22.588 | INFO     | src.policies:train:109 - Episode 433\n",
      "2021-08-25 11:21:22.600 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:22.602 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:21:22.604 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.71\n",
      "2021-08-25 11:21:22.605 | WARNING  | src.policies:train:131 - The actual batch size is 207, instead of 200\n",
      "2021-08-25 11:21:22.616 | INFO     | src.policies:train:157 - Total loss: 1.00202476978302\n",
      "2021-08-25 11:21:22.620 | INFO     | src.policies:train:103 - Epoch 51 / 800\n",
      "2021-08-25 11:21:22.622 | INFO     | src.policies:train:109 - Episode 434\n",
      "2021-08-25 11:21:22.638 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:22.639 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 11:21:22.641 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.9\n",
      "2021-08-25 11:21:22.642 | INFO     | src.policies:train:109 - Episode 435\n",
      "2021-08-25 11:21:22.657 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:22.658 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:21:22.660 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.02\n",
      "2021-08-25 11:21:22.661 | INFO     | src.policies:train:109 - Episode 436\n",
      "2021-08-25 11:21:22.690 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:22.691 | INFO     | src.policies:train:121 - Mean episode return: 62.0\n",
      "2021-08-25 11:21:22.692 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.43\n",
      "2021-08-25 11:21:22.693 | INFO     | src.policies:train:109 - Episode 437\n",
      "2021-08-25 11:21:22.705 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:22.706 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:22.707 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.4\n",
      "2021-08-25 11:21:22.708 | INFO     | src.policies:train:109 - Episode 438\n",
      "2021-08-25 11:21:22.719 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:22.720 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:21:22.721 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.0\n",
      "2021-08-25 11:21:22.722 | INFO     | src.policies:train:109 - Episode 439\n",
      "2021-08-25 11:21:22.729 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:22.730 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:21:22.731 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.82\n",
      "2021-08-25 11:21:22.732 | INFO     | src.policies:train:109 - Episode 440\n",
      "2021-08-25 11:21:22.744 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:22.745 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:21:22.746 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.88\n",
      "2021-08-25 11:21:22.747 | INFO     | src.policies:train:109 - Episode 441\n",
      "2021-08-25 11:21:22.760 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:22.761 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:21:22.762 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.64\n",
      "2021-08-25 11:21:22.763 | WARNING  | src.policies:train:131 - The actual batch size is 209, instead of 200\n",
      "2021-08-25 11:21:22.770 | INFO     | src.policies:train:157 - Total loss: 1.0020670890808105\n",
      "2021-08-25 11:21:22.773 | INFO     | src.policies:train:103 - Epoch 52 / 800\n",
      "2021-08-25 11:21:22.775 | INFO     | src.policies:train:109 - Episode 442\n",
      "2021-08-25 11:21:22.784 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:22.786 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:21:22.787 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.64\n",
      "2021-08-25 11:21:22.787 | INFO     | src.policies:train:109 - Episode 443\n",
      "2021-08-25 11:21:22.798 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:22.800 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:21:22.801 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.71\n",
      "2021-08-25 11:21:22.802 | INFO     | src.policies:train:109 - Episode 444\n",
      "2021-08-25 11:21:22.814 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:22.815 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:21:22.816 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.75\n",
      "2021-08-25 11:21:22.817 | INFO     | src.policies:train:109 - Episode 445\n",
      "2021-08-25 11:21:22.831 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:22.832 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:21:22.833 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.68\n",
      "2021-08-25 11:21:22.834 | INFO     | src.policies:train:109 - Episode 446\n",
      "2021-08-25 11:21:22.847 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:22.848 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:21:22.849 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.65\n",
      "2021-08-25 11:21:22.850 | INFO     | src.policies:train:109 - Episode 447\n",
      "2021-08-25 11:21:22.859 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:22.860 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:22.861 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.52\n",
      "2021-08-25 11:21:22.862 | INFO     | src.policies:train:109 - Episode 448\n",
      "2021-08-25 11:21:22.873 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:22.875 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:21:22.876 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.59\n",
      "2021-08-25 11:21:22.877 | INFO     | src.policies:train:109 - Episode 449\n",
      "2021-08-25 11:21:22.912 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:22.913 | INFO     | src.policies:train:121 - Mean episode return: 79.0\n",
      "2021-08-25 11:21:22.914 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.14\n",
      "2021-08-25 11:21:22.915 | WARNING  | src.policies:train:131 - The actual batch size is 220, instead of 200\n",
      "2021-08-25 11:21:22.922 | INFO     | src.policies:train:157 - Total loss: 1.0023359060287476\n",
      "2021-08-25 11:21:22.925 | INFO     | src.policies:train:103 - Epoch 53 / 800\n",
      "2021-08-25 11:21:22.926 | INFO     | src.policies:train:109 - Episode 450\n",
      "2021-08-25 11:21:22.939 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:22.940 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:21:22.941 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.12\n",
      "2021-08-25 11:21:22.942 | INFO     | src.policies:train:109 - Episode 451\n",
      "2021-08-25 11:21:22.961 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:22.963 | INFO     | src.policies:train:121 - Mean episode return: 43.0\n",
      "2021-08-25 11:21:22.964 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.29\n",
      "2021-08-25 11:21:22.965 | INFO     | src.policies:train:109 - Episode 452\n",
      "2021-08-25 11:21:22.974 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:22.975 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:22.976 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.11\n",
      "2021-08-25 11:21:22.977 | INFO     | src.policies:train:109 - Episode 453\n",
      "2021-08-25 11:21:23.007 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:23.008 | INFO     | src.policies:train:121 - Mean episode return: 69.0\n",
      "2021-08-25 11:21:23.009 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.54\n",
      "2021-08-25 11:21:23.010 | INFO     | src.policies:train:109 - Episode 454\n",
      "2021-08-25 11:21:23.027 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:23.028 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 11:21:23.029 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.57\n",
      "2021-08-25 11:21:23.030 | INFO     | src.policies:train:109 - Episode 455\n",
      "2021-08-25 11:21:23.053 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:23.054 | INFO     | src.policies:train:121 - Mean episode return: 51.0\n",
      "2021-08-25 11:21:23.056 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.68\n",
      "2021-08-25 11:21:23.057 | WARNING  | src.policies:train:131 - The actual batch size is 235, instead of 200\n",
      "2021-08-25 11:21:23.064 | INFO     | src.policies:train:157 - Total loss: 1.00259530544281\n",
      "2021-08-25 11:21:23.067 | INFO     | src.policies:train:103 - Epoch 54 / 800\n",
      "2021-08-25 11:21:23.068 | INFO     | src.policies:train:109 - Episode 456\n",
      "2021-08-25 11:21:23.075 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:23.076 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:21:23.077 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.59\n",
      "2021-08-25 11:21:23.078 | INFO     | src.policies:train:109 - Episode 457\n",
      "2021-08-25 11:21:23.086 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:23.087 | INFO     | src.policies:train:121 - Mean episode return: 9.0\n",
      "2021-08-25 11:21:23.088 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.91\n",
      "2021-08-25 11:21:23.089 | INFO     | src.policies:train:109 - Episode 458\n",
      "2021-08-25 11:21:23.099 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:23.101 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:23.101 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.88\n",
      "2021-08-25 11:21:23.102 | INFO     | src.policies:train:109 - Episode 459\n",
      "2021-08-25 11:21:23.127 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:23.129 | INFO     | src.policies:train:121 - Mean episode return: 57.0\n",
      "2021-08-25 11:21:23.130 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.28\n",
      "2021-08-25 11:21:23.131 | INFO     | src.policies:train:109 - Episode 460\n",
      "2021-08-25 11:21:23.148 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:23.149 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 11:21:23.150 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.36\n",
      "2021-08-25 11:21:23.151 | INFO     | src.policies:train:109 - Episode 461\n",
      "2021-08-25 11:21:23.164 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:23.166 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:21:23.167 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.42\n",
      "2021-08-25 11:21:23.167 | INFO     | src.policies:train:109 - Episode 462\n",
      "2021-08-25 11:21:23.178 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:23.179 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:23.180 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.33\n",
      "2021-08-25 11:21:23.181 | INFO     | src.policies:train:109 - Episode 463\n",
      "2021-08-25 11:21:23.203 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:23.204 | INFO     | src.policies:train:121 - Mean episode return: 52.0\n",
      "2021-08-25 11:21:23.205 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.7\n",
      "2021-08-25 11:21:23.206 | WARNING  | src.policies:train:131 - The actual batch size is 219, instead of 200\n",
      "2021-08-25 11:21:23.214 | INFO     | src.policies:train:157 - Total loss: 1.0022900104522705\n",
      "2021-08-25 11:21:23.217 | INFO     | src.policies:train:103 - Epoch 55 / 800\n",
      "2021-08-25 11:21:23.219 | INFO     | src.policies:train:109 - Episode 464\n",
      "2021-08-25 11:21:23.236 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:23.237 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 11:21:23.238 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.85\n",
      "2021-08-25 11:21:23.239 | INFO     | src.policies:train:109 - Episode 465\n",
      "2021-08-25 11:21:23.246 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:23.247 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 11:21:23.248 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.43\n",
      "2021-08-25 11:21:23.249 | INFO     | src.policies:train:109 - Episode 466\n",
      "2021-08-25 11:21:23.263 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:23.265 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:21:23.266 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.56\n",
      "2021-08-25 11:21:23.266 | INFO     | src.policies:train:109 - Episode 467\n",
      "2021-08-25 11:21:23.276 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:23.277 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:23.278 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.0\n",
      "2021-08-25 11:21:23.279 | INFO     | src.policies:train:109 - Episode 468\n",
      "2021-08-25 11:21:23.289 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:23.290 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:21:23.291 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.84\n",
      "2021-08-25 11:21:23.292 | INFO     | src.policies:train:109 - Episode 469\n",
      "2021-08-25 11:21:23.302 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:23.304 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:23.304 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.65\n",
      "2021-08-25 11:21:23.305 | INFO     | src.policies:train:109 - Episode 470\n",
      "2021-08-25 11:21:23.317 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:23.318 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:21:23.319 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.74\n",
      "2021-08-25 11:21:23.320 | INFO     | src.policies:train:109 - Episode 471\n",
      "2021-08-25 11:21:23.329 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:23.331 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:21:23.332 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.71\n",
      "2021-08-25 11:21:23.333 | INFO     | src.policies:train:109 - Episode 472\n",
      "2021-08-25 11:21:23.360 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:23.361 | INFO     | src.policies:train:121 - Mean episode return: 61.0\n",
      "2021-08-25 11:21:23.362 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.95\n",
      "2021-08-25 11:21:23.363 | WARNING  | src.policies:train:131 - The actual batch size is 212, instead of 200\n",
      "2021-08-25 11:21:23.370 | INFO     | src.policies:train:157 - Total loss: 1.0021185874938965\n",
      "2021-08-25 11:21:23.374 | INFO     | src.policies:train:103 - Epoch 56 / 800\n",
      "2021-08-25 11:21:23.375 | INFO     | src.policies:train:109 - Episode 473\n",
      "2021-08-25 11:21:23.381 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:23.383 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 11:21:23.384 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.79\n",
      "2021-08-25 11:21:23.385 | INFO     | src.policies:train:109 - Episode 474\n",
      "2021-08-25 11:21:23.395 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:23.397 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:21:23.398 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.85\n",
      "2021-08-25 11:21:23.399 | INFO     | src.policies:train:109 - Episode 475\n",
      "2021-08-25 11:21:23.411 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:23.412 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:23.413 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.66\n",
      "2021-08-25 11:21:23.414 | INFO     | src.policies:train:109 - Episode 476\n",
      "2021-08-25 11:21:23.423 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:23.425 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:23.425 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.69\n",
      "2021-08-25 11:21:23.426 | INFO     | src.policies:train:109 - Episode 477\n",
      "2021-08-25 11:21:23.440 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:23.441 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:21:23.443 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.69\n",
      "2021-08-25 11:21:23.444 | INFO     | src.policies:train:109 - Episode 478\n",
      "2021-08-25 11:21:23.458 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:23.459 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 11:21:23.460 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.35\n",
      "2021-08-25 11:21:23.461 | INFO     | src.policies:train:109 - Episode 479\n",
      "2021-08-25 11:21:23.489 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:23.491 | INFO     | src.policies:train:121 - Mean episode return: 65.0\n",
      "2021-08-25 11:21:23.492 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.88\n",
      "2021-08-25 11:21:23.493 | INFO     | src.policies:train:109 - Episode 480\n",
      "2021-08-25 11:21:23.502 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:23.503 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:23.504 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.76\n",
      "2021-08-25 11:21:23.505 | INFO     | src.policies:train:109 - Episode 481\n",
      "2021-08-25 11:21:23.519 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:23.521 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:21:23.522 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.73\n",
      "2021-08-25 11:21:23.523 | WARNING  | src.policies:train:131 - The actual batch size is 223, instead of 200\n",
      "2021-08-25 11:21:23.530 | INFO     | src.policies:train:157 - Total loss: 1.0023630857467651\n",
      "2021-08-25 11:21:23.534 | INFO     | src.policies:train:103 - Epoch 57 / 800\n",
      "2021-08-25 11:21:23.535 | INFO     | src.policies:train:109 - Episode 482\n",
      "2021-08-25 11:21:23.546 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:23.547 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:21:23.548 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.68\n",
      "2021-08-25 11:21:23.549 | INFO     | src.policies:train:109 - Episode 483\n",
      "2021-08-25 11:21:23.570 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:23.571 | INFO     | src.policies:train:121 - Mean episode return: 44.0\n",
      "2021-08-25 11:21:23.572 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.77\n",
      "2021-08-25 11:21:23.573 | INFO     | src.policies:train:109 - Episode 484\n",
      "2021-08-25 11:21:23.587 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:23.588 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:21:23.589 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.8\n",
      "2021-08-25 11:21:23.590 | INFO     | src.policies:train:109 - Episode 485\n",
      "2021-08-25 11:21:23.615 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:23.616 | INFO     | src.policies:train:121 - Mean episode return: 54.0\n",
      "2021-08-25 11:21:23.617 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.17\n",
      "2021-08-25 11:21:23.618 | INFO     | src.policies:train:109 - Episode 486\n",
      "2021-08-25 11:21:23.630 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:23.631 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:21:23.632 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.19\n",
      "2021-08-25 11:21:23.633 | INFO     | src.policies:train:109 - Episode 487\n",
      "2021-08-25 11:21:23.655 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:23.656 | INFO     | src.policies:train:121 - Mean episode return: 45.0\n",
      "2021-08-25 11:21:23.657 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.49\n",
      "2021-08-25 11:21:23.658 | WARNING  | src.policies:train:131 - The actual batch size is 205, instead of 200\n",
      "2021-08-25 11:21:23.665 | INFO     | src.policies:train:157 - Total loss: 1.0020147562026978\n",
      "2021-08-25 11:21:23.669 | INFO     | src.policies:train:103 - Epoch 58 / 800\n",
      "2021-08-25 11:21:23.670 | INFO     | src.policies:train:109 - Episode 488\n",
      "2021-08-25 11:21:23.680 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:23.682 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:21:23.683 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.48\n",
      "2021-08-25 11:21:23.683 | INFO     | src.policies:train:109 - Episode 489\n",
      "2021-08-25 11:21:23.701 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:23.703 | INFO     | src.policies:train:121 - Mean episode return: 39.0\n",
      "2021-08-25 11:21:23.704 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.7\n",
      "2021-08-25 11:21:23.705 | INFO     | src.policies:train:109 - Episode 490\n",
      "2021-08-25 11:21:23.715 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:23.716 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:21:23.717 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.27\n",
      "2021-08-25 11:21:23.718 | INFO     | src.policies:train:109 - Episode 491\n",
      "2021-08-25 11:21:23.733 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:23.735 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 11:21:23.735 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.42\n",
      "2021-08-25 11:21:23.736 | INFO     | src.policies:train:109 - Episode 492\n",
      "2021-08-25 11:21:23.745 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:23.746 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:23.747 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.95\n",
      "2021-08-25 11:21:23.748 | INFO     | src.policies:train:109 - Episode 493\n",
      "2021-08-25 11:21:23.757 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:23.758 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:21:23.759 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.99\n",
      "2021-08-25 11:21:23.760 | INFO     | src.policies:train:109 - Episode 494\n",
      "2021-08-25 11:21:23.777 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:23.778 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 11:21:23.779 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.15\n",
      "2021-08-25 11:21:23.780 | INFO     | src.policies:train:109 - Episode 495\n",
      "2021-08-25 11:21:23.792 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:23.793 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:21:23.794 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.15\n",
      "2021-08-25 11:21:23.795 | INFO     | src.policies:train:109 - Episode 496\n",
      "2021-08-25 11:21:23.807 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:23.809 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:23.810 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.22\n",
      "2021-08-25 11:21:23.810 | WARNING  | src.policies:train:131 - The actual batch size is 202, instead of 200\n",
      "2021-08-25 11:21:23.818 | INFO     | src.policies:train:157 - Total loss: 1.0018731355667114\n",
      "2021-08-25 11:21:23.822 | INFO     | src.policies:train:103 - Epoch 59 / 800\n",
      "2021-08-25 11:21:23.823 | INFO     | src.policies:train:109 - Episode 497\n",
      "2021-08-25 11:21:23.841 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:23.842 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 11:21:23.843 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.04\n",
      "2021-08-25 11:21:23.844 | INFO     | src.policies:train:109 - Episode 498\n",
      "2021-08-25 11:21:23.864 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:23.865 | INFO     | src.policies:train:121 - Mean episode return: 41.0\n",
      "2021-08-25 11:21:23.866 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.34\n",
      "2021-08-25 11:21:23.867 | INFO     | src.policies:train:109 - Episode 499\n",
      "2021-08-25 11:21:23.887 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:23.888 | INFO     | src.policies:train:121 - Mean episode return: 41.0\n",
      "2021-08-25 11:21:23.889 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.55\n",
      "2021-08-25 11:21:23.890 | INFO     | src.policies:train:109 - Episode 500\n",
      "2021-08-25 11:21:23.902 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:23.903 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:23.905 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.26\n",
      "2021-08-25 11:21:23.906 | INFO     | src.policies:train:109 - Episode 501\n",
      "2021-08-25 11:21:23.913 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:23.915 | INFO     | src.policies:train:121 - Mean episode return: 9.0\n",
      "2021-08-25 11:21:23.916 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.06\n",
      "2021-08-25 11:21:23.917 | INFO     | src.policies:train:109 - Episode 502\n",
      "2021-08-25 11:21:23.935 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:23.936 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 11:21:23.937 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.34\n",
      "2021-08-25 11:21:23.938 | INFO     | src.policies:train:109 - Episode 503\n",
      "2021-08-25 11:21:23.970 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:23.972 | INFO     | src.policies:train:121 - Mean episode return: 68.0\n",
      "2021-08-25 11:21:23.973 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.28\n",
      "2021-08-25 11:21:23.974 | WARNING  | src.policies:train:131 - The actual batch size is 252, instead of 200\n",
      "2021-08-25 11:21:23.982 | INFO     | src.policies:train:157 - Total loss: 1.0028941631317139\n",
      "2021-08-25 11:21:23.985 | INFO     | src.policies:train:103 - Epoch 60 / 800\n",
      "2021-08-25 11:21:23.986 | INFO     | src.policies:train:109 - Episode 504\n",
      "2021-08-25 11:21:24.000 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:24.001 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 11:21:24.002 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.44\n",
      "2021-08-25 11:21:24.003 | INFO     | src.policies:train:109 - Episode 505\n",
      "2021-08-25 11:21:24.014 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:24.015 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:24.016 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.44\n",
      "2021-08-25 11:21:24.017 | INFO     | src.policies:train:109 - Episode 506\n",
      "2021-08-25 11:21:24.031 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:24.033 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 11:21:24.034 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.53\n",
      "2021-08-25 11:21:24.035 | INFO     | src.policies:train:109 - Episode 507\n",
      "2021-08-25 11:21:24.042 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:24.044 | INFO     | src.policies:train:121 - Mean episode return: 9.0\n",
      "2021-08-25 11:21:24.044 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.22\n",
      "2021-08-25 11:21:24.045 | INFO     | src.policies:train:109 - Episode 508\n",
      "2021-08-25 11:21:24.057 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:24.058 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:21:24.059 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.05\n",
      "2021-08-25 11:21:24.060 | INFO     | src.policies:train:109 - Episode 509\n",
      "2021-08-25 11:21:24.069 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:24.070 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:21:24.071 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.99\n",
      "2021-08-25 11:21:24.072 | INFO     | src.policies:train:109 - Episode 510\n",
      "2021-08-25 11:21:24.090 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:24.091 | INFO     | src.policies:train:121 - Mean episode return: 38.0\n",
      "2021-08-25 11:21:24.092 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.92\n",
      "2021-08-25 11:21:24.093 | INFO     | src.policies:train:109 - Episode 511\n",
      "2021-08-25 11:21:24.123 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:24.125 | INFO     | src.policies:train:121 - Mean episode return: 68.0\n",
      "2021-08-25 11:21:24.126 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.42\n",
      "2021-08-25 11:21:24.126 | WARNING  | src.policies:train:131 - The actual batch size is 218, instead of 200\n",
      "2021-08-25 11:21:24.134 | INFO     | src.policies:train:157 - Total loss: 1.0022772550582886\n",
      "2021-08-25 11:21:24.138 | INFO     | src.policies:train:103 - Epoch 61 / 800\n",
      "2021-08-25 11:21:24.139 | INFO     | src.policies:train:109 - Episode 512\n",
      "2021-08-25 11:21:24.151 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:24.152 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 11:21:24.153 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.39\n",
      "2021-08-25 11:21:24.154 | INFO     | src.policies:train:109 - Episode 513\n",
      "2021-08-25 11:21:24.164 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:24.165 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:21:24.166 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.42\n",
      "2021-08-25 11:21:24.167 | INFO     | src.policies:train:109 - Episode 514\n",
      "2021-08-25 11:21:24.195 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:24.197 | INFO     | src.policies:train:121 - Mean episode return: 64.0\n",
      "2021-08-25 11:21:24.198 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.85\n",
      "2021-08-25 11:21:24.199 | INFO     | src.policies:train:109 - Episode 515\n",
      "2021-08-25 11:21:24.212 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:24.213 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:21:24.214 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.0\n",
      "2021-08-25 11:21:24.215 | INFO     | src.policies:train:109 - Episode 516\n",
      "2021-08-25 11:21:24.224 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:24.225 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:21:24.226 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:24.227 | INFO     | src.policies:train:109 - Episode 517\n",
      "2021-08-25 11:21:24.238 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:24.239 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:21:24.240 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.04\n",
      "2021-08-25 11:21:24.241 | INFO     | src.policies:train:109 - Episode 518\n",
      "2021-08-25 11:21:24.258 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:24.260 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 11:21:24.260 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.03\n",
      "2021-08-25 11:21:24.261 | INFO     | src.policies:train:109 - Episode 519\n",
      "2021-08-25 11:21:24.269 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:24.270 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:21:24.271 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.99\n",
      "2021-08-25 11:21:24.272 | WARNING  | src.policies:train:131 - The actual batch size is 210, instead of 200\n",
      "2021-08-25 11:21:24.280 | INFO     | src.policies:train:157 - Total loss: 1.002042293548584\n",
      "2021-08-25 11:21:24.283 | INFO     | src.policies:train:103 - Epoch 62 / 800\n",
      "2021-08-25 11:21:24.284 | INFO     | src.policies:train:109 - Episode 520\n",
      "2021-08-25 11:21:24.293 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:24.294 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:24.295 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.73\n",
      "2021-08-25 11:21:24.296 | INFO     | src.policies:train:109 - Episode 521\n",
      "2021-08-25 11:21:24.308 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:24.309 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:21:24.310 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.81\n",
      "2021-08-25 11:21:24.311 | INFO     | src.policies:train:109 - Episode 522\n",
      "2021-08-25 11:21:24.320 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:24.322 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:24.323 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.7\n",
      "2021-08-25 11:21:24.324 | INFO     | src.policies:train:109 - Episode 523\n",
      "2021-08-25 11:21:24.346 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:24.347 | INFO     | src.policies:train:121 - Mean episode return: 51.0\n",
      "2021-08-25 11:21:24.348 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.99\n",
      "2021-08-25 11:21:24.349 | INFO     | src.policies:train:109 - Episode 524\n",
      "2021-08-25 11:21:24.360 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:24.361 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:24.362 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.95\n",
      "2021-08-25 11:21:24.363 | INFO     | src.policies:train:109 - Episode 525\n",
      "2021-08-25 11:21:24.373 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:24.375 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:24.376 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.63\n",
      "2021-08-25 11:21:24.377 | INFO     | src.policies:train:109 - Episode 526\n",
      "2021-08-25 11:21:24.399 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:24.401 | INFO     | src.policies:train:121 - Mean episode return: 51.0\n",
      "2021-08-25 11:21:24.401 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.01\n",
      "2021-08-25 11:21:24.403 | INFO     | src.policies:train:109 - Episode 527\n",
      "2021-08-25 11:21:24.417 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:24.418 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:21:24.419 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.02\n",
      "2021-08-25 11:21:24.420 | WARNING  | src.policies:train:131 - The actual batch size is 213, instead of 200\n",
      "2021-08-25 11:21:24.428 | INFO     | src.policies:train:157 - Total loss: 1.0021374225616455\n",
      "2021-08-25 11:21:24.432 | INFO     | src.policies:train:103 - Epoch 63 / 800\n",
      "2021-08-25 11:21:24.433 | INFO     | src.policies:train:109 - Episode 528\n",
      "2021-08-25 11:21:24.444 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:24.445 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:21:24.446 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.81\n",
      "2021-08-25 11:21:24.447 | INFO     | src.policies:train:109 - Episode 529\n",
      "2021-08-25 11:21:24.467 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:24.468 | INFO     | src.policies:train:121 - Mean episode return: 42.0\n",
      "2021-08-25 11:21:24.469 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.07\n",
      "2021-08-25 11:21:24.470 | INFO     | src.policies:train:109 - Episode 530\n",
      "2021-08-25 11:21:24.480 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:24.481 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:21:24.482 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.86\n",
      "2021-08-25 11:21:24.483 | INFO     | src.policies:train:109 - Episode 531\n",
      "2021-08-25 11:21:24.500 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:24.502 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 11:21:24.503 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.88\n",
      "2021-08-25 11:21:24.504 | INFO     | src.policies:train:109 - Episode 532\n",
      "2021-08-25 11:21:24.516 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:24.517 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:21:24.518 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.66\n",
      "2021-08-25 11:21:24.519 | INFO     | src.policies:train:109 - Episode 533\n",
      "2021-08-25 11:21:24.540 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:24.542 | INFO     | src.policies:train:121 - Mean episode return: 47.0\n",
      "2021-08-25 11:21:24.543 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.95\n",
      "2021-08-25 11:21:24.544 | INFO     | src.policies:train:109 - Episode 534\n",
      "2021-08-25 11:21:24.568 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:24.570 | INFO     | src.policies:train:121 - Mean episode return: 51.0\n",
      "2021-08-25 11:21:24.571 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.15\n",
      "2021-08-25 11:21:24.572 | WARNING  | src.policies:train:131 - The actual batch size is 228, instead of 200\n",
      "2021-08-25 11:21:24.580 | INFO     | src.policies:train:157 - Total loss: 1.0024315118789673\n",
      "2021-08-25 11:21:24.583 | INFO     | src.policies:train:103 - Epoch 64 / 800\n",
      "2021-08-25 11:21:24.584 | INFO     | src.policies:train:109 - Episode 535\n",
      "2021-08-25 11:21:24.597 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:24.598 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 11:21:24.599 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.19\n",
      "2021-08-25 11:21:24.600 | INFO     | src.policies:train:109 - Episode 536\n",
      "2021-08-25 11:21:24.612 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:24.613 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:21:24.615 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.75\n",
      "2021-08-25 11:21:24.615 | INFO     | src.policies:train:109 - Episode 537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:24.626 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:24.627 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:21:24.628 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.71\n",
      "2021-08-25 11:21:24.629 | INFO     | src.policies:train:109 - Episode 538\n",
      "2021-08-25 11:21:24.639 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:24.640 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:21:24.641 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.67\n",
      "2021-08-25 11:21:24.643 | INFO     | src.policies:train:109 - Episode 539\n",
      "2021-08-25 11:21:24.663 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:24.664 | INFO     | src.policies:train:121 - Mean episode return: 41.0\n",
      "2021-08-25 11:21:24.665 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.97\n",
      "2021-08-25 11:21:24.666 | INFO     | src.policies:train:109 - Episode 540\n",
      "2021-08-25 11:21:24.682 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:24.683 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:21:24.684 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.04\n",
      "2021-08-25 11:21:24.685 | INFO     | src.policies:train:109 - Episode 541\n",
      "2021-08-25 11:21:24.695 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:24.696 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:24.698 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.96\n",
      "2021-08-25 11:21:24.698 | INFO     | src.policies:train:109 - Episode 542\n",
      "2021-08-25 11:21:24.710 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:24.711 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:24.712 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.94\n",
      "2021-08-25 11:21:24.714 | INFO     | src.policies:train:109 - Episode 543\n",
      "2021-08-25 11:21:24.726 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:24.727 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:21:24.728 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.94\n",
      "2021-08-25 11:21:24.729 | INFO     | src.policies:train:109 - Episode 544\n",
      "2021-08-25 11:21:24.738 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:24.739 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:21:24.740 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.82\n",
      "2021-08-25 11:21:24.741 | WARNING  | src.policies:train:131 - The actual batch size is 206, instead of 200\n",
      "2021-08-25 11:21:24.749 | INFO     | src.policies:train:157 - Total loss: 1.0019410848617554\n",
      "2021-08-25 11:21:24.752 | INFO     | src.policies:train:103 - Epoch 65 / 800\n",
      "2021-08-25 11:21:24.754 | INFO     | src.policies:train:109 - Episode 545\n",
      "2021-08-25 11:21:24.767 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:24.768 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 11:21:24.769 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.83\n",
      "2021-08-25 11:21:24.770 | INFO     | src.policies:train:109 - Episode 546\n",
      "2021-08-25 11:21:24.780 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:24.781 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:24.782 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.74\n",
      "2021-08-25 11:21:24.783 | INFO     | src.policies:train:109 - Episode 547\n",
      "2021-08-25 11:21:24.791 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:24.792 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 11:21:24.793 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.72\n",
      "2021-08-25 11:21:24.795 | INFO     | src.policies:train:109 - Episode 548\n",
      "2021-08-25 11:21:24.804 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:24.805 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 11:21:24.806 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.61\n",
      "2021-08-25 11:21:24.807 | INFO     | src.policies:train:109 - Episode 549\n",
      "2021-08-25 11:21:24.816 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:24.817 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:21:24.818 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.95\n",
      "2021-08-25 11:21:24.819 | INFO     | src.policies:train:109 - Episode 550\n",
      "2021-08-25 11:21:24.829 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:24.830 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:21:24.831 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.83\n",
      "2021-08-25 11:21:24.832 | INFO     | src.policies:train:109 - Episode 551\n",
      "2021-08-25 11:21:24.844 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:24.846 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:24.846 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.57\n",
      "2021-08-25 11:21:24.847 | INFO     | src.policies:train:109 - Episode 552\n",
      "2021-08-25 11:21:24.860 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:24.862 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:21:24.864 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.62\n",
      "2021-08-25 11:21:24.866 | INFO     | src.policies:train:109 - Episode 553\n",
      "2021-08-25 11:21:24.878 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:24.880 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:24.881 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.08\n",
      "2021-08-25 11:21:24.883 | INFO     | src.policies:train:109 - Episode 554\n",
      "2021-08-25 11:21:24.894 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:24.896 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:24.897 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.95\n",
      "2021-08-25 11:21:24.899 | INFO     | src.policies:train:109 - Episode 555\n",
      "2021-08-25 11:21:24.917 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:24.918 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 11:21:24.920 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.8\n",
      "2021-08-25 11:21:24.921 | INFO     | src.policies:train:109 - Episode 556\n",
      "2021-08-25 11:21:24.961 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:24.962 | INFO     | src.policies:train:121 - Mean episode return: 90.0\n",
      "2021-08-25 11:21:24.963 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.59\n",
      "2021-08-25 11:21:24.964 | WARNING  | src.policies:train:131 - The actual batch size is 282, instead of 200\n",
      "2021-08-25 11:21:24.972 | INFO     | src.policies:train:157 - Total loss: 1.0032678842544556\n",
      "2021-08-25 11:21:24.976 | INFO     | src.policies:train:103 - Epoch 66 / 800\n",
      "2021-08-25 11:21:24.977 | INFO     | src.policies:train:109 - Episode 557\n",
      "2021-08-25 11:21:24.987 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:24.988 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:24.989 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.67\n",
      "2021-08-25 11:21:24.990 | INFO     | src.policies:train:109 - Episode 558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:25.012 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:25.013 | INFO     | src.policies:train:121 - Mean episode return: 44.0\n",
      "2021-08-25 11:21:25.014 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.94\n",
      "2021-08-25 11:21:25.015 | INFO     | src.policies:train:109 - Episode 559\n",
      "2021-08-25 11:21:25.034 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:25.036 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 11:21:25.037 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.74\n",
      "2021-08-25 11:21:25.038 | INFO     | src.policies:train:109 - Episode 560\n",
      "2021-08-25 11:21:25.058 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:25.060 | INFO     | src.policies:train:121 - Mean episode return: 41.0\n",
      "2021-08-25 11:21:25.061 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.83\n",
      "2021-08-25 11:21:25.062 | INFO     | src.policies:train:109 - Episode 561\n",
      "2021-08-25 11:21:25.074 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:25.076 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:21:25.076 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.81\n",
      "2021-08-25 11:21:25.078 | INFO     | src.policies:train:109 - Episode 562\n",
      "2021-08-25 11:21:25.088 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:25.089 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:21:25.090 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.78\n",
      "2021-08-25 11:21:25.091 | INFO     | src.policies:train:109 - Episode 563\n",
      "2021-08-25 11:21:25.100 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:25.101 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 11:21:25.102 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.36\n",
      "2021-08-25 11:21:25.103 | INFO     | src.policies:train:109 - Episode 564\n",
      "2021-08-25 11:21:25.114 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:25.116 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:21:25.116 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.21\n",
      "2021-08-25 11:21:25.118 | WARNING  | src.policies:train:131 - The actual batch size is 206, instead of 200\n",
      "2021-08-25 11:21:25.126 | INFO     | src.policies:train:157 - Total loss: 1.0019806623458862\n",
      "2021-08-25 11:21:25.129 | INFO     | src.policies:train:103 - Epoch 67 / 800\n",
      "2021-08-25 11:21:25.130 | INFO     | src.policies:train:109 - Episode 565\n",
      "2021-08-25 11:21:25.142 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:25.143 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:21:25.144 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.34\n",
      "2021-08-25 11:21:25.145 | INFO     | src.policies:train:109 - Episode 566\n",
      "2021-08-25 11:21:25.186 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:25.187 | INFO     | src.policies:train:121 - Mean episode return: 98.0\n",
      "2021-08-25 11:21:25.188 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.06\n",
      "2021-08-25 11:21:25.189 | INFO     | src.policies:train:109 - Episode 567\n",
      "2021-08-25 11:21:25.207 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:25.208 | INFO     | src.policies:train:121 - Mean episode return: 38.0\n",
      "2021-08-25 11:21:25.209 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.29\n",
      "2021-08-25 11:21:25.210 | INFO     | src.policies:train:109 - Episode 568\n",
      "2021-08-25 11:21:25.231 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:25.232 | INFO     | src.policies:train:121 - Mean episode return: 43.0\n",
      "2021-08-25 11:21:25.233 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.58\n",
      "2021-08-25 11:21:25.234 | WARNING  | src.policies:train:131 - The actual batch size is 202, instead of 200\n",
      "2021-08-25 11:21:25.242 | INFO     | src.policies:train:157 - Total loss: 1.0019142627716064\n",
      "2021-08-25 11:21:25.245 | INFO     | src.policies:train:103 - Epoch 68 / 800\n",
      "2021-08-25 11:21:25.246 | INFO     | src.policies:train:109 - Episode 569\n",
      "2021-08-25 11:21:25.254 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:25.255 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:21:25.256 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.55\n",
      "2021-08-25 11:21:25.257 | INFO     | src.policies:train:109 - Episode 570\n",
      "2021-08-25 11:21:25.273 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:25.275 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 11:21:25.276 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.65\n",
      "2021-08-25 11:21:25.277 | INFO     | src.policies:train:109 - Episode 571\n",
      "2021-08-25 11:21:25.287 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:25.288 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:21:25.289 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.65\n",
      "2021-08-25 11:21:25.290 | INFO     | src.policies:train:109 - Episode 572\n",
      "2021-08-25 11:21:25.299 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:25.300 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:21:25.301 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.18\n",
      "2021-08-25 11:21:25.302 | INFO     | src.policies:train:109 - Episode 573\n",
      "2021-08-25 11:21:25.314 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:25.316 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:21:25.317 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.3\n",
      "2021-08-25 11:21:25.317 | INFO     | src.policies:train:109 - Episode 574\n",
      "2021-08-25 11:21:25.337 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:25.338 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 11:21:25.339 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.49\n",
      "2021-08-25 11:21:25.340 | INFO     | src.policies:train:109 - Episode 575\n",
      "2021-08-25 11:21:25.356 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:25.357 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 11:21:25.358 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.58\n",
      "2021-08-25 11:21:25.359 | INFO     | src.policies:train:109 - Episode 576\n",
      "2021-08-25 11:21:25.375 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:25.376 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 11:21:25.377 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.69\n",
      "2021-08-25 11:21:25.378 | INFO     | src.policies:train:109 - Episode 577\n",
      "2021-08-25 11:21:25.395 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:25.397 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 11:21:25.399 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.73\n",
      "2021-08-25 11:21:25.401 | WARNING  | src.policies:train:131 - The actual batch size is 215, instead of 200\n",
      "2021-08-25 11:21:25.411 | INFO     | src.policies:train:157 - Total loss: 1.0022306442260742\n",
      "2021-08-25 11:21:25.416 | INFO     | src.policies:train:103 - Epoch 69 / 800\n",
      "2021-08-25 11:21:25.417 | INFO     | src.policies:train:109 - Episode 578\n",
      "2021-08-25 11:21:25.427 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:25.429 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:21:25.430 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.58\n",
      "2021-08-25 11:21:25.432 | INFO     | src.policies:train:109 - Episode 579\n",
      "2021-08-25 11:21:25.454 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:25.455 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 11:21:25.457 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.33\n",
      "2021-08-25 11:21:25.458 | INFO     | src.policies:train:109 - Episode 580\n",
      "2021-08-25 11:21:25.475 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:25.476 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:21:25.478 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.45\n",
      "2021-08-25 11:21:25.479 | INFO     | src.policies:train:109 - Episode 581\n",
      "2021-08-25 11:21:25.490 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:25.492 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:25.493 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.28\n",
      "2021-08-25 11:21:25.495 | INFO     | src.policies:train:109 - Episode 582\n",
      "2021-08-25 11:21:25.512 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:25.513 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:21:25.515 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.36\n",
      "2021-08-25 11:21:25.516 | INFO     | src.policies:train:109 - Episode 583\n",
      "2021-08-25 11:21:25.537 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:25.538 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 11:21:25.540 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.29\n",
      "2021-08-25 11:21:25.542 | INFO     | src.policies:train:109 - Episode 584\n",
      "2021-08-25 11:21:25.559 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:25.560 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 11:21:25.562 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.37\n",
      "2021-08-25 11:21:25.563 | INFO     | src.policies:train:109 - Episode 585\n",
      "2021-08-25 11:21:25.587 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:25.588 | INFO     | src.policies:train:121 - Mean episode return: 45.0\n",
      "2021-08-25 11:21:25.589 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.28\n",
      "2021-08-25 11:21:25.590 | WARNING  | src.policies:train:131 - The actual batch size is 230, instead of 200\n",
      "2021-08-25 11:21:25.601 | INFO     | src.policies:train:157 - Total loss: 1.0024527311325073\n",
      "2021-08-25 11:21:25.604 | INFO     | src.policies:train:103 - Epoch 70 / 800\n",
      "2021-08-25 11:21:25.605 | INFO     | src.policies:train:109 - Episode 586\n",
      "2021-08-25 11:21:25.617 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:25.619 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:21:25.620 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.31\n",
      "2021-08-25 11:21:25.622 | INFO     | src.policies:train:109 - Episode 587\n",
      "2021-08-25 11:21:25.652 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:25.654 | INFO     | src.policies:train:121 - Mean episode return: 67.0\n",
      "2021-08-25 11:21:25.655 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.53\n",
      "2021-08-25 11:21:25.656 | INFO     | src.policies:train:109 - Episode 588\n",
      "2021-08-25 11:21:25.667 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:25.668 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:21:25.669 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.53\n",
      "2021-08-25 11:21:25.670 | INFO     | src.policies:train:109 - Episode 589\n",
      "2021-08-25 11:21:25.685 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:25.686 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:21:25.687 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.4\n",
      "2021-08-25 11:21:25.688 | INFO     | src.policies:train:109 - Episode 590\n",
      "2021-08-25 11:21:25.709 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:25.711 | INFO     | src.policies:train:121 - Mean episode return: 41.0\n",
      "2021-08-25 11:21:25.712 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.63\n",
      "2021-08-25 11:21:25.714 | INFO     | src.policies:train:109 - Episode 591\n",
      "2021-08-25 11:21:25.738 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:25.740 | INFO     | src.policies:train:121 - Mean episode return: 54.0\n",
      "2021-08-25 11:21:25.741 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.9\n",
      "2021-08-25 11:21:25.742 | WARNING  | src.policies:train:131 - The actual batch size is 229, instead of 200\n",
      "2021-08-25 11:21:25.751 | INFO     | src.policies:train:157 - Total loss: 1.0024279356002808\n",
      "2021-08-25 11:21:25.755 | INFO     | src.policies:train:103 - Epoch 71 / 800\n",
      "2021-08-25 11:21:25.756 | INFO     | src.policies:train:109 - Episode 592\n",
      "2021-08-25 11:21:25.767 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:25.768 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:25.769 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.94\n",
      "2021-08-25 11:21:25.770 | INFO     | src.policies:train:109 - Episode 593\n",
      "2021-08-25 11:21:25.782 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:25.783 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:25.785 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.98\n",
      "2021-08-25 11:21:25.786 | INFO     | src.policies:train:109 - Episode 594\n",
      "2021-08-25 11:21:25.804 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:25.805 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 11:21:25.806 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.98\n",
      "2021-08-25 11:21:25.807 | INFO     | src.policies:train:109 - Episode 595\n",
      "2021-08-25 11:21:25.828 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:25.830 | INFO     | src.policies:train:121 - Mean episode return: 42.0\n",
      "2021-08-25 11:21:25.831 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.21\n",
      "2021-08-25 11:21:25.832 | INFO     | src.policies:train:109 - Episode 596\n",
      "2021-08-25 11:21:25.847 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:25.849 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:21:25.850 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.23\n",
      "2021-08-25 11:21:25.851 | INFO     | src.policies:train:109 - Episode 597\n",
      "2021-08-25 11:21:25.867 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:25.868 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 11:21:25.869 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.08\n",
      "2021-08-25 11:21:25.870 | INFO     | src.policies:train:109 - Episode 598\n",
      "2021-08-25 11:21:25.891 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:25.893 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 11:21:25.894 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.07\n",
      "2021-08-25 11:21:25.895 | INFO     | src.policies:train:109 - Episode 599\n",
      "2021-08-25 11:21:25.907 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:25.908 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:25.910 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.82\n",
      "2021-08-25 11:21:25.910 | WARNING  | src.policies:train:131 - The actual batch size is 213, instead of 200\n",
      "2021-08-25 11:21:25.921 | INFO     | src.policies:train:157 - Total loss: 1.0022023916244507\n",
      "2021-08-25 11:21:25.925 | INFO     | src.policies:train:103 - Epoch 72 / 800\n",
      "2021-08-25 11:21:25.926 | INFO     | src.policies:train:109 - Episode 600\n",
      "2021-08-25 11:21:25.951 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:25.952 | INFO     | src.policies:train:121 - Mean episode return: 58.0\n",
      "2021-08-25 11:21:25.954 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.24\n",
      "2021-08-25 11:21:25.954 | INFO     | src.policies:train:109 - Episode 601\n",
      "2021-08-25 11:21:25.977 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:25.979 | INFO     | src.policies:train:121 - Mean episode return: 46.0\n",
      "2021-08-25 11:21:25.980 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.61\n",
      "2021-08-25 11:21:25.981 | INFO     | src.policies:train:109 - Episode 602\n",
      "2021-08-25 11:21:25.996 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:25.997 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:21:25.999 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.48\n",
      "2021-08-25 11:21:26.000 | INFO     | src.policies:train:109 - Episode 603\n",
      "2021-08-25 11:21:26.015 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:26.017 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 11:21:26.018 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.05\n",
      "2021-08-25 11:21:26.019 | INFO     | src.policies:train:109 - Episode 604\n",
      "2021-08-25 11:21:26.047 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:26.048 | INFO     | src.policies:train:121 - Mean episode return: 56.0\n",
      "2021-08-25 11:21:26.049 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.33\n",
      "2021-08-25 11:21:26.050 | WARNING  | src.policies:train:131 - The actual batch size is 209, instead of 200\n",
      "2021-08-25 11:21:26.059 | INFO     | src.policies:train:157 - Total loss: 1.0020784139633179\n",
      "2021-08-25 11:21:26.063 | INFO     | src.policies:train:103 - Epoch 73 / 800\n",
      "2021-08-25 11:21:26.064 | INFO     | src.policies:train:109 - Episode 605\n",
      "2021-08-25 11:21:26.075 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:26.077 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:21:26.078 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.35\n",
      "2021-08-25 11:21:26.079 | INFO     | src.policies:train:109 - Episode 606\n",
      "2021-08-25 11:21:26.105 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:26.107 | INFO     | src.policies:train:121 - Mean episode return: 52.0\n",
      "2021-08-25 11:21:26.108 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.62\n",
      "2021-08-25 11:21:26.109 | INFO     | src.policies:train:109 - Episode 607\n",
      "2021-08-25 11:21:26.129 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:26.130 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 11:21:26.131 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.89\n",
      "2021-08-25 11:21:26.132 | INFO     | src.policies:train:109 - Episode 608\n",
      "2021-08-25 11:21:26.148 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:26.149 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:21:26.150 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.92\n",
      "2021-08-25 11:21:26.152 | INFO     | src.policies:train:109 - Episode 609\n",
      "2021-08-25 11:21:26.167 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:26.168 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:21:26.169 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.04\n",
      "2021-08-25 11:21:26.170 | INFO     | src.policies:train:109 - Episode 610\n",
      "2021-08-25 11:21:26.188 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:26.190 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 11:21:26.191 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.96\n",
      "2021-08-25 11:21:26.193 | INFO     | src.policies:train:109 - Episode 611\n",
      "2021-08-25 11:21:26.211 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:26.212 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 11:21:26.214 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.62\n",
      "2021-08-25 11:21:26.215 | WARNING  | src.policies:train:131 - The actual batch size is 219, instead of 200\n",
      "2021-08-25 11:21:26.223 | INFO     | src.policies:train:157 - Total loss: 1.0021412372589111\n",
      "2021-08-25 11:21:26.226 | INFO     | src.policies:train:103 - Epoch 74 / 800\n",
      "2021-08-25 11:21:26.228 | INFO     | src.policies:train:109 - Episode 612\n",
      "2021-08-25 11:21:26.256 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:26.258 | INFO     | src.policies:train:121 - Mean episode return: 67.0\n",
      "2021-08-25 11:21:26.258 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.04\n",
      "2021-08-25 11:21:26.260 | INFO     | src.policies:train:109 - Episode 613\n",
      "2021-08-25 11:21:26.271 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:26.272 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:21:26.274 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.0\n",
      "2021-08-25 11:21:26.275 | INFO     | src.policies:train:109 - Episode 614\n",
      "2021-08-25 11:21:26.295 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:26.296 | INFO     | src.policies:train:121 - Mean episode return: 39.0\n",
      "2021-08-25 11:21:26.298 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.75\n",
      "2021-08-25 11:21:26.299 | INFO     | src.policies:train:109 - Episode 615\n",
      "2021-08-25 11:21:26.313 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:26.315 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:21:26.316 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.71\n",
      "2021-08-25 11:21:26.317 | INFO     | src.policies:train:109 - Episode 616\n",
      "2021-08-25 11:21:26.327 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:26.328 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:26.329 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.7\n",
      "2021-08-25 11:21:26.331 | INFO     | src.policies:train:109 - Episode 617\n",
      "2021-08-25 11:21:26.349 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:26.350 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 11:21:26.352 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.83\n",
      "2021-08-25 11:21:26.353 | INFO     | src.policies:train:109 - Episode 618\n",
      "2021-08-25 11:21:26.380 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:26.381 | INFO     | src.policies:train:121 - Mean episode return: 56.0\n",
      "2021-08-25 11:21:26.383 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.04\n",
      "2021-08-25 11:21:26.384 | WARNING  | src.policies:train:131 - The actual batch size is 241, instead of 200\n",
      "2021-08-25 11:21:26.393 | INFO     | src.policies:train:157 - Total loss: 1.0026768445968628\n",
      "2021-08-25 11:21:26.396 | INFO     | src.policies:train:103 - Epoch 75 / 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:26.397 | INFO     | src.policies:train:109 - Episode 619\n",
      "2021-08-25 11:21:26.411 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:26.413 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:21:26.415 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.19\n",
      "2021-08-25 11:21:26.416 | INFO     | src.policies:train:109 - Episode 620\n",
      "2021-08-25 11:21:26.428 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:26.429 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:26.430 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.18\n",
      "2021-08-25 11:21:26.431 | INFO     | src.policies:train:109 - Episode 621\n",
      "2021-08-25 11:21:26.441 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:26.443 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:21:26.444 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.05\n",
      "2021-08-25 11:21:26.445 | INFO     | src.policies:train:109 - Episode 622\n",
      "2021-08-25 11:21:26.459 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:26.461 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:21:26.462 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.14\n",
      "2021-08-25 11:21:26.464 | INFO     | src.policies:train:109 - Episode 623\n",
      "2021-08-25 11:21:26.474 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:26.476 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:21:26.477 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.76\n",
      "2021-08-25 11:21:26.479 | INFO     | src.policies:train:109 - Episode 624\n",
      "2021-08-25 11:21:26.502 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:26.504 | INFO     | src.policies:train:121 - Mean episode return: 47.0\n",
      "2021-08-25 11:21:26.505 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.07\n",
      "2021-08-25 11:21:26.506 | INFO     | src.policies:train:109 - Episode 625\n",
      "2021-08-25 11:21:26.517 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:26.519 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:21:26.520 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.12\n",
      "2021-08-25 11:21:26.521 | INFO     | src.policies:train:109 - Episode 626\n",
      "2021-08-25 11:21:26.530 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:26.531 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:26.532 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.73\n",
      "2021-08-25 11:21:26.533 | INFO     | src.policies:train:109 - Episode 627\n",
      "2021-08-25 11:21:26.547 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:26.548 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:21:26.549 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.68\n",
      "2021-08-25 11:21:26.550 | INFO     | src.policies:train:109 - Episode 628\n",
      "2021-08-25 11:21:26.568 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:26.569 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 11:21:26.570 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.79\n",
      "2021-08-25 11:21:26.572 | WARNING  | src.policies:train:131 - The actual batch size is 219, instead of 200\n",
      "2021-08-25 11:21:26.583 | INFO     | src.policies:train:157 - Total loss: 1.0022579431533813\n",
      "2021-08-25 11:21:26.586 | INFO     | src.policies:train:103 - Epoch 76 / 800\n",
      "2021-08-25 11:21:26.588 | INFO     | src.policies:train:109 - Episode 629\n",
      "2021-08-25 11:21:26.596 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:26.598 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:21:26.599 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.51\n",
      "2021-08-25 11:21:26.601 | INFO     | src.policies:train:109 - Episode 630\n",
      "2021-08-25 11:21:26.616 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:26.617 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:21:26.618 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.62\n",
      "2021-08-25 11:21:26.619 | INFO     | src.policies:train:109 - Episode 631\n",
      "2021-08-25 11:21:26.635 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:26.636 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:21:26.638 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.51\n",
      "2021-08-25 11:21:26.639 | INFO     | src.policies:train:109 - Episode 632\n",
      "2021-08-25 11:21:26.658 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:26.659 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 11:21:26.661 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.66\n",
      "2021-08-25 11:21:26.662 | INFO     | src.policies:train:109 - Episode 633\n",
      "2021-08-25 11:21:26.679 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:26.680 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:21:26.682 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.48\n",
      "2021-08-25 11:21:26.683 | INFO     | src.policies:train:109 - Episode 634\n",
      "2021-08-25 11:21:26.701 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:26.702 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 11:21:26.703 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.32\n",
      "2021-08-25 11:21:26.705 | INFO     | src.policies:train:109 - Episode 635\n",
      "2021-08-25 11:21:26.719 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:26.720 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:21:26.722 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.22\n",
      "2021-08-25 11:21:26.723 | INFO     | src.policies:train:109 - Episode 636\n",
      "2021-08-25 11:21:26.733 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:26.735 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:21:26.736 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.15\n",
      "2021-08-25 11:21:26.737 | INFO     | src.policies:train:109 - Episode 637\n",
      "2021-08-25 11:21:26.751 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:26.753 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:21:26.754 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.22\n",
      "2021-08-25 11:21:26.756 | WARNING  | src.policies:train:131 - The actual batch size is 210, instead of 200\n",
      "2021-08-25 11:21:26.765 | INFO     | src.policies:train:157 - Total loss: 1.0020545721054077\n",
      "2021-08-25 11:21:26.768 | INFO     | src.policies:train:103 - Epoch 77 / 800\n",
      "2021-08-25 11:21:26.770 | INFO     | src.policies:train:109 - Episode 638\n",
      "2021-08-25 11:21:26.792 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:26.794 | INFO     | src.policies:train:121 - Mean episode return: 47.0\n",
      "2021-08-25 11:21:26.795 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.55\n",
      "2021-08-25 11:21:26.796 | INFO     | src.policies:train:109 - Episode 639\n",
      "2021-08-25 11:21:26.825 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:26.826 | INFO     | src.policies:train:121 - Mean episode return: 65.0\n",
      "2021-08-25 11:21:26.828 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:26.829 | INFO     | src.policies:train:109 - Episode 640\n",
      "2021-08-25 11:21:26.852 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:26.854 | INFO     | src.policies:train:121 - Mean episode return: 45.0\n",
      "2021-08-25 11:21:26.855 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.95\n",
      "2021-08-25 11:21:26.856 | INFO     | src.policies:train:109 - Episode 641\n",
      "2021-08-25 11:21:26.870 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:26.871 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:21:26.873 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.01\n",
      "2021-08-25 11:21:26.874 | INFO     | src.policies:train:109 - Episode 642\n",
      "2021-08-25 11:21:26.884 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:26.885 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 11:21:26.886 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.94\n",
      "2021-08-25 11:21:26.887 | INFO     | src.policies:train:109 - Episode 643\n",
      "2021-08-25 11:21:26.901 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:26.903 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:21:26.904 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.01\n",
      "2021-08-25 11:21:26.905 | WARNING  | src.policies:train:131 - The actual batch size is 215, instead of 200\n",
      "2021-08-25 11:21:26.913 | INFO     | src.policies:train:157 - Total loss: 1.0022319555282593\n",
      "2021-08-25 11:21:26.917 | INFO     | src.policies:train:103 - Epoch 78 / 800\n",
      "2021-08-25 11:21:26.919 | INFO     | src.policies:train:109 - Episode 644\n",
      "2021-08-25 11:21:26.927 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:26.928 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:21:26.929 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.01\n",
      "2021-08-25 11:21:26.930 | INFO     | src.policies:train:109 - Episode 645\n",
      "2021-08-25 11:21:26.944 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:26.945 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:21:26.946 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.94\n",
      "2021-08-25 11:21:26.947 | INFO     | src.policies:train:109 - Episode 646\n",
      "2021-08-25 11:21:26.958 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:26.959 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:26.961 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.94\n",
      "2021-08-25 11:21:26.962 | INFO     | src.policies:train:109 - Episode 647\n",
      "2021-08-25 11:21:26.973 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:26.974 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:26.976 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.99\n",
      "2021-08-25 11:21:26.977 | INFO     | src.policies:train:109 - Episode 648\n",
      "2021-08-25 11:21:26.995 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:26.997 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 11:21:26.998 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.22\n",
      "2021-08-25 11:21:27.000 | INFO     | src.policies:train:109 - Episode 649\n",
      "2021-08-25 11:21:27.013 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:27.015 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:21:27.016 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.32\n",
      "2021-08-25 11:21:27.017 | INFO     | src.policies:train:109 - Episode 650\n",
      "2021-08-25 11:21:27.040 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:27.042 | INFO     | src.policies:train:121 - Mean episode return: 43.0\n",
      "2021-08-25 11:21:27.043 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.61\n",
      "2021-08-25 11:21:27.044 | INFO     | src.policies:train:109 - Episode 651\n",
      "2021-08-25 11:21:27.052 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:27.054 | INFO     | src.policies:train:121 - Mean episode return: 9.0\n",
      "2021-08-25 11:21:27.055 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.53\n",
      "2021-08-25 11:21:27.056 | INFO     | src.policies:train:109 - Episode 652\n",
      "2021-08-25 11:21:27.068 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:27.070 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:27.071 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.49\n",
      "2021-08-25 11:21:27.073 | INFO     | src.policies:train:109 - Episode 653\n",
      "2021-08-25 11:21:27.104 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:27.106 | INFO     | src.policies:train:121 - Mean episode return: 68.0\n",
      "2021-08-25 11:21:27.107 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.02\n",
      "2021-08-25 11:21:27.108 | WARNING  | src.policies:train:131 - The actual batch size is 251, instead of 200\n",
      "2021-08-25 11:21:27.116 | INFO     | src.policies:train:157 - Total loss: 1.0028388500213623\n",
      "2021-08-25 11:21:27.119 | INFO     | src.policies:train:103 - Epoch 79 / 800\n",
      "2021-08-25 11:21:27.120 | INFO     | src.policies:train:109 - Episode 654\n",
      "2021-08-25 11:21:27.131 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:27.133 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:21:27.134 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.03\n",
      "2021-08-25 11:21:27.135 | INFO     | src.policies:train:109 - Episode 655\n",
      "2021-08-25 11:21:27.148 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:27.149 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:21:27.150 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.9\n",
      "2021-08-25 11:21:27.151 | INFO     | src.policies:train:109 - Episode 656\n",
      "2021-08-25 11:21:27.162 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:27.163 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:27.164 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.16\n",
      "2021-08-25 11:21:27.165 | INFO     | src.policies:train:109 - Episode 657\n",
      "2021-08-25 11:21:27.177 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:27.179 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:21:27.180 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.21\n",
      "2021-08-25 11:21:27.181 | INFO     | src.policies:train:109 - Episode 658\n",
      "2021-08-25 11:21:27.189 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:27.190 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:27.191 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.89\n",
      "2021-08-25 11:21:27.192 | INFO     | src.policies:train:109 - Episode 659\n",
      "2021-08-25 11:21:27.203 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:27.204 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:21:27.205 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.71\n",
      "2021-08-25 11:21:27.206 | INFO     | src.policies:train:109 - Episode 660\n",
      "2021-08-25 11:21:27.215 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:27.216 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:27.217 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:27.218 | INFO     | src.policies:train:109 - Episode 661\n",
      "2021-08-25 11:21:27.245 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:27.246 | INFO     | src.policies:train:121 - Mean episode return: 62.0\n",
      "2021-08-25 11:21:27.247 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.82\n",
      "2021-08-25 11:21:27.248 | INFO     | src.policies:train:109 - Episode 662\n",
      "2021-08-25 11:21:27.262 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:27.263 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:21:27.264 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.91\n",
      "2021-08-25 11:21:27.265 | WARNING  | src.policies:train:131 - The actual batch size is 207, instead of 200\n",
      "2021-08-25 11:21:27.272 | INFO     | src.policies:train:157 - Total loss: 1.002049207687378\n",
      "2021-08-25 11:21:27.276 | INFO     | src.policies:train:103 - Epoch 80 / 800\n",
      "2021-08-25 11:21:27.277 | INFO     | src.policies:train:109 - Episode 663\n",
      "2021-08-25 11:21:27.295 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:27.296 | INFO     | src.policies:train:121 - Mean episode return: 42.0\n",
      "2021-08-25 11:21:27.297 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.23\n",
      "2021-08-25 11:21:27.299 | INFO     | src.policies:train:109 - Episode 664\n",
      "2021-08-25 11:21:27.307 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:27.308 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:27.309 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.14\n",
      "2021-08-25 11:21:27.310 | INFO     | src.policies:train:109 - Episode 665\n",
      "2021-08-25 11:21:27.323 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:27.324 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:21:27.325 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.13\n",
      "2021-08-25 11:21:27.326 | INFO     | src.policies:train:109 - Episode 666\n",
      "2021-08-25 11:21:27.348 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:27.349 | INFO     | src.policies:train:121 - Mean episode return: 49.0\n",
      "2021-08-25 11:21:27.350 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.64\n",
      "2021-08-25 11:21:27.351 | INFO     | src.policies:train:109 - Episode 667\n",
      "2021-08-25 11:21:27.361 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:27.362 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:27.363 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.41\n",
      "2021-08-25 11:21:27.364 | INFO     | src.policies:train:109 - Episode 668\n",
      "2021-08-25 11:21:27.382 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:27.383 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 11:21:27.384 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.35\n",
      "2021-08-25 11:21:27.385 | INFO     | src.policies:train:109 - Episode 669\n",
      "2021-08-25 11:21:27.413 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:27.414 | INFO     | src.policies:train:121 - Mean episode return: 64.0\n",
      "2021-08-25 11:21:27.415 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.85\n",
      "2021-08-25 11:21:27.416 | WARNING  | src.policies:train:131 - The actual batch size is 241, instead of 200\n",
      "2021-08-25 11:21:27.423 | INFO     | src.policies:train:157 - Total loss: 1.002655267715454\n",
      "2021-08-25 11:21:27.427 | INFO     | src.policies:train:103 - Epoch 81 / 800\n",
      "2021-08-25 11:21:27.428 | INFO     | src.policies:train:109 - Episode 670\n",
      "2021-08-25 11:21:27.439 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:27.440 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:21:27.441 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.78\n",
      "2021-08-25 11:21:27.442 | INFO     | src.policies:train:109 - Episode 671\n",
      "2021-08-25 11:21:27.452 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:27.453 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:27.454 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.8\n",
      "2021-08-25 11:21:27.455 | INFO     | src.policies:train:109 - Episode 672\n",
      "2021-08-25 11:21:27.466 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:27.467 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:21:27.468 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.8\n",
      "2021-08-25 11:21:27.469 | INFO     | src.policies:train:109 - Episode 673\n",
      "2021-08-25 11:21:27.480 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:27.481 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:21:27.482 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.76\n",
      "2021-08-25 11:21:27.483 | INFO     | src.policies:train:109 - Episode 674\n",
      "2021-08-25 11:21:27.505 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:27.506 | INFO     | src.policies:train:121 - Mean episode return: 50.0\n",
      "2021-08-25 11:21:27.507 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.89\n",
      "2021-08-25 11:21:27.508 | INFO     | src.policies:train:109 - Episode 675\n",
      "2021-08-25 11:21:27.516 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:27.517 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:21:27.518 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.7\n",
      "2021-08-25 11:21:27.519 | INFO     | src.policies:train:109 - Episode 676\n",
      "2021-08-25 11:21:27.535 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:27.536 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:21:27.537 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.72\n",
      "2021-08-25 11:21:27.538 | INFO     | src.policies:train:109 - Episode 677\n",
      "2021-08-25 11:21:27.548 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:27.549 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:27.550 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.6\n",
      "2021-08-25 11:21:27.551 | INFO     | src.policies:train:109 - Episode 678\n",
      "2021-08-25 11:21:27.561 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:27.563 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:27.564 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.64\n",
      "2021-08-25 11:21:27.565 | INFO     | src.policies:train:109 - Episode 679\n",
      "2021-08-25 11:21:27.574 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:27.576 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:21:27.577 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.42\n",
      "2021-08-25 11:21:27.578 | WARNING  | src.policies:train:131 - The actual batch size is 211, instead of 200\n",
      "2021-08-25 11:21:27.587 | INFO     | src.policies:train:157 - Total loss: 1.0021092891693115\n",
      "2021-08-25 11:21:27.590 | INFO     | src.policies:train:103 - Epoch 82 / 800\n",
      "2021-08-25 11:21:27.592 | INFO     | src.policies:train:109 - Episode 680\n",
      "2021-08-25 11:21:27.611 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:27.612 | INFO     | src.policies:train:121 - Mean episode return: 42.0\n",
      "2021-08-25 11:21:27.614 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.6\n",
      "2021-08-25 11:21:27.615 | INFO     | src.policies:train:109 - Episode 681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:27.633 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:27.634 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 11:21:27.635 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.83\n",
      "2021-08-25 11:21:27.636 | INFO     | src.policies:train:109 - Episode 682\n",
      "2021-08-25 11:21:27.658 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:27.660 | INFO     | src.policies:train:121 - Mean episode return: 44.0\n",
      "2021-08-25 11:21:27.661 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.98\n",
      "2021-08-25 11:21:27.662 | INFO     | src.policies:train:109 - Episode 683\n",
      "2021-08-25 11:21:27.691 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:27.692 | INFO     | src.policies:train:121 - Mean episode return: 64.0\n",
      "2021-08-25 11:21:27.693 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.25\n",
      "2021-08-25 11:21:27.694 | INFO     | src.policies:train:109 - Episode 684\n",
      "2021-08-25 11:21:27.711 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:27.713 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 11:21:27.714 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.27\n",
      "2021-08-25 11:21:27.715 | WARNING  | src.policies:train:131 - The actual batch size is 217, instead of 200\n",
      "2021-08-25 11:21:27.722 | INFO     | src.policies:train:157 - Total loss: 1.0021519660949707\n",
      "2021-08-25 11:21:27.725 | INFO     | src.policies:train:103 - Epoch 83 / 800\n",
      "2021-08-25 11:21:27.726 | INFO     | src.policies:train:109 - Episode 685\n",
      "2021-08-25 11:21:27.733 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:27.734 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:21:27.735 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.93\n",
      "2021-08-25 11:21:27.736 | INFO     | src.policies:train:109 - Episode 686\n",
      "2021-08-25 11:21:27.754 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:27.755 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 11:21:27.756 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.05\n",
      "2021-08-25 11:21:27.757 | INFO     | src.policies:train:109 - Episode 687\n",
      "2021-08-25 11:21:27.772 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:27.774 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 11:21:27.775 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.65\n",
      "2021-08-25 11:21:27.776 | INFO     | src.policies:train:109 - Episode 688\n",
      "2021-08-25 11:21:27.787 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:27.788 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:27.789 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.63\n",
      "2021-08-25 11:21:27.790 | INFO     | src.policies:train:109 - Episode 689\n",
      "2021-08-25 11:21:27.801 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:27.802 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:21:27.803 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.57\n",
      "2021-08-25 11:21:27.804 | INFO     | src.policies:train:109 - Episode 690\n",
      "2021-08-25 11:21:27.813 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:27.815 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:21:27.816 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.29\n",
      "2021-08-25 11:21:27.816 | INFO     | src.policies:train:109 - Episode 691\n",
      "2021-08-25 11:21:27.827 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:27.828 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:27.829 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.91\n",
      "2021-08-25 11:21:27.830 | INFO     | src.policies:train:109 - Episode 692\n",
      "2021-08-25 11:21:27.837 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:27.839 | INFO     | src.policies:train:121 - Mean episode return: 9.0\n",
      "2021-08-25 11:21:27.839 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.84\n",
      "2021-08-25 11:21:27.840 | INFO     | src.policies:train:109 - Episode 693\n",
      "2021-08-25 11:21:27.858 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:27.860 | INFO     | src.policies:train:121 - Mean episode return: 42.0\n",
      "2021-08-25 11:21:27.861 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.09\n",
      "2021-08-25 11:21:27.862 | INFO     | src.policies:train:109 - Episode 694\n",
      "2021-08-25 11:21:27.870 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:27.871 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:21:27.872 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.87\n",
      "2021-08-25 11:21:27.879 | INFO     | src.policies:train:157 - Total loss: 1.0018268823623657\n",
      "2021-08-25 11:21:27.882 | INFO     | src.policies:train:103 - Epoch 84 / 800\n",
      "2021-08-25 11:21:27.883 | INFO     | src.policies:train:109 - Episode 695\n",
      "2021-08-25 11:21:27.897 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:27.898 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 11:21:27.900 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.73\n",
      "2021-08-25 11:21:27.900 | INFO     | src.policies:train:109 - Episode 696\n",
      "2021-08-25 11:21:27.910 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:27.911 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:27.912 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.64\n",
      "2021-08-25 11:21:27.913 | INFO     | src.policies:train:109 - Episode 697\n",
      "2021-08-25 11:21:27.923 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:27.924 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:27.925 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.55\n",
      "2021-08-25 11:21:27.926 | INFO     | src.policies:train:109 - Episode 698\n",
      "2021-08-25 11:21:27.937 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:27.938 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:27.939 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.32\n",
      "2021-08-25 11:21:27.940 | INFO     | src.policies:train:109 - Episode 699\n",
      "2021-08-25 11:21:27.954 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:27.956 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 11:21:27.957 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.46\n",
      "2021-08-25 11:21:27.958 | INFO     | src.policies:train:109 - Episode 700\n",
      "2021-08-25 11:21:27.968 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:27.969 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:27.970 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.04\n",
      "2021-08-25 11:21:27.972 | INFO     | src.policies:train:109 - Episode 701\n",
      "2021-08-25 11:21:27.984 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:27.985 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:21:27.986 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.8\n",
      "2021-08-25 11:21:27.987 | INFO     | src.policies:train:109 - Episode 702\n",
      "2021-08-25 11:21:27.998 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:27.999 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:28.000 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.73\n",
      "2021-08-25 11:21:28.002 | INFO     | src.policies:train:109 - Episode 703\n",
      "2021-08-25 11:21:28.016 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:28.017 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:21:28.018 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.74\n",
      "2021-08-25 11:21:28.019 | INFO     | src.policies:train:109 - Episode 704\n",
      "2021-08-25 11:21:28.039 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:28.041 | INFO     | src.policies:train:121 - Mean episode return: 41.0\n",
      "2021-08-25 11:21:28.042 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.59\n",
      "2021-08-25 11:21:28.043 | WARNING  | src.policies:train:131 - The actual batch size is 228, instead of 200\n",
      "2021-08-25 11:21:28.050 | INFO     | src.policies:train:157 - Total loss: 1.0023666620254517\n",
      "2021-08-25 11:21:28.053 | INFO     | src.policies:train:103 - Epoch 85 / 800\n",
      "2021-08-25 11:21:28.055 | INFO     | src.policies:train:109 - Episode 705\n",
      "2021-08-25 11:21:28.075 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:28.076 | INFO     | src.policies:train:121 - Mean episode return: 44.0\n",
      "2021-08-25 11:21:28.077 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.85\n",
      "2021-08-25 11:21:28.078 | INFO     | src.policies:train:109 - Episode 706\n",
      "2021-08-25 11:21:28.088 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:28.089 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:28.090 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.48\n",
      "2021-08-25 11:21:28.091 | INFO     | src.policies:train:109 - Episode 707\n",
      "2021-08-25 11:21:28.102 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:28.103 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:28.104 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.29\n",
      "2021-08-25 11:21:28.105 | INFO     | src.policies:train:109 - Episode 708\n",
      "2021-08-25 11:21:28.123 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:28.124 | INFO     | src.policies:train:121 - Mean episode return: 38.0\n",
      "2021-08-25 11:21:28.125 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.41\n",
      "2021-08-25 11:21:28.126 | INFO     | src.policies:train:109 - Episode 709\n",
      "2021-08-25 11:21:28.134 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:28.135 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:21:28.136 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.32\n",
      "2021-08-25 11:21:28.138 | INFO     | src.policies:train:109 - Episode 710\n",
      "2021-08-25 11:21:28.151 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:28.153 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 11:21:28.154 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.29\n",
      "2021-08-25 11:21:28.155 | INFO     | src.policies:train:109 - Episode 711\n",
      "2021-08-25 11:21:28.171 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:28.172 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 11:21:28.173 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.28\n",
      "2021-08-25 11:21:28.175 | INFO     | src.policies:train:109 - Episode 712\n",
      "2021-08-25 11:21:28.188 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:28.190 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:21:28.191 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.84\n",
      "2021-08-25 11:21:28.192 | WARNING  | src.policies:train:131 - The actual batch size is 211, instead of 200\n",
      "2021-08-25 11:21:28.199 | INFO     | src.policies:train:157 - Total loss: 1.0021097660064697\n",
      "2021-08-25 11:21:28.202 | INFO     | src.policies:train:103 - Epoch 86 / 800\n",
      "2021-08-25 11:21:28.203 | INFO     | src.policies:train:109 - Episode 713\n",
      "2021-08-25 11:21:28.214 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:28.216 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:21:28.217 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.94\n",
      "2021-08-25 11:21:28.218 | INFO     | src.policies:train:109 - Episode 714\n",
      "2021-08-25 11:21:28.233 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:28.234 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 11:21:28.235 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.82\n",
      "2021-08-25 11:21:28.236 | INFO     | src.policies:train:109 - Episode 715\n",
      "2021-08-25 11:21:28.248 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:28.249 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:21:28.250 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.82\n",
      "2021-08-25 11:21:28.251 | INFO     | src.policies:train:109 - Episode 716\n",
      "2021-08-25 11:21:28.263 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:28.264 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:21:28.265 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.88\n",
      "2021-08-25 11:21:28.266 | INFO     | src.policies:train:109 - Episode 717\n",
      "2021-08-25 11:21:28.275 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:28.276 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:28.277 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.7\n",
      "2021-08-25 11:21:28.278 | INFO     | src.policies:train:109 - Episode 718\n",
      "2021-08-25 11:21:28.291 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:28.293 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:21:28.294 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.37\n",
      "2021-08-25 11:21:28.295 | INFO     | src.policies:train:109 - Episode 719\n",
      "2021-08-25 11:21:28.310 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:28.311 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:21:28.312 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.4\n",
      "2021-08-25 11:21:28.313 | INFO     | src.policies:train:109 - Episode 720\n",
      "2021-08-25 11:21:28.321 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:28.322 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:21:28.323 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.36\n",
      "2021-08-25 11:21:28.324 | INFO     | src.policies:train:109 - Episode 721\n",
      "2021-08-25 11:21:28.341 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:28.343 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 11:21:28.343 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.59\n",
      "2021-08-25 11:21:28.344 | WARNING  | src.policies:train:131 - The actual batch size is 201, instead of 200\n",
      "2021-08-25 11:21:28.352 | INFO     | src.policies:train:157 - Total loss: 1.001804232597351\n",
      "2021-08-25 11:21:28.355 | INFO     | src.policies:train:103 - Epoch 87 / 800\n",
      "2021-08-25 11:21:28.357 | INFO     | src.policies:train:109 - Episode 722\n",
      "2021-08-25 11:21:28.363 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:28.364 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:28.365 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.46\n",
      "2021-08-25 11:21:28.366 | INFO     | src.policies:train:109 - Episode 723\n",
      "2021-08-25 11:21:28.380 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:28.381 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 11:21:28.382 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.58\n",
      "2021-08-25 11:21:28.383 | INFO     | src.policies:train:109 - Episode 724\n",
      "2021-08-25 11:21:28.401 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:28.402 | INFO     | src.policies:train:121 - Mean episode return: 38.0\n",
      "2021-08-25 11:21:28.403 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.49\n",
      "2021-08-25 11:21:28.404 | INFO     | src.policies:train:109 - Episode 725\n",
      "2021-08-25 11:21:28.411 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:28.412 | INFO     | src.policies:train:121 - Mean episode return: 9.0\n",
      "2021-08-25 11:21:28.413 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.37\n",
      "2021-08-25 11:21:28.415 | INFO     | src.policies:train:109 - Episode 726\n",
      "2021-08-25 11:21:28.426 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:28.427 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:21:28.428 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.46\n",
      "2021-08-25 11:21:28.429 | INFO     | src.policies:train:109 - Episode 727\n",
      "2021-08-25 11:21:28.452 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:28.453 | INFO     | src.policies:train:121 - Mean episode return: 47.0\n",
      "2021-08-25 11:21:28.454 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.74\n",
      "2021-08-25 11:21:28.455 | INFO     | src.policies:train:109 - Episode 728\n",
      "2021-08-25 11:21:28.485 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:28.486 | INFO     | src.policies:train:121 - Mean episode return: 63.0\n",
      "2021-08-25 11:21:28.487 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.06\n",
      "2021-08-25 11:21:28.488 | WARNING  | src.policies:train:131 - The actual batch size is 214, instead of 200\n",
      "2021-08-25 11:21:28.496 | INFO     | src.policies:train:157 - Total loss: 1.0021235942840576\n",
      "2021-08-25 11:21:28.499 | INFO     | src.policies:train:103 - Epoch 88 / 800\n",
      "2021-08-25 11:21:28.500 | INFO     | src.policies:train:109 - Episode 729\n",
      "2021-08-25 11:21:28.516 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:28.518 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 11:21:28.519 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.26\n",
      "2021-08-25 11:21:28.520 | INFO     | src.policies:train:109 - Episode 730\n",
      "2021-08-25 11:21:28.530 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:28.532 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:21:28.532 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.2\n",
      "2021-08-25 11:21:28.533 | INFO     | src.policies:train:109 - Episode 731\n",
      "2021-08-25 11:21:28.567 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:28.569 | INFO     | src.policies:train:121 - Mean episode return: 79.0\n",
      "2021-08-25 11:21:28.570 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.76\n",
      "2021-08-25 11:21:28.571 | INFO     | src.policies:train:109 - Episode 732\n",
      "2021-08-25 11:21:28.591 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:28.592 | INFO     | src.policies:train:121 - Mean episode return: 41.0\n",
      "2021-08-25 11:21:28.593 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.81\n",
      "2021-08-25 11:21:28.594 | INFO     | src.policies:train:109 - Episode 733\n",
      "2021-08-25 11:21:28.602 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:28.603 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:21:28.604 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.63\n",
      "2021-08-25 11:21:28.605 | INFO     | src.policies:train:109 - Episode 734\n",
      "2021-08-25 11:21:28.622 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:28.623 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 11:21:28.624 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.6\n",
      "2021-08-25 11:21:28.625 | WARNING  | src.policies:train:131 - The actual batch size is 215, instead of 200\n",
      "2021-08-25 11:21:28.632 | INFO     | src.policies:train:157 - Total loss: 1.002021074295044\n",
      "2021-08-25 11:21:28.635 | INFO     | src.policies:train:103 - Epoch 89 / 800\n",
      "2021-08-25 11:21:28.637 | INFO     | src.policies:train:109 - Episode 735\n",
      "2021-08-25 11:21:28.648 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:28.649 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:21:28.650 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.65\n",
      "2021-08-25 11:21:28.651 | INFO     | src.policies:train:109 - Episode 736\n",
      "2021-08-25 11:21:28.665 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:28.666 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:21:28.667 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.8\n",
      "2021-08-25 11:21:28.668 | INFO     | src.policies:train:109 - Episode 737\n",
      "2021-08-25 11:21:28.681 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:28.682 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:21:28.683 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.82\n",
      "2021-08-25 11:21:28.684 | INFO     | src.policies:train:109 - Episode 738\n",
      "2021-08-25 11:21:28.697 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:28.698 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:21:28.699 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.59\n",
      "2021-08-25 11:21:28.700 | INFO     | src.policies:train:109 - Episode 739\n",
      "2021-08-25 11:21:28.709 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:28.710 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:28.711 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.09\n",
      "2021-08-25 11:21:28.712 | INFO     | src.policies:train:109 - Episode 740\n",
      "2021-08-25 11:21:28.722 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:28.723 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:21:28.724 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.78\n",
      "2021-08-25 11:21:28.725 | INFO     | src.policies:train:109 - Episode 741\n",
      "2021-08-25 11:21:28.742 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:28.743 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 11:21:28.744 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 25.93\n",
      "2021-08-25 11:21:28.745 | INFO     | src.policies:train:109 - Episode 742\n",
      "2021-08-25 11:21:28.759 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:28.761 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 11:21:28.762 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.13\n",
      "2021-08-25 11:21:28.763 | INFO     | src.policies:train:109 - Episode 743\n",
      "2021-08-25 11:21:28.773 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:28.774 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:28.775 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.04\n",
      "2021-08-25 11:21:28.776 | WARNING  | src.policies:train:131 - The actual batch size is 208, instead of 200\n",
      "2021-08-25 11:21:28.784 | INFO     | src.policies:train:157 - Total loss: 1.0020167827606201\n",
      "2021-08-25 11:21:28.788 | INFO     | src.policies:train:103 - Epoch 90 / 800\n",
      "2021-08-25 11:21:28.789 | INFO     | src.policies:train:109 - Episode 744\n",
      "2021-08-25 11:21:28.813 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:28.815 | INFO     | src.policies:train:121 - Mean episode return: 56.0\n",
      "2021-08-25 11:21:28.816 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.49\n",
      "2021-08-25 11:21:28.817 | INFO     | src.policies:train:109 - Episode 745\n",
      "2021-08-25 11:21:28.834 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:28.835 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 11:21:28.836 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.62\n",
      "2021-08-25 11:21:28.837 | INFO     | src.policies:train:109 - Episode 746\n",
      "2021-08-25 11:21:28.854 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:28.855 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 11:21:28.856 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.81\n",
      "2021-08-25 11:21:28.857 | INFO     | src.policies:train:109 - Episode 747\n",
      "2021-08-25 11:21:28.873 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:28.875 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 11:21:28.876 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.96\n",
      "2021-08-25 11:21:28.877 | INFO     | src.policies:train:109 - Episode 748\n",
      "2021-08-25 11:21:28.900 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:28.901 | INFO     | src.policies:train:121 - Mean episode return: 52.0\n",
      "2021-08-25 11:21:28.902 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.15\n",
      "2021-08-25 11:21:28.903 | WARNING  | src.policies:train:131 - The actual batch size is 202, instead of 200\n",
      "2021-08-25 11:21:28.909 | INFO     | src.policies:train:157 - Total loss: 1.0017939805984497\n",
      "2021-08-25 11:21:28.913 | INFO     | src.policies:train:103 - Epoch 91 / 800\n",
      "2021-08-25 11:21:28.914 | INFO     | src.policies:train:109 - Episode 749\n",
      "2021-08-25 11:21:28.932 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:28.933 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 11:21:28.934 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.32\n",
      "2021-08-25 11:21:28.935 | INFO     | src.policies:train:109 - Episode 750\n",
      "2021-08-25 11:21:28.947 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:28.948 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:21:28.949 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.08\n",
      "2021-08-25 11:21:28.950 | INFO     | src.policies:train:109 - Episode 751\n",
      "2021-08-25 11:21:28.961 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:28.962 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:21:28.963 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.17\n",
      "2021-08-25 11:21:28.964 | INFO     | src.policies:train:109 - Episode 752\n",
      "2021-08-25 11:21:28.978 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:28.980 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 11:21:28.981 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.25\n",
      "2021-08-25 11:21:28.982 | INFO     | src.policies:train:109 - Episode 753\n",
      "2021-08-25 11:21:28.992 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:28.994 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:21:28.995 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.76\n",
      "2021-08-25 11:21:28.995 | INFO     | src.policies:train:109 - Episode 754\n",
      "2021-08-25 11:21:29.010 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:29.011 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 11:21:29.012 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.86\n",
      "2021-08-25 11:21:29.013 | INFO     | src.policies:train:109 - Episode 755\n",
      "2021-08-25 11:21:29.025 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:29.026 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:21:29.027 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.84\n",
      "2021-08-25 11:21:29.028 | INFO     | src.policies:train:109 - Episode 756\n",
      "2021-08-25 11:21:29.071 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:29.073 | INFO     | src.policies:train:121 - Mean episode return: 105.0\n",
      "2021-08-25 11:21:29.074 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.73\n",
      "2021-08-25 11:21:29.075 | WARNING  | src.policies:train:131 - The actual batch size is 275, instead of 200\n",
      "2021-08-25 11:21:29.083 | INFO     | src.policies:train:157 - Total loss: 1.0092881917953491\n",
      "2021-08-25 11:21:29.086 | INFO     | src.policies:train:103 - Epoch 92 / 800\n",
      "2021-08-25 11:21:29.087 | INFO     | src.policies:train:109 - Episode 757\n",
      "2021-08-25 11:21:29.097 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:29.099 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:21:29.100 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.69\n",
      "2021-08-25 11:21:29.100 | INFO     | src.policies:train:109 - Episode 758\n",
      "2021-08-25 11:21:29.118 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:29.119 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 11:21:29.120 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.93\n",
      "2021-08-25 11:21:29.121 | INFO     | src.policies:train:109 - Episode 759\n",
      "2021-08-25 11:21:29.137 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:29.138 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:21:29.139 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.0\n",
      "2021-08-25 11:21:29.140 | INFO     | src.policies:train:109 - Episode 760\n",
      "2021-08-25 11:21:29.154 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:29.155 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:21:29.156 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.1\n",
      "2021-08-25 11:21:29.157 | INFO     | src.policies:train:109 - Episode 761\n",
      "2021-08-25 11:21:29.193 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:29.194 | INFO     | src.policies:train:121 - Mean episode return: 86.0\n",
      "2021-08-25 11:21:29.196 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.34\n",
      "2021-08-25 11:21:29.196 | INFO     | src.policies:train:109 - Episode 762\n",
      "2021-08-25 11:21:29.211 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:29.213 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 11:21:29.214 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.43\n",
      "2021-08-25 11:21:29.215 | WARNING  | src.policies:train:131 - The actual batch size is 220, instead of 200\n",
      "2021-08-25 11:21:29.221 | INFO     | src.policies:train:157 - Total loss: 1.0022979974746704\n",
      "2021-08-25 11:21:29.225 | INFO     | src.policies:train:103 - Epoch 93 / 800\n",
      "2021-08-25 11:21:29.226 | INFO     | src.policies:train:109 - Episode 763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:29.237 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:29.239 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:21:29.239 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.25\n",
      "2021-08-25 11:21:29.241 | INFO     | src.policies:train:109 - Episode 764\n",
      "2021-08-25 11:21:29.252 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:29.253 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:21:29.254 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.31\n",
      "2021-08-25 11:21:29.255 | INFO     | src.policies:train:109 - Episode 765\n",
      "2021-08-25 11:21:29.271 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:29.273 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 11:21:29.274 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.43\n",
      "2021-08-25 11:21:29.275 | INFO     | src.policies:train:109 - Episode 766\n",
      "2021-08-25 11:21:29.291 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:29.293 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 11:21:29.294 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.25\n",
      "2021-08-25 11:21:29.295 | INFO     | src.policies:train:109 - Episode 767\n",
      "2021-08-25 11:21:29.309 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:29.310 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 11:21:29.312 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.37\n",
      "2021-08-25 11:21:29.312 | INFO     | src.policies:train:109 - Episode 768\n",
      "2021-08-25 11:21:29.322 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:29.324 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:29.325 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.15\n",
      "2021-08-25 11:21:29.326 | INFO     | src.policies:train:109 - Episode 769\n",
      "2021-08-25 11:21:29.334 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:29.336 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:21:29.337 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.65\n",
      "2021-08-25 11:21:29.337 | INFO     | src.policies:train:109 - Episode 770\n",
      "2021-08-25 11:21:29.356 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:29.357 | INFO     | src.policies:train:121 - Mean episode return: 41.0\n",
      "2021-08-25 11:21:29.358 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.83\n",
      "2021-08-25 11:21:29.360 | WARNING  | src.policies:train:131 - The actual batch size is 204, instead of 200\n",
      "2021-08-25 11:21:29.367 | INFO     | src.policies:train:157 - Total loss: 1.0018811225891113\n",
      "2021-08-25 11:21:29.371 | INFO     | src.policies:train:103 - Epoch 94 / 800\n",
      "2021-08-25 11:21:29.372 | INFO     | src.policies:train:109 - Episode 771\n",
      "2021-08-25 11:21:29.382 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:29.384 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:21:29.385 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.88\n",
      "2021-08-25 11:21:29.385 | INFO     | src.policies:train:109 - Episode 772\n",
      "2021-08-25 11:21:29.393 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:29.394 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:29.395 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.86\n",
      "2021-08-25 11:21:29.396 | INFO     | src.policies:train:109 - Episode 773\n",
      "2021-08-25 11:21:29.422 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:29.423 | INFO     | src.policies:train:121 - Mean episode return: 57.0\n",
      "2021-08-25 11:21:29.424 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.25\n",
      "2021-08-25 11:21:29.425 | INFO     | src.policies:train:109 - Episode 774\n",
      "2021-08-25 11:21:29.436 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:29.438 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:21:29.439 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.96\n",
      "2021-08-25 11:21:29.440 | INFO     | src.policies:train:109 - Episode 775\n",
      "2021-08-25 11:21:29.450 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:29.451 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:29.452 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.01\n",
      "2021-08-25 11:21:29.453 | INFO     | src.policies:train:109 - Episode 776\n",
      "2021-08-25 11:21:29.470 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:29.472 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 11:21:29.473 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.08\n",
      "2021-08-25 11:21:29.474 | INFO     | src.policies:train:109 - Episode 777\n",
      "2021-08-25 11:21:29.482 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:29.483 | INFO     | src.policies:train:121 - Mean episode return: 9.0\n",
      "2021-08-25 11:21:29.484 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.01\n",
      "2021-08-25 11:21:29.485 | INFO     | src.policies:train:109 - Episode 778\n",
      "2021-08-25 11:21:29.516 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:29.517 | INFO     | src.policies:train:121 - Mean episode return: 70.0\n",
      "2021-08-25 11:21:29.518 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.54\n",
      "2021-08-25 11:21:29.519 | WARNING  | src.policies:train:131 - The actual batch size is 241, instead of 200\n",
      "2021-08-25 11:21:29.526 | INFO     | src.policies:train:157 - Total loss: 1.0025992393493652\n",
      "2021-08-25 11:21:29.529 | INFO     | src.policies:train:103 - Epoch 95 / 800\n",
      "2021-08-25 11:21:29.531 | INFO     | src.policies:train:109 - Episode 779\n",
      "2021-08-25 11:21:29.544 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:29.545 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:21:29.546 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.65\n",
      "2021-08-25 11:21:29.547 | INFO     | src.policies:train:109 - Episode 780\n",
      "2021-08-25 11:21:29.563 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:29.564 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 11:21:29.565 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.53\n",
      "2021-08-25 11:21:29.566 | INFO     | src.policies:train:109 - Episode 781\n",
      "2021-08-25 11:21:29.579 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:29.580 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:21:29.581 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.44\n",
      "2021-08-25 11:21:29.582 | INFO     | src.policies:train:109 - Episode 782\n",
      "2021-08-25 11:21:29.592 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:29.593 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:29.594 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.16\n",
      "2021-08-25 11:21:29.595 | INFO     | src.policies:train:109 - Episode 783\n",
      "2021-08-25 11:21:29.605 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:29.606 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:21:29.607 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.7\n",
      "2021-08-25 11:21:29.608 | INFO     | src.policies:train:109 - Episode 784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:29.620 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:29.621 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:21:29.622 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.61\n",
      "2021-08-25 11:21:29.623 | INFO     | src.policies:train:109 - Episode 785\n",
      "2021-08-25 11:21:29.632 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:29.634 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:29.635 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.67\n",
      "2021-08-25 11:21:29.636 | INFO     | src.policies:train:109 - Episode 786\n",
      "2021-08-25 11:21:29.650 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:29.651 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 11:21:29.652 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.64\n",
      "2021-08-25 11:21:29.653 | INFO     | src.policies:train:109 - Episode 787\n",
      "2021-08-25 11:21:29.665 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:29.666 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:21:29.667 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.57\n",
      "2021-08-25 11:21:29.668 | WARNING  | src.policies:train:131 - The actual batch size is 210, instead of 200\n",
      "2021-08-25 11:21:29.676 | INFO     | src.policies:train:157 - Total loss: 1.002075433731079\n",
      "2021-08-25 11:21:29.679 | INFO     | src.policies:train:103 - Epoch 96 / 800\n",
      "2021-08-25 11:21:29.680 | INFO     | src.policies:train:109 - Episode 788\n",
      "2021-08-25 11:21:29.696 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:29.697 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 11:21:29.698 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.76\n",
      "2021-08-25 11:21:29.699 | INFO     | src.policies:train:109 - Episode 789\n",
      "2021-08-25 11:21:29.707 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:29.708 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:29.709 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.68\n",
      "2021-08-25 11:21:29.710 | INFO     | src.policies:train:109 - Episode 790\n",
      "2021-08-25 11:21:29.723 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:29.725 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:21:29.726 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.81\n",
      "2021-08-25 11:21:29.727 | INFO     | src.policies:train:109 - Episode 791\n",
      "2021-08-25 11:21:29.747 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:29.749 | INFO     | src.policies:train:121 - Mean episode return: 46.0\n",
      "2021-08-25 11:21:29.749 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.11\n",
      "2021-08-25 11:21:29.750 | INFO     | src.policies:train:109 - Episode 792\n",
      "2021-08-25 11:21:29.761 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:29.763 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:29.763 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.19\n",
      "2021-08-25 11:21:29.764 | INFO     | src.policies:train:109 - Episode 793\n",
      "2021-08-25 11:21:29.775 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:29.776 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:21:29.777 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.95\n",
      "2021-08-25 11:21:29.778 | INFO     | src.policies:train:109 - Episode 794\n",
      "2021-08-25 11:21:29.788 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:29.789 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:29.790 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.99\n",
      "2021-08-25 11:21:29.791 | INFO     | src.policies:train:109 - Episode 795\n",
      "2021-08-25 11:21:29.807 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:29.808 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 11:21:29.809 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.04\n",
      "2021-08-25 11:21:29.810 | WARNING  | src.policies:train:131 - The actual batch size is 203, instead of 200\n",
      "2021-08-25 11:21:29.818 | INFO     | src.policies:train:157 - Total loss: 1.001955509185791\n",
      "2021-08-25 11:21:29.821 | INFO     | src.policies:train:103 - Epoch 97 / 800\n",
      "2021-08-25 11:21:29.823 | INFO     | src.policies:train:109 - Episode 796\n",
      "2021-08-25 11:21:29.831 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:29.832 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:29.834 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.04\n",
      "2021-08-25 11:21:29.835 | INFO     | src.policies:train:109 - Episode 797\n",
      "2021-08-25 11:21:29.861 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:29.862 | INFO     | src.policies:train:121 - Mean episode return: 56.0\n",
      "2021-08-25 11:21:29.863 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.44\n",
      "2021-08-25 11:21:29.864 | INFO     | src.policies:train:109 - Episode 798\n",
      "2021-08-25 11:21:29.887 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:29.888 | INFO     | src.policies:train:121 - Mean episode return: 50.0\n",
      "2021-08-25 11:21:29.889 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.77\n",
      "2021-08-25 11:21:29.890 | INFO     | src.policies:train:109 - Episode 799\n",
      "2021-08-25 11:21:29.925 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:29.926 | INFO     | src.policies:train:121 - Mean episode return: 82.0\n",
      "2021-08-25 11:21:29.927 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.29\n",
      "2021-08-25 11:21:29.928 | WARNING  | src.policies:train:131 - The actual batch size is 203, instead of 200\n",
      "2021-08-25 11:21:29.935 | INFO     | src.policies:train:157 - Total loss: 1.0018161535263062\n",
      "2021-08-25 11:21:29.938 | INFO     | src.policies:train:103 - Epoch 98 / 800\n",
      "2021-08-25 11:21:29.939 | INFO     | src.policies:train:109 - Episode 800\n",
      "2021-08-25 11:21:29.961 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:29.962 | INFO     | src.policies:train:121 - Mean episode return: 48.0\n",
      "2021-08-25 11:21:29.963 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.61\n",
      "2021-08-25 11:21:29.964 | INFO     | src.policies:train:109 - Episode 801\n",
      "2021-08-25 11:21:29.971 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:29.973 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 11:21:29.973 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.49\n",
      "2021-08-25 11:21:29.975 | INFO     | src.policies:train:109 - Episode 802\n",
      "2021-08-25 11:21:30.003 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:30.004 | INFO     | src.policies:train:121 - Mean episode return: 65.0\n",
      "2021-08-25 11:21:30.005 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.97\n",
      "2021-08-25 11:21:30.006 | INFO     | src.policies:train:109 - Episode 803\n",
      "2021-08-25 11:21:30.021 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:30.023 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 11:21:30.024 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.02\n",
      "2021-08-25 11:21:30.025 | INFO     | src.policies:train:109 - Episode 804\n",
      "2021-08-25 11:21:30.037 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:30.038 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:21:30.039 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.81\n",
      "2021-08-25 11:21:30.040 | INFO     | src.policies:train:109 - Episode 805\n",
      "2021-08-25 11:21:30.050 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:30.051 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:30.052 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.54\n",
      "2021-08-25 11:21:30.053 | INFO     | src.policies:train:109 - Episode 806\n",
      "2021-08-25 11:21:30.070 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:30.072 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 11:21:30.073 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.74\n",
      "2021-08-25 11:21:30.074 | WARNING  | src.policies:train:131 - The actual batch size is 226, instead of 200\n",
      "2021-08-25 11:21:30.081 | INFO     | src.policies:train:157 - Total loss: 1.002371907234192\n",
      "2021-08-25 11:21:30.084 | INFO     | src.policies:train:103 - Epoch 99 / 800\n",
      "2021-08-25 11:21:30.085 | INFO     | src.policies:train:109 - Episode 807\n",
      "2021-08-25 11:21:30.093 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:30.094 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:21:30.095 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.7\n",
      "2021-08-25 11:21:30.096 | INFO     | src.policies:train:109 - Episode 808\n",
      "2021-08-25 11:21:30.106 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:30.107 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:21:30.108 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.46\n",
      "2021-08-25 11:21:30.109 | INFO     | src.policies:train:109 - Episode 809\n",
      "2021-08-25 11:21:30.124 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:30.125 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:21:30.126 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.58\n",
      "2021-08-25 11:21:30.127 | INFO     | src.policies:train:109 - Episode 810\n",
      "2021-08-25 11:21:30.139 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:30.140 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:21:30.141 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.53\n",
      "2021-08-25 11:21:30.142 | INFO     | src.policies:train:109 - Episode 811\n",
      "2021-08-25 11:21:30.152 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:30.154 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:21:30.155 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.4\n",
      "2021-08-25 11:21:30.156 | INFO     | src.policies:train:109 - Episode 812\n",
      "2021-08-25 11:21:30.164 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:30.166 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:21:30.166 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.28\n",
      "2021-08-25 11:21:30.167 | INFO     | src.policies:train:109 - Episode 813\n",
      "2021-08-25 11:21:30.182 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:30.184 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:21:30.185 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.33\n",
      "2021-08-25 11:21:30.186 | INFO     | src.policies:train:109 - Episode 814\n",
      "2021-08-25 11:21:30.200 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:30.201 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 11:21:30.202 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.36\n",
      "2021-08-25 11:21:30.203 | INFO     | src.policies:train:109 - Episode 815\n",
      "2021-08-25 11:21:30.220 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:30.222 | INFO     | src.policies:train:121 - Mean episode return: 38.0\n",
      "2021-08-25 11:21:30.222 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.54\n",
      "2021-08-25 11:21:30.223 | WARNING  | src.policies:train:131 - The actual batch size is 203, instead of 200\n",
      "2021-08-25 11:21:30.231 | INFO     | src.policies:train:157 - Total loss: 1.0017503499984741\n",
      "2021-08-25 11:21:30.234 | INFO     | src.policies:train:103 - Epoch 100 / 800\n",
      "2021-08-25 11:21:30.235 | INFO     | src.policies:train:109 - Episode 816\n",
      "2021-08-25 11:21:30.242 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:30.243 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 11:21:30.244 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.46\n",
      "2021-08-25 11:21:30.245 | INFO     | src.policies:train:109 - Episode 817\n",
      "2021-08-25 11:21:30.257 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:30.258 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:21:30.260 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.53\n",
      "2021-08-25 11:21:30.261 | INFO     | src.policies:train:109 - Episode 818\n",
      "2021-08-25 11:21:30.270 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:30.271 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:21:30.272 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.44\n",
      "2021-08-25 11:21:30.273 | INFO     | src.policies:train:109 - Episode 819\n",
      "2021-08-25 11:21:30.284 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:30.285 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:30.287 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.32\n",
      "2021-08-25 11:21:30.287 | INFO     | src.policies:train:109 - Episode 820\n",
      "2021-08-25 11:21:30.303 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:30.304 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:21:30.305 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.5\n",
      "2021-08-25 11:21:30.306 | INFO     | src.policies:train:109 - Episode 821\n",
      "2021-08-25 11:21:30.321 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:30.322 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 11:21:30.323 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.46\n",
      "2021-08-25 11:21:30.324 | INFO     | src.policies:train:109 - Episode 822\n",
      "2021-08-25 11:21:30.335 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:30.336 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:21:30.337 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.54\n",
      "2021-08-25 11:21:30.338 | INFO     | src.policies:train:109 - Episode 823\n",
      "2021-08-25 11:21:30.364 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:30.366 | INFO     | src.policies:train:121 - Mean episode return: 60.0\n",
      "2021-08-25 11:21:30.366 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.89\n",
      "2021-08-25 11:21:30.367 | WARNING  | src.policies:train:131 - The actual batch size is 201, instead of 200\n",
      "2021-08-25 11:21:30.375 | INFO     | src.policies:train:157 - Total loss: 1.001828670501709\n",
      "2021-08-25 11:21:30.378 | INFO     | src.policies:train:103 - Epoch 101 / 800\n",
      "2021-08-25 11:21:30.379 | INFO     | src.policies:train:109 - Episode 824\n",
      "2021-08-25 11:21:30.408 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:30.409 | INFO     | src.policies:train:121 - Mean episode return: 67.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:30.411 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.18\n",
      "2021-08-25 11:21:30.411 | INFO     | src.policies:train:109 - Episode 825\n",
      "2021-08-25 11:21:30.420 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:30.421 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:21:30.422 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.2\n",
      "2021-08-25 11:21:30.423 | INFO     | src.policies:train:109 - Episode 826\n",
      "2021-08-25 11:21:30.435 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:30.436 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:21:30.437 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.21\n",
      "2021-08-25 11:21:30.438 | INFO     | src.policies:train:109 - Episode 827\n",
      "2021-08-25 11:21:30.453 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:30.455 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:21:30.456 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.0\n",
      "2021-08-25 11:21:30.457 | INFO     | src.policies:train:109 - Episode 828\n",
      "2021-08-25 11:21:30.475 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:30.477 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 11:21:30.478 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.74\n",
      "2021-08-25 11:21:30.479 | INFO     | src.policies:train:109 - Episode 829\n",
      "2021-08-25 11:21:30.488 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:30.489 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:21:30.490 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.54\n",
      "2021-08-25 11:21:30.491 | INFO     | src.policies:train:109 - Episode 830\n",
      "2021-08-25 11:21:30.500 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:30.502 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:21:30.503 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.49\n",
      "2021-08-25 11:21:30.504 | INFO     | src.policies:train:109 - Episode 831\n",
      "2021-08-25 11:21:30.518 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:30.519 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 11:21:30.520 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.0\n",
      "2021-08-25 11:21:30.521 | WARNING  | src.policies:train:131 - The actual batch size is 220, instead of 200\n",
      "2021-08-25 11:21:30.528 | INFO     | src.policies:train:157 - Total loss: 1.0022815465927124\n",
      "2021-08-25 11:21:30.531 | INFO     | src.policies:train:103 - Epoch 102 / 800\n",
      "2021-08-25 11:21:30.532 | INFO     | src.policies:train:109 - Episode 832\n",
      "2021-08-25 11:21:30.544 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:30.546 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:21:30.546 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.82\n",
      "2021-08-25 11:21:30.547 | INFO     | src.policies:train:109 - Episode 833\n",
      "2021-08-25 11:21:30.564 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:30.565 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 11:21:30.566 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.03\n",
      "2021-08-25 11:21:30.567 | INFO     | src.policies:train:109 - Episode 834\n",
      "2021-08-25 11:21:30.584 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:30.585 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 11:21:30.586 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.08\n",
      "2021-08-25 11:21:30.587 | INFO     | src.policies:train:109 - Episode 835\n",
      "2021-08-25 11:21:30.597 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:30.599 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:30.600 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.02\n",
      "2021-08-25 11:21:30.601 | INFO     | src.policies:train:109 - Episode 836\n",
      "2021-08-25 11:21:30.624 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:30.626 | INFO     | src.policies:train:121 - Mean episode return: 52.0\n",
      "2021-08-25 11:21:30.626 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.28\n",
      "2021-08-25 11:21:30.627 | INFO     | src.policies:train:109 - Episode 837\n",
      "2021-08-25 11:21:30.642 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:30.643 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 11:21:30.644 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.34\n",
      "2021-08-25 11:21:30.645 | INFO     | src.policies:train:109 - Episode 838\n",
      "2021-08-25 11:21:30.664 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:30.666 | INFO     | src.policies:train:121 - Mean episode return: 42.0\n",
      "2021-08-25 11:21:30.667 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.52\n",
      "2021-08-25 11:21:30.667 | WARNING  | src.policies:train:131 - The actual batch size is 231, instead of 200\n",
      "2021-08-25 11:21:30.674 | INFO     | src.policies:train:157 - Total loss: 1.0024094581604004\n",
      "2021-08-25 11:21:30.678 | INFO     | src.policies:train:103 - Epoch 103 / 800\n",
      "2021-08-25 11:21:30.679 | INFO     | src.policies:train:109 - Episode 839\n",
      "2021-08-25 11:21:30.691 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:30.692 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 11:21:30.693 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.62\n",
      "2021-08-25 11:21:30.694 | INFO     | src.policies:train:109 - Episode 840\n",
      "2021-08-25 11:21:30.702 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:30.703 | INFO     | src.policies:train:121 - Mean episode return: 8.0\n",
      "2021-08-25 11:21:30.704 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.56\n",
      "2021-08-25 11:21:30.705 | INFO     | src.policies:train:109 - Episode 841\n",
      "2021-08-25 11:21:30.715 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:30.717 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:21:30.717 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.39\n",
      "2021-08-25 11:21:30.718 | INFO     | src.policies:train:109 - Episode 842\n",
      "2021-08-25 11:21:30.731 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:30.733 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:21:30.734 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.31\n",
      "2021-08-25 11:21:30.734 | INFO     | src.policies:train:109 - Episode 843\n",
      "2021-08-25 11:21:30.745 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:30.746 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:30.747 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.31\n",
      "2021-08-25 11:21:30.748 | INFO     | src.policies:train:109 - Episode 844\n",
      "2021-08-25 11:21:30.768 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:30.769 | INFO     | src.policies:train:121 - Mean episode return: 43.0\n",
      "2021-08-25 11:21:30.770 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.18\n",
      "2021-08-25 11:21:30.771 | INFO     | src.policies:train:109 - Episode 845\n",
      "2021-08-25 11:21:30.784 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:30.786 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:30.786 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.11\n",
      "2021-08-25 11:21:30.787 | INFO     | src.policies:train:109 - Episode 846\n",
      "2021-08-25 11:21:30.798 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:30.799 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:21:30.800 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.93\n",
      "2021-08-25 11:21:30.801 | INFO     | src.policies:train:109 - Episode 847\n",
      "2021-08-25 11:21:30.817 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:30.818 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 11:21:30.819 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.94\n",
      "2021-08-25 11:21:30.820 | WARNING  | src.policies:train:131 - The actual batch size is 205, instead of 200\n",
      "2021-08-25 11:21:30.828 | INFO     | src.policies:train:157 - Total loss: 1.0019522905349731\n",
      "2021-08-25 11:21:30.831 | INFO     | src.policies:train:103 - Epoch 104 / 800\n",
      "2021-08-25 11:21:30.832 | INFO     | src.policies:train:109 - Episode 848\n",
      "2021-08-25 11:21:30.840 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:30.842 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:30.842 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.57\n",
      "2021-08-25 11:21:30.843 | INFO     | src.policies:train:109 - Episode 849\n",
      "2021-08-25 11:21:30.852 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:30.853 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:21:30.854 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.3\n",
      "2021-08-25 11:21:30.855 | INFO     | src.policies:train:109 - Episode 850\n",
      "2021-08-25 11:21:30.864 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:30.866 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:30.867 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.26\n",
      "2021-08-25 11:21:30.867 | INFO     | src.policies:train:109 - Episode 851\n",
      "2021-08-25 11:21:30.879 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:30.881 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:21:30.881 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.29\n",
      "2021-08-25 11:21:30.882 | INFO     | src.policies:train:109 - Episode 852\n",
      "2021-08-25 11:21:30.895 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:30.896 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:21:30.897 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.28\n",
      "2021-08-25 11:21:30.898 | INFO     | src.policies:train:109 - Episode 853\n",
      "2021-08-25 11:21:30.909 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:30.910 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:21:30.911 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.27\n",
      "2021-08-25 11:21:30.912 | INFO     | src.policies:train:109 - Episode 854\n",
      "2021-08-25 11:21:30.922 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:30.923 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:30.924 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.15\n",
      "2021-08-25 11:21:30.925 | INFO     | src.policies:train:109 - Episode 855\n",
      "2021-08-25 11:21:30.935 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:30.936 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:30.937 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.11\n",
      "2021-08-25 11:21:30.938 | INFO     | src.policies:train:109 - Episode 856\n",
      "2021-08-25 11:21:30.949 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:30.950 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:30.951 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.22\n",
      "2021-08-25 11:21:30.952 | INFO     | src.policies:train:109 - Episode 857\n",
      "2021-08-25 11:21:30.960 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:30.962 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:21:30.963 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.15\n",
      "2021-08-25 11:21:30.964 | INFO     | src.policies:train:109 - Episode 858\n",
      "2021-08-25 11:21:30.995 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:30.997 | INFO     | src.policies:train:121 - Mean episode return: 78.0\n",
      "2021-08-25 11:21:30.998 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.57\n",
      "2021-08-25 11:21:30.999 | WARNING  | src.policies:train:131 - The actual batch size is 244, instead of 200\n",
      "2021-08-25 11:21:31.007 | INFO     | src.policies:train:157 - Total loss: 1.0027551651000977\n",
      "2021-08-25 11:21:31.010 | INFO     | src.policies:train:103 - Epoch 105 / 800\n",
      "2021-08-25 11:21:31.011 | INFO     | src.policies:train:109 - Episode 859\n",
      "2021-08-25 11:21:31.019 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:31.021 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:21:31.022 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.45\n",
      "2021-08-25 11:21:31.023 | INFO     | src.policies:train:109 - Episode 860\n",
      "2021-08-25 11:21:31.033 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:31.034 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:31.035 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.38\n",
      "2021-08-25 11:21:31.036 | INFO     | src.policies:train:109 - Episode 861\n",
      "2021-08-25 11:21:31.047 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:31.048 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:21:31.049 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.73\n",
      "2021-08-25 11:21:31.050 | INFO     | src.policies:train:109 - Episode 862\n",
      "2021-08-25 11:21:31.061 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:31.062 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:21:31.063 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.6\n",
      "2021-08-25 11:21:31.064 | INFO     | src.policies:train:109 - Episode 863\n",
      "2021-08-25 11:21:31.085 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:31.086 | INFO     | src.policies:train:121 - Mean episode return: 46.0\n",
      "2021-08-25 11:21:31.087 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.82\n",
      "2021-08-25 11:21:31.088 | INFO     | src.policies:train:109 - Episode 864\n",
      "2021-08-25 11:21:31.106 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:31.107 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 11:21:31.108 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.99\n",
      "2021-08-25 11:21:31.109 | INFO     | src.policies:train:109 - Episode 865\n",
      "2021-08-25 11:21:31.128 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:31.129 | INFO     | src.policies:train:121 - Mean episode return: 39.0\n",
      "2021-08-25 11:21:31.130 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.04\n",
      "2021-08-25 11:21:31.131 | INFO     | src.policies:train:109 - Episode 866\n",
      "2021-08-25 11:21:31.140 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:31.141 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:31.143 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.85\n",
      "2021-08-25 11:21:31.144 | WARNING  | src.policies:train:131 - The actual batch size is 201, instead of 200\n",
      "2021-08-25 11:21:31.151 | INFO     | src.policies:train:157 - Total loss: 1.001747965812683\n",
      "2021-08-25 11:21:31.155 | INFO     | src.policies:train:103 - Epoch 106 / 800\n",
      "2021-08-25 11:21:31.156 | INFO     | src.policies:train:109 - Episode 867\n",
      "2021-08-25 11:21:31.171 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:31.173 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 11:21:31.174 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.89\n",
      "2021-08-25 11:21:31.175 | INFO     | src.policies:train:109 - Episode 868\n",
      "2021-08-25 11:21:31.186 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:31.187 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:31.188 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.91\n",
      "2021-08-25 11:21:31.189 | INFO     | src.policies:train:109 - Episode 869\n",
      "2021-08-25 11:21:31.210 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:31.212 | INFO     | src.policies:train:121 - Mean episode return: 44.0\n",
      "2021-08-25 11:21:31.213 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.21\n",
      "2021-08-25 11:21:31.214 | INFO     | src.policies:train:109 - Episode 870\n",
      "2021-08-25 11:21:31.241 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:31.242 | INFO     | src.policies:train:121 - Mean episode return: 58.0\n",
      "2021-08-25 11:21:31.243 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.38\n",
      "2021-08-25 11:21:31.244 | INFO     | src.policies:train:109 - Episode 871\n",
      "2021-08-25 11:21:31.255 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:31.257 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:21:31.258 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.38\n",
      "2021-08-25 11:21:31.259 | INFO     | src.policies:train:109 - Episode 872\n",
      "2021-08-25 11:21:31.270 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:31.271 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:21:31.272 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.45\n",
      "2021-08-25 11:21:31.273 | INFO     | src.policies:train:109 - Episode 873\n",
      "2021-08-25 11:21:31.291 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:31.292 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 11:21:31.293 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.24\n",
      "2021-08-25 11:21:31.294 | WARNING  | src.policies:train:131 - The actual batch size is 225, instead of 200\n",
      "2021-08-25 11:21:31.302 | INFO     | src.policies:train:157 - Total loss: 1.002424955368042\n",
      "2021-08-25 11:21:31.305 | INFO     | src.policies:train:103 - Epoch 107 / 800\n",
      "2021-08-25 11:21:31.307 | INFO     | src.policies:train:109 - Episode 874\n",
      "2021-08-25 11:21:31.316 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:31.318 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:21:31.319 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.23\n",
      "2021-08-25 11:21:31.319 | INFO     | src.policies:train:109 - Episode 875\n",
      "2021-08-25 11:21:31.331 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:31.333 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:21:31.334 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.28\n",
      "2021-08-25 11:21:31.335 | INFO     | src.policies:train:109 - Episode 876\n",
      "2021-08-25 11:21:31.345 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:31.346 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:21:31.347 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.06\n",
      "2021-08-25 11:21:31.348 | INFO     | src.policies:train:109 - Episode 877\n",
      "2021-08-25 11:21:31.360 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:31.361 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:21:31.362 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.17\n",
      "2021-08-25 11:21:31.363 | INFO     | src.policies:train:109 - Episode 878\n",
      "2021-08-25 11:21:31.394 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:31.395 | INFO     | src.policies:train:121 - Mean episode return: 73.0\n",
      "2021-08-25 11:21:31.397 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.2\n",
      "2021-08-25 11:21:31.397 | INFO     | src.policies:train:109 - Episode 879\n",
      "2021-08-25 11:21:31.406 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:31.407 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:31.408 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.06\n",
      "2021-08-25 11:21:31.409 | INFO     | src.policies:train:109 - Episode 880\n",
      "2021-08-25 11:21:31.428 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:31.429 | INFO     | src.policies:train:121 - Mean episode return: 39.0\n",
      "2021-08-25 11:21:31.430 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.15\n",
      "2021-08-25 11:21:31.431 | WARNING  | src.policies:train:131 - The actual batch size is 202, instead of 200\n",
      "2021-08-25 11:21:31.438 | INFO     | src.policies:train:157 - Total loss: 1.0016859769821167\n",
      "2021-08-25 11:21:31.441 | INFO     | src.policies:train:103 - Epoch 108 / 800\n",
      "2021-08-25 11:21:31.442 | INFO     | src.policies:train:109 - Episode 881\n",
      "2021-08-25 11:21:31.452 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:31.454 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:21:31.455 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.08\n",
      "2021-08-25 11:21:31.456 | INFO     | src.policies:train:109 - Episode 882\n",
      "2021-08-25 11:21:31.468 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:31.469 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:21:31.470 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.13\n",
      "2021-08-25 11:21:31.470 | INFO     | src.policies:train:109 - Episode 883\n",
      "2021-08-25 11:21:31.485 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:31.487 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 11:21:31.488 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.23\n",
      "2021-08-25 11:21:31.489 | INFO     | src.policies:train:109 - Episode 884\n",
      "2021-08-25 11:21:31.501 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:31.502 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:21:31.503 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.21\n",
      "2021-08-25 11:21:31.504 | INFO     | src.policies:train:109 - Episode 885\n",
      "2021-08-25 11:21:31.512 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:31.513 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:31.514 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.16\n",
      "2021-08-25 11:21:31.515 | INFO     | src.policies:train:109 - Episode 886\n",
      "2021-08-25 11:21:31.528 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:31.529 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:21:31.530 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:31.531 | INFO     | src.policies:train:109 - Episode 887\n",
      "2021-08-25 11:21:31.545 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:31.546 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:21:31.547 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.15\n",
      "2021-08-25 11:21:31.548 | INFO     | src.policies:train:109 - Episode 888\n",
      "2021-08-25 11:21:31.561 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:31.562 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:21:31.564 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.02\n",
      "2021-08-25 11:21:31.564 | INFO     | src.policies:train:109 - Episode 889\n",
      "2021-08-25 11:21:31.572 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:31.574 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:21:31.574 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.01\n",
      "2021-08-25 11:21:31.576 | INFO     | src.policies:train:109 - Episode 890\n",
      "2021-08-25 11:21:31.597 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:31.598 | INFO     | src.policies:train:121 - Mean episode return: 48.0\n",
      "2021-08-25 11:21:31.600 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.23\n",
      "2021-08-25 11:21:31.600 | WARNING  | src.policies:train:131 - The actual batch size is 233, instead of 200\n",
      "2021-08-25 11:21:31.608 | INFO     | src.policies:train:157 - Total loss: 1.002566933631897\n",
      "2021-08-25 11:21:31.611 | INFO     | src.policies:train:103 - Epoch 109 / 800\n",
      "2021-08-25 11:21:31.613 | INFO     | src.policies:train:109 - Episode 891\n",
      "2021-08-25 11:21:31.623 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:31.624 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:21:31.625 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.98\n",
      "2021-08-25 11:21:31.626 | INFO     | src.policies:train:109 - Episode 892\n",
      "2021-08-25 11:21:31.641 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:31.643 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 11:21:31.644 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.14\n",
      "2021-08-25 11:21:31.645 | INFO     | src.policies:train:109 - Episode 893\n",
      "2021-08-25 11:21:31.660 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:31.662 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 11:21:31.662 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.27\n",
      "2021-08-25 11:21:31.664 | INFO     | src.policies:train:109 - Episode 894\n",
      "2021-08-25 11:21:31.677 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:31.678 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:21:31.679 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.38\n",
      "2021-08-25 11:21:31.680 | INFO     | src.policies:train:109 - Episode 895\n",
      "2021-08-25 11:21:31.691 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:31.693 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:21:31.694 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.24\n",
      "2021-08-25 11:21:31.695 | INFO     | src.policies:train:109 - Episode 896\n",
      "2021-08-25 11:21:31.710 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:31.711 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 11:21:31.712 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.41\n",
      "2021-08-25 11:21:31.713 | INFO     | src.policies:train:109 - Episode 897\n",
      "2021-08-25 11:21:31.736 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:31.738 | INFO     | src.policies:train:121 - Mean episode return: 50.0\n",
      "2021-08-25 11:21:31.739 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.35\n",
      "2021-08-25 11:21:31.740 | WARNING  | src.policies:train:131 - The actual batch size is 212, instead of 200\n",
      "2021-08-25 11:21:31.748 | INFO     | src.policies:train:157 - Total loss: 1.0020835399627686\n",
      "2021-08-25 11:21:31.751 | INFO     | src.policies:train:103 - Epoch 110 / 800\n",
      "2021-08-25 11:21:31.753 | INFO     | src.policies:train:109 - Episode 898\n",
      "2021-08-25 11:21:31.779 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:31.780 | INFO     | src.policies:train:121 - Mean episode return: 62.0\n",
      "2021-08-25 11:21:31.782 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.47\n",
      "2021-08-25 11:21:31.782 | INFO     | src.policies:train:109 - Episode 899\n",
      "2021-08-25 11:21:31.806 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:31.807 | INFO     | src.policies:train:121 - Mean episode return: 52.0\n",
      "2021-08-25 11:21:31.808 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.17\n",
      "2021-08-25 11:21:31.809 | INFO     | src.policies:train:109 - Episode 900\n",
      "2021-08-25 11:21:31.823 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:31.824 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 11:21:31.825 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.99\n",
      "2021-08-25 11:21:31.826 | INFO     | src.policies:train:109 - Episode 901\n",
      "2021-08-25 11:21:31.840 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:31.841 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 11:21:31.842 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.16\n",
      "2021-08-25 11:21:31.843 | INFO     | src.policies:train:109 - Episode 902\n",
      "2021-08-25 11:21:31.859 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:31.860 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 11:21:31.861 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 26.84\n",
      "2021-08-25 11:21:31.862 | WARNING  | src.policies:train:131 - The actual batch size is 204, instead of 200\n",
      "2021-08-25 11:21:31.869 | INFO     | src.policies:train:157 - Total loss: 1.0018947124481201\n",
      "2021-08-25 11:21:31.872 | INFO     | src.policies:train:103 - Epoch 111 / 800\n",
      "2021-08-25 11:21:31.874 | INFO     | src.policies:train:109 - Episode 903\n",
      "2021-08-25 11:21:31.899 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:31.901 | INFO     | src.policies:train:121 - Mean episode return: 59.0\n",
      "2021-08-25 11:21:31.902 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.12\n",
      "2021-08-25 11:21:31.903 | INFO     | src.policies:train:109 - Episode 904\n",
      "2021-08-25 11:21:31.917 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:31.919 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 11:21:31.919 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.2\n",
      "2021-08-25 11:21:31.921 | INFO     | src.policies:train:109 - Episode 905\n",
      "2021-08-25 11:21:31.931 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:31.932 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:31.934 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.19\n",
      "2021-08-25 11:21:31.934 | INFO     | src.policies:train:109 - Episode 906\n",
      "2021-08-25 11:21:31.965 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:31.967 | INFO     | src.policies:train:121 - Mean episode return: 71.0\n",
      "2021-08-25 11:21:31.968 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.55\n",
      "2021-08-25 11:21:31.969 | INFO     | src.policies:train:109 - Episode 907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:31.986 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:31.987 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 11:21:31.988 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.74\n",
      "2021-08-25 11:21:31.989 | WARNING  | src.policies:train:131 - The actual batch size is 206, instead of 200\n",
      "2021-08-25 11:21:31.998 | INFO     | src.policies:train:157 - Total loss: 1.0018831491470337\n",
      "2021-08-25 11:21:32.001 | INFO     | src.policies:train:103 - Epoch 112 / 800\n",
      "2021-08-25 11:21:32.002 | INFO     | src.policies:train:109 - Episode 908\n",
      "2021-08-25 11:21:32.012 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:32.014 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:32.016 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.75\n",
      "2021-08-25 11:21:32.017 | INFO     | src.policies:train:109 - Episode 909\n",
      "2021-08-25 11:21:32.028 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:32.029 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:21:32.030 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.67\n",
      "2021-08-25 11:21:32.031 | INFO     | src.policies:train:109 - Episode 910\n",
      "2021-08-25 11:21:32.039 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:32.040 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:32.041 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.57\n",
      "2021-08-25 11:21:32.042 | INFO     | src.policies:train:109 - Episode 911\n",
      "2021-08-25 11:21:32.054 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:32.055 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:21:32.056 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.61\n",
      "2021-08-25 11:21:32.057 | INFO     | src.policies:train:109 - Episode 912\n",
      "2021-08-25 11:21:32.067 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:32.068 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:21:32.069 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.63\n",
      "2021-08-25 11:21:32.070 | INFO     | src.policies:train:109 - Episode 913\n",
      "2021-08-25 11:21:32.093 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:32.094 | INFO     | src.policies:train:121 - Mean episode return: 52.0\n",
      "2021-08-25 11:21:32.095 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.86\n",
      "2021-08-25 11:21:32.096 | INFO     | src.policies:train:109 - Episode 914\n",
      "2021-08-25 11:21:32.113 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:32.114 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 11:21:32.115 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.88\n",
      "2021-08-25 11:21:32.116 | INFO     | src.policies:train:109 - Episode 915\n",
      "2021-08-25 11:21:32.130 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:32.131 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 11:21:32.132 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.75\n",
      "2021-08-25 11:21:32.133 | INFO     | src.policies:train:109 - Episode 916\n",
      "2021-08-25 11:21:32.145 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:32.147 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:21:32.148 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.88\n",
      "2021-08-25 11:21:32.149 | WARNING  | src.policies:train:131 - The actual batch size is 214, instead of 200\n",
      "2021-08-25 11:21:32.157 | INFO     | src.policies:train:157 - Total loss: 1.0021412372589111\n",
      "2021-08-25 11:21:32.160 | INFO     | src.policies:train:103 - Epoch 113 / 800\n",
      "2021-08-25 11:21:32.161 | INFO     | src.policies:train:109 - Episode 917\n",
      "2021-08-25 11:21:32.175 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:32.176 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 11:21:32.177 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.94\n",
      "2021-08-25 11:21:32.178 | INFO     | src.policies:train:109 - Episode 918\n",
      "2021-08-25 11:21:32.189 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:32.190 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:32.191 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.96\n",
      "2021-08-25 11:21:32.192 | INFO     | src.policies:train:109 - Episode 919\n",
      "2021-08-25 11:21:32.201 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:32.202 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:32.203 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.94\n",
      "2021-08-25 11:21:32.204 | INFO     | src.policies:train:109 - Episode 920\n",
      "2021-08-25 11:21:32.219 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:32.220 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 11:21:32.221 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.92\n",
      "2021-08-25 11:21:32.222 | INFO     | src.policies:train:109 - Episode 921\n",
      "2021-08-25 11:21:32.235 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:32.236 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 11:21:32.237 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.87\n",
      "2021-08-25 11:21:32.238 | INFO     | src.policies:train:109 - Episode 922\n",
      "2021-08-25 11:21:32.250 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:32.251 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:21:32.252 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.87\n",
      "2021-08-25 11:21:32.253 | INFO     | src.policies:train:109 - Episode 923\n",
      "2021-08-25 11:21:32.272 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:32.274 | INFO     | src.policies:train:121 - Mean episode return: 41.0\n",
      "2021-08-25 11:21:32.274 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.68\n",
      "2021-08-25 11:21:32.275 | INFO     | src.policies:train:109 - Episode 924\n",
      "2021-08-25 11:21:32.298 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:32.299 | INFO     | src.policies:train:121 - Mean episode return: 50.0\n",
      "2021-08-25 11:21:32.300 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.51\n",
      "2021-08-25 11:21:32.301 | WARNING  | src.policies:train:131 - The actual batch size is 221, instead of 200\n",
      "2021-08-25 11:21:32.309 | INFO     | src.policies:train:157 - Total loss: 1.0022984743118286\n",
      "2021-08-25 11:21:32.312 | INFO     | src.policies:train:103 - Epoch 114 / 800\n",
      "2021-08-25 11:21:32.313 | INFO     | src.policies:train:109 - Episode 925\n",
      "2021-08-25 11:21:32.335 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:32.336 | INFO     | src.policies:train:121 - Mean episode return: 49.0\n",
      "2021-08-25 11:21:32.337 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.89\n",
      "2021-08-25 11:21:32.338 | INFO     | src.policies:train:109 - Episode 926\n",
      "2021-08-25 11:21:32.348 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:32.349 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:32.350 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.82\n",
      "2021-08-25 11:21:32.351 | INFO     | src.policies:train:109 - Episode 927\n",
      "2021-08-25 11:21:32.363 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:32.364 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:21:32.365 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.76\n",
      "2021-08-25 11:21:32.366 | INFO     | src.policies:train:109 - Episode 928\n",
      "2021-08-25 11:21:32.374 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:32.375 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:32.376 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.51\n",
      "2021-08-25 11:21:32.377 | INFO     | src.policies:train:109 - Episode 929\n",
      "2021-08-25 11:21:32.397 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:32.398 | INFO     | src.policies:train:121 - Mean episode return: 41.0\n",
      "2021-08-25 11:21:32.399 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 27.78\n",
      "2021-08-25 11:21:32.400 | INFO     | src.policies:train:109 - Episode 930\n",
      "2021-08-25 11:21:32.425 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:32.426 | INFO     | src.policies:train:121 - Mean episode return: 57.0\n",
      "2021-08-25 11:21:32.427 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.22\n",
      "2021-08-25 11:21:32.428 | INFO     | src.policies:train:109 - Episode 931\n",
      "2021-08-25 11:21:32.450 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:32.451 | INFO     | src.policies:train:121 - Mean episode return: 48.0\n",
      "2021-08-25 11:21:32.453 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.4\n",
      "2021-08-25 11:21:32.454 | WARNING  | src.policies:train:131 - The actual batch size is 242, instead of 200\n",
      "2021-08-25 11:21:32.463 | INFO     | src.policies:train:157 - Total loss: 1.0025839805603027\n",
      "2021-08-25 11:21:32.466 | INFO     | src.policies:train:103 - Epoch 115 / 800\n",
      "2021-08-25 11:21:32.467 | INFO     | src.policies:train:109 - Episode 932\n",
      "2021-08-25 11:21:32.485 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:32.487 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 11:21:32.488 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.57\n",
      "2021-08-25 11:21:32.488 | INFO     | src.policies:train:109 - Episode 933\n",
      "2021-08-25 11:21:32.510 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:32.511 | INFO     | src.policies:train:121 - Mean episode return: 44.0\n",
      "2021-08-25 11:21:32.512 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.69\n",
      "2021-08-25 11:21:32.513 | INFO     | src.policies:train:109 - Episode 934\n",
      "2021-08-25 11:21:32.529 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:32.530 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 11:21:32.531 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.65\n",
      "2021-08-25 11:21:32.532 | INFO     | src.policies:train:109 - Episode 935\n",
      "2021-08-25 11:21:32.547 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:32.548 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 11:21:32.549 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.73\n",
      "2021-08-25 11:21:32.550 | INFO     | src.policies:train:109 - Episode 936\n",
      "2021-08-25 11:21:32.558 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:32.560 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:32.561 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.33\n",
      "2021-08-25 11:21:32.561 | INFO     | src.policies:train:109 - Episode 937\n",
      "2021-08-25 11:21:32.575 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:32.576 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:21:32.577 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.31\n",
      "2021-08-25 11:21:32.579 | INFO     | src.policies:train:109 - Episode 938\n",
      "2021-08-25 11:21:32.587 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:32.589 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:21:32.589 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.02\n",
      "2021-08-25 11:21:32.591 | INFO     | src.policies:train:109 - Episode 939\n",
      "2021-08-25 11:21:32.612 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:32.613 | INFO     | src.policies:train:121 - Mean episode return: 47.0\n",
      "2021-08-25 11:21:32.614 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.24\n",
      "2021-08-25 11:21:32.615 | WARNING  | src.policies:train:131 - The actual batch size is 240, instead of 200\n",
      "2021-08-25 11:21:32.623 | INFO     | src.policies:train:157 - Total loss: 1.0025831460952759\n",
      "2021-08-25 11:21:32.626 | INFO     | src.policies:train:103 - Epoch 116 / 800\n",
      "2021-08-25 11:21:32.628 | INFO     | src.policies:train:109 - Episode 940\n",
      "2021-08-25 11:21:32.638 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:32.640 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:21:32.641 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.38\n",
      "2021-08-25 11:21:32.642 | INFO     | src.policies:train:109 - Episode 941\n",
      "2021-08-25 11:21:32.657 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:32.658 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 11:21:32.659 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.48\n",
      "2021-08-25 11:21:32.660 | INFO     | src.policies:train:109 - Episode 942\n",
      "2021-08-25 11:21:32.670 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:32.672 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:21:32.673 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.44\n",
      "2021-08-25 11:21:32.674 | INFO     | src.policies:train:109 - Episode 943\n",
      "2021-08-25 11:21:32.686 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:32.687 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:21:32.688 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.5\n",
      "2021-08-25 11:21:32.690 | INFO     | src.policies:train:109 - Episode 944\n",
      "2021-08-25 11:21:32.709 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:32.710 | INFO     | src.policies:train:121 - Mean episode return: 43.0\n",
      "2021-08-25 11:21:32.711 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.5\n",
      "2021-08-25 11:21:32.712 | INFO     | src.policies:train:109 - Episode 945\n",
      "2021-08-25 11:21:32.726 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:32.727 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 11:21:32.728 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.51\n",
      "2021-08-25 11:21:32.729 | INFO     | src.policies:train:109 - Episode 946\n",
      "2021-08-25 11:21:32.742 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:32.743 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 11:21:32.744 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.63\n",
      "2021-08-25 11:21:32.745 | INFO     | src.policies:train:109 - Episode 947\n",
      "2021-08-25 11:21:32.755 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:32.757 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:32.758 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.49\n",
      "2021-08-25 11:21:32.759 | WARNING  | src.policies:train:131 - The actual batch size is 205, instead of 200\n",
      "2021-08-25 11:21:32.766 | INFO     | src.policies:train:157 - Total loss: 1.001926064491272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:32.769 | INFO     | src.policies:train:103 - Epoch 117 / 800\n",
      "2021-08-25 11:21:32.770 | INFO     | src.policies:train:109 - Episode 948\n",
      "2021-08-25 11:21:32.779 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:32.781 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:32.782 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.51\n",
      "2021-08-25 11:21:32.783 | INFO     | src.policies:train:109 - Episode 949\n",
      "2021-08-25 11:21:32.791 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:32.793 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:21:32.794 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.52\n",
      "2021-08-25 11:21:32.795 | INFO     | src.policies:train:109 - Episode 950\n",
      "2021-08-25 11:21:32.806 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:32.808 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:21:32.809 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.58\n",
      "2021-08-25 11:21:32.810 | INFO     | src.policies:train:109 - Episode 951\n",
      "2021-08-25 11:21:32.820 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:32.822 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:32.823 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.52\n",
      "2021-08-25 11:21:32.823 | INFO     | src.policies:train:109 - Episode 952\n",
      "2021-08-25 11:21:32.831 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:32.833 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:32.834 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.4\n",
      "2021-08-25 11:21:32.835 | INFO     | src.policies:train:109 - Episode 953\n",
      "2021-08-25 11:21:32.850 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:32.851 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:21:32.852 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.51\n",
      "2021-08-25 11:21:32.853 | INFO     | src.policies:train:109 - Episode 954\n",
      "2021-08-25 11:21:32.865 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:32.866 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:21:32.867 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.55\n",
      "2021-08-25 11:21:32.868 | INFO     | src.policies:train:109 - Episode 955\n",
      "2021-08-25 11:21:32.883 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:32.885 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 11:21:32.886 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.68\n",
      "2021-08-25 11:21:32.887 | INFO     | src.policies:train:109 - Episode 956\n",
      "2021-08-25 11:21:32.900 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:32.901 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:21:32.902 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.74\n",
      "2021-08-25 11:21:32.903 | INFO     | src.policies:train:109 - Episode 957\n",
      "2021-08-25 11:21:32.911 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:32.912 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:21:32.913 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.74\n",
      "2021-08-25 11:21:32.914 | INFO     | src.policies:train:109 - Episode 958\n",
      "2021-08-25 11:21:32.926 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:32.927 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:21:32.928 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.17\n",
      "2021-08-25 11:21:32.929 | WARNING  | src.policies:train:131 - The actual batch size is 212, instead of 200\n",
      "2021-08-25 11:21:32.938 | INFO     | src.policies:train:157 - Total loss: 1.0019985437393188\n",
      "2021-08-25 11:21:32.941 | INFO     | src.policies:train:103 - Epoch 118 / 800\n",
      "2021-08-25 11:21:32.942 | INFO     | src.policies:train:109 - Episode 959\n",
      "2021-08-25 11:21:32.956 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:32.958 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 11:21:32.959 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.35\n",
      "2021-08-25 11:21:32.960 | INFO     | src.policies:train:109 - Episode 960\n",
      "2021-08-25 11:21:32.982 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:32.983 | INFO     | src.policies:train:121 - Mean episode return: 48.0\n",
      "2021-08-25 11:21:32.984 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.68\n",
      "2021-08-25 11:21:32.985 | INFO     | src.policies:train:109 - Episode 961\n",
      "2021-08-25 11:21:32.993 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:32.994 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:32.995 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.59\n",
      "2021-08-25 11:21:32.996 | INFO     | src.policies:train:109 - Episode 962\n",
      "2021-08-25 11:21:33.017 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:33.019 | INFO     | src.policies:train:121 - Mean episode return: 44.0\n",
      "2021-08-25 11:21:33.020 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.84\n",
      "2021-08-25 11:21:33.021 | INFO     | src.policies:train:109 - Episode 963\n",
      "2021-08-25 11:21:33.034 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:33.036 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:21:33.037 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.6\n",
      "2021-08-25 11:21:33.038 | INFO     | src.policies:train:109 - Episode 964\n",
      "2021-08-25 11:21:33.056 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:33.057 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 11:21:33.058 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.61\n",
      "2021-08-25 11:21:33.059 | INFO     | src.policies:train:109 - Episode 965\n",
      "2021-08-25 11:21:33.073 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:33.075 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:33.076 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.39\n",
      "2021-08-25 11:21:33.077 | WARNING  | src.policies:train:131 - The actual batch size is 211, instead of 200\n",
      "2021-08-25 11:21:33.085 | INFO     | src.policies:train:157 - Total loss: 1.0019887685775757\n",
      "2021-08-25 11:21:33.089 | INFO     | src.policies:train:103 - Epoch 119 / 800\n",
      "2021-08-25 11:21:33.090 | INFO     | src.policies:train:109 - Episode 966\n",
      "2021-08-25 11:21:33.119 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:33.121 | INFO     | src.policies:train:121 - Mean episode return: 65.0\n",
      "2021-08-25 11:21:33.122 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.92\n",
      "2021-08-25 11:21:33.123 | INFO     | src.policies:train:109 - Episode 967\n",
      "2021-08-25 11:21:33.139 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:33.140 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 11:21:33.141 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.94\n",
      "2021-08-25 11:21:33.142 | INFO     | src.policies:train:109 - Episode 968\n",
      "2021-08-25 11:21:33.156 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:33.158 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:33.158 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.06\n",
      "2021-08-25 11:21:33.159 | INFO     | src.policies:train:109 - Episode 969\n",
      "2021-08-25 11:21:33.204 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:33.205 | INFO     | src.policies:train:121 - Mean episode return: 104.0\n",
      "2021-08-25 11:21:33.206 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.66\n",
      "2021-08-25 11:21:33.207 | WARNING  | src.policies:train:131 - The actual batch size is 231, instead of 200\n",
      "2021-08-25 11:21:33.214 | INFO     | src.policies:train:157 - Total loss: 1.0024603605270386\n",
      "2021-08-25 11:21:33.217 | INFO     | src.policies:train:103 - Epoch 120 / 800\n",
      "2021-08-25 11:21:33.218 | INFO     | src.policies:train:109 - Episode 970\n",
      "2021-08-25 11:21:33.239 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:33.240 | INFO     | src.policies:train:121 - Mean episode return: 49.0\n",
      "2021-08-25 11:21:33.242 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.57\n",
      "2021-08-25 11:21:33.243 | INFO     | src.policies:train:109 - Episode 971\n",
      "2021-08-25 11:21:33.263 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:33.264 | INFO     | src.policies:train:121 - Mean episode return: 43.0\n",
      "2021-08-25 11:21:33.265 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.8\n",
      "2021-08-25 11:21:33.266 | INFO     | src.policies:train:109 - Episode 972\n",
      "2021-08-25 11:21:33.278 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:33.279 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:21:33.280 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.83\n",
      "2021-08-25 11:21:33.281 | INFO     | src.policies:train:109 - Episode 973\n",
      "2021-08-25 11:21:33.293 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:33.294 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:21:33.295 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.68\n",
      "2021-08-25 11:21:33.296 | INFO     | src.policies:train:109 - Episode 974\n",
      "2021-08-25 11:21:33.309 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:33.310 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:21:33.311 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.72\n",
      "2021-08-25 11:21:33.312 | INFO     | src.policies:train:109 - Episode 975\n",
      "2021-08-25 11:21:33.324 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:33.325 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:21:33.326 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.71\n",
      "2021-08-25 11:21:33.327 | INFO     | src.policies:train:109 - Episode 976\n",
      "2021-08-25 11:21:33.343 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:33.344 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 11:21:33.345 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.87\n",
      "2021-08-25 11:21:33.346 | WARNING  | src.policies:train:131 - The actual batch size is 209, instead of 200\n",
      "2021-08-25 11:21:33.353 | INFO     | src.policies:train:157 - Total loss: 1.0018669366836548\n",
      "2021-08-25 11:21:33.356 | INFO     | src.policies:train:103 - Epoch 121 / 800\n",
      "2021-08-25 11:21:33.358 | INFO     | src.policies:train:109 - Episode 977\n",
      "2021-08-25 11:21:33.374 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:33.376 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 11:21:33.377 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.07\n",
      "2021-08-25 11:21:33.378 | INFO     | src.policies:train:109 - Episode 978\n",
      "2021-08-25 11:21:33.394 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:33.395 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 11:21:33.396 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.68\n",
      "2021-08-25 11:21:33.397 | INFO     | src.policies:train:109 - Episode 979\n",
      "2021-08-25 11:21:33.419 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:33.420 | INFO     | src.policies:train:121 - Mean episode return: 46.0\n",
      "2021-08-25 11:21:33.421 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.99\n",
      "2021-08-25 11:21:33.422 | INFO     | src.policies:train:109 - Episode 980\n",
      "2021-08-25 11:21:33.433 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:33.435 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:21:33.436 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.82\n",
      "2021-08-25 11:21:33.436 | INFO     | src.policies:train:109 - Episode 981\n",
      "2021-08-25 11:21:33.452 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:33.454 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 11:21:33.455 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.94\n",
      "2021-08-25 11:21:33.456 | INFO     | src.policies:train:109 - Episode 982\n",
      "2021-08-25 11:21:33.465 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:33.467 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:33.468 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.85\n",
      "2021-08-25 11:21:33.469 | INFO     | src.policies:train:109 - Episode 983\n",
      "2021-08-25 11:21:33.477 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:33.478 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:21:33.479 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.68\n",
      "2021-08-25 11:21:33.480 | INFO     | src.policies:train:109 - Episode 984\n",
      "2021-08-25 11:21:33.496 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:33.497 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 11:21:33.498 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.78\n",
      "2021-08-25 11:21:33.499 | WARNING  | src.policies:train:131 - The actual batch size is 227, instead of 200\n",
      "2021-08-25 11:21:33.506 | INFO     | src.policies:train:157 - Total loss: 1.0023020505905151\n",
      "2021-08-25 11:21:33.510 | INFO     | src.policies:train:103 - Epoch 122 / 800\n",
      "2021-08-25 11:21:33.511 | INFO     | src.policies:train:109 - Episode 985\n",
      "2021-08-25 11:21:33.522 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:33.523 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:21:33.524 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.88\n",
      "2021-08-25 11:21:33.525 | INFO     | src.policies:train:109 - Episode 986\n",
      "2021-08-25 11:21:33.557 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:33.558 | INFO     | src.policies:train:121 - Mean episode return: 73.0\n",
      "2021-08-25 11:21:33.559 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.35\n",
      "2021-08-25 11:21:33.560 | INFO     | src.policies:train:109 - Episode 987\n",
      "2021-08-25 11:21:33.576 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:33.577 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 11:21:33.578 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.45\n",
      "2021-08-25 11:21:33.579 | INFO     | src.policies:train:109 - Episode 988\n",
      "2021-08-25 11:21:33.598 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:33.599 | INFO     | src.policies:train:121 - Mean episode return: 38.0\n",
      "2021-08-25 11:21:33.601 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:33.601 | INFO     | src.policies:train:109 - Episode 989\n",
      "2021-08-25 11:21:33.611 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:33.612 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:33.613 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.64\n",
      "2021-08-25 11:21:33.614 | INFO     | src.policies:train:109 - Episode 990\n",
      "2021-08-25 11:21:33.628 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:33.629 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 11:21:33.630 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.43\n",
      "2021-08-25 11:21:33.631 | WARNING  | src.policies:train:131 - The actual batch size is 209, instead of 200\n",
      "2021-08-25 11:21:33.639 | INFO     | src.policies:train:157 - Total loss: 1.002073884010315\n",
      "2021-08-25 11:21:33.642 | INFO     | src.policies:train:103 - Epoch 123 / 800\n",
      "2021-08-25 11:21:33.644 | INFO     | src.policies:train:109 - Episode 991\n",
      "2021-08-25 11:21:33.652 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:33.654 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:33.655 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.37\n",
      "2021-08-25 11:21:33.656 | INFO     | src.policies:train:109 - Episode 992\n",
      "2021-08-25 11:21:33.667 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:33.669 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:21:33.670 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.24\n",
      "2021-08-25 11:21:33.671 | INFO     | src.policies:train:109 - Episode 993\n",
      "2021-08-25 11:21:33.681 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:33.682 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:21:33.683 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.07\n",
      "2021-08-25 11:21:33.684 | INFO     | src.policies:train:109 - Episode 994\n",
      "2021-08-25 11:21:33.695 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:33.696 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:21:33.697 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.02\n",
      "2021-08-25 11:21:33.698 | INFO     | src.policies:train:109 - Episode 995\n",
      "2021-08-25 11:21:33.712 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:33.713 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:21:33.715 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.09\n",
      "2021-08-25 11:21:33.716 | INFO     | src.policies:train:109 - Episode 996\n",
      "2021-08-25 11:21:33.725 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:33.726 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:33.727 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.92\n",
      "2021-08-25 11:21:33.728 | INFO     | src.policies:train:109 - Episode 997\n",
      "2021-08-25 11:21:33.739 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:33.741 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:21:33.742 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.62\n",
      "2021-08-25 11:21:33.742 | INFO     | src.policies:train:109 - Episode 998\n",
      "2021-08-25 11:21:33.750 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:33.752 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:33.753 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.12\n",
      "2021-08-25 11:21:33.753 | INFO     | src.policies:train:109 - Episode 999\n",
      "2021-08-25 11:21:33.770 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:33.771 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 11:21:33.772 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.93\n",
      "2021-08-25 11:21:33.773 | INFO     | src.policies:train:109 - Episode 1000\n",
      "2021-08-25 11:21:33.789 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:33.790 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 11:21:33.791 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.93\n",
      "2021-08-25 11:21:33.792 | WARNING  | src.policies:train:131 - The actual batch size is 206, instead of 200\n",
      "2021-08-25 11:21:33.801 | INFO     | src.policies:train:157 - Total loss: 1.0019627809524536\n",
      "2021-08-25 11:21:33.804 | INFO     | src.policies:train:103 - Epoch 124 / 800\n",
      "2021-08-25 11:21:33.805 | INFO     | src.policies:train:109 - Episode 1001\n",
      "2021-08-25 11:21:33.831 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:33.832 | INFO     | src.policies:train:121 - Mean episode return: 63.0\n",
      "2021-08-25 11:21:33.833 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.29\n",
      "2021-08-25 11:21:33.834 | INFO     | src.policies:train:109 - Episode 1002\n",
      "2021-08-25 11:21:33.848 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:33.849 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:21:33.850 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.19\n",
      "2021-08-25 11:21:33.851 | INFO     | src.policies:train:109 - Episode 1003\n",
      "2021-08-25 11:21:33.866 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:33.867 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 11:21:33.868 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.9\n",
      "2021-08-25 11:21:33.868 | INFO     | src.policies:train:109 - Episode 1004\n",
      "2021-08-25 11:21:33.883 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:33.884 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:21:33.885 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.91\n",
      "2021-08-25 11:21:33.886 | INFO     | src.policies:train:109 - Episode 1005\n",
      "2021-08-25 11:21:33.906 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:33.908 | INFO     | src.policies:train:121 - Mean episode return: 44.0\n",
      "2021-08-25 11:21:33.908 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.19\n",
      "2021-08-25 11:21:33.909 | INFO     | src.policies:train:109 - Episode 1006\n",
      "2021-08-25 11:21:33.925 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:33.926 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:21:33.927 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.77\n",
      "2021-08-25 11:21:33.928 | WARNING  | src.policies:train:131 - The actual batch size is 218, instead of 200\n",
      "2021-08-25 11:21:33.935 | INFO     | src.policies:train:157 - Total loss: 1.0021840333938599\n",
      "2021-08-25 11:21:33.938 | INFO     | src.policies:train:103 - Epoch 125 / 800\n",
      "2021-08-25 11:21:33.939 | INFO     | src.policies:train:109 - Episode 1007\n",
      "2021-08-25 11:21:33.975 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:33.977 | INFO     | src.policies:train:121 - Mean episode return: 82.0\n",
      "2021-08-25 11:21:33.977 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.27\n",
      "2021-08-25 11:21:33.978 | INFO     | src.policies:train:109 - Episode 1008\n",
      "2021-08-25 11:21:33.986 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:33.987 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 11:21:33.988 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.22\n",
      "2021-08-25 11:21:33.989 | INFO     | src.policies:train:109 - Episode 1009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:33.999 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:34.000 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:34.001 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.2\n",
      "2021-08-25 11:21:34.002 | INFO     | src.policies:train:109 - Episode 1010\n",
      "2021-08-25 11:21:34.011 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:34.012 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:34.014 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.2\n",
      "2021-08-25 11:21:34.014 | INFO     | src.policies:train:109 - Episode 1011\n",
      "2021-08-25 11:21:34.022 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:34.024 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:21:34.025 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.07\n",
      "2021-08-25 11:21:34.026 | INFO     | src.policies:train:109 - Episode 1012\n",
      "2021-08-25 11:21:34.036 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:34.038 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:34.039 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.11\n",
      "2021-08-25 11:21:34.040 | INFO     | src.policies:train:109 - Episode 1013\n",
      "2021-08-25 11:21:34.050 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:34.051 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:21:34.052 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.78\n",
      "2021-08-25 11:21:34.053 | INFO     | src.policies:train:109 - Episode 1014\n",
      "2021-08-25 11:21:34.072 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:34.074 | INFO     | src.policies:train:121 - Mean episode return: 38.0\n",
      "2021-08-25 11:21:34.075 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.84\n",
      "2021-08-25 11:21:34.075 | WARNING  | src.policies:train:131 - The actual batch size is 205, instead of 200\n",
      "2021-08-25 11:21:34.083 | INFO     | src.policies:train:157 - Total loss: 1.0019352436065674\n",
      "2021-08-25 11:21:34.087 | INFO     | src.policies:train:103 - Epoch 126 / 800\n",
      "2021-08-25 11:21:34.088 | INFO     | src.policies:train:109 - Episode 1015\n",
      "2021-08-25 11:21:34.103 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:34.104 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 11:21:34.105 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.94\n",
      "2021-08-25 11:21:34.106 | INFO     | src.policies:train:109 - Episode 1016\n",
      "2021-08-25 11:21:34.122 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:34.123 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 11:21:34.124 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.04\n",
      "2021-08-25 11:21:34.125 | INFO     | src.policies:train:109 - Episode 1017\n",
      "2021-08-25 11:21:34.134 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:34.135 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:34.136 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 28.88\n",
      "2021-08-25 11:21:34.137 | INFO     | src.policies:train:109 - Episode 1018\n",
      "2021-08-25 11:21:34.151 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:34.153 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 11:21:34.154 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.02\n",
      "2021-08-25 11:21:34.155 | INFO     | src.policies:train:109 - Episode 1019\n",
      "2021-08-25 11:21:34.166 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:34.167 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:21:34.168 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.05\n",
      "2021-08-25 11:21:34.169 | INFO     | src.policies:train:109 - Episode 1020\n",
      "2021-08-25 11:21:34.187 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:34.188 | INFO     | src.policies:train:121 - Mean episode return: 38.0\n",
      "2021-08-25 11:21:34.189 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.16\n",
      "2021-08-25 11:21:34.190 | INFO     | src.policies:train:109 - Episode 1021\n",
      "2021-08-25 11:21:34.212 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:34.214 | INFO     | src.policies:train:121 - Mean episode return: 46.0\n",
      "2021-08-25 11:21:34.215 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.37\n",
      "2021-08-25 11:21:34.216 | WARNING  | src.policies:train:131 - The actual batch size is 212, instead of 200\n",
      "2021-08-25 11:21:34.223 | INFO     | src.policies:train:157 - Total loss: 1.0020854473114014\n",
      "2021-08-25 11:21:34.227 | INFO     | src.policies:train:103 - Epoch 127 / 800\n",
      "2021-08-25 11:21:34.228 | INFO     | src.policies:train:109 - Episode 1022\n",
      "2021-08-25 11:21:34.234 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:34.235 | INFO     | src.policies:train:121 - Mean episode return: 9.0\n",
      "2021-08-25 11:21:34.236 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.27\n",
      "2021-08-25 11:21:34.237 | INFO     | src.policies:train:109 - Episode 1023\n",
      "2021-08-25 11:21:34.257 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:34.259 | INFO     | src.policies:train:121 - Mean episode return: 42.0\n",
      "2021-08-25 11:21:34.259 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.28\n",
      "2021-08-25 11:21:34.261 | INFO     | src.policies:train:109 - Episode 1024\n",
      "2021-08-25 11:21:34.289 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:34.291 | INFO     | src.policies:train:121 - Mean episode return: 66.0\n",
      "2021-08-25 11:21:34.292 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.44\n",
      "2021-08-25 11:21:34.293 | INFO     | src.policies:train:109 - Episode 1025\n",
      "2021-08-25 11:21:34.302 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:34.304 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:34.305 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.12\n",
      "2021-08-25 11:21:34.306 | INFO     | src.policies:train:109 - Episode 1026\n",
      "2021-08-25 11:21:34.320 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:34.321 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 11:21:34.322 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.24\n",
      "2021-08-25 11:21:34.323 | INFO     | src.policies:train:109 - Episode 1027\n",
      "2021-08-25 11:21:34.340 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:34.342 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 11:21:34.342 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.4\n",
      "2021-08-25 11:21:34.344 | INFO     | src.policies:train:109 - Episode 1028\n",
      "2021-08-25 11:21:34.361 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:34.362 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 11:21:34.363 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.63\n",
      "2021-08-25 11:21:34.364 | WARNING  | src.policies:train:131 - The actual batch size is 232, instead of 200\n",
      "2021-08-25 11:21:34.372 | INFO     | src.policies:train:157 - Total loss: 1.0023705959320068\n",
      "2021-08-25 11:21:34.375 | INFO     | src.policies:train:103 - Epoch 128 / 800\n",
      "2021-08-25 11:21:34.376 | INFO     | src.policies:train:109 - Episode 1029\n",
      "2021-08-25 11:21:34.402 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:34.403 | INFO     | src.policies:train:121 - Mean episode return: 62.0\n",
      "2021-08-25 11:21:34.404 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.84\n",
      "2021-08-25 11:21:34.405 | INFO     | src.policies:train:109 - Episode 1030\n",
      "2021-08-25 11:21:34.430 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:34.431 | INFO     | src.policies:train:121 - Mean episode return: 54.0\n",
      "2021-08-25 11:21:34.432 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.81\n",
      "2021-08-25 11:21:34.433 | INFO     | src.policies:train:109 - Episode 1031\n",
      "2021-08-25 11:21:34.442 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:34.443 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:21:34.444 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.46\n",
      "2021-08-25 11:21:34.445 | INFO     | src.policies:train:109 - Episode 1032\n",
      "2021-08-25 11:21:34.466 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:34.467 | INFO     | src.policies:train:121 - Mean episode return: 46.0\n",
      "2021-08-25 11:21:34.468 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.52\n",
      "2021-08-25 11:21:34.469 | INFO     | src.policies:train:109 - Episode 1033\n",
      "2021-08-25 11:21:34.479 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:34.481 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:21:34.482 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.26\n",
      "2021-08-25 11:21:34.483 | INFO     | src.policies:train:109 - Episode 1034\n",
      "2021-08-25 11:21:34.498 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:34.499 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:21:34.501 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.22\n",
      "2021-08-25 11:21:34.501 | WARNING  | src.policies:train:131 - The actual batch size is 222, instead of 200\n",
      "2021-08-25 11:21:34.508 | INFO     | src.policies:train:157 - Total loss: 1.0022205114364624\n",
      "2021-08-25 11:21:34.511 | INFO     | src.policies:train:103 - Epoch 129 / 800\n",
      "2021-08-25 11:21:34.513 | INFO     | src.policies:train:109 - Episode 1035\n",
      "2021-08-25 11:21:34.528 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:34.530 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 11:21:34.531 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.3\n",
      "2021-08-25 11:21:34.532 | INFO     | src.policies:train:109 - Episode 1036\n",
      "2021-08-25 11:21:34.548 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:34.550 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:21:34.551 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.41\n",
      "2021-08-25 11:21:34.552 | INFO     | src.policies:train:109 - Episode 1037\n",
      "2021-08-25 11:21:34.574 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:34.575 | INFO     | src.policies:train:121 - Mean episode return: 38.0\n",
      "2021-08-25 11:21:34.577 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.53\n",
      "2021-08-25 11:21:34.578 | INFO     | src.policies:train:109 - Episode 1038\n",
      "2021-08-25 11:21:34.618 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:34.620 | INFO     | src.policies:train:121 - Mean episode return: 84.0\n",
      "2021-08-25 11:21:34.621 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.24\n",
      "2021-08-25 11:21:34.623 | INFO     | src.policies:train:109 - Episode 1039\n",
      "2021-08-25 11:21:34.640 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:34.641 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 11:21:34.642 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.04\n",
      "2021-08-25 11:21:34.644 | WARNING  | src.policies:train:131 - The actual batch size is 205, instead of 200\n",
      "2021-08-25 11:21:34.652 | INFO     | src.policies:train:157 - Total loss: 1.0019092559814453\n",
      "2021-08-25 11:21:34.657 | INFO     | src.policies:train:103 - Epoch 130 / 800\n",
      "2021-08-25 11:21:34.659 | INFO     | src.policies:train:109 - Episode 1040\n",
      "2021-08-25 11:21:34.695 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:34.696 | INFO     | src.policies:train:121 - Mean episode return: 62.0\n",
      "2021-08-25 11:21:34.698 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.44\n",
      "2021-08-25 11:21:34.699 | INFO     | src.policies:train:109 - Episode 1041\n",
      "2021-08-25 11:21:34.721 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:34.722 | INFO     | src.policies:train:121 - Mean episode return: 41.0\n",
      "2021-08-25 11:21:34.723 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.55\n",
      "2021-08-25 11:21:34.724 | INFO     | src.policies:train:109 - Episode 1042\n",
      "2021-08-25 11:21:34.737 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:34.738 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:21:34.739 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.63\n",
      "2021-08-25 11:21:34.740 | INFO     | src.policies:train:109 - Episode 1043\n",
      "2021-08-25 11:21:34.759 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:34.761 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 11:21:34.762 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.8\n",
      "2021-08-25 11:21:34.762 | INFO     | src.policies:train:109 - Episode 1044\n",
      "2021-08-25 11:21:34.784 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:34.785 | INFO     | src.policies:train:121 - Mean episode return: 51.0\n",
      "2021-08-25 11:21:34.786 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.88\n",
      "2021-08-25 11:21:34.787 | WARNING  | src.policies:train:131 - The actual batch size is 220, instead of 200\n",
      "2021-08-25 11:21:34.794 | INFO     | src.policies:train:157 - Total loss: 1.0020577907562256\n",
      "2021-08-25 11:21:34.797 | INFO     | src.policies:train:103 - Epoch 131 / 800\n",
      "2021-08-25 11:21:34.799 | INFO     | src.policies:train:109 - Episode 1045\n",
      "2021-08-25 11:21:34.808 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:34.809 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:21:34.810 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.81\n",
      "2021-08-25 11:21:34.811 | INFO     | src.policies:train:109 - Episode 1046\n",
      "2021-08-25 11:21:34.835 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:34.837 | INFO     | src.policies:train:121 - Mean episode return: 58.0\n",
      "2021-08-25 11:21:34.837 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.14\n",
      "2021-08-25 11:21:34.839 | INFO     | src.policies:train:109 - Episode 1047\n",
      "2021-08-25 11:21:34.860 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:34.861 | INFO     | src.policies:train:121 - Mean episode return: 48.0\n",
      "2021-08-25 11:21:34.862 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.45\n",
      "2021-08-25 11:21:34.863 | INFO     | src.policies:train:109 - Episode 1048\n",
      "2021-08-25 11:21:34.890 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:34.891 | INFO     | src.policies:train:121 - Mean episode return: 64.0\n",
      "2021-08-25 11:21:34.892 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.92\n",
      "2021-08-25 11:21:34.893 | INFO     | src.policies:train:109 - Episode 1049\n",
      "2021-08-25 11:21:34.928 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:34.930 | INFO     | src.policies:train:121 - Mean episode return: 88.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:34.930 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.66\n",
      "2021-08-25 11:21:34.931 | WARNING  | src.policies:train:131 - The actual batch size is 278, instead of 200\n",
      "2021-08-25 11:21:34.938 | INFO     | src.policies:train:157 - Total loss: 1.0031001567840576\n",
      "2021-08-25 11:21:34.941 | INFO     | src.policies:train:103 - Epoch 132 / 800\n",
      "2021-08-25 11:21:34.942 | INFO     | src.policies:train:109 - Episode 1050\n",
      "2021-08-25 11:21:34.954 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:34.955 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 11:21:34.956 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.7\n",
      "2021-08-25 11:21:34.957 | INFO     | src.policies:train:109 - Episode 1051\n",
      "2021-08-25 11:21:34.967 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:34.968 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:34.968 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.71\n",
      "2021-08-25 11:21:34.969 | INFO     | src.policies:train:109 - Episode 1052\n",
      "2021-08-25 11:21:34.980 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:34.981 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:21:34.982 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.77\n",
      "2021-08-25 11:21:34.983 | INFO     | src.policies:train:109 - Episode 1053\n",
      "2021-08-25 11:21:34.994 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:34.995 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:21:34.996 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.67\n",
      "2021-08-25 11:21:34.997 | INFO     | src.policies:train:109 - Episode 1054\n",
      "2021-08-25 11:21:35.010 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:35.011 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:21:35.012 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.76\n",
      "2021-08-25 11:21:35.013 | INFO     | src.policies:train:109 - Episode 1055\n",
      "2021-08-25 11:21:35.038 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:35.039 | INFO     | src.policies:train:121 - Mean episode return: 61.0\n",
      "2021-08-25 11:21:35.040 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.07\n",
      "2021-08-25 11:21:35.041 | INFO     | src.policies:train:109 - Episode 1056\n",
      "2021-08-25 11:21:35.055 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:35.056 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 11:21:35.057 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.15\n",
      "2021-08-25 11:21:35.058 | INFO     | src.policies:train:109 - Episode 1057\n",
      "2021-08-25 11:21:35.071 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:35.072 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:21:35.073 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.27\n",
      "2021-08-25 11:21:35.074 | WARNING  | src.policies:train:131 - The actual batch size is 221, instead of 200\n",
      "2021-08-25 11:21:35.081 | INFO     | src.policies:train:157 - Total loss: 1.0022609233856201\n",
      "2021-08-25 11:21:35.084 | INFO     | src.policies:train:103 - Epoch 133 / 800\n",
      "2021-08-25 11:21:35.085 | INFO     | src.policies:train:109 - Episode 1058\n",
      "2021-08-25 11:21:35.106 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:35.108 | INFO     | src.policies:train:121 - Mean episode return: 50.0\n",
      "2021-08-25 11:21:35.109 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.56\n",
      "2021-08-25 11:21:35.110 | INFO     | src.policies:train:109 - Episode 1059\n",
      "2021-08-25 11:21:35.118 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:35.120 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:21:35.121 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.35\n",
      "2021-08-25 11:21:35.122 | INFO     | src.policies:train:109 - Episode 1060\n",
      "2021-08-25 11:21:35.134 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:35.135 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:21:35.136 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.06\n",
      "2021-08-25 11:21:35.137 | INFO     | src.policies:train:109 - Episode 1061\n",
      "2021-08-25 11:21:35.153 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:35.155 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 11:21:35.156 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.24\n",
      "2021-08-25 11:21:35.157 | INFO     | src.policies:train:109 - Episode 1062\n",
      "2021-08-25 11:21:35.175 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:35.176 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 11:21:35.177 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.13\n",
      "2021-08-25 11:21:35.178 | INFO     | src.policies:train:109 - Episode 1063\n",
      "2021-08-25 11:21:35.187 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:35.189 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:35.190 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.03\n",
      "2021-08-25 11:21:35.191 | INFO     | src.policies:train:109 - Episode 1064\n",
      "2021-08-25 11:21:35.210 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:35.211 | INFO     | src.policies:train:121 - Mean episode return: 39.0\n",
      "2021-08-25 11:21:35.213 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.06\n",
      "2021-08-25 11:21:35.214 | INFO     | src.policies:train:109 - Episode 1065\n",
      "2021-08-25 11:21:35.232 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:35.233 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 11:21:35.234 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.26\n",
      "2021-08-25 11:21:35.235 | WARNING  | src.policies:train:131 - The actual batch size is 231, instead of 200\n",
      "2021-08-25 11:21:35.243 | INFO     | src.policies:train:157 - Total loss: 1.0023508071899414\n",
      "2021-08-25 11:21:35.246 | INFO     | src.policies:train:103 - Epoch 134 / 800\n",
      "2021-08-25 11:21:35.248 | INFO     | src.policies:train:109 - Episode 1066\n",
      "2021-08-25 11:21:35.273 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:35.275 | INFO     | src.policies:train:121 - Mean episode return: 61.0\n",
      "2021-08-25 11:21:35.276 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.22\n",
      "2021-08-25 11:21:35.277 | INFO     | src.policies:train:109 - Episode 1067\n",
      "2021-08-25 11:21:35.290 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:35.291 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:21:35.292 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.1\n",
      "2021-08-25 11:21:35.293 | INFO     | src.policies:train:109 - Episode 1068\n",
      "2021-08-25 11:21:35.303 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:35.304 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 11:21:35.305 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.91\n",
      "2021-08-25 11:21:35.306 | INFO     | src.policies:train:109 - Episode 1069\n",
      "2021-08-25 11:21:35.315 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:35.316 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:21:35.317 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:35.318 | INFO     | src.policies:train:109 - Episode 1070\n",
      "2021-08-25 11:21:35.353 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:35.354 | INFO     | src.policies:train:121 - Mean episode return: 74.0\n",
      "2021-08-25 11:21:35.356 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.23\n",
      "2021-08-25 11:21:35.357 | INFO     | src.policies:train:109 - Episode 1071\n",
      "2021-08-25 11:21:35.372 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:35.373 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 11:21:35.375 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.07\n",
      "2021-08-25 11:21:35.376 | WARNING  | src.policies:train:131 - The actual batch size is 204, instead of 200\n",
      "2021-08-25 11:21:35.384 | INFO     | src.policies:train:157 - Total loss: 1.0016850233078003\n",
      "2021-08-25 11:21:35.387 | INFO     | src.policies:train:103 - Epoch 135 / 800\n",
      "2021-08-25 11:21:35.389 | INFO     | src.policies:train:109 - Episode 1072\n",
      "2021-08-25 11:21:35.410 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:35.411 | INFO     | src.policies:train:121 - Mean episode return: 49.0\n",
      "2021-08-25 11:21:35.413 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.34\n",
      "2021-08-25 11:21:35.414 | INFO     | src.policies:train:109 - Episode 1073\n",
      "2021-08-25 11:21:35.424 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:35.425 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:35.426 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.29\n",
      "2021-08-25 11:21:35.428 | INFO     | src.policies:train:109 - Episode 1074\n",
      "2021-08-25 11:21:35.439 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:35.441 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:35.442 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.2\n",
      "2021-08-25 11:21:35.443 | INFO     | src.policies:train:109 - Episode 1075\n",
      "2021-08-25 11:21:35.461 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:35.462 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 11:21:35.463 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.34\n",
      "2021-08-25 11:21:35.464 | INFO     | src.policies:train:109 - Episode 1076\n",
      "2021-08-25 11:21:35.486 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:35.487 | INFO     | src.policies:train:121 - Mean episode return: 43.0\n",
      "2021-08-25 11:21:35.488 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.47\n",
      "2021-08-25 11:21:35.489 | INFO     | src.policies:train:109 - Episode 1077\n",
      "2021-08-25 11:21:35.531 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:35.532 | INFO     | src.policies:train:121 - Mean episode return: 96.0\n",
      "2021-08-25 11:21:35.533 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.03\n",
      "2021-08-25 11:21:35.535 | WARNING  | src.policies:train:131 - The actual batch size is 253, instead of 200\n",
      "2021-08-25 11:21:35.542 | INFO     | src.policies:train:157 - Total loss: 1.00267493724823\n",
      "2021-08-25 11:21:35.545 | INFO     | src.policies:train:103 - Epoch 136 / 800\n",
      "2021-08-25 11:21:35.546 | INFO     | src.policies:train:109 - Episode 1078\n",
      "2021-08-25 11:21:35.554 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:35.555 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:21:35.557 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.82\n",
      "2021-08-25 11:21:35.558 | INFO     | src.policies:train:109 - Episode 1079\n",
      "2021-08-25 11:21:35.567 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:35.568 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:21:35.569 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.47\n",
      "2021-08-25 11:21:35.570 | INFO     | src.policies:train:109 - Episode 1080\n",
      "2021-08-25 11:21:35.587 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:35.588 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 11:21:35.589 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.57\n",
      "2021-08-25 11:21:35.590 | INFO     | src.policies:train:109 - Episode 1081\n",
      "2021-08-25 11:21:35.618 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:35.619 | INFO     | src.policies:train:121 - Mean episode return: 60.0\n",
      "2021-08-25 11:21:35.621 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.86\n",
      "2021-08-25 11:21:35.622 | INFO     | src.policies:train:109 - Episode 1082\n",
      "2021-08-25 11:21:35.633 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:35.634 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:35.635 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.9\n",
      "2021-08-25 11:21:35.636 | INFO     | src.policies:train:109 - Episode 1083\n",
      "2021-08-25 11:21:35.663 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:35.664 | INFO     | src.policies:train:121 - Mean episode return: 59.0\n",
      "2021-08-25 11:21:35.665 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.38\n",
      "2021-08-25 11:21:35.666 | INFO     | src.policies:train:109 - Episode 1084\n",
      "2021-08-25 11:21:35.676 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:35.678 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:35.678 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.22\n",
      "2021-08-25 11:21:35.680 | WARNING  | src.policies:train:131 - The actual batch size is 206, instead of 200\n",
      "2021-08-25 11:21:35.688 | INFO     | src.policies:train:157 - Total loss: 1.0018962621688843\n",
      "2021-08-25 11:21:35.691 | INFO     | src.policies:train:103 - Epoch 137 / 800\n",
      "2021-08-25 11:21:35.692 | INFO     | src.policies:train:109 - Episode 1085\n",
      "2021-08-25 11:21:35.703 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:35.704 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:21:35.706 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.2\n",
      "2021-08-25 11:21:35.706 | INFO     | src.policies:train:109 - Episode 1086\n",
      "2021-08-25 11:21:35.718 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:35.720 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:21:35.721 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.68\n",
      "2021-08-25 11:21:35.722 | INFO     | src.policies:train:109 - Episode 1087\n",
      "2021-08-25 11:21:35.733 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:35.734 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:35.735 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.49\n",
      "2021-08-25 11:21:35.736 | INFO     | src.policies:train:109 - Episode 1088\n",
      "2021-08-25 11:21:35.749 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:35.750 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:21:35.751 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.31\n",
      "2021-08-25 11:21:35.753 | INFO     | src.policies:train:109 - Episode 1089\n",
      "2021-08-25 11:21:35.762 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:35.763 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:21:35.764 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.3\n",
      "2021-08-25 11:21:35.765 | INFO     | src.policies:train:109 - Episode 1090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:35.787 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:35.788 | INFO     | src.policies:train:121 - Mean episode return: 49.0\n",
      "2021-08-25 11:21:35.789 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.52\n",
      "2021-08-25 11:21:35.790 | INFO     | src.policies:train:109 - Episode 1091\n",
      "2021-08-25 11:21:35.803 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:35.804 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:21:35.805 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.57\n",
      "2021-08-25 11:21:35.807 | INFO     | src.policies:train:109 - Episode 1092\n",
      "2021-08-25 11:21:35.816 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:35.818 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:21:35.819 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.51\n",
      "2021-08-25 11:21:35.820 | INFO     | src.policies:train:109 - Episode 1093\n",
      "2021-08-25 11:21:35.842 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:35.844 | INFO     | src.policies:train:121 - Mean episode return: 48.0\n",
      "2021-08-25 11:21:35.844 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.85\n",
      "2021-08-25 11:21:35.846 | WARNING  | src.policies:train:131 - The actual batch size is 221, instead of 200\n",
      "2021-08-25 11:21:35.854 | INFO     | src.policies:train:157 - Total loss: 1.0021162033081055\n",
      "2021-08-25 11:21:35.858 | INFO     | src.policies:train:103 - Epoch 138 / 800\n",
      "2021-08-25 11:21:35.859 | INFO     | src.policies:train:109 - Episode 1094\n",
      "2021-08-25 11:21:35.868 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:35.869 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:35.871 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.79\n",
      "2021-08-25 11:21:35.871 | INFO     | src.policies:train:109 - Episode 1095\n",
      "2021-08-25 11:21:35.890 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:35.892 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 11:21:35.893 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.89\n",
      "2021-08-25 11:21:35.894 | INFO     | src.policies:train:109 - Episode 1096\n",
      "2021-08-25 11:21:35.913 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:35.914 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 11:21:35.915 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.11\n",
      "2021-08-25 11:21:35.916 | INFO     | src.policies:train:109 - Episode 1097\n",
      "2021-08-25 11:21:35.931 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:35.932 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:21:35.933 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.15\n",
      "2021-08-25 11:21:35.934 | INFO     | src.policies:train:109 - Episode 1098\n",
      "2021-08-25 11:21:35.946 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:35.947 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:21:35.948 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.22\n",
      "2021-08-25 11:21:35.949 | INFO     | src.policies:train:109 - Episode 1099\n",
      "2021-08-25 11:21:35.966 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:35.967 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 11:21:35.968 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.22\n",
      "2021-08-25 11:21:35.969 | INFO     | src.policies:train:109 - Episode 1100\n",
      "2021-08-25 11:21:35.985 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:35.987 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 11:21:35.988 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.22\n",
      "2021-08-25 11:21:35.989 | INFO     | src.policies:train:109 - Episode 1101\n",
      "2021-08-25 11:21:36.013 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:36.014 | INFO     | src.policies:train:121 - Mean episode return: 51.0\n",
      "2021-08-25 11:21:36.015 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.1\n",
      "2021-08-25 11:21:36.016 | WARNING  | src.policies:train:131 - The actual batch size is 245, instead of 200\n",
      "2021-08-25 11:21:36.025 | INFO     | src.policies:train:157 - Total loss: 1.0024527311325073\n",
      "2021-08-25 11:21:36.028 | INFO     | src.policies:train:103 - Epoch 139 / 800\n",
      "2021-08-25 11:21:36.030 | INFO     | src.policies:train:109 - Episode 1102\n",
      "2021-08-25 11:21:36.041 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:36.043 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:21:36.044 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.11\n",
      "2021-08-25 11:21:36.045 | INFO     | src.policies:train:109 - Episode 1103\n",
      "2021-08-25 11:21:36.059 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:36.061 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 11:21:36.062 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.08\n",
      "2021-08-25 11:21:36.063 | INFO     | src.policies:train:109 - Episode 1104\n",
      "2021-08-25 11:21:36.071 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:36.072 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 11:21:36.073 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.89\n",
      "2021-08-25 11:21:36.074 | INFO     | src.policies:train:109 - Episode 1105\n",
      "2021-08-25 11:21:36.087 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:36.088 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:21:36.089 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.66\n",
      "2021-08-25 11:21:36.090 | INFO     | src.policies:train:109 - Episode 1106\n",
      "2021-08-25 11:21:36.117 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:36.119 | INFO     | src.policies:train:121 - Mean episode return: 60.0\n",
      "2021-08-25 11:21:36.120 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.97\n",
      "2021-08-25 11:21:36.122 | INFO     | src.policies:train:109 - Episode 1107\n",
      "2021-08-25 11:21:36.131 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:36.132 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 11:21:36.134 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.25\n",
      "2021-08-25 11:21:36.135 | INFO     | src.policies:train:109 - Episode 1108\n",
      "2021-08-25 11:21:36.152 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:36.154 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 11:21:36.155 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.43\n",
      "2021-08-25 11:21:36.156 | INFO     | src.policies:train:109 - Episode 1109\n",
      "2021-08-25 11:21:36.172 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:36.174 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 11:21:36.175 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.54\n",
      "2021-08-25 11:21:36.176 | WARNING  | src.policies:train:131 - The actual batch size is 207, instead of 200\n",
      "2021-08-25 11:21:36.185 | INFO     | src.policies:train:157 - Total loss: 1.0018057823181152\n",
      "2021-08-25 11:21:36.188 | INFO     | src.policies:train:103 - Epoch 140 / 800\n",
      "2021-08-25 11:21:36.190 | INFO     | src.policies:train:109 - Episode 1110\n",
      "2021-08-25 11:21:36.201 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:36.202 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:21:36.204 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.62\n",
      "2021-08-25 11:21:36.205 | INFO     | src.policies:train:109 - Episode 1111\n",
      "2021-08-25 11:21:36.223 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:36.224 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:21:36.225 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.8\n",
      "2021-08-25 11:21:36.226 | INFO     | src.policies:train:109 - Episode 1112\n",
      "2021-08-25 11:21:36.250 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:36.252 | INFO     | src.policies:train:121 - Mean episode return: 45.0\n",
      "2021-08-25 11:21:36.253 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.08\n",
      "2021-08-25 11:21:36.254 | INFO     | src.policies:train:109 - Episode 1113\n",
      "2021-08-25 11:21:36.267 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:36.268 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:36.269 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.06\n",
      "2021-08-25 11:21:36.270 | INFO     | src.policies:train:109 - Episode 1114\n",
      "2021-08-25 11:21:36.308 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:36.310 | INFO     | src.policies:train:121 - Mean episode return: 85.0\n",
      "2021-08-25 11:21:36.311 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.53\n",
      "2021-08-25 11:21:36.312 | INFO     | src.policies:train:109 - Episode 1115\n",
      "2021-08-25 11:21:36.324 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:36.326 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:36.326 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.34\n",
      "2021-08-25 11:21:36.328 | WARNING  | src.policies:train:131 - The actual batch size is 212, instead of 200\n",
      "2021-08-25 11:21:36.336 | INFO     | src.policies:train:157 - Total loss: 1.0020328760147095\n",
      "2021-08-25 11:21:36.340 | INFO     | src.policies:train:103 - Epoch 141 / 800\n",
      "2021-08-25 11:21:36.341 | INFO     | src.policies:train:109 - Episode 1116\n",
      "2021-08-25 11:21:36.354 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:36.356 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:21:36.357 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.27\n",
      "2021-08-25 11:21:36.358 | INFO     | src.policies:train:109 - Episode 1117\n",
      "2021-08-25 11:21:36.369 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:36.370 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:36.371 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.31\n",
      "2021-08-25 11:21:36.373 | INFO     | src.policies:train:109 - Episode 1118\n",
      "2021-08-25 11:21:36.388 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:36.390 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 11:21:36.391 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.28\n",
      "2021-08-25 11:21:36.393 | INFO     | src.policies:train:109 - Episode 1119\n",
      "2021-08-25 11:21:36.418 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:36.420 | INFO     | src.policies:train:121 - Mean episode return: 55.0\n",
      "2021-08-25 11:21:36.421 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.65\n",
      "2021-08-25 11:21:36.422 | INFO     | src.policies:train:109 - Episode 1120\n",
      "2021-08-25 11:21:36.437 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:36.438 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 11:21:36.439 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.54\n",
      "2021-08-25 11:21:36.441 | INFO     | src.policies:train:109 - Episode 1121\n",
      "2021-08-25 11:21:36.451 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:36.453 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:36.454 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.25\n",
      "2021-08-25 11:21:36.455 | INFO     | src.policies:train:109 - Episode 1122\n",
      "2021-08-25 11:21:36.475 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:36.476 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 11:21:36.477 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.52\n",
      "2021-08-25 11:21:36.479 | WARNING  | src.policies:train:131 - The actual batch size is 204, instead of 200\n",
      "2021-08-25 11:21:36.488 | INFO     | src.policies:train:157 - Total loss: 1.0018181800842285\n",
      "2021-08-25 11:21:36.492 | INFO     | src.policies:train:103 - Epoch 142 / 800\n",
      "2021-08-25 11:21:36.494 | INFO     | src.policies:train:109 - Episode 1123\n",
      "2021-08-25 11:21:36.503 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:36.505 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:36.506 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.27\n",
      "2021-08-25 11:21:36.507 | INFO     | src.policies:train:109 - Episode 1124\n",
      "2021-08-25 11:21:36.520 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:36.522 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:21:36.523 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.81\n",
      "2021-08-25 11:21:36.524 | INFO     | src.policies:train:109 - Episode 1125\n",
      "2021-08-25 11:21:36.550 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:36.552 | INFO     | src.policies:train:121 - Mean episode return: 55.0\n",
      "2021-08-25 11:21:36.553 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.19\n",
      "2021-08-25 11:21:36.555 | INFO     | src.policies:train:109 - Episode 1126\n",
      "2021-08-25 11:21:36.565 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:36.567 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:21:36.568 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.06\n",
      "2021-08-25 11:21:36.570 | INFO     | src.policies:train:109 - Episode 1127\n",
      "2021-08-25 11:21:36.583 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:36.585 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:21:36.586 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.92\n",
      "2021-08-25 11:21:36.587 | INFO     | src.policies:train:109 - Episode 1128\n",
      "2021-08-25 11:21:36.620 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:36.622 | INFO     | src.policies:train:121 - Mean episode return: 72.0\n",
      "2021-08-25 11:21:36.623 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.29\n",
      "2021-08-25 11:21:36.630 | INFO     | src.policies:train:157 - Total loss: 1.0017902851104736\n",
      "2021-08-25 11:21:36.635 | INFO     | src.policies:train:103 - Epoch 143 / 800\n",
      "2021-08-25 11:21:36.636 | INFO     | src.policies:train:109 - Episode 1129\n",
      "2021-08-25 11:21:36.666 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:36.667 | INFO     | src.policies:train:121 - Mean episode return: 66.0\n",
      "2021-08-25 11:21:36.668 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.33\n",
      "2021-08-25 11:21:36.670 | INFO     | src.policies:train:109 - Episode 1130\n",
      "2021-08-25 11:21:36.684 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:36.685 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:21:36.686 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:36.687 | INFO     | src.policies:train:109 - Episode 1131\n",
      "2021-08-25 11:21:36.704 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:36.706 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:21:36.706 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.15\n",
      "2021-08-25 11:21:36.707 | INFO     | src.policies:train:109 - Episode 1132\n",
      "2021-08-25 11:21:36.719 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:36.720 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:36.721 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.86\n",
      "2021-08-25 11:21:36.723 | INFO     | src.policies:train:109 - Episode 1133\n",
      "2021-08-25 11:21:36.734 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:36.735 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:36.736 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.84\n",
      "2021-08-25 11:21:36.737 | INFO     | src.policies:train:109 - Episode 1134\n",
      "2021-08-25 11:21:36.747 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:36.749 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:21:36.750 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.68\n",
      "2021-08-25 11:21:36.751 | INFO     | src.policies:train:109 - Episode 1135\n",
      "2021-08-25 11:21:36.761 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:36.762 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:36.763 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.47\n",
      "2021-08-25 11:21:36.764 | INFO     | src.policies:train:109 - Episode 1136\n",
      "2021-08-25 11:21:36.781 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:36.782 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 11:21:36.783 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.56\n",
      "2021-08-25 11:21:36.784 | WARNING  | src.policies:train:131 - The actual batch size is 205, instead of 200\n",
      "2021-08-25 11:21:36.793 | INFO     | src.policies:train:157 - Total loss: 1.0017828941345215\n",
      "2021-08-25 11:21:36.796 | INFO     | src.policies:train:103 - Epoch 144 / 800\n",
      "2021-08-25 11:21:36.797 | INFO     | src.policies:train:109 - Episode 1137\n",
      "2021-08-25 11:21:36.818 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:36.819 | INFO     | src.policies:train:121 - Mean episode return: 46.0\n",
      "2021-08-25 11:21:36.820 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.64\n",
      "2021-08-25 11:21:36.822 | INFO     | src.policies:train:109 - Episode 1138\n",
      "2021-08-25 11:21:36.837 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:36.839 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 11:21:36.840 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.08\n",
      "2021-08-25 11:21:36.841 | INFO     | src.policies:train:109 - Episode 1139\n",
      "2021-08-25 11:21:36.850 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:36.852 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:36.853 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.96\n",
      "2021-08-25 11:21:36.854 | INFO     | src.policies:train:109 - Episode 1140\n",
      "2021-08-25 11:21:36.885 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:36.886 | INFO     | src.policies:train:121 - Mean episode return: 64.0\n",
      "2021-08-25 11:21:36.887 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.98\n",
      "2021-08-25 11:21:36.888 | INFO     | src.policies:train:109 - Episode 1141\n",
      "2021-08-25 11:21:36.900 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:36.901 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:21:36.902 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.75\n",
      "2021-08-25 11:21:36.903 | INFO     | src.policies:train:109 - Episode 1142\n",
      "2021-08-25 11:21:36.913 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:36.915 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:21:36.916 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.63\n",
      "2021-08-25 11:21:36.917 | INFO     | src.policies:train:109 - Episode 1143\n",
      "2021-08-25 11:21:36.936 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:36.938 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 11:21:36.939 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.58\n",
      "2021-08-25 11:21:36.940 | WARNING  | src.policies:train:131 - The actual batch size is 220, instead of 200\n",
      "2021-08-25 11:21:36.948 | INFO     | src.policies:train:157 - Total loss: 1.0021188259124756\n",
      "2021-08-25 11:21:36.952 | INFO     | src.policies:train:103 - Epoch 145 / 800\n",
      "2021-08-25 11:21:36.953 | INFO     | src.policies:train:109 - Episode 1144\n",
      "2021-08-25 11:21:36.967 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:36.968 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:21:36.969 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.3\n",
      "2021-08-25 11:21:36.970 | INFO     | src.policies:train:109 - Episode 1145\n",
      "2021-08-25 11:21:36.988 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:36.989 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 11:21:36.990 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.43\n",
      "2021-08-25 11:21:36.992 | INFO     | src.policies:train:109 - Episode 1146\n",
      "2021-08-25 11:21:37.003 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:37.005 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:37.006 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.01\n",
      "2021-08-25 11:21:37.007 | INFO     | src.policies:train:109 - Episode 1147\n",
      "2021-08-25 11:21:37.026 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:37.027 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 11:21:37.028 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.87\n",
      "2021-08-25 11:21:37.029 | INFO     | src.policies:train:109 - Episode 1148\n",
      "2021-08-25 11:21:37.043 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:37.044 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:21:37.045 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.43\n",
      "2021-08-25 11:21:37.046 | INFO     | src.policies:train:109 - Episode 1149\n",
      "2021-08-25 11:21:37.067 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:37.068 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 11:21:37.069 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.95\n",
      "2021-08-25 11:21:37.070 | INFO     | src.policies:train:109 - Episode 1150\n",
      "2021-08-25 11:21:37.080 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:37.081 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 11:21:37.082 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.8\n",
      "2021-08-25 11:21:37.083 | INFO     | src.policies:train:109 - Episode 1151\n",
      "2021-08-25 11:21:37.124 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:37.126 | INFO     | src.policies:train:121 - Mean episode return: 91.0\n",
      "2021-08-25 11:21:37.127 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:37.128 | WARNING  | src.policies:train:131 - The actual batch size is 267, instead of 200\n",
      "2021-08-25 11:21:37.138 | INFO     | src.policies:train:157 - Total loss: 1.0028561353683472\n",
      "2021-08-25 11:21:37.142 | INFO     | src.policies:train:103 - Epoch 146 / 800\n",
      "2021-08-25 11:21:37.144 | INFO     | src.policies:train:109 - Episode 1152\n",
      "2021-08-25 11:21:37.157 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:37.158 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:21:37.160 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.59\n",
      "2021-08-25 11:21:37.161 | INFO     | src.policies:train:109 - Episode 1153\n",
      "2021-08-25 11:21:37.178 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:37.179 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:21:37.181 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.69\n",
      "2021-08-25 11:21:37.181 | INFO     | src.policies:train:109 - Episode 1154\n",
      "2021-08-25 11:21:37.199 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:37.201 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 11:21:37.202 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.73\n",
      "2021-08-25 11:21:37.203 | INFO     | src.policies:train:109 - Episode 1155\n",
      "2021-08-25 11:21:37.222 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:37.224 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 11:21:37.225 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.47\n",
      "2021-08-25 11:21:37.226 | INFO     | src.policies:train:109 - Episode 1156\n",
      "2021-08-25 11:21:37.240 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:37.242 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:21:37.243 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.4\n",
      "2021-08-25 11:21:37.244 | INFO     | src.policies:train:109 - Episode 1157\n",
      "2021-08-25 11:21:37.256 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:37.257 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:21:37.258 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.37\n",
      "2021-08-25 11:21:37.260 | INFO     | src.policies:train:109 - Episode 1158\n",
      "2021-08-25 11:21:37.284 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:37.285 | INFO     | src.policies:train:121 - Mean episode return: 50.0\n",
      "2021-08-25 11:21:37.286 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.37\n",
      "2021-08-25 11:21:37.287 | WARNING  | src.policies:train:131 - The actual batch size is 212, instead of 200\n",
      "2021-08-25 11:21:37.296 | INFO     | src.policies:train:157 - Total loss: 1.0018906593322754\n",
      "2021-08-25 11:21:37.299 | INFO     | src.policies:train:103 - Epoch 147 / 800\n",
      "2021-08-25 11:21:37.300 | INFO     | src.policies:train:109 - Episode 1159\n",
      "2021-08-25 11:21:37.310 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:37.312 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:21:37.313 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.45\n",
      "2021-08-25 11:21:37.315 | INFO     | src.policies:train:109 - Episode 1160\n",
      "2021-08-25 11:21:37.324 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:37.325 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:37.326 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.38\n",
      "2021-08-25 11:21:37.327 | INFO     | src.policies:train:109 - Episode 1161\n",
      "2021-08-25 11:21:37.337 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:37.338 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:21:37.340 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.21\n",
      "2021-08-25 11:21:37.341 | INFO     | src.policies:train:109 - Episode 1162\n",
      "2021-08-25 11:21:37.353 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:37.354 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:21:37.355 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.08\n",
      "2021-08-25 11:21:37.356 | INFO     | src.policies:train:109 - Episode 1163\n",
      "2021-08-25 11:21:37.369 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:37.370 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:21:37.371 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.17\n",
      "2021-08-25 11:21:37.372 | INFO     | src.policies:train:109 - Episode 1164\n",
      "2021-08-25 11:21:37.403 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:37.404 | INFO     | src.policies:train:121 - Mean episode return: 65.0\n",
      "2021-08-25 11:21:37.405 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.43\n",
      "2021-08-25 11:21:37.406 | INFO     | src.policies:train:109 - Episode 1165\n",
      "2021-08-25 11:21:37.446 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:37.447 | INFO     | src.policies:train:121 - Mean episode return: 90.0\n",
      "2021-08-25 11:21:37.448 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.96\n",
      "2021-08-25 11:21:37.449 | WARNING  | src.policies:train:131 - The actual batch size is 240, instead of 200\n",
      "2021-08-25 11:21:37.457 | INFO     | src.policies:train:157 - Total loss: 1.0024387836456299\n",
      "2021-08-25 11:21:37.461 | INFO     | src.policies:train:103 - Epoch 148 / 800\n",
      "2021-08-25 11:21:37.463 | INFO     | src.policies:train:109 - Episode 1166\n",
      "2021-08-25 11:21:37.474 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:37.476 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:21:37.477 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.57\n",
      "2021-08-25 11:21:37.478 | INFO     | src.policies:train:109 - Episode 1167\n",
      "2021-08-25 11:21:37.507 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:37.508 | INFO     | src.policies:train:121 - Mean episode return: 59.0\n",
      "2021-08-25 11:21:37.509 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.95\n",
      "2021-08-25 11:21:37.511 | INFO     | src.policies:train:109 - Episode 1168\n",
      "2021-08-25 11:21:37.533 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:37.534 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 11:21:37.535 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.25\n",
      "2021-08-25 11:21:37.536 | INFO     | src.policies:train:109 - Episode 1169\n",
      "2021-08-25 11:21:37.553 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:37.555 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 11:21:37.556 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.45\n",
      "2021-08-25 11:21:37.558 | INFO     | src.policies:train:109 - Episode 1170\n",
      "2021-08-25 11:21:37.579 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:37.581 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 11:21:37.582 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.08\n",
      "2021-08-25 11:21:37.584 | INFO     | src.policies:train:109 - Episode 1171\n",
      "2021-08-25 11:21:37.594 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:37.595 | INFO     | src.policies:train:121 - Mean episode return: 9.0\n",
      "2021-08-25 11:21:37.597 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.9\n",
      "2021-08-25 11:21:37.598 | INFO     | src.policies:train:109 - Episode 1172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:37.619 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:37.620 | INFO     | src.policies:train:121 - Mean episode return: 38.0\n",
      "2021-08-25 11:21:37.622 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.79\n",
      "2021-08-25 11:21:37.623 | WARNING  | src.policies:train:131 - The actual batch size is 236, instead of 200\n",
      "2021-08-25 11:21:37.634 | INFO     | src.policies:train:157 - Total loss: 1.0025588274002075\n",
      "2021-08-25 11:21:37.639 | INFO     | src.policies:train:103 - Epoch 149 / 800\n",
      "2021-08-25 11:21:37.641 | INFO     | src.policies:train:109 - Episode 1173\n",
      "2021-08-25 11:21:37.661 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:37.662 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 11:21:37.664 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.98\n",
      "2021-08-25 11:21:37.665 | INFO     | src.policies:train:109 - Episode 1174\n",
      "2021-08-25 11:21:37.681 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:37.682 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:21:37.684 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.02\n",
      "2021-08-25 11:21:37.686 | INFO     | src.policies:train:109 - Episode 1175\n",
      "2021-08-25 11:21:37.715 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:37.717 | INFO     | src.policies:train:121 - Mean episode return: 60.0\n",
      "2021-08-25 11:21:37.718 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.28\n",
      "2021-08-25 11:21:37.720 | INFO     | src.policies:train:109 - Episode 1176\n",
      "2021-08-25 11:21:37.746 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:37.748 | INFO     | src.policies:train:121 - Mean episode return: 46.0\n",
      "2021-08-25 11:21:37.749 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.31\n",
      "2021-08-25 11:21:37.751 | INFO     | src.policies:train:109 - Episode 1177\n",
      "2021-08-25 11:21:37.775 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:37.777 | INFO     | src.policies:train:121 - Mean episode return: 44.0\n",
      "2021-08-25 11:21:37.778 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.79\n",
      "2021-08-25 11:21:37.779 | WARNING  | src.policies:train:131 - The actual batch size is 204, instead of 200\n",
      "2021-08-25 11:21:37.789 | INFO     | src.policies:train:157 - Total loss: 1.0017552375793457\n",
      "2021-08-25 11:21:37.793 | INFO     | src.policies:train:103 - Epoch 150 / 800\n",
      "2021-08-25 11:21:37.795 | INFO     | src.policies:train:109 - Episode 1178\n",
      "2021-08-25 11:21:37.813 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:37.814 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 11:21:37.816 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.01\n",
      "2021-08-25 11:21:37.817 | INFO     | src.policies:train:109 - Episode 1179\n",
      "2021-08-25 11:21:37.835 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:37.837 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 11:21:37.838 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.21\n",
      "2021-08-25 11:21:37.840 | INFO     | src.policies:train:109 - Episode 1180\n",
      "2021-08-25 11:21:37.855 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:37.857 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:21:37.858 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.15\n",
      "2021-08-25 11:21:37.859 | INFO     | src.policies:train:109 - Episode 1181\n",
      "2021-08-25 11:21:37.869 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:37.870 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:21:37.872 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.68\n",
      "2021-08-25 11:21:37.873 | INFO     | src.policies:train:109 - Episode 1182\n",
      "2021-08-25 11:21:37.882 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:37.883 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:21:37.885 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.65\n",
      "2021-08-25 11:21:37.886 | INFO     | src.policies:train:109 - Episode 1183\n",
      "2021-08-25 11:21:37.917 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:37.918 | INFO     | src.policies:train:121 - Mean episode return: 69.0\n",
      "2021-08-25 11:21:37.919 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.75\n",
      "2021-08-25 11:21:37.920 | INFO     | src.policies:train:109 - Episode 1184\n",
      "2021-08-25 11:21:37.931 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:37.932 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:21:37.934 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.73\n",
      "2021-08-25 11:21:37.943 | INFO     | src.policies:train:157 - Total loss: 1.0018237829208374\n",
      "2021-08-25 11:21:37.947 | INFO     | src.policies:train:103 - Epoch 151 / 800\n",
      "2021-08-25 11:21:37.949 | INFO     | src.policies:train:109 - Episode 1185\n",
      "2021-08-25 11:21:37.957 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:37.960 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:21:37.961 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.66\n",
      "2021-08-25 11:21:37.963 | INFO     | src.policies:train:109 - Episode 1186\n",
      "2021-08-25 11:21:37.993 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:37.994 | INFO     | src.policies:train:121 - Mean episode return: 61.0\n",
      "2021-08-25 11:21:37.995 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.06\n",
      "2021-08-25 11:21:37.996 | INFO     | src.policies:train:109 - Episode 1187\n",
      "2021-08-25 11:21:38.015 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:38.017 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 11:21:38.018 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.25\n",
      "2021-08-25 11:21:38.020 | INFO     | src.policies:train:109 - Episode 1188\n",
      "2021-08-25 11:21:38.045 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:38.046 | INFO     | src.policies:train:121 - Mean episode return: 47.0\n",
      "2021-08-25 11:21:38.047 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.52\n",
      "2021-08-25 11:21:38.049 | INFO     | src.policies:train:109 - Episode 1189\n",
      "2021-08-25 11:21:38.058 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:38.060 | INFO     | src.policies:train:121 - Mean episode return: 9.0\n",
      "2021-08-25 11:21:38.061 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.47\n",
      "2021-08-25 11:21:38.062 | INFO     | src.policies:train:109 - Episode 1190\n",
      "2021-08-25 11:21:38.075 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:38.077 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:38.078 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.13\n",
      "2021-08-25 11:21:38.080 | INFO     | src.policies:train:109 - Episode 1191\n",
      "2021-08-25 11:21:38.090 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:38.091 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:21:38.093 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.04\n",
      "2021-08-25 11:21:38.094 | INFO     | src.policies:train:109 - Episode 1192\n",
      "2021-08-25 11:21:38.106 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:38.107 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:38.108 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.05\n",
      "2021-08-25 11:21:38.110 | WARNING  | src.policies:train:131 - The actual batch size is 205, instead of 200\n",
      "2021-08-25 11:21:38.120 | INFO     | src.policies:train:157 - Total loss: 1.0019185543060303\n",
      "2021-08-25 11:21:38.124 | INFO     | src.policies:train:103 - Epoch 152 / 800\n",
      "2021-08-25 11:21:38.126 | INFO     | src.policies:train:109 - Episode 1193\n",
      "2021-08-25 11:21:38.164 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:38.165 | INFO     | src.policies:train:121 - Mean episode return: 84.0\n",
      "2021-08-25 11:21:38.166 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.41\n",
      "2021-08-25 11:21:38.167 | INFO     | src.policies:train:109 - Episode 1194\n",
      "2021-08-25 11:21:38.219 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:38.221 | INFO     | src.policies:train:121 - Mean episode return: 116.0\n",
      "2021-08-25 11:21:38.222 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.42\n",
      "2021-08-25 11:21:38.230 | INFO     | src.policies:train:157 - Total loss: 1.0016576051712036\n",
      "2021-08-25 11:21:38.235 | INFO     | src.policies:train:103 - Epoch 153 / 800\n",
      "2021-08-25 11:21:38.237 | INFO     | src.policies:train:109 - Episode 1195\n",
      "2021-08-25 11:21:38.254 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:38.256 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:21:38.257 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.32\n",
      "2021-08-25 11:21:38.259 | INFO     | src.policies:train:109 - Episode 1196\n",
      "2021-08-25 11:21:38.284 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:38.285 | INFO     | src.policies:train:121 - Mean episode return: 39.0\n",
      "2021-08-25 11:21:38.287 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.34\n",
      "2021-08-25 11:21:38.288 | INFO     | src.policies:train:109 - Episode 1197\n",
      "2021-08-25 11:21:38.307 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:38.308 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:21:38.310 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.39\n",
      "2021-08-25 11:21:38.312 | INFO     | src.policies:train:109 - Episode 1198\n",
      "2021-08-25 11:21:38.336 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:38.337 | INFO     | src.policies:train:121 - Mean episode return: 38.0\n",
      "2021-08-25 11:21:38.339 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.58\n",
      "2021-08-25 11:21:38.341 | INFO     | src.policies:train:109 - Episode 1199\n",
      "2021-08-25 11:21:38.355 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:38.357 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:21:38.359 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.39\n",
      "2021-08-25 11:21:38.360 | INFO     | src.policies:train:109 - Episode 1200\n",
      "2021-08-25 11:21:38.386 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:38.387 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 11:21:38.389 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.49\n",
      "2021-08-25 11:21:38.390 | INFO     | src.policies:train:109 - Episode 1201\n",
      "2021-08-25 11:21:38.405 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:38.407 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:21:38.408 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.18\n",
      "2021-08-25 11:21:38.409 | WARNING  | src.policies:train:131 - The actual batch size is 206, instead of 200\n",
      "2021-08-25 11:21:38.421 | INFO     | src.policies:train:157 - Total loss: 1.0018744468688965\n",
      "2021-08-25 11:21:38.426 | INFO     | src.policies:train:103 - Epoch 154 / 800\n",
      "2021-08-25 11:21:38.427 | INFO     | src.policies:train:109 - Episode 1202\n",
      "2021-08-25 11:21:38.447 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:38.448 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 11:21:38.450 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.24\n",
      "2021-08-25 11:21:38.451 | INFO     | src.policies:train:109 - Episode 1203\n",
      "2021-08-25 11:21:38.465 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:38.466 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:21:38.468 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.1\n",
      "2021-08-25 11:21:38.469 | INFO     | src.policies:train:109 - Episode 1204\n",
      "2021-08-25 11:21:38.482 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:38.483 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:21:38.485 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.14\n",
      "2021-08-25 11:21:38.487 | INFO     | src.policies:train:109 - Episode 1205\n",
      "2021-08-25 11:21:38.508 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:38.510 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 11:21:38.511 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.28\n",
      "2021-08-25 11:21:38.513 | INFO     | src.policies:train:109 - Episode 1206\n",
      "2021-08-25 11:21:38.545 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:38.547 | INFO     | src.policies:train:121 - Mean episode return: 64.0\n",
      "2021-08-25 11:21:38.548 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.32\n",
      "2021-08-25 11:21:38.549 | INFO     | src.policies:train:109 - Episode 1207\n",
      "2021-08-25 11:21:38.564 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:38.566 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:21:38.567 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.43\n",
      "2021-08-25 11:21:38.568 | INFO     | src.policies:train:109 - Episode 1208\n",
      "2021-08-25 11:21:38.580 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:38.581 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:38.583 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.32\n",
      "2021-08-25 11:21:38.584 | INFO     | src.policies:train:109 - Episode 1209\n",
      "2021-08-25 11:21:38.605 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:38.607 | INFO     | src.policies:train:121 - Mean episode return: 43.0\n",
      "2021-08-25 11:21:38.608 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.48\n",
      "2021-08-25 11:21:38.610 | WARNING  | src.policies:train:131 - The actual batch size is 237, instead of 200\n",
      "2021-08-25 11:21:38.621 | INFO     | src.policies:train:157 - Total loss: 1.0023632049560547\n",
      "2021-08-25 11:21:38.625 | INFO     | src.policies:train:103 - Epoch 155 / 800\n",
      "2021-08-25 11:21:38.626 | INFO     | src.policies:train:109 - Episode 1210\n",
      "2021-08-25 11:21:38.637 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:38.639 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:21:38.640 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.39\n",
      "2021-08-25 11:21:38.641 | INFO     | src.policies:train:109 - Episode 1211\n",
      "2021-08-25 11:21:38.651 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:38.653 | INFO     | src.policies:train:121 - Mean episode return: 9.0\n",
      "2021-08-25 11:21:38.654 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.19\n",
      "2021-08-25 11:21:38.656 | INFO     | src.policies:train:109 - Episode 1212\n",
      "2021-08-25 11:21:38.674 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:38.676 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 11:21:38.677 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.01\n",
      "2021-08-25 11:21:38.678 | INFO     | src.policies:train:109 - Episode 1213\n",
      "2021-08-25 11:21:38.692 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:38.694 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:21:38.695 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.03\n",
      "2021-08-25 11:21:38.697 | INFO     | src.policies:train:109 - Episode 1214\n",
      "2021-08-25 11:21:38.709 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:38.710 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:21:38.712 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.36\n",
      "2021-08-25 11:21:38.713 | INFO     | src.policies:train:109 - Episode 1215\n",
      "2021-08-25 11:21:38.758 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:38.759 | INFO     | src.policies:train:121 - Mean episode return: 100.0\n",
      "2021-08-25 11:21:38.760 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.2\n",
      "2021-08-25 11:21:38.762 | INFO     | src.policies:train:109 - Episode 1216\n",
      "2021-08-25 11:21:38.788 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:38.790 | INFO     | src.policies:train:121 - Mean episode return: 52.0\n",
      "2021-08-25 11:21:38.792 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.46\n",
      "2021-08-25 11:21:38.793 | WARNING  | src.policies:train:131 - The actual batch size is 236, instead of 200\n",
      "2021-08-25 11:21:38.803 | INFO     | src.policies:train:157 - Total loss: 1.002600073814392\n",
      "2021-08-25 11:21:38.806 | INFO     | src.policies:train:103 - Epoch 156 / 800\n",
      "2021-08-25 11:21:38.808 | INFO     | src.policies:train:109 - Episode 1217\n",
      "2021-08-25 11:21:38.826 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:38.828 | INFO     | src.policies:train:121 - Mean episode return: 39.0\n",
      "2021-08-25 11:21:38.829 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.69\n",
      "2021-08-25 11:21:38.830 | INFO     | src.policies:train:109 - Episode 1218\n",
      "2021-08-25 11:21:38.842 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:38.844 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:21:38.845 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.55\n",
      "2021-08-25 11:21:38.847 | INFO     | src.policies:train:109 - Episode 1219\n",
      "2021-08-25 11:21:38.858 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:38.859 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:38.861 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.12\n",
      "2021-08-25 11:21:38.862 | INFO     | src.policies:train:109 - Episode 1220\n",
      "2021-08-25 11:21:38.894 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:38.895 | INFO     | src.policies:train:121 - Mean episode return: 65.0\n",
      "2021-08-25 11:21:38.897 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.5\n",
      "2021-08-25 11:21:38.898 | INFO     | src.policies:train:109 - Episode 1221\n",
      "2021-08-25 11:21:38.913 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:38.915 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:21:38.916 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.44\n",
      "2021-08-25 11:21:38.917 | INFO     | src.policies:train:109 - Episode 1222\n",
      "2021-08-25 11:21:38.927 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:38.928 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:21:38.929 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.22\n",
      "2021-08-25 11:21:38.931 | INFO     | src.policies:train:109 - Episode 1223\n",
      "2021-08-25 11:21:38.945 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:38.946 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:21:38.947 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.25\n",
      "2021-08-25 11:21:38.948 | INFO     | src.policies:train:109 - Episode 1224\n",
      "2021-08-25 11:21:38.959 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:38.962 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:21:38.963 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.19\n",
      "2021-08-25 11:21:38.965 | INFO     | src.policies:train:109 - Episode 1225\n",
      "2021-08-25 11:21:38.979 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:38.980 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:21:38.982 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.9\n",
      "2021-08-25 11:21:38.983 | WARNING  | src.policies:train:131 - The actual batch size is 214, instead of 200\n",
      "2021-08-25 11:21:38.994 | INFO     | src.policies:train:157 - Total loss: 1.0020908117294312\n",
      "2021-08-25 11:21:38.998 | INFO     | src.policies:train:103 - Epoch 157 / 800\n",
      "2021-08-25 11:21:38.999 | INFO     | src.policies:train:109 - Episode 1226\n",
      "2021-08-25 11:21:39.010 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:39.012 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:39.013 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.93\n",
      "2021-08-25 11:21:39.015 | INFO     | src.policies:train:109 - Episode 1227\n",
      "2021-08-25 11:21:39.027 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:39.028 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:39.030 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.86\n",
      "2021-08-25 11:21:39.031 | INFO     | src.policies:train:109 - Episode 1228\n",
      "2021-08-25 11:21:39.067 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:39.069 | INFO     | src.policies:train:121 - Mean episode return: 77.0\n",
      "2021-08-25 11:21:39.070 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.91\n",
      "2021-08-25 11:21:39.072 | INFO     | src.policies:train:109 - Episode 1229\n",
      "2021-08-25 11:21:39.099 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:39.101 | INFO     | src.policies:train:121 - Mean episode return: 59.0\n",
      "2021-08-25 11:21:39.102 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.84\n",
      "2021-08-25 11:21:39.104 | INFO     | src.policies:train:109 - Episode 1230\n",
      "2021-08-25 11:21:39.119 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:39.121 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 11:21:39.122 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.89\n",
      "2021-08-25 11:21:39.124 | INFO     | src.policies:train:109 - Episode 1231\n",
      "2021-08-25 11:21:39.140 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:39.141 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 11:21:39.143 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.87\n",
      "2021-08-25 11:21:39.144 | WARNING  | src.policies:train:131 - The actual batch size is 220, instead of 200\n",
      "2021-08-25 11:21:39.154 | INFO     | src.policies:train:157 - Total loss: 1.0021353960037231\n",
      "2021-08-25 11:21:39.158 | INFO     | src.policies:train:103 - Epoch 158 / 800\n",
      "2021-08-25 11:21:39.160 | INFO     | src.policies:train:109 - Episode 1232\n",
      "2021-08-25 11:21:39.184 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:39.186 | INFO     | src.policies:train:121 - Mean episode return: 51.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:39.187 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.21\n",
      "2021-08-25 11:21:39.188 | INFO     | src.policies:train:109 - Episode 1233\n",
      "2021-08-25 11:21:39.204 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:39.205 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:21:39.207 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.31\n",
      "2021-08-25 11:21:39.207 | INFO     | src.policies:train:109 - Episode 1234\n",
      "2021-08-25 11:21:39.234 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:39.235 | INFO     | src.policies:train:121 - Mean episode return: 52.0\n",
      "2021-08-25 11:21:39.237 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.7\n",
      "2021-08-25 11:21:39.238 | INFO     | src.policies:train:109 - Episode 1235\n",
      "2021-08-25 11:21:39.250 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:39.252 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:39.254 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.74\n",
      "2021-08-25 11:21:39.255 | INFO     | src.policies:train:109 - Episode 1236\n",
      "2021-08-25 11:21:39.274 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:39.276 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 11:21:39.277 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.73\n",
      "2021-08-25 11:21:39.279 | INFO     | src.policies:train:109 - Episode 1237\n",
      "2021-08-25 11:21:39.304 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:39.306 | INFO     | src.policies:train:121 - Mean episode return: 47.0\n",
      "2021-08-25 11:21:39.307 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.74\n",
      "2021-08-25 11:21:39.309 | WARNING  | src.policies:train:131 - The actual batch size is 223, instead of 200\n",
      "2021-08-25 11:21:39.319 | INFO     | src.policies:train:157 - Total loss: 1.0021071434020996\n",
      "2021-08-25 11:21:39.324 | INFO     | src.policies:train:103 - Epoch 159 / 800\n",
      "2021-08-25 11:21:39.326 | INFO     | src.policies:train:109 - Episode 1238\n",
      "2021-08-25 11:21:39.350 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:39.351 | INFO     | src.policies:train:121 - Mean episode return: 48.0\n",
      "2021-08-25 11:21:39.353 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.94\n",
      "2021-08-25 11:21:39.354 | INFO     | src.policies:train:109 - Episode 1239\n",
      "2021-08-25 11:21:39.366 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:39.367 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:21:39.369 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.93\n",
      "2021-08-25 11:21:39.370 | INFO     | src.policies:train:109 - Episode 1240\n",
      "2021-08-25 11:21:39.392 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:39.394 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:21:39.395 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.58\n",
      "2021-08-25 11:21:39.397 | INFO     | src.policies:train:109 - Episode 1241\n",
      "2021-08-25 11:21:39.416 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:39.417 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:21:39.419 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.69\n",
      "2021-08-25 11:21:39.420 | INFO     | src.policies:train:109 - Episode 1242\n",
      "2021-08-25 11:21:39.439 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:39.441 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:21:39.442 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.79\n",
      "2021-08-25 11:21:39.444 | INFO     | src.policies:train:109 - Episode 1243\n",
      "2021-08-25 11:21:39.469 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:39.470 | INFO     | src.policies:train:121 - Mean episode return: 42.0\n",
      "2021-08-25 11:21:39.472 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.86\n",
      "2021-08-25 11:21:39.473 | INFO     | src.policies:train:109 - Episode 1244\n",
      "2021-08-25 11:21:39.487 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:39.489 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:21:39.490 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.84\n",
      "2021-08-25 11:21:39.491 | WARNING  | src.policies:train:131 - The actual batch size is 207, instead of 200\n",
      "2021-08-25 11:21:39.501 | INFO     | src.policies:train:157 - Total loss: 1.0017471313476562\n",
      "2021-08-25 11:21:39.507 | INFO     | src.policies:train:103 - Epoch 160 / 800\n",
      "2021-08-25 11:21:39.509 | INFO     | src.policies:train:109 - Episode 1245\n",
      "2021-08-25 11:21:39.527 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:39.531 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 11:21:39.535 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.79\n",
      "2021-08-25 11:21:39.542 | INFO     | src.policies:train:109 - Episode 1246\n",
      "2021-08-25 11:21:39.565 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:39.566 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 11:21:39.568 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.94\n",
      "2021-08-25 11:21:39.569 | INFO     | src.policies:train:109 - Episode 1247\n",
      "2021-08-25 11:21:39.584 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:39.585 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:21:39.586 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.84\n",
      "2021-08-25 11:21:39.587 | INFO     | src.policies:train:109 - Episode 1248\n",
      "2021-08-25 11:21:39.603 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:39.605 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 11:21:39.606 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.91\n",
      "2021-08-25 11:21:39.607 | INFO     | src.policies:train:109 - Episode 1249\n",
      "2021-08-25 11:21:39.620 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:39.622 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:21:39.623 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.7\n",
      "2021-08-25 11:21:39.624 | INFO     | src.policies:train:109 - Episode 1250\n",
      "2021-08-25 11:21:39.647 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:39.648 | INFO     | src.policies:train:121 - Mean episode return: 39.0\n",
      "2021-08-25 11:21:39.649 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.99\n",
      "2021-08-25 11:21:39.650 | INFO     | src.policies:train:109 - Episode 1251\n",
      "2021-08-25 11:21:39.661 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:39.662 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:39.663 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.23\n",
      "2021-08-25 11:21:39.664 | INFO     | src.policies:train:109 - Episode 1252\n",
      "2021-08-25 11:21:39.677 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:39.679 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:21:39.680 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.24\n",
      "2021-08-25 11:21:39.681 | WARNING  | src.policies:train:131 - The actual batch size is 206, instead of 200\n",
      "2021-08-25 11:21:39.688 | INFO     | src.policies:train:157 - Total loss: 1.001855731010437\n",
      "2021-08-25 11:21:39.692 | INFO     | src.policies:train:103 - Epoch 161 / 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:39.693 | INFO     | src.policies:train:109 - Episode 1253\n",
      "2021-08-25 11:21:39.708 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:39.709 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 11:21:39.711 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.26\n",
      "2021-08-25 11:21:39.712 | INFO     | src.policies:train:109 - Episode 1254\n",
      "2021-08-25 11:21:39.733 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:39.734 | INFO     | src.policies:train:121 - Mean episode return: 39.0\n",
      "2021-08-25 11:21:39.735 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.32\n",
      "2021-08-25 11:21:39.736 | INFO     | src.policies:train:109 - Episode 1255\n",
      "2021-08-25 11:21:39.780 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:39.781 | INFO     | src.policies:train:121 - Mean episode return: 101.0\n",
      "2021-08-25 11:21:39.782 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.98\n",
      "2021-08-25 11:21:39.783 | INFO     | src.policies:train:109 - Episode 1256\n",
      "2021-08-25 11:21:39.803 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:39.805 | INFO     | src.policies:train:121 - Mean episode return: 45.0\n",
      "2021-08-25 11:21:39.806 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.2\n",
      "2021-08-25 11:21:39.807 | WARNING  | src.policies:train:131 - The actual batch size is 216, instead of 200\n",
      "2021-08-25 11:21:39.815 | INFO     | src.policies:train:157 - Total loss: 1.002069115638733\n",
      "2021-08-25 11:21:39.818 | INFO     | src.policies:train:103 - Epoch 162 / 800\n",
      "2021-08-25 11:21:39.820 | INFO     | src.policies:train:109 - Episode 1257\n",
      "2021-08-25 11:21:39.827 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:39.829 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:39.830 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.12\n",
      "2021-08-25 11:21:39.831 | INFO     | src.policies:train:109 - Episode 1258\n",
      "2021-08-25 11:21:39.848 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:39.849 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 11:21:39.850 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.96\n",
      "2021-08-25 11:21:39.851 | INFO     | src.policies:train:109 - Episode 1259\n",
      "2021-08-25 11:21:39.867 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:39.868 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 11:21:39.869 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.05\n",
      "2021-08-25 11:21:39.871 | INFO     | src.policies:train:109 - Episode 1260\n",
      "2021-08-25 11:21:39.884 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:39.885 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:21:39.886 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.12\n",
      "2021-08-25 11:21:39.887 | INFO     | src.policies:train:109 - Episode 1261\n",
      "2021-08-25 11:21:39.899 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:39.901 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:39.902 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.16\n",
      "2021-08-25 11:21:39.903 | INFO     | src.policies:train:109 - Episode 1262\n",
      "2021-08-25 11:21:39.915 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:39.916 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:21:39.917 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.15\n",
      "2021-08-25 11:21:39.918 | INFO     | src.policies:train:109 - Episode 1263\n",
      "2021-08-25 11:21:39.930 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:39.932 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:21:39.934 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.14\n",
      "2021-08-25 11:21:39.935 | INFO     | src.policies:train:109 - Episode 1264\n",
      "2021-08-25 11:21:39.953 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:39.954 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 11:21:39.956 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.83\n",
      "2021-08-25 11:21:39.957 | INFO     | src.policies:train:109 - Episode 1265\n",
      "2021-08-25 11:21:39.979 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:39.981 | INFO     | src.policies:train:121 - Mean episode return: 46.0\n",
      "2021-08-25 11:21:39.982 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.39\n",
      "2021-08-25 11:21:39.983 | WARNING  | src.policies:train:131 - The actual batch size is 229, instead of 200\n",
      "2021-08-25 11:21:39.993 | INFO     | src.policies:train:157 - Total loss: 1.0025123357772827\n",
      "2021-08-25 11:21:39.997 | INFO     | src.policies:train:103 - Epoch 163 / 800\n",
      "2021-08-25 11:21:39.998 | INFO     | src.policies:train:109 - Episode 1266\n",
      "2021-08-25 11:21:40.019 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:40.022 | INFO     | src.policies:train:121 - Mean episode return: 42.0\n",
      "2021-08-25 11:21:40.023 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.59\n",
      "2021-08-25 11:21:40.024 | INFO     | src.policies:train:109 - Episode 1267\n",
      "2021-08-25 11:21:40.037 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:40.038 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:21:40.040 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.21\n",
      "2021-08-25 11:21:40.041 | INFO     | src.policies:train:109 - Episode 1268\n",
      "2021-08-25 11:21:40.055 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:40.056 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:21:40.057 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.01\n",
      "2021-08-25 11:21:40.059 | INFO     | src.policies:train:109 - Episode 1269\n",
      "2021-08-25 11:21:40.075 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:40.076 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:21:40.077 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.99\n",
      "2021-08-25 11:21:40.078 | INFO     | src.policies:train:109 - Episode 1270\n",
      "2021-08-25 11:21:40.090 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:40.091 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:40.092 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.79\n",
      "2021-08-25 11:21:40.093 | INFO     | src.policies:train:109 - Episode 1271\n",
      "2021-08-25 11:21:40.103 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:40.105 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:40.106 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.82\n",
      "2021-08-25 11:21:40.107 | INFO     | src.policies:train:109 - Episode 1272\n",
      "2021-08-25 11:21:40.137 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:40.138 | INFO     | src.policies:train:121 - Mean episode return: 55.0\n",
      "2021-08-25 11:21:40.140 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.99\n",
      "2021-08-25 11:21:40.141 | INFO     | src.policies:train:109 - Episode 1273\n",
      "2021-08-25 11:21:40.165 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:40.166 | INFO     | src.policies:train:121 - Mean episode return: 49.0\n",
      "2021-08-25 11:21:40.167 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:40.168 | WARNING  | src.policies:train:131 - The actual batch size is 245, instead of 200\n",
      "2021-08-25 11:21:40.177 | INFO     | src.policies:train:157 - Total loss: 1.0024616718292236\n",
      "2021-08-25 11:21:40.180 | INFO     | src.policies:train:103 - Epoch 164 / 800\n",
      "2021-08-25 11:21:40.182 | INFO     | src.policies:train:109 - Episode 1274\n",
      "2021-08-25 11:21:40.195 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:40.197 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 11:21:40.198 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.22\n",
      "2021-08-25 11:21:40.199 | INFO     | src.policies:train:109 - Episode 1275\n",
      "2021-08-25 11:21:40.227 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:40.228 | INFO     | src.policies:train:121 - Mean episode return: 59.0\n",
      "2021-08-25 11:21:40.229 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.21\n",
      "2021-08-25 11:21:40.230 | INFO     | src.policies:train:109 - Episode 1276\n",
      "2021-08-25 11:21:40.252 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:40.253 | INFO     | src.policies:train:121 - Mean episode return: 42.0\n",
      "2021-08-25 11:21:40.254 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.17\n",
      "2021-08-25 11:21:40.256 | INFO     | src.policies:train:109 - Episode 1277\n",
      "2021-08-25 11:21:40.274 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:40.275 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 11:21:40.277 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.08\n",
      "2021-08-25 11:21:40.278 | INFO     | src.policies:train:109 - Episode 1278\n",
      "2021-08-25 11:21:40.295 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:40.296 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 11:21:40.297 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.01\n",
      "2021-08-25 11:21:40.299 | INFO     | src.policies:train:109 - Episode 1279\n",
      "2021-08-25 11:21:40.323 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:40.324 | INFO     | src.policies:train:121 - Mean episode return: 52.0\n",
      "2021-08-25 11:21:40.325 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.22\n",
      "2021-08-25 11:21:40.326 | WARNING  | src.policies:train:131 - The actual batch size is 244, instead of 200\n",
      "2021-08-25 11:21:40.335 | INFO     | src.policies:train:157 - Total loss: 1.002544641494751\n",
      "2021-08-25 11:21:40.338 | INFO     | src.policies:train:103 - Epoch 165 / 800\n",
      "2021-08-25 11:21:40.340 | INFO     | src.policies:train:109 - Episode 1280\n",
      "2021-08-25 11:21:40.350 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:40.351 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:21:40.353 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.17\n",
      "2021-08-25 11:21:40.354 | INFO     | src.policies:train:109 - Episode 1281\n",
      "2021-08-25 11:21:40.370 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:40.371 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:21:40.373 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.33\n",
      "2021-08-25 11:21:40.374 | INFO     | src.policies:train:109 - Episode 1282\n",
      "2021-08-25 11:21:40.390 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:40.391 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 11:21:40.393 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.48\n",
      "2021-08-25 11:21:40.394 | INFO     | src.policies:train:109 - Episode 1283\n",
      "2021-08-25 11:21:40.405 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:40.406 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:40.407 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.96\n",
      "2021-08-25 11:21:40.408 | INFO     | src.policies:train:109 - Episode 1284\n",
      "2021-08-25 11:21:40.420 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:40.421 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:21:40.423 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.02\n",
      "2021-08-25 11:21:40.423 | INFO     | src.policies:train:109 - Episode 1285\n",
      "2021-08-25 11:21:40.434 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:40.435 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:40.436 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.05\n",
      "2021-08-25 11:21:40.438 | INFO     | src.policies:train:109 - Episode 1286\n",
      "2021-08-25 11:21:40.459 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:40.460 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 11:21:40.461 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.81\n",
      "2021-08-25 11:21:40.462 | INFO     | src.policies:train:109 - Episode 1287\n",
      "2021-08-25 11:21:40.474 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:40.476 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:21:40.477 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.67\n",
      "2021-08-25 11:21:40.478 | INFO     | src.policies:train:109 - Episode 1288\n",
      "2021-08-25 11:21:40.486 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:40.487 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:21:40.488 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.31\n",
      "2021-08-25 11:21:40.489 | INFO     | src.policies:train:109 - Episode 1289\n",
      "2021-08-25 11:21:40.504 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:40.506 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:21:40.507 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.48\n",
      "2021-08-25 11:21:40.508 | WARNING  | src.policies:train:131 - The actual batch size is 224, instead of 200\n",
      "2021-08-25 11:21:40.517 | INFO     | src.policies:train:157 - Total loss: 1.0021417140960693\n",
      "2021-08-25 11:21:40.520 | INFO     | src.policies:train:103 - Epoch 166 / 800\n",
      "2021-08-25 11:21:40.522 | INFO     | src.policies:train:109 - Episode 1290\n",
      "2021-08-25 11:21:40.536 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:40.537 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:21:40.538 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.62\n",
      "2021-08-25 11:21:40.539 | INFO     | src.policies:train:109 - Episode 1291\n",
      "2021-08-25 11:21:40.551 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:40.552 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:21:40.554 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.71\n",
      "2021-08-25 11:21:40.555 | INFO     | src.policies:train:109 - Episode 1292\n",
      "2021-08-25 11:21:40.570 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:40.572 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 11:21:40.573 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.88\n",
      "2021-08-25 11:21:40.575 | INFO     | src.policies:train:109 - Episode 1293\n",
      "2021-08-25 11:21:40.583 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:40.584 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 11:21:40.586 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.14\n",
      "2021-08-25 11:21:40.586 | INFO     | src.policies:train:109 - Episode 1294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:40.606 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:40.608 | INFO     | src.policies:train:121 - Mean episode return: 39.0\n",
      "2021-08-25 11:21:40.609 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.37\n",
      "2021-08-25 11:21:40.610 | INFO     | src.policies:train:109 - Episode 1295\n",
      "2021-08-25 11:21:40.623 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:40.625 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:21:40.626 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.3\n",
      "2021-08-25 11:21:40.627 | INFO     | src.policies:train:109 - Episode 1296\n",
      "2021-08-25 11:21:40.639 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:40.640 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:40.641 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.06\n",
      "2021-08-25 11:21:40.642 | INFO     | src.policies:train:109 - Episode 1297\n",
      "2021-08-25 11:21:40.654 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:40.655 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:21:40.656 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.96\n",
      "2021-08-25 11:21:40.657 | INFO     | src.policies:train:109 - Episode 1298\n",
      "2021-08-25 11:21:40.673 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:40.674 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 11:21:40.675 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.88\n",
      "2021-08-25 11:21:40.676 | WARNING  | src.policies:train:131 - The actual batch size is 213, instead of 200\n",
      "2021-08-25 11:21:40.685 | INFO     | src.policies:train:157 - Total loss: 1.002098560333252\n",
      "2021-08-25 11:21:40.689 | INFO     | src.policies:train:103 - Epoch 167 / 800\n",
      "2021-08-25 11:21:40.690 | INFO     | src.policies:train:109 - Episode 1299\n",
      "2021-08-25 11:21:40.702 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:40.703 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:21:40.704 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.95\n",
      "2021-08-25 11:21:40.705 | INFO     | src.policies:train:109 - Episode 1300\n",
      "2021-08-25 11:21:40.749 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:40.750 | INFO     | src.policies:train:121 - Mean episode return: 104.0\n",
      "2021-08-25 11:21:40.751 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.59\n",
      "2021-08-25 11:21:40.752 | INFO     | src.policies:train:109 - Episode 1301\n",
      "2021-08-25 11:21:40.767 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:40.768 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:21:40.769 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.65\n",
      "2021-08-25 11:21:40.770 | INFO     | src.policies:train:109 - Episode 1302\n",
      "2021-08-25 11:21:40.798 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:40.799 | INFO     | src.policies:train:121 - Mean episode return: 60.0\n",
      "2021-08-25 11:21:40.801 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.95\n",
      "2021-08-25 11:21:40.802 | WARNING  | src.policies:train:131 - The actual batch size is 211, instead of 200\n",
      "2021-08-25 11:21:40.809 | INFO     | src.policies:train:157 - Total loss: 1.0018589496612549\n",
      "2021-08-25 11:21:40.812 | INFO     | src.policies:train:103 - Epoch 168 / 800\n",
      "2021-08-25 11:21:40.813 | INFO     | src.policies:train:109 - Episode 1303\n",
      "2021-08-25 11:21:40.836 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:40.837 | INFO     | src.policies:train:121 - Mean episode return: 54.0\n",
      "2021-08-25 11:21:40.839 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.36\n",
      "2021-08-25 11:21:40.840 | INFO     | src.policies:train:109 - Episode 1304\n",
      "2021-08-25 11:21:40.862 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:40.863 | INFO     | src.policies:train:121 - Mean episode return: 47.0\n",
      "2021-08-25 11:21:40.864 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.69\n",
      "2021-08-25 11:21:40.865 | INFO     | src.policies:train:109 - Episode 1305\n",
      "2021-08-25 11:21:40.877 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:40.879 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:21:40.880 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.52\n",
      "2021-08-25 11:21:40.882 | INFO     | src.policies:train:109 - Episode 1306\n",
      "2021-08-25 11:21:40.896 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:40.898 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:21:40.899 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.14\n",
      "2021-08-25 11:21:40.900 | INFO     | src.policies:train:109 - Episode 1307\n",
      "2021-08-25 11:21:40.919 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:40.920 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 11:21:40.922 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.3\n",
      "2021-08-25 11:21:40.923 | INFO     | src.policies:train:109 - Episode 1308\n",
      "2021-08-25 11:21:40.946 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:40.947 | INFO     | src.policies:train:121 - Mean episode return: 48.0\n",
      "2021-08-25 11:21:40.948 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.61\n",
      "2021-08-25 11:21:40.949 | WARNING  | src.policies:train:131 - The actual batch size is 230, instead of 200\n",
      "2021-08-25 11:21:40.958 | INFO     | src.policies:train:157 - Total loss: 1.0023972988128662\n",
      "2021-08-25 11:21:40.962 | INFO     | src.policies:train:103 - Epoch 169 / 800\n",
      "2021-08-25 11:21:40.963 | INFO     | src.policies:train:109 - Episode 1309\n",
      "2021-08-25 11:21:40.975 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:40.976 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:21:40.977 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.38\n",
      "2021-08-25 11:21:40.978 | INFO     | src.policies:train:109 - Episode 1310\n",
      "2021-08-25 11:21:40.989 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:40.990 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:21:40.992 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.41\n",
      "2021-08-25 11:21:40.993 | INFO     | src.policies:train:109 - Episode 1311\n",
      "2021-08-25 11:21:41.010 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:41.011 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 11:21:41.012 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.59\n",
      "2021-08-25 11:21:41.013 | INFO     | src.policies:train:109 - Episode 1312\n",
      "2021-08-25 11:21:41.031 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:41.033 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 11:21:41.034 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.65\n",
      "2021-08-25 11:21:41.035 | INFO     | src.policies:train:109 - Episode 1313\n",
      "2021-08-25 11:21:41.066 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:41.068 | INFO     | src.policies:train:121 - Mean episode return: 67.0\n",
      "2021-08-25 11:21:41.069 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.13\n",
      "2021-08-25 11:21:41.069 | INFO     | src.policies:train:109 - Episode 1314\n",
      "2021-08-25 11:21:41.086 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:41.087 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 11:21:41.088 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.23\n",
      "2021-08-25 11:21:41.090 | INFO     | src.policies:train:109 - Episode 1315\n",
      "2021-08-25 11:21:41.105 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:41.107 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 11:21:41.108 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.48\n",
      "2021-08-25 11:21:41.109 | WARNING  | src.policies:train:131 - The actual batch size is 214, instead of 200\n",
      "2021-08-25 11:21:41.119 | INFO     | src.policies:train:157 - Total loss: 1.0018495321273804\n",
      "2021-08-25 11:21:41.124 | INFO     | src.policies:train:103 - Epoch 170 / 800\n",
      "2021-08-25 11:21:41.125 | INFO     | src.policies:train:109 - Episode 1316\n",
      "2021-08-25 11:21:41.133 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:41.135 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:21:41.136 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.07\n",
      "2021-08-25 11:21:41.138 | INFO     | src.policies:train:109 - Episode 1317\n",
      "2021-08-25 11:21:41.165 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:41.167 | INFO     | src.policies:train:121 - Mean episode return: 55.0\n",
      "2021-08-25 11:21:41.168 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.23\n",
      "2021-08-25 11:21:41.169 | INFO     | src.policies:train:109 - Episode 1318\n",
      "2021-08-25 11:21:41.181 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:41.182 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:21:41.183 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.24\n",
      "2021-08-25 11:21:41.184 | INFO     | src.policies:train:109 - Episode 1319\n",
      "2021-08-25 11:21:41.200 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:41.201 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:21:41.203 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.38\n",
      "2021-08-25 11:21:41.204 | INFO     | src.policies:train:109 - Episode 1320\n",
      "2021-08-25 11:21:41.223 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:41.224 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 11:21:41.226 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.1\n",
      "2021-08-25 11:21:41.227 | INFO     | src.policies:train:109 - Episode 1321\n",
      "2021-08-25 11:21:41.239 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:41.241 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:41.242 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.15\n",
      "2021-08-25 11:21:41.243 | INFO     | src.policies:train:109 - Episode 1322\n",
      "2021-08-25 11:21:41.253 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:41.254 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:41.255 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.16\n",
      "2021-08-25 11:21:41.256 | INFO     | src.policies:train:109 - Episode 1323\n",
      "2021-08-25 11:21:41.265 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:41.267 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:41.268 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.08\n",
      "2021-08-25 11:21:41.269 | INFO     | src.policies:train:109 - Episode 1324\n",
      "2021-08-25 11:21:41.299 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:41.300 | INFO     | src.policies:train:121 - Mean episode return: 68.0\n",
      "2021-08-25 11:21:41.302 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.62\n",
      "2021-08-25 11:21:41.303 | WARNING  | src.policies:train:131 - The actual batch size is 254, instead of 200\n",
      "2021-08-25 11:21:41.311 | INFO     | src.policies:train:157 - Total loss: 1.0026764869689941\n",
      "2021-08-25 11:21:41.315 | INFO     | src.policies:train:103 - Epoch 171 / 800\n",
      "2021-08-25 11:21:41.316 | INFO     | src.policies:train:109 - Episode 1325\n",
      "2021-08-25 11:21:41.325 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:41.327 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:41.328 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.52\n",
      "2021-08-25 11:21:41.328 | INFO     | src.policies:train:109 - Episode 1326\n",
      "2021-08-25 11:21:41.341 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:41.342 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:21:41.343 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.56\n",
      "2021-08-25 11:21:41.344 | INFO     | src.policies:train:109 - Episode 1327\n",
      "2021-08-25 11:21:41.362 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:41.364 | INFO     | src.policies:train:121 - Mean episode return: 42.0\n",
      "2021-08-25 11:21:41.364 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.83\n",
      "2021-08-25 11:21:41.365 | INFO     | src.policies:train:109 - Episode 1328\n",
      "2021-08-25 11:21:41.381 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:41.383 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 11:21:41.384 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.4\n",
      "2021-08-25 11:21:41.385 | INFO     | src.policies:train:109 - Episode 1329\n",
      "2021-08-25 11:21:41.401 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:41.403 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 11:21:41.404 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.15\n",
      "2021-08-25 11:21:41.405 | INFO     | src.policies:train:109 - Episode 1330\n",
      "2021-08-25 11:21:41.446 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:41.447 | INFO     | src.policies:train:121 - Mean episode return: 100.0\n",
      "2021-08-25 11:21:41.448 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.9\n",
      "2021-08-25 11:21:41.449 | WARNING  | src.policies:train:131 - The actual batch size is 247, instead of 200\n",
      "2021-08-25 11:21:41.459 | INFO     | src.policies:train:157 - Total loss: 1.0026847124099731\n",
      "2021-08-25 11:21:41.462 | INFO     | src.policies:train:103 - Epoch 172 / 800\n",
      "2021-08-25 11:21:41.464 | INFO     | src.policies:train:109 - Episode 1331\n",
      "2021-08-25 11:21:41.473 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:41.475 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:41.476 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.8\n",
      "2021-08-25 11:21:41.477 | INFO     | src.policies:train:109 - Episode 1332\n",
      "2021-08-25 11:21:41.486 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:41.488 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:21:41.489 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.42\n",
      "2021-08-25 11:21:41.490 | INFO     | src.policies:train:109 - Episode 1333\n",
      "2021-08-25 11:21:41.518 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:41.520 | INFO     | src.policies:train:121 - Mean episode return: 60.0\n",
      "2021-08-25 11:21:41.521 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.76\n",
      "2021-08-25 11:21:41.522 | INFO     | src.policies:train:109 - Episode 1334\n",
      "2021-08-25 11:21:41.534 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:41.536 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:41.537 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.44\n",
      "2021-08-25 11:21:41.538 | INFO     | src.policies:train:109 - Episode 1335\n",
      "2021-08-25 11:21:41.550 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:41.552 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:21:41.553 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.49\n",
      "2021-08-25 11:21:41.554 | INFO     | src.policies:train:109 - Episode 1336\n",
      "2021-08-25 11:21:41.563 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:41.564 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:41.565 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.3\n",
      "2021-08-25 11:21:41.566 | INFO     | src.policies:train:109 - Episode 1337\n",
      "2021-08-25 11:21:41.579 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:41.580 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:21:41.581 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.02\n",
      "2021-08-25 11:21:41.582 | INFO     | src.policies:train:109 - Episode 1338\n",
      "2021-08-25 11:21:41.605 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:41.607 | INFO     | src.policies:train:121 - Mean episode return: 50.0\n",
      "2021-08-25 11:21:41.607 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.04\n",
      "2021-08-25 11:21:41.609 | WARNING  | src.policies:train:131 - The actual batch size is 212, instead of 200\n",
      "2021-08-25 11:21:41.618 | INFO     | src.policies:train:157 - Total loss: 1.0020602941513062\n",
      "2021-08-25 11:21:41.621 | INFO     | src.policies:train:103 - Epoch 173 / 800\n",
      "2021-08-25 11:21:41.622 | INFO     | src.policies:train:109 - Episode 1339\n",
      "2021-08-25 11:21:41.630 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:41.632 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:21:41.633 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.04\n",
      "2021-08-25 11:21:41.635 | INFO     | src.policies:train:109 - Episode 1340\n",
      "2021-08-25 11:21:41.644 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:41.645 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:41.646 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.87\n",
      "2021-08-25 11:21:41.647 | INFO     | src.policies:train:109 - Episode 1341\n",
      "2021-08-25 11:21:41.656 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:41.657 | INFO     | src.policies:train:121 - Mean episode return: 9.0\n",
      "2021-08-25 11:21:41.659 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.67\n",
      "2021-08-25 11:21:41.660 | INFO     | src.policies:train:109 - Episode 1342\n",
      "2021-08-25 11:21:41.681 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:41.682 | INFO     | src.policies:train:121 - Mean episode return: 43.0\n",
      "2021-08-25 11:21:41.683 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.86\n",
      "2021-08-25 11:21:41.684 | INFO     | src.policies:train:109 - Episode 1343\n",
      "2021-08-25 11:21:41.701 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:41.702 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 11:21:41.703 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.77\n",
      "2021-08-25 11:21:41.704 | INFO     | src.policies:train:109 - Episode 1344\n",
      "2021-08-25 11:21:41.715 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:41.716 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:41.717 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.72\n",
      "2021-08-25 11:21:41.718 | INFO     | src.policies:train:109 - Episode 1345\n",
      "2021-08-25 11:21:41.739 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:41.740 | INFO     | src.policies:train:121 - Mean episode return: 42.0\n",
      "2021-08-25 11:21:41.741 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.86\n",
      "2021-08-25 11:21:41.742 | INFO     | src.policies:train:109 - Episode 1346\n",
      "2021-08-25 11:21:41.755 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:41.756 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:21:41.757 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.74\n",
      "2021-08-25 11:21:41.758 | INFO     | src.policies:train:109 - Episode 1347\n",
      "2021-08-25 11:21:41.767 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:41.768 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:21:41.769 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.61\n",
      "2021-08-25 11:21:41.770 | INFO     | src.policies:train:109 - Episode 1348\n",
      "2021-08-25 11:21:41.784 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:41.786 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:21:41.787 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.58\n",
      "2021-08-25 11:21:41.787 | WARNING  | src.policies:train:131 - The actual batch size is 223, instead of 200\n",
      "2021-08-25 11:21:41.797 | INFO     | src.policies:train:157 - Total loss: 1.0021494626998901\n",
      "2021-08-25 11:21:41.800 | INFO     | src.policies:train:103 - Epoch 174 / 800\n",
      "2021-08-25 11:21:41.801 | INFO     | src.policies:train:109 - Episode 1349\n",
      "2021-08-25 11:21:41.815 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:41.816 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:21:41.817 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.68\n",
      "2021-08-25 11:21:41.818 | INFO     | src.policies:train:109 - Episode 1350\n",
      "2021-08-25 11:21:41.832 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:41.834 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:21:41.836 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.52\n",
      "2021-08-25 11:21:41.837 | INFO     | src.policies:train:109 - Episode 1351\n",
      "2021-08-25 11:21:41.850 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:41.851 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:21:41.853 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.61\n",
      "2021-08-25 11:21:41.854 | INFO     | src.policies:train:109 - Episode 1352\n",
      "2021-08-25 11:21:41.876 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:41.877 | INFO     | src.policies:train:121 - Mean episode return: 47.0\n",
      "2021-08-25 11:21:41.878 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.85\n",
      "2021-08-25 11:21:41.880 | INFO     | src.policies:train:109 - Episode 1353\n",
      "2021-08-25 11:21:41.896 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:41.897 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 11:21:41.899 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.82\n",
      "2021-08-25 11:21:41.899 | INFO     | src.policies:train:109 - Episode 1354\n",
      "2021-08-25 11:21:41.923 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:41.924 | INFO     | src.policies:train:121 - Mean episode return: 45.0\n",
      "2021-08-25 11:21:41.925 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.88\n",
      "2021-08-25 11:21:41.926 | INFO     | src.policies:train:109 - Episode 1355\n",
      "2021-08-25 11:21:41.936 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:41.937 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:41.938 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.0\n",
      "2021-08-25 11:21:41.939 | WARNING  | src.policies:train:131 - The actual batch size is 209, instead of 200\n",
      "2021-08-25 11:21:41.947 | INFO     | src.policies:train:157 - Total loss: 1.0018216371536255\n",
      "2021-08-25 11:21:41.950 | INFO     | src.policies:train:103 - Epoch 175 / 800\n",
      "2021-08-25 11:21:41.951 | INFO     | src.policies:train:109 - Episode 1356\n",
      "2021-08-25 11:21:41.971 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:41.973 | INFO     | src.policies:train:121 - Mean episode return: 43.0\n",
      "2021-08-25 11:21:41.974 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.98\n",
      "2021-08-25 11:21:41.975 | INFO     | src.policies:train:109 - Episode 1357\n",
      "2021-08-25 11:21:41.990 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:41.992 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 11:21:41.994 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.14\n",
      "2021-08-25 11:21:41.995 | INFO     | src.policies:train:109 - Episode 1358\n",
      "2021-08-25 11:21:42.010 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:42.011 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 11:21:42.012 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.11\n",
      "2021-08-25 11:21:42.014 | INFO     | src.policies:train:109 - Episode 1359\n",
      "2021-08-25 11:21:42.023 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:42.025 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:42.025 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.98\n",
      "2021-08-25 11:21:42.027 | INFO     | src.policies:train:109 - Episode 1360\n",
      "2021-08-25 11:21:42.047 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:42.048 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 11:21:42.049 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.19\n",
      "2021-08-25 11:21:42.050 | INFO     | src.policies:train:109 - Episode 1361\n",
      "2021-08-25 11:21:42.061 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:42.062 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:42.063 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.18\n",
      "2021-08-25 11:21:42.064 | INFO     | src.policies:train:109 - Episode 1362\n",
      "2021-08-25 11:21:42.084 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:42.085 | INFO     | src.policies:train:121 - Mean episode return: 42.0\n",
      "2021-08-25 11:21:42.086 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.41\n",
      "2021-08-25 11:21:42.087 | WARNING  | src.policies:train:131 - The actual batch size is 215, instead of 200\n",
      "2021-08-25 11:21:42.094 | INFO     | src.policies:train:157 - Total loss: 1.0021061897277832\n",
      "2021-08-25 11:21:42.097 | INFO     | src.policies:train:103 - Epoch 176 / 800\n",
      "2021-08-25 11:21:42.098 | INFO     | src.policies:train:109 - Episode 1363\n",
      "2021-08-25 11:21:42.106 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:42.107 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:42.108 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.37\n",
      "2021-08-25 11:21:42.109 | INFO     | src.policies:train:109 - Episode 1364\n",
      "2021-08-25 11:21:42.134 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:42.135 | INFO     | src.policies:train:121 - Mean episode return: 52.0\n",
      "2021-08-25 11:21:42.136 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.55\n",
      "2021-08-25 11:21:42.137 | INFO     | src.policies:train:109 - Episode 1365\n",
      "2021-08-25 11:21:42.161 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:42.162 | INFO     | src.policies:train:121 - Mean episode return: 52.0\n",
      "2021-08-25 11:21:42.163 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.61\n",
      "2021-08-25 11:21:42.164 | INFO     | src.policies:train:109 - Episode 1366\n",
      "2021-08-25 11:21:42.181 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:42.182 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 11:21:42.183 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.52\n",
      "2021-08-25 11:21:42.184 | INFO     | src.policies:train:109 - Episode 1367\n",
      "2021-08-25 11:21:42.195 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:42.196 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:21:42.197 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.5\n",
      "2021-08-25 11:21:42.198 | INFO     | src.policies:train:109 - Episode 1368\n",
      "2021-08-25 11:21:42.208 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:42.210 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:42.211 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.46\n",
      "2021-08-25 11:21:42.212 | INFO     | src.policies:train:109 - Episode 1369\n",
      "2021-08-25 11:21:42.227 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:42.229 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 11:21:42.229 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.48\n",
      "2021-08-25 11:21:42.231 | WARNING  | src.policies:train:131 - The actual batch size is 219, instead of 200\n",
      "2021-08-25 11:21:42.239 | INFO     | src.policies:train:157 - Total loss: 1.001937747001648\n",
      "2021-08-25 11:21:42.243 | INFO     | src.policies:train:103 - Epoch 177 / 800\n",
      "2021-08-25 11:21:42.244 | INFO     | src.policies:train:109 - Episode 1370\n",
      "2021-08-25 11:21:42.264 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:42.266 | INFO     | src.policies:train:121 - Mean episode return: 47.0\n",
      "2021-08-25 11:21:42.266 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.78\n",
      "2021-08-25 11:21:42.268 | INFO     | src.policies:train:109 - Episode 1371\n",
      "2021-08-25 11:21:42.281 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:42.282 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:21:42.283 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.89\n",
      "2021-08-25 11:21:42.284 | INFO     | src.policies:train:109 - Episode 1372\n",
      "2021-08-25 11:21:42.301 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:42.302 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 11:21:42.303 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.67\n",
      "2021-08-25 11:21:42.304 | INFO     | src.policies:train:109 - Episode 1373\n",
      "2021-08-25 11:21:42.313 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:42.314 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:21:42.315 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.32\n",
      "2021-08-25 11:21:42.316 | INFO     | src.policies:train:109 - Episode 1374\n",
      "2021-08-25 11:21:42.327 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:42.328 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:42.329 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.2\n",
      "2021-08-25 11:21:42.330 | INFO     | src.policies:train:109 - Episode 1375\n",
      "2021-08-25 11:21:42.343 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:42.344 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:21:42.345 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:42.346 | INFO     | src.policies:train:109 - Episode 1376\n",
      "2021-08-25 11:21:42.369 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:42.370 | INFO     | src.policies:train:121 - Mean episode return: 49.0\n",
      "2021-08-25 11:21:42.371 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.87\n",
      "2021-08-25 11:21:42.372 | WARNING  | src.policies:train:131 - The actual batch size is 201, instead of 200\n",
      "2021-08-25 11:21:42.379 | INFO     | src.policies:train:157 - Total loss: 1.001662015914917\n",
      "2021-08-25 11:21:42.382 | INFO     | src.policies:train:103 - Epoch 178 / 800\n",
      "2021-08-25 11:21:42.383 | INFO     | src.policies:train:109 - Episode 1377\n",
      "2021-08-25 11:21:42.391 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:42.393 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:42.394 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.67\n",
      "2021-08-25 11:21:42.395 | INFO     | src.policies:train:109 - Episode 1378\n",
      "2021-08-25 11:21:42.415 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:42.416 | INFO     | src.policies:train:121 - Mean episode return: 42.0\n",
      "2021-08-25 11:21:42.417 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.81\n",
      "2021-08-25 11:21:42.419 | INFO     | src.policies:train:109 - Episode 1379\n",
      "2021-08-25 11:21:42.427 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:42.428 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:21:42.429 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.4\n",
      "2021-08-25 11:21:42.430 | INFO     | src.policies:train:109 - Episode 1380\n",
      "2021-08-25 11:21:42.438 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:42.440 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:21:42.441 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.3\n",
      "2021-08-25 11:21:42.441 | INFO     | src.policies:train:109 - Episode 1381\n",
      "2021-08-25 11:21:42.465 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:42.466 | INFO     | src.policies:train:121 - Mean episode return: 54.0\n",
      "2021-08-25 11:21:42.467 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.55\n",
      "2021-08-25 11:21:42.468 | INFO     | src.policies:train:109 - Episode 1382\n",
      "2021-08-25 11:21:42.486 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:42.487 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 11:21:42.488 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.63\n",
      "2021-08-25 11:21:42.489 | INFO     | src.policies:train:109 - Episode 1383\n",
      "2021-08-25 11:21:42.506 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:42.507 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 11:21:42.508 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 29.81\n",
      "2021-08-25 11:21:42.509 | WARNING  | src.policies:train:131 - The actual batch size is 204, instead of 200\n",
      "2021-08-25 11:21:42.517 | INFO     | src.policies:train:157 - Total loss: 1.001877784729004\n",
      "2021-08-25 11:21:42.521 | INFO     | src.policies:train:103 - Epoch 179 / 800\n",
      "2021-08-25 11:21:42.522 | INFO     | src.policies:train:109 - Episode 1384\n",
      "2021-08-25 11:21:42.568 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:42.569 | INFO     | src.policies:train:121 - Mean episode return: 119.0\n",
      "2021-08-25 11:21:42.571 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.81\n",
      "2021-08-25 11:21:42.571 | INFO     | src.policies:train:109 - Episode 1385\n",
      "2021-08-25 11:21:42.590 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:42.591 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 11:21:42.592 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.05\n",
      "2021-08-25 11:21:42.593 | INFO     | src.policies:train:109 - Episode 1386\n",
      "2021-08-25 11:21:42.610 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:42.611 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 11:21:42.612 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.03\n",
      "2021-08-25 11:21:42.613 | INFO     | src.policies:train:109 - Episode 1387\n",
      "2021-08-25 11:21:42.622 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:42.623 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:21:42.624 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 30.97\n",
      "2021-08-25 11:21:42.625 | WARNING  | src.policies:train:131 - The actual batch size is 208, instead of 200\n",
      "2021-08-25 11:21:42.632 | INFO     | src.policies:train:157 - Total loss: 1.0019147396087646\n",
      "2021-08-25 11:21:42.635 | INFO     | src.policies:train:103 - Epoch 180 / 800\n",
      "2021-08-25 11:21:42.636 | INFO     | src.policies:train:109 - Episode 1388\n",
      "2021-08-25 11:21:42.651 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:42.653 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 11:21:42.653 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.2\n",
      "2021-08-25 11:21:42.655 | INFO     | src.policies:train:109 - Episode 1389\n",
      "2021-08-25 11:21:42.696 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:42.697 | INFO     | src.policies:train:121 - Mean episode return: 101.0\n",
      "2021-08-25 11:21:42.698 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.95\n",
      "2021-08-25 11:21:42.699 | INFO     | src.policies:train:109 - Episode 1390\n",
      "2021-08-25 11:21:42.719 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:42.720 | INFO     | src.policies:train:121 - Mean episode return: 41.0\n",
      "2021-08-25 11:21:42.721 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.07\n",
      "2021-08-25 11:21:42.722 | INFO     | src.policies:train:109 - Episode 1391\n",
      "2021-08-25 11:21:42.732 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:42.733 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:21:42.734 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.06\n",
      "2021-08-25 11:21:42.735 | INFO     | src.policies:train:109 - Episode 1392\n",
      "2021-08-25 11:21:42.752 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:42.753 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 11:21:42.754 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.09\n",
      "2021-08-25 11:21:42.755 | WARNING  | src.policies:train:131 - The actual batch size is 230, instead of 200\n",
      "2021-08-25 11:21:42.762 | INFO     | src.policies:train:157 - Total loss: 1.002305269241333\n",
      "2021-08-25 11:21:42.765 | INFO     | src.policies:train:103 - Epoch 181 / 800\n",
      "2021-08-25 11:21:42.767 | INFO     | src.policies:train:109 - Episode 1393\n",
      "2021-08-25 11:21:42.785 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:42.786 | INFO     | src.policies:train:121 - Mean episode return: 39.0\n",
      "2021-08-25 11:21:42.787 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.38\n",
      "2021-08-25 11:21:42.788 | INFO     | src.policies:train:109 - Episode 1394\n",
      "2021-08-25 11:21:42.803 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:42.804 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:21:42.805 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.28\n",
      "2021-08-25 11:21:42.806 | INFO     | src.policies:train:109 - Episode 1395\n",
      "2021-08-25 11:21:42.825 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:42.826 | INFO     | src.policies:train:121 - Mean episode return: 39.0\n",
      "2021-08-25 11:21:42.827 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.48\n",
      "2021-08-25 11:21:42.828 | INFO     | src.policies:train:109 - Episode 1396\n",
      "2021-08-25 11:21:42.842 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:42.843 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:21:42.844 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.57\n",
      "2021-08-25 11:21:42.845 | INFO     | src.policies:train:109 - Episode 1397\n",
      "2021-08-25 11:21:42.853 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:42.855 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:21:42.856 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.49\n",
      "2021-08-25 11:21:42.857 | INFO     | src.policies:train:109 - Episode 1398\n",
      "2021-08-25 11:21:42.874 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:42.875 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 11:21:42.877 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.55\n",
      "2021-08-25 11:21:42.878 | INFO     | src.policies:train:109 - Episode 1399\n",
      "2021-08-25 11:21:42.895 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:42.897 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 11:21:42.897 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.7\n",
      "2021-08-25 11:21:42.899 | WARNING  | src.policies:train:131 - The actual batch size is 214, instead of 200\n",
      "2021-08-25 11:21:42.906 | INFO     | src.policies:train:157 - Total loss: 1.0018943548202515\n",
      "2021-08-25 11:21:42.909 | INFO     | src.policies:train:103 - Epoch 182 / 800\n",
      "2021-08-25 11:21:42.911 | INFO     | src.policies:train:109 - Episode 1400\n",
      "2021-08-25 11:21:42.923 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:42.924 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:21:42.925 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 31.9\n",
      "2021-08-25 11:21:42.926 | INFO     | src.policies:train:109 - Episode 1401\n",
      "2021-08-25 11:21:42.969 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:42.970 | INFO     | src.policies:train:121 - Mean episode return: 101.0\n",
      "2021-08-25 11:21:42.972 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.65\n",
      "2021-08-25 11:21:42.972 | INFO     | src.policies:train:109 - Episode 1402\n",
      "2021-08-25 11:21:42.983 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:42.984 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:21:42.985 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.24\n",
      "2021-08-25 11:21:42.986 | INFO     | src.policies:train:109 - Episode 1403\n",
      "2021-08-25 11:21:43.023 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:43.025 | INFO     | src.policies:train:121 - Mean episode return: 90.0\n",
      "2021-08-25 11:21:43.025 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.6\n",
      "2021-08-25 11:21:43.026 | WARNING  | src.policies:train:131 - The actual batch size is 234, instead of 200\n",
      "2021-08-25 11:21:43.033 | INFO     | src.policies:train:157 - Total loss: 1.0024774074554443\n",
      "2021-08-25 11:21:43.037 | INFO     | src.policies:train:103 - Epoch 183 / 800\n",
      "2021-08-25 11:21:43.038 | INFO     | src.policies:train:109 - Episode 1404\n",
      "2021-08-25 11:21:43.060 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:43.061 | INFO     | src.policies:train:121 - Mean episode return: 48.0\n",
      "2021-08-25 11:21:43.062 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 32.61\n",
      "2021-08-25 11:21:43.063 | INFO     | src.policies:train:109 - Episode 1405\n",
      "2021-08-25 11:21:43.095 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:43.096 | INFO     | src.policies:train:121 - Mean episode return: 72.0\n",
      "2021-08-25 11:21:43.097 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.15\n",
      "2021-08-25 11:21:43.098 | INFO     | src.policies:train:109 - Episode 1406\n",
      "2021-08-25 11:21:43.133 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:43.135 | INFO     | src.policies:train:121 - Mean episode return: 85.0\n",
      "2021-08-25 11:21:43.135 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.74\n",
      "2021-08-25 11:21:43.137 | WARNING  | src.policies:train:131 - The actual batch size is 205, instead of 200\n",
      "2021-08-25 11:21:43.143 | INFO     | src.policies:train:157 - Total loss: 1.0016988515853882\n",
      "2021-08-25 11:21:43.145 | INFO     | src.policies:train:103 - Epoch 184 / 800\n",
      "2021-08-25 11:21:43.146 | INFO     | src.policies:train:109 - Episode 1407\n",
      "2021-08-25 11:21:43.159 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:43.161 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 11:21:43.162 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.64\n",
      "2021-08-25 11:21:43.163 | INFO     | src.policies:train:109 - Episode 1408\n",
      "2021-08-25 11:21:43.175 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:43.176 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:21:43.177 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.34\n",
      "2021-08-25 11:21:43.178 | INFO     | src.policies:train:109 - Episode 1409\n",
      "2021-08-25 11:21:43.193 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:43.195 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 11:21:43.195 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.42\n",
      "2021-08-25 11:21:43.196 | INFO     | src.policies:train:109 - Episode 1410\n",
      "2021-08-25 11:21:43.212 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:43.213 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 11:21:43.214 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.58\n",
      "2021-08-25 11:21:43.215 | INFO     | src.policies:train:109 - Episode 1411\n",
      "2021-08-25 11:21:43.225 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:43.227 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:43.227 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.46\n",
      "2021-08-25 11:21:43.228 | INFO     | src.policies:train:109 - Episode 1412\n",
      "2021-08-25 11:21:43.265 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:43.266 | INFO     | src.policies:train:121 - Mean episode return: 86.0\n",
      "2021-08-25 11:21:43.267 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.99\n",
      "2021-08-25 11:21:43.268 | WARNING  | src.policies:train:131 - The actual batch size is 204, instead of 200\n",
      "2021-08-25 11:21:43.275 | INFO     | src.policies:train:157 - Total loss: 1.0018198490142822\n",
      "2021-08-25 11:21:43.278 | INFO     | src.policies:train:103 - Epoch 185 / 800\n",
      "2021-08-25 11:21:43.279 | INFO     | src.policies:train:109 - Episode 1413\n",
      "2021-08-25 11:21:43.289 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:43.290 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:21:43.291 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.5\n",
      "2021-08-25 11:21:43.292 | INFO     | src.policies:train:109 - Episode 1414\n",
      "2021-08-25 11:21:43.303 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:43.305 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:21:43.306 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:43.307 | INFO     | src.policies:train:109 - Episode 1415\n",
      "2021-08-25 11:21:43.324 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:43.326 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 11:21:43.326 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.57\n",
      "2021-08-25 11:21:43.327 | INFO     | src.policies:train:109 - Episode 1416\n",
      "2021-08-25 11:21:43.337 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:43.338 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:43.339 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.58\n",
      "2021-08-25 11:21:43.340 | INFO     | src.policies:train:109 - Episode 1417\n",
      "2021-08-25 11:21:43.358 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:43.359 | INFO     | src.policies:train:121 - Mean episode return: 41.0\n",
      "2021-08-25 11:21:43.360 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.44\n",
      "2021-08-25 11:21:43.361 | INFO     | src.policies:train:109 - Episode 1418\n",
      "2021-08-25 11:21:43.376 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:43.378 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 11:21:43.379 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.62\n",
      "2021-08-25 11:21:43.380 | INFO     | src.policies:train:109 - Episode 1419\n",
      "2021-08-25 11:21:43.387 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:43.389 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:43.389 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.48\n",
      "2021-08-25 11:21:43.390 | INFO     | src.policies:train:109 - Episode 1420\n",
      "2021-08-25 11:21:43.403 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:43.404 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:21:43.405 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.34\n",
      "2021-08-25 11:21:43.406 | INFO     | src.policies:train:109 - Episode 1421\n",
      "2021-08-25 11:21:43.422 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:43.423 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 11:21:43.424 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.48\n",
      "2021-08-25 11:21:43.425 | WARNING  | src.policies:train:131 - The actual batch size is 228, instead of 200\n",
      "2021-08-25 11:21:43.433 | INFO     | src.policies:train:157 - Total loss: 1.0023410320281982\n",
      "2021-08-25 11:21:43.436 | INFO     | src.policies:train:103 - Epoch 186 / 800\n",
      "2021-08-25 11:21:43.437 | INFO     | src.policies:train:109 - Episode 1422\n",
      "2021-08-25 11:21:43.444 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:43.445 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:21:43.446 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 33.44\n",
      "2021-08-25 11:21:43.446 | INFO     | src.policies:train:109 - Episode 1423\n",
      "2021-08-25 11:21:43.491 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:43.492 | INFO     | src.policies:train:121 - Mean episode return: 110.0\n",
      "2021-08-25 11:21:43.493 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.42\n",
      "2021-08-25 11:21:43.494 | INFO     | src.policies:train:109 - Episode 1424\n",
      "2021-08-25 11:21:43.508 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:43.509 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:21:43.510 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.0\n",
      "2021-08-25 11:21:43.511 | INFO     | src.policies:train:109 - Episode 1425\n",
      "2021-08-25 11:21:43.537 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:43.539 | INFO     | src.policies:train:121 - Mean episode return: 60.0\n",
      "2021-08-25 11:21:43.540 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 34.44\n",
      "2021-08-25 11:21:43.541 | WARNING  | src.policies:train:131 - The actual batch size is 207, instead of 200\n",
      "2021-08-25 11:21:43.548 | INFO     | src.policies:train:157 - Total loss: 1.0016424655914307\n",
      "2021-08-25 11:21:43.551 | INFO     | src.policies:train:103 - Epoch 187 / 800\n",
      "2021-08-25 11:21:43.552 | INFO     | src.policies:train:109 - Episode 1426\n",
      "2021-08-25 11:21:43.592 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:43.594 | INFO     | src.policies:train:121 - Mean episode return: 97.0\n",
      "2021-08-25 11:21:43.595 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.2\n",
      "2021-08-25 11:21:43.596 | INFO     | src.policies:train:109 - Episode 1427\n",
      "2021-08-25 11:21:43.662 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:43.663 | INFO     | src.policies:train:121 - Mean episode return: 167.0\n",
      "2021-08-25 11:21:43.664 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.45\n",
      "2021-08-25 11:21:43.665 | WARNING  | src.policies:train:131 - The actual batch size is 264, instead of 200\n",
      "2021-08-25 11:21:43.672 | INFO     | src.policies:train:157 - Total loss: 1.00281822681427\n",
      "2021-08-25 11:21:43.675 | INFO     | src.policies:train:103 - Epoch 188 / 800\n",
      "2021-08-25 11:21:43.676 | INFO     | src.policies:train:109 - Episode 1428\n",
      "2021-08-25 11:21:43.686 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:43.687 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:21:43.688 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.31\n",
      "2021-08-25 11:21:43.689 | INFO     | src.policies:train:109 - Episode 1429\n",
      "2021-08-25 11:21:43.701 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:43.702 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:21:43.703 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.16\n",
      "2021-08-25 11:21:43.704 | INFO     | src.policies:train:109 - Episode 1430\n",
      "2021-08-25 11:21:43.718 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:43.719 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 11:21:43.720 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.43\n",
      "2021-08-25 11:21:43.721 | INFO     | src.policies:train:109 - Episode 1431\n",
      "2021-08-25 11:21:43.730 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:43.732 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:21:43.734 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.4\n",
      "2021-08-25 11:21:43.735 | INFO     | src.policies:train:109 - Episode 1432\n",
      "2021-08-25 11:21:43.749 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:43.751 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 11:21:43.752 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.52\n",
      "2021-08-25 11:21:43.754 | INFO     | src.policies:train:109 - Episode 1433\n",
      "2021-08-25 11:21:43.762 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:43.763 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:43.764 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.04\n",
      "2021-08-25 11:21:43.765 | INFO     | src.policies:train:109 - Episode 1434\n",
      "2021-08-25 11:21:43.805 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:43.807 | INFO     | src.policies:train:121 - Mean episode return: 98.0\n",
      "2021-08-25 11:21:43.807 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.82\n",
      "2021-08-25 11:21:43.808 | WARNING  | src.policies:train:131 - The actual batch size is 215, instead of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:43.815 | INFO     | src.policies:train:157 - Total loss: 1.0021885633468628\n",
      "2021-08-25 11:21:43.818 | INFO     | src.policies:train:103 - Epoch 189 / 800\n",
      "2021-08-25 11:21:43.819 | INFO     | src.policies:train:109 - Episode 1435\n",
      "2021-08-25 11:21:43.848 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:43.850 | INFO     | src.policies:train:121 - Mean episode return: 76.0\n",
      "2021-08-25 11:21:43.851 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.37\n",
      "2021-08-25 11:21:43.852 | INFO     | src.policies:train:109 - Episode 1436\n",
      "2021-08-25 11:21:43.866 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:43.867 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 11:21:43.868 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.52\n",
      "2021-08-25 11:21:43.869 | INFO     | src.policies:train:109 - Episode 1437\n",
      "2021-08-25 11:21:43.884 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:43.885 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:21:43.886 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.62\n",
      "2021-08-25 11:21:43.887 | INFO     | src.policies:train:109 - Episode 1438\n",
      "2021-08-25 11:21:43.897 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:43.898 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:43.899 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.27\n",
      "2021-08-25 11:21:43.900 | INFO     | src.policies:train:109 - Episode 1439\n",
      "2021-08-25 11:21:43.912 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:43.913 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:21:43.914 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.35\n",
      "2021-08-25 11:21:43.915 | INFO     | src.policies:train:109 - Episode 1440\n",
      "2021-08-25 11:21:43.928 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:43.929 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:21:43.930 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.46\n",
      "2021-08-25 11:21:43.931 | INFO     | src.policies:train:109 - Episode 1441\n",
      "2021-08-25 11:21:43.978 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:43.979 | INFO     | src.policies:train:121 - Mean episode return: 112.0\n",
      "2021-08-25 11:21:43.980 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.49\n",
      "2021-08-25 11:21:43.981 | WARNING  | src.policies:train:131 - The actual batch size is 304, instead of 200\n",
      "2021-08-25 11:21:43.988 | INFO     | src.policies:train:157 - Total loss: 1.0034054517745972\n",
      "2021-08-25 11:21:43.992 | INFO     | src.policies:train:103 - Epoch 190 / 800\n",
      "2021-08-25 11:21:43.993 | INFO     | src.policies:train:109 - Episode 1442\n",
      "2021-08-25 11:21:44.024 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:44.026 | INFO     | src.policies:train:121 - Mean episode return: 75.0\n",
      "2021-08-25 11:21:44.027 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.81\n",
      "2021-08-25 11:21:44.028 | INFO     | src.policies:train:109 - Episode 1443\n",
      "2021-08-25 11:21:44.045 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:44.046 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 11:21:44.047 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.85\n",
      "2021-08-25 11:21:44.048 | INFO     | src.policies:train:109 - Episode 1444\n",
      "2021-08-25 11:21:44.067 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:44.068 | INFO     | src.policies:train:121 - Mean episode return: 41.0\n",
      "2021-08-25 11:21:44.069 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.1\n",
      "2021-08-25 11:21:44.070 | INFO     | src.policies:train:109 - Episode 1445\n",
      "2021-08-25 11:21:44.099 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:44.101 | INFO     | src.policies:train:121 - Mean episode return: 63.0\n",
      "2021-08-25 11:21:44.102 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.31\n",
      "2021-08-25 11:21:44.103 | WARNING  | src.policies:train:131 - The actual batch size is 216, instead of 200\n",
      "2021-08-25 11:21:44.109 | INFO     | src.policies:train:157 - Total loss: 1.0020067691802979\n",
      "2021-08-25 11:21:44.113 | INFO     | src.policies:train:103 - Epoch 191 / 800\n",
      "2021-08-25 11:21:44.114 | INFO     | src.policies:train:109 - Episode 1446\n",
      "2021-08-25 11:21:44.124 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:44.126 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:21:44.127 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.32\n",
      "2021-08-25 11:21:44.128 | INFO     | src.policies:train:109 - Episode 1447\n",
      "2021-08-25 11:21:44.152 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:44.154 | INFO     | src.policies:train:121 - Mean episode return: 57.0\n",
      "2021-08-25 11:21:44.155 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.78\n",
      "2021-08-25 11:21:44.156 | INFO     | src.policies:train:109 - Episode 1448\n",
      "2021-08-25 11:21:44.177 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:44.178 | INFO     | src.policies:train:121 - Mean episode return: 48.0\n",
      "2021-08-25 11:21:44.179 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.02\n",
      "2021-08-25 11:21:44.181 | INFO     | src.policies:train:109 - Episode 1449\n",
      "2021-08-25 11:21:44.199 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:44.200 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 11:21:44.201 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.1\n",
      "2021-08-25 11:21:44.202 | INFO     | src.policies:train:109 - Episode 1450\n",
      "2021-08-25 11:21:44.211 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:44.212 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:21:44.213 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.0\n",
      "2021-08-25 11:21:44.214 | INFO     | src.policies:train:109 - Episode 1451\n",
      "2021-08-25 11:21:44.234 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:44.236 | INFO     | src.policies:train:121 - Mean episode return: 44.0\n",
      "2021-08-25 11:21:44.237 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.2\n",
      "2021-08-25 11:21:44.238 | WARNING  | src.policies:train:131 - The actual batch size is 219, instead of 200\n",
      "2021-08-25 11:21:44.248 | INFO     | src.policies:train:157 - Total loss: 1.0018450021743774\n",
      "2021-08-25 11:21:44.252 | INFO     | src.policies:train:103 - Epoch 192 / 800\n",
      "2021-08-25 11:21:44.254 | INFO     | src.policies:train:109 - Episode 1452\n",
      "2021-08-25 11:21:44.281 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:44.283 | INFO     | src.policies:train:121 - Mean episode return: 54.0\n",
      "2021-08-25 11:21:44.285 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.27\n",
      "2021-08-25 11:21:44.287 | INFO     | src.policies:train:109 - Episode 1453\n",
      "2021-08-25 11:21:44.299 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:44.300 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:21:44.302 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.12\n",
      "2021-08-25 11:21:44.303 | INFO     | src.policies:train:109 - Episode 1454\n",
      "2021-08-25 11:21:44.314 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:44.316 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:44.317 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.78\n",
      "2021-08-25 11:21:44.318 | INFO     | src.policies:train:109 - Episode 1455\n",
      "2021-08-25 11:21:44.341 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:44.343 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 11:21:44.344 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.96\n",
      "2021-08-25 11:21:44.345 | INFO     | src.policies:train:109 - Episode 1456\n",
      "2021-08-25 11:21:44.367 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:44.369 | INFO     | src.policies:train:121 - Mean episode return: 42.0\n",
      "2021-08-25 11:21:44.369 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.95\n",
      "2021-08-25 11:21:44.371 | INFO     | src.policies:train:109 - Episode 1457\n",
      "2021-08-25 11:21:44.390 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:44.391 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 11:21:44.392 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.04\n",
      "2021-08-25 11:21:44.393 | INFO     | src.policies:train:109 - Episode 1458\n",
      "2021-08-25 11:21:44.403 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:44.404 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:44.405 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.85\n",
      "2021-08-25 11:21:44.411 | INFO     | src.policies:train:157 - Total loss: 1.001733422279358\n",
      "2021-08-25 11:21:44.415 | INFO     | src.policies:train:103 - Epoch 193 / 800\n",
      "2021-08-25 11:21:44.416 | INFO     | src.policies:train:109 - Episode 1459\n",
      "2021-08-25 11:21:44.426 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:44.427 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:21:44.428 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.89\n",
      "2021-08-25 11:21:44.429 | INFO     | src.policies:train:109 - Episode 1460\n",
      "2021-08-25 11:21:44.446 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:44.447 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 11:21:44.448 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.82\n",
      "2021-08-25 11:21:44.449 | INFO     | src.policies:train:109 - Episode 1461\n",
      "2021-08-25 11:21:44.461 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:44.462 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:21:44.463 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.85\n",
      "2021-08-25 11:21:44.464 | INFO     | src.policies:train:109 - Episode 1462\n",
      "2021-08-25 11:21:44.477 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:44.478 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:21:44.479 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.67\n",
      "2021-08-25 11:21:44.480 | INFO     | src.policies:train:109 - Episode 1463\n",
      "2021-08-25 11:21:44.489 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:44.490 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:44.491 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.63\n",
      "2021-08-25 11:21:44.492 | INFO     | src.policies:train:109 - Episode 1464\n",
      "2021-08-25 11:21:44.517 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:44.519 | INFO     | src.policies:train:121 - Mean episode return: 55.0\n",
      "2021-08-25 11:21:44.521 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.66\n",
      "2021-08-25 11:21:44.522 | INFO     | src.policies:train:109 - Episode 1465\n",
      "2021-08-25 11:21:44.530 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:44.532 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:44.534 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.29\n",
      "2021-08-25 11:21:44.535 | INFO     | src.policies:train:109 - Episode 1466\n",
      "2021-08-25 11:21:44.545 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:44.546 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:21:44.547 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.09\n",
      "2021-08-25 11:21:44.548 | INFO     | src.policies:train:109 - Episode 1467\n",
      "2021-08-25 11:21:44.557 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:44.558 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:44.559 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.02\n",
      "2021-08-25 11:21:44.560 | WARNING  | src.policies:train:131 - The actual batch size is 202, instead of 200\n",
      "2021-08-25 11:21:44.567 | INFO     | src.policies:train:157 - Total loss: 1.0016355514526367\n",
      "2021-08-25 11:21:44.571 | INFO     | src.policies:train:103 - Epoch 194 / 800\n",
      "2021-08-25 11:21:44.572 | INFO     | src.policies:train:109 - Episode 1468\n",
      "2021-08-25 11:21:44.587 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:44.589 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 11:21:44.590 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.19\n",
      "2021-08-25 11:21:44.590 | INFO     | src.policies:train:109 - Episode 1469\n",
      "2021-08-25 11:21:44.600 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:44.601 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:44.602 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.03\n",
      "2021-08-25 11:21:44.603 | INFO     | src.policies:train:109 - Episode 1470\n",
      "2021-08-25 11:21:44.631 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:44.632 | INFO     | src.policies:train:121 - Mean episode return: 63.0\n",
      "2021-08-25 11:21:44.633 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.19\n",
      "2021-08-25 11:21:44.634 | INFO     | src.policies:train:109 - Episode 1471\n",
      "2021-08-25 11:21:44.678 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:44.680 | INFO     | src.policies:train:121 - Mean episode return: 113.0\n",
      "2021-08-25 11:21:44.680 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.09\n",
      "2021-08-25 11:21:44.681 | WARNING  | src.policies:train:131 - The actual batch size is 224, instead of 200\n",
      "2021-08-25 11:21:44.687 | INFO     | src.policies:train:157 - Total loss: 1.0022952556610107\n",
      "2021-08-25 11:21:44.691 | INFO     | src.policies:train:103 - Epoch 195 / 800\n",
      "2021-08-25 11:21:44.693 | INFO     | src.policies:train:109 - Episode 1472\n",
      "2021-08-25 11:21:44.706 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:44.707 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:21:44.708 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.05\n",
      "2021-08-25 11:21:44.709 | INFO     | src.policies:train:109 - Episode 1473\n",
      "2021-08-25 11:21:44.717 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:44.718 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:21:44.719 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.02\n",
      "2021-08-25 11:21:44.720 | INFO     | src.policies:train:109 - Episode 1474\n",
      "2021-08-25 11:21:44.731 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:44.732 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:44.733 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.03\n",
      "2021-08-25 11:21:44.734 | INFO     | src.policies:train:109 - Episode 1475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:44.742 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:44.743 | INFO     | src.policies:train:121 - Mean episode return: 10.0\n",
      "2021-08-25 11:21:44.744 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.94\n",
      "2021-08-25 11:21:44.745 | INFO     | src.policies:train:109 - Episode 1476\n",
      "2021-08-25 11:21:44.753 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:44.755 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:21:44.756 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.59\n",
      "2021-08-25 11:21:44.757 | INFO     | src.policies:train:109 - Episode 1477\n",
      "2021-08-25 11:21:44.770 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:44.771 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:21:44.772 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.67\n",
      "2021-08-25 11:21:44.773 | INFO     | src.policies:train:109 - Episode 1478\n",
      "2021-08-25 11:21:44.787 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:44.788 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 11:21:44.789 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.52\n",
      "2021-08-25 11:21:44.790 | INFO     | src.policies:train:109 - Episode 1479\n",
      "2021-08-25 11:21:44.813 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:44.814 | INFO     | src.policies:train:121 - Mean episode return: 48.0\n",
      "2021-08-25 11:21:44.815 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.89\n",
      "2021-08-25 11:21:44.816 | INFO     | src.policies:train:109 - Episode 1480\n",
      "2021-08-25 11:21:44.825 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:44.826 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:21:44.827 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.91\n",
      "2021-08-25 11:21:44.828 | INFO     | src.policies:train:109 - Episode 1481\n",
      "2021-08-25 11:21:44.844 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:44.845 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:21:44.846 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.66\n",
      "2021-08-25 11:21:44.847 | WARNING  | src.policies:train:131 - The actual batch size is 221, instead of 200\n",
      "2021-08-25 11:21:44.856 | INFO     | src.policies:train:157 - Total loss: 1.0021545886993408\n",
      "2021-08-25 11:21:44.861 | INFO     | src.policies:train:103 - Epoch 196 / 800\n",
      "2021-08-25 11:21:44.862 | INFO     | src.policies:train:109 - Episode 1482\n",
      "2021-08-25 11:21:44.878 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:44.880 | INFO     | src.policies:train:121 - Mean episode return: 38.0\n",
      "2021-08-25 11:21:44.881 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.68\n",
      "2021-08-25 11:21:44.881 | INFO     | src.policies:train:109 - Episode 1483\n",
      "2021-08-25 11:21:44.900 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:44.901 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 11:21:44.902 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.7\n",
      "2021-08-25 11:21:44.903 | INFO     | src.policies:train:109 - Episode 1484\n",
      "2021-08-25 11:21:44.913 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:44.914 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:21:44.915 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.64\n",
      "2021-08-25 11:21:44.916 | INFO     | src.policies:train:109 - Episode 1485\n",
      "2021-08-25 11:21:44.928 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:44.929 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:21:44.930 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.43\n",
      "2021-08-25 11:21:44.931 | INFO     | src.policies:train:109 - Episode 1486\n",
      "2021-08-25 11:21:44.945 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:44.946 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 11:21:44.947 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.33\n",
      "2021-08-25 11:21:44.948 | INFO     | src.policies:train:109 - Episode 1487\n",
      "2021-08-25 11:21:44.987 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:44.988 | INFO     | src.policies:train:121 - Mean episode return: 90.0\n",
      "2021-08-25 11:21:44.989 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.09\n",
      "2021-08-25 11:21:44.990 | WARNING  | src.policies:train:131 - The actual batch size is 222, instead of 200\n",
      "2021-08-25 11:21:44.998 | INFO     | src.policies:train:157 - Total loss: 1.00216543674469\n",
      "2021-08-25 11:21:45.002 | INFO     | src.policies:train:103 - Epoch 197 / 800\n",
      "2021-08-25 11:21:45.003 | INFO     | src.policies:train:109 - Episode 1488\n",
      "2021-08-25 11:21:45.027 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:45.028 | INFO     | src.policies:train:121 - Mean episode return: 58.0\n",
      "2021-08-25 11:21:45.029 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.33\n",
      "2021-08-25 11:21:45.030 | INFO     | src.policies:train:109 - Episode 1489\n",
      "2021-08-25 11:21:45.057 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:45.058 | INFO     | src.policies:train:121 - Mean episode return: 57.0\n",
      "2021-08-25 11:21:45.059 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.89\n",
      "2021-08-25 11:21:45.060 | INFO     | src.policies:train:109 - Episode 1490\n",
      "2021-08-25 11:21:45.068 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:45.070 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:21:45.070 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.61\n",
      "2021-08-25 11:21:45.072 | INFO     | src.policies:train:109 - Episode 1491\n",
      "2021-08-25 11:21:45.086 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:45.087 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:21:45.088 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.68\n",
      "2021-08-25 11:21:45.089 | INFO     | src.policies:train:109 - Episode 1492\n",
      "2021-08-25 11:21:45.111 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:45.112 | INFO     | src.policies:train:121 - Mean episode return: 49.0\n",
      "2021-08-25 11:21:45.113 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.82\n",
      "2021-08-25 11:21:45.114 | WARNING  | src.policies:train:131 - The actual batch size is 203, instead of 200\n",
      "2021-08-25 11:21:45.122 | INFO     | src.policies:train:157 - Total loss: 1.0017956495285034\n",
      "2021-08-25 11:21:45.125 | INFO     | src.policies:train:103 - Epoch 198 / 800\n",
      "2021-08-25 11:21:45.126 | INFO     | src.policies:train:109 - Episode 1493\n",
      "2021-08-25 11:21:45.133 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:45.134 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:45.135 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.55\n",
      "2021-08-25 11:21:45.136 | INFO     | src.policies:train:109 - Episode 1494\n",
      "2021-08-25 11:21:45.147 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:45.149 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:21:45.150 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.44\n",
      "2021-08-25 11:21:45.151 | INFO     | src.policies:train:109 - Episode 1495\n",
      "2021-08-25 11:21:45.160 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:45.161 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:21:45.162 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.19\n",
      "2021-08-25 11:21:45.163 | INFO     | src.policies:train:109 - Episode 1496\n",
      "2021-08-25 11:21:45.197 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:45.199 | INFO     | src.policies:train:121 - Mean episode return: 85.0\n",
      "2021-08-25 11:21:45.200 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.8\n",
      "2021-08-25 11:21:45.200 | INFO     | src.policies:train:109 - Episode 1497\n",
      "2021-08-25 11:21:45.224 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:45.225 | INFO     | src.policies:train:121 - Mean episode return: 55.0\n",
      "2021-08-25 11:21:45.226 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.24\n",
      "2021-08-25 11:21:45.227 | INFO     | src.policies:train:109 - Episode 1498\n",
      "2021-08-25 11:21:45.238 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:45.239 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:21:45.240 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.07\n",
      "2021-08-25 11:21:45.241 | WARNING  | src.policies:train:131 - The actual batch size is 203, instead of 200\n",
      "2021-08-25 11:21:45.248 | INFO     | src.policies:train:157 - Total loss: 1.0016257762908936\n",
      "2021-08-25 11:21:45.251 | INFO     | src.policies:train:103 - Epoch 199 / 800\n",
      "2021-08-25 11:21:45.252 | INFO     | src.policies:train:109 - Episode 1499\n",
      "2021-08-25 11:21:45.279 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:45.280 | INFO     | src.policies:train:121 - Mean episode return: 63.0\n",
      "2021-08-25 11:21:45.281 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.34\n",
      "2021-08-25 11:21:45.282 | INFO     | src.policies:train:109 - Episode 1500\n",
      "2021-08-25 11:21:45.291 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:45.292 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:21:45.293 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.24\n",
      "2021-08-25 11:21:45.294 | INFO     | src.policies:train:109 - Episode 1501\n",
      "2021-08-25 11:21:45.315 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:45.316 | INFO     | src.policies:train:121 - Mean episode return: 47.0\n",
      "2021-08-25 11:21:45.317 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.7\n",
      "2021-08-25 11:21:45.318 | INFO     | src.policies:train:109 - Episode 1502\n",
      "2021-08-25 11:21:45.340 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:45.341 | INFO     | src.policies:train:121 - Mean episode return: 44.0\n",
      "2021-08-25 11:21:45.342 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.95\n",
      "2021-08-25 11:21:45.343 | INFO     | src.policies:train:109 - Episode 1503\n",
      "2021-08-25 11:21:45.371 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:45.372 | INFO     | src.policies:train:121 - Mean episode return: 66.0\n",
      "2021-08-25 11:21:45.373 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.71\n",
      "2021-08-25 11:21:45.374 | WARNING  | src.policies:train:131 - The actual batch size is 234, instead of 200\n",
      "2021-08-25 11:21:45.381 | INFO     | src.policies:train:157 - Total loss: 1.0022629499435425\n",
      "2021-08-25 11:21:45.384 | INFO     | src.policies:train:103 - Epoch 200 / 800\n",
      "2021-08-25 11:21:45.386 | INFO     | src.policies:train:109 - Episode 1504\n",
      "2021-08-25 11:21:45.402 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:45.404 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 11:21:45.404 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.6\n",
      "2021-08-25 11:21:45.405 | INFO     | src.policies:train:109 - Episode 1505\n",
      "2021-08-25 11:21:45.435 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:45.436 | INFO     | src.policies:train:121 - Mean episode return: 70.0\n",
      "2021-08-25 11:21:45.437 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.58\n",
      "2021-08-25 11:21:45.438 | INFO     | src.policies:train:109 - Episode 1506\n",
      "2021-08-25 11:21:45.453 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:45.455 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:21:45.456 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.02\n",
      "2021-08-25 11:21:45.457 | INFO     | src.policies:train:109 - Episode 1507\n",
      "2021-08-25 11:21:45.477 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:45.478 | INFO     | src.policies:train:121 - Mean episode return: 43.0\n",
      "2021-08-25 11:21:45.479 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.18\n",
      "2021-08-25 11:21:45.480 | INFO     | src.policies:train:109 - Episode 1508\n",
      "2021-08-25 11:21:45.500 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:45.502 | INFO     | src.policies:train:121 - Mean episode return: 44.0\n",
      "2021-08-25 11:21:45.503 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.44\n",
      "2021-08-25 11:21:45.504 | WARNING  | src.policies:train:131 - The actual batch size is 223, instead of 200\n",
      "2021-08-25 11:21:45.511 | INFO     | src.policies:train:157 - Total loss: 1.0019932985305786\n",
      "2021-08-25 11:21:45.514 | INFO     | src.policies:train:103 - Epoch 201 / 800\n",
      "2021-08-25 11:21:45.515 | INFO     | src.policies:train:109 - Episode 1509\n",
      "2021-08-25 11:21:45.526 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:45.528 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:21:45.528 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.4\n",
      "2021-08-25 11:21:45.530 | INFO     | src.policies:train:109 - Episode 1510\n",
      "2021-08-25 11:21:45.545 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:45.546 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 11:21:45.547 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.41\n",
      "2021-08-25 11:21:45.548 | INFO     | src.policies:train:109 - Episode 1511\n",
      "2021-08-25 11:21:45.556 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:45.557 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:21:45.558 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.39\n",
      "2021-08-25 11:21:45.559 | INFO     | src.policies:train:109 - Episode 1512\n",
      "2021-08-25 11:21:45.585 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:45.586 | INFO     | src.policies:train:121 - Mean episode return: 57.0\n",
      "2021-08-25 11:21:45.587 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.1\n",
      "2021-08-25 11:21:45.588 | INFO     | src.policies:train:109 - Episode 1513\n",
      "2021-08-25 11:21:45.596 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:45.597 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:21:45.598 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.03\n",
      "2021-08-25 11:21:45.599 | INFO     | src.policies:train:109 - Episode 1514\n",
      "2021-08-25 11:21:45.609 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:45.610 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:21:45.611 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.96\n",
      "2021-08-25 11:21:45.612 | INFO     | src.policies:train:109 - Episode 1515\n",
      "2021-08-25 11:21:45.628 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:45.630 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:45.631 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.92\n",
      "2021-08-25 11:21:45.631 | INFO     | src.policies:train:109 - Episode 1516\n",
      "2021-08-25 11:21:45.669 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:45.670 | INFO     | src.policies:train:121 - Mean episode return: 92.0\n",
      "2021-08-25 11:21:45.671 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.72\n",
      "2021-08-25 11:21:45.672 | WARNING  | src.policies:train:131 - The actual batch size is 277, instead of 200\n",
      "2021-08-25 11:21:45.680 | INFO     | src.policies:train:157 - Total loss: 1.0029674768447876\n",
      "2021-08-25 11:21:45.684 | INFO     | src.policies:train:103 - Epoch 202 / 800\n",
      "2021-08-25 11:21:45.685 | INFO     | src.policies:train:109 - Episode 1517\n",
      "2021-08-25 11:21:45.698 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:45.699 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 11:21:45.700 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.61\n",
      "2021-08-25 11:21:45.701 | INFO     | src.policies:train:109 - Episode 1518\n",
      "2021-08-25 11:21:45.715 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:45.716 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 11:21:45.717 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.56\n",
      "2021-08-25 11:21:45.718 | INFO     | src.policies:train:109 - Episode 1519\n",
      "2021-08-25 11:21:45.735 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:45.737 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 11:21:45.738 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.8\n",
      "2021-08-25 11:21:45.739 | INFO     | src.policies:train:109 - Episode 1520\n",
      "2021-08-25 11:21:45.754 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:45.755 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 11:21:45.756 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.89\n",
      "2021-08-25 11:21:45.757 | INFO     | src.policies:train:109 - Episode 1521\n",
      "2021-08-25 11:21:45.777 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:45.778 | INFO     | src.policies:train:121 - Mean episode return: 46.0\n",
      "2021-08-25 11:21:45.779 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.05\n",
      "2021-08-25 11:21:45.780 | INFO     | src.policies:train:109 - Episode 1522\n",
      "2021-08-25 11:21:45.819 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:45.821 | INFO     | src.policies:train:121 - Mean episode return: 95.0\n",
      "2021-08-25 11:21:45.822 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.89\n",
      "2021-08-25 11:21:45.823 | WARNING  | src.policies:train:131 - The actual batch size is 266, instead of 200\n",
      "2021-08-25 11:21:45.830 | INFO     | src.policies:train:157 - Total loss: 1.0029098987579346\n",
      "2021-08-25 11:21:45.833 | INFO     | src.policies:train:103 - Epoch 203 / 800\n",
      "2021-08-25 11:21:45.834 | INFO     | src.policies:train:109 - Episode 1523\n",
      "2021-08-25 11:21:45.856 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:45.857 | INFO     | src.policies:train:121 - Mean episode return: 52.0\n",
      "2021-08-25 11:21:45.859 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.31\n",
      "2021-08-25 11:21:45.859 | INFO     | src.policies:train:109 - Episode 1524\n",
      "2021-08-25 11:21:45.868 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:45.869 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:21:45.870 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.18\n",
      "2021-08-25 11:21:45.871 | INFO     | src.policies:train:109 - Episode 1525\n",
      "2021-08-25 11:21:45.891 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:45.892 | INFO     | src.policies:train:121 - Mean episode return: 42.0\n",
      "2021-08-25 11:21:45.893 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.0\n",
      "2021-08-25 11:21:45.894 | INFO     | src.policies:train:109 - Episode 1526\n",
      "2021-08-25 11:21:45.907 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:45.908 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:21:45.909 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.26\n",
      "2021-08-25 11:21:45.910 | INFO     | src.policies:train:109 - Episode 1527\n",
      "2021-08-25 11:21:45.923 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:45.924 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:21:45.926 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.81\n",
      "2021-08-25 11:21:45.926 | INFO     | src.policies:train:109 - Episode 1528\n",
      "2021-08-25 11:21:45.968 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:45.969 | INFO     | src.policies:train:121 - Mean episode return: 100.0\n",
      "2021-08-25 11:21:45.970 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.61\n",
      "2021-08-25 11:21:45.971 | WARNING  | src.policies:train:131 - The actual batch size is 252, instead of 200\n",
      "2021-08-25 11:21:45.978 | INFO     | src.policies:train:157 - Total loss: 1.0026575326919556\n",
      "2021-08-25 11:21:45.982 | INFO     | src.policies:train:103 - Epoch 204 / 800\n",
      "2021-08-25 11:21:45.983 | INFO     | src.policies:train:109 - Episode 1529\n",
      "2021-08-25 11:21:45.995 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:45.997 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 11:21:45.998 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.69\n",
      "2021-08-25 11:21:45.999 | INFO     | src.policies:train:109 - Episode 1530\n",
      "2021-08-25 11:21:46.010 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:46.011 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:46.012 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.59\n",
      "2021-08-25 11:21:46.013 | INFO     | src.policies:train:109 - Episode 1531\n",
      "2021-08-25 11:21:46.031 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:46.032 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 11:21:46.033 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.82\n",
      "2021-08-25 11:21:46.034 | INFO     | src.policies:train:109 - Episode 1532\n",
      "2021-08-25 11:21:46.044 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:46.045 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:46.046 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.72\n",
      "2021-08-25 11:21:46.047 | INFO     | src.policies:train:109 - Episode 1533\n",
      "2021-08-25 11:21:46.073 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:46.074 | INFO     | src.policies:train:121 - Mean episode return: 56.0\n",
      "2021-08-25 11:21:46.075 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.16\n",
      "2021-08-25 11:21:46.076 | INFO     | src.policies:train:109 - Episode 1534\n",
      "2021-08-25 11:21:46.093 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:46.095 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 11:21:46.095 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.55\n",
      "2021-08-25 11:21:46.096 | INFO     | src.policies:train:109 - Episode 1535\n",
      "2021-08-25 11:21:46.139 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:46.140 | INFO     | src.policies:train:121 - Mean episode return: 99.0\n",
      "2021-08-25 11:21:46.141 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:46.142 | WARNING  | src.policies:train:131 - The actual batch size is 288, instead of 200\n",
      "2021-08-25 11:21:46.149 | INFO     | src.policies:train:157 - Total loss: 1.0030380487442017\n",
      "2021-08-25 11:21:46.153 | INFO     | src.policies:train:103 - Epoch 205 / 800\n",
      "2021-08-25 11:21:46.154 | INFO     | src.policies:train:109 - Episode 1536\n",
      "2021-08-25 11:21:46.170 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:46.173 | INFO     | src.policies:train:121 - Mean episode return: 38.0\n",
      "2021-08-25 11:21:46.174 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.89\n",
      "2021-08-25 11:21:46.175 | INFO     | src.policies:train:109 - Episode 1537\n",
      "2021-08-25 11:21:46.206 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:46.208 | INFO     | src.policies:train:121 - Mean episode return: 73.0\n",
      "2021-08-25 11:21:46.209 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.33\n",
      "2021-08-25 11:21:46.209 | INFO     | src.policies:train:109 - Episode 1538\n",
      "2021-08-25 11:21:46.224 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:46.225 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 11:21:46.226 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.46\n",
      "2021-08-25 11:21:46.227 | INFO     | src.policies:train:109 - Episode 1539\n",
      "2021-08-25 11:21:46.242 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:46.243 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:21:46.244 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.5\n",
      "2021-08-25 11:21:46.245 | INFO     | src.policies:train:109 - Episode 1540\n",
      "2021-08-25 11:21:46.260 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:46.261 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 11:21:46.262 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.58\n",
      "2021-08-25 11:21:46.263 | INFO     | src.policies:train:109 - Episode 1541\n",
      "2021-08-25 11:21:46.289 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:46.291 | INFO     | src.policies:train:121 - Mean episode return: 61.0\n",
      "2021-08-25 11:21:46.292 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.07\n",
      "2021-08-25 11:21:46.293 | WARNING  | src.policies:train:131 - The actual batch size is 257, instead of 200\n",
      "2021-08-25 11:21:46.301 | INFO     | src.policies:train:157 - Total loss: 1.002632975578308\n",
      "2021-08-25 11:21:46.304 | INFO     | src.policies:train:103 - Epoch 206 / 800\n",
      "2021-08-25 11:21:46.305 | INFO     | src.policies:train:109 - Episode 1542\n",
      "2021-08-25 11:21:46.312 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:46.313 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:46.314 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.44\n",
      "2021-08-25 11:21:46.315 | INFO     | src.policies:train:109 - Episode 1543\n",
      "2021-08-25 11:21:46.338 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:46.339 | INFO     | src.policies:train:121 - Mean episode return: 49.0\n",
      "2021-08-25 11:21:46.340 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.56\n",
      "2021-08-25 11:21:46.341 | INFO     | src.policies:train:109 - Episode 1544\n",
      "2021-08-25 11:21:46.361 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:46.362 | INFO     | src.policies:train:121 - Mean episode return: 43.0\n",
      "2021-08-25 11:21:46.363 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.58\n",
      "2021-08-25 11:21:46.364 | INFO     | src.policies:train:109 - Episode 1545\n",
      "2021-08-25 11:21:46.372 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:46.373 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:46.374 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.07\n",
      "2021-08-25 11:21:46.375 | INFO     | src.policies:train:109 - Episode 1546\n",
      "2021-08-25 11:21:46.395 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:46.396 | INFO     | src.policies:train:121 - Mean episode return: 45.0\n",
      "2021-08-25 11:21:46.397 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.32\n",
      "2021-08-25 11:21:46.398 | INFO     | src.policies:train:109 - Episode 1547\n",
      "2021-08-25 11:21:46.409 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:46.410 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:46.411 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.92\n",
      "2021-08-25 11:21:46.412 | INFO     | src.policies:train:109 - Episode 1548\n",
      "2021-08-25 11:21:46.423 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:46.424 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:21:46.425 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.62\n",
      "2021-08-25 11:21:46.426 | INFO     | src.policies:train:109 - Episode 1549\n",
      "2021-08-25 11:21:46.438 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:46.439 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:21:46.440 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.48\n",
      "2021-08-25 11:21:46.441 | WARNING  | src.policies:train:131 - The actual batch size is 219, instead of 200\n",
      "2021-08-25 11:21:46.448 | INFO     | src.policies:train:157 - Total loss: 1.0022190809249878\n",
      "2021-08-25 11:21:46.451 | INFO     | src.policies:train:103 - Epoch 207 / 800\n",
      "2021-08-25 11:21:46.452 | INFO     | src.policies:train:109 - Episode 1550\n",
      "2021-08-25 11:21:46.472 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:46.473 | INFO     | src.policies:train:121 - Mean episode return: 43.0\n",
      "2021-08-25 11:21:46.474 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.78\n",
      "2021-08-25 11:21:46.475 | INFO     | src.policies:train:109 - Episode 1551\n",
      "2021-08-25 11:21:46.498 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:46.499 | INFO     | src.policies:train:121 - Mean episode return: 50.0\n",
      "2021-08-25 11:21:46.500 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.84\n",
      "2021-08-25 11:21:46.501 | INFO     | src.policies:train:109 - Episode 1552\n",
      "2021-08-25 11:21:46.512 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:46.513 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:21:46.514 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.51\n",
      "2021-08-25 11:21:46.515 | INFO     | src.policies:train:109 - Episode 1553\n",
      "2021-08-25 11:21:46.525 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:46.526 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:21:46.527 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.56\n",
      "2021-08-25 11:21:46.528 | INFO     | src.policies:train:109 - Episode 1554\n",
      "2021-08-25 11:21:46.555 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:46.556 | INFO     | src.policies:train:121 - Mean episode return: 59.0\n",
      "2021-08-25 11:21:46.557 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.04\n",
      "2021-08-25 11:21:46.557 | INFO     | src.policies:train:109 - Episode 1555\n",
      "2021-08-25 11:21:46.570 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:46.571 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:21:46.572 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.92\n",
      "2021-08-25 11:21:46.573 | WARNING  | src.policies:train:131 - The actual batch size is 210, instead of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:46.580 | INFO     | src.policies:train:157 - Total loss: 1.0018982887268066\n",
      "2021-08-25 11:21:46.584 | INFO     | src.policies:train:103 - Epoch 208 / 800\n",
      "2021-08-25 11:21:46.585 | INFO     | src.policies:train:109 - Episode 1556\n",
      "2021-08-25 11:21:46.592 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:46.593 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:21:46.594 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.64\n",
      "2021-08-25 11:21:46.595 | INFO     | src.policies:train:109 - Episode 1557\n",
      "2021-08-25 11:21:46.602 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:46.603 | INFO     | src.policies:train:121 - Mean episode return: 9.0\n",
      "2021-08-25 11:21:46.604 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.36\n",
      "2021-08-25 11:21:46.605 | INFO     | src.policies:train:109 - Episode 1558\n",
      "2021-08-25 11:21:46.619 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:46.620 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 11:21:46.621 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.52\n",
      "2021-08-25 11:21:46.622 | INFO     | src.policies:train:109 - Episode 1559\n",
      "2021-08-25 11:21:46.630 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:46.631 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:46.632 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.45\n",
      "2021-08-25 11:21:46.633 | INFO     | src.policies:train:109 - Episode 1560\n",
      "2021-08-25 11:21:46.647 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:46.649 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 11:21:46.650 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.39\n",
      "2021-08-25 11:21:46.651 | INFO     | src.policies:train:109 - Episode 1561\n",
      "2021-08-25 11:21:46.671 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:46.672 | INFO     | src.policies:train:121 - Mean episode return: 43.0\n",
      "2021-08-25 11:21:46.673 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.63\n",
      "2021-08-25 11:21:46.674 | INFO     | src.policies:train:109 - Episode 1562\n",
      "2021-08-25 11:21:46.697 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:46.699 | INFO     | src.policies:train:121 - Mean episode return: 51.0\n",
      "2021-08-25 11:21:46.700 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.9\n",
      "2021-08-25 11:21:46.701 | INFO     | src.policies:train:109 - Episode 1563\n",
      "2021-08-25 11:21:46.714 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:46.715 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 11:21:46.716 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.05\n",
      "2021-08-25 11:21:46.717 | WARNING  | src.policies:train:131 - The actual batch size is 211, instead of 200\n",
      "2021-08-25 11:21:46.725 | INFO     | src.policies:train:157 - Total loss: 1.001927375793457\n",
      "2021-08-25 11:21:46.728 | INFO     | src.policies:train:103 - Epoch 209 / 800\n",
      "2021-08-25 11:21:46.729 | INFO     | src.policies:train:109 - Episode 1564\n",
      "2021-08-25 11:21:46.737 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:46.738 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:21:46.739 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.64\n",
      "2021-08-25 11:21:46.740 | INFO     | src.policies:train:109 - Episode 1565\n",
      "2021-08-25 11:21:46.753 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:46.754 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:21:46.755 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.73\n",
      "2021-08-25 11:21:46.756 | INFO     | src.policies:train:109 - Episode 1566\n",
      "2021-08-25 11:21:46.766 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:46.767 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:46.768 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.75\n",
      "2021-08-25 11:21:46.769 | INFO     | src.policies:train:109 - Episode 1567\n",
      "2021-08-25 11:21:46.779 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:46.780 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:21:46.781 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.81\n",
      "2021-08-25 11:21:46.782 | INFO     | src.policies:train:109 - Episode 1568\n",
      "2021-08-25 11:21:46.811 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:46.812 | INFO     | src.policies:train:121 - Mean episode return: 64.0\n",
      "2021-08-25 11:21:46.813 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.12\n",
      "2021-08-25 11:21:46.814 | INFO     | src.policies:train:109 - Episode 1569\n",
      "2021-08-25 11:21:46.838 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:46.839 | INFO     | src.policies:train:121 - Mean episode return: 54.0\n",
      "2021-08-25 11:21:46.840 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.51\n",
      "2021-08-25 11:21:46.841 | INFO     | src.policies:train:109 - Episode 1570\n",
      "2021-08-25 11:21:46.853 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:46.854 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:21:46.855 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.07\n",
      "2021-08-25 11:21:46.856 | WARNING  | src.policies:train:131 - The actual batch size is 208, instead of 200\n",
      "2021-08-25 11:21:46.864 | INFO     | src.policies:train:157 - Total loss: 1.0014300346374512\n",
      "2021-08-25 11:21:46.867 | INFO     | src.policies:train:103 - Epoch 210 / 800\n",
      "2021-08-25 11:21:46.868 | INFO     | src.policies:train:109 - Episode 1571\n",
      "2021-08-25 11:21:46.888 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:46.889 | INFO     | src.policies:train:121 - Mean episode return: 49.0\n",
      "2021-08-25 11:21:46.890 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.43\n",
      "2021-08-25 11:21:46.891 | INFO     | src.policies:train:109 - Episode 1572\n",
      "2021-08-25 11:21:46.914 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:46.916 | INFO     | src.policies:train:121 - Mean episode return: 52.0\n",
      "2021-08-25 11:21:46.916 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.66\n",
      "2021-08-25 11:21:46.917 | INFO     | src.policies:train:109 - Episode 1573\n",
      "2021-08-25 11:21:46.933 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:46.935 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 11:21:46.935 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.86\n",
      "2021-08-25 11:21:46.936 | INFO     | src.policies:train:109 - Episode 1574\n",
      "2021-08-25 11:21:46.945 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:46.946 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:21:46.947 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.82\n",
      "2021-08-25 11:21:46.948 | INFO     | src.policies:train:109 - Episode 1575\n",
      "2021-08-25 11:21:46.964 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:46.965 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 11:21:46.966 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.03\n",
      "2021-08-25 11:21:46.967 | INFO     | src.policies:train:109 - Episode 1576\n",
      "2021-08-25 11:21:46.977 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:46.979 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:21:46.979 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.07\n",
      "2021-08-25 11:21:46.981 | INFO     | src.policies:train:109 - Episode 1577\n",
      "2021-08-25 11:21:47.001 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:47.002 | INFO     | src.policies:train:121 - Mean episode return: 42.0\n",
      "2021-08-25 11:21:47.003 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.26\n",
      "2021-08-25 11:21:47.004 | WARNING  | src.policies:train:131 - The actual batch size is 236, instead of 200\n",
      "2021-08-25 11:21:47.011 | INFO     | src.policies:train:157 - Total loss: 1.0023647546768188\n",
      "2021-08-25 11:21:47.015 | INFO     | src.policies:train:103 - Epoch 211 / 800\n",
      "2021-08-25 11:21:47.016 | INFO     | src.policies:train:109 - Episode 1578\n",
      "2021-08-25 11:21:47.030 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:47.031 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:21:47.032 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.28\n",
      "2021-08-25 11:21:47.033 | INFO     | src.policies:train:109 - Episode 1579\n",
      "2021-08-25 11:21:47.054 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:47.056 | INFO     | src.policies:train:121 - Mean episode return: 44.0\n",
      "2021-08-25 11:21:47.057 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.24\n",
      "2021-08-25 11:21:47.058 | INFO     | src.policies:train:109 - Episode 1580\n",
      "2021-08-25 11:21:47.076 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:47.078 | INFO     | src.policies:train:121 - Mean episode return: 39.0\n",
      "2021-08-25 11:21:47.079 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.5\n",
      "2021-08-25 11:21:47.079 | INFO     | src.policies:train:109 - Episode 1581\n",
      "2021-08-25 11:21:47.088 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:47.089 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:21:47.090 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.34\n",
      "2021-08-25 11:21:47.091 | INFO     | src.policies:train:109 - Episode 1582\n",
      "2021-08-25 11:21:47.140 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:47.141 | INFO     | src.policies:train:121 - Mean episode return: 101.0\n",
      "2021-08-25 11:21:47.143 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.97\n",
      "2021-08-25 11:21:47.144 | WARNING  | src.policies:train:131 - The actual batch size is 226, instead of 200\n",
      "2021-08-25 11:21:47.153 | INFO     | src.policies:train:157 - Total loss: 1.0021896362304688\n",
      "2021-08-25 11:21:47.157 | INFO     | src.policies:train:103 - Epoch 212 / 800\n",
      "2021-08-25 11:21:47.158 | INFO     | src.policies:train:109 - Episode 1583\n",
      "2021-08-25 11:21:47.218 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:47.219 | INFO     | src.policies:train:121 - Mean episode return: 140.0\n",
      "2021-08-25 11:21:47.221 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.0\n",
      "2021-08-25 11:21:47.222 | INFO     | src.policies:train:109 - Episode 1584\n",
      "2021-08-25 11:21:47.245 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:47.247 | INFO     | src.policies:train:121 - Mean episode return: 47.0\n",
      "2021-08-25 11:21:47.248 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.34\n",
      "2021-08-25 11:21:47.249 | INFO     | src.policies:train:109 - Episode 1585\n",
      "2021-08-25 11:21:47.260 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:47.261 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:47.262 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.27\n",
      "2021-08-25 11:21:47.263 | INFO     | src.policies:train:109 - Episode 1586\n",
      "2021-08-25 11:21:47.274 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:47.275 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:21:47.276 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.24\n",
      "2021-08-25 11:21:47.277 | WARNING  | src.policies:train:131 - The actual batch size is 221, instead of 200\n",
      "2021-08-25 11:21:47.284 | INFO     | src.policies:train:157 - Total loss: 1.0020924806594849\n",
      "2021-08-25 11:21:47.288 | INFO     | src.policies:train:103 - Epoch 213 / 800\n",
      "2021-08-25 11:21:47.289 | INFO     | src.policies:train:109 - Episode 1587\n",
      "2021-08-25 11:21:47.307 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:47.308 | INFO     | src.policies:train:121 - Mean episode return: 43.0\n",
      "2021-08-25 11:21:47.309 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.77\n",
      "2021-08-25 11:21:47.310 | INFO     | src.policies:train:109 - Episode 1588\n",
      "2021-08-25 11:21:47.321 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:47.322 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:21:47.323 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.38\n",
      "2021-08-25 11:21:47.324 | INFO     | src.policies:train:109 - Episode 1589\n",
      "2021-08-25 11:21:47.339 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:47.341 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 11:21:47.342 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.12\n",
      "2021-08-25 11:21:47.342 | INFO     | src.policies:train:109 - Episode 1590\n",
      "2021-08-25 11:21:47.360 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:47.361 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 11:21:47.362 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.36\n",
      "2021-08-25 11:21:47.363 | INFO     | src.policies:train:109 - Episode 1591\n",
      "2021-08-25 11:21:47.376 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:47.377 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 11:21:47.378 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.38\n",
      "2021-08-25 11:21:47.379 | INFO     | src.policies:train:109 - Episode 1592\n",
      "2021-08-25 11:21:47.398 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:47.399 | INFO     | src.policies:train:121 - Mean episode return: 38.0\n",
      "2021-08-25 11:21:47.400 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.27\n",
      "2021-08-25 11:21:47.401 | INFO     | src.policies:train:109 - Episode 1593\n",
      "2021-08-25 11:21:47.411 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:47.412 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:47.413 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.32\n",
      "2021-08-25 11:21:47.414 | WARNING  | src.policies:train:131 - The actual batch size is 213, instead of 200\n",
      "2021-08-25 11:21:47.421 | INFO     | src.policies:train:157 - Total loss: 1.0018696784973145\n",
      "2021-08-25 11:21:47.425 | INFO     | src.policies:train:103 - Epoch 214 / 800\n",
      "2021-08-25 11:21:47.426 | INFO     | src.policies:train:109 - Episode 1594\n",
      "2021-08-25 11:21:47.433 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:47.435 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:21:47.436 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.28\n",
      "2021-08-25 11:21:47.437 | INFO     | src.policies:train:109 - Episode 1595\n",
      "2021-08-25 11:21:47.459 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:47.461 | INFO     | src.policies:train:121 - Mean episode return: 51.0\n",
      "2021-08-25 11:21:47.462 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:47.463 | INFO     | src.policies:train:109 - Episode 1596\n",
      "2021-08-25 11:21:47.470 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:47.472 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:21:47.473 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.91\n",
      "2021-08-25 11:21:47.474 | INFO     | src.policies:train:109 - Episode 1597\n",
      "2021-08-25 11:21:47.488 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:47.490 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 11:21:47.491 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.66\n",
      "2021-08-25 11:21:47.492 | INFO     | src.policies:train:109 - Episode 1598\n",
      "2021-08-25 11:21:47.503 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:47.504 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:21:47.505 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.66\n",
      "2021-08-25 11:21:47.506 | INFO     | src.policies:train:109 - Episode 1599\n",
      "2021-08-25 11:21:47.518 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:47.519 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:21:47.520 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.26\n",
      "2021-08-25 11:21:47.521 | INFO     | src.policies:train:109 - Episode 1600\n",
      "2021-08-25 11:21:47.535 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:47.536 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 11:21:47.537 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.4\n",
      "2021-08-25 11:21:47.539 | INFO     | src.policies:train:109 - Episode 1601\n",
      "2021-08-25 11:21:47.550 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:47.551 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:21:47.552 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.15\n",
      "2021-08-25 11:21:47.554 | INFO     | src.policies:train:109 - Episode 1602\n",
      "2021-08-25 11:21:47.599 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:47.600 | INFO     | src.policies:train:121 - Mean episode return: 111.0\n",
      "2021-08-25 11:21:47.601 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.82\n",
      "2021-08-25 11:21:47.602 | WARNING  | src.policies:train:131 - The actual batch size is 309, instead of 200\n",
      "2021-08-25 11:21:47.610 | INFO     | src.policies:train:157 - Total loss: 1.0032627582550049\n",
      "2021-08-25 11:21:47.613 | INFO     | src.policies:train:103 - Epoch 215 / 800\n",
      "2021-08-25 11:21:47.614 | INFO     | src.policies:train:109 - Episode 1603\n",
      "2021-08-25 11:21:47.622 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:47.623 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:47.624 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.31\n",
      "2021-08-25 11:21:47.625 | INFO     | src.policies:train:109 - Episode 1604\n",
      "2021-08-25 11:21:47.640 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:47.641 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:21:47.642 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.23\n",
      "2021-08-25 11:21:47.643 | INFO     | src.policies:train:109 - Episode 1605\n",
      "2021-08-25 11:21:47.653 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:47.655 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:47.656 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.7\n",
      "2021-08-25 11:21:47.657 | INFO     | src.policies:train:109 - Episode 1606\n",
      "2021-08-25 11:21:47.679 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:47.680 | INFO     | src.policies:train:121 - Mean episode return: 49.0\n",
      "2021-08-25 11:21:47.681 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.9\n",
      "2021-08-25 11:21:47.682 | INFO     | src.policies:train:109 - Episode 1607\n",
      "2021-08-25 11:21:47.725 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:47.726 | INFO     | src.policies:train:121 - Mean episode return: 105.0\n",
      "2021-08-25 11:21:47.727 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.52\n",
      "2021-08-25 11:21:47.728 | WARNING  | src.policies:train:131 - The actual batch size is 215, instead of 200\n",
      "2021-08-25 11:21:47.735 | INFO     | src.policies:train:157 - Total loss: 1.001737356185913\n",
      "2021-08-25 11:21:47.739 | INFO     | src.policies:train:103 - Epoch 216 / 800\n",
      "2021-08-25 11:21:47.740 | INFO     | src.policies:train:109 - Episode 1608\n",
      "2021-08-25 11:21:47.762 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:47.764 | INFO     | src.policies:train:121 - Mean episode return: 54.0\n",
      "2021-08-25 11:21:47.765 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.62\n",
      "2021-08-25 11:21:47.765 | INFO     | src.policies:train:109 - Episode 1609\n",
      "2021-08-25 11:21:47.777 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:47.778 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:21:47.779 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.61\n",
      "2021-08-25 11:21:47.780 | INFO     | src.policies:train:109 - Episode 1610\n",
      "2021-08-25 11:21:47.790 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:47.792 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:21:47.792 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.51\n",
      "2021-08-25 11:21:47.794 | INFO     | src.policies:train:109 - Episode 1611\n",
      "2021-08-25 11:21:47.810 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:47.811 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 11:21:47.812 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.73\n",
      "2021-08-25 11:21:47.813 | INFO     | src.policies:train:109 - Episode 1612\n",
      "2021-08-25 11:21:47.837 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:47.838 | INFO     | src.policies:train:121 - Mean episode return: 55.0\n",
      "2021-08-25 11:21:47.839 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.71\n",
      "2021-08-25 11:21:47.840 | INFO     | src.policies:train:109 - Episode 1613\n",
      "2021-08-25 11:21:47.863 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:47.864 | INFO     | src.policies:train:121 - Mean episode return: 48.0\n",
      "2021-08-25 11:21:47.865 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.08\n",
      "2021-08-25 11:21:47.866 | WARNING  | src.policies:train:131 - The actual batch size is 236, instead of 200\n",
      "2021-08-25 11:21:47.874 | INFO     | src.policies:train:157 - Total loss: 1.0020946264266968\n",
      "2021-08-25 11:21:47.877 | INFO     | src.policies:train:103 - Epoch 217 / 800\n",
      "2021-08-25 11:21:47.878 | INFO     | src.policies:train:109 - Episode 1614\n",
      "2021-08-25 11:21:47.891 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:47.892 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:21:47.893 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.19\n",
      "2021-08-25 11:21:47.894 | INFO     | src.policies:train:109 - Episode 1615\n",
      "2021-08-25 11:21:47.904 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:47.905 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:47.906 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.99\n",
      "2021-08-25 11:21:47.907 | INFO     | src.policies:train:109 - Episode 1616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:47.917 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:47.918 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:21:47.919 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.26\n",
      "2021-08-25 11:21:47.921 | INFO     | src.policies:train:109 - Episode 1617\n",
      "2021-08-25 11:21:47.938 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:47.939 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 11:21:47.940 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.32\n",
      "2021-08-25 11:21:47.941 | INFO     | src.policies:train:109 - Episode 1618\n",
      "2021-08-25 11:21:47.951 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:47.953 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:47.954 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.21\n",
      "2021-08-25 11:21:47.955 | INFO     | src.policies:train:109 - Episode 1619\n",
      "2021-08-25 11:21:47.980 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:47.982 | INFO     | src.policies:train:121 - Mean episode return: 52.0\n",
      "2021-08-25 11:21:47.983 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.37\n",
      "2021-08-25 11:21:47.983 | INFO     | src.policies:train:109 - Episode 1620\n",
      "2021-08-25 11:21:47.992 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:47.994 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:47.995 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.2\n",
      "2021-08-25 11:21:47.996 | INFO     | src.policies:train:109 - Episode 1621\n",
      "2021-08-25 11:21:48.017 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:48.018 | INFO     | src.policies:train:121 - Mean episode return: 45.0\n",
      "2021-08-25 11:21:48.019 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.19\n",
      "2021-08-25 11:21:48.020 | WARNING  | src.policies:train:131 - The actual batch size is 223, instead of 200\n",
      "2021-08-25 11:21:48.028 | INFO     | src.policies:train:157 - Total loss: 1.0021789073944092\n",
      "2021-08-25 11:21:48.031 | INFO     | src.policies:train:103 - Epoch 218 / 800\n",
      "2021-08-25 11:21:48.032 | INFO     | src.policies:train:109 - Episode 1622\n",
      "2021-08-25 11:21:48.049 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:48.050 | INFO     | src.policies:train:121 - Mean episode return: 39.0\n",
      "2021-08-25 11:21:48.051 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.63\n",
      "2021-08-25 11:21:48.052 | INFO     | src.policies:train:109 - Episode 1623\n",
      "2021-08-25 11:21:48.068 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:48.069 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 11:21:48.070 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.39\n",
      "2021-08-25 11:21:48.071 | INFO     | src.policies:train:109 - Episode 1624\n",
      "2021-08-25 11:21:48.111 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:48.112 | INFO     | src.policies:train:121 - Mean episode return: 94.0\n",
      "2021-08-25 11:21:48.114 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.2\n",
      "2021-08-25 11:21:48.115 | INFO     | src.policies:train:109 - Episode 1625\n",
      "2021-08-25 11:21:48.139 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:48.141 | INFO     | src.policies:train:121 - Mean episode return: 56.0\n",
      "2021-08-25 11:21:48.142 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.34\n",
      "2021-08-25 11:21:48.143 | WARNING  | src.policies:train:131 - The actual batch size is 217, instead of 200\n",
      "2021-08-25 11:21:48.149 | INFO     | src.policies:train:157 - Total loss: 1.0018819570541382\n",
      "2021-08-25 11:21:48.153 | INFO     | src.policies:train:103 - Epoch 219 / 800\n",
      "2021-08-25 11:21:48.154 | INFO     | src.policies:train:109 - Episode 1626\n",
      "2021-08-25 11:21:48.166 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:48.167 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 11:21:48.168 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.38\n",
      "2021-08-25 11:21:48.170 | INFO     | src.policies:train:109 - Episode 1627\n",
      "2021-08-25 11:21:48.203 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:48.204 | INFO     | src.policies:train:121 - Mean episode return: 73.0\n",
      "2021-08-25 11:21:48.205 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.89\n",
      "2021-08-25 11:21:48.206 | INFO     | src.policies:train:109 - Episode 1628\n",
      "2021-08-25 11:21:48.245 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:48.246 | INFO     | src.policies:train:121 - Mean episode return: 88.0\n",
      "2021-08-25 11:21:48.247 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.77\n",
      "2021-08-25 11:21:48.248 | INFO     | src.policies:train:109 - Episode 1629\n",
      "2021-08-25 11:21:48.278 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:48.279 | INFO     | src.policies:train:121 - Mean episode return: 66.0\n",
      "2021-08-25 11:21:48.280 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.16\n",
      "2021-08-25 11:21:48.281 | WARNING  | src.policies:train:131 - The actual batch size is 254, instead of 200\n",
      "2021-08-25 11:21:48.289 | INFO     | src.policies:train:157 - Total loss: 1.0022419691085815\n",
      "2021-08-25 11:21:48.292 | INFO     | src.policies:train:103 - Epoch 220 / 800\n",
      "2021-08-25 11:21:48.294 | INFO     | src.policies:train:109 - Episode 1630\n",
      "2021-08-25 11:21:48.317 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:48.319 | INFO     | src.policies:train:121 - Mean episode return: 55.0\n",
      "2021-08-25 11:21:48.320 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.54\n",
      "2021-08-25 11:21:48.321 | INFO     | src.policies:train:109 - Episode 1631\n",
      "2021-08-25 11:21:48.337 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:48.339 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 11:21:48.340 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.5\n",
      "2021-08-25 11:21:48.341 | INFO     | src.policies:train:109 - Episode 1632\n",
      "2021-08-25 11:21:48.374 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:48.375 | INFO     | src.policies:train:121 - Mean episode return: 73.0\n",
      "2021-08-25 11:21:48.377 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.08\n",
      "2021-08-25 11:21:48.378 | INFO     | src.policies:train:109 - Episode 1633\n",
      "2021-08-25 11:21:48.418 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:48.419 | INFO     | src.policies:train:121 - Mean episode return: 100.0\n",
      "2021-08-25 11:21:48.420 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.52\n",
      "2021-08-25 11:21:48.421 | WARNING  | src.policies:train:131 - The actual batch size is 261, instead of 200\n",
      "2021-08-25 11:21:48.430 | INFO     | src.policies:train:157 - Total loss: 1.002671718597412\n",
      "2021-08-25 11:21:48.434 | INFO     | src.policies:train:103 - Epoch 221 / 800\n",
      "2021-08-25 11:21:48.435 | INFO     | src.policies:train:109 - Episode 1634\n",
      "2021-08-25 11:21:48.445 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:48.446 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:48.447 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.32\n",
      "2021-08-25 11:21:48.448 | INFO     | src.policies:train:109 - Episode 1635\n",
      "2021-08-25 11:21:48.466 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:48.467 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:48.468 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.69\n",
      "2021-08-25 11:21:48.469 | INFO     | src.policies:train:109 - Episode 1636\n",
      "2021-08-25 11:21:48.484 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:48.485 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 11:21:48.486 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.56\n",
      "2021-08-25 11:21:48.487 | INFO     | src.policies:train:109 - Episode 1637\n",
      "2021-08-25 11:21:48.498 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:48.499 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:48.500 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.98\n",
      "2021-08-25 11:21:48.501 | INFO     | src.policies:train:109 - Episode 1638\n",
      "2021-08-25 11:21:48.512 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:48.513 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:21:48.515 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.88\n",
      "2021-08-25 11:21:48.515 | INFO     | src.policies:train:109 - Episode 1639\n",
      "2021-08-25 11:21:48.533 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:48.534 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 11:21:48.535 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.98\n",
      "2021-08-25 11:21:48.536 | INFO     | src.policies:train:109 - Episode 1640\n",
      "2021-08-25 11:21:48.546 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:48.547 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:21:48.548 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.81\n",
      "2021-08-25 11:21:48.549 | INFO     | src.policies:train:109 - Episode 1641\n",
      "2021-08-25 11:21:48.559 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:48.560 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:21:48.561 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.33\n",
      "2021-08-25 11:21:48.562 | INFO     | src.policies:train:109 - Episode 1642\n",
      "2021-08-25 11:21:48.612 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:48.614 | INFO     | src.policies:train:121 - Mean episode return: 128.0\n",
      "2021-08-25 11:21:48.615 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.49\n",
      "2021-08-25 11:21:48.615 | WARNING  | src.policies:train:131 - The actual batch size is 302, instead of 200\n",
      "2021-08-25 11:21:48.624 | INFO     | src.policies:train:157 - Total loss: 1.0034806728363037\n",
      "2021-08-25 11:21:48.627 | INFO     | src.policies:train:103 - Epoch 222 / 800\n",
      "2021-08-25 11:21:48.628 | INFO     | src.policies:train:109 - Episode 1643\n",
      "2021-08-25 11:21:48.655 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:48.657 | INFO     | src.policies:train:121 - Mean episode return: 63.0\n",
      "2021-08-25 11:21:48.658 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.63\n",
      "2021-08-25 11:21:48.659 | INFO     | src.policies:train:109 - Episode 1644\n",
      "2021-08-25 11:21:48.668 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:48.670 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:48.671 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.35\n",
      "2021-08-25 11:21:48.672 | INFO     | src.policies:train:109 - Episode 1645\n",
      "2021-08-25 11:21:48.681 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:48.682 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:21:48.683 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.37\n",
      "2021-08-25 11:21:48.684 | INFO     | src.policies:train:109 - Episode 1646\n",
      "2021-08-25 11:21:48.695 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:48.697 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:21:48.698 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.11\n",
      "2021-08-25 11:21:48.699 | INFO     | src.policies:train:109 - Episode 1647\n",
      "2021-08-25 11:21:48.711 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:48.712 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:21:48.713 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.13\n",
      "2021-08-25 11:21:48.714 | INFO     | src.policies:train:109 - Episode 1648\n",
      "2021-08-25 11:21:48.743 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:48.744 | INFO     | src.policies:train:121 - Mean episode return: 60.0\n",
      "2021-08-25 11:21:48.745 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.55\n",
      "2021-08-25 11:21:48.746 | INFO     | src.policies:train:109 - Episode 1649\n",
      "2021-08-25 11:21:48.766 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:48.767 | INFO     | src.policies:train:121 - Mean episode return: 44.0\n",
      "2021-08-25 11:21:48.768 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.76\n",
      "2021-08-25 11:21:48.769 | WARNING  | src.policies:train:131 - The actual batch size is 234, instead of 200\n",
      "2021-08-25 11:21:48.777 | INFO     | src.policies:train:157 - Total loss: 1.002367377281189\n",
      "2021-08-25 11:21:48.781 | INFO     | src.policies:train:103 - Epoch 223 / 800\n",
      "2021-08-25 11:21:48.783 | INFO     | src.policies:train:109 - Episode 1650\n",
      "2021-08-25 11:21:48.809 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:48.811 | INFO     | src.policies:train:121 - Mean episode return: 65.0\n",
      "2021-08-25 11:21:48.812 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.98\n",
      "2021-08-25 11:21:48.814 | INFO     | src.policies:train:109 - Episode 1651\n",
      "2021-08-25 11:21:48.856 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:48.858 | INFO     | src.policies:train:121 - Mean episode return: 101.0\n",
      "2021-08-25 11:21:48.859 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.49\n",
      "2021-08-25 11:21:48.860 | INFO     | src.policies:train:109 - Episode 1652\n",
      "2021-08-25 11:21:48.880 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:48.882 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 11:21:48.883 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.68\n",
      "2021-08-25 11:21:48.884 | WARNING  | src.policies:train:131 - The actual batch size is 206, instead of 200\n",
      "2021-08-25 11:21:48.890 | INFO     | src.policies:train:157 - Total loss: 1.0019158124923706\n",
      "2021-08-25 11:21:48.894 | INFO     | src.policies:train:103 - Epoch 224 / 800\n",
      "2021-08-25 11:21:48.895 | INFO     | src.policies:train:109 - Episode 1653\n",
      "2021-08-25 11:21:48.908 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:48.909 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 11:21:48.910 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.75\n",
      "2021-08-25 11:21:48.911 | INFO     | src.policies:train:109 - Episode 1654\n",
      "2021-08-25 11:21:48.931 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:48.933 | INFO     | src.policies:train:121 - Mean episode return: 41.0\n",
      "2021-08-25 11:21:48.934 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.57\n",
      "2021-08-25 11:21:48.935 | INFO     | src.policies:train:109 - Episode 1655\n",
      "2021-08-25 11:21:48.947 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:48.948 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:21:48.949 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:48.950 | INFO     | src.policies:train:109 - Episode 1656\n",
      "2021-08-25 11:21:48.963 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:48.965 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:21:48.966 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.65\n",
      "2021-08-25 11:21:48.967 | INFO     | src.policies:train:109 - Episode 1657\n",
      "2021-08-25 11:21:48.980 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:48.982 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:21:48.983 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.75\n",
      "2021-08-25 11:21:48.984 | INFO     | src.policies:train:109 - Episode 1658\n",
      "2021-08-25 11:21:48.995 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:48.997 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:21:48.998 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.61\n",
      "2021-08-25 11:21:48.999 | INFO     | src.policies:train:109 - Episode 1659\n",
      "2021-08-25 11:21:49.014 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:49.016 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:21:49.017 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.7\n",
      "2021-08-25 11:21:49.018 | INFO     | src.policies:train:109 - Episode 1660\n",
      "2021-08-25 11:21:49.040 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:49.041 | INFO     | src.policies:train:121 - Mean episode return: 44.0\n",
      "2021-08-25 11:21:49.042 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.87\n",
      "2021-08-25 11:21:49.043 | WARNING  | src.policies:train:131 - The actual batch size is 205, instead of 200\n",
      "2021-08-25 11:21:49.051 | INFO     | src.policies:train:157 - Total loss: 1.0020134449005127\n",
      "2021-08-25 11:21:49.055 | INFO     | src.policies:train:103 - Epoch 225 / 800\n",
      "2021-08-25 11:21:49.056 | INFO     | src.policies:train:109 - Episode 1661\n",
      "2021-08-25 11:21:49.098 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:49.099 | INFO     | src.policies:train:121 - Mean episode return: 94.0\n",
      "2021-08-25 11:21:49.100 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.38\n",
      "2021-08-25 11:21:49.101 | INFO     | src.policies:train:109 - Episode 1662\n",
      "2021-08-25 11:21:49.132 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:49.133 | INFO     | src.policies:train:121 - Mean episode return: 69.0\n",
      "2021-08-25 11:21:49.134 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.56\n",
      "2021-08-25 11:21:49.135 | INFO     | src.policies:train:109 - Episode 1663\n",
      "2021-08-25 11:21:49.155 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:49.156 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 11:21:49.157 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.63\n",
      "2021-08-25 11:21:49.158 | INFO     | src.policies:train:109 - Episode 1664\n",
      "2021-08-25 11:21:49.171 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:49.173 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:21:49.174 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.72\n",
      "2021-08-25 11:21:49.175 | WARNING  | src.policies:train:131 - The actual batch size is 220, instead of 200\n",
      "2021-08-25 11:21:49.184 | INFO     | src.policies:train:157 - Total loss: 1.0019639730453491\n",
      "2021-08-25 11:21:49.187 | INFO     | src.policies:train:103 - Epoch 226 / 800\n",
      "2021-08-25 11:21:49.189 | INFO     | src.policies:train:109 - Episode 1665\n",
      "2021-08-25 11:21:49.200 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:49.201 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:49.202 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.64\n",
      "2021-08-25 11:21:49.203 | INFO     | src.policies:train:109 - Episode 1666\n",
      "2021-08-25 11:21:49.226 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:49.228 | INFO     | src.policies:train:121 - Mean episode return: 46.0\n",
      "2021-08-25 11:21:49.229 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.95\n",
      "2021-08-25 11:21:49.230 | INFO     | src.policies:train:109 - Episode 1667\n",
      "2021-08-25 11:21:49.247 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:49.248 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:21:49.250 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 40.06\n",
      "2021-08-25 11:21:49.251 | INFO     | src.policies:train:109 - Episode 1668\n",
      "2021-08-25 11:21:49.265 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:49.266 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:21:49.267 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.65\n",
      "2021-08-25 11:21:49.268 | INFO     | src.policies:train:109 - Episode 1669\n",
      "2021-08-25 11:21:49.311 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:49.313 | INFO     | src.policies:train:121 - Mean episode return: 103.0\n",
      "2021-08-25 11:21:49.314 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 40.14\n",
      "2021-08-25 11:21:49.315 | WARNING  | src.policies:train:131 - The actual batch size is 217, instead of 200\n",
      "2021-08-25 11:21:49.322 | INFO     | src.policies:train:157 - Total loss: 1.0020440816879272\n",
      "2021-08-25 11:21:49.325 | INFO     | src.policies:train:103 - Epoch 227 / 800\n",
      "2021-08-25 11:21:49.326 | INFO     | src.policies:train:109 - Episode 1670\n",
      "2021-08-25 11:21:49.336 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:49.338 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:21:49.339 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 40.13\n",
      "2021-08-25 11:21:49.340 | INFO     | src.policies:train:109 - Episode 1671\n",
      "2021-08-25 11:21:49.364 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:49.366 | INFO     | src.policies:train:121 - Mean episode return: 53.0\n",
      "2021-08-25 11:21:49.367 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 40.17\n",
      "2021-08-25 11:21:49.368 | INFO     | src.policies:train:109 - Episode 1672\n",
      "2021-08-25 11:21:49.378 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:49.379 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:21:49.380 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.78\n",
      "2021-08-25 11:21:49.382 | INFO     | src.policies:train:109 - Episode 1673\n",
      "2021-08-25 11:21:49.406 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:49.407 | INFO     | src.policies:train:121 - Mean episode return: 49.0\n",
      "2021-08-25 11:21:49.408 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.96\n",
      "2021-08-25 11:21:49.409 | INFO     | src.policies:train:109 - Episode 1674\n",
      "2021-08-25 11:21:49.435 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:49.437 | INFO     | src.policies:train:121 - Mean episode return: 52.0\n",
      "2021-08-25 11:21:49.438 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 40.35\n",
      "2021-08-25 11:21:49.439 | INFO     | src.policies:train:109 - Episode 1675\n",
      "2021-08-25 11:21:49.470 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:49.471 | INFO     | src.policies:train:121 - Mean episode return: 63.0\n",
      "2021-08-25 11:21:49.472 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 40.67\n",
      "2021-08-25 11:21:49.473 | WARNING  | src.policies:train:131 - The actual batch size is 248, instead of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:49.483 | INFO     | src.policies:train:157 - Total loss: 1.0025438070297241\n",
      "2021-08-25 11:21:49.487 | INFO     | src.policies:train:103 - Epoch 228 / 800\n",
      "2021-08-25 11:21:49.489 | INFO     | src.policies:train:109 - Episode 1676\n",
      "2021-08-25 11:21:49.503 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:49.505 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:21:49.506 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 40.78\n",
      "2021-08-25 11:21:49.508 | INFO     | src.policies:train:109 - Episode 1677\n",
      "2021-08-25 11:21:49.517 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:49.519 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:49.521 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 40.48\n",
      "2021-08-25 11:21:49.522 | INFO     | src.policies:train:109 - Episode 1678\n",
      "2021-08-25 11:21:49.536 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:49.538 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:21:49.539 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 40.45\n",
      "2021-08-25 11:21:49.540 | INFO     | src.policies:train:109 - Episode 1679\n",
      "2021-08-25 11:21:49.573 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:49.574 | INFO     | src.policies:train:121 - Mean episode return: 75.0\n",
      "2021-08-25 11:21:49.576 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 40.76\n",
      "2021-08-25 11:21:49.577 | INFO     | src.policies:train:109 - Episode 1680\n",
      "2021-08-25 11:21:49.598 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:49.600 | INFO     | src.policies:train:121 - Mean episode return: 46.0\n",
      "2021-08-25 11:21:49.601 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 40.83\n",
      "2021-08-25 11:21:49.602 | INFO     | src.policies:train:109 - Episode 1681\n",
      "2021-08-25 11:21:49.618 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:49.619 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 11:21:49.620 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 40.95\n",
      "2021-08-25 11:21:49.621 | WARNING  | src.policies:train:131 - The actual batch size is 213, instead of 200\n",
      "2021-08-25 11:21:49.629 | INFO     | src.policies:train:157 - Total loss: 1.0020238161087036\n",
      "2021-08-25 11:21:49.633 | INFO     | src.policies:train:103 - Epoch 229 / 800\n",
      "2021-08-25 11:21:49.635 | INFO     | src.policies:train:109 - Episode 1682\n",
      "2021-08-25 11:21:49.645 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:49.646 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:49.647 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 40.1\n",
      "2021-08-25 11:21:49.648 | INFO     | src.policies:train:109 - Episode 1683\n",
      "2021-08-25 11:21:49.663 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:49.664 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:21:49.665 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.96\n",
      "2021-08-25 11:21:49.666 | INFO     | src.policies:train:109 - Episode 1684\n",
      "2021-08-25 11:21:49.687 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:49.688 | INFO     | src.policies:train:121 - Mean episode return: 39.0\n",
      "2021-08-25 11:21:49.690 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.88\n",
      "2021-08-25 11:21:49.691 | INFO     | src.policies:train:109 - Episode 1685\n",
      "2021-08-25 11:21:49.703 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:49.704 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:49.708 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.93\n",
      "2021-08-25 11:21:49.709 | INFO     | src.policies:train:109 - Episode 1686\n",
      "2021-08-25 11:21:49.731 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:49.732 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 11:21:49.734 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.05\n",
      "2021-08-25 11:21:49.735 | INFO     | src.policies:train:109 - Episode 1687\n",
      "2021-08-25 11:21:49.749 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:49.750 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:21:49.752 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.85\n",
      "2021-08-25 11:21:49.753 | INFO     | src.policies:train:109 - Episode 1688\n",
      "2021-08-25 11:21:49.771 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:49.772 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 11:21:49.773 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.96\n",
      "2021-08-25 11:21:49.774 | INFO     | src.policies:train:109 - Episode 1689\n",
      "2021-08-25 11:21:49.791 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:49.793 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 11:21:49.794 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.95\n",
      "2021-08-25 11:21:49.795 | WARNING  | src.policies:train:131 - The actual batch size is 215, instead of 200\n",
      "2021-08-25 11:21:49.805 | INFO     | src.policies:train:157 - Total loss: 1.0020593404769897\n",
      "2021-08-25 11:21:49.808 | INFO     | src.policies:train:103 - Epoch 230 / 800\n",
      "2021-08-25 11:21:49.809 | INFO     | src.policies:train:109 - Episode 1690\n",
      "2021-08-25 11:21:49.820 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:49.822 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:21:49.824 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.76\n",
      "2021-08-25 11:21:49.825 | INFO     | src.policies:train:109 - Episode 1691\n",
      "2021-08-25 11:21:49.838 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:49.840 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:21:49.841 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.69\n",
      "2021-08-25 11:21:49.842 | INFO     | src.policies:train:109 - Episode 1692\n",
      "2021-08-25 11:21:49.856 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:49.857 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:21:49.858 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.52\n",
      "2021-08-25 11:21:49.859 | INFO     | src.policies:train:109 - Episode 1693\n",
      "2021-08-25 11:21:49.880 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:49.881 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 11:21:49.883 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.75\n",
      "2021-08-25 11:21:49.884 | INFO     | src.policies:train:109 - Episode 1694\n",
      "2021-08-25 11:21:49.905 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:49.906 | INFO     | src.policies:train:121 - Mean episode return: 43.0\n",
      "2021-08-25 11:21:49.907 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.04\n",
      "2021-08-25 11:21:49.908 | INFO     | src.policies:train:109 - Episode 1695\n",
      "2021-08-25 11:21:49.921 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:49.922 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:21:49.923 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.73\n",
      "2021-08-25 11:21:49.924 | INFO     | src.policies:train:109 - Episode 1696\n",
      "2021-08-25 11:21:49.946 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:49.948 | INFO     | src.policies:train:121 - Mean episode return: 44.0\n",
      "2021-08-25 11:21:49.949 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.06\n",
      "2021-08-25 11:21:49.951 | WARNING  | src.policies:train:131 - The actual batch size is 207, instead of 200\n",
      "2021-08-25 11:21:49.961 | INFO     | src.policies:train:157 - Total loss: 1.001866102218628\n",
      "2021-08-25 11:21:49.964 | INFO     | src.policies:train:103 - Epoch 231 / 800\n",
      "2021-08-25 11:21:49.966 | INFO     | src.policies:train:109 - Episode 1697\n",
      "2021-08-25 11:21:49.976 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:49.978 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:21:49.979 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.9\n",
      "2021-08-25 11:21:49.981 | INFO     | src.policies:train:109 - Episode 1698\n",
      "2021-08-25 11:21:49.994 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:49.996 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:21:49.998 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.89\n",
      "2021-08-25 11:21:49.999 | INFO     | src.policies:train:109 - Episode 1699\n",
      "2021-08-25 11:21:50.030 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:50.032 | INFO     | src.policies:train:121 - Mean episode return: 65.0\n",
      "2021-08-25 11:21:50.033 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.31\n",
      "2021-08-25 11:21:50.035 | INFO     | src.policies:train:109 - Episode 1700\n",
      "2021-08-25 11:21:50.052 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:50.054 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:21:50.056 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.24\n",
      "2021-08-25 11:21:50.057 | INFO     | src.policies:train:109 - Episode 1701\n",
      "2021-08-25 11:21:50.069 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:50.071 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:21:50.073 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.2\n",
      "2021-08-25 11:21:50.074 | INFO     | src.policies:train:109 - Episode 1702\n",
      "2021-08-25 11:21:50.092 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:50.094 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 11:21:50.095 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.39\n",
      "2021-08-25 11:21:50.096 | INFO     | src.policies:train:109 - Episode 1703\n",
      "2021-08-25 11:21:50.118 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:50.120 | INFO     | src.policies:train:121 - Mean episode return: 38.0\n",
      "2021-08-25 11:21:50.121 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.62\n",
      "2021-08-25 11:21:50.123 | WARNING  | src.policies:train:131 - The actual batch size is 204, instead of 200\n",
      "2021-08-25 11:21:50.133 | INFO     | src.policies:train:157 - Total loss: 1.0019211769104004\n",
      "2021-08-25 11:21:50.136 | INFO     | src.policies:train:103 - Epoch 232 / 800\n",
      "2021-08-25 11:21:50.138 | INFO     | src.policies:train:109 - Episode 1704\n",
      "2021-08-25 11:21:50.164 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:50.166 | INFO     | src.policies:train:121 - Mean episode return: 57.0\n",
      "2021-08-25 11:21:50.167 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.9\n",
      "2021-08-25 11:21:50.169 | INFO     | src.policies:train:109 - Episode 1705\n",
      "2021-08-25 11:21:50.177 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:50.179 | INFO     | src.policies:train:121 - Mean episode return: 9.0\n",
      "2021-08-25 11:21:50.181 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.82\n",
      "2021-08-25 11:21:50.182 | INFO     | src.policies:train:109 - Episode 1706\n",
      "2021-08-25 11:21:50.201 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:50.203 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 11:21:50.204 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.67\n",
      "2021-08-25 11:21:50.206 | INFO     | src.policies:train:109 - Episode 1707\n",
      "2021-08-25 11:21:50.245 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:50.247 | INFO     | src.policies:train:121 - Mean episode return: 89.0\n",
      "2021-08-25 11:21:50.248 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.51\n",
      "2021-08-25 11:21:50.250 | INFO     | src.policies:train:109 - Episode 1708\n",
      "2021-08-25 11:21:50.274 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:50.276 | INFO     | src.policies:train:121 - Mean episode return: 48.0\n",
      "2021-08-25 11:21:50.277 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.45\n",
      "2021-08-25 11:21:50.279 | WARNING  | src.policies:train:131 - The actual batch size is 237, instead of 200\n",
      "2021-08-25 11:21:50.288 | INFO     | src.policies:train:157 - Total loss: 1.0022038221359253\n",
      "2021-08-25 11:21:50.292 | INFO     | src.policies:train:103 - Epoch 233 / 800\n",
      "2021-08-25 11:21:50.294 | INFO     | src.policies:train:109 - Episode 1709\n",
      "2021-08-25 11:21:50.320 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:50.322 | INFO     | src.policies:train:121 - Mean episode return: 59.0\n",
      "2021-08-25 11:21:50.323 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.81\n",
      "2021-08-25 11:21:50.324 | INFO     | src.policies:train:109 - Episode 1710\n",
      "2021-08-25 11:21:50.333 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:50.334 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:21:50.335 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.74\n",
      "2021-08-25 11:21:50.336 | INFO     | src.policies:train:109 - Episode 1711\n",
      "2021-08-25 11:21:50.348 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:50.350 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:21:50.351 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.58\n",
      "2021-08-25 11:21:50.352 | INFO     | src.policies:train:109 - Episode 1712\n",
      "2021-08-25 11:21:50.371 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:50.373 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 11:21:50.374 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.3\n",
      "2021-08-25 11:21:50.376 | INFO     | src.policies:train:109 - Episode 1713\n",
      "2021-08-25 11:21:50.387 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:50.389 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:50.391 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.98\n",
      "2021-08-25 11:21:50.392 | INFO     | src.policies:train:109 - Episode 1714\n",
      "2021-08-25 11:21:50.404 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:50.406 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:50.407 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.9\n",
      "2021-08-25 11:21:50.408 | INFO     | src.policies:train:109 - Episode 1715\n",
      "2021-08-25 11:21:50.427 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:50.429 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 11:21:50.430 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.1\n",
      "2021-08-25 11:21:50.431 | INFO     | src.policies:train:109 - Episode 1716\n",
      "2021-08-25 11:21:50.442 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:50.444 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:50.445 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.05\n",
      "2021-08-25 11:21:50.446 | WARNING  | src.policies:train:131 - The actual batch size is 201, instead of 200\n",
      "2021-08-25 11:21:50.456 | INFO     | src.policies:train:157 - Total loss: 1.001941204071045\n",
      "2021-08-25 11:21:50.460 | INFO     | src.policies:train:103 - Epoch 234 / 800\n",
      "2021-08-25 11:21:50.461 | INFO     | src.policies:train:109 - Episode 1717\n",
      "2021-08-25 11:21:50.477 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:50.480 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:21:50.481 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.98\n",
      "2021-08-25 11:21:50.483 | INFO     | src.policies:train:109 - Episode 1718\n",
      "2021-08-25 11:21:50.498 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:50.499 | INFO     | src.policies:train:121 - Mean episode return: 24.0\n",
      "2021-08-25 11:21:50.500 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.06\n",
      "2021-08-25 11:21:50.502 | INFO     | src.policies:train:109 - Episode 1719\n",
      "2021-08-25 11:21:50.525 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:50.526 | INFO     | src.policies:train:121 - Mean episode return: 45.0\n",
      "2021-08-25 11:21:50.527 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.99\n",
      "2021-08-25 11:21:50.529 | INFO     | src.policies:train:109 - Episode 1720\n",
      "2021-08-25 11:21:50.545 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:50.546 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:21:50.547 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.1\n",
      "2021-08-25 11:21:50.548 | INFO     | src.policies:train:109 - Episode 1721\n",
      "2021-08-25 11:21:50.566 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:50.568 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 11:21:50.569 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.97\n",
      "2021-08-25 11:21:50.570 | INFO     | src.policies:train:109 - Episode 1722\n",
      "2021-08-25 11:21:50.583 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:50.585 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:21:50.586 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.78\n",
      "2021-08-25 11:21:50.587 | INFO     | src.policies:train:109 - Episode 1723\n",
      "2021-08-25 11:21:50.607 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:50.608 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 11:21:50.609 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.83\n",
      "2021-08-25 11:21:50.610 | WARNING  | src.policies:train:131 - The actual batch size is 209, instead of 200\n",
      "2021-08-25 11:21:50.620 | INFO     | src.policies:train:157 - Total loss: 1.0016982555389404\n",
      "2021-08-25 11:21:50.624 | INFO     | src.policies:train:103 - Epoch 235 / 800\n",
      "2021-08-25 11:21:50.626 | INFO     | src.policies:train:109 - Episode 1724\n",
      "2021-08-25 11:21:50.636 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:50.638 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:50.639 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.06\n",
      "2021-08-25 11:21:50.640 | INFO     | src.policies:train:109 - Episode 1725\n",
      "2021-08-25 11:21:50.675 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:50.677 | INFO     | src.policies:train:121 - Mean episode return: 78.0\n",
      "2021-08-25 11:21:50.678 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.28\n",
      "2021-08-25 11:21:50.679 | INFO     | src.policies:train:109 - Episode 1726\n",
      "2021-08-25 11:21:50.721 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:50.722 | INFO     | src.policies:train:121 - Mean episode return: 91.0\n",
      "2021-08-25 11:21:50.723 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.92\n",
      "2021-08-25 11:21:50.725 | INFO     | src.policies:train:109 - Episode 1727\n",
      "2021-08-25 11:21:50.736 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:50.737 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:50.739 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.34\n",
      "2021-08-25 11:21:50.740 | WARNING  | src.policies:train:131 - The actual batch size is 201, instead of 200\n",
      "2021-08-25 11:21:50.749 | INFO     | src.policies:train:157 - Total loss: 1.0015549659729004\n",
      "2021-08-25 11:21:50.754 | INFO     | src.policies:train:103 - Epoch 236 / 800\n",
      "2021-08-25 11:21:50.755 | INFO     | src.policies:train:109 - Episode 1728\n",
      "2021-08-25 11:21:50.769 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:50.771 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:21:50.772 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.72\n",
      "2021-08-25 11:21:50.774 | INFO     | src.policies:train:109 - Episode 1729\n",
      "2021-08-25 11:21:50.809 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:50.810 | INFO     | src.policies:train:121 - Mean episode return: 78.0\n",
      "2021-08-25 11:21:50.812 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.84\n",
      "2021-08-25 11:21:50.813 | INFO     | src.policies:train:109 - Episode 1730\n",
      "2021-08-25 11:21:50.826 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:50.827 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:50.828 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.46\n",
      "2021-08-25 11:21:50.829 | INFO     | src.policies:train:109 - Episode 1731\n",
      "2021-08-25 11:21:50.840 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:50.842 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:21:50.843 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.24\n",
      "2021-08-25 11:21:50.844 | INFO     | src.policies:train:109 - Episode 1732\n",
      "2021-08-25 11:21:50.854 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:50.856 | INFO     | src.policies:train:121 - Mean episode return: 11.0\n",
      "2021-08-25 11:21:50.857 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.62\n",
      "2021-08-25 11:21:50.858 | INFO     | src.policies:train:109 - Episode 1733\n",
      "2021-08-25 11:21:50.923 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:50.924 | INFO     | src.policies:train:121 - Mean episode return: 160.0\n",
      "2021-08-25 11:21:50.925 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.22\n",
      "2021-08-25 11:21:50.926 | WARNING  | src.policies:train:131 - The actual batch size is 303, instead of 200\n",
      "2021-08-25 11:21:50.934 | INFO     | src.policies:train:157 - Total loss: 1.0033388137817383\n",
      "2021-08-25 11:21:50.937 | INFO     | src.policies:train:103 - Epoch 237 / 800\n",
      "2021-08-25 11:21:50.939 | INFO     | src.policies:train:109 - Episode 1734\n",
      "2021-08-25 11:21:50.953 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:50.954 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:21:50.955 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.34\n",
      "2021-08-25 11:21:50.956 | INFO     | src.policies:train:109 - Episode 1735\n",
      "2021-08-25 11:21:50.975 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:50.977 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 11:21:50.978 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.31\n",
      "2021-08-25 11:21:50.979 | INFO     | src.policies:train:109 - Episode 1736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:50.997 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:50.998 | INFO     | src.policies:train:121 - Mean episode return: 33.0\n",
      "2021-08-25 11:21:51.000 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.39\n",
      "2021-08-25 11:21:51.001 | INFO     | src.policies:train:109 - Episode 1737\n",
      "2021-08-25 11:21:51.015 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:51.016 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:51.018 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.4\n",
      "2021-08-25 11:21:51.019 | INFO     | src.policies:train:109 - Episode 1738\n",
      "2021-08-25 11:21:51.037 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:51.038 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:21:51.040 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.51\n",
      "2021-08-25 11:21:51.041 | INFO     | src.policies:train:109 - Episode 1739\n",
      "2021-08-25 11:21:51.065 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:51.066 | INFO     | src.policies:train:121 - Mean episode return: 45.0\n",
      "2021-08-25 11:21:51.067 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.6\n",
      "2021-08-25 11:21:51.068 | INFO     | src.policies:train:109 - Episode 1740\n",
      "2021-08-25 11:21:51.088 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:51.090 | INFO     | src.policies:train:121 - Mean episode return: 38.0\n",
      "2021-08-25 11:21:51.091 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.84\n",
      "2021-08-25 11:21:51.093 | WARNING  | src.policies:train:131 - The actual batch size is 223, instead of 200\n",
      "2021-08-25 11:21:51.102 | INFO     | src.policies:train:157 - Total loss: 1.0023367404937744\n",
      "2021-08-25 11:21:51.105 | INFO     | src.policies:train:103 - Epoch 238 / 800\n",
      "2021-08-25 11:21:51.107 | INFO     | src.policies:train:109 - Episode 1741\n",
      "2021-08-25 11:21:51.120 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:51.122 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:21:51.124 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.97\n",
      "2021-08-25 11:21:51.125 | INFO     | src.policies:train:109 - Episode 1742\n",
      "2021-08-25 11:21:51.145 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:51.147 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 11:21:51.148 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.03\n",
      "2021-08-25 11:21:51.150 | INFO     | src.policies:train:109 - Episode 1743\n",
      "2021-08-25 11:21:51.164 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:51.165 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:21:51.167 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.59\n",
      "2021-08-25 11:21:51.168 | INFO     | src.policies:train:109 - Episode 1744\n",
      "2021-08-25 11:21:51.200 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:51.202 | INFO     | src.policies:train:121 - Mean episode return: 64.0\n",
      "2021-08-25 11:21:51.203 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.08\n",
      "2021-08-25 11:21:51.204 | INFO     | src.policies:train:109 - Episode 1745\n",
      "2021-08-25 11:21:51.220 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:51.222 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 11:21:51.223 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.19\n",
      "2021-08-25 11:21:51.224 | INFO     | src.policies:train:109 - Episode 1746\n",
      "2021-08-25 11:21:51.245 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:51.246 | INFO     | src.policies:train:121 - Mean episode return: 39.0\n",
      "2021-08-25 11:21:51.247 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.39\n",
      "2021-08-25 11:21:51.248 | WARNING  | src.policies:train:131 - The actual batch size is 207, instead of 200\n",
      "2021-08-25 11:21:51.256 | INFO     | src.policies:train:157 - Total loss: 1.0018362998962402\n",
      "2021-08-25 11:21:51.260 | INFO     | src.policies:train:103 - Epoch 239 / 800\n",
      "2021-08-25 11:21:51.261 | INFO     | src.policies:train:109 - Episode 1747\n",
      "2021-08-25 11:21:51.289 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:51.290 | INFO     | src.policies:train:121 - Mean episode return: 56.0\n",
      "2021-08-25 11:21:51.292 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.76\n",
      "2021-08-25 11:21:51.293 | INFO     | src.policies:train:109 - Episode 1748\n",
      "2021-08-25 11:21:51.307 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:51.308 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:21:51.309 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.34\n",
      "2021-08-25 11:21:51.310 | INFO     | src.policies:train:109 - Episode 1749\n",
      "2021-08-25 11:21:51.333 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:51.334 | INFO     | src.policies:train:121 - Mean episode return: 39.0\n",
      "2021-08-25 11:21:51.335 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.29\n",
      "2021-08-25 11:21:51.336 | INFO     | src.policies:train:109 - Episode 1750\n",
      "2021-08-25 11:21:51.353 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:51.354 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 11:21:51.356 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.89\n",
      "2021-08-25 11:21:51.357 | INFO     | src.policies:train:109 - Episode 1751\n",
      "2021-08-25 11:21:51.376 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:51.378 | INFO     | src.policies:train:121 - Mean episode return: 36.0\n",
      "2021-08-25 11:21:51.379 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.24\n",
      "2021-08-25 11:21:51.380 | INFO     | src.policies:train:109 - Episode 1752\n",
      "2021-08-25 11:21:51.392 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:51.393 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:51.394 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.01\n",
      "2021-08-25 11:21:51.395 | INFO     | src.policies:train:109 - Episode 1753\n",
      "2021-08-25 11:21:51.413 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:51.414 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 11:21:51.415 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.11\n",
      "2021-08-25 11:21:51.417 | WARNING  | src.policies:train:131 - The actual batch size is 226, instead of 200\n",
      "2021-08-25 11:21:51.426 | INFO     | src.policies:train:157 - Total loss: 1.002150297164917\n",
      "2021-08-25 11:21:51.430 | INFO     | src.policies:train:103 - Epoch 240 / 800\n",
      "2021-08-25 11:21:51.431 | INFO     | src.policies:train:109 - Episode 1754\n",
      "2021-08-25 11:21:51.469 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:51.470 | INFO     | src.policies:train:121 - Mean episode return: 88.0\n",
      "2021-08-25 11:21:51.471 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 35.58\n",
      "2021-08-25 11:21:51.473 | INFO     | src.policies:train:109 - Episode 1755\n",
      "2021-08-25 11:21:51.509 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:51.511 | INFO     | src.policies:train:121 - Mean episode return: 84.0\n",
      "2021-08-25 11:21:51.512 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.22\n",
      "2021-08-25 11:21:51.513 | INFO     | src.policies:train:109 - Episode 1756\n",
      "2021-08-25 11:21:51.538 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:51.539 | INFO     | src.policies:train:121 - Mean episode return: 56.0\n",
      "2021-08-25 11:21:51.540 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.57\n",
      "2021-08-25 11:21:51.541 | WARNING  | src.policies:train:131 - The actual batch size is 228, instead of 200\n",
      "2021-08-25 11:21:51.549 | INFO     | src.policies:train:157 - Total loss: 1.002274513244629\n",
      "2021-08-25 11:21:51.553 | INFO     | src.policies:train:103 - Epoch 241 / 800\n",
      "2021-08-25 11:21:51.555 | INFO     | src.policies:train:109 - Episode 1757\n",
      "2021-08-25 11:21:51.575 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:51.576 | INFO     | src.policies:train:121 - Mean episode return: 45.0\n",
      "2021-08-25 11:21:51.578 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.83\n",
      "2021-08-25 11:21:51.579 | INFO     | src.policies:train:109 - Episode 1758\n",
      "2021-08-25 11:21:51.590 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:51.591 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:21:51.592 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.82\n",
      "2021-08-25 11:21:51.594 | INFO     | src.policies:train:109 - Episode 1759\n",
      "2021-08-25 11:21:51.611 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:51.613 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 11:21:51.614 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.91\n",
      "2021-08-25 11:21:51.615 | INFO     | src.policies:train:109 - Episode 1760\n",
      "2021-08-25 11:21:51.658 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:51.660 | INFO     | src.policies:train:121 - Mean episode return: 103.0\n",
      "2021-08-25 11:21:51.661 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.5\n",
      "2021-08-25 11:21:51.662 | INFO     | src.policies:train:109 - Episode 1761\n",
      "2021-08-25 11:21:51.703 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:51.704 | INFO     | src.policies:train:121 - Mean episode return: 98.0\n",
      "2021-08-25 11:21:51.705 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.54\n",
      "2021-08-25 11:21:51.707 | WARNING  | src.policies:train:131 - The actual batch size is 289, instead of 200\n",
      "2021-08-25 11:21:51.715 | INFO     | src.policies:train:157 - Total loss: 1.0031964778900146\n",
      "2021-08-25 11:21:51.719 | INFO     | src.policies:train:103 - Epoch 242 / 800\n",
      "2021-08-25 11:21:51.720 | INFO     | src.policies:train:109 - Episode 1762\n",
      "2021-08-25 11:21:51.730 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:51.732 | INFO     | src.policies:train:121 - Mean episode return: 17.0\n",
      "2021-08-25 11:21:51.733 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.02\n",
      "2021-08-25 11:21:51.734 | INFO     | src.policies:train:109 - Episode 1763\n",
      "2021-08-25 11:21:51.745 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:51.746 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:21:51.747 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.81\n",
      "2021-08-25 11:21:51.748 | INFO     | src.policies:train:109 - Episode 1764\n",
      "2021-08-25 11:21:51.774 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:51.775 | INFO     | src.policies:train:121 - Mean episode return: 56.0\n",
      "2021-08-25 11:21:51.776 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.14\n",
      "2021-08-25 11:21:51.777 | INFO     | src.policies:train:109 - Episode 1765\n",
      "2021-08-25 11:21:51.789 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:51.790 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:21:51.791 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.2\n",
      "2021-08-25 11:21:51.792 | INFO     | src.policies:train:109 - Episode 1766\n",
      "2021-08-25 11:21:51.804 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:51.806 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 11:21:51.806 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 36.99\n",
      "2021-08-25 11:21:51.807 | INFO     | src.policies:train:109 - Episode 1767\n",
      "2021-08-25 11:21:51.825 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:51.827 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 11:21:51.828 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.05\n",
      "2021-08-25 11:21:51.828 | INFO     | src.policies:train:109 - Episode 1768\n",
      "2021-08-25 11:21:51.874 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:51.875 | INFO     | src.policies:train:121 - Mean episode return: 114.0\n",
      "2021-08-25 11:21:51.876 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.96\n",
      "2021-08-25 11:21:51.877 | WARNING  | src.policies:train:131 - The actual batch size is 282, instead of 200\n",
      "2021-08-25 11:21:51.884 | INFO     | src.policies:train:157 - Total loss: 1.0029571056365967\n",
      "2021-08-25 11:21:51.887 | INFO     | src.policies:train:103 - Epoch 243 / 800\n",
      "2021-08-25 11:21:51.888 | INFO     | src.policies:train:109 - Episode 1769\n",
      "2021-08-25 11:21:51.910 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:51.912 | INFO     | src.policies:train:121 - Mean episode return: 53.0\n",
      "2021-08-25 11:21:51.913 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.46\n",
      "2021-08-25 11:21:51.914 | INFO     | src.policies:train:109 - Episode 1770\n",
      "2021-08-25 11:21:51.923 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:51.924 | INFO     | src.policies:train:121 - Mean episode return: 14.0\n",
      "2021-08-25 11:21:51.925 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.42\n",
      "2021-08-25 11:21:51.926 | INFO     | src.policies:train:109 - Episode 1771\n",
      "2021-08-25 11:21:51.937 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:51.938 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:21:51.939 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.08\n",
      "2021-08-25 11:21:51.941 | INFO     | src.policies:train:109 - Episode 1772\n",
      "2021-08-25 11:21:51.964 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:51.966 | INFO     | src.policies:train:121 - Mean episode return: 54.0\n",
      "2021-08-25 11:21:51.967 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.49\n",
      "2021-08-25 11:21:51.968 | INFO     | src.policies:train:109 - Episode 1773\n",
      "2021-08-25 11:21:51.983 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:51.984 | INFO     | src.policies:train:121 - Mean episode return: 30.0\n",
      "2021-08-25 11:21:51.985 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.3\n",
      "2021-08-25 11:21:51.986 | INFO     | src.policies:train:109 - Episode 1774\n",
      "2021-08-25 11:21:52.040 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:52.041 | INFO     | src.policies:train:121 - Mean episode return: 136.0\n",
      "2021-08-25 11:21:52.042 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.14\n",
      "2021-08-25 11:21:52.043 | WARNING  | src.policies:train:131 - The actual batch size is 306, instead of 200\n",
      "2021-08-25 11:21:52.050 | INFO     | src.policies:train:157 - Total loss: 1.0033851861953735\n",
      "2021-08-25 11:21:52.053 | INFO     | src.policies:train:103 - Epoch 244 / 800\n",
      "2021-08-25 11:21:52.054 | INFO     | src.policies:train:109 - Episode 1775\n",
      "2021-08-25 11:21:52.061 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:52.063 | INFO     | src.policies:train:121 - Mean episode return: 13.0\n",
      "2021-08-25 11:21:52.064 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:52.064 | INFO     | src.policies:train:109 - Episode 1776\n",
      "2021-08-25 11:21:52.085 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:52.086 | INFO     | src.policies:train:121 - Mean episode return: 47.0\n",
      "2021-08-25 11:21:52.087 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.82\n",
      "2021-08-25 11:21:52.088 | INFO     | src.policies:train:109 - Episode 1777\n",
      "2021-08-25 11:21:52.102 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:52.103 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:21:52.104 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.96\n",
      "2021-08-25 11:21:52.105 | INFO     | src.policies:train:109 - Episode 1778\n",
      "2021-08-25 11:21:52.115 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:52.117 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:52.118 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.86\n",
      "2021-08-25 11:21:52.119 | INFO     | src.policies:train:109 - Episode 1779\n",
      "2021-08-25 11:21:52.135 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:52.136 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 11:21:52.137 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.43\n",
      "2021-08-25 11:21:52.138 | INFO     | src.policies:train:109 - Episode 1780\n",
      "2021-08-25 11:21:52.160 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:52.161 | INFO     | src.policies:train:121 - Mean episode return: 50.0\n",
      "2021-08-25 11:21:52.162 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.47\n",
      "2021-08-25 11:21:52.163 | INFO     | src.policies:train:109 - Episode 1781\n",
      "2021-08-25 11:21:52.191 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:52.193 | INFO     | src.policies:train:121 - Mean episode return: 67.0\n",
      "2021-08-25 11:21:52.194 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.89\n",
      "2021-08-25 11:21:52.195 | WARNING  | src.policies:train:131 - The actual batch size is 251, instead of 200\n",
      "2021-08-25 11:21:52.202 | INFO     | src.policies:train:157 - Total loss: 1.0026487112045288\n",
      "2021-08-25 11:21:52.205 | INFO     | src.policies:train:103 - Epoch 245 / 800\n",
      "2021-08-25 11:21:52.206 | INFO     | src.policies:train:109 - Episode 1782\n",
      "2021-08-25 11:21:52.216 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:52.217 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:21:52.218 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.94\n",
      "2021-08-25 11:21:52.219 | INFO     | src.policies:train:109 - Episode 1783\n",
      "2021-08-25 11:21:52.228 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:52.230 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:52.231 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.84\n",
      "2021-08-25 11:21:52.232 | INFO     | src.policies:train:109 - Episode 1784\n",
      "2021-08-25 11:21:52.247 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:52.249 | INFO     | src.policies:train:121 - Mean episode return: 32.0\n",
      "2021-08-25 11:21:52.250 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 37.77\n",
      "2021-08-25 11:21:52.251 | INFO     | src.policies:train:109 - Episode 1785\n",
      "2021-08-25 11:21:52.276 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:52.277 | INFO     | src.policies:train:121 - Mean episode return: 57.0\n",
      "2021-08-25 11:21:52.278 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.17\n",
      "2021-08-25 11:21:52.279 | INFO     | src.policies:train:109 - Episode 1786\n",
      "2021-08-25 11:21:52.305 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:52.306 | INFO     | src.policies:train:121 - Mean episode return: 60.0\n",
      "2021-08-25 11:21:52.307 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.43\n",
      "2021-08-25 11:21:52.308 | INFO     | src.policies:train:109 - Episode 1787\n",
      "2021-08-25 11:21:52.343 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:52.344 | INFO     | src.policies:train:121 - Mean episode return: 82.0\n",
      "2021-08-25 11:21:52.345 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.02\n",
      "2021-08-25 11:21:52.346 | WARNING  | src.policies:train:131 - The actual batch size is 268, instead of 200\n",
      "2021-08-25 11:21:52.353 | INFO     | src.policies:train:157 - Total loss: 1.0027849674224854\n",
      "2021-08-25 11:21:52.356 | INFO     | src.policies:train:103 - Epoch 246 / 800\n",
      "2021-08-25 11:21:52.357 | INFO     | src.policies:train:109 - Episode 1788\n",
      "2021-08-25 11:21:52.369 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:52.370 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:21:52.371 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 38.94\n",
      "2021-08-25 11:21:52.372 | INFO     | src.policies:train:109 - Episode 1789\n",
      "2021-08-25 11:21:52.391 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:52.392 | INFO     | src.policies:train:121 - Mean episode return: 43.0\n",
      "2021-08-25 11:21:52.394 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.07\n",
      "2021-08-25 11:21:52.394 | INFO     | src.policies:train:109 - Episode 1790\n",
      "2021-08-25 11:21:52.411 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:52.412 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 11:21:52.413 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.2\n",
      "2021-08-25 11:21:52.414 | INFO     | src.policies:train:109 - Episode 1791\n",
      "2021-08-25 11:21:52.428 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:52.430 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 11:21:52.431 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.27\n",
      "2021-08-25 11:21:52.432 | INFO     | src.policies:train:109 - Episode 1792\n",
      "2021-08-25 11:21:52.446 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:52.447 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:21:52.448 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.35\n",
      "2021-08-25 11:21:52.449 | INFO     | src.policies:train:109 - Episode 1793\n",
      "2021-08-25 11:21:52.464 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:52.465 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 11:21:52.466 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.26\n",
      "2021-08-25 11:21:52.467 | INFO     | src.policies:train:109 - Episode 1794\n",
      "2021-08-25 11:21:52.483 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:52.484 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 11:21:52.485 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.14\n",
      "2021-08-25 11:21:52.486 | WARNING  | src.policies:train:131 - The actual batch size is 215, instead of 200\n",
      "2021-08-25 11:21:52.494 | INFO     | src.policies:train:157 - Total loss: 1.0017932653427124\n",
      "2021-08-25 11:21:52.497 | INFO     | src.policies:train:103 - Epoch 247 / 800\n",
      "2021-08-25 11:21:52.498 | INFO     | src.policies:train:109 - Episode 1795\n",
      "2021-08-25 11:21:52.550 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:52.551 | INFO     | src.policies:train:121 - Mean episode return: 130.0\n",
      "2021-08-25 11:21:52.552 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 40.24\n",
      "2021-08-25 11:21:52.553 | INFO     | src.policies:train:109 - Episode 1796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:52.562 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:52.563 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:52.564 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 39.95\n",
      "2021-08-25 11:21:52.565 | INFO     | src.policies:train:109 - Episode 1797\n",
      "2021-08-25 11:21:52.596 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:52.597 | INFO     | src.policies:train:121 - Mean episode return: 72.0\n",
      "2021-08-25 11:21:52.598 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 40.53\n",
      "2021-08-25 11:21:52.599 | WARNING  | src.policies:train:131 - The actual batch size is 217, instead of 200\n",
      "2021-08-25 11:21:52.606 | INFO     | src.policies:train:157 - Total loss: 1.002049207687378\n",
      "2021-08-25 11:21:52.609 | INFO     | src.policies:train:103 - Epoch 248 / 800\n",
      "2021-08-25 11:21:52.610 | INFO     | src.policies:train:109 - Episode 1798\n",
      "2021-08-25 11:21:52.624 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:52.625 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 11:21:52.626 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 40.63\n",
      "2021-08-25 11:21:52.627 | INFO     | src.policies:train:109 - Episode 1799\n",
      "2021-08-25 11:21:52.640 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:52.642 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:21:52.643 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 40.24\n",
      "2021-08-25 11:21:52.644 | INFO     | src.policies:train:109 - Episode 1800\n",
      "2021-08-25 11:21:52.679 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:52.680 | INFO     | src.policies:train:121 - Mean episode return: 84.0\n",
      "2021-08-25 11:21:52.681 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 40.87\n",
      "2021-08-25 11:21:52.682 | INFO     | src.policies:train:109 - Episode 1801\n",
      "2021-08-25 11:21:52.700 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:52.701 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 11:21:52.702 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 41.06\n",
      "2021-08-25 11:21:52.703 | INFO     | src.policies:train:109 - Episode 1802\n",
      "2021-08-25 11:21:52.720 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:52.721 | INFO     | src.policies:train:121 - Mean episode return: 39.0\n",
      "2021-08-25 11:21:52.722 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 41.15\n",
      "2021-08-25 11:21:52.723 | WARNING  | src.policies:train:131 - The actual batch size is 214, instead of 200\n",
      "2021-08-25 11:21:52.730 | INFO     | src.policies:train:157 - Total loss: 1.0017837285995483\n",
      "2021-08-25 11:21:52.733 | INFO     | src.policies:train:103 - Epoch 249 / 800\n",
      "2021-08-25 11:21:52.734 | INFO     | src.policies:train:109 - Episode 1803\n",
      "2021-08-25 11:21:52.755 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:52.756 | INFO     | src.policies:train:121 - Mean episode return: 48.0\n",
      "2021-08-25 11:21:52.757 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 41.25\n",
      "2021-08-25 11:21:52.758 | INFO     | src.policies:train:109 - Episode 1804\n",
      "2021-08-25 11:21:52.776 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:52.777 | INFO     | src.policies:train:121 - Mean episode return: 39.0\n",
      "2021-08-25 11:21:52.778 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 41.07\n",
      "2021-08-25 11:21:52.779 | INFO     | src.policies:train:109 - Episode 1805\n",
      "2021-08-25 11:21:52.793 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:52.795 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:21:52.796 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 41.27\n",
      "2021-08-25 11:21:52.796 | INFO     | src.policies:train:109 - Episode 1806\n",
      "2021-08-25 11:21:52.805 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:52.806 | INFO     | src.policies:train:121 - Mean episode return: 12.0\n",
      "2021-08-25 11:21:52.807 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 41.05\n",
      "2021-08-25 11:21:52.808 | INFO     | src.policies:train:109 - Episode 1807\n",
      "2021-08-25 11:21:52.834 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:52.835 | INFO     | src.policies:train:121 - Mean episode return: 57.0\n",
      "2021-08-25 11:21:52.836 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 40.73\n",
      "2021-08-25 11:21:52.837 | INFO     | src.policies:train:109 - Episode 1808\n",
      "2021-08-25 11:21:52.849 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:52.851 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:21:52.851 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 40.45\n",
      "2021-08-25 11:21:52.852 | WARNING  | src.policies:train:131 - The actual batch size is 205, instead of 200\n",
      "2021-08-25 11:21:52.860 | INFO     | src.policies:train:157 - Total loss: 1.0014801025390625\n",
      "2021-08-25 11:21:52.863 | INFO     | src.policies:train:103 - Epoch 250 / 800\n",
      "2021-08-25 11:21:52.864 | INFO     | src.policies:train:109 - Episode 1809\n",
      "2021-08-25 11:21:52.874 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:52.875 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:21:52.876 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 40.05\n",
      "2021-08-25 11:21:52.877 | INFO     | src.policies:train:109 - Episode 1810\n",
      "2021-08-25 11:21:52.903 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:52.904 | INFO     | src.policies:train:121 - Mean episode return: 58.0\n",
      "2021-08-25 11:21:52.905 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 40.49\n",
      "2021-08-25 11:21:52.906 | INFO     | src.policies:train:109 - Episode 1811\n",
      "2021-08-25 11:21:52.961 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:52.962 | INFO     | src.policies:train:121 - Mean episode return: 136.0\n",
      "2021-08-25 11:21:52.963 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 41.66\n",
      "2021-08-25 11:21:52.964 | WARNING  | src.policies:train:131 - The actual batch size is 213, instead of 200\n",
      "2021-08-25 11:21:52.970 | INFO     | src.policies:train:157 - Total loss: 1.0018483400344849\n",
      "2021-08-25 11:21:52.974 | INFO     | src.policies:train:103 - Epoch 251 / 800\n",
      "2021-08-25 11:21:52.975 | INFO     | src.policies:train:109 - Episode 1812\n",
      "2021-08-25 11:21:53.012 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:53.014 | INFO     | src.policies:train:121 - Mean episode return: 92.0\n",
      "2021-08-25 11:21:53.015 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 42.31\n",
      "2021-08-25 11:21:53.016 | INFO     | src.policies:train:109 - Episode 1813\n",
      "2021-08-25 11:21:53.049 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:53.051 | INFO     | src.policies:train:121 - Mean episode return: 83.0\n",
      "2021-08-25 11:21:53.052 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 42.98\n",
      "2021-08-25 11:21:53.053 | INFO     | src.policies:train:109 - Episode 1814\n",
      "2021-08-25 11:21:53.089 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:53.090 | INFO     | src.policies:train:121 - Mean episode return: 87.0\n",
      "2021-08-25 11:21:53.091 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 43.69\n",
      "2021-08-25 11:21:53.092 | WARNING  | src.policies:train:131 - The actual batch size is 262, instead of 200\n",
      "2021-08-25 11:21:53.098 | INFO     | src.policies:train:157 - Total loss: 1.002600073814392\n",
      "2021-08-25 11:21:53.101 | INFO     | src.policies:train:103 - Epoch 252 / 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:53.103 | INFO     | src.policies:train:109 - Episode 1815\n",
      "2021-08-25 11:21:53.124 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:53.126 | INFO     | src.policies:train:121 - Mean episode return: 51.0\n",
      "2021-08-25 11:21:53.127 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 43.84\n",
      "2021-08-25 11:21:53.128 | INFO     | src.policies:train:109 - Episode 1816\n",
      "2021-08-25 11:21:53.167 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:53.168 | INFO     | src.policies:train:121 - Mean episode return: 98.0\n",
      "2021-08-25 11:21:53.169 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 44.68\n",
      "2021-08-25 11:21:53.170 | INFO     | src.policies:train:109 - Episode 1817\n",
      "2021-08-25 11:21:53.184 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:53.185 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:21:53.186 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 44.65\n",
      "2021-08-25 11:21:53.187 | INFO     | src.policies:train:109 - Episode 1818\n",
      "2021-08-25 11:21:53.198 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:53.200 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n",
      "2021-08-25 11:21:53.200 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 44.6\n",
      "2021-08-25 11:21:53.201 | INFO     | src.policies:train:109 - Episode 1819\n",
      "2021-08-25 11:21:53.214 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:53.215 | INFO     | src.policies:train:121 - Mean episode return: 25.0\n",
      "2021-08-25 11:21:53.216 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 44.4\n",
      "2021-08-25 11:21:53.217 | WARNING  | src.policies:train:131 - The actual batch size is 219, instead of 200\n",
      "2021-08-25 11:21:53.224 | INFO     | src.policies:train:157 - Total loss: 1.0019407272338867\n",
      "2021-08-25 11:21:53.227 | INFO     | src.policies:train:103 - Epoch 253 / 800\n",
      "2021-08-25 11:21:53.228 | INFO     | src.policies:train:109 - Episode 1820\n",
      "2021-08-25 11:21:53.241 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:53.242 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 11:21:53.243 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 44.41\n",
      "2021-08-25 11:21:53.244 | INFO     | src.policies:train:109 - Episode 1821\n",
      "2021-08-25 11:21:53.272 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:53.273 | INFO     | src.policies:train:121 - Mean episode return: 67.0\n",
      "2021-08-25 11:21:53.274 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 44.76\n",
      "2021-08-25 11:21:53.275 | INFO     | src.policies:train:109 - Episode 1822\n",
      "2021-08-25 11:21:53.285 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:53.286 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:53.287 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 44.72\n",
      "2021-08-25 11:21:53.288 | INFO     | src.policies:train:109 - Episode 1823\n",
      "2021-08-25 11:21:53.306 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:53.308 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 11:21:53.309 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 44.74\n",
      "2021-08-25 11:21:53.310 | INFO     | src.policies:train:109 - Episode 1824\n",
      "2021-08-25 11:21:53.342 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:53.343 | INFO     | src.policies:train:121 - Mean episode return: 75.0\n",
      "2021-08-25 11:21:53.344 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 45.32\n",
      "2021-08-25 11:21:53.345 | WARNING  | src.policies:train:131 - The actual batch size is 220, instead of 200\n",
      "2021-08-25 11:21:53.352 | INFO     | src.policies:train:157 - Total loss: 1.0019499063491821\n",
      "2021-08-25 11:21:53.355 | INFO     | src.policies:train:103 - Epoch 254 / 800\n",
      "2021-08-25 11:21:53.356 | INFO     | src.policies:train:109 - Episode 1825\n",
      "2021-08-25 11:21:53.373 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:53.374 | INFO     | src.policies:train:121 - Mean episode return: 37.0\n",
      "2021-08-25 11:21:53.375 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 44.91\n",
      "2021-08-25 11:21:53.376 | INFO     | src.policies:train:109 - Episode 1826\n",
      "2021-08-25 11:21:53.424 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:53.425 | INFO     | src.policies:train:121 - Mean episode return: 110.0\n",
      "2021-08-25 11:21:53.426 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 45.1\n",
      "2021-08-25 11:21:53.427 | INFO     | src.policies:train:109 - Episode 1827\n",
      "2021-08-25 11:21:53.445 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:53.446 | INFO     | src.policies:train:121 - Mean episode return: 38.0\n",
      "2021-08-25 11:21:53.448 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 45.33\n",
      "2021-08-25 11:21:53.448 | INFO     | src.policies:train:109 - Episode 1828\n",
      "2021-08-25 11:21:53.523 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:53.524 | INFO     | src.policies:train:121 - Mean episode return: 196.0\n",
      "2021-08-25 11:21:53.525 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 47.03\n",
      "2021-08-25 11:21:53.526 | WARNING  | src.policies:train:131 - The actual batch size is 381, instead of 200\n",
      "2021-08-25 11:21:53.533 | INFO     | src.policies:train:157 - Total loss: 1.0039173364639282\n",
      "2021-08-25 11:21:53.536 | INFO     | src.policies:train:103 - Epoch 255 / 800\n",
      "2021-08-25 11:21:53.538 | INFO     | src.policies:train:109 - Episode 1829\n",
      "2021-08-25 11:21:53.568 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:53.570 | INFO     | src.policies:train:121 - Mean episode return: 73.0\n",
      "2021-08-25 11:21:53.571 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 46.98\n",
      "2021-08-25 11:21:53.572 | INFO     | src.policies:train:109 - Episode 1830\n",
      "2021-08-25 11:21:53.584 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:53.585 | INFO     | src.policies:train:121 - Mean episode return: 23.0\n",
      "2021-08-25 11:21:53.586 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 47.04\n",
      "2021-08-25 11:21:53.587 | INFO     | src.policies:train:109 - Episode 1831\n",
      "2021-08-25 11:21:53.623 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:53.624 | INFO     | src.policies:train:121 - Mean episode return: 90.0\n",
      "2021-08-25 11:21:53.625 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 47.83\n",
      "2021-08-25 11:21:53.626 | INFO     | src.policies:train:109 - Episode 1832\n",
      "2021-08-25 11:21:53.661 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:53.663 | INFO     | src.policies:train:121 - Mean episode return: 87.0\n",
      "2021-08-25 11:21:53.664 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 48.59\n",
      "2021-08-25 11:21:53.665 | WARNING  | src.policies:train:131 - The actual batch size is 273, instead of 200\n",
      "2021-08-25 11:21:53.672 | INFO     | src.policies:train:157 - Total loss: 1.0027145147323608\n",
      "2021-08-25 11:21:53.675 | INFO     | src.policies:train:103 - Epoch 256 / 800\n",
      "2021-08-25 11:21:53.676 | INFO     | src.policies:train:109 - Episode 1833\n",
      "2021-08-25 11:21:53.718 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:53.719 | INFO     | src.policies:train:121 - Mean episode return: 106.0\n",
      "2021-08-25 11:21:53.720 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 48.05\n",
      "2021-08-25 11:21:53.721 | INFO     | src.policies:train:109 - Episode 1834\n",
      "2021-08-25 11:21:53.769 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:53.771 | INFO     | src.policies:train:121 - Mean episode return: 126.0\n",
      "2021-08-25 11:21:53.772 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 49.02\n",
      "2021-08-25 11:21:53.773 | WARNING  | src.policies:train:131 - The actual batch size is 232, instead of 200\n",
      "2021-08-25 11:21:53.779 | INFO     | src.policies:train:157 - Total loss: 1.0020813941955566\n",
      "2021-08-25 11:21:53.782 | INFO     | src.policies:train:103 - Epoch 257 / 800\n",
      "2021-08-25 11:21:53.783 | INFO     | src.policies:train:109 - Episode 1835\n",
      "2021-08-25 11:21:53.797 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:53.798 | INFO     | src.policies:train:121 - Mean episode return: 29.0\n",
      "2021-08-25 11:21:53.799 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 48.98\n",
      "2021-08-25 11:21:53.800 | INFO     | src.policies:train:109 - Episode 1836\n",
      "2021-08-25 11:21:53.814 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:53.815 | INFO     | src.policies:train:121 - Mean episode return: 28.0\n",
      "2021-08-25 11:21:53.816 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 48.93\n",
      "2021-08-25 11:21:53.817 | INFO     | src.policies:train:109 - Episode 1837\n",
      "2021-08-25 11:21:53.877 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:53.878 | INFO     | src.policies:train:121 - Mean episode return: 154.0\n",
      "2021-08-25 11:21:53.879 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 50.31\n",
      "2021-08-25 11:21:53.880 | WARNING  | src.policies:train:131 - The actual batch size is 211, instead of 200\n",
      "2021-08-25 11:21:53.887 | INFO     | src.policies:train:157 - Total loss: 1.001676082611084\n",
      "2021-08-25 11:21:53.890 | INFO     | src.policies:train:103 - Epoch 258 / 800\n",
      "2021-08-25 11:21:53.891 | INFO     | src.policies:train:109 - Episode 1838\n",
      "2021-08-25 11:21:53.913 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:53.915 | INFO     | src.policies:train:121 - Mean episode return: 54.0\n",
      "2021-08-25 11:21:53.915 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 50.56\n",
      "2021-08-25 11:21:53.916 | INFO     | src.policies:train:109 - Episode 1839\n",
      "2021-08-25 11:21:53.932 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:53.933 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 11:21:53.934 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 50.42\n",
      "2021-08-25 11:21:53.935 | INFO     | src.policies:train:109 - Episode 1840\n",
      "2021-08-25 11:21:53.995 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:53.996 | INFO     | src.policies:train:121 - Mean episode return: 151.0\n",
      "2021-08-25 11:21:53.997 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 51.55\n",
      "2021-08-25 11:21:53.998 | WARNING  | src.policies:train:131 - The actual batch size is 236, instead of 200\n",
      "2021-08-25 11:21:54.005 | INFO     | src.policies:train:157 - Total loss: 1.002280831336975\n",
      "2021-08-25 11:21:54.008 | INFO     | src.policies:train:103 - Epoch 259 / 800\n",
      "2021-08-25 11:21:54.009 | INFO     | src.policies:train:109 - Episode 1841\n",
      "2021-08-25 11:21:54.032 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:54.034 | INFO     | src.policies:train:121 - Mean episode return: 54.0\n",
      "2021-08-25 11:21:54.035 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 51.83\n",
      "2021-08-25 11:21:54.035 | INFO     | src.policies:train:109 - Episode 1842\n",
      "2021-08-25 11:21:54.060 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:54.061 | INFO     | src.policies:train:121 - Mean episode return: 53.0\n",
      "2021-08-25 11:21:54.062 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 52.02\n",
      "2021-08-25 11:21:54.063 | INFO     | src.policies:train:109 - Episode 1843\n",
      "2021-08-25 11:21:54.088 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:54.090 | INFO     | src.policies:train:121 - Mean episode return: 56.0\n",
      "2021-08-25 11:21:54.091 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 52.39\n",
      "2021-08-25 11:21:54.092 | INFO     | src.policies:train:109 - Episode 1844\n",
      "2021-08-25 11:21:54.101 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:54.102 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:21:54.103 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 51.9\n",
      "2021-08-25 11:21:54.104 | INFO     | src.policies:train:109 - Episode 1845\n",
      "2021-08-25 11:21:54.117 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:54.118 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:21:54.119 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 51.86\n",
      "2021-08-25 11:21:54.120 | INFO     | src.policies:train:109 - Episode 1846\n",
      "2021-08-25 11:21:54.170 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:54.171 | INFO     | src.policies:train:121 - Mean episode return: 127.0\n",
      "2021-08-25 11:21:54.172 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 52.74\n",
      "2021-08-25 11:21:54.173 | WARNING  | src.policies:train:131 - The actual batch size is 326, instead of 200\n",
      "2021-08-25 11:21:54.180 | INFO     | src.policies:train:157 - Total loss: 1.0033259391784668\n",
      "2021-08-25 11:21:54.184 | INFO     | src.policies:train:103 - Epoch 260 / 800\n",
      "2021-08-25 11:21:54.185 | INFO     | src.policies:train:109 - Episode 1847\n",
      "2021-08-25 11:21:54.208 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:54.210 | INFO     | src.policies:train:121 - Mean episode return: 55.0\n",
      "2021-08-25 11:21:54.211 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 52.73\n",
      "2021-08-25 11:21:54.212 | INFO     | src.policies:train:109 - Episode 1848\n",
      "2021-08-25 11:21:54.289 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:54.291 | INFO     | src.policies:train:121 - Mean episode return: 195.0\n",
      "2021-08-25 11:21:54.292 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 54.5\n",
      "2021-08-25 11:21:54.293 | WARNING  | src.policies:train:131 - The actual batch size is 250, instead of 200\n",
      "2021-08-25 11:21:54.299 | INFO     | src.policies:train:157 - Total loss: 1.0024462938308716\n",
      "2021-08-25 11:21:54.302 | INFO     | src.policies:train:103 - Epoch 261 / 800\n",
      "2021-08-25 11:21:54.303 | INFO     | src.policies:train:109 - Episode 1849\n",
      "2021-08-25 11:21:54.340 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:54.341 | INFO     | src.policies:train:121 - Mean episode return: 90.0\n",
      "2021-08-25 11:21:54.342 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 55.01\n",
      "2021-08-25 11:21:54.343 | INFO     | src.policies:train:109 - Episode 1850\n",
      "2021-08-25 11:21:54.383 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:54.384 | INFO     | src.policies:train:121 - Mean episode return: 97.0\n",
      "2021-08-25 11:21:54.385 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 55.73\n",
      "2021-08-25 11:21:54.386 | INFO     | src.policies:train:109 - Episode 1851\n",
      "2021-08-25 11:21:54.423 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:54.425 | INFO     | src.policies:train:121 - Mean episode return: 82.0\n",
      "2021-08-25 11:21:54.426 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 56.19\n",
      "2021-08-25 11:21:54.427 | WARNING  | src.policies:train:131 - The actual batch size is 269, instead of 200\n",
      "2021-08-25 11:21:54.436 | INFO     | src.policies:train:157 - Total loss: 1.002562403678894\n",
      "2021-08-25 11:21:54.440 | INFO     | src.policies:train:103 - Epoch 262 / 800\n",
      "2021-08-25 11:21:54.441 | INFO     | src.policies:train:109 - Episode 1852\n",
      "2021-08-25 11:21:54.456 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:54.458 | INFO     | src.policies:train:121 - Mean episode return: 31.0\n",
      "2021-08-25 11:21:54.459 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 56.33\n",
      "2021-08-25 11:21:54.460 | INFO     | src.policies:train:109 - Episode 1853\n",
      "2021-08-25 11:21:54.505 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:54.506 | INFO     | src.policies:train:121 - Mean episode return: 105.0\n",
      "2021-08-25 11:21:54.508 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 57.03\n",
      "2021-08-25 11:21:54.509 | INFO     | src.policies:train:109 - Episode 1854\n",
      "2021-08-25 11:21:54.568 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:54.570 | INFO     | src.policies:train:121 - Mean episode return: 146.0\n",
      "2021-08-25 11:21:54.571 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 57.61\n",
      "2021-08-25 11:21:54.572 | WARNING  | src.policies:train:131 - The actual batch size is 282, instead of 200\n",
      "2021-08-25 11:21:54.579 | INFO     | src.policies:train:157 - Total loss: 1.002808690071106\n",
      "2021-08-25 11:21:54.582 | INFO     | src.policies:train:103 - Epoch 263 / 800\n",
      "2021-08-25 11:21:54.583 | INFO     | src.policies:train:109 - Episode 1855\n",
      "2021-08-25 11:21:54.592 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:54.594 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:21:54.595 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 56.97\n",
      "2021-08-25 11:21:54.596 | INFO     | src.policies:train:109 - Episode 1856\n",
      "2021-08-25 11:21:54.611 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:54.613 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 11:21:54.614 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 56.75\n",
      "2021-08-25 11:21:54.615 | INFO     | src.policies:train:109 - Episode 1857\n",
      "2021-08-25 11:21:54.638 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:54.639 | INFO     | src.policies:train:121 - Mean episode return: 46.0\n",
      "2021-08-25 11:21:54.640 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 56.76\n",
      "2021-08-25 11:21:54.641 | INFO     | src.policies:train:109 - Episode 1858\n",
      "2021-08-25 11:21:54.718 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:54.719 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:21:54.720 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 58.63\n",
      "2021-08-25 11:21:54.721 | WARNING  | src.policies:train:131 - The actual batch size is 300, instead of 200\n",
      "2021-08-25 11:21:54.728 | INFO     | src.policies:train:157 - Total loss: 1.003085732460022\n",
      "2021-08-25 11:21:54.731 | INFO     | src.policies:train:103 - Epoch 264 / 800\n",
      "2021-08-25 11:21:54.732 | INFO     | src.policies:train:109 - Episode 1859\n",
      "2021-08-25 11:21:54.750 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:54.751 | INFO     | src.policies:train:121 - Mean episode return: 44.0\n",
      "2021-08-25 11:21:54.753 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 58.77\n",
      "2021-08-25 11:21:54.753 | INFO     | src.policies:train:109 - Episode 1860\n",
      "2021-08-25 11:21:54.779 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:54.781 | INFO     | src.policies:train:121 - Mean episode return: 59.0\n",
      "2021-08-25 11:21:54.782 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 58.33\n",
      "2021-08-25 11:21:54.783 | INFO     | src.policies:train:109 - Episode 1861\n",
      "2021-08-25 11:21:54.802 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:54.804 | INFO     | src.policies:train:121 - Mean episode return: 42.0\n",
      "2021-08-25 11:21:54.804 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 57.77\n",
      "2021-08-25 11:21:54.805 | INFO     | src.policies:train:109 - Episode 1862\n",
      "2021-08-25 11:21:54.881 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:54.882 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:21:54.883 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 59.6\n",
      "2021-08-25 11:21:54.884 | WARNING  | src.policies:train:131 - The actual batch size is 345, instead of 200\n",
      "2021-08-25 11:21:54.891 | INFO     | src.policies:train:157 - Total loss: 1.00346839427948\n",
      "2021-08-25 11:21:54.894 | INFO     | src.policies:train:103 - Epoch 265 / 800\n",
      "2021-08-25 11:21:54.895 | INFO     | src.policies:train:109 - Episode 1863\n",
      "2021-08-25 11:21:54.955 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:54.956 | INFO     | src.policies:train:121 - Mean episode return: 152.0\n",
      "2021-08-25 11:21:54.958 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 60.99\n",
      "2021-08-25 11:21:54.958 | INFO     | src.policies:train:109 - Episode 1864\n",
      "2021-08-25 11:21:55.012 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:55.013 | INFO     | src.policies:train:121 - Mean episode return: 136.0\n",
      "2021-08-25 11:21:55.014 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 61.79\n",
      "2021-08-25 11:21:55.015 | WARNING  | src.policies:train:131 - The actual batch size is 288, instead of 200\n",
      "2021-08-25 11:21:55.021 | INFO     | src.policies:train:157 - Total loss: 1.0028823614120483\n",
      "2021-08-25 11:21:55.025 | INFO     | src.policies:train:103 - Epoch 266 / 800\n",
      "2021-08-25 11:21:55.026 | INFO     | src.policies:train:109 - Episode 1865\n",
      "2021-08-25 11:21:55.066 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:55.067 | INFO     | src.policies:train:121 - Mean episode return: 105.0\n",
      "2021-08-25 11:21:55.068 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 62.62\n",
      "2021-08-25 11:21:55.069 | INFO     | src.policies:train:109 - Episode 1866\n",
      "2021-08-25 11:21:55.109 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:55.111 | INFO     | src.policies:train:121 - Mean episode return: 97.0\n",
      "2021-08-25 11:21:55.112 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 63.34\n",
      "2021-08-25 11:21:55.113 | WARNING  | src.policies:train:131 - The actual batch size is 202, instead of 200\n",
      "2021-08-25 11:21:55.119 | INFO     | src.policies:train:157 - Total loss: 1.001081109046936\n",
      "2021-08-25 11:21:55.122 | INFO     | src.policies:train:103 - Epoch 267 / 800\n",
      "2021-08-25 11:21:55.123 | INFO     | src.policies:train:109 - Episode 1867\n",
      "2021-08-25 11:21:55.132 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:55.133 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:21:55.134 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 63.17\n",
      "2021-08-25 11:21:55.135 | INFO     | src.policies:train:109 - Episode 1868\n",
      "2021-08-25 11:21:55.180 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:55.181 | INFO     | src.policies:train:121 - Mean episode return: 115.0\n",
      "2021-08-25 11:21:55.182 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 63.18\n",
      "2021-08-25 11:21:55.183 | INFO     | src.policies:train:109 - Episode 1869\n",
      "2021-08-25 11:21:55.228 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:55.229 | INFO     | src.policies:train:121 - Mean episode return: 113.0\n",
      "2021-08-25 11:21:55.230 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 63.78\n",
      "2021-08-25 11:21:55.231 | WARNING  | src.policies:train:131 - The actual batch size is 246, instead of 200\n",
      "2021-08-25 11:21:55.238 | INFO     | src.policies:train:157 - Total loss: 1.0022304058074951\n",
      "2021-08-25 11:21:55.241 | INFO     | src.policies:train:103 - Epoch 268 / 800\n",
      "2021-08-25 11:21:55.242 | INFO     | src.policies:train:109 - Episode 1870\n",
      "2021-08-25 11:21:55.293 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:55.295 | INFO     | src.policies:train:121 - Mean episode return: 134.0\n",
      "2021-08-25 11:21:55.296 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 64.98\n",
      "2021-08-25 11:21:55.296 | INFO     | src.policies:train:109 - Episode 1871\n",
      "2021-08-25 11:21:55.337 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:55.338 | INFO     | src.policies:train:121 - Mean episode return: 95.0\n",
      "2021-08-25 11:21:55.339 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 65.74\n",
      "2021-08-25 11:21:55.340 | WARNING  | src.policies:train:131 - The actual batch size is 229, instead of 200\n",
      "2021-08-25 11:21:55.347 | INFO     | src.policies:train:157 - Total loss: 1.0019248723983765\n",
      "2021-08-25 11:21:55.350 | INFO     | src.policies:train:103 - Epoch 269 / 800\n",
      "2021-08-25 11:21:55.351 | INFO     | src.policies:train:109 - Episode 1872\n",
      "2021-08-25 11:21:55.384 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:55.386 | INFO     | src.policies:train:121 - Mean episode return: 83.0\n",
      "2021-08-25 11:21:55.387 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 66.03\n",
      "2021-08-25 11:21:55.387 | INFO     | src.policies:train:109 - Episode 1873\n",
      "2021-08-25 11:21:55.424 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:55.426 | INFO     | src.policies:train:121 - Mean episode return: 91.0\n",
      "2021-08-25 11:21:55.427 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 66.64\n",
      "2021-08-25 11:21:55.428 | INFO     | src.policies:train:109 - Episode 1874\n",
      "2021-08-25 11:21:55.499 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:55.500 | INFO     | src.policies:train:121 - Mean episode return: 187.0\n",
      "2021-08-25 11:21:55.501 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 67.15\n",
      "2021-08-25 11:21:55.502 | WARNING  | src.policies:train:131 - The actual batch size is 361, instead of 200\n",
      "2021-08-25 11:21:55.509 | INFO     | src.policies:train:157 - Total loss: 1.0034490823745728\n",
      "2021-08-25 11:21:55.512 | INFO     | src.policies:train:103 - Epoch 270 / 800\n",
      "2021-08-25 11:21:55.513 | INFO     | src.policies:train:109 - Episode 1875\n",
      "2021-08-25 11:21:55.566 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:55.567 | INFO     | src.policies:train:121 - Mean episode return: 135.0\n",
      "2021-08-25 11:21:55.568 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 68.37\n",
      "2021-08-25 11:21:55.569 | INFO     | src.policies:train:109 - Episode 1876\n",
      "2021-08-25 11:21:55.616 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:55.617 | INFO     | src.policies:train:121 - Mean episode return: 120.0\n",
      "2021-08-25 11:21:55.618 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 69.1\n",
      "2021-08-25 11:21:55.619 | WARNING  | src.policies:train:131 - The actual batch size is 255, instead of 200\n",
      "2021-08-25 11:21:55.628 | INFO     | src.policies:train:157 - Total loss: 1.0022470951080322\n",
      "2021-08-25 11:21:55.631 | INFO     | src.policies:train:103 - Epoch 271 / 800\n",
      "2021-08-25 11:21:55.632 | INFO     | src.policies:train:109 - Episode 1877\n",
      "2021-08-25 11:21:55.654 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:55.656 | INFO     | src.policies:train:121 - Mean episode return: 57.0\n",
      "2021-08-25 11:21:55.657 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 69.41\n",
      "2021-08-25 11:21:55.658 | INFO     | src.policies:train:109 - Episode 1878\n",
      "2021-08-25 11:21:55.685 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:55.686 | INFO     | src.policies:train:121 - Mean episode return: 67.0\n",
      "2021-08-25 11:21:55.687 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 69.92\n",
      "2021-08-25 11:21:55.688 | INFO     | src.policies:train:109 - Episode 1879\n",
      "2021-08-25 11:21:55.713 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:55.714 | INFO     | src.policies:train:121 - Mean episode return: 53.0\n",
      "2021-08-25 11:21:55.715 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 70.13\n",
      "2021-08-25 11:21:55.716 | INFO     | src.policies:train:109 - Episode 1880\n",
      "2021-08-25 11:21:55.727 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:55.728 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:21:55.729 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 69.84\n",
      "2021-08-25 11:21:55.730 | INFO     | src.policies:train:109 - Episode 1881\n",
      "2021-08-25 11:21:55.779 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:55.780 | INFO     | src.policies:train:121 - Mean episode return: 126.0\n",
      "2021-08-25 11:21:55.781 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 70.43\n",
      "2021-08-25 11:21:55.782 | WARNING  | src.policies:train:131 - The actual batch size is 324, instead of 200\n",
      "2021-08-25 11:21:55.789 | INFO     | src.policies:train:157 - Total loss: 1.0031763315200806\n",
      "2021-08-25 11:21:55.792 | INFO     | src.policies:train:103 - Epoch 272 / 800\n",
      "2021-08-25 11:21:55.793 | INFO     | src.policies:train:109 - Episode 1882\n",
      "2021-08-25 11:21:55.841 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:55.843 | INFO     | src.policies:train:121 - Mean episode return: 125.0\n",
      "2021-08-25 11:21:55.844 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 71.47\n",
      "2021-08-25 11:21:55.845 | INFO     | src.policies:train:109 - Episode 1883\n",
      "2021-08-25 11:21:55.882 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:55.883 | INFO     | src.policies:train:121 - Mean episode return: 91.0\n",
      "2021-08-25 11:21:55.884 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 72.22\n",
      "2021-08-25 11:21:55.885 | WARNING  | src.policies:train:131 - The actual batch size is 216, instead of 200\n",
      "2021-08-25 11:21:55.891 | INFO     | src.policies:train:157 - Total loss: 1.0013600587844849\n",
      "2021-08-25 11:21:55.894 | INFO     | src.policies:train:103 - Epoch 273 / 800\n",
      "2021-08-25 11:21:55.895 | INFO     | src.policies:train:109 - Episode 1884\n",
      "2021-08-25 11:21:55.953 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:55.954 | INFO     | src.policies:train:121 - Mean episode return: 150.0\n",
      "2021-08-25 11:21:55.955 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 73.4\n",
      "2021-08-25 11:21:55.956 | INFO     | src.policies:train:109 - Episode 1885\n",
      "2021-08-25 11:21:55.969 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:55.970 | INFO     | src.policies:train:121 - Mean episode return: 26.0\n",
      "2021-08-25 11:21:55.971 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 73.09\n",
      "2021-08-25 11:21:55.972 | INFO     | src.policies:train:109 - Episode 1886\n",
      "2021-08-25 11:21:55.990 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:55.991 | INFO     | src.policies:train:121 - Mean episode return: 38.0\n",
      "2021-08-25 11:21:55.992 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 72.87\n",
      "2021-08-25 11:21:55.993 | WARNING  | src.policies:train:131 - The actual batch size is 214, instead of 200\n",
      "2021-08-25 11:21:56.000 | INFO     | src.policies:train:157 - Total loss: 1.0016543865203857\n",
      "2021-08-25 11:21:56.004 | INFO     | src.policies:train:103 - Epoch 274 / 800\n",
      "2021-08-25 11:21:56.005 | INFO     | src.policies:train:109 - Episode 1887\n",
      "2021-08-25 11:21:56.053 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:56.054 | INFO     | src.policies:train:121 - Mean episode return: 128.0\n",
      "2021-08-25 11:21:56.055 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 73.33\n",
      "2021-08-25 11:21:56.056 | INFO     | src.policies:train:109 - Episode 1888\n",
      "2021-08-25 11:21:56.127 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:56.129 | INFO     | src.policies:train:121 - Mean episode return: 183.0\n",
      "2021-08-25 11:21:56.129 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 74.94\n",
      "2021-08-25 11:21:56.131 | WARNING  | src.policies:train:131 - The actual batch size is 311, instead of 200\n",
      "2021-08-25 11:21:56.138 | INFO     | src.policies:train:157 - Total loss: 1.003029465675354\n",
      "2021-08-25 11:21:56.141 | INFO     | src.policies:train:103 - Epoch 275 / 800\n",
      "2021-08-25 11:21:56.142 | INFO     | src.policies:train:109 - Episode 1889\n",
      "2021-08-25 11:21:56.201 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:56.203 | INFO     | src.policies:train:121 - Mean episode return: 153.0\n",
      "2021-08-25 11:21:56.204 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 76.04\n",
      "2021-08-25 11:21:56.205 | INFO     | src.policies:train:109 - Episode 1890\n",
      "2021-08-25 11:21:56.262 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:56.263 | INFO     | src.policies:train:121 - Mean episode return: 143.0\n",
      "2021-08-25 11:21:56.264 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 77.16\n",
      "2021-08-25 11:21:56.265 | WARNING  | src.policies:train:131 - The actual batch size is 296, instead of 200\n",
      "2021-08-25 11:21:56.272 | INFO     | src.policies:train:157 - Total loss: 1.0027332305908203\n",
      "2021-08-25 11:21:56.276 | INFO     | src.policies:train:103 - Epoch 276 / 800\n",
      "2021-08-25 11:21:56.277 | INFO     | src.policies:train:109 - Episode 1891\n",
      "2021-08-25 11:21:56.331 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:56.333 | INFO     | src.policies:train:121 - Mean episode return: 145.0\n",
      "2021-08-25 11:21:56.334 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 78.33\n",
      "2021-08-25 11:21:56.335 | INFO     | src.policies:train:109 - Episode 1892\n",
      "2021-08-25 11:21:56.347 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:56.349 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:21:56.350 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 78.25\n",
      "2021-08-25 11:21:56.350 | INFO     | src.policies:train:109 - Episode 1893\n",
      "2021-08-25 11:21:56.376 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:56.377 | INFO     | src.policies:train:121 - Mean episode return: 58.0\n",
      "2021-08-25 11:21:56.378 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 78.52\n",
      "2021-08-25 11:21:56.379 | WARNING  | src.policies:train:131 - The actual batch size is 224, instead of 200\n",
      "2021-08-25 11:21:56.385 | INFO     | src.policies:train:157 - Total loss: 1.0018281936645508\n",
      "2021-08-25 11:21:56.389 | INFO     | src.policies:train:103 - Epoch 277 / 800\n",
      "2021-08-25 11:21:56.390 | INFO     | src.policies:train:109 - Episode 1894\n",
      "2021-08-25 11:21:56.406 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:56.408 | INFO     | src.policies:train:121 - Mean episode return: 34.0\n",
      "2021-08-25 11:21:56.409 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 78.55\n",
      "2021-08-25 11:21:56.410 | INFO     | src.policies:train:109 - Episode 1895\n",
      "2021-08-25 11:21:56.474 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:56.475 | INFO     | src.policies:train:121 - Mean episode return: 166.0\n",
      "2021-08-25 11:21:56.476 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 78.91\n",
      "2021-08-25 11:21:56.482 | INFO     | src.policies:train:157 - Total loss: 1.0011885166168213\n",
      "2021-08-25 11:21:56.485 | INFO     | src.policies:train:103 - Epoch 278 / 800\n",
      "2021-08-25 11:21:56.486 | INFO     | src.policies:train:109 - Episode 1896\n",
      "2021-08-25 11:21:56.509 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:56.510 | INFO     | src.policies:train:121 - Mean episode return: 59.0\n",
      "2021-08-25 11:21:56.511 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 79.35\n",
      "2021-08-25 11:21:56.512 | INFO     | src.policies:train:109 - Episode 1897\n",
      "2021-08-25 11:21:56.565 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:56.566 | INFO     | src.policies:train:121 - Mean episode return: 130.0\n",
      "2021-08-25 11:21:56.567 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 79.93\n",
      "2021-08-25 11:21:56.568 | INFO     | src.policies:train:109 - Episode 1898\n",
      "2021-08-25 11:21:56.616 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:56.618 | INFO     | src.policies:train:121 - Mean episode return: 116.0\n",
      "2021-08-25 11:21:56.619 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 80.81\n",
      "2021-08-25 11:21:56.620 | WARNING  | src.policies:train:131 - The actual batch size is 305, instead of 200\n",
      "2021-08-25 11:21:56.627 | INFO     | src.policies:train:157 - Total loss: 1.0028395652770996\n",
      "2021-08-25 11:21:56.630 | INFO     | src.policies:train:103 - Epoch 279 / 800\n",
      "2021-08-25 11:21:56.632 | INFO     | src.policies:train:109 - Episode 1899\n",
      "2021-08-25 11:21:56.711 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:56.713 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:21:56.714 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 82.55\n",
      "2021-08-25 11:21:56.720 | INFO     | src.policies:train:157 - Total loss: 1.0012444257736206\n",
      "2021-08-25 11:21:56.723 | INFO     | src.policies:train:103 - Epoch 280 / 800\n",
      "2021-08-25 11:21:56.724 | INFO     | src.policies:train:109 - Episode 1900\n",
      "2021-08-25 11:21:56.735 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:56.736 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:21:56.737 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 81.92\n",
      "2021-08-25 11:21:56.738 | INFO     | src.policies:train:109 - Episode 1901\n",
      "2021-08-25 11:21:56.789 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:56.790 | INFO     | src.policies:train:121 - Mean episode return: 127.0\n",
      "2021-08-25 11:21:56.791 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 82.82\n",
      "2021-08-25 11:21:56.792 | INFO     | src.policies:train:109 - Episode 1902\n",
      "2021-08-25 11:21:56.818 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:56.820 | INFO     | src.policies:train:121 - Mean episode return: 63.0\n",
      "2021-08-25 11:21:56.821 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 83.06\n",
      "2021-08-25 11:21:56.822 | WARNING  | src.policies:train:131 - The actual batch size is 211, instead of 200\n",
      "2021-08-25 11:21:56.828 | INFO     | src.policies:train:157 - Total loss: 1.0014715194702148\n",
      "2021-08-25 11:21:56.831 | INFO     | src.policies:train:103 - Epoch 281 / 800\n",
      "2021-08-25 11:21:56.833 | INFO     | src.policies:train:109 - Episode 1903\n",
      "2021-08-25 11:21:56.842 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:56.843 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:21:56.844 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 82.76\n",
      "2021-08-25 11:21:56.845 | INFO     | src.policies:train:109 - Episode 1904\n",
      "2021-08-25 11:21:56.915 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:56.916 | INFO     | src.policies:train:121 - Mean episode return: 191.0\n",
      "2021-08-25 11:21:56.917 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 84.28\n",
      "2021-08-25 11:21:56.918 | WARNING  | src.policies:train:131 - The actual batch size is 209, instead of 200\n",
      "2021-08-25 11:21:56.925 | INFO     | src.policies:train:157 - Total loss: 1.0012140274047852\n",
      "2021-08-25 11:21:56.928 | INFO     | src.policies:train:103 - Epoch 282 / 800\n",
      "2021-08-25 11:21:56.929 | INFO     | src.policies:train:109 - Episode 1905\n",
      "2021-08-25 11:21:56.978 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:56.980 | INFO     | src.policies:train:121 - Mean episode return: 129.0\n",
      "2021-08-25 11:21:56.981 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 85.28\n",
      "2021-08-25 11:21:56.982 | INFO     | src.policies:train:109 - Episode 1906\n",
      "2021-08-25 11:21:57.035 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:57.036 | INFO     | src.policies:train:121 - Mean episode return: 136.0\n",
      "2021-08-25 11:21:57.037 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 86.52\n",
      "2021-08-25 11:21:57.038 | WARNING  | src.policies:train:131 - The actual batch size is 265, instead of 200\n",
      "2021-08-25 11:21:57.045 | INFO     | src.policies:train:157 - Total loss: 1.0023598670959473\n",
      "2021-08-25 11:21:57.048 | INFO     | src.policies:train:103 - Epoch 283 / 800\n",
      "2021-08-25 11:21:57.049 | INFO     | src.policies:train:109 - Episode 1907\n",
      "2021-08-25 11:21:57.126 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:57.127 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:21:57.128 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 87.95\n",
      "2021-08-25 11:21:57.134 | INFO     | src.policies:train:157 - Total loss: 1.0010454654693604\n",
      "2021-08-25 11:21:57.136 | INFO     | src.policies:train:103 - Epoch 284 / 800\n",
      "2021-08-25 11:21:57.138 | INFO     | src.policies:train:109 - Episode 1908\n",
      "2021-08-25 11:21:57.154 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:57.156 | INFO     | src.policies:train:121 - Mean episode return: 41.0\n",
      "2021-08-25 11:21:57.157 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 88.16\n",
      "2021-08-25 11:21:57.158 | INFO     | src.policies:train:109 - Episode 1909\n",
      "2021-08-25 11:21:57.198 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:57.199 | INFO     | src.policies:train:121 - Mean episode return: 99.0\n",
      "2021-08-25 11:21:57.200 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 88.96\n",
      "2021-08-25 11:21:57.201 | INFO     | src.policies:train:109 - Episode 1910\n",
      "2021-08-25 11:21:57.217 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:57.219 | INFO     | src.policies:train:121 - Mean episode return: 35.0\n",
      "2021-08-25 11:21:57.219 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 88.73\n",
      "2021-08-25 11:21:57.220 | INFO     | src.policies:train:109 - Episode 1911\n",
      "2021-08-25 11:21:57.280 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:57.281 | INFO     | src.policies:train:121 - Mean episode return: 155.0\n",
      "2021-08-25 11:21:57.282 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 88.92\n",
      "2021-08-25 11:21:57.283 | WARNING  | src.policies:train:131 - The actual batch size is 330, instead of 200\n",
      "2021-08-25 11:21:57.290 | INFO     | src.policies:train:157 - Total loss: 1.003138542175293\n",
      "2021-08-25 11:21:57.294 | INFO     | src.policies:train:103 - Epoch 285 / 800\n",
      "2021-08-25 11:21:57.295 | INFO     | src.policies:train:109 - Episode 1912\n",
      "2021-08-25 11:21:57.326 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:57.327 | INFO     | src.policies:train:121 - Mean episode return: 81.0\n",
      "2021-08-25 11:21:57.328 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 88.81\n",
      "2021-08-25 11:21:57.329 | INFO     | src.policies:train:109 - Episode 1913\n",
      "2021-08-25 11:21:57.383 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:57.384 | INFO     | src.policies:train:121 - Mean episode return: 137.0\n",
      "2021-08-25 11:21:57.385 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 89.35\n",
      "2021-08-25 11:21:57.386 | WARNING  | src.policies:train:131 - The actual batch size is 218, instead of 200\n",
      "2021-08-25 11:21:57.392 | INFO     | src.policies:train:157 - Total loss: 1.0014981031417847\n",
      "2021-08-25 11:21:57.396 | INFO     | src.policies:train:103 - Epoch 286 / 800\n",
      "2021-08-25 11:21:57.397 | INFO     | src.policies:train:109 - Episode 1914\n",
      "2021-08-25 11:21:57.470 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:57.472 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:21:57.473 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 90.48\n",
      "2021-08-25 11:21:57.478 | INFO     | src.policies:train:157 - Total loss: 1.0010164976119995\n",
      "2021-08-25 11:21:57.481 | INFO     | src.policies:train:103 - Epoch 287 / 800\n",
      "2021-08-25 11:21:57.482 | INFO     | src.policies:train:109 - Episode 1915\n",
      "2021-08-25 11:21:57.532 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:57.534 | INFO     | src.policies:train:121 - Mean episode return: 133.0\n",
      "2021-08-25 11:21:57.535 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 91.3\n",
      "2021-08-25 11:21:57.535 | INFO     | src.policies:train:109 - Episode 1916\n",
      "2021-08-25 11:21:57.593 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:57.594 | INFO     | src.policies:train:121 - Mean episode return: 149.0\n",
      "2021-08-25 11:21:57.595 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 91.81\n",
      "2021-08-25 11:21:57.596 | WARNING  | src.policies:train:131 - The actual batch size is 282, instead of 200\n",
      "2021-08-25 11:21:57.602 | INFO     | src.policies:train:157 - Total loss: 1.0024131536483765\n",
      "2021-08-25 11:21:57.606 | INFO     | src.policies:train:103 - Epoch 288 / 800\n",
      "2021-08-25 11:21:57.607 | INFO     | src.policies:train:109 - Episode 1917\n",
      "2021-08-25 11:21:57.616 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:57.617 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:21:57.618 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 91.73\n",
      "2021-08-25 11:21:57.619 | INFO     | src.policies:train:109 - Episode 1918\n",
      "2021-08-25 11:21:57.696 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:57.698 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:21:57.699 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 93.54\n",
      "2021-08-25 11:21:57.700 | WARNING  | src.policies:train:131 - The actual batch size is 218, instead of 200\n",
      "2021-08-25 11:21:57.706 | INFO     | src.policies:train:157 - Total loss: 1.0015063285827637\n",
      "2021-08-25 11:21:57.709 | INFO     | src.policies:train:103 - Epoch 289 / 800\n",
      "2021-08-25 11:21:57.711 | INFO     | src.policies:train:109 - Episode 1919\n",
      "2021-08-25 11:21:57.757 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:57.759 | INFO     | src.policies:train:121 - Mean episode return: 123.0\n",
      "2021-08-25 11:21:57.760 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 94.52\n",
      "2021-08-25 11:21:57.761 | INFO     | src.policies:train:109 - Episode 1920\n",
      "2021-08-25 11:21:57.839 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:57.840 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:21:57.841 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 96.25\n",
      "2021-08-25 11:21:57.842 | WARNING  | src.policies:train:131 - The actual batch size is 323, instead of 200\n",
      "2021-08-25 11:21:57.848 | INFO     | src.policies:train:157 - Total loss: 1.0029566287994385\n",
      "2021-08-25 11:21:57.852 | INFO     | src.policies:train:103 - Epoch 290 / 800\n",
      "2021-08-25 11:21:57.853 | INFO     | src.policies:train:109 - Episode 1921\n",
      "2021-08-25 11:21:57.903 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:57.904 | INFO     | src.policies:train:121 - Mean episode return: 133.0\n",
      "2021-08-25 11:21:57.905 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 96.91\n",
      "2021-08-25 11:21:57.906 | INFO     | src.policies:train:109 - Episode 1922\n",
      "2021-08-25 11:21:57.960 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:57.961 | INFO     | src.policies:train:121 - Mean episode return: 138.0\n",
      "2021-08-25 11:21:57.962 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 98.13\n",
      "2021-08-25 11:21:57.963 | WARNING  | src.policies:train:131 - The actual batch size is 271, instead of 200\n",
      "2021-08-25 11:21:57.969 | INFO     | src.policies:train:157 - Total loss: 1.0023741722106934\n",
      "2021-08-25 11:21:57.973 | INFO     | src.policies:train:103 - Epoch 291 / 800\n",
      "2021-08-25 11:21:57.974 | INFO     | src.policies:train:109 - Episode 1923\n",
      "2021-08-25 11:21:58.023 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:58.024 | INFO     | src.policies:train:121 - Mean episode return: 130.0\n",
      "2021-08-25 11:21:58.026 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 99.08\n",
      "2021-08-25 11:21:58.026 | INFO     | src.policies:train:109 - Episode 1924\n",
      "2021-08-25 11:21:58.084 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:58.086 | INFO     | src.policies:train:121 - Mean episode return: 150.0\n",
      "2021-08-25 11:21:58.086 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 99.83\n",
      "2021-08-25 11:21:58.087 | WARNING  | src.policies:train:131 - The actual batch size is 280, instead of 200\n",
      "2021-08-25 11:21:58.094 | INFO     | src.policies:train:157 - Total loss: 1.002448558807373\n",
      "2021-08-25 11:21:58.098 | INFO     | src.policies:train:103 - Epoch 292 / 800\n",
      "2021-08-25 11:21:58.099 | INFO     | src.policies:train:109 - Episode 1925\n",
      "2021-08-25 11:21:58.130 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:58.132 | INFO     | src.policies:train:121 - Mean episode return: 77.0\n",
      "2021-08-25 11:21:58.133 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 100.23\n",
      "2021-08-25 11:21:58.134 | INFO     | src.policies:train:109 - Episode 1926\n",
      "2021-08-25 11:21:58.186 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:58.187 | INFO     | src.policies:train:121 - Mean episode return: 130.0\n",
      "2021-08-25 11:21:58.188 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 100.43\n",
      "2021-08-25 11:21:58.189 | WARNING  | src.policies:train:131 - The actual batch size is 207, instead of 200\n",
      "2021-08-25 11:21:58.195 | INFO     | src.policies:train:157 - Total loss: 1.001137137413025\n",
      "2021-08-25 11:21:58.198 | INFO     | src.policies:train:103 - Epoch 293 / 800\n",
      "2021-08-25 11:21:58.199 | INFO     | src.policies:train:109 - Episode 1927\n",
      "2021-08-25 11:21:58.253 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:58.255 | INFO     | src.policies:train:121 - Mean episode return: 143.0\n",
      "2021-08-25 11:21:58.256 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 101.48\n",
      "2021-08-25 11:21:58.257 | INFO     | src.policies:train:109 - Episode 1928\n",
      "2021-08-25 11:21:58.318 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:58.319 | INFO     | src.policies:train:121 - Mean episode return: 152.0\n",
      "2021-08-25 11:21:58.320 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 101.04\n",
      "2021-08-25 11:21:58.321 | WARNING  | src.policies:train:131 - The actual batch size is 295, instead of 200\n",
      "2021-08-25 11:21:58.328 | INFO     | src.policies:train:157 - Total loss: 1.002502202987671\n",
      "2021-08-25 11:21:58.331 | INFO     | src.policies:train:103 - Epoch 294 / 800\n",
      "2021-08-25 11:21:58.332 | INFO     | src.policies:train:109 - Episode 1929\n",
      "2021-08-25 11:21:58.373 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:58.374 | INFO     | src.policies:train:121 - Mean episode return: 105.0\n",
      "2021-08-25 11:21:58.375 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 101.36\n",
      "2021-08-25 11:21:58.376 | INFO     | src.policies:train:109 - Episode 1930\n",
      "2021-08-25 11:21:58.451 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:58.453 | INFO     | src.policies:train:121 - Mean episode return: 195.0\n",
      "2021-08-25 11:21:58.454 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 103.08\n",
      "2021-08-25 11:21:58.454 | WARNING  | src.policies:train:131 - The actual batch size is 300, instead of 200\n",
      "2021-08-25 11:21:58.461 | INFO     | src.policies:train:157 - Total loss: 1.00276517868042\n",
      "2021-08-25 11:21:58.465 | INFO     | src.policies:train:103 - Epoch 295 / 800\n",
      "2021-08-25 11:21:58.466 | INFO     | src.policies:train:109 - Episode 1931\n",
      "2021-08-25 11:21:58.542 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:58.544 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:21:58.545 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 104.18\n",
      "2021-08-25 11:21:58.550 | INFO     | src.policies:train:157 - Total loss: 1.0010117292404175\n",
      "2021-08-25 11:21:58.554 | INFO     | src.policies:train:103 - Epoch 296 / 800\n",
      "2021-08-25 11:21:58.555 | INFO     | src.policies:train:109 - Episode 1932\n",
      "2021-08-25 11:21:58.624 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:58.626 | INFO     | src.policies:train:121 - Mean episode return: 190.0\n",
      "2021-08-25 11:21:58.627 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 105.21\n",
      "2021-08-25 11:21:58.628 | INFO     | src.policies:train:109 - Episode 1933\n",
      "2021-08-25 11:21:58.705 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:58.706 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:21:58.707 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 106.15\n",
      "2021-08-25 11:21:58.708 | WARNING  | src.policies:train:131 - The actual batch size is 390, instead of 200\n",
      "2021-08-25 11:21:58.715 | INFO     | src.policies:train:157 - Total loss: 1.0034754276275635\n",
      "2021-08-25 11:21:58.718 | INFO     | src.policies:train:103 - Epoch 297 / 800\n",
      "2021-08-25 11:21:58.719 | INFO     | src.policies:train:109 - Episode 1934\n",
      "2021-08-25 11:21:58.794 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:58.796 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:21:58.796 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 106.89\n",
      "2021-08-25 11:21:58.802 | INFO     | src.policies:train:157 - Total loss: 1.0010062456130981\n",
      "2021-08-25 11:21:58.805 | INFO     | src.policies:train:103 - Epoch 298 / 800\n",
      "2021-08-25 11:21:58.806 | INFO     | src.policies:train:109 - Episode 1935\n",
      "2021-08-25 11:21:58.865 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:58.867 | INFO     | src.policies:train:121 - Mean episode return: 156.0\n",
      "2021-08-25 11:21:58.868 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 108.16\n",
      "2021-08-25 11:21:58.869 | INFO     | src.policies:train:109 - Episode 1936\n",
      "2021-08-25 11:21:58.905 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:58.906 | INFO     | src.policies:train:121 - Mean episode return: 93.0\n",
      "2021-08-25 11:21:58.907 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 108.81\n",
      "2021-08-25 11:21:58.908 | WARNING  | src.policies:train:131 - The actual batch size is 249, instead of 200\n",
      "2021-08-25 11:21:58.915 | INFO     | src.policies:train:157 - Total loss: 1.0019545555114746\n",
      "2021-08-25 11:21:58.918 | INFO     | src.policies:train:103 - Epoch 299 / 800\n",
      "2021-08-25 11:21:58.919 | INFO     | src.policies:train:109 - Episode 1937\n",
      "2021-08-25 11:21:58.994 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:58.996 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:21:58.997 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 109.27\n",
      "2021-08-25 11:21:59.003 | INFO     | src.policies:train:157 - Total loss: 1.0010586977005005\n",
      "2021-08-25 11:21:59.006 | INFO     | src.policies:train:103 - Epoch 300 / 800\n",
      "2021-08-25 11:21:59.007 | INFO     | src.policies:train:109 - Episode 1938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:59.071 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:59.073 | INFO     | src.policies:train:121 - Mean episode return: 152.0\n",
      "2021-08-25 11:21:59.074 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 110.25\n",
      "2021-08-25 11:21:59.075 | INFO     | src.policies:train:109 - Episode 1939\n",
      "2021-08-25 11:21:59.096 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:59.098 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 11:21:59.099 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 110.34\n",
      "2021-08-25 11:21:59.100 | INFO     | src.policies:train:109 - Episode 1940\n",
      "2021-08-25 11:21:59.181 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:59.182 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:21:59.184 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 110.83\n",
      "2021-08-25 11:21:59.185 | WARNING  | src.policies:train:131 - The actual batch size is 392, instead of 200\n",
      "2021-08-25 11:21:59.193 | INFO     | src.policies:train:157 - Total loss: 1.0035240650177002\n",
      "2021-08-25 11:21:59.198 | INFO     | src.policies:train:103 - Epoch 301 / 800\n",
      "2021-08-25 11:21:59.199 | INFO     | src.policies:train:109 - Episode 1941\n",
      "2021-08-25 11:21:59.212 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:59.214 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:21:59.215 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 110.51\n",
      "2021-08-25 11:21:59.216 | INFO     | src.policies:train:109 - Episode 1942\n",
      "2021-08-25 11:21:59.253 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:59.254 | INFO     | src.policies:train:121 - Mean episode return: 86.0\n",
      "2021-08-25 11:21:59.256 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 110.84\n",
      "2021-08-25 11:21:59.256 | INFO     | src.policies:train:109 - Episode 1943\n",
      "2021-08-25 11:21:59.332 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:59.333 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:21:59.334 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 112.28\n",
      "2021-08-25 11:21:59.335 | WARNING  | src.policies:train:131 - The actual batch size is 308, instead of 200\n",
      "2021-08-25 11:21:59.341 | INFO     | src.policies:train:157 - Total loss: 1.0024933815002441\n",
      "2021-08-25 11:21:59.344 | INFO     | src.policies:train:103 - Epoch 302 / 800\n",
      "2021-08-25 11:21:59.345 | INFO     | src.policies:train:109 - Episode 1944\n",
      "2021-08-25 11:21:59.383 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:59.385 | INFO     | src.policies:train:121 - Mean episode return: 102.0\n",
      "2021-08-25 11:21:59.386 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 113.15\n",
      "2021-08-25 11:21:59.387 | INFO     | src.policies:train:109 - Episode 1945\n",
      "2021-08-25 11:21:59.459 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:59.460 | INFO     | src.policies:train:121 - Mean episode return: 187.0\n",
      "2021-08-25 11:21:59.461 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 114.81\n",
      "2021-08-25 11:21:59.462 | WARNING  | src.policies:train:131 - The actual batch size is 289, instead of 200\n",
      "2021-08-25 11:21:59.469 | INFO     | src.policies:train:157 - Total loss: 1.0025779008865356\n",
      "2021-08-25 11:21:59.472 | INFO     | src.policies:train:103 - Epoch 303 / 800\n",
      "2021-08-25 11:21:59.474 | INFO     | src.policies:train:109 - Episode 1946\n",
      "2021-08-25 11:21:59.530 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:59.532 | INFO     | src.policies:train:121 - Mean episode return: 155.0\n",
      "2021-08-25 11:21:59.533 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 115.09\n",
      "2021-08-25 11:21:59.534 | INFO     | src.policies:train:109 - Episode 1947\n",
      "2021-08-25 11:21:59.565 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:59.566 | INFO     | src.policies:train:121 - Mean episode return: 75.0\n",
      "2021-08-25 11:21:59.567 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 115.29\n",
      "2021-08-25 11:21:59.568 | WARNING  | src.policies:train:131 - The actual batch size is 230, instead of 200\n",
      "2021-08-25 11:21:59.575 | INFO     | src.policies:train:157 - Total loss: 1.0015342235565186\n",
      "2021-08-25 11:21:59.579 | INFO     | src.policies:train:103 - Epoch 304 / 800\n",
      "2021-08-25 11:21:59.580 | INFO     | src.policies:train:109 - Episode 1948\n",
      "2021-08-25 11:21:59.589 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:59.591 | INFO     | src.policies:train:121 - Mean episode return: 16.0\n",
      "2021-08-25 11:21:59.592 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 113.5\n",
      "2021-08-25 11:21:59.593 | INFO     | src.policies:train:109 - Episode 1949\n",
      "2021-08-25 11:21:59.611 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:59.612 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 11:21:59.613 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 113.0\n",
      "2021-08-25 11:21:59.614 | INFO     | src.policies:train:109 - Episode 1950\n",
      "2021-08-25 11:21:59.690 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:59.691 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:21:59.692 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 114.03\n",
      "2021-08-25 11:21:59.693 | WARNING  | src.policies:train:131 - The actual batch size is 256, instead of 200\n",
      "2021-08-25 11:21:59.700 | INFO     | src.policies:train:157 - Total loss: 1.0020115375518799\n",
      "2021-08-25 11:21:59.703 | INFO     | src.policies:train:103 - Epoch 305 / 800\n",
      "2021-08-25 11:21:59.704 | INFO     | src.policies:train:109 - Episode 1951\n",
      "2021-08-25 11:21:59.721 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:59.723 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 11:21:59.724 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 113.61\n",
      "2021-08-25 11:21:59.725 | INFO     | src.policies:train:109 - Episode 1952\n",
      "2021-08-25 11:21:59.803 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:59.804 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:21:59.805 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 115.3\n",
      "2021-08-25 11:21:59.806 | WARNING  | src.policies:train:131 - The actual batch size is 240, instead of 200\n",
      "2021-08-25 11:21:59.812 | INFO     | src.policies:train:157 - Total loss: 1.0016084909439087\n",
      "2021-08-25 11:21:59.815 | INFO     | src.policies:train:103 - Epoch 306 / 800\n",
      "2021-08-25 11:21:59.816 | INFO     | src.policies:train:109 - Episode 1953\n",
      "2021-08-25 11:21:59.890 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:59.891 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:21:59.893 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 116.25\n",
      "2021-08-25 11:21:59.898 | INFO     | src.policies:train:157 - Total loss: 1.0008338689804077\n",
      "2021-08-25 11:21:59.901 | INFO     | src.policies:train:103 - Epoch 307 / 800\n",
      "2021-08-25 11:21:59.902 | INFO     | src.policies:train:109 - Episode 1954\n",
      "2021-08-25 11:21:59.967 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:59.968 | INFO     | src.policies:train:121 - Mean episode return: 174.0\n",
      "2021-08-25 11:21:59.970 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 116.53\n",
      "2021-08-25 11:21:59.970 | INFO     | src.policies:train:109 - Episode 1955\n",
      "2021-08-25 11:21:59.981 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:21:59.982 | INFO     | src.policies:train:121 - Mean episode return: 19.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:21:59.983 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 116.52\n",
      "2021-08-25 11:21:59.984 | INFO     | src.policies:train:109 - Episode 1956\n",
      "2021-08-25 11:22:00.060 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:00.061 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:00.062 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 118.18\n",
      "2021-08-25 11:22:00.063 | WARNING  | src.policies:train:131 - The actual batch size is 393, instead of 200\n",
      "2021-08-25 11:22:00.071 | INFO     | src.policies:train:157 - Total loss: 1.0033644437789917\n",
      "2021-08-25 11:22:00.074 | INFO     | src.policies:train:103 - Epoch 308 / 800\n",
      "2021-08-25 11:22:00.075 | INFO     | src.policies:train:109 - Episode 1957\n",
      "2021-08-25 11:22:00.085 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:00.087 | INFO     | src.policies:train:121 - Mean episode return: 20.0\n",
      "2021-08-25 11:22:00.088 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 117.92\n",
      "2021-08-25 11:22:00.088 | INFO     | src.policies:train:109 - Episode 1958\n",
      "2021-08-25 11:22:00.134 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:00.136 | INFO     | src.policies:train:121 - Mean episode return: 112.0\n",
      "2021-08-25 11:22:00.136 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 117.04\n",
      "2021-08-25 11:22:00.137 | INFO     | src.policies:train:109 - Episode 1959\n",
      "2021-08-25 11:22:00.196 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:00.198 | INFO     | src.policies:train:121 - Mean episode return: 153.0\n",
      "2021-08-25 11:22:00.199 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 118.13\n",
      "2021-08-25 11:22:00.200 | WARNING  | src.policies:train:131 - The actual batch size is 285, instead of 200\n",
      "2021-08-25 11:22:00.207 | INFO     | src.policies:train:157 - Total loss: 1.0021647214889526\n",
      "2021-08-25 11:22:00.210 | INFO     | src.policies:train:103 - Epoch 309 / 800\n",
      "2021-08-25 11:22:00.211 | INFO     | src.policies:train:109 - Episode 1960\n",
      "2021-08-25 11:22:00.285 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:00.287 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:00.288 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 119.54\n",
      "2021-08-25 11:22:00.294 | INFO     | src.policies:train:157 - Total loss: 1.0009516477584839\n",
      "2021-08-25 11:22:00.297 | INFO     | src.policies:train:103 - Epoch 310 / 800\n",
      "2021-08-25 11:22:00.298 | INFO     | src.policies:train:109 - Episode 1961\n",
      "2021-08-25 11:22:00.307 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:00.308 | INFO     | src.policies:train:121 - Mean episode return: 18.0\n",
      "2021-08-25 11:22:00.309 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 119.3\n",
      "2021-08-25 11:22:00.310 | INFO     | src.policies:train:109 - Episode 1962\n",
      "2021-08-25 11:22:00.369 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:00.370 | INFO     | src.policies:train:121 - Mean episode return: 155.0\n",
      "2021-08-25 11:22:00.371 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 118.85\n",
      "2021-08-25 11:22:00.372 | INFO     | src.policies:train:109 - Episode 1963\n",
      "2021-08-25 11:22:00.437 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:00.439 | INFO     | src.policies:train:121 - Mean episode return: 168.0\n",
      "2021-08-25 11:22:00.440 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 119.01\n",
      "2021-08-25 11:22:00.440 | WARNING  | src.policies:train:131 - The actual batch size is 341, instead of 200\n",
      "2021-08-25 11:22:00.447 | INFO     | src.policies:train:157 - Total loss: 1.0029813051223755\n",
      "2021-08-25 11:22:00.451 | INFO     | src.policies:train:103 - Epoch 311 / 800\n",
      "2021-08-25 11:22:00.452 | INFO     | src.policies:train:109 - Episode 1964\n",
      "2021-08-25 11:22:00.482 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:00.484 | INFO     | src.policies:train:121 - Mean episode return: 72.0\n",
      "2021-08-25 11:22:00.485 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 118.37\n",
      "2021-08-25 11:22:00.486 | INFO     | src.policies:train:109 - Episode 1965\n",
      "2021-08-25 11:22:00.559 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:00.560 | INFO     | src.policies:train:121 - Mean episode return: 193.0\n",
      "2021-08-25 11:22:00.561 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 119.25\n",
      "2021-08-25 11:22:00.562 | WARNING  | src.policies:train:131 - The actual batch size is 265, instead of 200\n",
      "2021-08-25 11:22:00.569 | INFO     | src.policies:train:157 - Total loss: 1.0020147562026978\n",
      "2021-08-25 11:22:00.572 | INFO     | src.policies:train:103 - Epoch 312 / 800\n",
      "2021-08-25 11:22:00.574 | INFO     | src.policies:train:109 - Episode 1966\n",
      "2021-08-25 11:22:00.648 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:00.650 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:00.651 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 120.28\n",
      "2021-08-25 11:22:00.657 | INFO     | src.policies:train:157 - Total loss: 1.001007318496704\n",
      "2021-08-25 11:22:00.660 | INFO     | src.policies:train:103 - Epoch 313 / 800\n",
      "2021-08-25 11:22:00.661 | INFO     | src.policies:train:109 - Episode 1967\n",
      "2021-08-25 11:22:00.734 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:00.736 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:00.737 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 122.1\n",
      "2021-08-25 11:22:00.742 | INFO     | src.policies:train:157 - Total loss: 1.0009315013885498\n",
      "2021-08-25 11:22:00.745 | INFO     | src.policies:train:103 - Epoch 314 / 800\n",
      "2021-08-25 11:22:00.746 | INFO     | src.policies:train:109 - Episode 1968\n",
      "2021-08-25 11:22:00.823 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:00.825 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:00.826 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 122.95\n",
      "2021-08-25 11:22:00.832 | INFO     | src.policies:train:157 - Total loss: 1.001011610031128\n",
      "2021-08-25 11:22:00.835 | INFO     | src.policies:train:103 - Epoch 315 / 800\n",
      "2021-08-25 11:22:00.836 | INFO     | src.policies:train:109 - Episode 1969\n",
      "2021-08-25 11:22:00.888 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:00.890 | INFO     | src.policies:train:121 - Mean episode return: 135.0\n",
      "2021-08-25 11:22:00.891 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 123.17\n",
      "2021-08-25 11:22:00.891 | INFO     | src.policies:train:109 - Episode 1970\n",
      "2021-08-25 11:22:00.905 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:00.906 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 11:22:00.907 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 122.1\n",
      "2021-08-25 11:22:00.908 | INFO     | src.policies:train:109 - Episode 1971\n",
      "2021-08-25 11:22:00.974 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:00.976 | INFO     | src.policies:train:121 - Mean episode return: 171.0\n",
      "2021-08-25 11:22:00.977 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 122.86\n",
      "2021-08-25 11:22:00.977 | WARNING  | src.policies:train:131 - The actual batch size is 333, instead of 200\n",
      "2021-08-25 11:22:00.984 | INFO     | src.policies:train:157 - Total loss: 1.0028077363967896\n",
      "2021-08-25 11:22:00.988 | INFO     | src.policies:train:103 - Epoch 316 / 800\n",
      "2021-08-25 11:22:00.989 | INFO     | src.policies:train:109 - Episode 1972\n",
      "2021-08-25 11:22:01.065 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:22:01.066 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:01.067 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 124.03\n",
      "2021-08-25 11:22:01.073 | INFO     | src.policies:train:157 - Total loss: 1.0008388757705688\n",
      "2021-08-25 11:22:01.076 | INFO     | src.policies:train:103 - Epoch 317 / 800\n",
      "2021-08-25 11:22:01.077 | INFO     | src.policies:train:109 - Episode 1973\n",
      "2021-08-25 11:22:01.153 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:01.155 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:01.156 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 125.12\n",
      "2021-08-25 11:22:01.161 | INFO     | src.policies:train:157 - Total loss: 1.0007582902908325\n",
      "2021-08-25 11:22:01.164 | INFO     | src.policies:train:103 - Epoch 318 / 800\n",
      "2021-08-25 11:22:01.165 | INFO     | src.policies:train:109 - Episode 1974\n",
      "2021-08-25 11:22:01.201 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:01.202 | INFO     | src.policies:train:121 - Mean episode return: 86.0\n",
      "2021-08-25 11:22:01.203 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 124.11\n",
      "2021-08-25 11:22:01.204 | INFO     | src.policies:train:109 - Episode 1975\n",
      "2021-08-25 11:22:01.270 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:01.271 | INFO     | src.policies:train:121 - Mean episode return: 172.0\n",
      "2021-08-25 11:22:01.272 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 124.48\n",
      "2021-08-25 11:22:01.273 | WARNING  | src.policies:train:131 - The actual batch size is 258, instead of 200\n",
      "2021-08-25 11:22:01.280 | INFO     | src.policies:train:157 - Total loss: 1.001844882965088\n",
      "2021-08-25 11:22:01.284 | INFO     | src.policies:train:103 - Epoch 319 / 800\n",
      "2021-08-25 11:22:01.285 | INFO     | src.policies:train:109 - Episode 1976\n",
      "2021-08-25 11:22:01.311 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:01.313 | INFO     | src.policies:train:121 - Mean episode return: 67.0\n",
      "2021-08-25 11:22:01.314 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 123.95\n",
      "2021-08-25 11:22:01.315 | INFO     | src.policies:train:109 - Episode 1977\n",
      "2021-08-25 11:22:01.391 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:01.393 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:01.394 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 125.38\n",
      "2021-08-25 11:22:01.395 | WARNING  | src.policies:train:131 - The actual batch size is 267, instead of 200\n",
      "2021-08-25 11:22:01.402 | INFO     | src.policies:train:157 - Total loss: 1.0020571947097778\n",
      "2021-08-25 11:22:01.406 | INFO     | src.policies:train:103 - Epoch 320 / 800\n",
      "2021-08-25 11:22:01.407 | INFO     | src.policies:train:109 - Episode 1978\n",
      "2021-08-25 11:22:01.479 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:01.481 | INFO     | src.policies:train:121 - Mean episode return: 194.0\n",
      "2021-08-25 11:22:01.482 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 126.65\n",
      "2021-08-25 11:22:01.483 | INFO     | src.policies:train:109 - Episode 1979\n",
      "2021-08-25 11:22:01.500 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:01.502 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 11:22:01.503 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 126.52\n",
      "2021-08-25 11:22:01.503 | WARNING  | src.policies:train:131 - The actual batch size is 234, instead of 200\n",
      "2021-08-25 11:22:01.509 | INFO     | src.policies:train:157 - Total loss: 1.0014077425003052\n",
      "2021-08-25 11:22:01.513 | INFO     | src.policies:train:103 - Epoch 321 / 800\n",
      "2021-08-25 11:22:01.514 | INFO     | src.policies:train:109 - Episode 1980\n",
      "2021-08-25 11:22:01.586 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:01.588 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:01.589 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 128.31\n",
      "2021-08-25 11:22:01.594 | INFO     | src.policies:train:157 - Total loss: 1.0006659030914307\n",
      "2021-08-25 11:22:01.598 | INFO     | src.policies:train:103 - Epoch 322 / 800\n",
      "2021-08-25 11:22:01.598 | INFO     | src.policies:train:109 - Episode 1981\n",
      "2021-08-25 11:22:01.665 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:01.666 | INFO     | src.policies:train:121 - Mean episode return: 175.0\n",
      "2021-08-25 11:22:01.668 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 128.8\n",
      "2021-08-25 11:22:01.669 | INFO     | src.policies:train:109 - Episode 1982\n",
      "2021-08-25 11:22:01.749 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:01.750 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:01.751 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 129.55\n",
      "2021-08-25 11:22:01.752 | WARNING  | src.policies:train:131 - The actual batch size is 375, instead of 200\n",
      "2021-08-25 11:22:01.760 | INFO     | src.policies:train:157 - Total loss: 1.0031296014785767\n",
      "2021-08-25 11:22:01.764 | INFO     | src.policies:train:103 - Epoch 323 / 800\n",
      "2021-08-25 11:22:01.766 | INFO     | src.policies:train:109 - Episode 1983\n",
      "2021-08-25 11:22:01.840 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:01.841 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:01.842 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 130.64\n",
      "2021-08-25 11:22:01.848 | INFO     | src.policies:train:157 - Total loss: 1.0005738735198975\n",
      "2021-08-25 11:22:01.851 | INFO     | src.policies:train:103 - Epoch 324 / 800\n",
      "2021-08-25 11:22:01.852 | INFO     | src.policies:train:109 - Episode 1984\n",
      "2021-08-25 11:22:01.915 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:01.917 | INFO     | src.policies:train:121 - Mean episode return: 160.0\n",
      "2021-08-25 11:22:01.918 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 130.74\n",
      "2021-08-25 11:22:01.919 | INFO     | src.policies:train:109 - Episode 1985\n",
      "2021-08-25 11:22:01.931 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:01.932 | INFO     | src.policies:train:121 - Mean episode return: 15.0\n",
      "2021-08-25 11:22:01.934 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 130.63\n",
      "2021-08-25 11:22:01.935 | INFO     | src.policies:train:109 - Episode 1986\n",
      "2021-08-25 11:22:01.992 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:01.993 | INFO     | src.policies:train:121 - Mean episode return: 133.0\n",
      "2021-08-25 11:22:01.995 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 131.58\n",
      "2021-08-25 11:22:01.996 | WARNING  | src.policies:train:131 - The actual batch size is 308, instead of 200\n",
      "2021-08-25 11:22:02.005 | INFO     | src.policies:train:157 - Total loss: 1.0024806261062622\n",
      "2021-08-25 11:22:02.010 | INFO     | src.policies:train:103 - Epoch 325 / 800\n",
      "2021-08-25 11:22:02.011 | INFO     | src.policies:train:109 - Episode 1987\n",
      "2021-08-25 11:22:02.097 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:02.098 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:02.100 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 132.3\n",
      "2021-08-25 11:22:02.106 | INFO     | src.policies:train:157 - Total loss: 1.0008615255355835\n",
      "2021-08-25 11:22:02.110 | INFO     | src.policies:train:103 - Epoch 326 / 800\n",
      "2021-08-25 11:22:02.111 | INFO     | src.policies:train:109 - Episode 1988\n",
      "2021-08-25 11:22:02.189 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:02.191 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:22:02.192 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 132.47\n",
      "2021-08-25 11:22:02.199 | INFO     | src.policies:train:157 - Total loss: 1.0006763935089111\n",
      "2021-08-25 11:22:02.202 | INFO     | src.policies:train:103 - Epoch 327 / 800\n",
      "2021-08-25 11:22:02.203 | INFO     | src.policies:train:109 - Episode 1989\n",
      "2021-08-25 11:22:02.258 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:02.260 | INFO     | src.policies:train:121 - Mean episode return: 138.0\n",
      "2021-08-25 11:22:02.261 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 132.32\n",
      "2021-08-25 11:22:02.262 | INFO     | src.policies:train:109 - Episode 1990\n",
      "2021-08-25 11:22:02.328 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:02.329 | INFO     | src.policies:train:121 - Mean episode return: 166.0\n",
      "2021-08-25 11:22:02.330 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 132.55\n",
      "2021-08-25 11:22:02.331 | WARNING  | src.policies:train:131 - The actual batch size is 304, instead of 200\n",
      "2021-08-25 11:22:02.339 | INFO     | src.policies:train:157 - Total loss: 1.0024769306182861\n",
      "2021-08-25 11:22:02.343 | INFO     | src.policies:train:103 - Epoch 328 / 800\n",
      "2021-08-25 11:22:02.344 | INFO     | src.policies:train:109 - Episode 1991\n",
      "2021-08-25 11:22:02.365 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:02.366 | INFO     | src.policies:train:121 - Mean episode return: 47.0\n",
      "2021-08-25 11:22:02.367 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 131.57\n",
      "2021-08-25 11:22:02.368 | INFO     | src.policies:train:109 - Episode 1992\n",
      "2021-08-25 11:22:02.419 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:02.420 | INFO     | src.policies:train:121 - Mean episode return: 122.0\n",
      "2021-08-25 11:22:02.421 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 132.58\n",
      "2021-08-25 11:22:02.422 | INFO     | src.policies:train:109 - Episode 1993\n",
      "2021-08-25 11:22:02.498 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:02.499 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:02.500 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 134.0\n",
      "2021-08-25 11:22:02.501 | WARNING  | src.policies:train:131 - The actual batch size is 369, instead of 200\n",
      "2021-08-25 11:22:02.511 | INFO     | src.policies:train:157 - Total loss: 1.0029534101486206\n",
      "2021-08-25 11:22:02.515 | INFO     | src.policies:train:103 - Epoch 329 / 800\n",
      "2021-08-25 11:22:02.516 | INFO     | src.policies:train:109 - Episode 1994\n",
      "2021-08-25 11:22:02.597 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:02.599 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:02.600 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 135.66\n",
      "2021-08-25 11:22:02.607 | INFO     | src.policies:train:157 - Total loss: 1.0007754564285278\n",
      "2021-08-25 11:22:02.610 | INFO     | src.policies:train:103 - Epoch 330 / 800\n",
      "2021-08-25 11:22:02.612 | INFO     | src.policies:train:109 - Episode 1995\n",
      "2021-08-25 11:22:02.686 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:02.688 | INFO     | src.policies:train:121 - Mean episode return: 190.0\n",
      "2021-08-25 11:22:02.689 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 135.9\n",
      "2021-08-25 11:22:02.690 | INFO     | src.policies:train:109 - Episode 1996\n",
      "2021-08-25 11:22:02.764 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:02.765 | INFO     | src.policies:train:121 - Mean episode return: 181.0\n",
      "2021-08-25 11:22:02.766 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 137.12\n",
      "2021-08-25 11:22:02.767 | WARNING  | src.policies:train:131 - The actual batch size is 371, instead of 200\n",
      "2021-08-25 11:22:02.776 | INFO     | src.policies:train:157 - Total loss: 1.003018856048584\n",
      "2021-08-25 11:22:02.780 | INFO     | src.policies:train:103 - Epoch 331 / 800\n",
      "2021-08-25 11:22:02.781 | INFO     | src.policies:train:109 - Episode 1997\n",
      "2021-08-25 11:22:02.858 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:02.860 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:02.862 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 137.82\n",
      "2021-08-25 11:22:02.868 | INFO     | src.policies:train:157 - Total loss: 1.0006756782531738\n",
      "2021-08-25 11:22:02.872 | INFO     | src.policies:train:103 - Epoch 332 / 800\n",
      "2021-08-25 11:22:02.873 | INFO     | src.policies:train:109 - Episode 1998\n",
      "2021-08-25 11:22:02.944 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:02.946 | INFO     | src.policies:train:121 - Mean episode return: 184.0\n",
      "2021-08-25 11:22:02.947 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 138.5\n",
      "2021-08-25 11:22:02.948 | INFO     | src.policies:train:109 - Episode 1999\n",
      "2021-08-25 11:22:03.005 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:03.006 | INFO     | src.policies:train:121 - Mean episode return: 141.0\n",
      "2021-08-25 11:22:03.008 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 137.91\n",
      "2021-08-25 11:22:03.009 | WARNING  | src.policies:train:131 - The actual batch size is 325, instead of 200\n",
      "2021-08-25 11:22:03.018 | INFO     | src.policies:train:157 - Total loss: 1.0025129318237305\n",
      "2021-08-25 11:22:03.021 | INFO     | src.policies:train:103 - Epoch 333 / 800\n",
      "2021-08-25 11:22:03.023 | INFO     | src.policies:train:109 - Episode 2000\n",
      "2021-08-25 11:22:03.101 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:03.102 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:03.104 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 139.7\n",
      "2021-08-25 11:22:03.111 | INFO     | src.policies:train:157 - Total loss: 1.0009304285049438\n",
      "2021-08-25 11:22:03.114 | INFO     | src.policies:train:103 - Epoch 334 / 800\n",
      "2021-08-25 11:22:03.115 | INFO     | src.policies:train:109 - Episode 2001\n",
      "2021-08-25 11:22:03.149 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:03.151 | INFO     | src.policies:train:121 - Mean episode return: 81.0\n",
      "2021-08-25 11:22:03.152 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 139.24\n",
      "2021-08-25 11:22:03.154 | INFO     | src.policies:train:109 - Episode 2002\n",
      "2021-08-25 11:22:03.217 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:03.218 | INFO     | src.policies:train:121 - Mean episode return: 153.0\n",
      "2021-08-25 11:22:03.219 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 140.14\n",
      "2021-08-25 11:22:03.220 | WARNING  | src.policies:train:131 - The actual batch size is 234, instead of 200\n",
      "2021-08-25 11:22:03.228 | INFO     | src.policies:train:157 - Total loss: 1.0012320280075073\n",
      "2021-08-25 11:22:03.231 | INFO     | src.policies:train:103 - Epoch 335 / 800\n",
      "2021-08-25 11:22:03.232 | INFO     | src.policies:train:109 - Episode 2003\n",
      "2021-08-25 11:22:03.290 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:03.292 | INFO     | src.policies:train:121 - Mean episode return: 148.0\n",
      "2021-08-25 11:22:03.293 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 141.44\n",
      "2021-08-25 11:22:03.294 | INFO     | src.policies:train:109 - Episode 2004\n",
      "2021-08-25 11:22:03.376 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:03.377 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:03.378 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 141.53\n",
      "2021-08-25 11:22:03.379 | WARNING  | src.policies:train:131 - The actual batch size is 348, instead of 200\n",
      "2021-08-25 11:22:03.388 | INFO     | src.policies:train:157 - Total loss: 1.0027220249176025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:22:03.392 | INFO     | src.policies:train:103 - Epoch 336 / 800\n",
      "2021-08-25 11:22:03.394 | INFO     | src.policies:train:109 - Episode 2005\n",
      "2021-08-25 11:22:03.471 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:03.473 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:03.474 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 142.24\n",
      "2021-08-25 11:22:03.481 | INFO     | src.policies:train:157 - Total loss: 1.000608205795288\n",
      "2021-08-25 11:22:03.485 | INFO     | src.policies:train:103 - Epoch 337 / 800\n",
      "2021-08-25 11:22:03.486 | INFO     | src.policies:train:109 - Episode 2006\n",
      "2021-08-25 11:22:03.550 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:03.551 | INFO     | src.policies:train:121 - Mean episode return: 160.0\n",
      "2021-08-25 11:22:03.552 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 142.48\n",
      "2021-08-25 11:22:03.553 | INFO     | src.policies:train:109 - Episode 2007\n",
      "2021-08-25 11:22:03.596 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:03.598 | INFO     | src.policies:train:121 - Mean episode return: 106.0\n",
      "2021-08-25 11:22:03.598 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 141.54\n",
      "2021-08-25 11:22:03.599 | WARNING  | src.policies:train:131 - The actual batch size is 266, instead of 200\n",
      "2021-08-25 11:22:03.606 | INFO     | src.policies:train:157 - Total loss: 1.0018665790557861\n",
      "2021-08-25 11:22:03.609 | INFO     | src.policies:train:103 - Epoch 338 / 800\n",
      "2021-08-25 11:22:03.610 | INFO     | src.policies:train:109 - Episode 2008\n",
      "2021-08-25 11:22:03.681 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:03.683 | INFO     | src.policies:train:121 - Mean episode return: 193.0\n",
      "2021-08-25 11:22:03.684 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 143.06\n",
      "2021-08-25 11:22:03.685 | INFO     | src.policies:train:109 - Episode 2009\n",
      "2021-08-25 11:22:03.761 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:03.762 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:03.763 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 144.07\n",
      "2021-08-25 11:22:03.764 | WARNING  | src.policies:train:131 - The actual batch size is 393, instead of 200\n",
      "2021-08-25 11:22:03.771 | INFO     | src.policies:train:157 - Total loss: 1.0032899379730225\n",
      "2021-08-25 11:22:03.774 | INFO     | src.policies:train:103 - Epoch 339 / 800\n",
      "2021-08-25 11:22:03.775 | INFO     | src.policies:train:109 - Episode 2010\n",
      "2021-08-25 11:22:03.831 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:03.833 | INFO     | src.policies:train:121 - Mean episode return: 144.0\n",
      "2021-08-25 11:22:03.834 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 145.16\n",
      "2021-08-25 11:22:03.835 | INFO     | src.policies:train:109 - Episode 2011\n",
      "2021-08-25 11:22:03.911 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:03.913 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:03.914 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 145.61\n",
      "2021-08-25 11:22:03.915 | WARNING  | src.policies:train:131 - The actual batch size is 344, instead of 200\n",
      "2021-08-25 11:22:03.922 | INFO     | src.policies:train:157 - Total loss: 1.0026366710662842\n",
      "2021-08-25 11:22:03.925 | INFO     | src.policies:train:103 - Epoch 340 / 800\n",
      "2021-08-25 11:22:03.926 | INFO     | src.policies:train:109 - Episode 2012\n",
      "2021-08-25 11:22:03.986 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:03.988 | INFO     | src.policies:train:121 - Mean episode return: 154.0\n",
      "2021-08-25 11:22:03.990 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 146.34\n",
      "2021-08-25 11:22:03.990 | INFO     | src.policies:train:109 - Episode 2013\n",
      "2021-08-25 11:22:04.043 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:04.044 | INFO     | src.policies:train:121 - Mean episode return: 137.0\n",
      "2021-08-25 11:22:04.045 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 146.34\n",
      "2021-08-25 11:22:04.046 | WARNING  | src.policies:train:131 - The actual batch size is 291, instead of 200\n",
      "2021-08-25 11:22:04.052 | INFO     | src.policies:train:157 - Total loss: 1.0019971132278442\n",
      "2021-08-25 11:22:04.056 | INFO     | src.policies:train:103 - Epoch 341 / 800\n",
      "2021-08-25 11:22:04.057 | INFO     | src.policies:train:109 - Episode 2014\n",
      "2021-08-25 11:22:04.131 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:04.133 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:04.133 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 146.34\n",
      "2021-08-25 11:22:04.139 | INFO     | src.policies:train:157 - Total loss: 1.000687837600708\n",
      "2021-08-25 11:22:04.142 | INFO     | src.policies:train:103 - Epoch 342 / 800\n",
      "2021-08-25 11:22:04.143 | INFO     | src.policies:train:109 - Episode 2015\n",
      "2021-08-25 11:22:04.209 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:04.211 | INFO     | src.policies:train:121 - Mean episode return: 177.0\n",
      "2021-08-25 11:22:04.212 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 146.78\n",
      "2021-08-25 11:22:04.212 | INFO     | src.policies:train:109 - Episode 2016\n",
      "2021-08-25 11:22:04.277 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:04.278 | INFO     | src.policies:train:121 - Mean episode return: 166.0\n",
      "2021-08-25 11:22:04.279 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 146.95\n",
      "2021-08-25 11:22:04.280 | WARNING  | src.policies:train:131 - The actual batch size is 343, instead of 200\n",
      "2021-08-25 11:22:04.287 | INFO     | src.policies:train:157 - Total loss: 1.002679705619812\n",
      "2021-08-25 11:22:04.290 | INFO     | src.policies:train:103 - Epoch 343 / 800\n",
      "2021-08-25 11:22:04.291 | INFO     | src.policies:train:109 - Episode 2017\n",
      "2021-08-25 11:22:04.369 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:04.370 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:04.371 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 148.77\n",
      "2021-08-25 11:22:04.376 | INFO     | src.policies:train:157 - Total loss: 1.000691294670105\n",
      "2021-08-25 11:22:04.379 | INFO     | src.policies:train:103 - Epoch 344 / 800\n",
      "2021-08-25 11:22:04.380 | INFO     | src.policies:train:109 - Episode 2018\n",
      "2021-08-25 11:22:04.439 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:04.441 | INFO     | src.policies:train:121 - Mean episode return: 159.0\n",
      "2021-08-25 11:22:04.442 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 148.36\n",
      "2021-08-25 11:22:04.442 | INFO     | src.policies:train:109 - Episode 2019\n",
      "2021-08-25 11:22:04.504 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:04.505 | INFO     | src.policies:train:121 - Mean episode return: 161.0\n",
      "2021-08-25 11:22:04.506 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 148.74\n",
      "2021-08-25 11:22:04.507 | WARNING  | src.policies:train:131 - The actual batch size is 320, instead of 200\n",
      "2021-08-25 11:22:04.514 | INFO     | src.policies:train:157 - Total loss: 1.0024442672729492\n",
      "2021-08-25 11:22:04.517 | INFO     | src.policies:train:103 - Epoch 345 / 800\n",
      "2021-08-25 11:22:04.518 | INFO     | src.policies:train:109 - Episode 2020\n",
      "2021-08-25 11:22:04.592 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:04.594 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:04.595 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 148.74\n",
      "2021-08-25 11:22:04.600 | INFO     | src.policies:train:157 - Total loss: 1.0004924535751343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:22:04.603 | INFO     | src.policies:train:103 - Epoch 346 / 800\n",
      "2021-08-25 11:22:04.604 | INFO     | src.policies:train:109 - Episode 2021\n",
      "2021-08-25 11:22:04.680 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:04.682 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:04.683 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 149.41\n",
      "2021-08-25 11:22:04.689 | INFO     | src.policies:train:157 - Total loss: 1.0006147623062134\n",
      "2021-08-25 11:22:04.692 | INFO     | src.policies:train:103 - Epoch 347 / 800\n",
      "2021-08-25 11:22:04.692 | INFO     | src.policies:train:109 - Episode 2022\n",
      "2021-08-25 11:22:04.769 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:04.771 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:04.772 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 150.03\n",
      "2021-08-25 11:22:04.777 | INFO     | src.policies:train:157 - Total loss: 1.0006680488586426\n",
      "2021-08-25 11:22:04.780 | INFO     | src.policies:train:103 - Epoch 348 / 800\n",
      "2021-08-25 11:22:04.781 | INFO     | src.policies:train:109 - Episode 2023\n",
      "2021-08-25 11:22:04.852 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:04.853 | INFO     | src.policies:train:121 - Mean episode return: 186.0\n",
      "2021-08-25 11:22:04.854 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 150.59\n",
      "2021-08-25 11:22:04.855 | INFO     | src.policies:train:109 - Episode 2024\n",
      "2021-08-25 11:22:04.897 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:04.899 | INFO     | src.policies:train:121 - Mean episode return: 106.0\n",
      "2021-08-25 11:22:04.900 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 150.15\n",
      "2021-08-25 11:22:04.901 | WARNING  | src.policies:train:131 - The actual batch size is 292, instead of 200\n",
      "2021-08-25 11:22:04.907 | INFO     | src.policies:train:157 - Total loss: 1.002195119857788\n",
      "2021-08-25 11:22:04.910 | INFO     | src.policies:train:103 - Epoch 349 / 800\n",
      "2021-08-25 11:22:04.911 | INFO     | src.policies:train:109 - Episode 2025\n",
      "2021-08-25 11:22:04.986 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:04.988 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:04.989 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 151.38\n",
      "2021-08-25 11:22:04.994 | INFO     | src.policies:train:157 - Total loss: 1.0007939338684082\n",
      "2021-08-25 11:22:04.997 | INFO     | src.policies:train:103 - Epoch 350 / 800\n",
      "2021-08-25 11:22:04.998 | INFO     | src.policies:train:109 - Episode 2026\n",
      "2021-08-25 11:22:05.075 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:05.077 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:05.078 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 152.08\n",
      "2021-08-25 11:22:05.084 | INFO     | src.policies:train:157 - Total loss: 1.0005296468734741\n",
      "2021-08-25 11:22:05.087 | INFO     | src.policies:train:103 - Epoch 351 / 800\n",
      "2021-08-25 11:22:05.088 | INFO     | src.policies:train:109 - Episode 2027\n",
      "2021-08-25 11:22:05.154 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:05.156 | INFO     | src.policies:train:121 - Mean episode return: 178.0\n",
      "2021-08-25 11:22:05.157 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 152.43\n",
      "2021-08-25 11:22:05.158 | INFO     | src.policies:train:109 - Episode 2028\n",
      "2021-08-25 11:22:05.236 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:05.237 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:05.238 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 152.91\n",
      "2021-08-25 11:22:05.239 | WARNING  | src.policies:train:131 - The actual batch size is 378, instead of 200\n",
      "2021-08-25 11:22:05.246 | INFO     | src.policies:train:157 - Total loss: 1.0030120611190796\n",
      "2021-08-25 11:22:05.249 | INFO     | src.policies:train:103 - Epoch 352 / 800\n",
      "2021-08-25 11:22:05.251 | INFO     | src.policies:train:109 - Episode 2029\n",
      "2021-08-25 11:22:05.327 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:05.329 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:05.331 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 153.86\n",
      "2021-08-25 11:22:05.338 | INFO     | src.policies:train:157 - Total loss: 1.0006519556045532\n",
      "2021-08-25 11:22:05.341 | INFO     | src.policies:train:103 - Epoch 353 / 800\n",
      "2021-08-25 11:22:05.342 | INFO     | src.policies:train:109 - Episode 2030\n",
      "2021-08-25 11:22:05.390 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:05.392 | INFO     | src.policies:train:121 - Mean episode return: 125.0\n",
      "2021-08-25 11:22:05.393 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 153.16\n",
      "2021-08-25 11:22:05.394 | INFO     | src.policies:train:109 - Episode 2031\n",
      "2021-08-25 11:22:05.470 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:05.471 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:05.472 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 153.16\n",
      "2021-08-25 11:22:05.473 | WARNING  | src.policies:train:131 - The actual batch size is 325, instead of 200\n",
      "2021-08-25 11:22:05.480 | INFO     | src.policies:train:157 - Total loss: 1.0025410652160645\n",
      "2021-08-25 11:22:05.483 | INFO     | src.policies:train:103 - Epoch 354 / 800\n",
      "2021-08-25 11:22:05.485 | INFO     | src.policies:train:109 - Episode 2032\n",
      "2021-08-25 11:22:05.559 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:05.560 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:05.561 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 153.26\n",
      "2021-08-25 11:22:05.567 | INFO     | src.policies:train:157 - Total loss: 1.0007739067077637\n",
      "2021-08-25 11:22:05.570 | INFO     | src.policies:train:103 - Epoch 355 / 800\n",
      "2021-08-25 11:22:05.571 | INFO     | src.policies:train:109 - Episode 2033\n",
      "2021-08-25 11:22:05.645 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:05.647 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:05.648 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 153.26\n",
      "2021-08-25 11:22:05.654 | INFO     | src.policies:train:157 - Total loss: 1.0003193616867065\n",
      "2021-08-25 11:22:05.657 | INFO     | src.policies:train:103 - Epoch 356 / 800\n",
      "2021-08-25 11:22:05.658 | INFO     | src.policies:train:109 - Episode 2034\n",
      "2021-08-25 11:22:05.721 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:05.723 | INFO     | src.policies:train:121 - Mean episode return: 166.0\n",
      "2021-08-25 11:22:05.724 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 152.92\n",
      "2021-08-25 11:22:05.725 | INFO     | src.policies:train:109 - Episode 2035\n",
      "2021-08-25 11:22:05.796 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:05.798 | INFO     | src.policies:train:121 - Mean episode return: 188.0\n",
      "2021-08-25 11:22:05.799 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 153.24\n",
      "2021-08-25 11:22:05.800 | WARNING  | src.policies:train:131 - The actual batch size is 354, instead of 200\n",
      "2021-08-25 11:22:05.806 | INFO     | src.policies:train:157 - Total loss: 1.002852201461792\n",
      "2021-08-25 11:22:05.809 | INFO     | src.policies:train:103 - Epoch 357 / 800\n",
      "2021-08-25 11:22:05.810 | INFO     | src.policies:train:109 - Episode 2036\n",
      "2021-08-25 11:22:05.886 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:05.888 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:05.889 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 154.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:22:05.894 | INFO     | src.policies:train:157 - Total loss: 1.0006686449050903\n",
      "2021-08-25 11:22:05.897 | INFO     | src.policies:train:103 - Epoch 358 / 800\n",
      "2021-08-25 11:22:05.898 | INFO     | src.policies:train:109 - Episode 2037\n",
      "2021-08-25 11:22:05.947 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:05.948 | INFO     | src.policies:train:121 - Mean episode return: 121.0\n",
      "2021-08-25 11:22:05.949 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 153.52\n",
      "2021-08-25 11:22:05.950 | INFO     | src.policies:train:109 - Episode 2038\n",
      "2021-08-25 11:22:05.980 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:05.981 | INFO     | src.policies:train:121 - Mean episode return: 70.0\n",
      "2021-08-25 11:22:05.982 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 152.7\n",
      "2021-08-25 11:22:05.983 | INFO     | src.policies:train:109 - Episode 2039\n",
      "2021-08-25 11:22:06.060 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:06.061 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:06.063 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 154.3\n",
      "2021-08-25 11:22:06.064 | WARNING  | src.policies:train:131 - The actual batch size is 391, instead of 200\n",
      "2021-08-25 11:22:06.071 | INFO     | src.policies:train:157 - Total loss: 1.0027761459350586\n",
      "2021-08-25 11:22:06.074 | INFO     | src.policies:train:103 - Epoch 359 / 800\n",
      "2021-08-25 11:22:06.076 | INFO     | src.policies:train:109 - Episode 2040\n",
      "2021-08-25 11:22:06.138 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:06.140 | INFO     | src.policies:train:121 - Mean episode return: 164.0\n",
      "2021-08-25 11:22:06.141 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 153.94\n",
      "2021-08-25 11:22:06.142 | INFO     | src.policies:train:109 - Episode 2041\n",
      "2021-08-25 11:22:06.208 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:06.209 | INFO     | src.policies:train:121 - Mean episode return: 170.0\n",
      "2021-08-25 11:22:06.210 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 155.42\n",
      "2021-08-25 11:22:06.211 | WARNING  | src.policies:train:131 - The actual batch size is 334, instead of 200\n",
      "2021-08-25 11:22:06.218 | INFO     | src.policies:train:157 - Total loss: 1.0025709867477417\n",
      "2021-08-25 11:22:06.222 | INFO     | src.policies:train:103 - Epoch 360 / 800\n",
      "2021-08-25 11:22:06.223 | INFO     | src.policies:train:109 - Episode 2042\n",
      "2021-08-25 11:22:06.299 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:06.300 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:06.301 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 156.56\n",
      "2021-08-25 11:22:06.307 | INFO     | src.policies:train:157 - Total loss: 1.0005757808685303\n",
      "2021-08-25 11:22:06.310 | INFO     | src.policies:train:103 - Epoch 361 / 800\n",
      "2021-08-25 11:22:06.311 | INFO     | src.policies:train:109 - Episode 2043\n",
      "2021-08-25 11:22:06.381 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:06.383 | INFO     | src.policies:train:121 - Mean episode return: 188.0\n",
      "2021-08-25 11:22:06.385 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 156.44\n",
      "2021-08-25 11:22:06.385 | INFO     | src.policies:train:109 - Episode 2044\n",
      "2021-08-25 11:22:06.457 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:06.458 | INFO     | src.policies:train:121 - Mean episode return: 183.0\n",
      "2021-08-25 11:22:06.459 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 157.25\n",
      "2021-08-25 11:22:06.460 | WARNING  | src.policies:train:131 - The actual batch size is 371, instead of 200\n",
      "2021-08-25 11:22:06.467 | INFO     | src.policies:train:157 - Total loss: 1.0030312538146973\n",
      "2021-08-25 11:22:06.470 | INFO     | src.policies:train:103 - Epoch 362 / 800\n",
      "2021-08-25 11:22:06.471 | INFO     | src.policies:train:109 - Episode 2045\n",
      "2021-08-25 11:22:06.544 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:06.546 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:06.547 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 157.38\n",
      "2021-08-25 11:22:06.552 | INFO     | src.policies:train:157 - Total loss: 1.000420093536377\n",
      "2021-08-25 11:22:06.556 | INFO     | src.policies:train:103 - Epoch 363 / 800\n",
      "2021-08-25 11:22:06.556 | INFO     | src.policies:train:109 - Episode 2046\n",
      "2021-08-25 11:22:06.567 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:06.569 | INFO     | src.policies:train:121 - Mean episode return: 22.0\n",
      "2021-08-25 11:22:06.570 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 156.05\n",
      "2021-08-25 11:22:06.571 | INFO     | src.policies:train:109 - Episode 2047\n",
      "2021-08-25 11:22:06.647 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:06.648 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:06.649 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 157.3\n",
      "2021-08-25 11:22:06.650 | WARNING  | src.policies:train:131 - The actual batch size is 222, instead of 200\n",
      "2021-08-25 11:22:06.656 | INFO     | src.policies:train:157 - Total loss: 1.0009750127792358\n",
      "2021-08-25 11:22:06.660 | INFO     | src.policies:train:103 - Epoch 364 / 800\n",
      "2021-08-25 11:22:06.661 | INFO     | src.policies:train:109 - Episode 2048\n",
      "2021-08-25 11:22:06.736 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:06.738 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:06.739 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 159.14\n",
      "2021-08-25 11:22:06.744 | INFO     | src.policies:train:157 - Total loss: 1.0004931688308716\n",
      "2021-08-25 11:22:06.747 | INFO     | src.policies:train:103 - Epoch 365 / 800\n",
      "2021-08-25 11:22:06.748 | INFO     | src.policies:train:109 - Episode 2049\n",
      "2021-08-25 11:22:06.826 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:06.828 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:06.829 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 160.74\n",
      "2021-08-25 11:22:06.835 | INFO     | src.policies:train:157 - Total loss: 1.000598669052124\n",
      "2021-08-25 11:22:06.838 | INFO     | src.policies:train:103 - Epoch 366 / 800\n",
      "2021-08-25 11:22:06.839 | INFO     | src.policies:train:109 - Episode 2050\n",
      "2021-08-25 11:22:06.897 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:06.899 | INFO     | src.policies:train:121 - Mean episode return: 151.0\n",
      "2021-08-25 11:22:06.900 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 160.25\n",
      "2021-08-25 11:22:06.901 | INFO     | src.policies:train:109 - Episode 2051\n",
      "2021-08-25 11:22:06.912 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:06.913 | INFO     | src.policies:train:121 - Mean episode return: 21.0\n",
      "2021-08-25 11:22:06.914 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 160.06\n",
      "2021-08-25 11:22:06.915 | INFO     | src.policies:train:109 - Episode 2052\n",
      "2021-08-25 11:22:06.963 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:06.964 | INFO     | src.policies:train:121 - Mean episode return: 125.0\n",
      "2021-08-25 11:22:06.965 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 159.31\n",
      "2021-08-25 11:22:06.966 | WARNING  | src.policies:train:131 - The actual batch size is 297, instead of 200\n",
      "2021-08-25 11:22:06.973 | INFO     | src.policies:train:157 - Total loss: 1.0019891262054443\n",
      "2021-08-25 11:22:06.976 | INFO     | src.policies:train:103 - Epoch 367 / 800\n",
      "2021-08-25 11:22:06.977 | INFO     | src.policies:train:109 - Episode 2053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:22:07.053 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:07.054 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:07.055 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 159.31\n",
      "2021-08-25 11:22:07.061 | INFO     | src.policies:train:157 - Total loss: 1.0006074905395508\n",
      "2021-08-25 11:22:07.064 | INFO     | src.policies:train:103 - Epoch 368 / 800\n",
      "2021-08-25 11:22:07.065 | INFO     | src.policies:train:109 - Episode 2054\n",
      "2021-08-25 11:22:07.120 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:07.122 | INFO     | src.policies:train:121 - Mean episode return: 143.0\n",
      "2021-08-25 11:22:07.123 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 159.0\n",
      "2021-08-25 11:22:07.124 | INFO     | src.policies:train:109 - Episode 2055\n",
      "2021-08-25 11:22:07.200 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:07.201 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:07.202 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 160.81\n",
      "2021-08-25 11:22:07.203 | WARNING  | src.policies:train:131 - The actual batch size is 343, instead of 200\n",
      "2021-08-25 11:22:07.209 | INFO     | src.policies:train:157 - Total loss: 1.002686619758606\n",
      "2021-08-25 11:22:07.213 | INFO     | src.policies:train:103 - Epoch 369 / 800\n",
      "2021-08-25 11:22:07.214 | INFO     | src.policies:train:109 - Episode 2056\n",
      "2021-08-25 11:22:07.266 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:07.268 | INFO     | src.policies:train:121 - Mean episode return: 134.0\n",
      "2021-08-25 11:22:07.269 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 160.15\n",
      "2021-08-25 11:22:07.270 | INFO     | src.policies:train:109 - Episode 2057\n",
      "2021-08-25 11:22:07.333 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:07.334 | INFO     | src.policies:train:121 - Mean episode return: 168.0\n",
      "2021-08-25 11:22:07.335 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 161.63\n",
      "2021-08-25 11:22:07.336 | WARNING  | src.policies:train:131 - The actual batch size is 302, instead of 200\n",
      "2021-08-25 11:22:07.344 | INFO     | src.policies:train:157 - Total loss: 1.0023150444030762\n",
      "2021-08-25 11:22:07.347 | INFO     | src.policies:train:103 - Epoch 370 / 800\n",
      "2021-08-25 11:22:07.348 | INFO     | src.policies:train:109 - Episode 2058\n",
      "2021-08-25 11:22:07.412 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:07.413 | INFO     | src.policies:train:121 - Mean episode return: 173.0\n",
      "2021-08-25 11:22:07.415 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 162.24\n",
      "2021-08-25 11:22:07.415 | INFO     | src.policies:train:109 - Episode 2059\n",
      "2021-08-25 11:22:07.491 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:07.493 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:07.494 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 162.71\n",
      "2021-08-25 11:22:07.494 | WARNING  | src.policies:train:131 - The actual batch size is 373, instead of 200\n",
      "2021-08-25 11:22:07.501 | INFO     | src.policies:train:157 - Total loss: 1.002727746963501\n",
      "2021-08-25 11:22:07.504 | INFO     | src.policies:train:103 - Epoch 371 / 800\n",
      "2021-08-25 11:22:07.505 | INFO     | src.policies:train:109 - Episode 2060\n",
      "2021-08-25 11:22:07.580 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:07.582 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:07.583 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 162.71\n",
      "2021-08-25 11:22:07.588 | INFO     | src.policies:train:157 - Total loss: 1.000212550163269\n",
      "2021-08-25 11:22:07.591 | INFO     | src.policies:train:103 - Epoch 372 / 800\n",
      "2021-08-25 11:22:07.592 | INFO     | src.policies:train:109 - Episode 2061\n",
      "2021-08-25 11:22:07.665 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:07.667 | INFO     | src.policies:train:121 - Mean episode return: 196.0\n",
      "2021-08-25 11:22:07.668 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 164.49\n",
      "2021-08-25 11:22:07.669 | INFO     | src.policies:train:109 - Episode 2062\n",
      "2021-08-25 11:22:07.745 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:07.747 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:07.748 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 164.94\n",
      "2021-08-25 11:22:07.749 | WARNING  | src.policies:train:131 - The actual batch size is 396, instead of 200\n",
      "2021-08-25 11:22:07.756 | INFO     | src.policies:train:157 - Total loss: 1.0030264854431152\n",
      "2021-08-25 11:22:07.759 | INFO     | src.policies:train:103 - Epoch 373 / 800\n",
      "2021-08-25 11:22:07.760 | INFO     | src.policies:train:109 - Episode 2063\n",
      "2021-08-25 11:22:07.820 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:07.821 | INFO     | src.policies:train:121 - Mean episode return: 153.0\n",
      "2021-08-25 11:22:07.823 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 164.79\n",
      "2021-08-25 11:22:07.823 | INFO     | src.policies:train:109 - Episode 2064\n",
      "2021-08-25 11:22:07.898 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:07.900 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:07.901 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 166.07\n",
      "2021-08-25 11:22:07.901 | WARNING  | src.policies:train:131 - The actual batch size is 353, instead of 200\n",
      "2021-08-25 11:22:07.908 | INFO     | src.policies:train:157 - Total loss: 1.0027484893798828\n",
      "2021-08-25 11:22:07.911 | INFO     | src.policies:train:103 - Epoch 374 / 800\n",
      "2021-08-25 11:22:07.913 | INFO     | src.policies:train:109 - Episode 2065\n",
      "2021-08-25 11:22:07.987 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:07.989 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:07.990 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 166.14\n",
      "2021-08-25 11:22:07.995 | INFO     | src.policies:train:157 - Total loss: 1.0006129741668701\n",
      "2021-08-25 11:22:07.999 | INFO     | src.policies:train:103 - Epoch 375 / 800\n",
      "2021-08-25 11:22:08.000 | INFO     | src.policies:train:109 - Episode 2066\n",
      "2021-08-25 11:22:08.076 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:08.078 | INFO     | src.policies:train:121 - Mean episode return: 199.0\n",
      "2021-08-25 11:22:08.079 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 166.13\n",
      "2021-08-25 11:22:08.080 | INFO     | src.policies:train:109 - Episode 2067\n",
      "2021-08-25 11:22:08.157 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:08.159 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:08.160 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 166.13\n",
      "2021-08-25 11:22:08.161 | WARNING  | src.policies:train:131 - The actual batch size is 399, instead of 200\n",
      "2021-08-25 11:22:08.167 | INFO     | src.policies:train:157 - Total loss: 1.0030103921890259\n",
      "2021-08-25 11:22:08.171 | INFO     | src.policies:train:103 - Epoch 376 / 800\n",
      "2021-08-25 11:22:08.172 | INFO     | src.policies:train:109 - Episode 2068\n",
      "2021-08-25 11:22:08.247 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:08.249 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:08.250 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 166.13\n",
      "2021-08-25 11:22:08.255 | INFO     | src.policies:train:157 - Total loss: 1.0004526376724243\n",
      "2021-08-25 11:22:08.259 | INFO     | src.policies:train:103 - Epoch 377 / 800\n",
      "2021-08-25 11:22:08.260 | INFO     | src.policies:train:109 - Episode 2069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:22:08.301 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:08.302 | INFO     | src.policies:train:121 - Mean episode return: 104.0\n",
      "2021-08-25 11:22:08.303 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 165.82\n",
      "2021-08-25 11:22:08.304 | INFO     | src.policies:train:109 - Episode 2070\n",
      "2021-08-25 11:22:08.382 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:08.383 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:08.385 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 167.55\n",
      "2021-08-25 11:22:08.385 | WARNING  | src.policies:train:131 - The actual batch size is 304, instead of 200\n",
      "2021-08-25 11:22:08.392 | INFO     | src.policies:train:157 - Total loss: 1.0021560192108154\n",
      "2021-08-25 11:22:08.396 | INFO     | src.policies:train:103 - Epoch 378 / 800\n",
      "2021-08-25 11:22:08.397 | INFO     | src.policies:train:109 - Episode 2071\n",
      "2021-08-25 11:22:08.471 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:08.473 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:08.474 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 167.84\n",
      "2021-08-25 11:22:08.479 | INFO     | src.policies:train:157 - Total loss: 1.0005664825439453\n",
      "2021-08-25 11:22:08.482 | INFO     | src.policies:train:103 - Epoch 379 / 800\n",
      "2021-08-25 11:22:08.483 | INFO     | src.policies:train:109 - Episode 2072\n",
      "2021-08-25 11:22:08.496 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:08.497 | INFO     | src.policies:train:121 - Mean episode return: 27.0\n",
      "2021-08-25 11:22:08.498 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 166.11\n",
      "2021-08-25 11:22:08.499 | INFO     | src.policies:train:109 - Episode 2073\n",
      "2021-08-25 11:22:08.572 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:08.573 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:08.574 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 166.11\n",
      "2021-08-25 11:22:08.575 | WARNING  | src.policies:train:131 - The actual batch size is 227, instead of 200\n",
      "2021-08-25 11:22:08.581 | INFO     | src.policies:train:157 - Total loss: 1.0010039806365967\n",
      "2021-08-25 11:22:08.584 | INFO     | src.policies:train:103 - Epoch 380 / 800\n",
      "2021-08-25 11:22:08.585 | INFO     | src.policies:train:109 - Episode 2074\n",
      "2021-08-25 11:22:08.645 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:08.647 | INFO     | src.policies:train:121 - Mean episode return: 162.0\n",
      "2021-08-25 11:22:08.648 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 166.87\n",
      "2021-08-25 11:22:08.648 | INFO     | src.policies:train:109 - Episode 2075\n",
      "2021-08-25 11:22:08.716 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:08.718 | INFO     | src.policies:train:121 - Mean episode return: 176.0\n",
      "2021-08-25 11:22:08.719 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 166.91\n",
      "2021-08-25 11:22:08.719 | WARNING  | src.policies:train:131 - The actual batch size is 338, instead of 200\n",
      "2021-08-25 11:22:08.726 | INFO     | src.policies:train:157 - Total loss: 1.0025084018707275\n",
      "2021-08-25 11:22:08.730 | INFO     | src.policies:train:103 - Epoch 381 / 800\n",
      "2021-08-25 11:22:08.731 | INFO     | src.policies:train:109 - Episode 2076\n",
      "2021-08-25 11:22:08.806 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:08.808 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:08.809 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 168.24\n",
      "2021-08-25 11:22:08.815 | INFO     | src.policies:train:157 - Total loss: 1.0005308389663696\n",
      "2021-08-25 11:22:08.818 | INFO     | src.policies:train:103 - Epoch 382 / 800\n",
      "2021-08-25 11:22:08.819 | INFO     | src.policies:train:109 - Episode 2077\n",
      "2021-08-25 11:22:08.896 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:08.897 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:08.898 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 168.24\n",
      "2021-08-25 11:22:08.904 | INFO     | src.policies:train:157 - Total loss: 1.0004942417144775\n",
      "2021-08-25 11:22:08.907 | INFO     | src.policies:train:103 - Epoch 383 / 800\n",
      "2021-08-25 11:22:08.908 | INFO     | src.policies:train:109 - Episode 2078\n",
      "2021-08-25 11:22:08.980 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:08.982 | INFO     | src.policies:train:121 - Mean episode return: 184.0\n",
      "2021-08-25 11:22:08.983 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 168.14\n",
      "2021-08-25 11:22:08.984 | INFO     | src.policies:train:109 - Episode 2079\n",
      "2021-08-25 11:22:09.037 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:09.039 | INFO     | src.policies:train:121 - Mean episode return: 134.0\n",
      "2021-08-25 11:22:09.040 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 169.08\n",
      "2021-08-25 11:22:09.040 | WARNING  | src.policies:train:131 - The actual batch size is 318, instead of 200\n",
      "2021-08-25 11:22:09.047 | INFO     | src.policies:train:157 - Total loss: 1.00229811668396\n",
      "2021-08-25 11:22:09.050 | INFO     | src.policies:train:103 - Epoch 384 / 800\n",
      "2021-08-25 11:22:09.052 | INFO     | src.policies:train:109 - Episode 2080\n",
      "2021-08-25 11:22:09.116 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:09.117 | INFO     | src.policies:train:121 - Mean episode return: 171.0\n",
      "2021-08-25 11:22:09.118 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 168.79\n",
      "2021-08-25 11:22:09.119 | INFO     | src.policies:train:109 - Episode 2081\n",
      "2021-08-25 11:22:09.192 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:09.193 | INFO     | src.policies:train:121 - Mean episode return: 196.0\n",
      "2021-08-25 11:22:09.194 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 169.0\n",
      "2021-08-25 11:22:09.195 | WARNING  | src.policies:train:131 - The actual batch size is 367, instead of 200\n",
      "2021-08-25 11:22:09.202 | INFO     | src.policies:train:157 - Total loss: 1.0027363300323486\n",
      "2021-08-25 11:22:09.205 | INFO     | src.policies:train:103 - Epoch 385 / 800\n",
      "2021-08-25 11:22:09.206 | INFO     | src.policies:train:109 - Episode 2082\n",
      "2021-08-25 11:22:09.263 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:09.265 | INFO     | src.policies:train:121 - Mean episode return: 152.0\n",
      "2021-08-25 11:22:09.266 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 168.52\n",
      "2021-08-25 11:22:09.266 | INFO     | src.policies:train:109 - Episode 2083\n",
      "2021-08-25 11:22:09.338 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:09.339 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:09.340 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 168.52\n",
      "2021-08-25 11:22:09.341 | WARNING  | src.policies:train:131 - The actual batch size is 352, instead of 200\n",
      "2021-08-25 11:22:09.348 | INFO     | src.policies:train:157 - Total loss: 1.002720594406128\n",
      "2021-08-25 11:22:09.351 | INFO     | src.policies:train:103 - Epoch 386 / 800\n",
      "2021-08-25 11:22:09.352 | INFO     | src.policies:train:109 - Episode 2084\n",
      "2021-08-25 11:22:09.421 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:09.422 | INFO     | src.policies:train:121 - Mean episode return: 191.0\n",
      "2021-08-25 11:22:09.423 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 168.83\n",
      "2021-08-25 11:22:09.424 | INFO     | src.policies:train:109 - Episode 2085\n",
      "2021-08-25 11:22:09.480 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:09.481 | INFO     | src.policies:train:121 - Mean episode return: 153.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:22:09.482 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 170.21\n",
      "2021-08-25 11:22:09.483 | WARNING  | src.policies:train:131 - The actual batch size is 344, instead of 200\n",
      "2021-08-25 11:22:09.490 | INFO     | src.policies:train:157 - Total loss: 1.0025975704193115\n",
      "2021-08-25 11:22:09.494 | INFO     | src.policies:train:103 - Epoch 387 / 800\n",
      "2021-08-25 11:22:09.495 | INFO     | src.policies:train:109 - Episode 2086\n",
      "2021-08-25 11:22:09.566 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:09.567 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:09.569 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 170.88\n",
      "2021-08-25 11:22:09.574 | INFO     | src.policies:train:157 - Total loss: 1.0005714893341064\n",
      "2021-08-25 11:22:09.577 | INFO     | src.policies:train:103 - Epoch 388 / 800\n",
      "2021-08-25 11:22:09.578 | INFO     | src.policies:train:109 - Episode 2087\n",
      "2021-08-25 11:22:09.649 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:09.651 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:09.652 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 170.88\n",
      "2021-08-25 11:22:09.657 | INFO     | src.policies:train:157 - Total loss: 1.0006901025772095\n",
      "2021-08-25 11:22:09.660 | INFO     | src.policies:train:103 - Epoch 389 / 800\n",
      "2021-08-25 11:22:09.661 | INFO     | src.policies:train:109 - Episode 2088\n",
      "2021-08-25 11:22:09.732 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:09.734 | INFO     | src.policies:train:121 - Mean episode return: 193.0\n",
      "2021-08-25 11:22:09.735 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 170.81\n",
      "2021-08-25 11:22:09.736 | INFO     | src.policies:train:109 - Episode 2089\n",
      "2021-08-25 11:22:09.810 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:09.811 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:09.812 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 171.43\n",
      "2021-08-25 11:22:09.813 | WARNING  | src.policies:train:131 - The actual batch size is 393, instead of 200\n",
      "2021-08-25 11:22:09.820 | INFO     | src.policies:train:157 - Total loss: 1.002795934677124\n",
      "2021-08-25 11:22:09.823 | INFO     | src.policies:train:103 - Epoch 390 / 800\n",
      "2021-08-25 11:22:09.824 | INFO     | src.policies:train:109 - Episode 2090\n",
      "2021-08-25 11:22:09.894 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:09.896 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:09.897 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 171.77\n",
      "2021-08-25 11:22:09.902 | INFO     | src.policies:train:157 - Total loss: 1.0005794763565063\n",
      "2021-08-25 11:22:09.905 | INFO     | src.policies:train:103 - Epoch 391 / 800\n",
      "2021-08-25 11:22:09.906 | INFO     | src.policies:train:109 - Episode 2091\n",
      "2021-08-25 11:22:09.948 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:09.950 | INFO     | src.policies:train:121 - Mean episode return: 117.0\n",
      "2021-08-25 11:22:09.951 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.47\n",
      "2021-08-25 11:22:09.951 | INFO     | src.policies:train:109 - Episode 2092\n",
      "2021-08-25 11:22:10.007 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:10.008 | INFO     | src.policies:train:121 - Mean episode return: 147.0\n",
      "2021-08-25 11:22:10.009 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.72\n",
      "2021-08-25 11:22:10.010 | WARNING  | src.policies:train:131 - The actual batch size is 264, instead of 200\n",
      "2021-08-25 11:22:10.016 | INFO     | src.policies:train:157 - Total loss: 1.0017874240875244\n",
      "2021-08-25 11:22:10.019 | INFO     | src.policies:train:103 - Epoch 392 / 800\n",
      "2021-08-25 11:22:10.020 | INFO     | src.policies:train:109 - Episode 2093\n",
      "2021-08-25 11:22:10.090 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:10.092 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:10.093 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.72\n",
      "2021-08-25 11:22:10.098 | INFO     | src.policies:train:157 - Total loss: 1.0004699230194092\n",
      "2021-08-25 11:22:10.101 | INFO     | src.policies:train:103 - Epoch 393 / 800\n",
      "2021-08-25 11:22:10.102 | INFO     | src.policies:train:109 - Episode 2094\n",
      "2021-08-25 11:22:10.173 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:10.175 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:10.176 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.72\n",
      "2021-08-25 11:22:10.182 | INFO     | src.policies:train:157 - Total loss: 1.0006039142608643\n",
      "2021-08-25 11:22:10.185 | INFO     | src.policies:train:103 - Epoch 394 / 800\n",
      "2021-08-25 11:22:10.186 | INFO     | src.policies:train:109 - Episode 2095\n",
      "2021-08-25 11:22:10.259 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:10.260 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:10.261 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.82\n",
      "2021-08-25 11:22:10.267 | INFO     | src.policies:train:157 - Total loss: 1.0006581544876099\n",
      "2021-08-25 11:22:10.270 | INFO     | src.policies:train:103 - Epoch 395 / 800\n",
      "2021-08-25 11:22:10.271 | INFO     | src.policies:train:109 - Episode 2096\n",
      "2021-08-25 11:22:10.344 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:10.345 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:10.346 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 173.01\n",
      "2021-08-25 11:22:10.351 | INFO     | src.policies:train:157 - Total loss: 1.0006301403045654\n",
      "2021-08-25 11:22:10.354 | INFO     | src.policies:train:103 - Epoch 396 / 800\n",
      "2021-08-25 11:22:10.355 | INFO     | src.policies:train:109 - Episode 2097\n",
      "2021-08-25 11:22:10.421 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:10.423 | INFO     | src.policies:train:121 - Mean episode return: 185.0\n",
      "2021-08-25 11:22:10.424 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.86\n",
      "2021-08-25 11:22:10.425 | INFO     | src.policies:train:109 - Episode 2098\n",
      "2021-08-25 11:22:10.492 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:10.493 | INFO     | src.policies:train:121 - Mean episode return: 184.0\n",
      "2021-08-25 11:22:10.494 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.86\n",
      "2021-08-25 11:22:10.495 | WARNING  | src.policies:train:131 - The actual batch size is 369, instead of 200\n",
      "2021-08-25 11:22:10.502 | INFO     | src.policies:train:157 - Total loss: 1.002816081047058\n",
      "2021-08-25 11:22:10.504 | INFO     | src.policies:train:103 - Epoch 397 / 800\n",
      "2021-08-25 11:22:10.505 | INFO     | src.policies:train:109 - Episode 2099\n",
      "2021-08-25 11:22:10.576 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:10.577 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:10.578 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 173.45\n",
      "2021-08-25 11:22:10.584 | INFO     | src.policies:train:157 - Total loss: 1.000547170639038\n",
      "2021-08-25 11:22:10.587 | INFO     | src.policies:train:103 - Epoch 398 / 800\n",
      "2021-08-25 11:22:10.588 | INFO     | src.policies:train:109 - Episode 2100\n",
      "2021-08-25 11:22:10.662 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:10.664 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:10.665 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 173.45\n",
      "2021-08-25 11:22:10.671 | INFO     | src.policies:train:157 - Total loss: 1.0006598234176636\n",
      "2021-08-25 11:22:10.675 | INFO     | src.policies:train:103 - Epoch 399 / 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:22:10.676 | INFO     | src.policies:train:109 - Episode 2101\n",
      "2021-08-25 11:22:10.753 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:10.755 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:10.756 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.64\n",
      "2021-08-25 11:22:10.763 | INFO     | src.policies:train:157 - Total loss: 1.000580072402954\n",
      "2021-08-25 11:22:10.766 | INFO     | src.policies:train:103 - Epoch 400 / 800\n",
      "2021-08-25 11:22:10.767 | INFO     | src.policies:train:109 - Episode 2102\n",
      "2021-08-25 11:22:10.823 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:10.825 | INFO     | src.policies:train:121 - Mean episode return: 135.0\n",
      "2021-08-25 11:22:10.826 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.46\n",
      "2021-08-25 11:22:10.827 | INFO     | src.policies:train:109 - Episode 2103\n",
      "2021-08-25 11:22:10.900 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:10.901 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:10.902 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.98\n",
      "2021-08-25 11:22:10.903 | WARNING  | src.policies:train:131 - The actual batch size is 335, instead of 200\n",
      "2021-08-25 11:22:10.909 | INFO     | src.policies:train:157 - Total loss: 1.0026155710220337\n",
      "2021-08-25 11:22:10.912 | INFO     | src.policies:train:103 - Epoch 401 / 800\n",
      "2021-08-25 11:22:10.913 | INFO     | src.policies:train:109 - Episode 2104\n",
      "2021-08-25 11:22:10.980 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:10.981 | INFO     | src.policies:train:121 - Mean episode return: 184.0\n",
      "2021-08-25 11:22:10.982 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.82\n",
      "2021-08-25 11:22:10.983 | INFO     | src.policies:train:109 - Episode 2105\n",
      "2021-08-25 11:22:11.055 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:11.056 | INFO     | src.policies:train:121 - Mean episode return: 195.0\n",
      "2021-08-25 11:22:11.057 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.77\n",
      "2021-08-25 11:22:11.058 | WARNING  | src.policies:train:131 - The actual batch size is 379, instead of 200\n",
      "2021-08-25 11:22:11.064 | INFO     | src.policies:train:157 - Total loss: 1.0027766227722168\n",
      "2021-08-25 11:22:11.068 | INFO     | src.policies:train:103 - Epoch 402 / 800\n",
      "2021-08-25 11:22:11.069 | INFO     | src.policies:train:109 - Episode 2106\n",
      "2021-08-25 11:22:11.141 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:11.142 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:11.143 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.17\n",
      "2021-08-25 11:22:11.148 | INFO     | src.policies:train:157 - Total loss: 1.0005627870559692\n",
      "2021-08-25 11:22:11.151 | INFO     | src.policies:train:103 - Epoch 403 / 800\n",
      "2021-08-25 11:22:11.152 | INFO     | src.policies:train:109 - Episode 2107\n",
      "2021-08-25 11:22:11.225 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:11.226 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:11.227 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.11\n",
      "2021-08-25 11:22:11.233 | INFO     | src.policies:train:157 - Total loss: 1.0008527040481567\n",
      "2021-08-25 11:22:11.235 | INFO     | src.policies:train:103 - Epoch 404 / 800\n",
      "2021-08-25 11:22:11.236 | INFO     | src.policies:train:109 - Episode 2108\n",
      "2021-08-25 11:22:11.307 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:11.308 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:11.309 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.18\n",
      "2021-08-25 11:22:11.315 | INFO     | src.policies:train:157 - Total loss: 1.0005055665969849\n",
      "2021-08-25 11:22:11.318 | INFO     | src.policies:train:103 - Epoch 405 / 800\n",
      "2021-08-25 11:22:11.319 | INFO     | src.policies:train:109 - Episode 2109\n",
      "2021-08-25 11:22:11.389 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:11.391 | INFO     | src.policies:train:121 - Mean episode return: 199.0\n",
      "2021-08-25 11:22:11.392 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.17\n",
      "2021-08-25 11:22:11.393 | INFO     | src.policies:train:109 - Episode 2110\n",
      "2021-08-25 11:22:11.450 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:11.451 | INFO     | src.policies:train:121 - Mean episode return: 155.0\n",
      "2021-08-25 11:22:11.452 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.28\n",
      "2021-08-25 11:22:11.453 | WARNING  | src.policies:train:131 - The actual batch size is 354, instead of 200\n",
      "2021-08-25 11:22:11.460 | INFO     | src.policies:train:157 - Total loss: 1.0028024911880493\n",
      "2021-08-25 11:22:11.464 | INFO     | src.policies:train:103 - Epoch 406 / 800\n",
      "2021-08-25 11:22:11.465 | INFO     | src.policies:train:109 - Episode 2111\n",
      "2021-08-25 11:22:11.537 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:11.538 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:11.539 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.28\n",
      "2021-08-25 11:22:11.545 | INFO     | src.policies:train:157 - Total loss: 1.000680685043335\n",
      "2021-08-25 11:22:11.547 | INFO     | src.policies:train:103 - Epoch 407 / 800\n",
      "2021-08-25 11:22:11.548 | INFO     | src.policies:train:109 - Episode 2112\n",
      "2021-08-25 11:22:11.621 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:11.623 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:11.624 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.74\n",
      "2021-08-25 11:22:11.629 | INFO     | src.policies:train:157 - Total loss: 1.0003561973571777\n",
      "2021-08-25 11:22:11.632 | INFO     | src.policies:train:103 - Epoch 408 / 800\n",
      "2021-08-25 11:22:11.632 | INFO     | src.policies:train:109 - Episode 2113\n",
      "2021-08-25 11:22:11.693 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:11.695 | INFO     | src.policies:train:121 - Mean episode return: 170.0\n",
      "2021-08-25 11:22:11.696 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 177.07\n",
      "2021-08-25 11:22:11.697 | INFO     | src.policies:train:109 - Episode 2114\n",
      "2021-08-25 11:22:11.748 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:11.749 | INFO     | src.policies:train:121 - Mean episode return: 140.0\n",
      "2021-08-25 11:22:11.750 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.47\n",
      "2021-08-25 11:22:11.751 | WARNING  | src.policies:train:131 - The actual batch size is 310, instead of 200\n",
      "2021-08-25 11:22:11.757 | INFO     | src.policies:train:157 - Total loss: 1.0020432472229004\n",
      "2021-08-25 11:22:11.760 | INFO     | src.policies:train:103 - Epoch 409 / 800\n",
      "2021-08-25 11:22:11.761 | INFO     | src.policies:train:109 - Episode 2115\n",
      "2021-08-25 11:22:11.822 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:11.824 | INFO     | src.policies:train:121 - Mean episode return: 178.0\n",
      "2021-08-25 11:22:11.825 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.48\n",
      "2021-08-25 11:22:11.825 | INFO     | src.policies:train:109 - Episode 2116\n",
      "2021-08-25 11:22:11.900 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:11.901 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:11.902 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.82\n",
      "2021-08-25 11:22:11.903 | WARNING  | src.policies:train:131 - The actual batch size is 378, instead of 200\n",
      "2021-08-25 11:22:11.909 | INFO     | src.policies:train:157 - Total loss: 1.0029572248458862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:22:11.912 | INFO     | src.policies:train:103 - Epoch 410 / 800\n",
      "2021-08-25 11:22:11.913 | INFO     | src.policies:train:109 - Episode 2117\n",
      "2021-08-25 11:22:11.970 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:11.972 | INFO     | src.policies:train:121 - Mean episode return: 156.0\n",
      "2021-08-25 11:22:11.973 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.38\n",
      "2021-08-25 11:22:11.973 | INFO     | src.policies:train:109 - Episode 2118\n",
      "2021-08-25 11:22:12.043 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:12.045 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:12.045 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.79\n",
      "2021-08-25 11:22:12.047 | WARNING  | src.policies:train:131 - The actual batch size is 356, instead of 200\n",
      "2021-08-25 11:22:12.053 | INFO     | src.policies:train:157 - Total loss: 1.0026451349258423\n",
      "2021-08-25 11:22:12.056 | INFO     | src.policies:train:103 - Epoch 411 / 800\n",
      "2021-08-25 11:22:12.057 | INFO     | src.policies:train:109 - Episode 2119\n",
      "2021-08-25 11:22:12.094 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:12.095 | INFO     | src.policies:train:121 - Mean episode return: 100.0\n",
      "2021-08-25 11:22:12.096 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.18\n",
      "2021-08-25 11:22:12.097 | INFO     | src.policies:train:109 - Episode 2120\n",
      "2021-08-25 11:22:12.170 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:12.171 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:12.172 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.18\n",
      "2021-08-25 11:22:12.173 | WARNING  | src.policies:train:131 - The actual batch size is 300, instead of 200\n",
      "2021-08-25 11:22:12.179 | INFO     | src.policies:train:157 - Total loss: 1.0021276473999023\n",
      "2021-08-25 11:22:12.182 | INFO     | src.policies:train:103 - Epoch 412 / 800\n",
      "2021-08-25 11:22:12.183 | INFO     | src.policies:train:109 - Episode 2121\n",
      "2021-08-25 11:22:12.254 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:12.255 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:12.257 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.18\n",
      "2021-08-25 11:22:12.262 | INFO     | src.policies:train:157 - Total loss: 1.0006293058395386\n",
      "2021-08-25 11:22:12.265 | INFO     | src.policies:train:103 - Epoch 413 / 800\n",
      "2021-08-25 11:22:12.266 | INFO     | src.policies:train:109 - Episode 2122\n",
      "2021-08-25 11:22:12.335 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:12.336 | INFO     | src.policies:train:121 - Mean episode return: 195.0\n",
      "2021-08-25 11:22:12.337 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.13\n",
      "2021-08-25 11:22:12.338 | INFO     | src.policies:train:109 - Episode 2123\n",
      "2021-08-25 11:22:12.410 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:12.411 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:12.412 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.27\n",
      "2021-08-25 11:22:12.413 | WARNING  | src.policies:train:131 - The actual batch size is 395, instead of 200\n",
      "2021-08-25 11:22:12.419 | INFO     | src.policies:train:157 - Total loss: 1.003023386001587\n",
      "2021-08-25 11:22:12.422 | INFO     | src.policies:train:103 - Epoch 414 / 800\n",
      "2021-08-25 11:22:12.424 | INFO     | src.policies:train:109 - Episode 2124\n",
      "2021-08-25 11:22:12.478 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:12.480 | INFO     | src.policies:train:121 - Mean episode return: 144.0\n",
      "2021-08-25 11:22:12.481 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.65\n",
      "2021-08-25 11:22:12.482 | INFO     | src.policies:train:109 - Episode 2125\n",
      "2021-08-25 11:22:12.553 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:12.555 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:12.556 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.65\n",
      "2021-08-25 11:22:12.556 | WARNING  | src.policies:train:131 - The actual batch size is 344, instead of 200\n",
      "2021-08-25 11:22:12.563 | INFO     | src.policies:train:157 - Total loss: 1.0026092529296875\n",
      "2021-08-25 11:22:12.566 | INFO     | src.policies:train:103 - Epoch 415 / 800\n",
      "2021-08-25 11:22:12.568 | INFO     | src.policies:train:109 - Episode 2126\n",
      "2021-08-25 11:22:12.641 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:12.642 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:12.643 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.65\n",
      "2021-08-25 11:22:12.648 | INFO     | src.policies:train:157 - Total loss: 1.0007785558700562\n",
      "2021-08-25 11:22:12.651 | INFO     | src.policies:train:103 - Epoch 416 / 800\n",
      "2021-08-25 11:22:12.652 | INFO     | src.policies:train:109 - Episode 2127\n",
      "2021-08-25 11:22:12.721 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:12.723 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:12.724 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.87\n",
      "2021-08-25 11:22:12.729 | INFO     | src.policies:train:157 - Total loss: 1.000630259513855\n",
      "2021-08-25 11:22:12.732 | INFO     | src.policies:train:103 - Epoch 417 / 800\n",
      "2021-08-25 11:22:12.733 | INFO     | src.policies:train:109 - Episode 2128\n",
      "2021-08-25 11:22:12.793 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:12.795 | INFO     | src.policies:train:121 - Mean episode return: 164.0\n",
      "2021-08-25 11:22:12.796 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.51\n",
      "2021-08-25 11:22:12.797 | INFO     | src.policies:train:109 - Episode 2129\n",
      "2021-08-25 11:22:12.866 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:12.867 | INFO     | src.policies:train:121 - Mean episode return: 191.0\n",
      "2021-08-25 11:22:12.868 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.42\n",
      "2021-08-25 11:22:12.869 | WARNING  | src.policies:train:131 - The actual batch size is 355, instead of 200\n",
      "2021-08-25 11:22:12.876 | INFO     | src.policies:train:157 - Total loss: 1.0027581453323364\n",
      "2021-08-25 11:22:12.879 | INFO     | src.policies:train:103 - Epoch 418 / 800\n",
      "2021-08-25 11:22:12.880 | INFO     | src.policies:train:109 - Episode 2130\n",
      "2021-08-25 11:22:12.938 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:12.939 | INFO     | src.policies:train:121 - Mean episode return: 155.0\n",
      "2021-08-25 11:22:12.940 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.72\n",
      "2021-08-25 11:22:12.941 | INFO     | src.policies:train:109 - Episode 2131\n",
      "2021-08-25 11:22:13.015 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:13.016 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:13.017 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.72\n",
      "2021-08-25 11:22:13.018 | WARNING  | src.policies:train:131 - The actual batch size is 355, instead of 200\n",
      "2021-08-25 11:22:13.025 | INFO     | src.policies:train:157 - Total loss: 1.0026991367340088\n",
      "2021-08-25 11:22:13.029 | INFO     | src.policies:train:103 - Epoch 419 / 800\n",
      "2021-08-25 11:22:13.030 | INFO     | src.policies:train:109 - Episode 2132\n",
      "2021-08-25 11:22:13.092 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:13.094 | INFO     | src.policies:train:121 - Mean episode return: 172.0\n",
      "2021-08-25 11:22:13.095 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.44\n",
      "2021-08-25 11:22:13.096 | INFO     | src.policies:train:109 - Episode 2133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:22:13.167 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:13.168 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:13.169 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.44\n",
      "2021-08-25 11:22:13.170 | WARNING  | src.policies:train:131 - The actual batch size is 372, instead of 200\n",
      "2021-08-25 11:22:13.177 | INFO     | src.policies:train:157 - Total loss: 1.0028690099716187\n",
      "2021-08-25 11:22:13.181 | INFO     | src.policies:train:103 - Epoch 420 / 800\n",
      "2021-08-25 11:22:13.182 | INFO     | src.policies:train:109 - Episode 2134\n",
      "2021-08-25 11:22:13.243 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:13.244 | INFO     | src.policies:train:121 - Mean episode return: 169.0\n",
      "2021-08-25 11:22:13.245 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.47\n",
      "2021-08-25 11:22:13.246 | INFO     | src.policies:train:109 - Episode 2135\n",
      "2021-08-25 11:22:13.319 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:13.320 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:13.321 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.59\n",
      "2021-08-25 11:22:13.322 | WARNING  | src.policies:train:131 - The actual batch size is 369, instead of 200\n",
      "2021-08-25 11:22:13.329 | INFO     | src.policies:train:157 - Total loss: 1.0029211044311523\n",
      "2021-08-25 11:22:13.333 | INFO     | src.policies:train:103 - Epoch 421 / 800\n",
      "2021-08-25 11:22:13.335 | INFO     | src.policies:train:109 - Episode 2136\n",
      "2021-08-25 11:22:13.411 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:13.413 | INFO     | src.policies:train:121 - Mean episode return: 197.0\n",
      "2021-08-25 11:22:13.414 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.56\n",
      "2021-08-25 11:22:13.415 | INFO     | src.policies:train:109 - Episode 2137\n",
      "2021-08-25 11:22:13.490 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:13.491 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:13.492 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 177.35\n",
      "2021-08-25 11:22:13.494 | WARNING  | src.policies:train:131 - The actual batch size is 397, instead of 200\n",
      "2021-08-25 11:22:13.503 | INFO     | src.policies:train:157 - Total loss: 1.0030152797698975\n",
      "2021-08-25 11:22:13.506 | INFO     | src.policies:train:103 - Epoch 422 / 800\n",
      "2021-08-25 11:22:13.508 | INFO     | src.policies:train:109 - Episode 2138\n",
      "2021-08-25 11:22:13.585 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:13.586 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:13.587 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 178.65\n",
      "2021-08-25 11:22:13.593 | INFO     | src.policies:train:157 - Total loss: 1.0005784034729004\n",
      "2021-08-25 11:22:13.596 | INFO     | src.policies:train:103 - Epoch 423 / 800\n",
      "2021-08-25 11:22:13.597 | INFO     | src.policies:train:109 - Episode 2139\n",
      "2021-08-25 11:22:13.665 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:13.667 | INFO     | src.policies:train:121 - Mean episode return: 186.0\n",
      "2021-08-25 11:22:13.668 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 178.51\n",
      "2021-08-25 11:22:13.669 | INFO     | src.policies:train:109 - Episode 2140\n",
      "2021-08-25 11:22:13.730 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:13.731 | INFO     | src.policies:train:121 - Mean episode return: 152.0\n",
      "2021-08-25 11:22:13.732 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 178.39\n",
      "2021-08-25 11:22:13.734 | WARNING  | src.policies:train:131 - The actual batch size is 338, instead of 200\n",
      "2021-08-25 11:22:13.742 | INFO     | src.policies:train:157 - Total loss: 1.0024821758270264\n",
      "2021-08-25 11:22:13.746 | INFO     | src.policies:train:103 - Epoch 424 / 800\n",
      "2021-08-25 11:22:13.747 | INFO     | src.policies:train:109 - Episode 2141\n",
      "2021-08-25 11:22:13.803 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:13.804 | INFO     | src.policies:train:121 - Mean episode return: 149.0\n",
      "2021-08-25 11:22:13.805 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 178.18\n",
      "2021-08-25 11:22:13.806 | INFO     | src.policies:train:109 - Episode 2142\n",
      "2021-08-25 11:22:13.869 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:13.870 | INFO     | src.policies:train:121 - Mean episode return: 172.0\n",
      "2021-08-25 11:22:13.871 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 177.9\n",
      "2021-08-25 11:22:13.872 | WARNING  | src.policies:train:131 - The actual batch size is 321, instead of 200\n",
      "2021-08-25 11:22:13.880 | INFO     | src.policies:train:157 - Total loss: 1.0024815797805786\n",
      "2021-08-25 11:22:13.883 | INFO     | src.policies:train:103 - Epoch 425 / 800\n",
      "2021-08-25 11:22:13.884 | INFO     | src.policies:train:109 - Episode 2143\n",
      "2021-08-25 11:22:13.936 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:13.938 | INFO     | src.policies:train:121 - Mean episode return: 147.0\n",
      "2021-08-25 11:22:13.939 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 177.49\n",
      "2021-08-25 11:22:13.940 | INFO     | src.policies:train:109 - Episode 2144\n",
      "2021-08-25 11:22:14.008 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:14.009 | INFO     | src.policies:train:121 - Mean episode return: 177.0\n",
      "2021-08-25 11:22:14.010 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 177.43\n",
      "2021-08-25 11:22:14.011 | WARNING  | src.policies:train:131 - The actual batch size is 324, instead of 200\n",
      "2021-08-25 11:22:14.019 | INFO     | src.policies:train:157 - Total loss: 1.0023106336593628\n",
      "2021-08-25 11:22:14.023 | INFO     | src.policies:train:103 - Epoch 426 / 800\n",
      "2021-08-25 11:22:14.024 | INFO     | src.policies:train:109 - Episode 2145\n",
      "2021-08-25 11:22:14.094 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:14.096 | INFO     | src.policies:train:121 - Mean episode return: 190.0\n",
      "2021-08-25 11:22:14.097 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 177.33\n",
      "2021-08-25 11:22:14.097 | INFO     | src.policies:train:109 - Episode 2146\n",
      "2021-08-25 11:22:14.168 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:14.170 | INFO     | src.policies:train:121 - Mean episode return: 198.0\n",
      "2021-08-25 11:22:14.171 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 179.09\n",
      "2021-08-25 11:22:14.172 | WARNING  | src.policies:train:131 - The actual batch size is 388, instead of 200\n",
      "2021-08-25 11:22:14.180 | INFO     | src.policies:train:157 - Total loss: 1.0030475854873657\n",
      "2021-08-25 11:22:14.183 | INFO     | src.policies:train:103 - Epoch 427 / 800\n",
      "2021-08-25 11:22:14.184 | INFO     | src.policies:train:109 - Episode 2147\n",
      "2021-08-25 11:22:14.248 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:14.249 | INFO     | src.policies:train:121 - Mean episode return: 175.0\n",
      "2021-08-25 11:22:14.250 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 178.84\n",
      "2021-08-25 11:22:14.251 | INFO     | src.policies:train:109 - Episode 2148\n",
      "2021-08-25 11:22:14.318 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:14.319 | INFO     | src.policies:train:121 - Mean episode return: 176.0\n",
      "2021-08-25 11:22:14.320 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 178.6\n",
      "2021-08-25 11:22:14.321 | WARNING  | src.policies:train:131 - The actual batch size is 351, instead of 200\n",
      "2021-08-25 11:22:14.329 | INFO     | src.policies:train:157 - Total loss: 1.0028128623962402\n",
      "2021-08-25 11:22:14.332 | INFO     | src.policies:train:103 - Epoch 428 / 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:22:14.333 | INFO     | src.policies:train:109 - Episode 2149\n",
      "2021-08-25 11:22:14.405 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:14.407 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:14.408 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 178.6\n",
      "2021-08-25 11:22:14.414 | INFO     | src.policies:train:157 - Total loss: 1.0005940198898315\n",
      "2021-08-25 11:22:14.418 | INFO     | src.policies:train:103 - Epoch 429 / 800\n",
      "2021-08-25 11:22:14.419 | INFO     | src.policies:train:109 - Episode 2150\n",
      "2021-08-25 11:22:14.455 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:14.457 | INFO     | src.policies:train:121 - Mean episode return: 94.0\n",
      "2021-08-25 11:22:14.458 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 178.03\n",
      "2021-08-25 11:22:14.459 | INFO     | src.policies:train:109 - Episode 2151\n",
      "2021-08-25 11:22:14.526 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:14.527 | INFO     | src.policies:train:121 - Mean episode return: 179.0\n",
      "2021-08-25 11:22:14.528 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 179.61\n",
      "2021-08-25 11:22:14.529 | WARNING  | src.policies:train:131 - The actual batch size is 273, instead of 200\n",
      "2021-08-25 11:22:14.537 | INFO     | src.policies:train:157 - Total loss: 1.0019991397857666\n",
      "2021-08-25 11:22:14.541 | INFO     | src.policies:train:103 - Epoch 430 / 800\n",
      "2021-08-25 11:22:14.542 | INFO     | src.policies:train:109 - Episode 2152\n",
      "2021-08-25 11:22:14.592 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:14.594 | INFO     | src.policies:train:121 - Mean episode return: 138.0\n",
      "2021-08-25 11:22:14.595 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 179.74\n",
      "2021-08-25 11:22:14.596 | INFO     | src.policies:train:109 - Episode 2153\n",
      "2021-08-25 11:22:14.657 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:14.659 | INFO     | src.policies:train:121 - Mean episode return: 165.0\n",
      "2021-08-25 11:22:14.660 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 179.39\n",
      "2021-08-25 11:22:14.660 | WARNING  | src.policies:train:131 - The actual batch size is 303, instead of 200\n",
      "2021-08-25 11:22:14.667 | INFO     | src.policies:train:157 - Total loss: 1.002307415008545\n",
      "2021-08-25 11:22:14.671 | INFO     | src.policies:train:103 - Epoch 431 / 800\n",
      "2021-08-25 11:22:14.672 | INFO     | src.policies:train:109 - Episode 2154\n",
      "2021-08-25 11:22:14.744 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:14.746 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:14.747 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 179.96\n",
      "2021-08-25 11:22:14.753 | INFO     | src.policies:train:157 - Total loss: 1.000610589981079\n",
      "2021-08-25 11:22:14.756 | INFO     | src.policies:train:103 - Epoch 432 / 800\n",
      "2021-08-25 11:22:14.757 | INFO     | src.policies:train:109 - Episode 2155\n",
      "2021-08-25 11:22:14.831 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:14.833 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:14.834 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 179.96\n",
      "2021-08-25 11:22:14.839 | INFO     | src.policies:train:157 - Total loss: 1.0006256103515625\n",
      "2021-08-25 11:22:14.842 | INFO     | src.policies:train:103 - Epoch 433 / 800\n",
      "2021-08-25 11:22:14.843 | INFO     | src.policies:train:109 - Episode 2156\n",
      "2021-08-25 11:22:14.905 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:14.907 | INFO     | src.policies:train:121 - Mean episode return: 176.0\n",
      "2021-08-25 11:22:14.908 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 180.38\n",
      "2021-08-25 11:22:14.909 | INFO     | src.policies:train:109 - Episode 2157\n",
      "2021-08-25 11:22:14.929 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:14.930 | INFO     | src.policies:train:121 - Mean episode return: 46.0\n",
      "2021-08-25 11:22:14.931 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 179.16\n",
      "2021-08-25 11:22:14.932 | WARNING  | src.policies:train:131 - The actual batch size is 222, instead of 200\n",
      "2021-08-25 11:22:14.938 | INFO     | src.policies:train:157 - Total loss: 1.0008426904678345\n",
      "2021-08-25 11:22:14.941 | INFO     | src.policies:train:103 - Epoch 434 / 800\n",
      "2021-08-25 11:22:14.942 | INFO     | src.policies:train:109 - Episode 2158\n",
      "2021-08-25 11:22:14.991 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:14.992 | INFO     | src.policies:train:121 - Mean episode return: 134.0\n",
      "2021-08-25 11:22:14.993 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 178.77\n",
      "2021-08-25 11:22:14.994 | INFO     | src.policies:train:109 - Episode 2159\n",
      "2021-08-25 11:22:15.064 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:15.066 | INFO     | src.policies:train:121 - Mean episode return: 189.0\n",
      "2021-08-25 11:22:15.066 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 178.66\n",
      "2021-08-25 11:22:15.067 | WARNING  | src.policies:train:131 - The actual batch size is 323, instead of 200\n",
      "2021-08-25 11:22:15.074 | INFO     | src.policies:train:157 - Total loss: 1.0025458335876465\n",
      "2021-08-25 11:22:15.077 | INFO     | src.policies:train:103 - Epoch 435 / 800\n",
      "2021-08-25 11:22:15.078 | INFO     | src.policies:train:109 - Episode 2160\n",
      "2021-08-25 11:22:15.144 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:15.146 | INFO     | src.policies:train:121 - Mean episode return: 181.0\n",
      "2021-08-25 11:22:15.147 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 178.47\n",
      "2021-08-25 11:22:15.148 | INFO     | src.policies:train:109 - Episode 2161\n",
      "2021-08-25 11:22:15.198 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:15.199 | INFO     | src.policies:train:121 - Mean episode return: 137.0\n",
      "2021-08-25 11:22:15.200 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 177.88\n",
      "2021-08-25 11:22:15.201 | WARNING  | src.policies:train:131 - The actual batch size is 318, instead of 200\n",
      "2021-08-25 11:22:15.207 | INFO     | src.policies:train:157 - Total loss: 1.0022577047348022\n",
      "2021-08-25 11:22:15.210 | INFO     | src.policies:train:103 - Epoch 436 / 800\n",
      "2021-08-25 11:22:15.212 | INFO     | src.policies:train:109 - Episode 2162\n",
      "2021-08-25 11:22:15.284 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:15.285 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:15.286 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 177.88\n",
      "2021-08-25 11:22:15.292 | INFO     | src.policies:train:157 - Total loss: 1.0005252361297607\n",
      "2021-08-25 11:22:15.294 | INFO     | src.policies:train:103 - Epoch 437 / 800\n",
      "2021-08-25 11:22:15.295 | INFO     | src.policies:train:109 - Episode 2163\n",
      "2021-08-25 11:22:15.365 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:15.367 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:15.368 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 178.35\n",
      "2021-08-25 11:22:15.373 | INFO     | src.policies:train:157 - Total loss: 1.0004172325134277\n",
      "2021-08-25 11:22:15.376 | INFO     | src.policies:train:103 - Epoch 438 / 800\n",
      "2021-08-25 11:22:15.377 | INFO     | src.policies:train:109 - Episode 2164\n",
      "2021-08-25 11:22:15.450 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:15.452 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:15.453 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 178.35\n",
      "2021-08-25 11:22:15.458 | INFO     | src.policies:train:157 - Total loss: 1.000568151473999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:22:15.461 | INFO     | src.policies:train:103 - Epoch 439 / 800\n",
      "2021-08-25 11:22:15.462 | INFO     | src.policies:train:109 - Episode 2165\n",
      "2021-08-25 11:22:15.515 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:15.516 | INFO     | src.policies:train:121 - Mean episode return: 145.0\n",
      "2021-08-25 11:22:15.517 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 177.8\n",
      "2021-08-25 11:22:15.518 | INFO     | src.policies:train:109 - Episode 2166\n",
      "2021-08-25 11:22:15.574 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:15.576 | INFO     | src.policies:train:121 - Mean episode return: 156.0\n",
      "2021-08-25 11:22:15.576 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 177.37\n",
      "2021-08-25 11:22:15.577 | WARNING  | src.policies:train:131 - The actual batch size is 301, instead of 200\n",
      "2021-08-25 11:22:15.583 | INFO     | src.policies:train:157 - Total loss: 1.0023548603057861\n",
      "2021-08-25 11:22:15.587 | INFO     | src.policies:train:103 - Epoch 440 / 800\n",
      "2021-08-25 11:22:15.588 | INFO     | src.policies:train:109 - Episode 2167\n",
      "2021-08-25 11:22:15.657 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:15.658 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:15.659 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 177.37\n",
      "2021-08-25 11:22:15.664 | INFO     | src.policies:train:157 - Total loss: 1.0004312992095947\n",
      "2021-08-25 11:22:15.667 | INFO     | src.policies:train:103 - Epoch 441 / 800\n",
      "2021-08-25 11:22:15.668 | INFO     | src.policies:train:109 - Episode 2168\n",
      "2021-08-25 11:22:15.726 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:15.728 | INFO     | src.policies:train:121 - Mean episode return: 164.0\n",
      "2021-08-25 11:22:15.729 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 177.01\n",
      "2021-08-25 11:22:15.730 | INFO     | src.policies:train:109 - Episode 2169\n",
      "2021-08-25 11:22:15.790 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:15.791 | INFO     | src.policies:train:121 - Mean episode return: 165.0\n",
      "2021-08-25 11:22:15.792 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 177.62\n",
      "2021-08-25 11:22:15.793 | WARNING  | src.policies:train:131 - The actual batch size is 329, instead of 200\n",
      "2021-08-25 11:22:15.799 | INFO     | src.policies:train:157 - Total loss: 1.002521276473999\n",
      "2021-08-25 11:22:15.802 | INFO     | src.policies:train:103 - Epoch 442 / 800\n",
      "2021-08-25 11:22:15.803 | INFO     | src.policies:train:109 - Episode 2170\n",
      "2021-08-25 11:22:15.867 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:15.869 | INFO     | src.policies:train:121 - Mean episode return: 178.0\n",
      "2021-08-25 11:22:15.870 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 177.4\n",
      "2021-08-25 11:22:15.870 | INFO     | src.policies:train:109 - Episode 2171\n",
      "2021-08-25 11:22:15.942 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:15.943 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:15.944 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 177.4\n",
      "2021-08-25 11:22:15.945 | WARNING  | src.policies:train:131 - The actual batch size is 378, instead of 200\n",
      "2021-08-25 11:22:15.952 | INFO     | src.policies:train:157 - Total loss: 1.0029641389846802\n",
      "2021-08-25 11:22:15.954 | INFO     | src.policies:train:103 - Epoch 443 / 800\n",
      "2021-08-25 11:22:15.955 | INFO     | src.policies:train:109 - Episode 2172\n",
      "2021-08-25 11:22:16.015 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:16.016 | INFO     | src.policies:train:121 - Mean episode return: 165.0\n",
      "2021-08-25 11:22:16.017 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 178.78\n",
      "2021-08-25 11:22:16.018 | INFO     | src.policies:train:109 - Episode 2173\n",
      "2021-08-25 11:22:16.088 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:16.089 | INFO     | src.policies:train:121 - Mean episode return: 197.0\n",
      "2021-08-25 11:22:16.090 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 178.75\n",
      "2021-08-25 11:22:16.091 | WARNING  | src.policies:train:131 - The actual batch size is 362, instead of 200\n",
      "2021-08-25 11:22:16.097 | INFO     | src.policies:train:157 - Total loss: 1.0027668476104736\n",
      "2021-08-25 11:22:16.100 | INFO     | src.policies:train:103 - Epoch 444 / 800\n",
      "2021-08-25 11:22:16.102 | INFO     | src.policies:train:109 - Episode 2174\n",
      "2021-08-25 11:22:16.172 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:16.174 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:16.175 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 179.13\n",
      "2021-08-25 11:22:16.179 | INFO     | src.policies:train:157 - Total loss: 1.0005139112472534\n",
      "2021-08-25 11:22:16.182 | INFO     | src.policies:train:103 - Epoch 445 / 800\n",
      "2021-08-25 11:22:16.183 | INFO     | src.policies:train:109 - Episode 2175\n",
      "2021-08-25 11:22:16.252 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:16.254 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:16.255 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 179.37\n",
      "2021-08-25 11:22:16.260 | INFO     | src.policies:train:157 - Total loss: 1.0005730390548706\n",
      "2021-08-25 11:22:16.263 | INFO     | src.policies:train:103 - Epoch 446 / 800\n",
      "2021-08-25 11:22:16.264 | INFO     | src.policies:train:109 - Episode 2176\n",
      "2021-08-25 11:22:16.333 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:16.334 | INFO     | src.policies:train:121 - Mean episode return: 192.0\n",
      "2021-08-25 11:22:16.335 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 179.29\n",
      "2021-08-25 11:22:16.336 | INFO     | src.policies:train:109 - Episode 2177\n",
      "2021-08-25 11:22:16.397 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:16.398 | INFO     | src.policies:train:121 - Mean episode return: 163.0\n",
      "2021-08-25 11:22:16.399 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 178.92\n",
      "2021-08-25 11:22:16.400 | WARNING  | src.policies:train:131 - The actual batch size is 355, instead of 200\n",
      "2021-08-25 11:22:16.406 | INFO     | src.policies:train:157 - Total loss: 1.0028108358383179\n",
      "2021-08-25 11:22:16.409 | INFO     | src.policies:train:103 - Epoch 447 / 800\n",
      "2021-08-25 11:22:16.410 | INFO     | src.policies:train:109 - Episode 2178\n",
      "2021-08-25 11:22:16.481 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:16.483 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:16.484 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 179.08\n",
      "2021-08-25 11:22:16.489 | INFO     | src.policies:train:157 - Total loss: 1.0006674528121948\n",
      "2021-08-25 11:22:16.492 | INFO     | src.policies:train:103 - Epoch 448 / 800\n",
      "2021-08-25 11:22:16.492 | INFO     | src.policies:train:109 - Episode 2179\n",
      "2021-08-25 11:22:16.515 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:16.517 | INFO     | src.policies:train:121 - Mean episode return: 60.0\n",
      "2021-08-25 11:22:16.518 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 178.34\n",
      "2021-08-25 11:22:16.518 | INFO     | src.policies:train:109 - Episode 2180\n",
      "2021-08-25 11:22:16.584 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:16.585 | INFO     | src.policies:train:121 - Mean episode return: 181.0\n",
      "2021-08-25 11:22:16.586 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 178.44\n",
      "2021-08-25 11:22:16.587 | WARNING  | src.policies:train:131 - The actual batch size is 241, instead of 200\n",
      "2021-08-25 11:22:16.593 | INFO     | src.policies:train:157 - Total loss: 1.0012744665145874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:22:16.596 | INFO     | src.policies:train:103 - Epoch 449 / 800\n",
      "2021-08-25 11:22:16.597 | INFO     | src.policies:train:109 - Episode 2181\n",
      "2021-08-25 11:22:16.656 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:16.658 | INFO     | src.policies:train:121 - Mean episode return: 163.0\n",
      "2021-08-25 11:22:16.659 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 178.11\n",
      "2021-08-25 11:22:16.660 | INFO     | src.policies:train:109 - Episode 2182\n",
      "2021-08-25 11:22:16.719 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:16.720 | INFO     | src.policies:train:121 - Mean episode return: 157.0\n",
      "2021-08-25 11:22:16.721 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 178.16\n",
      "2021-08-25 11:22:16.722 | WARNING  | src.policies:train:131 - The actual batch size is 320, instead of 200\n",
      "2021-08-25 11:22:16.728 | INFO     | src.policies:train:157 - Total loss: 1.0024750232696533\n",
      "2021-08-25 11:22:16.731 | INFO     | src.policies:train:103 - Epoch 450 / 800\n",
      "2021-08-25 11:22:16.733 | INFO     | src.policies:train:109 - Episode 2183\n",
      "2021-08-25 11:22:16.749 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:16.751 | INFO     | src.policies:train:121 - Mean episode return: 40.0\n",
      "2021-08-25 11:22:16.752 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.56\n",
      "2021-08-25 11:22:16.753 | INFO     | src.policies:train:109 - Episode 2184\n",
      "2021-08-25 11:22:16.812 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:16.813 | INFO     | src.policies:train:121 - Mean episode return: 161.0\n",
      "2021-08-25 11:22:16.814 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.26\n",
      "2021-08-25 11:22:16.815 | WARNING  | src.policies:train:131 - The actual batch size is 201, instead of 200\n",
      "2021-08-25 11:22:16.821 | INFO     | src.policies:train:157 - Total loss: 1.0002598762512207\n",
      "2021-08-25 11:22:16.824 | INFO     | src.policies:train:103 - Epoch 451 / 800\n",
      "2021-08-25 11:22:16.825 | INFO     | src.policies:train:109 - Episode 2185\n",
      "2021-08-25 11:22:16.880 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:16.882 | INFO     | src.policies:train:121 - Mean episode return: 151.0\n",
      "2021-08-25 11:22:16.883 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.24\n",
      "2021-08-25 11:22:16.883 | INFO     | src.policies:train:109 - Episode 2186\n",
      "2021-08-25 11:22:16.946 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:16.947 | INFO     | src.policies:train:121 - Mean episode return: 169.0\n",
      "2021-08-25 11:22:16.948 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.93\n",
      "2021-08-25 11:22:16.949 | WARNING  | src.policies:train:131 - The actual batch size is 320, instead of 200\n",
      "2021-08-25 11:22:16.956 | INFO     | src.policies:train:157 - Total loss: 1.0024058818817139\n",
      "2021-08-25 11:22:16.959 | INFO     | src.policies:train:103 - Epoch 452 / 800\n",
      "2021-08-25 11:22:16.960 | INFO     | src.policies:train:109 - Episode 2187\n",
      "2021-08-25 11:22:17.031 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:17.033 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:17.035 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.93\n",
      "2021-08-25 11:22:17.040 | INFO     | src.policies:train:157 - Total loss: 1.0006093978881836\n",
      "2021-08-25 11:22:17.042 | INFO     | src.policies:train:103 - Epoch 453 / 800\n",
      "2021-08-25 11:22:17.043 | INFO     | src.policies:train:109 - Episode 2188\n",
      "2021-08-25 11:22:17.113 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:17.115 | INFO     | src.policies:train:121 - Mean episode return: 196.0\n",
      "2021-08-25 11:22:17.116 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.96\n",
      "2021-08-25 11:22:17.116 | INFO     | src.policies:train:109 - Episode 2189\n",
      "2021-08-25 11:22:17.182 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:17.183 | INFO     | src.policies:train:121 - Mean episode return: 183.0\n",
      "2021-08-25 11:22:17.184 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.79\n",
      "2021-08-25 11:22:17.185 | WARNING  | src.policies:train:131 - The actual batch size is 379, instead of 200\n",
      "2021-08-25 11:22:17.191 | INFO     | src.policies:train:157 - Total loss: 1.0029901266098022\n",
      "2021-08-25 11:22:17.194 | INFO     | src.policies:train:103 - Epoch 454 / 800\n",
      "2021-08-25 11:22:17.195 | INFO     | src.policies:train:109 - Episode 2190\n",
      "2021-08-25 11:22:17.267 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:17.269 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:17.270 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.79\n",
      "2021-08-25 11:22:17.275 | INFO     | src.policies:train:157 - Total loss: 1.0003682374954224\n",
      "2021-08-25 11:22:17.278 | INFO     | src.policies:train:103 - Epoch 455 / 800\n",
      "2021-08-25 11:22:17.279 | INFO     | src.policies:train:109 - Episode 2191\n",
      "2021-08-25 11:22:17.343 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:17.345 | INFO     | src.policies:train:121 - Mean episode return: 178.0\n",
      "2021-08-25 11:22:17.346 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.4\n",
      "2021-08-25 11:22:17.346 | INFO     | src.policies:train:109 - Episode 2192\n",
      "2021-08-25 11:22:17.419 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:17.420 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:17.421 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.93\n",
      "2021-08-25 11:22:17.422 | WARNING  | src.policies:train:131 - The actual batch size is 378, instead of 200\n",
      "2021-08-25 11:22:17.429 | INFO     | src.policies:train:157 - Total loss: 1.0027168989181519\n",
      "2021-08-25 11:22:17.432 | INFO     | src.policies:train:103 - Epoch 456 / 800\n",
      "2021-08-25 11:22:17.433 | INFO     | src.policies:train:109 - Episode 2193\n",
      "2021-08-25 11:22:17.503 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:17.505 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:17.506 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.93\n",
      "2021-08-25 11:22:17.511 | INFO     | src.policies:train:157 - Total loss: 1.0003784894943237\n",
      "2021-08-25 11:22:17.514 | INFO     | src.policies:train:103 - Epoch 457 / 800\n",
      "2021-08-25 11:22:17.515 | INFO     | src.policies:train:109 - Episode 2194\n",
      "2021-08-25 11:22:17.585 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:17.586 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:17.587 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.93\n",
      "2021-08-25 11:22:17.592 | INFO     | src.policies:train:157 - Total loss: 1.0004860162734985\n",
      "2021-08-25 11:22:17.595 | INFO     | src.policies:train:103 - Epoch 458 / 800\n",
      "2021-08-25 11:22:17.596 | INFO     | src.policies:train:109 - Episode 2195\n",
      "2021-08-25 11:22:17.666 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:17.668 | INFO     | src.policies:train:121 - Mean episode return: 195.0\n",
      "2021-08-25 11:22:17.669 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.88\n",
      "2021-08-25 11:22:17.669 | INFO     | src.policies:train:109 - Episode 2196\n",
      "2021-08-25 11:22:17.742 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:17.743 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:17.744 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.88\n",
      "2021-08-25 11:22:17.745 | WARNING  | src.policies:train:131 - The actual batch size is 395, instead of 200\n",
      "2021-08-25 11:22:17.752 | INFO     | src.policies:train:157 - Total loss: 1.0030450820922852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:22:17.755 | INFO     | src.policies:train:103 - Epoch 459 / 800\n",
      "2021-08-25 11:22:17.756 | INFO     | src.policies:train:109 - Episode 2197\n",
      "2021-08-25 11:22:17.808 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:17.810 | INFO     | src.policies:train:121 - Mean episode return: 145.0\n",
      "2021-08-25 11:22:17.811 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.48\n",
      "2021-08-25 11:22:17.812 | INFO     | src.policies:train:109 - Episode 2198\n",
      "2021-08-25 11:22:17.869 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:17.871 | INFO     | src.policies:train:121 - Mean episode return: 158.0\n",
      "2021-08-25 11:22:17.872 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.22\n",
      "2021-08-25 11:22:17.873 | WARNING  | src.policies:train:131 - The actual batch size is 303, instead of 200\n",
      "2021-08-25 11:22:17.879 | INFO     | src.policies:train:157 - Total loss: 1.0021708011627197\n",
      "2021-08-25 11:22:17.882 | INFO     | src.policies:train:103 - Epoch 460 / 800\n",
      "2021-08-25 11:22:17.883 | INFO     | src.policies:train:109 - Episode 2199\n",
      "2021-08-25 11:22:17.938 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:17.939 | INFO     | src.policies:train:121 - Mean episode return: 159.0\n",
      "2021-08-25 11:22:17.940 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.81\n",
      "2021-08-25 11:22:17.941 | INFO     | src.policies:train:109 - Episode 2200\n",
      "2021-08-25 11:22:18.014 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:18.015 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:18.017 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.81\n",
      "2021-08-25 11:22:18.018 | WARNING  | src.policies:train:131 - The actual batch size is 359, instead of 200\n",
      "2021-08-25 11:22:18.024 | INFO     | src.policies:train:157 - Total loss: 1.0027648210525513\n",
      "2021-08-25 11:22:18.028 | INFO     | src.policies:train:103 - Epoch 461 / 800\n",
      "2021-08-25 11:22:18.029 | INFO     | src.policies:train:109 - Episode 2201\n",
      "2021-08-25 11:22:18.085 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:18.087 | INFO     | src.policies:train:121 - Mean episode return: 155.0\n",
      "2021-08-25 11:22:18.087 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.36\n",
      "2021-08-25 11:22:18.088 | INFO     | src.policies:train:109 - Episode 2202\n",
      "2021-08-25 11:22:18.150 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:18.151 | INFO     | src.policies:train:121 - Mean episode return: 170.0\n",
      "2021-08-25 11:22:18.152 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.71\n",
      "2021-08-25 11:22:18.153 | WARNING  | src.policies:train:131 - The actual batch size is 325, instead of 200\n",
      "2021-08-25 11:22:18.160 | INFO     | src.policies:train:157 - Total loss: 1.002488374710083\n",
      "2021-08-25 11:22:18.164 | INFO     | src.policies:train:103 - Epoch 462 / 800\n",
      "2021-08-25 11:22:18.165 | INFO     | src.policies:train:109 - Episode 2203\n",
      "2021-08-25 11:22:18.235 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:18.237 | INFO     | src.policies:train:121 - Mean episode return: 198.0\n",
      "2021-08-25 11:22:18.238 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.69\n",
      "2021-08-25 11:22:18.238 | INFO     | src.policies:train:109 - Episode 2204\n",
      "2021-08-25 11:22:18.296 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:18.297 | INFO     | src.policies:train:121 - Mean episode return: 157.0\n",
      "2021-08-25 11:22:18.298 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.42\n",
      "2021-08-25 11:22:18.299 | WARNING  | src.policies:train:131 - The actual batch size is 355, instead of 200\n",
      "2021-08-25 11:22:18.305 | INFO     | src.policies:train:157 - Total loss: 1.0025882720947266\n",
      "2021-08-25 11:22:18.308 | INFO     | src.policies:train:103 - Epoch 463 / 800\n",
      "2021-08-25 11:22:18.309 | INFO     | src.policies:train:109 - Episode 2205\n",
      "2021-08-25 11:22:18.379 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:18.381 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:18.382 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.47\n",
      "2021-08-25 11:22:18.387 | INFO     | src.policies:train:157 - Total loss: 1.0003067255020142\n",
      "2021-08-25 11:22:18.390 | INFO     | src.policies:train:103 - Epoch 464 / 800\n",
      "2021-08-25 11:22:18.392 | INFO     | src.policies:train:109 - Episode 2206\n",
      "2021-08-25 11:22:18.454 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:18.455 | INFO     | src.policies:train:121 - Mean episode return: 178.0\n",
      "2021-08-25 11:22:18.456 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.25\n",
      "2021-08-25 11:22:18.457 | INFO     | src.policies:train:109 - Episode 2207\n",
      "2021-08-25 11:22:18.529 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:18.530 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:18.531 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.25\n",
      "2021-08-25 11:22:18.532 | WARNING  | src.policies:train:131 - The actual batch size is 378, instead of 200\n",
      "2021-08-25 11:22:18.538 | INFO     | src.policies:train:157 - Total loss: 1.0028446912765503\n",
      "2021-08-25 11:22:18.542 | INFO     | src.policies:train:103 - Epoch 465 / 800\n",
      "2021-08-25 11:22:18.543 | INFO     | src.policies:train:109 - Episode 2208\n",
      "2021-08-25 11:22:18.599 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:18.600 | INFO     | src.policies:train:121 - Mean episode return: 157.0\n",
      "2021-08-25 11:22:18.601 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.82\n",
      "2021-08-25 11:22:18.602 | INFO     | src.policies:train:109 - Episode 2209\n",
      "2021-08-25 11:22:18.664 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:18.665 | INFO     | src.policies:train:121 - Mean episode return: 177.0\n",
      "2021-08-25 11:22:18.666 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.6\n",
      "2021-08-25 11:22:18.667 | WARNING  | src.policies:train:131 - The actual batch size is 334, instead of 200\n",
      "2021-08-25 11:22:18.673 | INFO     | src.policies:train:157 - Total loss: 1.002440333366394\n",
      "2021-08-25 11:22:18.676 | INFO     | src.policies:train:103 - Epoch 466 / 800\n",
      "2021-08-25 11:22:18.677 | INFO     | src.policies:train:109 - Episode 2210\n",
      "2021-08-25 11:22:18.749 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:18.750 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:18.751 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.05\n",
      "2021-08-25 11:22:18.757 | INFO     | src.policies:train:157 - Total loss: 1.0004723072052002\n",
      "2021-08-25 11:22:18.760 | INFO     | src.policies:train:103 - Epoch 467 / 800\n",
      "2021-08-25 11:22:18.760 | INFO     | src.policies:train:109 - Episode 2211\n",
      "2021-08-25 11:22:18.831 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:18.833 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:18.834 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.05\n",
      "2021-08-25 11:22:18.839 | INFO     | src.policies:train:157 - Total loss: 1.0007405281066895\n",
      "2021-08-25 11:22:18.842 | INFO     | src.policies:train:103 - Epoch 468 / 800\n",
      "2021-08-25 11:22:18.843 | INFO     | src.policies:train:109 - Episode 2212\n",
      "2021-08-25 11:22:18.907 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:18.909 | INFO     | src.policies:train:121 - Mean episode return: 177.0\n",
      "2021-08-25 11:22:18.910 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.82\n",
      "2021-08-25 11:22:18.911 | INFO     | src.policies:train:109 - Episode 2213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:22:18.979 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:18.980 | INFO     | src.policies:train:121 - Mean episode return: 189.0\n",
      "2021-08-25 11:22:18.981 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.01\n",
      "2021-08-25 11:22:18.982 | WARNING  | src.policies:train:131 - The actual batch size is 366, instead of 200\n",
      "2021-08-25 11:22:18.989 | INFO     | src.policies:train:157 - Total loss: 1.0027161836624146\n",
      "2021-08-25 11:22:18.991 | INFO     | src.policies:train:103 - Epoch 469 / 800\n",
      "2021-08-25 11:22:18.993 | INFO     | src.policies:train:109 - Episode 2214\n",
      "2021-08-25 11:22:19.047 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:19.048 | INFO     | src.policies:train:121 - Mean episode return: 149.0\n",
      "2021-08-25 11:22:19.050 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.1\n",
      "2021-08-25 11:22:19.050 | INFO     | src.policies:train:109 - Episode 2215\n",
      "2021-08-25 11:22:19.122 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:19.123 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:19.124 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.32\n",
      "2021-08-25 11:22:19.125 | WARNING  | src.policies:train:131 - The actual batch size is 349, instead of 200\n",
      "2021-08-25 11:22:19.131 | INFO     | src.policies:train:157 - Total loss: 1.0026344060897827\n",
      "2021-08-25 11:22:19.134 | INFO     | src.policies:train:103 - Epoch 470 / 800\n",
      "2021-08-25 11:22:19.135 | INFO     | src.policies:train:109 - Episode 2216\n",
      "2021-08-25 11:22:19.180 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:19.182 | INFO     | src.policies:train:121 - Mean episode return: 120.0\n",
      "2021-08-25 11:22:19.183 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.52\n",
      "2021-08-25 11:22:19.184 | INFO     | src.policies:train:109 - Episode 2217\n",
      "2021-08-25 11:22:19.254 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:19.256 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:19.257 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.96\n",
      "2021-08-25 11:22:19.257 | WARNING  | src.policies:train:131 - The actual batch size is 320, instead of 200\n",
      "2021-08-25 11:22:19.263 | INFO     | src.policies:train:157 - Total loss: 1.0022324323654175\n",
      "2021-08-25 11:22:19.267 | INFO     | src.policies:train:103 - Epoch 471 / 800\n",
      "2021-08-25 11:22:19.268 | INFO     | src.policies:train:109 - Episode 2218\n",
      "2021-08-25 11:22:19.322 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:19.324 | INFO     | src.policies:train:121 - Mean episode return: 155.0\n",
      "2021-08-25 11:22:19.325 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.51\n",
      "2021-08-25 11:22:19.326 | INFO     | src.policies:train:109 - Episode 2219\n",
      "2021-08-25 11:22:19.396 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:19.398 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:19.399 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.51\n",
      "2021-08-25 11:22:19.399 | WARNING  | src.policies:train:131 - The actual batch size is 355, instead of 200\n",
      "2021-08-25 11:22:19.406 | INFO     | src.policies:train:157 - Total loss: 1.0025756359100342\n",
      "2021-08-25 11:22:19.409 | INFO     | src.policies:train:103 - Epoch 472 / 800\n",
      "2021-08-25 11:22:19.410 | INFO     | src.policies:train:109 - Episode 2220\n",
      "2021-08-25 11:22:19.481 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:19.483 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:19.484 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.51\n",
      "2021-08-25 11:22:19.489 | INFO     | src.policies:train:157 - Total loss: 1.0004093647003174\n",
      "2021-08-25 11:22:19.493 | INFO     | src.policies:train:103 - Epoch 473 / 800\n",
      "2021-08-25 11:22:19.494 | INFO     | src.policies:train:109 - Episode 2221\n",
      "2021-08-25 11:22:19.566 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:19.567 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:19.568 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.51\n",
      "2021-08-25 11:22:19.573 | INFO     | src.policies:train:157 - Total loss: 1.0004106760025024\n",
      "2021-08-25 11:22:19.576 | INFO     | src.policies:train:103 - Epoch 474 / 800\n",
      "2021-08-25 11:22:19.577 | INFO     | src.policies:train:109 - Episode 2222\n",
      "2021-08-25 11:22:19.649 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:19.650 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:19.651 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.56\n",
      "2021-08-25 11:22:19.656 | INFO     | src.policies:train:157 - Total loss: 1.0004035234451294\n",
      "2021-08-25 11:22:19.659 | INFO     | src.policies:train:103 - Epoch 475 / 800\n",
      "2021-08-25 11:22:19.660 | INFO     | src.policies:train:109 - Episode 2223\n",
      "2021-08-25 11:22:19.731 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:19.733 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:19.734 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.56\n",
      "2021-08-25 11:22:19.739 | INFO     | src.policies:train:157 - Total loss: 1.0003377199172974\n",
      "2021-08-25 11:22:19.742 | INFO     | src.policies:train:103 - Epoch 476 / 800\n",
      "2021-08-25 11:22:19.743 | INFO     | src.policies:train:109 - Episode 2224\n",
      "2021-08-25 11:22:19.803 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:19.804 | INFO     | src.policies:train:121 - Mean episode return: 164.0\n",
      "2021-08-25 11:22:19.805 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.76\n",
      "2021-08-25 11:22:19.806 | INFO     | src.policies:train:109 - Episode 2225\n",
      "2021-08-25 11:22:19.878 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:19.880 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:19.880 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.76\n",
      "2021-08-25 11:22:19.881 | WARNING  | src.policies:train:131 - The actual batch size is 364, instead of 200\n",
      "2021-08-25 11:22:19.888 | INFO     | src.policies:train:157 - Total loss: 1.002588152885437\n",
      "2021-08-25 11:22:19.891 | INFO     | src.policies:train:103 - Epoch 477 / 800\n",
      "2021-08-25 11:22:19.893 | INFO     | src.policies:train:109 - Episode 2226\n",
      "2021-08-25 11:22:19.944 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:19.946 | INFO     | src.policies:train:121 - Mean episode return: 144.0\n",
      "2021-08-25 11:22:19.947 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.2\n",
      "2021-08-25 11:22:19.948 | INFO     | src.policies:train:109 - Episode 2227\n",
      "2021-08-25 11:22:20.018 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:20.020 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:20.021 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.2\n",
      "2021-08-25 11:22:20.021 | WARNING  | src.policies:train:131 - The actual batch size is 344, instead of 200\n",
      "2021-08-25 11:22:20.028 | INFO     | src.policies:train:157 - Total loss: 1.0026012659072876\n",
      "2021-08-25 11:22:20.031 | INFO     | src.policies:train:103 - Epoch 478 / 800\n",
      "2021-08-25 11:22:20.032 | INFO     | src.policies:train:109 - Episode 2228\n",
      "2021-08-25 11:22:20.086 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:20.087 | INFO     | src.policies:train:121 - Mean episode return: 151.0\n",
      "2021-08-25 11:22:20.088 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.07\n",
      "2021-08-25 11:22:20.089 | INFO     | src.policies:train:109 - Episode 2229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:22:20.163 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:20.165 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:20.166 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.16\n",
      "2021-08-25 11:22:20.167 | WARNING  | src.policies:train:131 - The actual batch size is 351, instead of 200\n",
      "2021-08-25 11:22:20.173 | INFO     | src.policies:train:157 - Total loss: 1.0023193359375\n",
      "2021-08-25 11:22:20.176 | INFO     | src.policies:train:103 - Epoch 479 / 800\n",
      "2021-08-25 11:22:20.177 | INFO     | src.policies:train:109 - Episode 2230\n",
      "2021-08-25 11:22:20.250 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:20.252 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:20.253 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.61\n",
      "2021-08-25 11:22:20.258 | INFO     | src.policies:train:157 - Total loss: 1.0003548860549927\n",
      "2021-08-25 11:22:20.261 | INFO     | src.policies:train:103 - Epoch 480 / 800\n",
      "2021-08-25 11:22:20.262 | INFO     | src.policies:train:109 - Episode 2231\n",
      "2021-08-25 11:22:20.333 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:20.334 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:20.335 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.61\n",
      "2021-08-25 11:22:20.340 | INFO     | src.policies:train:157 - Total loss: 1.000359058380127\n",
      "2021-08-25 11:22:20.343 | INFO     | src.policies:train:103 - Epoch 481 / 800\n",
      "2021-08-25 11:22:20.344 | INFO     | src.policies:train:109 - Episode 2232\n",
      "2021-08-25 11:22:20.416 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:20.417 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:20.418 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.89\n",
      "2021-08-25 11:22:20.423 | INFO     | src.policies:train:157 - Total loss: 1.000342607498169\n",
      "2021-08-25 11:22:20.427 | INFO     | src.policies:train:103 - Epoch 482 / 800\n",
      "2021-08-25 11:22:20.427 | INFO     | src.policies:train:109 - Episode 2233\n",
      "2021-08-25 11:22:20.475 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:20.476 | INFO     | src.policies:train:121 - Mean episode return: 129.0\n",
      "2021-08-25 11:22:20.477 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.18\n",
      "2021-08-25 11:22:20.478 | INFO     | src.policies:train:109 - Episode 2234\n",
      "2021-08-25 11:22:20.551 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:20.552 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:20.553 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.49\n",
      "2021-08-25 11:22:20.554 | WARNING  | src.policies:train:131 - The actual batch size is 329, instead of 200\n",
      "2021-08-25 11:22:20.560 | INFO     | src.policies:train:157 - Total loss: 1.0022752285003662\n",
      "2021-08-25 11:22:20.563 | INFO     | src.policies:train:103 - Epoch 483 / 800\n",
      "2021-08-25 11:22:20.564 | INFO     | src.policies:train:109 - Episode 2235\n",
      "2021-08-25 11:22:20.634 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:20.636 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:20.637 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.49\n",
      "2021-08-25 11:22:20.642 | INFO     | src.policies:train:157 - Total loss: 1.0003798007965088\n",
      "2021-08-25 11:22:20.645 | INFO     | src.policies:train:103 - Epoch 484 / 800\n",
      "2021-08-25 11:22:20.645 | INFO     | src.policies:train:109 - Episode 2236\n",
      "2021-08-25 11:22:20.711 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:20.712 | INFO     | src.policies:train:121 - Mean episode return: 184.0\n",
      "2021-08-25 11:22:20.713 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.36\n",
      "2021-08-25 11:22:20.714 | INFO     | src.policies:train:109 - Episode 2237\n",
      "2021-08-25 11:22:20.781 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:20.782 | INFO     | src.policies:train:121 - Mean episode return: 189.0\n",
      "2021-08-25 11:22:20.783 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.25\n",
      "2021-08-25 11:22:20.784 | WARNING  | src.policies:train:131 - The actual batch size is 373, instead of 200\n",
      "2021-08-25 11:22:20.791 | INFO     | src.policies:train:157 - Total loss: 1.0025769472122192\n",
      "2021-08-25 11:22:20.794 | INFO     | src.policies:train:103 - Epoch 485 / 800\n",
      "2021-08-25 11:22:20.795 | INFO     | src.policies:train:109 - Episode 2238\n",
      "2021-08-25 11:22:20.865 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:20.867 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:20.868 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.25\n",
      "2021-08-25 11:22:20.873 | INFO     | src.policies:train:157 - Total loss: 1.0003368854522705\n",
      "2021-08-25 11:22:20.876 | INFO     | src.policies:train:103 - Epoch 486 / 800\n",
      "2021-08-25 11:22:20.876 | INFO     | src.policies:train:109 - Episode 2239\n",
      "2021-08-25 11:22:20.948 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:20.950 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:20.951 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.39\n",
      "2021-08-25 11:22:20.956 | INFO     | src.policies:train:157 - Total loss: 1.0004552602767944\n",
      "2021-08-25 11:22:20.959 | INFO     | src.policies:train:103 - Epoch 487 / 800\n",
      "2021-08-25 11:22:20.960 | INFO     | src.policies:train:109 - Episode 2240\n",
      "2021-08-25 11:22:21.033 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:21.035 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:21.036 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.87\n",
      "2021-08-25 11:22:21.040 | INFO     | src.policies:train:157 - Total loss: 1.0004247426986694\n",
      "2021-08-25 11:22:21.043 | INFO     | src.policies:train:103 - Epoch 488 / 800\n",
      "2021-08-25 11:22:21.044 | INFO     | src.policies:train:109 - Episode 2241\n",
      "2021-08-25 11:22:21.115 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:21.117 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:21.118 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.38\n",
      "2021-08-25 11:22:21.123 | INFO     | src.policies:train:157 - Total loss: 1.0003896951675415\n",
      "2021-08-25 11:22:21.125 | INFO     | src.policies:train:103 - Epoch 489 / 800\n",
      "2021-08-25 11:22:21.126 | INFO     | src.policies:train:109 - Episode 2242\n",
      "2021-08-25 11:22:21.196 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:21.198 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:21.199 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.66\n",
      "2021-08-25 11:22:21.204 | INFO     | src.policies:train:157 - Total loss: 1.0002734661102295\n",
      "2021-08-25 11:22:21.207 | INFO     | src.policies:train:103 - Epoch 490 / 800\n",
      "2021-08-25 11:22:21.208 | INFO     | src.policies:train:109 - Episode 2243\n",
      "2021-08-25 11:22:21.280 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:21.282 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:21.283 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 177.19\n",
      "2021-08-25 11:22:21.288 | INFO     | src.policies:train:157 - Total loss: 1.000295877456665\n",
      "2021-08-25 11:22:21.291 | INFO     | src.policies:train:103 - Epoch 491 / 800\n",
      "2021-08-25 11:22:21.292 | INFO     | src.policies:train:109 - Episode 2244\n",
      "2021-08-25 11:22:21.363 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:21.364 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:22:21.365 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 177.42\n",
      "2021-08-25 11:22:21.370 | INFO     | src.policies:train:157 - Total loss: 1.0001649856567383\n",
      "2021-08-25 11:22:21.373 | INFO     | src.policies:train:103 - Epoch 492 / 800\n",
      "2021-08-25 11:22:21.374 | INFO     | src.policies:train:109 - Episode 2245\n",
      "2021-08-25 11:22:21.445 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:21.447 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:21.448 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 177.52\n",
      "2021-08-25 11:22:21.453 | INFO     | src.policies:train:157 - Total loss: 1.0002065896987915\n",
      "2021-08-25 11:22:21.457 | INFO     | src.policies:train:103 - Epoch 493 / 800\n",
      "2021-08-25 11:22:21.458 | INFO     | src.policies:train:109 - Episode 2246\n",
      "2021-08-25 11:22:21.530 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:21.531 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:21.532 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 177.54\n",
      "2021-08-25 11:22:21.537 | INFO     | src.policies:train:157 - Total loss: 1.000268578529358\n",
      "2021-08-25 11:22:21.540 | INFO     | src.policies:train:103 - Epoch 494 / 800\n",
      "2021-08-25 11:22:21.541 | INFO     | src.policies:train:109 - Episode 2247\n",
      "2021-08-25 11:22:21.612 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:21.614 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:21.615 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 177.79\n",
      "2021-08-25 11:22:21.620 | INFO     | src.policies:train:157 - Total loss: 1.0002814531326294\n",
      "2021-08-25 11:22:21.623 | INFO     | src.policies:train:103 - Epoch 495 / 800\n",
      "2021-08-25 11:22:21.624 | INFO     | src.policies:train:109 - Episode 2248\n",
      "2021-08-25 11:22:21.697 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:21.698 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:21.699 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 178.03\n",
      "2021-08-25 11:22:21.704 | INFO     | src.policies:train:157 - Total loss: 1.0004184246063232\n",
      "2021-08-25 11:22:21.707 | INFO     | src.policies:train:103 - Epoch 496 / 800\n",
      "2021-08-25 11:22:21.708 | INFO     | src.policies:train:109 - Episode 2249\n",
      "2021-08-25 11:22:21.781 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:21.783 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:21.784 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 178.03\n",
      "2021-08-25 11:22:21.790 | INFO     | src.policies:train:157 - Total loss: 1.0003985166549683\n",
      "2021-08-25 11:22:21.794 | INFO     | src.policies:train:103 - Epoch 497 / 800\n",
      "2021-08-25 11:22:21.795 | INFO     | src.policies:train:109 - Episode 2250\n",
      "2021-08-25 11:22:21.869 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:21.871 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:21.872 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 179.09\n",
      "2021-08-25 11:22:21.880 | INFO     | src.policies:train:157 - Total loss: 1.000268578529358\n",
      "2021-08-25 11:22:21.884 | INFO     | src.policies:train:103 - Epoch 498 / 800\n",
      "2021-08-25 11:22:21.885 | INFO     | src.policies:train:109 - Episode 2251\n",
      "2021-08-25 11:22:21.957 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:21.959 | INFO     | src.policies:train:121 - Mean episode return: 196.0\n",
      "2021-08-25 11:22:21.960 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 179.26\n",
      "2021-08-25 11:22:21.961 | INFO     | src.policies:train:109 - Episode 2252\n",
      "2021-08-25 11:22:22.033 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:22.034 | INFO     | src.policies:train:121 - Mean episode return: 198.0\n",
      "2021-08-25 11:22:22.035 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 179.86\n",
      "2021-08-25 11:22:22.036 | WARNING  | src.policies:train:131 - The actual batch size is 394, instead of 200\n",
      "2021-08-25 11:22:22.043 | INFO     | src.policies:train:157 - Total loss: 1.0027433633804321\n",
      "2021-08-25 11:22:22.046 | INFO     | src.policies:train:103 - Epoch 499 / 800\n",
      "2021-08-25 11:22:22.047 | INFO     | src.policies:train:109 - Episode 2253\n",
      "2021-08-25 11:22:22.120 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:22.122 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:22.123 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 180.21\n",
      "2021-08-25 11:22:22.128 | INFO     | src.policies:train:157 - Total loss: 1.0002485513687134\n",
      "2021-08-25 11:22:22.131 | INFO     | src.policies:train:103 - Epoch 500 / 800\n",
      "2021-08-25 11:22:22.132 | INFO     | src.policies:train:109 - Episode 2254\n",
      "2021-08-25 11:22:22.201 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:22.203 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:22.204 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 180.21\n",
      "2021-08-25 11:22:22.209 | INFO     | src.policies:train:157 - Total loss: 1.0003135204315186\n",
      "2021-08-25 11:22:22.212 | INFO     | src.policies:train:103 - Epoch 501 / 800\n",
      "2021-08-25 11:22:22.213 | INFO     | src.policies:train:109 - Episode 2255\n",
      "2021-08-25 11:22:22.266 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:22.268 | INFO     | src.policies:train:121 - Mean episode return: 142.0\n",
      "2021-08-25 11:22:22.269 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 179.63\n",
      "2021-08-25 11:22:22.270 | INFO     | src.policies:train:109 - Episode 2256\n",
      "2021-08-25 11:22:22.329 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:22.330 | INFO     | src.policies:train:121 - Mean episode return: 157.0\n",
      "2021-08-25 11:22:22.331 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 179.44\n",
      "2021-08-25 11:22:22.332 | WARNING  | src.policies:train:131 - The actual batch size is 299, instead of 200\n",
      "2021-08-25 11:22:22.338 | INFO     | src.policies:train:157 - Total loss: 1.0019121170043945\n",
      "2021-08-25 11:22:22.341 | INFO     | src.policies:train:103 - Epoch 502 / 800\n",
      "2021-08-25 11:22:22.342 | INFO     | src.policies:train:109 - Episode 2257\n",
      "2021-08-25 11:22:22.413 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:22.415 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:22.416 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 180.98\n",
      "2021-08-25 11:22:22.421 | INFO     | src.policies:train:157 - Total loss: 1.0004103183746338\n",
      "2021-08-25 11:22:22.424 | INFO     | src.policies:train:103 - Epoch 503 / 800\n",
      "2021-08-25 11:22:22.424 | INFO     | src.policies:train:109 - Episode 2258\n",
      "2021-08-25 11:22:22.494 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:22.495 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:22.496 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.64\n",
      "2021-08-25 11:22:22.501 | INFO     | src.policies:train:157 - Total loss: 1.0003485679626465\n",
      "2021-08-25 11:22:22.504 | INFO     | src.policies:train:103 - Epoch 504 / 800\n",
      "2021-08-25 11:22:22.505 | INFO     | src.policies:train:109 - Episode 2259\n",
      "2021-08-25 11:22:22.577 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:22.579 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:22.580 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.75\n",
      "2021-08-25 11:22:22.585 | INFO     | src.policies:train:157 - Total loss: 1.0003347396850586\n",
      "2021-08-25 11:22:22.587 | INFO     | src.policies:train:103 - Epoch 505 / 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:22:22.588 | INFO     | src.policies:train:109 - Episode 2260\n",
      "2021-08-25 11:22:22.648 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:22.649 | INFO     | src.policies:train:121 - Mean episode return: 160.0\n",
      "2021-08-25 11:22:22.650 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.54\n",
      "2021-08-25 11:22:22.651 | INFO     | src.policies:train:109 - Episode 2261\n",
      "2021-08-25 11:22:22.723 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:22.724 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:22.725 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.17\n",
      "2021-08-25 11:22:22.726 | WARNING  | src.policies:train:131 - The actual batch size is 360, instead of 200\n",
      "2021-08-25 11:22:22.733 | INFO     | src.policies:train:157 - Total loss: 1.0025252103805542\n",
      "2021-08-25 11:22:22.736 | INFO     | src.policies:train:103 - Epoch 506 / 800\n",
      "2021-08-25 11:22:22.737 | INFO     | src.policies:train:109 - Episode 2262\n",
      "2021-08-25 11:22:22.808 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:22.809 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:22.811 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.17\n",
      "2021-08-25 11:22:22.816 | INFO     | src.policies:train:157 - Total loss: 1.0004464387893677\n",
      "2021-08-25 11:22:22.819 | INFO     | src.policies:train:103 - Epoch 507 / 800\n",
      "2021-08-25 11:22:22.820 | INFO     | src.policies:train:109 - Episode 2263\n",
      "2021-08-25 11:22:22.863 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:22.864 | INFO     | src.policies:train:121 - Mean episode return: 118.0\n",
      "2021-08-25 11:22:22.865 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.35\n",
      "2021-08-25 11:22:22.866 | INFO     | src.policies:train:109 - Episode 2264\n",
      "2021-08-25 11:22:22.933 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:22.934 | INFO     | src.policies:train:121 - Mean episode return: 184.0\n",
      "2021-08-25 11:22:22.935 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.19\n",
      "2021-08-25 11:22:22.936 | WARNING  | src.policies:train:131 - The actual batch size is 302, instead of 200\n",
      "2021-08-25 11:22:22.942 | INFO     | src.policies:train:157 - Total loss: 1.0019372701644897\n",
      "2021-08-25 11:22:22.945 | INFO     | src.policies:train:103 - Epoch 508 / 800\n",
      "2021-08-25 11:22:22.946 | INFO     | src.policies:train:109 - Episode 2265\n",
      "2021-08-25 11:22:23.004 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:23.005 | INFO     | src.policies:train:121 - Mean episode return: 166.0\n",
      "2021-08-25 11:22:23.006 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.4\n",
      "2021-08-25 11:22:23.007 | INFO     | src.policies:train:109 - Episode 2266\n",
      "2021-08-25 11:22:23.079 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:23.080 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:23.081 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.84\n",
      "2021-08-25 11:22:23.082 | WARNING  | src.policies:train:131 - The actual batch size is 366, instead of 200\n",
      "2021-08-25 11:22:23.089 | INFO     | src.policies:train:157 - Total loss: 1.0025490522384644\n",
      "2021-08-25 11:22:23.092 | INFO     | src.policies:train:103 - Epoch 509 / 800\n",
      "2021-08-25 11:22:23.093 | INFO     | src.policies:train:109 - Episode 2267\n",
      "2021-08-25 11:22:23.163 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:23.165 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:23.166 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.84\n",
      "2021-08-25 11:22:23.171 | INFO     | src.policies:train:157 - Total loss: 1.0001782178878784\n",
      "2021-08-25 11:22:23.174 | INFO     | src.policies:train:103 - Epoch 510 / 800\n",
      "2021-08-25 11:22:23.175 | INFO     | src.policies:train:109 - Episode 2268\n",
      "2021-08-25 11:22:23.240 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:23.242 | INFO     | src.policies:train:121 - Mean episode return: 184.0\n",
      "2021-08-25 11:22:23.243 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.04\n",
      "2021-08-25 11:22:23.243 | INFO     | src.policies:train:109 - Episode 2269\n",
      "2021-08-25 11:22:23.316 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:23.317 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:23.318 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.39\n",
      "2021-08-25 11:22:23.319 | WARNING  | src.policies:train:131 - The actual batch size is 384, instead of 200\n",
      "2021-08-25 11:22:23.325 | INFO     | src.policies:train:157 - Total loss: 1.0025688409805298\n",
      "2021-08-25 11:22:23.329 | INFO     | src.policies:train:103 - Epoch 511 / 800\n",
      "2021-08-25 11:22:23.331 | INFO     | src.policies:train:109 - Episode 2270\n",
      "2021-08-25 11:22:23.401 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:23.403 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:23.404 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.61\n",
      "2021-08-25 11:22:23.409 | INFO     | src.policies:train:157 - Total loss: 1.0001229047775269\n",
      "2021-08-25 11:22:23.412 | INFO     | src.policies:train:103 - Epoch 512 / 800\n",
      "2021-08-25 11:22:23.413 | INFO     | src.policies:train:109 - Episode 2271\n",
      "2021-08-25 11:22:23.485 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:23.486 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:23.487 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.61\n",
      "2021-08-25 11:22:23.493 | INFO     | src.policies:train:157 - Total loss: 1.000236988067627\n",
      "2021-08-25 11:22:23.496 | INFO     | src.policies:train:103 - Epoch 513 / 800\n",
      "2021-08-25 11:22:23.497 | INFO     | src.policies:train:109 - Episode 2272\n",
      "2021-08-25 11:22:23.516 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:23.518 | INFO     | src.policies:train:121 - Mean episode return: 47.0\n",
      "2021-08-25 11:22:23.519 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.43\n",
      "2021-08-25 11:22:23.520 | INFO     | src.policies:train:109 - Episode 2273\n",
      "2021-08-25 11:22:23.571 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:23.572 | INFO     | src.policies:train:121 - Mean episode return: 136.0\n",
      "2021-08-25 11:22:23.574 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 180.82\n",
      "2021-08-25 11:22:23.575 | INFO     | src.policies:train:109 - Episode 2274\n",
      "2021-08-25 11:22:23.627 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:23.628 | INFO     | src.policies:train:121 - Mean episode return: 138.0\n",
      "2021-08-25 11:22:23.629 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 180.2\n",
      "2021-08-25 11:22:23.630 | WARNING  | src.policies:train:131 - The actual batch size is 321, instead of 200\n",
      "2021-08-25 11:22:23.638 | INFO     | src.policies:train:157 - Total loss: 1.0019563436508179\n",
      "2021-08-25 11:22:23.641 | INFO     | src.policies:train:103 - Epoch 514 / 800\n",
      "2021-08-25 11:22:23.642 | INFO     | src.policies:train:109 - Episode 2275\n",
      "2021-08-25 11:22:23.714 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:23.716 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:23.717 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 180.2\n",
      "2021-08-25 11:22:23.723 | INFO     | src.policies:train:157 - Total loss: 1.0001894235610962\n",
      "2021-08-25 11:22:23.725 | INFO     | src.policies:train:103 - Epoch 515 / 800\n",
      "2021-08-25 11:22:23.726 | INFO     | src.policies:train:109 - Episode 2276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:22:23.777 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:23.778 | INFO     | src.policies:train:121 - Mean episode return: 145.0\n",
      "2021-08-25 11:22:23.779 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 179.73\n",
      "2021-08-25 11:22:23.780 | INFO     | src.policies:train:109 - Episode 2277\n",
      "2021-08-25 11:22:23.852 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:23.853 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:23.854 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 180.1\n",
      "2021-08-25 11:22:23.855 | WARNING  | src.policies:train:131 - The actual batch size is 345, instead of 200\n",
      "2021-08-25 11:22:23.862 | INFO     | src.policies:train:157 - Total loss: 1.0023442506790161\n",
      "2021-08-25 11:22:23.866 | INFO     | src.policies:train:103 - Epoch 516 / 800\n",
      "2021-08-25 11:22:23.867 | INFO     | src.policies:train:109 - Episode 2278\n",
      "2021-08-25 11:22:23.932 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:23.933 | INFO     | src.policies:train:121 - Mean episode return: 176.0\n",
      "2021-08-25 11:22:23.934 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 179.86\n",
      "2021-08-25 11:22:23.935 | INFO     | src.policies:train:109 - Episode 2279\n",
      "2021-08-25 11:22:24.006 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:24.008 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:24.008 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.26\n",
      "2021-08-25 11:22:24.009 | WARNING  | src.policies:train:131 - The actual batch size is 376, instead of 200\n",
      "2021-08-25 11:22:24.017 | INFO     | src.policies:train:157 - Total loss: 1.0025417804718018\n",
      "2021-08-25 11:22:24.021 | INFO     | src.policies:train:103 - Epoch 517 / 800\n",
      "2021-08-25 11:22:24.022 | INFO     | src.policies:train:109 - Episode 2280\n",
      "2021-08-25 11:22:24.094 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:24.096 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:24.097 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.45\n",
      "2021-08-25 11:22:24.103 | INFO     | src.policies:train:157 - Total loss: 0.999976396560669\n",
      "2021-08-25 11:22:24.106 | INFO     | src.policies:train:103 - Epoch 518 / 800\n",
      "2021-08-25 11:22:24.107 | INFO     | src.policies:train:109 - Episode 2281\n",
      "2021-08-25 11:22:24.179 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:24.181 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:24.182 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.82\n",
      "2021-08-25 11:22:24.187 | INFO     | src.policies:train:157 - Total loss: 1.0003385543823242\n",
      "2021-08-25 11:22:24.190 | INFO     | src.policies:train:103 - Epoch 519 / 800\n",
      "2021-08-25 11:22:24.191 | INFO     | src.policies:train:109 - Episode 2282\n",
      "2021-08-25 11:22:24.241 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:24.243 | INFO     | src.policies:train:121 - Mean episode return: 132.0\n",
      "2021-08-25 11:22:24.244 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.57\n",
      "2021-08-25 11:22:24.245 | INFO     | src.policies:train:109 - Episode 2283\n",
      "2021-08-25 11:22:24.319 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:24.320 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:24.321 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 183.17\n",
      "2021-08-25 11:22:24.322 | WARNING  | src.policies:train:131 - The actual batch size is 332, instead of 200\n",
      "2021-08-25 11:22:24.329 | INFO     | src.policies:train:157 - Total loss: 1.002219796180725\n",
      "2021-08-25 11:22:24.332 | INFO     | src.policies:train:103 - Epoch 520 / 800\n",
      "2021-08-25 11:22:24.333 | INFO     | src.policies:train:109 - Episode 2284\n",
      "2021-08-25 11:22:24.405 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:24.407 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:24.408 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 183.56\n",
      "2021-08-25 11:22:24.415 | INFO     | src.policies:train:157 - Total loss: 1.0002477169036865\n",
      "2021-08-25 11:22:24.419 | INFO     | src.policies:train:103 - Epoch 521 / 800\n",
      "2021-08-25 11:22:24.420 | INFO     | src.policies:train:109 - Episode 2285\n",
      "2021-08-25 11:22:24.493 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:24.495 | INFO     | src.policies:train:121 - Mean episode return: 195.0\n",
      "2021-08-25 11:22:24.496 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 184.0\n",
      "2021-08-25 11:22:24.497 | INFO     | src.policies:train:109 - Episode 2286\n",
      "2021-08-25 11:22:24.551 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:24.552 | INFO     | src.policies:train:121 - Mean episode return: 131.0\n",
      "2021-08-25 11:22:24.554 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 183.62\n",
      "2021-08-25 11:22:24.555 | WARNING  | src.policies:train:131 - The actual batch size is 326, instead of 200\n",
      "2021-08-25 11:22:24.563 | INFO     | src.policies:train:157 - Total loss: 1.0022494792938232\n",
      "2021-08-25 11:22:24.567 | INFO     | src.policies:train:103 - Epoch 522 / 800\n",
      "2021-08-25 11:22:24.568 | INFO     | src.policies:train:109 - Episode 2287\n",
      "2021-08-25 11:22:24.632 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:24.634 | INFO     | src.policies:train:121 - Mean episode return: 175.0\n",
      "2021-08-25 11:22:24.635 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 183.37\n",
      "2021-08-25 11:22:24.636 | INFO     | src.policies:train:109 - Episode 2288\n",
      "2021-08-25 11:22:24.708 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:24.710 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:24.710 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 183.41\n",
      "2021-08-25 11:22:24.711 | WARNING  | src.policies:train:131 - The actual batch size is 375, instead of 200\n",
      "2021-08-25 11:22:24.720 | INFO     | src.policies:train:157 - Total loss: 1.0025062561035156\n",
      "2021-08-25 11:22:24.724 | INFO     | src.policies:train:103 - Epoch 523 / 800\n",
      "2021-08-25 11:22:24.725 | INFO     | src.policies:train:109 - Episode 2289\n",
      "2021-08-25 11:22:24.781 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:24.782 | INFO     | src.policies:train:121 - Mean episode return: 147.0\n",
      "2021-08-25 11:22:24.783 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 183.05\n",
      "2021-08-25 11:22:24.784 | INFO     | src.policies:train:109 - Episode 2290\n",
      "2021-08-25 11:22:24.824 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:24.826 | INFO     | src.policies:train:121 - Mean episode return: 100.0\n",
      "2021-08-25 11:22:24.826 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.05\n",
      "2021-08-25 11:22:24.828 | WARNING  | src.policies:train:131 - The actual batch size is 247, instead of 200\n",
      "2021-08-25 11:22:24.836 | INFO     | src.policies:train:157 - Total loss: 1.0010052919387817\n",
      "2021-08-25 11:22:24.839 | INFO     | src.policies:train:103 - Epoch 524 / 800\n",
      "2021-08-25 11:22:24.840 | INFO     | src.policies:train:109 - Episode 2291\n",
      "2021-08-25 11:22:24.904 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:24.906 | INFO     | src.policies:train:121 - Mean episode return: 173.0\n",
      "2021-08-25 11:22:24.907 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 182.0\n",
      "2021-08-25 11:22:24.907 | INFO     | src.policies:train:109 - Episode 2292\n",
      "2021-08-25 11:22:24.970 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:24.972 | INFO     | src.policies:train:121 - Mean episode return: 169.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:22:24.973 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.69\n",
      "2021-08-25 11:22:24.974 | WARNING  | src.policies:train:131 - The actual batch size is 342, instead of 200\n",
      "2021-08-25 11:22:24.983 | INFO     | src.policies:train:157 - Total loss: 1.0023596286773682\n",
      "2021-08-25 11:22:24.986 | INFO     | src.policies:train:103 - Epoch 525 / 800\n",
      "2021-08-25 11:22:24.987 | INFO     | src.policies:train:109 - Episode 2293\n",
      "2021-08-25 11:22:25.055 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:25.056 | INFO     | src.policies:train:121 - Mean episode return: 189.0\n",
      "2021-08-25 11:22:25.057 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.58\n",
      "2021-08-25 11:22:25.058 | INFO     | src.policies:train:109 - Episode 2294\n",
      "2021-08-25 11:22:25.132 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:25.133 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:25.134 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.58\n",
      "2021-08-25 11:22:25.135 | WARNING  | src.policies:train:131 - The actual batch size is 389, instead of 200\n",
      "2021-08-25 11:22:25.143 | INFO     | src.policies:train:157 - Total loss: 1.0027424097061157\n",
      "2021-08-25 11:22:25.146 | INFO     | src.policies:train:103 - Epoch 526 / 800\n",
      "2021-08-25 11:22:25.147 | INFO     | src.policies:train:109 - Episode 2295\n",
      "2021-08-25 11:22:25.219 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:25.221 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:25.222 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.63\n",
      "2021-08-25 11:22:25.228 | INFO     | src.policies:train:157 - Total loss: 1.0003931522369385\n",
      "2021-08-25 11:22:25.231 | INFO     | src.policies:train:103 - Epoch 527 / 800\n",
      "2021-08-25 11:22:25.232 | INFO     | src.policies:train:109 - Episode 2296\n",
      "2021-08-25 11:22:25.287 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:25.288 | INFO     | src.policies:train:121 - Mean episode return: 144.0\n",
      "2021-08-25 11:22:25.289 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.07\n",
      "2021-08-25 11:22:25.290 | INFO     | src.policies:train:109 - Episode 2297\n",
      "2021-08-25 11:22:25.343 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:25.344 | INFO     | src.policies:train:121 - Mean episode return: 131.0\n",
      "2021-08-25 11:22:25.345 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 180.93\n",
      "2021-08-25 11:22:25.346 | WARNING  | src.policies:train:131 - The actual batch size is 275, instead of 200\n",
      "2021-08-25 11:22:25.354 | INFO     | src.policies:train:157 - Total loss: 1.0014766454696655\n",
      "2021-08-25 11:22:25.358 | INFO     | src.policies:train:103 - Epoch 528 / 800\n",
      "2021-08-25 11:22:25.359 | INFO     | src.policies:train:109 - Episode 2298\n",
      "2021-08-25 11:22:25.423 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:25.425 | INFO     | src.policies:train:121 - Mean episode return: 176.0\n",
      "2021-08-25 11:22:25.426 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.11\n",
      "2021-08-25 11:22:25.426 | INFO     | src.policies:train:109 - Episode 2299\n",
      "2021-08-25 11:22:25.499 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:25.500 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:25.501 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.52\n",
      "2021-08-25 11:22:25.502 | WARNING  | src.policies:train:131 - The actual batch size is 376, instead of 200\n",
      "2021-08-25 11:22:25.510 | INFO     | src.policies:train:157 - Total loss: 1.0025311708450317\n",
      "2021-08-25 11:22:25.515 | INFO     | src.policies:train:103 - Epoch 529 / 800\n",
      "2021-08-25 11:22:25.516 | INFO     | src.policies:train:109 - Episode 2300\n",
      "2021-08-25 11:22:25.578 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:25.580 | INFO     | src.policies:train:121 - Mean episode return: 164.0\n",
      "2021-08-25 11:22:25.581 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.16\n",
      "2021-08-25 11:22:25.582 | INFO     | src.policies:train:109 - Episode 2301\n",
      "2021-08-25 11:22:25.647 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:25.648 | INFO     | src.policies:train:121 - Mean episode return: 171.0\n",
      "2021-08-25 11:22:25.649 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.32\n",
      "2021-08-25 11:22:25.650 | WARNING  | src.policies:train:131 - The actual batch size is 335, instead of 200\n",
      "2021-08-25 11:22:25.658 | INFO     | src.policies:train:157 - Total loss: 1.002331018447876\n",
      "2021-08-25 11:22:25.662 | INFO     | src.policies:train:103 - Epoch 530 / 800\n",
      "2021-08-25 11:22:25.664 | INFO     | src.policies:train:109 - Episode 2302\n",
      "2021-08-25 11:22:25.722 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:25.723 | INFO     | src.policies:train:121 - Mean episode return: 155.0\n",
      "2021-08-25 11:22:25.725 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 181.17\n",
      "2021-08-25 11:22:25.726 | INFO     | src.policies:train:109 - Episode 2303\n",
      "2021-08-25 11:22:25.786 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:25.787 | INFO     | src.policies:train:121 - Mean episode return: 153.0\n",
      "2021-08-25 11:22:25.788 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 180.72\n",
      "2021-08-25 11:22:25.789 | WARNING  | src.policies:train:131 - The actual batch size is 308, instead of 200\n",
      "2021-08-25 11:22:25.797 | INFO     | src.policies:train:157 - Total loss: 1.0020190477371216\n",
      "2021-08-25 11:22:25.800 | INFO     | src.policies:train:103 - Epoch 531 / 800\n",
      "2021-08-25 11:22:25.801 | INFO     | src.policies:train:109 - Episode 2304\n",
      "2021-08-25 11:22:25.855 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:25.857 | INFO     | src.policies:train:121 - Mean episode return: 150.0\n",
      "2021-08-25 11:22:25.858 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 180.65\n",
      "2021-08-25 11:22:25.859 | INFO     | src.policies:train:109 - Episode 2305\n",
      "2021-08-25 11:22:25.930 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:25.931 | INFO     | src.policies:train:121 - Mean episode return: 193.0\n",
      "2021-08-25 11:22:25.932 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 180.58\n",
      "2021-08-25 11:22:25.933 | WARNING  | src.policies:train:131 - The actual batch size is 343, instead of 200\n",
      "2021-08-25 11:22:25.941 | INFO     | src.policies:train:157 - Total loss: 1.0023432970046997\n",
      "2021-08-25 11:22:25.944 | INFO     | src.policies:train:103 - Epoch 532 / 800\n",
      "2021-08-25 11:22:25.945 | INFO     | src.policies:train:109 - Episode 2306\n",
      "2021-08-25 11:22:26.017 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:26.019 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:26.020 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 180.8\n",
      "2021-08-25 11:22:26.025 | INFO     | src.policies:train:157 - Total loss: 1.0003331899642944\n",
      "2021-08-25 11:22:26.028 | INFO     | src.policies:train:103 - Epoch 533 / 800\n",
      "2021-08-25 11:22:26.029 | INFO     | src.policies:train:109 - Episode 2307\n",
      "2021-08-25 11:22:26.082 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:26.084 | INFO     | src.policies:train:121 - Mean episode return: 142.0\n",
      "2021-08-25 11:22:26.085 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 180.22\n",
      "2021-08-25 11:22:26.086 | INFO     | src.policies:train:109 - Episode 2308\n",
      "2021-08-25 11:22:26.131 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:26.132 | INFO     | src.policies:train:121 - Mean episode return: 120.0\n",
      "2021-08-25 11:22:26.133 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 179.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:22:26.134 | WARNING  | src.policies:train:131 - The actual batch size is 262, instead of 200\n",
      "2021-08-25 11:22:26.140 | INFO     | src.policies:train:157 - Total loss: 1.001160979270935\n",
      "2021-08-25 11:22:26.143 | INFO     | src.policies:train:103 - Epoch 534 / 800\n",
      "2021-08-25 11:22:26.144 | INFO     | src.policies:train:109 - Episode 2309\n",
      "2021-08-25 11:22:26.214 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:26.216 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:26.217 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 180.08\n",
      "2021-08-25 11:22:26.222 | INFO     | src.policies:train:157 - Total loss: 1.000244140625\n",
      "2021-08-25 11:22:26.225 | INFO     | src.policies:train:103 - Epoch 535 / 800\n",
      "2021-08-25 11:22:26.226 | INFO     | src.policies:train:109 - Episode 2310\n",
      "2021-08-25 11:22:26.294 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:26.296 | INFO     | src.policies:train:121 - Mean episode return: 194.0\n",
      "2021-08-25 11:22:26.297 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 180.02\n",
      "2021-08-25 11:22:26.297 | INFO     | src.policies:train:109 - Episode 2311\n",
      "2021-08-25 11:22:26.350 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:26.352 | INFO     | src.policies:train:121 - Mean episode return: 142.0\n",
      "2021-08-25 11:22:26.353 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 179.44\n",
      "2021-08-25 11:22:26.354 | WARNING  | src.policies:train:131 - The actual batch size is 336, instead of 200\n",
      "2021-08-25 11:22:26.360 | INFO     | src.policies:train:157 - Total loss: 1.002198576927185\n",
      "2021-08-25 11:22:26.364 | INFO     | src.policies:train:103 - Epoch 536 / 800\n",
      "2021-08-25 11:22:26.365 | INFO     | src.policies:train:109 - Episode 2312\n",
      "2021-08-25 11:22:26.435 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:26.436 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:26.437 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 179.67\n",
      "2021-08-25 11:22:26.443 | INFO     | src.policies:train:157 - Total loss: 1.0001835823059082\n",
      "2021-08-25 11:22:26.445 | INFO     | src.policies:train:103 - Epoch 537 / 800\n",
      "2021-08-25 11:22:26.446 | INFO     | src.policies:train:109 - Episode 2313\n",
      "2021-08-25 11:22:26.504 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:26.506 | INFO     | src.policies:train:121 - Mean episode return: 166.0\n",
      "2021-08-25 11:22:26.507 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 179.44\n",
      "2021-08-25 11:22:26.508 | INFO     | src.policies:train:109 - Episode 2314\n",
      "2021-08-25 11:22:26.580 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:26.581 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:26.582 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 179.95\n",
      "2021-08-25 11:22:26.583 | WARNING  | src.policies:train:131 - The actual batch size is 366, instead of 200\n",
      "2021-08-25 11:22:26.589 | INFO     | src.policies:train:157 - Total loss: 1.0025831460952759\n",
      "2021-08-25 11:22:26.593 | INFO     | src.policies:train:103 - Epoch 538 / 800\n",
      "2021-08-25 11:22:26.594 | INFO     | src.policies:train:109 - Episode 2315\n",
      "2021-08-25 11:22:26.665 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:26.667 | INFO     | src.policies:train:121 - Mean episode return: 199.0\n",
      "2021-08-25 11:22:26.668 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 179.94\n",
      "2021-08-25 11:22:26.668 | INFO     | src.policies:train:109 - Episode 2316\n",
      "2021-08-25 11:22:26.741 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:26.743 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:26.744 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 180.74\n",
      "2021-08-25 11:22:26.744 | WARNING  | src.policies:train:131 - The actual batch size is 399, instead of 200\n",
      "2021-08-25 11:22:26.751 | INFO     | src.policies:train:157 - Total loss: 1.0028315782546997\n",
      "2021-08-25 11:22:26.755 | INFO     | src.policies:train:103 - Epoch 539 / 800\n",
      "2021-08-25 11:22:26.756 | INFO     | src.policies:train:109 - Episode 2317\n",
      "2021-08-25 11:22:26.828 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:26.830 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:26.831 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 180.74\n",
      "2021-08-25 11:22:26.836 | INFO     | src.policies:train:157 - Total loss: 1.000441312789917\n",
      "2021-08-25 11:22:26.839 | INFO     | src.policies:train:103 - Epoch 540 / 800\n",
      "2021-08-25 11:22:26.840 | INFO     | src.policies:train:109 - Episode 2318\n",
      "2021-08-25 11:22:26.885 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:26.887 | INFO     | src.policies:train:121 - Mean episode return: 126.0\n",
      "2021-08-25 11:22:26.888 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 180.45\n",
      "2021-08-25 11:22:26.889 | INFO     | src.policies:train:109 - Episode 2319\n",
      "2021-08-25 11:22:26.958 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:26.959 | INFO     | src.policies:train:121 - Mean episode return: 188.0\n",
      "2021-08-25 11:22:26.960 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 180.33\n",
      "2021-08-25 11:22:26.961 | WARNING  | src.policies:train:131 - The actual batch size is 314, instead of 200\n",
      "2021-08-25 11:22:26.968 | INFO     | src.policies:train:157 - Total loss: 1.001960277557373\n",
      "2021-08-25 11:22:26.971 | INFO     | src.policies:train:103 - Epoch 541 / 800\n",
      "2021-08-25 11:22:26.972 | INFO     | src.policies:train:109 - Episode 2320\n",
      "2021-08-25 11:22:27.021 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:27.022 | INFO     | src.policies:train:121 - Mean episode return: 138.0\n",
      "2021-08-25 11:22:27.024 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 179.71\n",
      "2021-08-25 11:22:27.024 | INFO     | src.policies:train:109 - Episode 2321\n",
      "2021-08-25 11:22:27.081 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:27.083 | INFO     | src.policies:train:121 - Mean episode return: 160.0\n",
      "2021-08-25 11:22:27.084 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 179.31\n",
      "2021-08-25 11:22:27.084 | WARNING  | src.policies:train:131 - The actual batch size is 298, instead of 200\n",
      "2021-08-25 11:22:27.091 | INFO     | src.policies:train:157 - Total loss: 1.0018341541290283\n",
      "2021-08-25 11:22:27.094 | INFO     | src.policies:train:103 - Epoch 542 / 800\n",
      "2021-08-25 11:22:27.095 | INFO     | src.policies:train:109 - Episode 2322\n",
      "2021-08-25 11:22:27.147 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:27.149 | INFO     | src.policies:train:121 - Mean episode return: 150.0\n",
      "2021-08-25 11:22:27.150 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 178.81\n",
      "2021-08-25 11:22:27.150 | INFO     | src.policies:train:109 - Episode 2323\n",
      "2021-08-25 11:22:27.222 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:27.223 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:27.224 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 178.81\n",
      "2021-08-25 11:22:27.225 | WARNING  | src.policies:train:131 - The actual batch size is 350, instead of 200\n",
      "2021-08-25 11:22:27.231 | INFO     | src.policies:train:157 - Total loss: 1.0025357007980347\n",
      "2021-08-25 11:22:27.234 | INFO     | src.policies:train:103 - Epoch 543 / 800\n",
      "2021-08-25 11:22:27.235 | INFO     | src.policies:train:109 - Episode 2324\n",
      "2021-08-25 11:22:27.286 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:27.287 | INFO     | src.policies:train:121 - Mean episode return: 144.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:22:27.288 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 178.61\n",
      "2021-08-25 11:22:27.289 | INFO     | src.policies:train:109 - Episode 2325\n",
      "2021-08-25 11:22:27.352 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:27.353 | INFO     | src.policies:train:121 - Mean episode return: 169.0\n",
      "2021-08-25 11:22:27.354 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 178.3\n",
      "2021-08-25 11:22:27.355 | WARNING  | src.policies:train:131 - The actual batch size is 313, instead of 200\n",
      "2021-08-25 11:22:27.361 | INFO     | src.policies:train:157 - Total loss: 1.0020465850830078\n",
      "2021-08-25 11:22:27.365 | INFO     | src.policies:train:103 - Epoch 544 / 800\n",
      "2021-08-25 11:22:27.366 | INFO     | src.policies:train:109 - Episode 2326\n",
      "2021-08-25 11:22:27.427 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:27.429 | INFO     | src.policies:train:121 - Mean episode return: 170.0\n",
      "2021-08-25 11:22:27.430 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 178.56\n",
      "2021-08-25 11:22:27.431 | INFO     | src.policies:train:109 - Episode 2327\n",
      "2021-08-25 11:22:27.503 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:27.504 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:27.505 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 178.56\n",
      "2021-08-25 11:22:27.506 | WARNING  | src.policies:train:131 - The actual batch size is 370, instead of 200\n",
      "2021-08-25 11:22:27.513 | INFO     | src.policies:train:157 - Total loss: 1.0025206804275513\n",
      "2021-08-25 11:22:27.516 | INFO     | src.policies:train:103 - Epoch 545 / 800\n",
      "2021-08-25 11:22:27.517 | INFO     | src.policies:train:109 - Episode 2328\n",
      "2021-08-25 11:22:27.574 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:27.576 | INFO     | src.policies:train:121 - Mean episode return: 154.0\n",
      "2021-08-25 11:22:27.577 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 178.59\n",
      "2021-08-25 11:22:27.578 | INFO     | src.policies:train:109 - Episode 2329\n",
      "2021-08-25 11:22:27.648 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:27.650 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:27.651 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 178.59\n",
      "2021-08-25 11:22:27.652 | WARNING  | src.policies:train:131 - The actual batch size is 354, instead of 200\n",
      "2021-08-25 11:22:27.658 | INFO     | src.policies:train:157 - Total loss: 1.0024491548538208\n",
      "2021-08-25 11:22:27.662 | INFO     | src.policies:train:103 - Epoch 546 / 800\n",
      "2021-08-25 11:22:27.663 | INFO     | src.policies:train:109 - Episode 2330\n",
      "2021-08-25 11:22:27.735 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:27.737 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:27.738 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 178.59\n",
      "2021-08-25 11:22:27.743 | INFO     | src.policies:train:157 - Total loss: 1.0003846883773804\n",
      "2021-08-25 11:22:27.746 | INFO     | src.policies:train:103 - Epoch 547 / 800\n",
      "2021-08-25 11:22:27.747 | INFO     | src.policies:train:109 - Episode 2331\n",
      "2021-08-25 11:22:27.817 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:27.819 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:27.820 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 178.59\n",
      "2021-08-25 11:22:27.825 | INFO     | src.policies:train:157 - Total loss: 1.0000836849212646\n",
      "2021-08-25 11:22:27.828 | INFO     | src.policies:train:103 - Epoch 548 / 800\n",
      "2021-08-25 11:22:27.829 | INFO     | src.policies:train:109 - Episode 2332\n",
      "2021-08-25 11:22:27.875 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:27.876 | INFO     | src.policies:train:121 - Mean episode return: 125.0\n",
      "2021-08-25 11:22:27.877 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 177.84\n",
      "2021-08-25 11:22:27.878 | INFO     | src.policies:train:109 - Episode 2333\n",
      "2021-08-25 11:22:27.940 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:27.942 | INFO     | src.policies:train:121 - Mean episode return: 171.0\n",
      "2021-08-25 11:22:27.942 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 178.26\n",
      "2021-08-25 11:22:27.943 | WARNING  | src.policies:train:131 - The actual batch size is 296, instead of 200\n",
      "2021-08-25 11:22:27.949 | INFO     | src.policies:train:157 - Total loss: 1.0020195245742798\n",
      "2021-08-25 11:22:27.952 | INFO     | src.policies:train:103 - Epoch 549 / 800\n",
      "2021-08-25 11:22:27.953 | INFO     | src.policies:train:109 - Episode 2334\n",
      "2021-08-25 11:22:28.023 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:28.024 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:28.025 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 178.26\n",
      "2021-08-25 11:22:28.031 | INFO     | src.policies:train:157 - Total loss: 1.0003043413162231\n",
      "2021-08-25 11:22:28.034 | INFO     | src.policies:train:103 - Epoch 550 / 800\n",
      "2021-08-25 11:22:28.034 | INFO     | src.policies:train:109 - Episode 2335\n",
      "2021-08-25 11:22:28.104 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:28.105 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:28.106 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 178.26\n",
      "2021-08-25 11:22:28.112 | INFO     | src.policies:train:157 - Total loss: 1.0003807544708252\n",
      "2021-08-25 11:22:28.115 | INFO     | src.policies:train:103 - Epoch 551 / 800\n",
      "2021-08-25 11:22:28.116 | INFO     | src.policies:train:109 - Episode 2336\n",
      "2021-08-25 11:22:28.160 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:28.162 | INFO     | src.policies:train:121 - Mean episode return: 114.0\n",
      "2021-08-25 11:22:28.163 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 177.56\n",
      "2021-08-25 11:22:28.164 | INFO     | src.policies:train:109 - Episode 2337\n",
      "2021-08-25 11:22:28.219 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:28.220 | INFO     | src.policies:train:121 - Mean episode return: 149.0\n",
      "2021-08-25 11:22:28.221 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 177.16\n",
      "2021-08-25 11:22:28.222 | WARNING  | src.policies:train:131 - The actual batch size is 263, instead of 200\n",
      "2021-08-25 11:22:28.228 | INFO     | src.policies:train:157 - Total loss: 1.0016999244689941\n",
      "2021-08-25 11:22:28.231 | INFO     | src.policies:train:103 - Epoch 552 / 800\n",
      "2021-08-25 11:22:28.232 | INFO     | src.policies:train:109 - Episode 2338\n",
      "2021-08-25 11:22:28.282 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:28.283 | INFO     | src.policies:train:121 - Mean episode return: 134.0\n",
      "2021-08-25 11:22:28.284 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.5\n",
      "2021-08-25 11:22:28.285 | INFO     | src.policies:train:109 - Episode 2339\n",
      "2021-08-25 11:22:28.332 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:28.333 | INFO     | src.policies:train:121 - Mean episode return: 122.0\n",
      "2021-08-25 11:22:28.334 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.72\n",
      "2021-08-25 11:22:28.335 | WARNING  | src.policies:train:131 - The actual batch size is 256, instead of 200\n",
      "2021-08-25 11:22:28.343 | INFO     | src.policies:train:157 - Total loss: 1.0013607740402222\n",
      "2021-08-25 11:22:28.346 | INFO     | src.policies:train:103 - Epoch 553 / 800\n",
      "2021-08-25 11:22:28.348 | INFO     | src.policies:train:109 - Episode 2340\n",
      "2021-08-25 11:22:28.413 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:28.415 | INFO     | src.policies:train:121 - Mean episode return: 187.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:22:28.416 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.59\n",
      "2021-08-25 11:22:28.417 | INFO     | src.policies:train:109 - Episode 2341\n",
      "2021-08-25 11:22:28.478 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:28.479 | INFO     | src.policies:train:121 - Mean episode return: 172.0\n",
      "2021-08-25 11:22:28.480 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.31\n",
      "2021-08-25 11:22:28.481 | WARNING  | src.policies:train:131 - The actual batch size is 359, instead of 200\n",
      "2021-08-25 11:22:28.487 | INFO     | src.policies:train:157 - Total loss: 1.0026148557662964\n",
      "2021-08-25 11:22:28.490 | INFO     | src.policies:train:103 - Epoch 554 / 800\n",
      "2021-08-25 11:22:28.492 | INFO     | src.policies:train:109 - Episode 2342\n",
      "2021-08-25 11:22:28.547 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:28.548 | INFO     | src.policies:train:121 - Mean episode return: 153.0\n",
      "2021-08-25 11:22:28.549 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.84\n",
      "2021-08-25 11:22:28.550 | INFO     | src.policies:train:109 - Episode 2343\n",
      "2021-08-25 11:22:28.620 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:28.622 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:28.623 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.84\n",
      "2021-08-25 11:22:28.623 | WARNING  | src.policies:train:131 - The actual batch size is 353, instead of 200\n",
      "2021-08-25 11:22:28.630 | INFO     | src.policies:train:157 - Total loss: 1.0025445222854614\n",
      "2021-08-25 11:22:28.633 | INFO     | src.policies:train:103 - Epoch 555 / 800\n",
      "2021-08-25 11:22:28.634 | INFO     | src.policies:train:109 - Episode 2344\n",
      "2021-08-25 11:22:28.704 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:28.706 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:28.707 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.84\n",
      "2021-08-25 11:22:28.712 | INFO     | src.policies:train:157 - Total loss: 1.0004173517227173\n",
      "2021-08-25 11:22:28.715 | INFO     | src.policies:train:103 - Epoch 556 / 800\n",
      "2021-08-25 11:22:28.716 | INFO     | src.policies:train:109 - Episode 2345\n",
      "2021-08-25 11:22:28.762 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:28.763 | INFO     | src.policies:train:121 - Mean episode return: 127.0\n",
      "2021-08-25 11:22:28.764 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.11\n",
      "2021-08-25 11:22:28.765 | INFO     | src.policies:train:109 - Episode 2346\n",
      "2021-08-25 11:22:28.837 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:28.839 | INFO     | src.policies:train:121 - Mean episode return: 195.0\n",
      "2021-08-25 11:22:28.839 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.06\n",
      "2021-08-25 11:22:28.840 | WARNING  | src.policies:train:131 - The actual batch size is 322, instead of 200\n",
      "2021-08-25 11:22:28.846 | INFO     | src.policies:train:157 - Total loss: 1.002160668373108\n",
      "2021-08-25 11:22:28.849 | INFO     | src.policies:train:103 - Epoch 557 / 800\n",
      "2021-08-25 11:22:28.850 | INFO     | src.policies:train:109 - Episode 2347\n",
      "2021-08-25 11:22:28.923 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:28.924 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:28.925 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.06\n",
      "2021-08-25 11:22:28.931 | INFO     | src.policies:train:157 - Total loss: 1.000360131263733\n",
      "2021-08-25 11:22:28.934 | INFO     | src.policies:train:103 - Epoch 558 / 800\n",
      "2021-08-25 11:22:28.935 | INFO     | src.policies:train:109 - Episode 2348\n",
      "2021-08-25 11:22:28.984 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:28.986 | INFO     | src.policies:train:121 - Mean episode return: 135.0\n",
      "2021-08-25 11:22:28.987 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 173.41\n",
      "2021-08-25 11:22:28.987 | INFO     | src.policies:train:109 - Episode 2349\n",
      "2021-08-25 11:22:29.055 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:29.056 | INFO     | src.policies:train:121 - Mean episode return: 180.0\n",
      "2021-08-25 11:22:29.057 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 173.21\n",
      "2021-08-25 11:22:29.058 | WARNING  | src.policies:train:131 - The actual batch size is 315, instead of 200\n",
      "2021-08-25 11:22:29.064 | INFO     | src.policies:train:157 - Total loss: 1.0022310018539429\n",
      "2021-08-25 11:22:29.068 | INFO     | src.policies:train:103 - Epoch 559 / 800\n",
      "2021-08-25 11:22:29.069 | INFO     | src.policies:train:109 - Episode 2350\n",
      "2021-08-25 11:22:29.140 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:29.142 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:29.143 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 173.21\n",
      "2021-08-25 11:22:29.148 | INFO     | src.policies:train:157 - Total loss: 1.0004111528396606\n",
      "2021-08-25 11:22:29.151 | INFO     | src.policies:train:103 - Epoch 560 / 800\n",
      "2021-08-25 11:22:29.151 | INFO     | src.policies:train:109 - Episode 2351\n",
      "2021-08-25 11:22:29.223 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:29.225 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:29.226 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 173.25\n",
      "2021-08-25 11:22:29.231 | INFO     | src.policies:train:157 - Total loss: 1.0004351139068604\n",
      "2021-08-25 11:22:29.235 | INFO     | src.policies:train:103 - Epoch 561 / 800\n",
      "2021-08-25 11:22:29.236 | INFO     | src.policies:train:109 - Episode 2352\n",
      "2021-08-25 11:22:29.308 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:29.309 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:29.310 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 173.27\n",
      "2021-08-25 11:22:29.315 | INFO     | src.policies:train:157 - Total loss: 1.0003050565719604\n",
      "2021-08-25 11:22:29.318 | INFO     | src.policies:train:103 - Epoch 562 / 800\n",
      "2021-08-25 11:22:29.319 | INFO     | src.policies:train:109 - Episode 2353\n",
      "2021-08-25 11:22:29.374 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:29.376 | INFO     | src.policies:train:121 - Mean episode return: 149.0\n",
      "2021-08-25 11:22:29.377 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.76\n",
      "2021-08-25 11:22:29.377 | INFO     | src.policies:train:109 - Episode 2354\n",
      "2021-08-25 11:22:29.443 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:29.444 | INFO     | src.policies:train:121 - Mean episode return: 181.0\n",
      "2021-08-25 11:22:29.445 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.57\n",
      "2021-08-25 11:22:29.446 | WARNING  | src.policies:train:131 - The actual batch size is 330, instead of 200\n",
      "2021-08-25 11:22:29.452 | INFO     | src.policies:train:157 - Total loss: 1.0023916959762573\n",
      "2021-08-25 11:22:29.455 | INFO     | src.policies:train:103 - Epoch 563 / 800\n",
      "2021-08-25 11:22:29.456 | INFO     | src.policies:train:109 - Episode 2355\n",
      "2021-08-25 11:22:29.527 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:29.528 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:29.529 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 173.15\n",
      "2021-08-25 11:22:29.535 | INFO     | src.policies:train:157 - Total loss: 1.000395655632019\n",
      "2021-08-25 11:22:29.537 | INFO     | src.policies:train:103 - Epoch 564 / 800\n",
      "2021-08-25 11:22:29.538 | INFO     | src.policies:train:109 - Episode 2356\n",
      "2021-08-25 11:22:29.604 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:22:29.605 | INFO     | src.policies:train:121 - Mean episode return: 184.0\n",
      "2021-08-25 11:22:29.606 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 173.42\n",
      "2021-08-25 11:22:29.607 | INFO     | src.policies:train:109 - Episode 2357\n",
      "2021-08-25 11:22:29.675 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:29.676 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:29.677 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 173.42\n",
      "2021-08-25 11:22:29.678 | WARNING  | src.policies:train:131 - The actual batch size is 384, instead of 200\n",
      "2021-08-25 11:22:29.684 | INFO     | src.policies:train:157 - Total loss: 1.0026582479476929\n",
      "2021-08-25 11:22:29.687 | INFO     | src.policies:train:103 - Epoch 565 / 800\n",
      "2021-08-25 11:22:29.688 | INFO     | src.policies:train:109 - Episode 2358\n",
      "2021-08-25 11:22:29.756 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:29.757 | INFO     | src.policies:train:121 - Mean episode return: 196.0\n",
      "2021-08-25 11:22:29.758 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 173.38\n",
      "2021-08-25 11:22:29.759 | INFO     | src.policies:train:109 - Episode 2359\n",
      "2021-08-25 11:22:29.826 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:29.827 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:29.828 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 173.38\n",
      "2021-08-25 11:22:29.829 | WARNING  | src.policies:train:131 - The actual batch size is 396, instead of 200\n",
      "2021-08-25 11:22:29.835 | INFO     | src.policies:train:157 - Total loss: 1.0027989149093628\n",
      "2021-08-25 11:22:29.838 | INFO     | src.policies:train:103 - Epoch 566 / 800\n",
      "2021-08-25 11:22:29.839 | INFO     | src.policies:train:109 - Episode 2360\n",
      "2021-08-25 11:22:29.906 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:29.908 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:29.909 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 173.78\n",
      "2021-08-25 11:22:29.914 | INFO     | src.policies:train:157 - Total loss: 1.0002880096435547\n",
      "2021-08-25 11:22:29.917 | INFO     | src.policies:train:103 - Epoch 567 / 800\n",
      "2021-08-25 11:22:29.918 | INFO     | src.policies:train:109 - Episode 2361\n",
      "2021-08-25 11:22:29.981 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:29.983 | INFO     | src.policies:train:121 - Mean episode return: 191.0\n",
      "2021-08-25 11:22:29.984 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 173.69\n",
      "2021-08-25 11:22:29.985 | INFO     | src.policies:train:109 - Episode 2362\n",
      "2021-08-25 11:22:30.053 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:30.055 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:30.055 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 173.69\n",
      "2021-08-25 11:22:30.056 | WARNING  | src.policies:train:131 - The actual batch size is 391, instead of 200\n",
      "2021-08-25 11:22:30.062 | INFO     | src.policies:train:157 - Total loss: 1.0028234720230103\n",
      "2021-08-25 11:22:30.066 | INFO     | src.policies:train:103 - Epoch 568 / 800\n",
      "2021-08-25 11:22:30.067 | INFO     | src.policies:train:109 - Episode 2363\n",
      "2021-08-25 11:22:30.126 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:30.127 | INFO     | src.policies:train:121 - Mean episode return: 168.0\n",
      "2021-08-25 11:22:30.128 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.19\n",
      "2021-08-25 11:22:30.129 | INFO     | src.policies:train:109 - Episode 2364\n",
      "2021-08-25 11:22:30.196 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:30.197 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:30.198 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.35\n",
      "2021-08-25 11:22:30.199 | WARNING  | src.policies:train:131 - The actual batch size is 368, instead of 200\n",
      "2021-08-25 11:22:30.205 | INFO     | src.policies:train:157 - Total loss: 1.0024975538253784\n",
      "2021-08-25 11:22:30.208 | INFO     | src.policies:train:103 - Epoch 569 / 800\n",
      "2021-08-25 11:22:30.209 | INFO     | src.policies:train:109 - Episode 2365\n",
      "2021-08-25 11:22:30.277 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:30.279 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:30.280 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.69\n",
      "2021-08-25 11:22:30.285 | INFO     | src.policies:train:157 - Total loss: 1.0002576112747192\n",
      "2021-08-25 11:22:30.288 | INFO     | src.policies:train:103 - Epoch 570 / 800\n",
      "2021-08-25 11:22:30.289 | INFO     | src.policies:train:109 - Episode 2366\n",
      "2021-08-25 11:22:30.355 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:30.357 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:30.358 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.69\n",
      "2021-08-25 11:22:30.363 | INFO     | src.policies:train:157 - Total loss: 1.0004366636276245\n",
      "2021-08-25 11:22:30.366 | INFO     | src.policies:train:103 - Epoch 571 / 800\n",
      "2021-08-25 11:22:30.366 | INFO     | src.policies:train:109 - Episode 2367\n",
      "2021-08-25 11:22:30.434 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:30.436 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:30.437 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.69\n",
      "2021-08-25 11:22:30.442 | INFO     | src.policies:train:157 - Total loss: 1.0002508163452148\n",
      "2021-08-25 11:22:30.444 | INFO     | src.policies:train:103 - Epoch 572 / 800\n",
      "2021-08-25 11:22:30.445 | INFO     | src.policies:train:109 - Episode 2368\n",
      "2021-08-25 11:22:30.513 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:30.515 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:30.516 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.85\n",
      "2021-08-25 11:22:30.521 | INFO     | src.policies:train:157 - Total loss: 1.0002753734588623\n",
      "2021-08-25 11:22:30.523 | INFO     | src.policies:train:103 - Epoch 573 / 800\n",
      "2021-08-25 11:22:30.524 | INFO     | src.policies:train:109 - Episode 2369\n",
      "2021-08-25 11:22:30.580 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:30.581 | INFO     | src.policies:train:121 - Mean episode return: 162.0\n",
      "2021-08-25 11:22:30.582 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.47\n",
      "2021-08-25 11:22:30.583 | INFO     | src.policies:train:109 - Episode 2370\n",
      "2021-08-25 11:22:30.650 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:30.651 | INFO     | src.policies:train:121 - Mean episode return: 189.0\n",
      "2021-08-25 11:22:30.652 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.36\n",
      "2021-08-25 11:22:30.653 | WARNING  | src.policies:train:131 - The actual batch size is 351, instead of 200\n",
      "2021-08-25 11:22:30.659 | INFO     | src.policies:train:157 - Total loss: 1.0025261640548706\n",
      "2021-08-25 11:22:30.662 | INFO     | src.policies:train:103 - Epoch 574 / 800\n",
      "2021-08-25 11:22:30.663 | INFO     | src.policies:train:109 - Episode 2371\n",
      "2021-08-25 11:22:30.730 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:30.731 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:30.732 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.36\n",
      "2021-08-25 11:22:30.737 | INFO     | src.policies:train:157 - Total loss: 1.0004158020019531\n",
      "2021-08-25 11:22:30.739 | INFO     | src.policies:train:103 - Epoch 575 / 800\n",
      "2021-08-25 11:22:30.740 | INFO     | src.policies:train:109 - Episode 2372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:22:30.791 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:30.792 | INFO     | src.policies:train:121 - Mean episode return: 146.0\n",
      "2021-08-25 11:22:30.793 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.35\n",
      "2021-08-25 11:22:30.794 | INFO     | src.policies:train:109 - Episode 2373\n",
      "2021-08-25 11:22:30.845 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:30.846 | INFO     | src.policies:train:121 - Mean episode return: 148.0\n",
      "2021-08-25 11:22:30.847 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.47\n",
      "2021-08-25 11:22:30.848 | WARNING  | src.policies:train:131 - The actual batch size is 294, instead of 200\n",
      "2021-08-25 11:22:30.854 | INFO     | src.policies:train:157 - Total loss: 1.0021276473999023\n",
      "2021-08-25 11:22:30.857 | INFO     | src.policies:train:103 - Epoch 576 / 800\n",
      "2021-08-25 11:22:30.858 | INFO     | src.policies:train:109 - Episode 2374\n",
      "2021-08-25 11:22:30.925 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:30.926 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:30.927 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.09\n",
      "2021-08-25 11:22:30.932 | INFO     | src.policies:train:157 - Total loss: 1.0003148317337036\n",
      "2021-08-25 11:22:30.934 | INFO     | src.policies:train:103 - Epoch 577 / 800\n",
      "2021-08-25 11:22:30.935 | INFO     | src.policies:train:109 - Episode 2375\n",
      "2021-08-25 11:22:30.981 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:30.982 | INFO     | src.policies:train:121 - Mean episode return: 133.0\n",
      "2021-08-25 11:22:30.983 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.42\n",
      "2021-08-25 11:22:30.984 | INFO     | src.policies:train:109 - Episode 2376\n",
      "2021-08-25 11:22:31.050 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:31.051 | INFO     | src.policies:train:121 - Mean episode return: 188.0\n",
      "2021-08-25 11:22:31.051 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.85\n",
      "2021-08-25 11:22:31.052 | WARNING  | src.policies:train:131 - The actual batch size is 321, instead of 200\n",
      "2021-08-25 11:22:31.058 | INFO     | src.policies:train:157 - Total loss: 1.0019807815551758\n",
      "2021-08-25 11:22:31.061 | INFO     | src.policies:train:103 - Epoch 578 / 800\n",
      "2021-08-25 11:22:31.062 | INFO     | src.policies:train:109 - Episode 2377\n",
      "2021-08-25 11:22:31.131 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:31.132 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:31.133 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.85\n",
      "2021-08-25 11:22:31.138 | INFO     | src.policies:train:157 - Total loss: 1.0002810955047607\n",
      "2021-08-25 11:22:31.141 | INFO     | src.policies:train:103 - Epoch 579 / 800\n",
      "2021-08-25 11:22:31.142 | INFO     | src.policies:train:109 - Episode 2378\n",
      "2021-08-25 11:22:31.210 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:31.211 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:31.212 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.09\n",
      "2021-08-25 11:22:31.217 | INFO     | src.policies:train:157 - Total loss: 1.0002591609954834\n",
      "2021-08-25 11:22:31.220 | INFO     | src.policies:train:103 - Epoch 580 / 800\n",
      "2021-08-25 11:22:31.221 | INFO     | src.policies:train:109 - Episode 2379\n",
      "2021-08-25 11:22:31.278 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:31.279 | INFO     | src.policies:train:121 - Mean episode return: 166.0\n",
      "2021-08-25 11:22:31.280 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.75\n",
      "2021-08-25 11:22:31.281 | INFO     | src.policies:train:109 - Episode 2380\n",
      "2021-08-25 11:22:31.350 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:31.352 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:31.353 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.75\n",
      "2021-08-25 11:22:31.354 | WARNING  | src.policies:train:131 - The actual batch size is 366, instead of 200\n",
      "2021-08-25 11:22:31.360 | INFO     | src.policies:train:157 - Total loss: 1.00262451171875\n",
      "2021-08-25 11:22:31.363 | INFO     | src.policies:train:103 - Epoch 581 / 800\n",
      "2021-08-25 11:22:31.364 | INFO     | src.policies:train:109 - Episode 2381\n",
      "2021-08-25 11:22:31.413 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:31.414 | INFO     | src.policies:train:121 - Mean episode return: 148.0\n",
      "2021-08-25 11:22:31.416 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.23\n",
      "2021-08-25 11:22:31.416 | INFO     | src.policies:train:109 - Episode 2382\n",
      "2021-08-25 11:22:31.484 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:31.486 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:31.486 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.91\n",
      "2021-08-25 11:22:31.487 | WARNING  | src.policies:train:131 - The actual batch size is 348, instead of 200\n",
      "2021-08-25 11:22:31.494 | INFO     | src.policies:train:157 - Total loss: 1.0024702548980713\n",
      "2021-08-25 11:22:31.497 | INFO     | src.policies:train:103 - Epoch 582 / 800\n",
      "2021-08-25 11:22:31.498 | INFO     | src.policies:train:109 - Episode 2383\n",
      "2021-08-25 11:22:31.560 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:31.561 | INFO     | src.policies:train:121 - Mean episode return: 183.0\n",
      "2021-08-25 11:22:31.563 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.74\n",
      "2021-08-25 11:22:31.563 | INFO     | src.policies:train:109 - Episode 2384\n",
      "2021-08-25 11:22:31.615 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:31.616 | INFO     | src.policies:train:121 - Mean episode return: 144.0\n",
      "2021-08-25 11:22:31.617 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.18\n",
      "2021-08-25 11:22:31.618 | WARNING  | src.policies:train:131 - The actual batch size is 327, instead of 200\n",
      "2021-08-25 11:22:31.623 | INFO     | src.policies:train:157 - Total loss: 1.002336859703064\n",
      "2021-08-25 11:22:31.626 | INFO     | src.policies:train:103 - Epoch 583 / 800\n",
      "2021-08-25 11:22:31.627 | INFO     | src.policies:train:109 - Episode 2385\n",
      "2021-08-25 11:22:31.681 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:31.683 | INFO     | src.policies:train:121 - Mean episode return: 164.0\n",
      "2021-08-25 11:22:31.684 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.87\n",
      "2021-08-25 11:22:31.685 | INFO     | src.policies:train:109 - Episode 2386\n",
      "2021-08-25 11:22:31.741 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:31.742 | INFO     | src.policies:train:121 - Mean episode return: 160.0\n",
      "2021-08-25 11:22:31.743 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.16\n",
      "2021-08-25 11:22:31.744 | WARNING  | src.policies:train:131 - The actual batch size is 324, instead of 200\n",
      "2021-08-25 11:22:31.750 | INFO     | src.policies:train:157 - Total loss: 1.002305030822754\n",
      "2021-08-25 11:22:31.753 | INFO     | src.policies:train:103 - Epoch 584 / 800\n",
      "2021-08-25 11:22:31.754 | INFO     | src.policies:train:109 - Episode 2387\n",
      "2021-08-25 11:22:31.794 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:31.796 | INFO     | src.policies:train:121 - Mean episode return: 119.0\n",
      "2021-08-25 11:22:31.797 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.6\n",
      "2021-08-25 11:22:31.797 | INFO     | src.policies:train:109 - Episode 2388\n",
      "2021-08-25 11:22:31.866 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:31.867 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:22:31.868 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.6\n",
      "2021-08-25 11:22:31.869 | WARNING  | src.policies:train:131 - The actual batch size is 319, instead of 200\n",
      "2021-08-25 11:22:31.875 | INFO     | src.policies:train:157 - Total loss: 1.0021268129348755\n",
      "2021-08-25 11:22:31.878 | INFO     | src.policies:train:103 - Epoch 585 / 800\n",
      "2021-08-25 11:22:31.879 | INFO     | src.policies:train:109 - Episode 2389\n",
      "2021-08-25 11:22:31.946 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:31.948 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:31.949 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.13\n",
      "2021-08-25 11:22:31.953 | INFO     | src.policies:train:157 - Total loss: 1.0001559257507324\n",
      "2021-08-25 11:22:31.956 | INFO     | src.policies:train:103 - Epoch 586 / 800\n",
      "2021-08-25 11:22:31.957 | INFO     | src.policies:train:109 - Episode 2390\n",
      "2021-08-25 11:22:32.022 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:32.024 | INFO     | src.policies:train:121 - Mean episode return: 195.0\n",
      "2021-08-25 11:22:32.025 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.08\n",
      "2021-08-25 11:22:32.025 | INFO     | src.policies:train:109 - Episode 2391\n",
      "2021-08-25 11:22:32.077 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:32.079 | INFO     | src.policies:train:121 - Mean episode return: 148.0\n",
      "2021-08-25 11:22:32.079 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.83\n",
      "2021-08-25 11:22:32.080 | WARNING  | src.policies:train:131 - The actual batch size is 343, instead of 200\n",
      "2021-08-25 11:22:32.087 | INFO     | src.policies:train:157 - Total loss: 1.0023950338363647\n",
      "2021-08-25 11:22:32.090 | INFO     | src.policies:train:103 - Epoch 587 / 800\n",
      "2021-08-25 11:22:32.091 | INFO     | src.policies:train:109 - Episode 2392\n",
      "2021-08-25 11:22:32.142 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:32.143 | INFO     | src.policies:train:121 - Mean episode return: 154.0\n",
      "2021-08-25 11:22:32.144 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.68\n",
      "2021-08-25 11:22:32.145 | INFO     | src.policies:train:109 - Episode 2393\n",
      "2021-08-25 11:22:32.210 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:32.211 | INFO     | src.policies:train:121 - Mean episode return: 190.0\n",
      "2021-08-25 11:22:32.212 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.69\n",
      "2021-08-25 11:22:32.213 | WARNING  | src.policies:train:131 - The actual batch size is 344, instead of 200\n",
      "2021-08-25 11:22:32.219 | INFO     | src.policies:train:157 - Total loss: 1.0023586750030518\n",
      "2021-08-25 11:22:32.222 | INFO     | src.policies:train:103 - Epoch 588 / 800\n",
      "2021-08-25 11:22:32.223 | INFO     | src.policies:train:109 - Episode 2394\n",
      "2021-08-25 11:22:32.290 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:32.291 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:32.292 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.69\n",
      "2021-08-25 11:22:32.297 | INFO     | src.policies:train:157 - Total loss: 1.000248908996582\n",
      "2021-08-25 11:22:32.300 | INFO     | src.policies:train:103 - Epoch 589 / 800\n",
      "2021-08-25 11:22:32.301 | INFO     | src.policies:train:109 - Episode 2395\n",
      "2021-08-25 11:22:32.362 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:32.364 | INFO     | src.policies:train:121 - Mean episode return: 184.0\n",
      "2021-08-25 11:22:32.365 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.53\n",
      "2021-08-25 11:22:32.365 | INFO     | src.policies:train:109 - Episode 2396\n",
      "2021-08-25 11:22:32.435 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:32.436 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:32.437 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.09\n",
      "2021-08-25 11:22:32.438 | WARNING  | src.policies:train:131 - The actual batch size is 384, instead of 200\n",
      "2021-08-25 11:22:32.444 | INFO     | src.policies:train:157 - Total loss: 1.0027841329574585\n",
      "2021-08-25 11:22:32.447 | INFO     | src.policies:train:103 - Epoch 590 / 800\n",
      "2021-08-25 11:22:32.448 | INFO     | src.policies:train:109 - Episode 2397\n",
      "2021-08-25 11:22:32.506 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:32.508 | INFO     | src.policies:train:121 - Mean episode return: 169.0\n",
      "2021-08-25 11:22:32.509 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.47\n",
      "2021-08-25 11:22:32.509 | INFO     | src.policies:train:109 - Episode 2398\n",
      "2021-08-25 11:22:32.571 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:32.572 | INFO     | src.policies:train:121 - Mean episode return: 179.0\n",
      "2021-08-25 11:22:32.573 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.5\n",
      "2021-08-25 11:22:32.574 | WARNING  | src.policies:train:131 - The actual batch size is 348, instead of 200\n",
      "2021-08-25 11:22:32.580 | INFO     | src.policies:train:157 - Total loss: 1.0024235248565674\n",
      "2021-08-25 11:22:32.582 | INFO     | src.policies:train:103 - Epoch 591 / 800\n",
      "2021-08-25 11:22:32.583 | INFO     | src.policies:train:109 - Episode 2399\n",
      "2021-08-25 11:22:32.637 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:32.639 | INFO     | src.policies:train:121 - Mean episode return: 166.0\n",
      "2021-08-25 11:22:32.640 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.16\n",
      "2021-08-25 11:22:32.641 | INFO     | src.policies:train:109 - Episode 2400\n",
      "2021-08-25 11:22:32.696 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:32.697 | INFO     | src.policies:train:121 - Mean episode return: 161.0\n",
      "2021-08-25 11:22:32.697 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.13\n",
      "2021-08-25 11:22:32.698 | WARNING  | src.policies:train:131 - The actual batch size is 327, instead of 200\n",
      "2021-08-25 11:22:32.704 | INFO     | src.policies:train:157 - Total loss: 1.0023889541625977\n",
      "2021-08-25 11:22:32.708 | INFO     | src.policies:train:103 - Epoch 592 / 800\n",
      "2021-08-25 11:22:32.708 | INFO     | src.policies:train:109 - Episode 2401\n",
      "2021-08-25 11:22:32.774 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:32.776 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:32.777 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.42\n",
      "2021-08-25 11:22:32.782 | INFO     | src.policies:train:157 - Total loss: 1.000443696975708\n",
      "2021-08-25 11:22:32.784 | INFO     | src.policies:train:103 - Epoch 593 / 800\n",
      "2021-08-25 11:22:32.786 | INFO     | src.policies:train:109 - Episode 2402\n",
      "2021-08-25 11:22:32.853 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:32.854 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:32.855 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.87\n",
      "2021-08-25 11:22:32.860 | INFO     | src.policies:train:157 - Total loss: 1.0004587173461914\n",
      "2021-08-25 11:22:32.864 | INFO     | src.policies:train:103 - Epoch 594 / 800\n",
      "2021-08-25 11:22:32.864 | INFO     | src.policies:train:109 - Episode 2403\n",
      "2021-08-25 11:22:32.915 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:32.916 | INFO     | src.policies:train:121 - Mean episode return: 145.0\n",
      "2021-08-25 11:22:32.917 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.79\n",
      "2021-08-25 11:22:32.918 | INFO     | src.policies:train:109 - Episode 2404\n",
      "2021-08-25 11:22:32.979 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:32.980 | INFO     | src.policies:train:121 - Mean episode return: 181.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:22:32.981 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 177.1\n",
      "2021-08-25 11:22:32.982 | WARNING  | src.policies:train:131 - The actual batch size is 326, instead of 200\n",
      "2021-08-25 11:22:32.988 | INFO     | src.policies:train:157 - Total loss: 1.002247929573059\n",
      "2021-08-25 11:22:32.991 | INFO     | src.policies:train:103 - Epoch 595 / 800\n",
      "2021-08-25 11:22:32.992 | INFO     | src.policies:train:109 - Episode 2405\n",
      "2021-08-25 11:22:33.060 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:33.062 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:33.063 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 177.17\n",
      "2021-08-25 11:22:33.069 | INFO     | src.policies:train:157 - Total loss: 1.000458002090454\n",
      "2021-08-25 11:22:33.074 | INFO     | src.policies:train:103 - Epoch 596 / 800\n",
      "2021-08-25 11:22:33.075 | INFO     | src.policies:train:109 - Episode 2406\n",
      "2021-08-25 11:22:33.146 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:33.147 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:33.149 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 177.17\n",
      "2021-08-25 11:22:33.155 | INFO     | src.policies:train:157 - Total loss: 1.0004048347473145\n",
      "2021-08-25 11:22:33.159 | INFO     | src.policies:train:103 - Epoch 597 / 800\n",
      "2021-08-25 11:22:33.160 | INFO     | src.policies:train:109 - Episode 2407\n",
      "2021-08-25 11:22:33.225 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:33.226 | INFO     | src.policies:train:121 - Mean episode return: 180.0\n",
      "2021-08-25 11:22:33.227 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 177.55\n",
      "2021-08-25 11:22:33.228 | INFO     | src.policies:train:109 - Episode 2408\n",
      "2021-08-25 11:22:33.285 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:33.286 | INFO     | src.policies:train:121 - Mean episode return: 164.0\n",
      "2021-08-25 11:22:33.287 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 177.99\n",
      "2021-08-25 11:22:33.288 | WARNING  | src.policies:train:131 - The actual batch size is 344, instead of 200\n",
      "2021-08-25 11:22:33.294 | INFO     | src.policies:train:157 - Total loss: 1.0024123191833496\n",
      "2021-08-25 11:22:33.297 | INFO     | src.policies:train:103 - Epoch 598 / 800\n",
      "2021-08-25 11:22:33.298 | INFO     | src.policies:train:109 - Episode 2409\n",
      "2021-08-25 11:22:33.356 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:33.358 | INFO     | src.policies:train:121 - Mean episode return: 172.0\n",
      "2021-08-25 11:22:33.359 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 177.71\n",
      "2021-08-25 11:22:33.359 | INFO     | src.policies:train:109 - Episode 2410\n",
      "2021-08-25 11:22:33.416 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:33.418 | INFO     | src.policies:train:121 - Mean episode return: 170.0\n",
      "2021-08-25 11:22:33.418 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 177.47\n",
      "2021-08-25 11:22:33.419 | WARNING  | src.policies:train:131 - The actual batch size is 342, instead of 200\n",
      "2021-08-25 11:22:33.425 | INFO     | src.policies:train:157 - Total loss: 1.0023692846298218\n",
      "2021-08-25 11:22:33.428 | INFO     | src.policies:train:103 - Epoch 599 / 800\n",
      "2021-08-25 11:22:33.429 | INFO     | src.policies:train:109 - Episode 2411\n",
      "2021-08-25 11:22:33.482 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:33.484 | INFO     | src.policies:train:121 - Mean episode return: 156.0\n",
      "2021-08-25 11:22:33.484 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 177.61\n",
      "2021-08-25 11:22:33.485 | INFO     | src.policies:train:109 - Episode 2412\n",
      "2021-08-25 11:22:33.554 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:33.555 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:33.556 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 177.61\n",
      "2021-08-25 11:22:33.556 | WARNING  | src.policies:train:131 - The actual batch size is 356, instead of 200\n",
      "2021-08-25 11:22:33.563 | INFO     | src.policies:train:157 - Total loss: 1.002371072769165\n",
      "2021-08-25 11:22:33.566 | INFO     | src.policies:train:103 - Epoch 600 / 800\n",
      "2021-08-25 11:22:33.567 | INFO     | src.policies:train:109 - Episode 2413\n",
      "2021-08-25 11:22:33.637 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:33.638 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:33.639 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 177.95\n",
      "2021-08-25 11:22:33.645 | INFO     | src.policies:train:157 - Total loss: 1.0000522136688232\n",
      "2021-08-25 11:22:33.647 | INFO     | src.policies:train:103 - Epoch 601 / 800\n",
      "2021-08-25 11:22:33.648 | INFO     | src.policies:train:109 - Episode 2414\n",
      "2021-08-25 11:22:33.707 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:33.709 | INFO     | src.policies:train:121 - Mean episode return: 167.0\n",
      "2021-08-25 11:22:33.710 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 177.62\n",
      "2021-08-25 11:22:33.710 | INFO     | src.policies:train:109 - Episode 2415\n",
      "2021-08-25 11:22:33.781 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:33.782 | INFO     | src.policies:train:121 - Mean episode return: 199.0\n",
      "2021-08-25 11:22:33.783 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 177.62\n",
      "2021-08-25 11:22:33.784 | WARNING  | src.policies:train:131 - The actual batch size is 366, instead of 200\n",
      "2021-08-25 11:22:33.790 | INFO     | src.policies:train:157 - Total loss: 1.0026129484176636\n",
      "2021-08-25 11:22:33.793 | INFO     | src.policies:train:103 - Epoch 602 / 800\n",
      "2021-08-25 11:22:33.794 | INFO     | src.policies:train:109 - Episode 2416\n",
      "2021-08-25 11:22:33.860 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:33.861 | INFO     | src.policies:train:121 - Mean episode return: 196.0\n",
      "2021-08-25 11:22:33.862 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 177.58\n",
      "2021-08-25 11:22:33.863 | INFO     | src.policies:train:109 - Episode 2417\n",
      "2021-08-25 11:22:33.930 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:33.931 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:33.932 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 177.58\n",
      "2021-08-25 11:22:33.933 | WARNING  | src.policies:train:131 - The actual batch size is 396, instead of 200\n",
      "2021-08-25 11:22:33.940 | INFO     | src.policies:train:157 - Total loss: 1.0027116537094116\n",
      "2021-08-25 11:22:33.943 | INFO     | src.policies:train:103 - Epoch 603 / 800\n",
      "2021-08-25 11:22:33.944 | INFO     | src.policies:train:109 - Episode 2418\n",
      "2021-08-25 11:22:34.002 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:34.003 | INFO     | src.policies:train:121 - Mean episode return: 169.0\n",
      "2021-08-25 11:22:34.004 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 178.01\n",
      "2021-08-25 11:22:34.005 | INFO     | src.policies:train:109 - Episode 2419\n",
      "2021-08-25 11:22:34.069 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:34.071 | INFO     | src.policies:train:121 - Mean episode return: 190.0\n",
      "2021-08-25 11:22:34.072 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 178.03\n",
      "2021-08-25 11:22:34.072 | WARNING  | src.policies:train:131 - The actual batch size is 359, instead of 200\n",
      "2021-08-25 11:22:34.078 | INFO     | src.policies:train:157 - Total loss: 1.0026909112930298\n",
      "2021-08-25 11:22:34.081 | INFO     | src.policies:train:103 - Epoch 604 / 800\n",
      "2021-08-25 11:22:34.083 | INFO     | src.policies:train:109 - Episode 2420\n",
      "2021-08-25 11:22:34.151 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:22:34.153 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:34.154 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 178.65\n",
      "2021-08-25 11:22:34.159 | INFO     | src.policies:train:157 - Total loss: 1.000416874885559\n",
      "2021-08-25 11:22:34.162 | INFO     | src.policies:train:103 - Epoch 605 / 800\n",
      "2021-08-25 11:22:34.163 | INFO     | src.policies:train:109 - Episode 2421\n",
      "2021-08-25 11:22:34.220 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:34.222 | INFO     | src.policies:train:121 - Mean episode return: 170.0\n",
      "2021-08-25 11:22:34.223 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 178.75\n",
      "2021-08-25 11:22:34.224 | INFO     | src.policies:train:109 - Episode 2422\n",
      "2021-08-25 11:22:34.287 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:34.288 | INFO     | src.policies:train:121 - Mean episode return: 183.0\n",
      "2021-08-25 11:22:34.289 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 179.08\n",
      "2021-08-25 11:22:34.290 | WARNING  | src.policies:train:131 - The actual batch size is 353, instead of 200\n",
      "2021-08-25 11:22:34.297 | INFO     | src.policies:train:157 - Total loss: 1.0024104118347168\n",
      "2021-08-25 11:22:34.299 | INFO     | src.policies:train:103 - Epoch 606 / 800\n",
      "2021-08-25 11:22:34.301 | INFO     | src.policies:train:109 - Episode 2423\n",
      "2021-08-25 11:22:34.356 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:34.358 | INFO     | src.policies:train:121 - Mean episode return: 160.0\n",
      "2021-08-25 11:22:34.359 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 178.68\n",
      "2021-08-25 11:22:34.360 | INFO     | src.policies:train:109 - Episode 2424\n",
      "2021-08-25 11:22:34.427 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:34.428 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:34.429 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 179.24\n",
      "2021-08-25 11:22:34.430 | WARNING  | src.policies:train:131 - The actual batch size is 360, instead of 200\n",
      "2021-08-25 11:22:34.437 | INFO     | src.policies:train:157 - Total loss: 1.0024327039718628\n",
      "2021-08-25 11:22:34.441 | INFO     | src.policies:train:103 - Epoch 607 / 800\n",
      "2021-08-25 11:22:34.442 | INFO     | src.policies:train:109 - Episode 2425\n",
      "2021-08-25 11:22:34.510 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:34.512 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:34.513 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 179.55\n",
      "2021-08-25 11:22:34.517 | INFO     | src.policies:train:157 - Total loss: 1.000262975692749\n",
      "2021-08-25 11:22:34.520 | INFO     | src.policies:train:103 - Epoch 608 / 800\n",
      "2021-08-25 11:22:34.521 | INFO     | src.policies:train:109 - Episode 2426\n",
      "2021-08-25 11:22:34.581 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:34.582 | INFO     | src.policies:train:121 - Mean episode return: 179.0\n",
      "2021-08-25 11:22:34.583 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 179.64\n",
      "2021-08-25 11:22:34.584 | INFO     | src.policies:train:109 - Episode 2427\n",
      "2021-08-25 11:22:34.635 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:34.636 | INFO     | src.policies:train:121 - Mean episode return: 151.0\n",
      "2021-08-25 11:22:34.637 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 179.15\n",
      "2021-08-25 11:22:34.638 | WARNING  | src.policies:train:131 - The actual batch size is 330, instead of 200\n",
      "2021-08-25 11:22:34.644 | INFO     | src.policies:train:157 - Total loss: 1.0022776126861572\n",
      "2021-08-25 11:22:34.648 | INFO     | src.policies:train:103 - Epoch 609 / 800\n",
      "2021-08-25 11:22:34.649 | INFO     | src.policies:train:109 - Episode 2428\n",
      "2021-08-25 11:22:34.715 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:34.716 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:34.717 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 179.61\n",
      "2021-08-25 11:22:34.722 | INFO     | src.policies:train:157 - Total loss: 1.0003440380096436\n",
      "2021-08-25 11:22:34.725 | INFO     | src.policies:train:103 - Epoch 610 / 800\n",
      "2021-08-25 11:22:34.726 | INFO     | src.policies:train:109 - Episode 2429\n",
      "2021-08-25 11:22:34.769 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:34.771 | INFO     | src.policies:train:121 - Mean episode return: 127.0\n",
      "2021-08-25 11:22:34.772 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 178.88\n",
      "2021-08-25 11:22:34.772 | INFO     | src.policies:train:109 - Episode 2430\n",
      "2021-08-25 11:22:34.823 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:34.824 | INFO     | src.policies:train:121 - Mean episode return: 147.0\n",
      "2021-08-25 11:22:34.825 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 178.35\n",
      "2021-08-25 11:22:34.826 | WARNING  | src.policies:train:131 - The actual batch size is 274, instead of 200\n",
      "2021-08-25 11:22:34.832 | INFO     | src.policies:train:157 - Total loss: 1.0016409158706665\n",
      "2021-08-25 11:22:34.835 | INFO     | src.policies:train:103 - Epoch 611 / 800\n",
      "2021-08-25 11:22:34.836 | INFO     | src.policies:train:109 - Episode 2431\n",
      "2021-08-25 11:22:34.888 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:34.889 | INFO     | src.policies:train:121 - Mean episode return: 152.0\n",
      "2021-08-25 11:22:34.890 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 177.87\n",
      "2021-08-25 11:22:34.891 | INFO     | src.policies:train:109 - Episode 2432\n",
      "2021-08-25 11:22:34.949 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:34.951 | INFO     | src.policies:train:121 - Mean episode return: 163.0\n",
      "2021-08-25 11:22:34.952 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 178.25\n",
      "2021-08-25 11:22:34.952 | WARNING  | src.policies:train:131 - The actual batch size is 315, instead of 200\n",
      "2021-08-25 11:22:34.959 | INFO     | src.policies:train:157 - Total loss: 1.0018969774246216\n",
      "2021-08-25 11:22:34.962 | INFO     | src.policies:train:103 - Epoch 612 / 800\n",
      "2021-08-25 11:22:34.964 | INFO     | src.policies:train:109 - Episode 2433\n",
      "2021-08-25 11:22:35.034 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:35.035 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:35.036 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 178.54\n",
      "2021-08-25 11:22:35.041 | INFO     | src.policies:train:157 - Total loss: 1.0003350973129272\n",
      "2021-08-25 11:22:35.044 | INFO     | src.policies:train:103 - Epoch 613 / 800\n",
      "2021-08-25 11:22:35.045 | INFO     | src.policies:train:109 - Episode 2434\n",
      "2021-08-25 11:22:35.096 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:35.098 | INFO     | src.policies:train:121 - Mean episode return: 143.0\n",
      "2021-08-25 11:22:35.099 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 177.97\n",
      "2021-08-25 11:22:35.099 | INFO     | src.policies:train:109 - Episode 2435\n",
      "2021-08-25 11:22:35.160 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:35.161 | INFO     | src.policies:train:121 - Mean episode return: 176.0\n",
      "2021-08-25 11:22:35.162 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 177.73\n",
      "2021-08-25 11:22:35.163 | WARNING  | src.policies:train:131 - The actual batch size is 319, instead of 200\n",
      "2021-08-25 11:22:35.169 | INFO     | src.policies:train:157 - Total loss: 1.0020322799682617\n",
      "2021-08-25 11:22:35.172 | INFO     | src.policies:train:103 - Epoch 614 / 800\n",
      "2021-08-25 11:22:35.173 | INFO     | src.policies:train:109 - Episode 2436\n",
      "2021-08-25 11:22:35.220 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:22:35.222 | INFO     | src.policies:train:121 - Mean episode return: 132.0\n",
      "2021-08-25 11:22:35.223 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 177.91\n",
      "2021-08-25 11:22:35.223 | INFO     | src.policies:train:109 - Episode 2437\n",
      "2021-08-25 11:22:35.287 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:35.289 | INFO     | src.policies:train:121 - Mean episode return: 188.0\n",
      "2021-08-25 11:22:35.289 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 178.3\n",
      "2021-08-25 11:22:35.291 | WARNING  | src.policies:train:131 - The actual batch size is 320, instead of 200\n",
      "2021-08-25 11:22:35.297 | INFO     | src.policies:train:157 - Total loss: 1.0022387504577637\n",
      "2021-08-25 11:22:35.300 | INFO     | src.policies:train:103 - Epoch 615 / 800\n",
      "2021-08-25 11:22:35.301 | INFO     | src.policies:train:109 - Episode 2438\n",
      "2021-08-25 11:22:35.365 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:35.366 | INFO     | src.policies:train:121 - Mean episode return: 189.0\n",
      "2021-08-25 11:22:35.367 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 178.85\n",
      "2021-08-25 11:22:35.368 | INFO     | src.policies:train:109 - Episode 2439\n",
      "2021-08-25 11:22:35.434 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:35.436 | INFO     | src.policies:train:121 - Mean episode return: 187.0\n",
      "2021-08-25 11:22:35.437 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 179.5\n",
      "2021-08-25 11:22:35.438 | WARNING  | src.policies:train:131 - The actual batch size is 376, instead of 200\n",
      "2021-08-25 11:22:35.444 | INFO     | src.policies:train:157 - Total loss: 1.0026496648788452\n",
      "2021-08-25 11:22:35.447 | INFO     | src.policies:train:103 - Epoch 616 / 800\n",
      "2021-08-25 11:22:35.448 | INFO     | src.policies:train:109 - Episode 2440\n",
      "2021-08-25 11:22:35.508 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:35.510 | INFO     | src.policies:train:121 - Mean episode return: 178.0\n",
      "2021-08-25 11:22:35.511 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 179.41\n",
      "2021-08-25 11:22:35.512 | INFO     | src.policies:train:109 - Episode 2441\n",
      "2021-08-25 11:22:35.565 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:35.566 | INFO     | src.policies:train:121 - Mean episode return: 150.0\n",
      "2021-08-25 11:22:35.568 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 179.19\n",
      "2021-08-25 11:22:35.569 | WARNING  | src.policies:train:131 - The actual batch size is 328, instead of 200\n",
      "2021-08-25 11:22:35.577 | INFO     | src.policies:train:157 - Total loss: 1.0020537376403809\n",
      "2021-08-25 11:22:35.581 | INFO     | src.policies:train:103 - Epoch 617 / 800\n",
      "2021-08-25 11:22:35.582 | INFO     | src.policies:train:109 - Episode 2442\n",
      "2021-08-25 11:22:35.633 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:35.635 | INFO     | src.policies:train:121 - Mean episode return: 144.0\n",
      "2021-08-25 11:22:35.636 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 179.1\n",
      "2021-08-25 11:22:35.637 | INFO     | src.policies:train:109 - Episode 2443\n",
      "2021-08-25 11:22:35.682 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:35.684 | INFO     | src.policies:train:121 - Mean episode return: 124.0\n",
      "2021-08-25 11:22:35.684 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 178.34\n",
      "2021-08-25 11:22:35.686 | WARNING  | src.policies:train:131 - The actual batch size is 268, instead of 200\n",
      "2021-08-25 11:22:35.694 | INFO     | src.policies:train:157 - Total loss: 1.0015047788619995\n",
      "2021-08-25 11:22:35.698 | INFO     | src.policies:train:103 - Epoch 618 / 800\n",
      "2021-08-25 11:22:35.699 | INFO     | src.policies:train:109 - Episode 2444\n",
      "2021-08-25 11:22:35.740 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:35.741 | INFO     | src.policies:train:121 - Mean episode return: 112.0\n",
      "2021-08-25 11:22:35.742 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 177.46\n",
      "2021-08-25 11:22:35.743 | INFO     | src.policies:train:109 - Episode 2445\n",
      "2021-08-25 11:22:35.813 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:35.814 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:35.815 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 178.19\n",
      "2021-08-25 11:22:35.816 | WARNING  | src.policies:train:131 - The actual batch size is 312, instead of 200\n",
      "2021-08-25 11:22:35.824 | INFO     | src.policies:train:157 - Total loss: 1.0019996166229248\n",
      "2021-08-25 11:22:35.827 | INFO     | src.policies:train:103 - Epoch 619 / 800\n",
      "2021-08-25 11:22:35.829 | INFO     | src.policies:train:109 - Episode 2446\n",
      "2021-08-25 11:22:35.900 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:35.902 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:35.903 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 178.24\n",
      "2021-08-25 11:22:35.908 | INFO     | src.policies:train:157 - Total loss: 1.000234603881836\n",
      "2021-08-25 11:22:35.911 | INFO     | src.policies:train:103 - Epoch 620 / 800\n",
      "2021-08-25 11:22:35.912 | INFO     | src.policies:train:109 - Episode 2447\n",
      "2021-08-25 11:22:35.934 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:35.936 | INFO     | src.policies:train:121 - Mean episode return: 59.0\n",
      "2021-08-25 11:22:35.937 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.83\n",
      "2021-08-25 11:22:35.938 | INFO     | src.policies:train:109 - Episode 2448\n",
      "2021-08-25 11:22:35.994 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:35.996 | INFO     | src.policies:train:121 - Mean episode return: 155.0\n",
      "2021-08-25 11:22:35.997 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 177.03\n",
      "2021-08-25 11:22:35.997 | WARNING  | src.policies:train:131 - The actual batch size is 214, instead of 200\n",
      "2021-08-25 11:22:36.004 | INFO     | src.policies:train:157 - Total loss: 1.0004432201385498\n",
      "2021-08-25 11:22:36.008 | INFO     | src.policies:train:103 - Epoch 621 / 800\n",
      "2021-08-25 11:22:36.009 | INFO     | src.policies:train:109 - Episode 2449\n",
      "2021-08-25 11:22:36.076 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:36.078 | INFO     | src.policies:train:121 - Mean episode return: 199.0\n",
      "2021-08-25 11:22:36.079 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 177.22\n",
      "2021-08-25 11:22:36.080 | INFO     | src.policies:train:109 - Episode 2450\n",
      "2021-08-25 11:22:36.140 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:36.141 | INFO     | src.policies:train:121 - Mean episode return: 169.0\n",
      "2021-08-25 11:22:36.143 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.91\n",
      "2021-08-25 11:22:36.144 | WARNING  | src.policies:train:131 - The actual batch size is 368, instead of 200\n",
      "2021-08-25 11:22:36.151 | INFO     | src.policies:train:157 - Total loss: 1.0024607181549072\n",
      "2021-08-25 11:22:36.154 | INFO     | src.policies:train:103 - Epoch 622 / 800\n",
      "2021-08-25 11:22:36.155 | INFO     | src.policies:train:109 - Episode 2451\n",
      "2021-08-25 11:22:36.212 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:36.214 | INFO     | src.policies:train:121 - Mean episode return: 156.0\n",
      "2021-08-25 11:22:36.215 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.47\n",
      "2021-08-25 11:22:36.216 | INFO     | src.policies:train:109 - Episode 2452\n",
      "2021-08-25 11:22:36.289 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:36.290 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:36.291 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.47\n",
      "2021-08-25 11:22:36.292 | WARNING  | src.policies:train:131 - The actual batch size is 356, instead of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:22:36.300 | INFO     | src.policies:train:157 - Total loss: 1.0023576021194458\n",
      "2021-08-25 11:22:36.303 | INFO     | src.policies:train:103 - Epoch 623 / 800\n",
      "2021-08-25 11:22:36.304 | INFO     | src.policies:train:109 - Episode 2453\n",
      "2021-08-25 11:22:36.348 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:36.350 | INFO     | src.policies:train:121 - Mean episode return: 121.0\n",
      "2021-08-25 11:22:36.351 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.19\n",
      "2021-08-25 11:22:36.352 | INFO     | src.policies:train:109 - Episode 2454\n",
      "2021-08-25 11:22:36.423 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:36.424 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:36.425 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.38\n",
      "2021-08-25 11:22:36.426 | WARNING  | src.policies:train:131 - The actual batch size is 321, instead of 200\n",
      "2021-08-25 11:22:36.434 | INFO     | src.policies:train:157 - Total loss: 1.0019841194152832\n",
      "2021-08-25 11:22:36.437 | INFO     | src.policies:train:103 - Epoch 624 / 800\n",
      "2021-08-25 11:22:36.438 | INFO     | src.policies:train:109 - Episode 2455\n",
      "2021-08-25 11:22:36.495 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:36.496 | INFO     | src.policies:train:121 - Mean episode return: 155.0\n",
      "2021-08-25 11:22:36.497 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.93\n",
      "2021-08-25 11:22:36.498 | INFO     | src.policies:train:109 - Episode 2456\n",
      "2021-08-25 11:22:36.568 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:36.569 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:36.570 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.09\n",
      "2021-08-25 11:22:36.571 | WARNING  | src.policies:train:131 - The actual batch size is 355, instead of 200\n",
      "2021-08-25 11:22:36.579 | INFO     | src.policies:train:157 - Total loss: 1.0023813247680664\n",
      "2021-08-25 11:22:36.583 | INFO     | src.policies:train:103 - Epoch 625 / 800\n",
      "2021-08-25 11:22:36.584 | INFO     | src.policies:train:109 - Episode 2457\n",
      "2021-08-25 11:22:36.649 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:36.650 | INFO     | src.policies:train:121 - Mean episode return: 182.0\n",
      "2021-08-25 11:22:36.651 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.91\n",
      "2021-08-25 11:22:36.652 | INFO     | src.policies:train:109 - Episode 2458\n",
      "2021-08-25 11:22:36.723 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:36.724 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:36.725 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.95\n",
      "2021-08-25 11:22:36.726 | WARNING  | src.policies:train:131 - The actual batch size is 382, instead of 200\n",
      "2021-08-25 11:22:36.734 | INFO     | src.policies:train:157 - Total loss: 1.0026757717132568\n",
      "2021-08-25 11:22:36.738 | INFO     | src.policies:train:103 - Epoch 626 / 800\n",
      "2021-08-25 11:22:36.739 | INFO     | src.policies:train:109 - Episode 2459\n",
      "2021-08-25 11:22:36.796 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:36.797 | INFO     | src.policies:train:121 - Mean episode return: 158.0\n",
      "2021-08-25 11:22:36.798 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.53\n",
      "2021-08-25 11:22:36.800 | INFO     | src.policies:train:109 - Episode 2460\n",
      "2021-08-25 11:22:36.862 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:36.864 | INFO     | src.policies:train:121 - Mean episode return: 181.0\n",
      "2021-08-25 11:22:36.865 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.34\n",
      "2021-08-25 11:22:36.866 | WARNING  | src.policies:train:131 - The actual batch size is 339, instead of 200\n",
      "2021-08-25 11:22:36.873 | INFO     | src.policies:train:157 - Total loss: 1.0022677183151245\n",
      "2021-08-25 11:22:36.877 | INFO     | src.policies:train:103 - Epoch 627 / 800\n",
      "2021-08-25 11:22:36.879 | INFO     | src.policies:train:109 - Episode 2461\n",
      "2021-08-25 11:22:36.925 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:36.926 | INFO     | src.policies:train:121 - Mean episode return: 129.0\n",
      "2021-08-25 11:22:36.927 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.72\n",
      "2021-08-25 11:22:36.928 | INFO     | src.policies:train:109 - Episode 2462\n",
      "2021-08-25 11:22:36.980 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:36.981 | INFO     | src.policies:train:121 - Mean episode return: 138.0\n",
      "2021-08-25 11:22:36.982 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.1\n",
      "2021-08-25 11:22:36.983 | WARNING  | src.policies:train:131 - The actual batch size is 267, instead of 200\n",
      "2021-08-25 11:22:36.990 | INFO     | src.policies:train:157 - Total loss: 1.0014450550079346\n",
      "2021-08-25 11:22:36.994 | INFO     | src.policies:train:103 - Epoch 628 / 800\n",
      "2021-08-25 11:22:36.995 | INFO     | src.policies:train:109 - Episode 2463\n",
      "2021-08-25 11:22:37.056 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:37.058 | INFO     | src.policies:train:121 - Mean episode return: 179.0\n",
      "2021-08-25 11:22:37.059 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.21\n",
      "2021-08-25 11:22:37.060 | INFO     | src.policies:train:109 - Episode 2464\n",
      "2021-08-25 11:22:37.113 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:37.114 | INFO     | src.policies:train:121 - Mean episode return: 152.0\n",
      "2021-08-25 11:22:37.115 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 173.73\n",
      "2021-08-25 11:22:37.116 | WARNING  | src.policies:train:131 - The actual batch size is 331, instead of 200\n",
      "2021-08-25 11:22:37.121 | INFO     | src.policies:train:157 - Total loss: 1.0022611618041992\n",
      "2021-08-25 11:22:37.124 | INFO     | src.policies:train:103 - Epoch 629 / 800\n",
      "2021-08-25 11:22:37.126 | INFO     | src.policies:train:109 - Episode 2465\n",
      "2021-08-25 11:22:37.193 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:37.195 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:37.196 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 173.73\n",
      "2021-08-25 11:22:37.201 | INFO     | src.policies:train:157 - Total loss: 1.00030517578125\n",
      "2021-08-25 11:22:37.204 | INFO     | src.policies:train:103 - Epoch 630 / 800\n",
      "2021-08-25 11:22:37.204 | INFO     | src.policies:train:109 - Episode 2466\n",
      "2021-08-25 11:22:37.271 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:37.273 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:37.274 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 173.73\n",
      "2021-08-25 11:22:37.279 | INFO     | src.policies:train:157 - Total loss: 1.0002448558807373\n",
      "2021-08-25 11:22:37.281 | INFO     | src.policies:train:103 - Epoch 631 / 800\n",
      "2021-08-25 11:22:37.282 | INFO     | src.policies:train:109 - Episode 2467\n",
      "2021-08-25 11:22:37.333 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:37.335 | INFO     | src.policies:train:121 - Mean episode return: 152.0\n",
      "2021-08-25 11:22:37.336 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 173.25\n",
      "2021-08-25 11:22:37.336 | INFO     | src.policies:train:109 - Episode 2468\n",
      "2021-08-25 11:22:37.382 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:37.383 | INFO     | src.policies:train:121 - Mean episode return: 134.0\n",
      "2021-08-25 11:22:37.384 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.59\n",
      "2021-08-25 11:22:37.385 | WARNING  | src.policies:train:131 - The actual batch size is 286, instead of 200\n",
      "2021-08-25 11:22:37.391 | INFO     | src.policies:train:157 - Total loss: 1.0016586780548096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:22:37.394 | INFO     | src.policies:train:103 - Epoch 632 / 800\n",
      "2021-08-25 11:22:37.395 | INFO     | src.policies:train:109 - Episode 2469\n",
      "2021-08-25 11:22:37.433 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:37.434 | INFO     | src.policies:train:121 - Mean episode return: 110.0\n",
      "2021-08-25 11:22:37.435 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.07\n",
      "2021-08-25 11:22:37.436 | INFO     | src.policies:train:109 - Episode 2470\n",
      "2021-08-25 11:22:37.486 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:37.487 | INFO     | src.policies:train:121 - Mean episode return: 141.0\n",
      "2021-08-25 11:22:37.488 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 171.59\n",
      "2021-08-25 11:22:37.489 | WARNING  | src.policies:train:131 - The actual batch size is 251, instead of 200\n",
      "2021-08-25 11:22:37.494 | INFO     | src.policies:train:157 - Total loss: 1.0012056827545166\n",
      "2021-08-25 11:22:37.497 | INFO     | src.policies:train:103 - Epoch 633 / 800\n",
      "2021-08-25 11:22:37.498 | INFO     | src.policies:train:109 - Episode 2471\n",
      "2021-08-25 11:22:37.565 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:37.567 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:37.568 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 171.59\n",
      "2021-08-25 11:22:37.573 | INFO     | src.policies:train:157 - Total loss: 1.0002241134643555\n",
      "2021-08-25 11:22:37.576 | INFO     | src.policies:train:103 - Epoch 634 / 800\n",
      "2021-08-25 11:22:37.577 | INFO     | src.policies:train:109 - Episode 2472\n",
      "2021-08-25 11:22:37.645 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:37.647 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:37.648 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.13\n",
      "2021-08-25 11:22:37.653 | INFO     | src.policies:train:157 - Total loss: 1.000346064567566\n",
      "2021-08-25 11:22:37.656 | INFO     | src.policies:train:103 - Epoch 635 / 800\n",
      "2021-08-25 11:22:37.656 | INFO     | src.policies:train:109 - Episode 2473\n",
      "2021-08-25 11:22:37.694 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:37.696 | INFO     | src.policies:train:121 - Mean episode return: 110.0\n",
      "2021-08-25 11:22:37.697 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 171.75\n",
      "2021-08-25 11:22:37.697 | INFO     | src.policies:train:109 - Episode 2474\n",
      "2021-08-25 11:22:37.765 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:37.766 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:37.767 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 171.75\n",
      "2021-08-25 11:22:37.768 | WARNING  | src.policies:train:131 - The actual batch size is 310, instead of 200\n",
      "2021-08-25 11:22:37.774 | INFO     | src.policies:train:157 - Total loss: 1.002061367034912\n",
      "2021-08-25 11:22:37.777 | INFO     | src.policies:train:103 - Epoch 636 / 800\n",
      "2021-08-25 11:22:37.778 | INFO     | src.policies:train:109 - Episode 2475\n",
      "2021-08-25 11:22:37.844 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:37.846 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:37.846 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.42\n",
      "2021-08-25 11:22:37.852 | INFO     | src.policies:train:157 - Total loss: 1.0001918077468872\n",
      "2021-08-25 11:22:37.855 | INFO     | src.policies:train:103 - Epoch 637 / 800\n",
      "2021-08-25 11:22:37.856 | INFO     | src.policies:train:109 - Episode 2476\n",
      "2021-08-25 11:22:37.904 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:37.906 | INFO     | src.policies:train:121 - Mean episode return: 142.0\n",
      "2021-08-25 11:22:37.907 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 171.96\n",
      "2021-08-25 11:22:37.907 | INFO     | src.policies:train:109 - Episode 2477\n",
      "2021-08-25 11:22:37.950 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:37.951 | INFO     | src.policies:train:121 - Mean episode return: 121.0\n",
      "2021-08-25 11:22:37.952 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 171.17\n",
      "2021-08-25 11:22:37.953 | WARNING  | src.policies:train:131 - The actual batch size is 263, instead of 200\n",
      "2021-08-25 11:22:37.960 | INFO     | src.policies:train:157 - Total loss: 1.0015008449554443\n",
      "2021-08-25 11:22:37.963 | INFO     | src.policies:train:103 - Epoch 638 / 800\n",
      "2021-08-25 11:22:37.964 | INFO     | src.policies:train:109 - Episode 2478\n",
      "2021-08-25 11:22:38.030 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:38.032 | INFO     | src.policies:train:121 - Mean episode return: 199.0\n",
      "2021-08-25 11:22:38.033 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 171.16\n",
      "2021-08-25 11:22:38.034 | INFO     | src.policies:train:109 - Episode 2479\n",
      "2021-08-25 11:22:38.101 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:38.102 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:38.103 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 171.5\n",
      "2021-08-25 11:22:38.104 | WARNING  | src.policies:train:131 - The actual batch size is 399, instead of 200\n",
      "2021-08-25 11:22:38.110 | INFO     | src.policies:train:157 - Total loss: 1.0027891397476196\n",
      "2021-08-25 11:22:38.113 | INFO     | src.policies:train:103 - Epoch 639 / 800\n",
      "2021-08-25 11:22:38.114 | INFO     | src.policies:train:109 - Episode 2480\n",
      "2021-08-25 11:22:38.160 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:38.162 | INFO     | src.policies:train:121 - Mean episode return: 134.0\n",
      "2021-08-25 11:22:38.163 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 170.84\n",
      "2021-08-25 11:22:38.163 | INFO     | src.policies:train:109 - Episode 2481\n",
      "2021-08-25 11:22:38.216 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:38.217 | INFO     | src.policies:train:121 - Mean episode return: 156.0\n",
      "2021-08-25 11:22:38.218 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 170.92\n",
      "2021-08-25 11:22:38.218 | WARNING  | src.policies:train:131 - The actual batch size is 290, instead of 200\n",
      "2021-08-25 11:22:38.224 | INFO     | src.policies:train:157 - Total loss: 1.0018812417984009\n",
      "2021-08-25 11:22:38.227 | INFO     | src.policies:train:103 - Epoch 640 / 800\n",
      "2021-08-25 11:22:38.228 | INFO     | src.policies:train:109 - Episode 2482\n",
      "2021-08-25 11:22:38.294 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:38.295 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:38.296 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 170.92\n",
      "2021-08-25 11:22:38.301 | INFO     | src.policies:train:157 - Total loss: 1.0003628730773926\n",
      "2021-08-25 11:22:38.304 | INFO     | src.policies:train:103 - Epoch 641 / 800\n",
      "2021-08-25 11:22:38.305 | INFO     | src.policies:train:109 - Episode 2483\n",
      "2021-08-25 11:22:38.354 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:38.355 | INFO     | src.policies:train:121 - Mean episode return: 139.0\n",
      "2021-08-25 11:22:38.356 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 170.48\n",
      "2021-08-25 11:22:38.357 | INFO     | src.policies:train:109 - Episode 2484\n",
      "2021-08-25 11:22:38.423 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:38.424 | INFO     | src.policies:train:121 - Mean episode return: 188.0\n",
      "2021-08-25 11:22:38.425 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 170.92\n",
      "2021-08-25 11:22:38.426 | WARNING  | src.policies:train:131 - The actual batch size is 327, instead of 200\n",
      "2021-08-25 11:22:38.432 | INFO     | src.policies:train:157 - Total loss: 1.002315878868103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:22:38.434 | INFO     | src.policies:train:103 - Epoch 642 / 800\n",
      "2021-08-25 11:22:38.435 | INFO     | src.policies:train:109 - Episode 2485\n",
      "2021-08-25 11:22:38.502 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:38.503 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:38.504 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 171.28\n",
      "2021-08-25 11:22:38.510 | INFO     | src.policies:train:157 - Total loss: 1.000100016593933\n",
      "2021-08-25 11:22:38.513 | INFO     | src.policies:train:103 - Epoch 643 / 800\n",
      "2021-08-25 11:22:38.513 | INFO     | src.policies:train:109 - Episode 2486\n",
      "2021-08-25 11:22:38.580 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:38.582 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:38.583 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 171.68\n",
      "2021-08-25 11:22:38.588 | INFO     | src.policies:train:157 - Total loss: 1.0003366470336914\n",
      "2021-08-25 11:22:38.591 | INFO     | src.policies:train:103 - Epoch 644 / 800\n",
      "2021-08-25 11:22:38.592 | INFO     | src.policies:train:109 - Episode 2487\n",
      "2021-08-25 11:22:38.659 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:38.660 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:38.661 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.49\n",
      "2021-08-25 11:22:38.666 | INFO     | src.policies:train:157 - Total loss: 1.000167965888977\n",
      "2021-08-25 11:22:38.669 | INFO     | src.policies:train:103 - Epoch 645 / 800\n",
      "2021-08-25 11:22:38.670 | INFO     | src.policies:train:109 - Episode 2488\n",
      "2021-08-25 11:22:38.734 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:38.736 | INFO     | src.policies:train:121 - Mean episode return: 191.0\n",
      "2021-08-25 11:22:38.737 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.4\n",
      "2021-08-25 11:22:38.737 | INFO     | src.policies:train:109 - Episode 2489\n",
      "2021-08-25 11:22:38.807 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:38.808 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:38.809 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.4\n",
      "2021-08-25 11:22:38.810 | WARNING  | src.policies:train:131 - The actual batch size is 391, instead of 200\n",
      "2021-08-25 11:22:38.816 | INFO     | src.policies:train:157 - Total loss: 1.00260329246521\n",
      "2021-08-25 11:22:38.819 | INFO     | src.policies:train:103 - Epoch 646 / 800\n",
      "2021-08-25 11:22:38.820 | INFO     | src.policies:train:109 - Episode 2490\n",
      "2021-08-25 11:22:38.882 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:38.883 | INFO     | src.policies:train:121 - Mean episode return: 186.0\n",
      "2021-08-25 11:22:38.884 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.31\n",
      "2021-08-25 11:22:38.885 | INFO     | src.policies:train:109 - Episode 2491\n",
      "2021-08-25 11:22:38.946 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:38.947 | INFO     | src.policies:train:121 - Mean episode return: 179.0\n",
      "2021-08-25 11:22:38.948 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.62\n",
      "2021-08-25 11:22:38.949 | WARNING  | src.policies:train:131 - The actual batch size is 365, instead of 200\n",
      "2021-08-25 11:22:38.955 | INFO     | src.policies:train:157 - Total loss: 1.0026401281356812\n",
      "2021-08-25 11:22:38.958 | INFO     | src.policies:train:103 - Epoch 647 / 800\n",
      "2021-08-25 11:22:38.959 | INFO     | src.policies:train:109 - Episode 2492\n",
      "2021-08-25 11:22:39.024 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:39.025 | INFO     | src.policies:train:121 - Mean episode return: 191.0\n",
      "2021-08-25 11:22:39.026 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.99\n",
      "2021-08-25 11:22:39.027 | INFO     | src.policies:train:109 - Episode 2493\n",
      "2021-08-25 11:22:39.096 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:39.098 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:39.098 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 173.09\n",
      "2021-08-25 11:22:39.099 | WARNING  | src.policies:train:131 - The actual batch size is 391, instead of 200\n",
      "2021-08-25 11:22:39.106 | INFO     | src.policies:train:157 - Total loss: 1.0028414726257324\n",
      "2021-08-25 11:22:39.109 | INFO     | src.policies:train:103 - Epoch 648 / 800\n",
      "2021-08-25 11:22:39.110 | INFO     | src.policies:train:109 - Episode 2494\n",
      "2021-08-25 11:22:39.169 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:39.170 | INFO     | src.policies:train:121 - Mean episode return: 174.0\n",
      "2021-08-25 11:22:39.171 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.83\n",
      "2021-08-25 11:22:39.172 | INFO     | src.policies:train:109 - Episode 2495\n",
      "2021-08-25 11:22:39.227 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:39.228 | INFO     | src.policies:train:121 - Mean episode return: 154.0\n",
      "2021-08-25 11:22:39.229 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.53\n",
      "2021-08-25 11:22:39.230 | WARNING  | src.policies:train:131 - The actual batch size is 328, instead of 200\n",
      "2021-08-25 11:22:39.236 | INFO     | src.policies:train:157 - Total loss: 1.002400279045105\n",
      "2021-08-25 11:22:39.239 | INFO     | src.policies:train:103 - Epoch 649 / 800\n",
      "2021-08-25 11:22:39.240 | INFO     | src.policies:train:109 - Episode 2496\n",
      "2021-08-25 11:22:39.306 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:39.307 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:39.308 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.53\n",
      "2021-08-25 11:22:39.313 | INFO     | src.policies:train:157 - Total loss: 1.0003762245178223\n",
      "2021-08-25 11:22:39.316 | INFO     | src.policies:train:103 - Epoch 650 / 800\n",
      "2021-08-25 11:22:39.317 | INFO     | src.policies:train:109 - Episode 2497\n",
      "2021-08-25 11:22:39.376 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:39.377 | INFO     | src.policies:train:121 - Mean episode return: 176.0\n",
      "2021-08-25 11:22:39.378 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.6\n",
      "2021-08-25 11:22:39.379 | INFO     | src.policies:train:109 - Episode 2498\n",
      "2021-08-25 11:22:39.424 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:39.425 | INFO     | src.policies:train:121 - Mean episode return: 130.0\n",
      "2021-08-25 11:22:39.426 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.11\n",
      "2021-08-25 11:22:39.427 | WARNING  | src.policies:train:131 - The actual batch size is 306, instead of 200\n",
      "2021-08-25 11:22:39.433 | INFO     | src.policies:train:157 - Total loss: 1.0020869970321655\n",
      "2021-08-25 11:22:39.436 | INFO     | src.policies:train:103 - Epoch 651 / 800\n",
      "2021-08-25 11:22:39.437 | INFO     | src.policies:train:109 - Episode 2499\n",
      "2021-08-25 11:22:39.504 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:39.506 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:39.506 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.45\n",
      "2021-08-25 11:22:39.512 | INFO     | src.policies:train:157 - Total loss: 1.0003044605255127\n",
      "2021-08-25 11:22:39.514 | INFO     | src.policies:train:103 - Epoch 652 / 800\n",
      "2021-08-25 11:22:39.515 | INFO     | src.policies:train:109 - Episode 2500\n",
      "2021-08-25 11:22:39.574 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:39.575 | INFO     | src.policies:train:121 - Mean episode return: 177.0\n",
      "2021-08-25 11:22:39.576 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:22:39.577 | INFO     | src.policies:train:109 - Episode 2501\n",
      "2021-08-25 11:22:39.646 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:39.647 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:39.648 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.61\n",
      "2021-08-25 11:22:39.649 | WARNING  | src.policies:train:131 - The actual batch size is 377, instead of 200\n",
      "2021-08-25 11:22:39.655 | INFO     | src.policies:train:157 - Total loss: 1.0025243759155273\n",
      "2021-08-25 11:22:39.658 | INFO     | src.policies:train:103 - Epoch 653 / 800\n",
      "2021-08-25 11:22:39.659 | INFO     | src.policies:train:109 - Episode 2502\n",
      "2021-08-25 11:22:39.721 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:39.722 | INFO     | src.policies:train:121 - Mean episode return: 183.0\n",
      "2021-08-25 11:22:39.723 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.44\n",
      "2021-08-25 11:22:39.724 | INFO     | src.policies:train:109 - Episode 2503\n",
      "2021-08-25 11:22:39.793 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:39.794 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:39.795 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.99\n",
      "2021-08-25 11:22:39.796 | WARNING  | src.policies:train:131 - The actual batch size is 383, instead of 200\n",
      "2021-08-25 11:22:39.803 | INFO     | src.policies:train:157 - Total loss: 1.0026187896728516\n",
      "2021-08-25 11:22:39.806 | INFO     | src.policies:train:103 - Epoch 654 / 800\n",
      "2021-08-25 11:22:39.807 | INFO     | src.policies:train:109 - Episode 2504\n",
      "2021-08-25 11:22:39.853 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:39.855 | INFO     | src.policies:train:121 - Mean episode return: 131.0\n",
      "2021-08-25 11:22:39.856 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.49\n",
      "2021-08-25 11:22:39.856 | INFO     | src.policies:train:109 - Episode 2505\n",
      "2021-08-25 11:22:39.916 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:39.917 | INFO     | src.policies:train:121 - Mean episode return: 168.0\n",
      "2021-08-25 11:22:39.918 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.17\n",
      "2021-08-25 11:22:39.919 | WARNING  | src.policies:train:131 - The actual batch size is 299, instead of 200\n",
      "2021-08-25 11:22:39.925 | INFO     | src.policies:train:157 - Total loss: 1.0020021200180054\n",
      "2021-08-25 11:22:39.927 | INFO     | src.policies:train:103 - Epoch 655 / 800\n",
      "2021-08-25 11:22:39.928 | INFO     | src.policies:train:109 - Episode 2506\n",
      "2021-08-25 11:22:39.977 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:39.979 | INFO     | src.policies:train:121 - Mean episode return: 143.0\n",
      "2021-08-25 11:22:39.980 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 171.6\n",
      "2021-08-25 11:22:39.981 | INFO     | src.policies:train:109 - Episode 2507\n",
      "2021-08-25 11:22:40.050 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:40.051 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:40.052 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 171.8\n",
      "2021-08-25 11:22:40.053 | WARNING  | src.policies:train:131 - The actual batch size is 343, instead of 200\n",
      "2021-08-25 11:22:40.059 | INFO     | src.policies:train:157 - Total loss: 1.0025140047073364\n",
      "2021-08-25 11:22:40.062 | INFO     | src.policies:train:103 - Epoch 656 / 800\n",
      "2021-08-25 11:22:40.063 | INFO     | src.policies:train:109 - Episode 2508\n",
      "2021-08-25 11:22:40.106 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:40.108 | INFO     | src.policies:train:121 - Mean episode return: 130.0\n",
      "2021-08-25 11:22:40.109 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 171.46\n",
      "2021-08-25 11:22:40.109 | INFO     | src.policies:train:109 - Episode 2509\n",
      "2021-08-25 11:22:40.153 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:40.154 | INFO     | src.policies:train:121 - Mean episode return: 121.0\n",
      "2021-08-25 11:22:40.155 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 170.95\n",
      "2021-08-25 11:22:40.156 | WARNING  | src.policies:train:131 - The actual batch size is 251, instead of 200\n",
      "2021-08-25 11:22:40.162 | INFO     | src.policies:train:157 - Total loss: 1.0012550354003906\n",
      "2021-08-25 11:22:40.164 | INFO     | src.policies:train:103 - Epoch 657 / 800\n",
      "2021-08-25 11:22:40.165 | INFO     | src.policies:train:109 - Episode 2510\n",
      "2021-08-25 11:22:40.222 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:40.224 | INFO     | src.policies:train:121 - Mean episode return: 171.0\n",
      "2021-08-25 11:22:40.225 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 170.96\n",
      "2021-08-25 11:22:40.225 | INFO     | src.policies:train:109 - Episode 2511\n",
      "2021-08-25 11:22:40.295 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:40.297 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:40.297 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 171.4\n",
      "2021-08-25 11:22:40.298 | WARNING  | src.policies:train:131 - The actual batch size is 371, instead of 200\n",
      "2021-08-25 11:22:40.304 | INFO     | src.policies:train:157 - Total loss: 1.0024720430374146\n",
      "2021-08-25 11:22:40.307 | INFO     | src.policies:train:103 - Epoch 658 / 800\n",
      "2021-08-25 11:22:40.308 | INFO     | src.policies:train:109 - Episode 2512\n",
      "2021-08-25 11:22:40.347 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:40.348 | INFO     | src.policies:train:121 - Mean episode return: 116.0\n",
      "2021-08-25 11:22:40.349 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 170.56\n",
      "2021-08-25 11:22:40.350 | INFO     | src.policies:train:109 - Episode 2513\n",
      "2021-08-25 11:22:40.419 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:40.420 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:40.421 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 170.56\n",
      "2021-08-25 11:22:40.422 | WARNING  | src.policies:train:131 - The actual batch size is 316, instead of 200\n",
      "2021-08-25 11:22:40.428 | INFO     | src.policies:train:157 - Total loss: 1.0022804737091064\n",
      "2021-08-25 11:22:40.431 | INFO     | src.policies:train:103 - Epoch 659 / 800\n",
      "2021-08-25 11:22:40.432 | INFO     | src.policies:train:109 - Episode 2514\n",
      "2021-08-25 11:22:40.489 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:40.491 | INFO     | src.policies:train:121 - Mean episode return: 171.0\n",
      "2021-08-25 11:22:40.492 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 170.6\n",
      "2021-08-25 11:22:40.493 | INFO     | src.policies:train:109 - Episode 2515\n",
      "2021-08-25 11:22:40.554 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:40.555 | INFO     | src.policies:train:121 - Mean episode return: 179.0\n",
      "2021-08-25 11:22:40.556 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 170.4\n",
      "2021-08-25 11:22:40.557 | WARNING  | src.policies:train:131 - The actual batch size is 350, instead of 200\n",
      "2021-08-25 11:22:40.563 | INFO     | src.policies:train:157 - Total loss: 1.002363681793213\n",
      "2021-08-25 11:22:40.566 | INFO     | src.policies:train:103 - Epoch 660 / 800\n",
      "2021-08-25 11:22:40.567 | INFO     | src.policies:train:109 - Episode 2516\n",
      "2021-08-25 11:22:40.621 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:40.622 | INFO     | src.policies:train:121 - Mean episode return: 160.0\n",
      "2021-08-25 11:22:40.623 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 170.04\n",
      "2021-08-25 11:22:40.624 | INFO     | src.policies:train:109 - Episode 2517\n",
      "2021-08-25 11:22:40.690 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:22:40.691 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:40.692 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 170.04\n",
      "2021-08-25 11:22:40.693 | WARNING  | src.policies:train:131 - The actual batch size is 360, instead of 200\n",
      "2021-08-25 11:22:40.700 | INFO     | src.policies:train:157 - Total loss: 1.0026201009750366\n",
      "2021-08-25 11:22:40.704 | INFO     | src.policies:train:103 - Epoch 661 / 800\n",
      "2021-08-25 11:22:40.706 | INFO     | src.policies:train:109 - Episode 2518\n",
      "2021-08-25 11:22:40.749 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:40.751 | INFO     | src.policies:train:121 - Mean episode return: 125.0\n",
      "2021-08-25 11:22:40.752 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 169.6\n",
      "2021-08-25 11:22:40.752 | INFO     | src.policies:train:109 - Episode 2519\n",
      "2021-08-25 11:22:40.819 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:40.821 | INFO     | src.policies:train:121 - Mean episode return: 188.0\n",
      "2021-08-25 11:22:40.822 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 169.58\n",
      "2021-08-25 11:22:40.823 | WARNING  | src.policies:train:131 - The actual batch size is 313, instead of 200\n",
      "2021-08-25 11:22:40.828 | INFO     | src.policies:train:157 - Total loss: 1.002089500427246\n",
      "2021-08-25 11:22:40.832 | INFO     | src.policies:train:103 - Epoch 662 / 800\n",
      "2021-08-25 11:22:40.833 | INFO     | src.policies:train:109 - Episode 2520\n",
      "2021-08-25 11:22:40.899 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:40.900 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:40.901 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 169.58\n",
      "2021-08-25 11:22:40.906 | INFO     | src.policies:train:157 - Total loss: 1.0003567934036255\n",
      "2021-08-25 11:22:40.909 | INFO     | src.policies:train:103 - Epoch 663 / 800\n",
      "2021-08-25 11:22:40.910 | INFO     | src.policies:train:109 - Episode 2521\n",
      "2021-08-25 11:22:40.977 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:40.978 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:40.979 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 169.88\n",
      "2021-08-25 11:22:40.985 | INFO     | src.policies:train:157 - Total loss: 1.0002517700195312\n",
      "2021-08-25 11:22:40.987 | INFO     | src.policies:train:103 - Epoch 664 / 800\n",
      "2021-08-25 11:22:40.988 | INFO     | src.policies:train:109 - Episode 2522\n",
      "2021-08-25 11:22:41.055 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:41.057 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:41.058 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 170.05\n",
      "2021-08-25 11:22:41.063 | INFO     | src.policies:train:157 - Total loss: 1.000268816947937\n",
      "2021-08-25 11:22:41.065 | INFO     | src.policies:train:103 - Epoch 665 / 800\n",
      "2021-08-25 11:22:41.066 | INFO     | src.policies:train:109 - Episode 2523\n",
      "2021-08-25 11:22:41.121 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:41.123 | INFO     | src.policies:train:121 - Mean episode return: 161.0\n",
      "2021-08-25 11:22:41.124 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 170.06\n",
      "2021-08-25 11:22:41.124 | INFO     | src.policies:train:109 - Episode 2524\n",
      "2021-08-25 11:22:41.185 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:41.186 | INFO     | src.policies:train:121 - Mean episode return: 180.0\n",
      "2021-08-25 11:22:41.187 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 169.86\n",
      "2021-08-25 11:22:41.188 | WARNING  | src.policies:train:131 - The actual batch size is 341, instead of 200\n",
      "2021-08-25 11:22:41.194 | INFO     | src.policies:train:157 - Total loss: 1.0022683143615723\n",
      "2021-08-25 11:22:41.198 | INFO     | src.policies:train:103 - Epoch 666 / 800\n",
      "2021-08-25 11:22:41.200 | INFO     | src.policies:train:109 - Episode 2525\n",
      "2021-08-25 11:22:41.263 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:41.264 | INFO     | src.policies:train:121 - Mean episode return: 177.0\n",
      "2021-08-25 11:22:41.265 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 169.63\n",
      "2021-08-25 11:22:41.266 | INFO     | src.policies:train:109 - Episode 2526\n",
      "2021-08-25 11:22:41.313 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:41.314 | INFO     | src.policies:train:121 - Mean episode return: 135.0\n",
      "2021-08-25 11:22:41.315 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 169.19\n",
      "2021-08-25 11:22:41.316 | WARNING  | src.policies:train:131 - The actual batch size is 312, instead of 200\n",
      "2021-08-25 11:22:41.322 | INFO     | src.policies:train:157 - Total loss: 1.0019360780715942\n",
      "2021-08-25 11:22:41.325 | INFO     | src.policies:train:103 - Epoch 667 / 800\n",
      "2021-08-25 11:22:41.326 | INFO     | src.policies:train:109 - Episode 2527\n",
      "2021-08-25 11:22:41.370 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:41.372 | INFO     | src.policies:train:121 - Mean episode return: 126.0\n",
      "2021-08-25 11:22:41.373 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 168.94\n",
      "2021-08-25 11:22:41.373 | INFO     | src.policies:train:109 - Episode 2528\n",
      "2021-08-25 11:22:41.442 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:41.443 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:41.444 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 168.94\n",
      "2021-08-25 11:22:41.445 | WARNING  | src.policies:train:131 - The actual batch size is 326, instead of 200\n",
      "2021-08-25 11:22:41.451 | INFO     | src.policies:train:157 - Total loss: 1.002348780632019\n",
      "2021-08-25 11:22:41.454 | INFO     | src.policies:train:103 - Epoch 668 / 800\n",
      "2021-08-25 11:22:41.455 | INFO     | src.policies:train:109 - Episode 2529\n",
      "2021-08-25 11:22:41.514 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:41.515 | INFO     | src.policies:train:121 - Mean episode return: 176.0\n",
      "2021-08-25 11:22:41.516 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 169.43\n",
      "2021-08-25 11:22:41.517 | INFO     | src.policies:train:109 - Episode 2530\n",
      "2021-08-25 11:22:41.587 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:41.588 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:41.590 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 169.96\n",
      "2021-08-25 11:22:41.590 | WARNING  | src.policies:train:131 - The actual batch size is 376, instead of 200\n",
      "2021-08-25 11:22:41.596 | INFO     | src.policies:train:157 - Total loss: 1.0026469230651855\n",
      "2021-08-25 11:22:41.599 | INFO     | src.policies:train:103 - Epoch 669 / 800\n",
      "2021-08-25 11:22:41.600 | INFO     | src.policies:train:109 - Episode 2531\n",
      "2021-08-25 11:22:41.652 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:41.653 | INFO     | src.policies:train:121 - Mean episode return: 152.0\n",
      "2021-08-25 11:22:41.654 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 169.96\n",
      "2021-08-25 11:22:41.655 | INFO     | src.policies:train:109 - Episode 2532\n",
      "2021-08-25 11:22:41.701 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:41.702 | INFO     | src.policies:train:121 - Mean episode return: 136.0\n",
      "2021-08-25 11:22:41.703 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 169.69\n",
      "2021-08-25 11:22:41.704 | WARNING  | src.policies:train:131 - The actual batch size is 288, instead of 200\n",
      "2021-08-25 11:22:41.710 | INFO     | src.policies:train:157 - Total loss: 1.001834750175476\n",
      "2021-08-25 11:22:41.713 | INFO     | src.policies:train:103 - Epoch 670 / 800\n",
      "2021-08-25 11:22:41.714 | INFO     | src.policies:train:109 - Episode 2533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:22:41.761 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:41.762 | INFO     | src.policies:train:121 - Mean episode return: 138.0\n",
      "2021-08-25 11:22:41.763 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 169.07\n",
      "2021-08-25 11:22:41.764 | INFO     | src.policies:train:109 - Episode 2534\n",
      "2021-08-25 11:22:41.817 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:41.818 | INFO     | src.policies:train:121 - Mean episode return: 152.0\n",
      "2021-08-25 11:22:41.819 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 169.16\n",
      "2021-08-25 11:22:41.820 | WARNING  | src.policies:train:131 - The actual batch size is 290, instead of 200\n",
      "2021-08-25 11:22:41.826 | INFO     | src.policies:train:157 - Total loss: 1.001956582069397\n",
      "2021-08-25 11:22:41.829 | INFO     | src.policies:train:103 - Epoch 671 / 800\n",
      "2021-08-25 11:22:41.830 | INFO     | src.policies:train:109 - Episode 2535\n",
      "2021-08-25 11:22:41.891 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:41.893 | INFO     | src.policies:train:121 - Mean episode return: 182.0\n",
      "2021-08-25 11:22:41.894 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 169.22\n",
      "2021-08-25 11:22:41.894 | INFO     | src.policies:train:109 - Episode 2536\n",
      "2021-08-25 11:22:41.945 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:41.946 | INFO     | src.policies:train:121 - Mean episode return: 142.0\n",
      "2021-08-25 11:22:41.947 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 169.32\n",
      "2021-08-25 11:22:41.948 | WARNING  | src.policies:train:131 - The actual batch size is 324, instead of 200\n",
      "2021-08-25 11:22:41.954 | INFO     | src.policies:train:157 - Total loss: 1.0023388862609863\n",
      "2021-08-25 11:22:41.957 | INFO     | src.policies:train:103 - Epoch 672 / 800\n",
      "2021-08-25 11:22:41.958 | INFO     | src.policies:train:109 - Episode 2537\n",
      "2021-08-25 11:22:42.022 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:42.024 | INFO     | src.policies:train:121 - Mean episode return: 193.0\n",
      "2021-08-25 11:22:42.025 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 169.37\n",
      "2021-08-25 11:22:42.025 | INFO     | src.policies:train:109 - Episode 2538\n",
      "2021-08-25 11:22:42.087 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:42.088 | INFO     | src.policies:train:121 - Mean episode return: 183.0\n",
      "2021-08-25 11:22:42.089 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 169.31\n",
      "2021-08-25 11:22:42.090 | WARNING  | src.policies:train:131 - The actual batch size is 376, instead of 200\n",
      "2021-08-25 11:22:42.096 | INFO     | src.policies:train:157 - Total loss: 1.0026146173477173\n",
      "2021-08-25 11:22:42.099 | INFO     | src.policies:train:103 - Epoch 673 / 800\n",
      "2021-08-25 11:22:42.100 | INFO     | src.policies:train:109 - Episode 2539\n",
      "2021-08-25 11:22:42.150 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:42.152 | INFO     | src.policies:train:121 - Mean episode return: 152.0\n",
      "2021-08-25 11:22:42.153 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 168.96\n",
      "2021-08-25 11:22:42.154 | INFO     | src.policies:train:109 - Episode 2540\n",
      "2021-08-25 11:22:42.202 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:42.203 | INFO     | src.policies:train:121 - Mean episode return: 135.0\n",
      "2021-08-25 11:22:42.204 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 168.53\n",
      "2021-08-25 11:22:42.205 | WARNING  | src.policies:train:131 - The actual batch size is 287, instead of 200\n",
      "2021-08-25 11:22:42.211 | INFO     | src.policies:train:157 - Total loss: 1.0017285346984863\n",
      "2021-08-25 11:22:42.214 | INFO     | src.policies:train:103 - Epoch 674 / 800\n",
      "2021-08-25 11:22:42.215 | INFO     | src.policies:train:109 - Episode 2541\n",
      "2021-08-25 11:22:42.281 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:42.283 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:42.284 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 169.03\n",
      "2021-08-25 11:22:42.289 | INFO     | src.policies:train:157 - Total loss: 1.000186562538147\n",
      "2021-08-25 11:22:42.291 | INFO     | src.policies:train:103 - Epoch 675 / 800\n",
      "2021-08-25 11:22:42.292 | INFO     | src.policies:train:109 - Episode 2542\n",
      "2021-08-25 11:22:42.345 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:42.347 | INFO     | src.policies:train:121 - Mean episode return: 160.0\n",
      "2021-08-25 11:22:42.348 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 169.19\n",
      "2021-08-25 11:22:42.348 | INFO     | src.policies:train:109 - Episode 2543\n",
      "2021-08-25 11:22:42.401 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:42.402 | INFO     | src.policies:train:121 - Mean episode return: 146.0\n",
      "2021-08-25 11:22:42.403 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 169.41\n",
      "2021-08-25 11:22:42.404 | WARNING  | src.policies:train:131 - The actual batch size is 306, instead of 200\n",
      "2021-08-25 11:22:42.410 | INFO     | src.policies:train:157 - Total loss: 1.0020694732666016\n",
      "2021-08-25 11:22:42.413 | INFO     | src.policies:train:103 - Epoch 676 / 800\n",
      "2021-08-25 11:22:42.414 | INFO     | src.policies:train:109 - Episode 2544\n",
      "2021-08-25 11:22:42.470 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:42.472 | INFO     | src.policies:train:121 - Mean episode return: 171.0\n",
      "2021-08-25 11:22:42.473 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 170.0\n",
      "2021-08-25 11:22:42.473 | INFO     | src.policies:train:109 - Episode 2545\n",
      "2021-08-25 11:22:42.542 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:42.543 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:42.544 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 170.0\n",
      "2021-08-25 11:22:42.545 | WARNING  | src.policies:train:131 - The actual batch size is 371, instead of 200\n",
      "2021-08-25 11:22:42.551 | INFO     | src.policies:train:157 - Total loss: 1.0024858713150024\n",
      "2021-08-25 11:22:42.554 | INFO     | src.policies:train:103 - Epoch 677 / 800\n",
      "2021-08-25 11:22:42.555 | INFO     | src.policies:train:109 - Episode 2546\n",
      "2021-08-25 11:22:42.618 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:42.620 | INFO     | src.policies:train:121 - Mean episode return: 181.0\n",
      "2021-08-25 11:22:42.621 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 169.81\n",
      "2021-08-25 11:22:42.622 | INFO     | src.policies:train:109 - Episode 2547\n",
      "2021-08-25 11:22:42.662 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:42.663 | INFO     | src.policies:train:121 - Mean episode return: 113.0\n",
      "2021-08-25 11:22:42.664 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 170.35\n",
      "2021-08-25 11:22:42.665 | WARNING  | src.policies:train:131 - The actual batch size is 294, instead of 200\n",
      "2021-08-25 11:22:42.671 | INFO     | src.policies:train:157 - Total loss: 1.0018012523651123\n",
      "2021-08-25 11:22:42.674 | INFO     | src.policies:train:103 - Epoch 678 / 800\n",
      "2021-08-25 11:22:42.675 | INFO     | src.policies:train:109 - Episode 2548\n",
      "2021-08-25 11:22:42.717 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:42.719 | INFO     | src.policies:train:121 - Mean episode return: 124.0\n",
      "2021-08-25 11:22:42.719 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 170.04\n",
      "2021-08-25 11:22:42.720 | INFO     | src.policies:train:109 - Episode 2549\n",
      "2021-08-25 11:22:42.767 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:42.768 | INFO     | src.policies:train:121 - Mean episode return: 132.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:22:42.769 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 169.37\n",
      "2021-08-25 11:22:42.770 | WARNING  | src.policies:train:131 - The actual batch size is 256, instead of 200\n",
      "2021-08-25 11:22:42.776 | INFO     | src.policies:train:157 - Total loss: 1.0012487173080444\n",
      "2021-08-25 11:22:42.779 | INFO     | src.policies:train:103 - Epoch 679 / 800\n",
      "2021-08-25 11:22:42.780 | INFO     | src.policies:train:109 - Episode 2550\n",
      "2021-08-25 11:22:42.837 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:42.838 | INFO     | src.policies:train:121 - Mean episode return: 166.0\n",
      "2021-08-25 11:22:42.839 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 169.34\n",
      "2021-08-25 11:22:42.840 | INFO     | src.policies:train:109 - Episode 2551\n",
      "2021-08-25 11:22:42.909 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:42.910 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:42.911 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 169.78\n",
      "2021-08-25 11:22:42.912 | WARNING  | src.policies:train:131 - The actual batch size is 366, instead of 200\n",
      "2021-08-25 11:22:42.918 | INFO     | src.policies:train:157 - Total loss: 1.0025947093963623\n",
      "2021-08-25 11:22:42.921 | INFO     | src.policies:train:103 - Epoch 680 / 800\n",
      "2021-08-25 11:22:42.922 | INFO     | src.policies:train:109 - Episode 2552\n",
      "2021-08-25 11:22:42.975 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:42.977 | INFO     | src.policies:train:121 - Mean episode return: 162.0\n",
      "2021-08-25 11:22:42.978 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 169.4\n",
      "2021-08-25 11:22:42.979 | INFO     | src.policies:train:109 - Episode 2553\n",
      "2021-08-25 11:22:43.042 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:43.043 | INFO     | src.policies:train:121 - Mean episode return: 187.0\n",
      "2021-08-25 11:22:43.044 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 170.06\n",
      "2021-08-25 11:22:43.045 | WARNING  | src.policies:train:131 - The actual batch size is 349, instead of 200\n",
      "2021-08-25 11:22:43.051 | INFO     | src.policies:train:157 - Total loss: 1.0024559497833252\n",
      "2021-08-25 11:22:43.054 | INFO     | src.policies:train:103 - Epoch 681 / 800\n",
      "2021-08-25 11:22:43.055 | INFO     | src.policies:train:109 - Episode 2554\n",
      "2021-08-25 11:22:43.103 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:43.105 | INFO     | src.policies:train:121 - Mean episode return: 142.0\n",
      "2021-08-25 11:22:43.106 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 169.48\n",
      "2021-08-25 11:22:43.106 | INFO     | src.policies:train:109 - Episode 2555\n",
      "2021-08-25 11:22:43.167 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:43.169 | INFO     | src.policies:train:121 - Mean episode return: 177.0\n",
      "2021-08-25 11:22:43.170 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 169.7\n",
      "2021-08-25 11:22:43.170 | WARNING  | src.policies:train:131 - The actual batch size is 319, instead of 200\n",
      "2021-08-25 11:22:43.177 | INFO     | src.policies:train:157 - Total loss: 1.0021610260009766\n",
      "2021-08-25 11:22:43.180 | INFO     | src.policies:train:103 - Epoch 682 / 800\n",
      "2021-08-25 11:22:43.182 | INFO     | src.policies:train:109 - Episode 2556\n",
      "2021-08-25 11:22:43.249 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:43.250 | INFO     | src.policies:train:121 - Mean episode return: 199.0\n",
      "2021-08-25 11:22:43.251 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 169.69\n",
      "2021-08-25 11:22:43.252 | INFO     | src.policies:train:109 - Episode 2557\n",
      "2021-08-25 11:22:43.320 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:43.321 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:43.322 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 169.87\n",
      "2021-08-25 11:22:43.323 | WARNING  | src.policies:train:131 - The actual batch size is 399, instead of 200\n",
      "2021-08-25 11:22:43.329 | INFO     | src.policies:train:157 - Total loss: 1.0028712749481201\n",
      "2021-08-25 11:22:43.332 | INFO     | src.policies:train:103 - Epoch 683 / 800\n",
      "2021-08-25 11:22:43.333 | INFO     | src.policies:train:109 - Episode 2558\n",
      "2021-08-25 11:22:43.400 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:43.401 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:43.402 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 169.87\n",
      "2021-08-25 11:22:43.407 | INFO     | src.policies:train:157 - Total loss: 1.0004372596740723\n",
      "2021-08-25 11:22:43.410 | INFO     | src.policies:train:103 - Epoch 684 / 800\n",
      "2021-08-25 11:22:43.411 | INFO     | src.policies:train:109 - Episode 2559\n",
      "2021-08-25 11:22:43.477 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:43.479 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:43.480 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 170.29\n",
      "2021-08-25 11:22:43.485 | INFO     | src.policies:train:157 - Total loss: 1.0003902912139893\n",
      "2021-08-25 11:22:43.487 | INFO     | src.policies:train:103 - Epoch 685 / 800\n",
      "2021-08-25 11:22:43.488 | INFO     | src.policies:train:109 - Episode 2560\n",
      "2021-08-25 11:22:43.556 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:43.557 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:43.558 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 170.48\n",
      "2021-08-25 11:22:43.563 | INFO     | src.policies:train:157 - Total loss: 1.0002543926239014\n",
      "2021-08-25 11:22:43.566 | INFO     | src.policies:train:103 - Epoch 686 / 800\n",
      "2021-08-25 11:22:43.567 | INFO     | src.policies:train:109 - Episode 2561\n",
      "2021-08-25 11:22:43.637 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:43.639 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:43.640 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 171.19\n",
      "2021-08-25 11:22:43.646 | INFO     | src.policies:train:157 - Total loss: 1.0002325773239136\n",
      "2021-08-25 11:22:43.650 | INFO     | src.policies:train:103 - Epoch 687 / 800\n",
      "2021-08-25 11:22:43.651 | INFO     | src.policies:train:109 - Episode 2562\n",
      "2021-08-25 11:22:43.722 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:43.724 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:43.725 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 171.81\n",
      "2021-08-25 11:22:43.731 | INFO     | src.policies:train:157 - Total loss: 1.0002007484436035\n",
      "2021-08-25 11:22:43.735 | INFO     | src.policies:train:103 - Epoch 688 / 800\n",
      "2021-08-25 11:22:43.736 | INFO     | src.policies:train:109 - Episode 2563\n",
      "2021-08-25 11:22:43.790 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:43.791 | INFO     | src.policies:train:121 - Mean episode return: 150.0\n",
      "2021-08-25 11:22:43.792 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 171.52\n",
      "2021-08-25 11:22:43.793 | INFO     | src.policies:train:109 - Episode 2564\n",
      "2021-08-25 11:22:43.860 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:43.861 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:43.862 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.0\n",
      "2021-08-25 11:22:43.863 | WARNING  | src.policies:train:131 - The actual batch size is 350, instead of 200\n",
      "2021-08-25 11:22:43.870 | INFO     | src.policies:train:157 - Total loss: 1.0024837255477905\n",
      "2021-08-25 11:22:43.873 | INFO     | src.policies:train:103 - Epoch 689 / 800\n",
      "2021-08-25 11:22:43.874 | INFO     | src.policies:train:109 - Episode 2565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:22:43.928 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:43.929 | INFO     | src.policies:train:121 - Mean episode return: 165.0\n",
      "2021-08-25 11:22:43.930 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 171.65\n",
      "2021-08-25 11:22:43.931 | INFO     | src.policies:train:109 - Episode 2566\n",
      "2021-08-25 11:22:43.996 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:43.997 | INFO     | src.policies:train:121 - Mean episode return: 187.0\n",
      "2021-08-25 11:22:43.997 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 171.52\n",
      "2021-08-25 11:22:43.999 | WARNING  | src.policies:train:131 - The actual batch size is 352, instead of 200\n",
      "2021-08-25 11:22:44.005 | INFO     | src.policies:train:157 - Total loss: 1.0026627779006958\n",
      "2021-08-25 11:22:44.008 | INFO     | src.policies:train:103 - Epoch 690 / 800\n",
      "2021-08-25 11:22:44.009 | INFO     | src.policies:train:109 - Episode 2567\n",
      "2021-08-25 11:22:44.076 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:44.078 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:44.079 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.0\n",
      "2021-08-25 11:22:44.083 | INFO     | src.policies:train:157 - Total loss: 1.0002745389938354\n",
      "2021-08-25 11:22:44.087 | INFO     | src.policies:train:103 - Epoch 691 / 800\n",
      "2021-08-25 11:22:44.087 | INFO     | src.policies:train:109 - Episode 2568\n",
      "2021-08-25 11:22:44.154 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:44.155 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:44.156 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.66\n",
      "2021-08-25 11:22:44.161 | INFO     | src.policies:train:157 - Total loss: 1.000306487083435\n",
      "2021-08-25 11:22:44.164 | INFO     | src.policies:train:103 - Epoch 692 / 800\n",
      "2021-08-25 11:22:44.165 | INFO     | src.policies:train:109 - Episode 2569\n",
      "2021-08-25 11:22:44.211 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:44.213 | INFO     | src.policies:train:121 - Mean episode return: 133.0\n",
      "2021-08-25 11:22:44.214 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.89\n",
      "2021-08-25 11:22:44.215 | INFO     | src.policies:train:109 - Episode 2570\n",
      "2021-08-25 11:22:44.266 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:44.267 | INFO     | src.policies:train:121 - Mean episode return: 150.0\n",
      "2021-08-25 11:22:44.268 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.98\n",
      "2021-08-25 11:22:44.269 | WARNING  | src.policies:train:131 - The actual batch size is 283, instead of 200\n",
      "2021-08-25 11:22:44.275 | INFO     | src.policies:train:157 - Total loss: 1.0018069744110107\n",
      "2021-08-25 11:22:44.278 | INFO     | src.policies:train:103 - Epoch 693 / 800\n",
      "2021-08-25 11:22:44.279 | INFO     | src.policies:train:109 - Episode 2571\n",
      "2021-08-25 11:22:44.347 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:44.348 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:44.349 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.98\n",
      "2021-08-25 11:22:44.354 | INFO     | src.policies:train:157 - Total loss: 1.0003968477249146\n",
      "2021-08-25 11:22:44.357 | INFO     | src.policies:train:103 - Epoch 694 / 800\n",
      "2021-08-25 11:22:44.358 | INFO     | src.policies:train:109 - Episode 2572\n",
      "2021-08-25 11:22:44.412 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:44.414 | INFO     | src.policies:train:121 - Mean episode return: 163.0\n",
      "2021-08-25 11:22:44.414 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.61\n",
      "2021-08-25 11:22:44.415 | INFO     | src.policies:train:109 - Episode 2573\n",
      "2021-08-25 11:22:44.483 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:44.484 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:44.485 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 173.51\n",
      "2021-08-25 11:22:44.485 | WARNING  | src.policies:train:131 - The actual batch size is 363, instead of 200\n",
      "2021-08-25 11:22:44.491 | INFO     | src.policies:train:157 - Total loss: 1.0026413202285767\n",
      "2021-08-25 11:22:44.494 | INFO     | src.policies:train:103 - Epoch 695 / 800\n",
      "2021-08-25 11:22:44.495 | INFO     | src.policies:train:109 - Episode 2574\n",
      "2021-08-25 11:22:44.563 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:44.564 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:44.565 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 173.51\n",
      "2021-08-25 11:22:44.570 | INFO     | src.policies:train:157 - Total loss: 1.0002176761627197\n",
      "2021-08-25 11:22:44.573 | INFO     | src.policies:train:103 - Epoch 696 / 800\n",
      "2021-08-25 11:22:44.573 | INFO     | src.policies:train:109 - Episode 2575\n",
      "2021-08-25 11:22:44.641 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:44.642 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:44.643 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 173.51\n",
      "2021-08-25 11:22:44.648 | INFO     | src.policies:train:157 - Total loss: 1.0003366470336914\n",
      "2021-08-25 11:22:44.651 | INFO     | src.policies:train:103 - Epoch 697 / 800\n",
      "2021-08-25 11:22:44.652 | INFO     | src.policies:train:109 - Episode 2576\n",
      "2021-08-25 11:22:44.708 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:44.710 | INFO     | src.policies:train:121 - Mean episode return: 166.0\n",
      "2021-08-25 11:22:44.711 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 173.75\n",
      "2021-08-25 11:22:44.712 | INFO     | src.policies:train:109 - Episode 2577\n",
      "2021-08-25 11:22:44.779 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:44.780 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:44.781 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.54\n",
      "2021-08-25 11:22:44.782 | WARNING  | src.policies:train:131 - The actual batch size is 366, instead of 200\n",
      "2021-08-25 11:22:44.788 | INFO     | src.policies:train:157 - Total loss: 1.0026392936706543\n",
      "2021-08-25 11:22:44.790 | INFO     | src.policies:train:103 - Epoch 698 / 800\n",
      "2021-08-25 11:22:44.792 | INFO     | src.policies:train:109 - Episode 2578\n",
      "2021-08-25 11:22:44.858 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:44.860 | INFO     | src.policies:train:121 - Mean episode return: 198.0\n",
      "2021-08-25 11:22:44.861 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.53\n",
      "2021-08-25 11:22:44.862 | INFO     | src.policies:train:109 - Episode 2579\n",
      "2021-08-25 11:22:44.919 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:44.921 | INFO     | src.policies:train:121 - Mean episode return: 166.0\n",
      "2021-08-25 11:22:44.921 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.19\n",
      "2021-08-25 11:22:44.922 | WARNING  | src.policies:train:131 - The actual batch size is 364, instead of 200\n",
      "2021-08-25 11:22:44.928 | INFO     | src.policies:train:157 - Total loss: 1.0027055740356445\n",
      "2021-08-25 11:22:44.931 | INFO     | src.policies:train:103 - Epoch 699 / 800\n",
      "2021-08-25 11:22:44.933 | INFO     | src.policies:train:109 - Episode 2580\n",
      "2021-08-25 11:22:45.001 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:45.003 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:45.004 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.85\n",
      "2021-08-25 11:22:45.008 | INFO     | src.policies:train:157 - Total loss: 1.0003538131713867\n",
      "2021-08-25 11:22:45.011 | INFO     | src.policies:train:103 - Epoch 700 / 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:22:45.012 | INFO     | src.policies:train:109 - Episode 2581\n",
      "2021-08-25 11:22:45.080 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:45.082 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:45.082 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.29\n",
      "2021-08-25 11:22:45.087 | INFO     | src.policies:train:157 - Total loss: 1.0000466108322144\n",
      "2021-08-25 11:22:45.090 | INFO     | src.policies:train:103 - Epoch 701 / 800\n",
      "2021-08-25 11:22:45.091 | INFO     | src.policies:train:109 - Episode 2582\n",
      "2021-08-25 11:22:45.156 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:45.158 | INFO     | src.policies:train:121 - Mean episode return: 195.0\n",
      "2021-08-25 11:22:45.159 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.24\n",
      "2021-08-25 11:22:45.159 | INFO     | src.policies:train:109 - Episode 2583\n",
      "2021-08-25 11:22:45.210 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:45.211 | INFO     | src.policies:train:121 - Mean episode return: 142.0\n",
      "2021-08-25 11:22:45.212 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.27\n",
      "2021-08-25 11:22:45.213 | WARNING  | src.policies:train:131 - The actual batch size is 337, instead of 200\n",
      "2021-08-25 11:22:45.219 | INFO     | src.policies:train:157 - Total loss: 1.0024904012680054\n",
      "2021-08-25 11:22:45.222 | INFO     | src.policies:train:103 - Epoch 702 / 800\n",
      "2021-08-25 11:22:45.223 | INFO     | src.policies:train:109 - Episode 2584\n",
      "2021-08-25 11:22:45.282 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:45.284 | INFO     | src.policies:train:121 - Mean episode return: 177.0\n",
      "2021-08-25 11:22:45.285 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.16\n",
      "2021-08-25 11:22:45.285 | INFO     | src.policies:train:109 - Episode 2585\n",
      "2021-08-25 11:22:45.356 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:45.357 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:45.358 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.16\n",
      "2021-08-25 11:22:45.359 | WARNING  | src.policies:train:131 - The actual batch size is 377, instead of 200\n",
      "2021-08-25 11:22:45.365 | INFO     | src.policies:train:157 - Total loss: 1.0027415752410889\n",
      "2021-08-25 11:22:45.368 | INFO     | src.policies:train:103 - Epoch 703 / 800\n",
      "2021-08-25 11:22:45.369 | INFO     | src.policies:train:109 - Episode 2586\n",
      "2021-08-25 11:22:45.411 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:45.412 | INFO     | src.policies:train:121 - Mean episode return: 120.0\n",
      "2021-08-25 11:22:45.414 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.36\n",
      "2021-08-25 11:22:45.414 | INFO     | src.policies:train:109 - Episode 2587\n",
      "2021-08-25 11:22:45.482 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:45.483 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:45.484 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.36\n",
      "2021-08-25 11:22:45.485 | WARNING  | src.policies:train:131 - The actual batch size is 320, instead of 200\n",
      "2021-08-25 11:22:45.491 | INFO     | src.policies:train:157 - Total loss: 1.0022560358047485\n",
      "2021-08-25 11:22:45.494 | INFO     | src.policies:train:103 - Epoch 704 / 800\n",
      "2021-08-25 11:22:45.495 | INFO     | src.policies:train:109 - Episode 2588\n",
      "2021-08-25 11:22:45.560 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:45.562 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:45.563 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.45\n",
      "2021-08-25 11:22:45.568 | INFO     | src.policies:train:157 - Total loss: 1.000317096710205\n",
      "2021-08-25 11:22:45.571 | INFO     | src.policies:train:103 - Epoch 705 / 800\n",
      "2021-08-25 11:22:45.572 | INFO     | src.policies:train:109 - Episode 2589\n",
      "2021-08-25 11:22:45.641 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:45.642 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:45.643 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.45\n",
      "2021-08-25 11:22:45.648 | INFO     | src.policies:train:157 - Total loss: 1.0003315210342407\n",
      "2021-08-25 11:22:45.651 | INFO     | src.policies:train:103 - Epoch 706 / 800\n",
      "2021-08-25 11:22:45.652 | INFO     | src.policies:train:109 - Episode 2590\n",
      "2021-08-25 11:22:45.719 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:45.720 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:45.721 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.59\n",
      "2021-08-25 11:22:45.727 | INFO     | src.policies:train:157 - Total loss: 1.0003807544708252\n",
      "2021-08-25 11:22:45.729 | INFO     | src.policies:train:103 - Epoch 707 / 800\n",
      "2021-08-25 11:22:45.730 | INFO     | src.policies:train:109 - Episode 2591\n",
      "2021-08-25 11:22:45.783 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:45.784 | INFO     | src.policies:train:121 - Mean episode return: 150.0\n",
      "2021-08-25 11:22:45.785 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.3\n",
      "2021-08-25 11:22:45.786 | INFO     | src.policies:train:109 - Episode 2592\n",
      "2021-08-25 11:22:45.842 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:45.843 | INFO     | src.policies:train:121 - Mean episode return: 165.0\n",
      "2021-08-25 11:22:45.844 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.04\n",
      "2021-08-25 11:22:45.845 | WARNING  | src.policies:train:131 - The actual batch size is 315, instead of 200\n",
      "2021-08-25 11:22:45.852 | INFO     | src.policies:train:157 - Total loss: 1.0021129846572876\n",
      "2021-08-25 11:22:45.855 | INFO     | src.policies:train:103 - Epoch 708 / 800\n",
      "2021-08-25 11:22:45.856 | INFO     | src.policies:train:109 - Episode 2593\n",
      "2021-08-25 11:22:45.905 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:45.906 | INFO     | src.policies:train:121 - Mean episode return: 142.0\n",
      "2021-08-25 11:22:45.907 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 173.46\n",
      "2021-08-25 11:22:45.908 | INFO     | src.policies:train:109 - Episode 2594\n",
      "2021-08-25 11:22:45.979 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:45.980 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:45.981 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 173.72\n",
      "2021-08-25 11:22:45.982 | WARNING  | src.policies:train:131 - The actual batch size is 342, instead of 200\n",
      "2021-08-25 11:22:45.988 | INFO     | src.policies:train:157 - Total loss: 1.002458095550537\n",
      "2021-08-25 11:22:45.991 | INFO     | src.policies:train:103 - Epoch 709 / 800\n",
      "2021-08-25 11:22:45.992 | INFO     | src.policies:train:109 - Episode 2595\n",
      "2021-08-25 11:22:46.050 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:46.052 | INFO     | src.policies:train:121 - Mean episode return: 172.0\n",
      "2021-08-25 11:22:46.053 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 173.9\n",
      "2021-08-25 11:22:46.054 | INFO     | src.policies:train:109 - Episode 2596\n",
      "2021-08-25 11:22:46.117 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:46.119 | INFO     | src.policies:train:121 - Mean episode return: 177.0\n",
      "2021-08-25 11:22:46.119 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 173.67\n",
      "2021-08-25 11:22:46.120 | WARNING  | src.policies:train:131 - The actual batch size is 349, instead of 200\n",
      "2021-08-25 11:22:46.127 | INFO     | src.policies:train:157 - Total loss: 1.0026798248291016\n",
      "2021-08-25 11:22:46.130 | INFO     | src.policies:train:103 - Epoch 710 / 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:22:46.131 | INFO     | src.policies:train:109 - Episode 2597\n",
      "2021-08-25 11:22:46.185 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:46.187 | INFO     | src.policies:train:121 - Mean episode return: 144.0\n",
      "2021-08-25 11:22:46.188 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 173.35\n",
      "2021-08-25 11:22:46.189 | INFO     | src.policies:train:109 - Episode 2598\n",
      "2021-08-25 11:22:46.249 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:46.251 | INFO     | src.policies:train:121 - Mean episode return: 163.0\n",
      "2021-08-25 11:22:46.252 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 173.68\n",
      "2021-08-25 11:22:46.253 | WARNING  | src.policies:train:131 - The actual batch size is 307, instead of 200\n",
      "2021-08-25 11:22:46.262 | INFO     | src.policies:train:157 - Total loss: 1.0021368265151978\n",
      "2021-08-25 11:22:46.265 | INFO     | src.policies:train:103 - Epoch 711 / 800\n",
      "2021-08-25 11:22:46.266 | INFO     | src.policies:train:109 - Episode 2599\n",
      "2021-08-25 11:22:46.337 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:46.339 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:46.340 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 173.68\n",
      "2021-08-25 11:22:46.345 | INFO     | src.policies:train:157 - Total loss: 1.000218152999878\n",
      "2021-08-25 11:22:46.349 | INFO     | src.policies:train:103 - Epoch 712 / 800\n",
      "2021-08-25 11:22:46.350 | INFO     | src.policies:train:109 - Episode 2600\n",
      "2021-08-25 11:22:46.420 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:46.422 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:46.423 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 173.91\n",
      "2021-08-25 11:22:46.428 | INFO     | src.policies:train:157 - Total loss: 1.0003894567489624\n",
      "2021-08-25 11:22:46.431 | INFO     | src.policies:train:103 - Epoch 713 / 800\n",
      "2021-08-25 11:22:46.432 | INFO     | src.policies:train:109 - Episode 2601\n",
      "2021-08-25 11:22:46.485 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:46.487 | INFO     | src.policies:train:121 - Mean episode return: 148.0\n",
      "2021-08-25 11:22:46.488 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 173.39\n",
      "2021-08-25 11:22:46.488 | INFO     | src.policies:train:109 - Episode 2602\n",
      "2021-08-25 11:22:46.560 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:46.561 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:46.562 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 173.56\n",
      "2021-08-25 11:22:46.563 | WARNING  | src.policies:train:131 - The actual batch size is 348, instead of 200\n",
      "2021-08-25 11:22:46.571 | INFO     | src.policies:train:157 - Total loss: 1.002370834350586\n",
      "2021-08-25 11:22:46.574 | INFO     | src.policies:train:103 - Epoch 714 / 800\n",
      "2021-08-25 11:22:46.576 | INFO     | src.policies:train:109 - Episode 2603\n",
      "2021-08-25 11:22:46.645 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:46.647 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:46.648 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 173.56\n",
      "2021-08-25 11:22:46.653 | INFO     | src.policies:train:157 - Total loss: 1.0004005432128906\n",
      "2021-08-25 11:22:46.656 | INFO     | src.policies:train:103 - Epoch 715 / 800\n",
      "2021-08-25 11:22:46.656 | INFO     | src.policies:train:109 - Episode 2604\n",
      "2021-08-25 11:22:46.720 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:46.722 | INFO     | src.policies:train:121 - Mean episode return: 183.0\n",
      "2021-08-25 11:22:46.723 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.08\n",
      "2021-08-25 11:22:46.724 | INFO     | src.policies:train:109 - Episode 2605\n",
      "2021-08-25 11:22:46.794 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:46.795 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:46.796 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.4\n",
      "2021-08-25 11:22:46.797 | WARNING  | src.policies:train:131 - The actual batch size is 383, instead of 200\n",
      "2021-08-25 11:22:46.804 | INFO     | src.policies:train:157 - Total loss: 1.002801537513733\n",
      "2021-08-25 11:22:46.808 | INFO     | src.policies:train:103 - Epoch 716 / 800\n",
      "2021-08-25 11:22:46.809 | INFO     | src.policies:train:109 - Episode 2606\n",
      "2021-08-25 11:22:46.856 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:46.858 | INFO     | src.policies:train:121 - Mean episode return: 134.0\n",
      "2021-08-25 11:22:46.859 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.31\n",
      "2021-08-25 11:22:46.860 | INFO     | src.policies:train:109 - Episode 2607\n",
      "2021-08-25 11:22:46.927 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:46.928 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:46.929 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.31\n",
      "2021-08-25 11:22:46.931 | WARNING  | src.policies:train:131 - The actual batch size is 334, instead of 200\n",
      "2021-08-25 11:22:46.938 | INFO     | src.policies:train:157 - Total loss: 1.0024954080581665\n",
      "2021-08-25 11:22:46.942 | INFO     | src.policies:train:103 - Epoch 717 / 800\n",
      "2021-08-25 11:22:46.943 | INFO     | src.policies:train:109 - Episode 2608\n",
      "2021-08-25 11:22:46.990 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:46.992 | INFO     | src.policies:train:121 - Mean episode return: 133.0\n",
      "2021-08-25 11:22:46.993 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.34\n",
      "2021-08-25 11:22:46.994 | INFO     | src.policies:train:109 - Episode 2609\n",
      "2021-08-25 11:22:47.067 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:47.069 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:47.069 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.13\n",
      "2021-08-25 11:22:47.071 | WARNING  | src.policies:train:131 - The actual batch size is 333, instead of 200\n",
      "2021-08-25 11:22:47.078 | INFO     | src.policies:train:157 - Total loss: 1.0023857355117798\n",
      "2021-08-25 11:22:47.083 | INFO     | src.policies:train:103 - Epoch 718 / 800\n",
      "2021-08-25 11:22:47.084 | INFO     | src.policies:train:109 - Episode 2610\n",
      "2021-08-25 11:22:47.136 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:47.137 | INFO     | src.policies:train:121 - Mean episode return: 144.0\n",
      "2021-08-25 11:22:47.138 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.86\n",
      "2021-08-25 11:22:47.139 | INFO     | src.policies:train:109 - Episode 2611\n",
      "2021-08-25 11:22:47.196 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:47.197 | INFO     | src.policies:train:121 - Mean episode return: 158.0\n",
      "2021-08-25 11:22:47.198 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.44\n",
      "2021-08-25 11:22:47.198 | WARNING  | src.policies:train:131 - The actual batch size is 302, instead of 200\n",
      "2021-08-25 11:22:47.206 | INFO     | src.policies:train:157 - Total loss: 1.0020705461502075\n",
      "2021-08-25 11:22:47.209 | INFO     | src.policies:train:103 - Epoch 719 / 800\n",
      "2021-08-25 11:22:47.210 | INFO     | src.policies:train:109 - Episode 2612\n",
      "2021-08-25 11:22:47.281 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:47.282 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:47.284 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.28\n",
      "2021-08-25 11:22:47.290 | INFO     | src.policies:train:157 - Total loss: 1.0005056858062744\n",
      "2021-08-25 11:22:47.293 | INFO     | src.policies:train:103 - Epoch 720 / 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:22:47.294 | INFO     | src.policies:train:109 - Episode 2613\n",
      "2021-08-25 11:22:47.363 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:47.364 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:47.365 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.28\n",
      "2021-08-25 11:22:47.370 | INFO     | src.policies:train:157 - Total loss: 1.0002535581588745\n",
      "2021-08-25 11:22:47.373 | INFO     | src.policies:train:103 - Epoch 721 / 800\n",
      "2021-08-25 11:22:47.373 | INFO     | src.policies:train:109 - Episode 2614\n",
      "2021-08-25 11:22:47.420 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:47.421 | INFO     | src.policies:train:121 - Mean episode return: 131.0\n",
      "2021-08-25 11:22:47.422 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.88\n",
      "2021-08-25 11:22:47.423 | INFO     | src.policies:train:109 - Episode 2615\n",
      "2021-08-25 11:22:47.465 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:47.466 | INFO     | src.policies:train:121 - Mean episode return: 109.0\n",
      "2021-08-25 11:22:47.468 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.18\n",
      "2021-08-25 11:22:47.469 | WARNING  | src.policies:train:131 - The actual batch size is 240, instead of 200\n",
      "2021-08-25 11:22:47.476 | INFO     | src.policies:train:157 - Total loss: 1.0012261867523193\n",
      "2021-08-25 11:22:47.480 | INFO     | src.policies:train:103 - Epoch 722 / 800\n",
      "2021-08-25 11:22:47.481 | INFO     | src.policies:train:109 - Episode 2616\n",
      "2021-08-25 11:22:47.550 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:47.551 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:47.552 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.58\n",
      "2021-08-25 11:22:47.558 | INFO     | src.policies:train:157 - Total loss: 1.0004737377166748\n",
      "2021-08-25 11:22:47.562 | INFO     | src.policies:train:103 - Epoch 723 / 800\n",
      "2021-08-25 11:22:47.563 | INFO     | src.policies:train:109 - Episode 2617\n",
      "2021-08-25 11:22:47.619 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:47.621 | INFO     | src.policies:train:121 - Mean episode return: 162.0\n",
      "2021-08-25 11:22:47.622 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.2\n",
      "2021-08-25 11:22:47.623 | INFO     | src.policies:train:109 - Episode 2618\n",
      "2021-08-25 11:22:47.687 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:47.688 | INFO     | src.policies:train:121 - Mean episode return: 186.0\n",
      "2021-08-25 11:22:47.689 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.81\n",
      "2021-08-25 11:22:47.690 | WARNING  | src.policies:train:131 - The actual batch size is 348, instead of 200\n",
      "2021-08-25 11:22:47.696 | INFO     | src.policies:train:157 - Total loss: 1.002569317817688\n",
      "2021-08-25 11:22:47.699 | INFO     | src.policies:train:103 - Epoch 724 / 800\n",
      "2021-08-25 11:22:47.700 | INFO     | src.policies:train:109 - Episode 2619\n",
      "2021-08-25 11:22:47.752 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:47.754 | INFO     | src.policies:train:121 - Mean episode return: 157.0\n",
      "2021-08-25 11:22:47.755 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.5\n",
      "2021-08-25 11:22:47.755 | INFO     | src.policies:train:109 - Episode 2620\n",
      "2021-08-25 11:22:47.823 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:47.824 | INFO     | src.policies:train:121 - Mean episode return: 197.0\n",
      "2021-08-25 11:22:47.825 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.47\n",
      "2021-08-25 11:22:47.826 | WARNING  | src.policies:train:131 - The actual batch size is 354, instead of 200\n",
      "2021-08-25 11:22:47.832 | INFO     | src.policies:train:157 - Total loss: 1.0025156736373901\n",
      "2021-08-25 11:22:47.835 | INFO     | src.policies:train:103 - Epoch 725 / 800\n",
      "2021-08-25 11:22:47.836 | INFO     | src.policies:train:109 - Episode 2621\n",
      "2021-08-25 11:22:47.883 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:47.885 | INFO     | src.policies:train:121 - Mean episode return: 139.0\n",
      "2021-08-25 11:22:47.886 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 173.86\n",
      "2021-08-25 11:22:47.887 | INFO     | src.policies:train:109 - Episode 2622\n",
      "2021-08-25 11:22:47.955 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:47.957 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:47.958 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 173.86\n",
      "2021-08-25 11:22:47.958 | WARNING  | src.policies:train:131 - The actual batch size is 339, instead of 200\n",
      "2021-08-25 11:22:47.964 | INFO     | src.policies:train:157 - Total loss: 1.0024155378341675\n",
      "2021-08-25 11:22:47.967 | INFO     | src.policies:train:103 - Epoch 726 / 800\n",
      "2021-08-25 11:22:47.968 | INFO     | src.policies:train:109 - Episode 2623\n",
      "2021-08-25 11:22:48.036 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:48.038 | INFO     | src.policies:train:121 - Mean episode return: 196.0\n",
      "2021-08-25 11:22:48.039 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.21\n",
      "2021-08-25 11:22:48.040 | INFO     | src.policies:train:109 - Episode 2624\n",
      "2021-08-25 11:22:48.103 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:48.104 | INFO     | src.policies:train:121 - Mean episode return: 179.0\n",
      "2021-08-25 11:22:48.105 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.2\n",
      "2021-08-25 11:22:48.106 | WARNING  | src.policies:train:131 - The actual batch size is 375, instead of 200\n",
      "2021-08-25 11:22:48.112 | INFO     | src.policies:train:157 - Total loss: 1.0028332471847534\n",
      "2021-08-25 11:22:48.115 | INFO     | src.policies:train:103 - Epoch 727 / 800\n",
      "2021-08-25 11:22:48.116 | INFO     | src.policies:train:109 - Episode 2625\n",
      "2021-08-25 11:22:48.186 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:48.187 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:48.188 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.43\n",
      "2021-08-25 11:22:48.193 | INFO     | src.policies:train:157 - Total loss: 1.0004342794418335\n",
      "2021-08-25 11:22:48.196 | INFO     | src.policies:train:103 - Epoch 728 / 800\n",
      "2021-08-25 11:22:48.197 | INFO     | src.policies:train:109 - Episode 2626\n",
      "2021-08-25 11:22:48.263 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:48.265 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:48.266 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.08\n",
      "2021-08-25 11:22:48.271 | INFO     | src.policies:train:157 - Total loss: 1.0002039670944214\n",
      "2021-08-25 11:22:48.274 | INFO     | src.policies:train:103 - Epoch 729 / 800\n",
      "2021-08-25 11:22:48.275 | INFO     | src.policies:train:109 - Episode 2627\n",
      "2021-08-25 11:22:48.331 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:48.333 | INFO     | src.policies:train:121 - Mean episode return: 166.0\n",
      "2021-08-25 11:22:48.334 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.48\n",
      "2021-08-25 11:22:48.334 | INFO     | src.policies:train:109 - Episode 2628\n",
      "2021-08-25 11:22:48.399 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:48.400 | INFO     | src.policies:train:121 - Mean episode return: 191.0\n",
      "2021-08-25 11:22:48.401 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.39\n",
      "2021-08-25 11:22:48.402 | WARNING  | src.policies:train:131 - The actual batch size is 357, instead of 200\n",
      "2021-08-25 11:22:48.408 | INFO     | src.policies:train:157 - Total loss: 1.0026534795761108\n",
      "2021-08-25 11:22:48.410 | INFO     | src.policies:train:103 - Epoch 730 / 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:22:48.411 | INFO     | src.policies:train:109 - Episode 2629\n",
      "2021-08-25 11:22:48.480 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:48.482 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:48.483 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.63\n",
      "2021-08-25 11:22:48.487 | INFO     | src.policies:train:157 - Total loss: 1.000393033027649\n",
      "2021-08-25 11:22:48.491 | INFO     | src.policies:train:103 - Epoch 731 / 800\n",
      "2021-08-25 11:22:48.492 | INFO     | src.policies:train:109 - Episode 2630\n",
      "2021-08-25 11:22:48.554 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:48.555 | INFO     | src.policies:train:121 - Mean episode return: 185.0\n",
      "2021-08-25 11:22:48.556 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.48\n",
      "2021-08-25 11:22:48.557 | INFO     | src.policies:train:109 - Episode 2631\n",
      "2021-08-25 11:22:48.617 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:48.618 | INFO     | src.policies:train:121 - Mean episode return: 177.0\n",
      "2021-08-25 11:22:48.619 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.73\n",
      "2021-08-25 11:22:48.620 | WARNING  | src.policies:train:131 - The actual batch size is 362, instead of 200\n",
      "2021-08-25 11:22:48.626 | INFO     | src.policies:train:157 - Total loss: 1.0026512145996094\n",
      "2021-08-25 11:22:48.629 | INFO     | src.policies:train:103 - Epoch 732 / 800\n",
      "2021-08-25 11:22:48.630 | INFO     | src.policies:train:109 - Episode 2632\n",
      "2021-08-25 11:22:48.684 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:48.686 | INFO     | src.policies:train:121 - Mean episode return: 156.0\n",
      "2021-08-25 11:22:48.687 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.93\n",
      "2021-08-25 11:22:48.688 | INFO     | src.policies:train:109 - Episode 2633\n",
      "2021-08-25 11:22:48.737 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:48.738 | INFO     | src.policies:train:121 - Mean episode return: 141.0\n",
      "2021-08-25 11:22:48.739 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.96\n",
      "2021-08-25 11:22:48.740 | WARNING  | src.policies:train:131 - The actual batch size is 297, instead of 200\n",
      "2021-08-25 11:22:48.746 | INFO     | src.policies:train:157 - Total loss: 1.002105474472046\n",
      "2021-08-25 11:22:48.749 | INFO     | src.policies:train:103 - Epoch 733 / 800\n",
      "2021-08-25 11:22:48.750 | INFO     | src.policies:train:109 - Episode 2634\n",
      "2021-08-25 11:22:48.817 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:48.818 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:48.819 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.44\n",
      "2021-08-25 11:22:48.824 | INFO     | src.policies:train:157 - Total loss: 1.0004000663757324\n",
      "2021-08-25 11:22:48.827 | INFO     | src.policies:train:103 - Epoch 734 / 800\n",
      "2021-08-25 11:22:48.828 | INFO     | src.policies:train:109 - Episode 2635\n",
      "2021-08-25 11:22:48.885 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:48.886 | INFO     | src.policies:train:121 - Mean episode return: 172.0\n",
      "2021-08-25 11:22:48.887 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.34\n",
      "2021-08-25 11:22:48.888 | INFO     | src.policies:train:109 - Episode 2636\n",
      "2021-08-25 11:22:48.957 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:48.958 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:48.959 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.92\n",
      "2021-08-25 11:22:48.960 | WARNING  | src.policies:train:131 - The actual batch size is 372, instead of 200\n",
      "2021-08-25 11:22:48.966 | INFO     | src.policies:train:157 - Total loss: 1.0026544332504272\n",
      "2021-08-25 11:22:48.969 | INFO     | src.policies:train:103 - Epoch 735 / 800\n",
      "2021-08-25 11:22:48.970 | INFO     | src.policies:train:109 - Episode 2637\n",
      "2021-08-25 11:22:49.038 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:49.040 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:49.041 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.99\n",
      "2021-08-25 11:22:49.046 | INFO     | src.policies:train:157 - Total loss: 1.000415563583374\n",
      "2021-08-25 11:22:49.049 | INFO     | src.policies:train:103 - Epoch 736 / 800\n",
      "2021-08-25 11:22:49.050 | INFO     | src.policies:train:109 - Episode 2638\n",
      "2021-08-25 11:22:49.117 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:49.118 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:49.119 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 177.16\n",
      "2021-08-25 11:22:49.124 | INFO     | src.policies:train:157 - Total loss: 1.0003694295883179\n",
      "2021-08-25 11:22:49.127 | INFO     | src.policies:train:103 - Epoch 737 / 800\n",
      "2021-08-25 11:22:49.128 | INFO     | src.policies:train:109 - Episode 2639\n",
      "2021-08-25 11:22:49.172 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:49.174 | INFO     | src.policies:train:121 - Mean episode return: 127.0\n",
      "2021-08-25 11:22:49.175 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.91\n",
      "2021-08-25 11:22:49.175 | INFO     | src.policies:train:109 - Episode 2640\n",
      "2021-08-25 11:22:49.216 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:49.218 | INFO     | src.policies:train:121 - Mean episode return: 121.0\n",
      "2021-08-25 11:22:49.219 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.77\n",
      "2021-08-25 11:22:49.219 | WARNING  | src.policies:train:131 - The actual batch size is 248, instead of 200\n",
      "2021-08-25 11:22:49.225 | INFO     | src.policies:train:157 - Total loss: 1.0014545917510986\n",
      "2021-08-25 11:22:49.228 | INFO     | src.policies:train:103 - Epoch 738 / 800\n",
      "2021-08-25 11:22:49.229 | INFO     | src.policies:train:109 - Episode 2641\n",
      "2021-08-25 11:22:49.282 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:49.283 | INFO     | src.policies:train:121 - Mean episode return: 150.0\n",
      "2021-08-25 11:22:49.284 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.27\n",
      "2021-08-25 11:22:49.285 | INFO     | src.policies:train:109 - Episode 2642\n",
      "2021-08-25 11:22:49.341 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:49.342 | INFO     | src.policies:train:121 - Mean episode return: 156.0\n",
      "2021-08-25 11:22:49.343 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.23\n",
      "2021-08-25 11:22:49.344 | WARNING  | src.policies:train:131 - The actual batch size is 306, instead of 200\n",
      "2021-08-25 11:22:49.350 | INFO     | src.policies:train:157 - Total loss: 1.0023114681243896\n",
      "2021-08-25 11:22:49.353 | INFO     | src.policies:train:103 - Epoch 739 / 800\n",
      "2021-08-25 11:22:49.354 | INFO     | src.policies:train:109 - Episode 2643\n",
      "2021-08-25 11:22:49.422 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:49.423 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:49.424 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.77\n",
      "2021-08-25 11:22:49.429 | INFO     | src.policies:train:157 - Total loss: 1.000436544418335\n",
      "2021-08-25 11:22:49.431 | INFO     | src.policies:train:103 - Epoch 740 / 800\n",
      "2021-08-25 11:22:49.432 | INFO     | src.policies:train:109 - Episode 2644\n",
      "2021-08-25 11:22:49.478 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:49.480 | INFO     | src.policies:train:121 - Mean episode return: 135.0\n",
      "2021-08-25 11:22:49.481 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.41\n",
      "2021-08-25 11:22:49.481 | INFO     | src.policies:train:109 - Episode 2645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:22:49.534 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:49.535 | INFO     | src.policies:train:121 - Mean episode return: 149.0\n",
      "2021-08-25 11:22:49.536 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.9\n",
      "2021-08-25 11:22:49.537 | WARNING  | src.policies:train:131 - The actual batch size is 284, instead of 200\n",
      "2021-08-25 11:22:49.543 | INFO     | src.policies:train:157 - Total loss: 1.0019237995147705\n",
      "2021-08-25 11:22:49.546 | INFO     | src.policies:train:103 - Epoch 741 / 800\n",
      "2021-08-25 11:22:49.547 | INFO     | src.policies:train:109 - Episode 2646\n",
      "2021-08-25 11:22:49.611 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:49.612 | INFO     | src.policies:train:121 - Mean episode return: 184.0\n",
      "2021-08-25 11:22:49.613 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.93\n",
      "2021-08-25 11:22:49.614 | INFO     | src.policies:train:109 - Episode 2647\n",
      "2021-08-25 11:22:49.658 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:49.659 | INFO     | src.policies:train:121 - Mean episode return: 118.0\n",
      "2021-08-25 11:22:49.660 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.98\n",
      "2021-08-25 11:22:49.661 | WARNING  | src.policies:train:131 - The actual batch size is 302, instead of 200\n",
      "2021-08-25 11:22:49.667 | INFO     | src.policies:train:157 - Total loss: 1.002393126487732\n",
      "2021-08-25 11:22:49.670 | INFO     | src.policies:train:103 - Epoch 742 / 800\n",
      "2021-08-25 11:22:49.671 | INFO     | src.policies:train:109 - Episode 2648\n",
      "2021-08-25 11:22:49.722 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:49.724 | INFO     | src.policies:train:121 - Mean episode return: 152.0\n",
      "2021-08-25 11:22:49.725 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.26\n",
      "2021-08-25 11:22:49.725 | INFO     | src.policies:train:109 - Episode 2649\n",
      "2021-08-25 11:22:49.796 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:49.797 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:49.797 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.94\n",
      "2021-08-25 11:22:49.798 | WARNING  | src.policies:train:131 - The actual batch size is 352, instead of 200\n",
      "2021-08-25 11:22:49.805 | INFO     | src.policies:train:157 - Total loss: 1.0028187036514282\n",
      "2021-08-25 11:22:49.808 | INFO     | src.policies:train:103 - Epoch 743 / 800\n",
      "2021-08-25 11:22:49.809 | INFO     | src.policies:train:109 - Episode 2650\n",
      "2021-08-25 11:22:49.848 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:49.850 | INFO     | src.policies:train:121 - Mean episode return: 115.0\n",
      "2021-08-25 11:22:49.851 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.43\n",
      "2021-08-25 11:22:49.852 | INFO     | src.policies:train:109 - Episode 2651\n",
      "2021-08-25 11:22:49.919 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:49.920 | INFO     | src.policies:train:121 - Mean episode return: 197.0\n",
      "2021-08-25 11:22:49.921 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.4\n",
      "2021-08-25 11:22:49.922 | WARNING  | src.policies:train:131 - The actual batch size is 312, instead of 200\n",
      "2021-08-25 11:22:49.928 | INFO     | src.policies:train:157 - Total loss: 1.0022629499435425\n",
      "2021-08-25 11:22:49.931 | INFO     | src.policies:train:103 - Epoch 744 / 800\n",
      "2021-08-25 11:22:49.931 | INFO     | src.policies:train:109 - Episode 2652\n",
      "2021-08-25 11:22:49.997 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:49.998 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:49.999 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.78\n",
      "2021-08-25 11:22:50.005 | INFO     | src.policies:train:157 - Total loss: 1.0003193616867065\n",
      "2021-08-25 11:22:50.008 | INFO     | src.policies:train:103 - Epoch 745 / 800\n",
      "2021-08-25 11:22:50.008 | INFO     | src.policies:train:109 - Episode 2653\n",
      "2021-08-25 11:22:50.079 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:50.080 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:50.081 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.91\n",
      "2021-08-25 11:22:50.086 | INFO     | src.policies:train:157 - Total loss: 1.0005323886871338\n",
      "2021-08-25 11:22:50.089 | INFO     | src.policies:train:103 - Epoch 746 / 800\n",
      "2021-08-25 11:22:50.090 | INFO     | src.policies:train:109 - Episode 2654\n",
      "2021-08-25 11:22:50.135 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:50.136 | INFO     | src.policies:train:121 - Mean episode return: 129.0\n",
      "2021-08-25 11:22:50.137 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.78\n",
      "2021-08-25 11:22:50.138 | INFO     | src.policies:train:109 - Episode 2655\n",
      "2021-08-25 11:22:50.190 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:50.191 | INFO     | src.policies:train:121 - Mean episode return: 148.0\n",
      "2021-08-25 11:22:50.192 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.49\n",
      "2021-08-25 11:22:50.193 | WARNING  | src.policies:train:131 - The actual batch size is 277, instead of 200\n",
      "2021-08-25 11:22:50.198 | INFO     | src.policies:train:157 - Total loss: 1.0019291639328003\n",
      "2021-08-25 11:22:50.202 | INFO     | src.policies:train:103 - Epoch 747 / 800\n",
      "2021-08-25 11:22:50.203 | INFO     | src.policies:train:109 - Episode 2656\n",
      "2021-08-25 11:22:50.246 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:50.247 | INFO     | src.policies:train:121 - Mean episode return: 129.0\n",
      "2021-08-25 11:22:50.248 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.79\n",
      "2021-08-25 11:22:50.249 | INFO     | src.policies:train:109 - Episode 2657\n",
      "2021-08-25 11:22:50.302 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:50.303 | INFO     | src.policies:train:121 - Mean episode return: 151.0\n",
      "2021-08-25 11:22:50.303 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.3\n",
      "2021-08-25 11:22:50.304 | WARNING  | src.policies:train:131 - The actual batch size is 280, instead of 200\n",
      "2021-08-25 11:22:50.310 | INFO     | src.policies:train:157 - Total loss: 1.0017554759979248\n",
      "2021-08-25 11:22:50.313 | INFO     | src.policies:train:103 - Epoch 748 / 800\n",
      "2021-08-25 11:22:50.314 | INFO     | src.policies:train:109 - Episode 2658\n",
      "2021-08-25 11:22:50.380 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:50.382 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:50.382 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.3\n",
      "2021-08-25 11:22:50.388 | INFO     | src.policies:train:157 - Total loss: 1.000339150428772\n",
      "2021-08-25 11:22:50.391 | INFO     | src.policies:train:103 - Epoch 749 / 800\n",
      "2021-08-25 11:22:50.392 | INFO     | src.policies:train:109 - Episode 2659\n",
      "2021-08-25 11:22:50.458 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:50.460 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:50.461 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.3\n",
      "2021-08-25 11:22:50.466 | INFO     | src.policies:train:157 - Total loss: 1.0005336999893188\n",
      "2021-08-25 11:22:50.469 | INFO     | src.policies:train:103 - Epoch 750 / 800\n",
      "2021-08-25 11:22:50.469 | INFO     | src.policies:train:109 - Episode 2660\n",
      "2021-08-25 11:22:50.537 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:50.539 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:50.540 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.3\n",
      "2021-08-25 11:22:50.544 | INFO     | src.policies:train:157 - Total loss: 1.0005866289138794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:22:50.547 | INFO     | src.policies:train:103 - Epoch 751 / 800\n",
      "2021-08-25 11:22:50.548 | INFO     | src.policies:train:109 - Episode 2661\n",
      "2021-08-25 11:22:50.618 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:50.620 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:50.621 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.3\n",
      "2021-08-25 11:22:50.626 | INFO     | src.policies:train:157 - Total loss: 1.000360131263733\n",
      "2021-08-25 11:22:50.628 | INFO     | src.policies:train:103 - Epoch 752 / 800\n",
      "2021-08-25 11:22:50.629 | INFO     | src.policies:train:109 - Episode 2662\n",
      "2021-08-25 11:22:50.697 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:50.699 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:50.700 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.3\n",
      "2021-08-25 11:22:50.705 | INFO     | src.policies:train:157 - Total loss: 1.0002955198287964\n",
      "2021-08-25 11:22:50.708 | INFO     | src.policies:train:103 - Epoch 753 / 800\n",
      "2021-08-25 11:22:50.709 | INFO     | src.policies:train:109 - Episode 2663\n",
      "2021-08-25 11:22:50.777 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:50.779 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:50.780 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.8\n",
      "2021-08-25 11:22:50.785 | INFO     | src.policies:train:157 - Total loss: 1.0002976655960083\n",
      "2021-08-25 11:22:50.787 | INFO     | src.policies:train:103 - Epoch 754 / 800\n",
      "2021-08-25 11:22:50.788 | INFO     | src.policies:train:109 - Episode 2664\n",
      "2021-08-25 11:22:50.855 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:50.856 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:50.857 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.8\n",
      "2021-08-25 11:22:50.862 | INFO     | src.policies:train:157 - Total loss: 1.0004990100860596\n",
      "2021-08-25 11:22:50.865 | INFO     | src.policies:train:103 - Epoch 755 / 800\n",
      "2021-08-25 11:22:50.865 | INFO     | src.policies:train:109 - Episode 2665\n",
      "2021-08-25 11:22:50.931 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:50.933 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:50.934 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.15\n",
      "2021-08-25 11:22:50.939 | INFO     | src.policies:train:157 - Total loss: 1.0004454851150513\n",
      "2021-08-25 11:22:50.942 | INFO     | src.policies:train:103 - Epoch 756 / 800\n",
      "2021-08-25 11:22:50.942 | INFO     | src.policies:train:109 - Episode 2666\n",
      "2021-08-25 11:22:51.010 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:51.011 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:51.012 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.28\n",
      "2021-08-25 11:22:51.017 | INFO     | src.policies:train:157 - Total loss: 1.000475525856018\n",
      "2021-08-25 11:22:51.020 | INFO     | src.policies:train:103 - Epoch 757 / 800\n",
      "2021-08-25 11:22:51.021 | INFO     | src.policies:train:109 - Episode 2667\n",
      "2021-08-25 11:22:51.066 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:51.068 | INFO     | src.policies:train:121 - Mean episode return: 130.0\n",
      "2021-08-25 11:22:51.069 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.58\n",
      "2021-08-25 11:22:51.070 | INFO     | src.policies:train:109 - Episode 2668\n",
      "2021-08-25 11:22:51.108 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:51.110 | INFO     | src.policies:train:121 - Mean episode return: 110.0\n",
      "2021-08-25 11:22:51.110 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.68\n",
      "2021-08-25 11:22:51.111 | WARNING  | src.policies:train:131 - The actual batch size is 240, instead of 200\n",
      "2021-08-25 11:22:51.117 | INFO     | src.policies:train:157 - Total loss: 1.0013008117675781\n",
      "2021-08-25 11:22:51.120 | INFO     | src.policies:train:103 - Epoch 758 / 800\n",
      "2021-08-25 11:22:51.121 | INFO     | src.policies:train:109 - Episode 2669\n",
      "2021-08-25 11:22:51.165 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:51.166 | INFO     | src.policies:train:121 - Mean episode return: 125.0\n",
      "2021-08-25 11:22:51.167 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.6\n",
      "2021-08-25 11:22:51.169 | INFO     | src.policies:train:109 - Episode 2670\n",
      "2021-08-25 11:22:51.242 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:51.243 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:51.244 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.1\n",
      "2021-08-25 11:22:51.245 | WARNING  | src.policies:train:131 - The actual batch size is 325, instead of 200\n",
      "2021-08-25 11:22:51.251 | INFO     | src.policies:train:157 - Total loss: 1.002345323562622\n",
      "2021-08-25 11:22:51.254 | INFO     | src.policies:train:103 - Epoch 759 / 800\n",
      "2021-08-25 11:22:51.255 | INFO     | src.policies:train:109 - Episode 2671\n",
      "2021-08-25 11:22:51.324 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:51.325 | INFO     | src.policies:train:121 - Mean episode return: 199.0\n",
      "2021-08-25 11:22:51.326 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.09\n",
      "2021-08-25 11:22:51.327 | INFO     | src.policies:train:109 - Episode 2672\n",
      "2021-08-25 11:22:51.364 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:51.365 | INFO     | src.policies:train:121 - Mean episode return: 104.0\n",
      "2021-08-25 11:22:51.366 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.5\n",
      "2021-08-25 11:22:51.367 | WARNING  | src.policies:train:131 - The actual batch size is 303, instead of 200\n",
      "2021-08-25 11:22:51.373 | INFO     | src.policies:train:157 - Total loss: 1.0020133256912231\n",
      "2021-08-25 11:22:51.377 | INFO     | src.policies:train:103 - Epoch 760 / 800\n",
      "2021-08-25 11:22:51.378 | INFO     | src.policies:train:109 - Episode 2673\n",
      "2021-08-25 11:22:51.435 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:51.436 | INFO     | src.policies:train:121 - Mean episode return: 167.0\n",
      "2021-08-25 11:22:51.437 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.17\n",
      "2021-08-25 11:22:51.438 | INFO     | src.policies:train:109 - Episode 2674\n",
      "2021-08-25 11:22:51.507 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:51.508 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:51.509 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.17\n",
      "2021-08-25 11:22:51.510 | WARNING  | src.policies:train:131 - The actual batch size is 367, instead of 200\n",
      "2021-08-25 11:22:51.517 | INFO     | src.policies:train:157 - Total loss: 1.0028005838394165\n",
      "2021-08-25 11:22:51.520 | INFO     | src.policies:train:103 - Epoch 761 / 800\n",
      "2021-08-25 11:22:51.521 | INFO     | src.policies:train:109 - Episode 2675\n",
      "2021-08-25 11:22:51.575 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:51.577 | INFO     | src.policies:train:121 - Mean episode return: 153.0\n",
      "2021-08-25 11:22:51.578 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 173.7\n",
      "2021-08-25 11:22:51.578 | INFO     | src.policies:train:109 - Episode 2676\n",
      "2021-08-25 11:22:51.622 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:51.623 | INFO     | src.policies:train:121 - Mean episode return: 125.0\n",
      "2021-08-25 11:22:51.624 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 173.29\n",
      "2021-08-25 11:22:51.625 | WARNING  | src.policies:train:131 - The actual batch size is 278, instead of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:22:51.630 | INFO     | src.policies:train:157 - Total loss: 1.0017198324203491\n",
      "2021-08-25 11:22:51.633 | INFO     | src.policies:train:103 - Epoch 762 / 800\n",
      "2021-08-25 11:22:51.634 | INFO     | src.policies:train:109 - Episode 2677\n",
      "2021-08-25 11:22:51.699 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:51.700 | INFO     | src.policies:train:121 - Mean episode return: 189.0\n",
      "2021-08-25 11:22:51.701 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 173.18\n",
      "2021-08-25 11:22:51.702 | INFO     | src.policies:train:109 - Episode 2678\n",
      "2021-08-25 11:22:51.770 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:51.771 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:51.772 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 173.2\n",
      "2021-08-25 11:22:51.773 | WARNING  | src.policies:train:131 - The actual batch size is 389, instead of 200\n",
      "2021-08-25 11:22:51.780 | INFO     | src.policies:train:157 - Total loss: 1.002837061882019\n",
      "2021-08-25 11:22:51.783 | INFO     | src.policies:train:103 - Epoch 763 / 800\n",
      "2021-08-25 11:22:51.784 | INFO     | src.policies:train:109 - Episode 2679\n",
      "2021-08-25 11:22:51.845 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:51.847 | INFO     | src.policies:train:121 - Mean episode return: 184.0\n",
      "2021-08-25 11:22:51.848 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 173.38\n",
      "2021-08-25 11:22:51.848 | INFO     | src.policies:train:109 - Episode 2680\n",
      "2021-08-25 11:22:51.900 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:51.901 | INFO     | src.policies:train:121 - Mean episode return: 149.0\n",
      "2021-08-25 11:22:51.902 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.87\n",
      "2021-08-25 11:22:51.903 | WARNING  | src.policies:train:131 - The actual batch size is 333, instead of 200\n",
      "2021-08-25 11:22:51.908 | INFO     | src.policies:train:157 - Total loss: 1.0023996829986572\n",
      "2021-08-25 11:22:51.911 | INFO     | src.policies:train:103 - Epoch 764 / 800\n",
      "2021-08-25 11:22:51.912 | INFO     | src.policies:train:109 - Episode 2681\n",
      "2021-08-25 11:22:51.955 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:51.956 | INFO     | src.policies:train:121 - Mean episode return: 126.0\n",
      "2021-08-25 11:22:51.957 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.13\n",
      "2021-08-25 11:22:51.958 | INFO     | src.policies:train:109 - Episode 2682\n",
      "2021-08-25 11:22:52.027 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:52.028 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:52.029 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.18\n",
      "2021-08-25 11:22:52.030 | WARNING  | src.policies:train:131 - The actual batch size is 326, instead of 200\n",
      "2021-08-25 11:22:52.037 | INFO     | src.policies:train:157 - Total loss: 1.002342939376831\n",
      "2021-08-25 11:22:52.040 | INFO     | src.policies:train:103 - Epoch 765 / 800\n",
      "2021-08-25 11:22:52.041 | INFO     | src.policies:train:109 - Episode 2683\n",
      "2021-08-25 11:22:52.093 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:52.094 | INFO     | src.policies:train:121 - Mean episode return: 148.0\n",
      "2021-08-25 11:22:52.095 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.24\n",
      "2021-08-25 11:22:52.096 | INFO     | src.policies:train:109 - Episode 2684\n",
      "2021-08-25 11:22:52.165 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:52.167 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:52.167 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.47\n",
      "2021-08-25 11:22:52.168 | WARNING  | src.policies:train:131 - The actual batch size is 348, instead of 200\n",
      "2021-08-25 11:22:52.175 | INFO     | src.policies:train:157 - Total loss: 1.0025418996810913\n",
      "2021-08-25 11:22:52.178 | INFO     | src.policies:train:103 - Epoch 766 / 800\n",
      "2021-08-25 11:22:52.179 | INFO     | src.policies:train:109 - Episode 2685\n",
      "2021-08-25 11:22:52.245 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:52.247 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:52.248 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.47\n",
      "2021-08-25 11:22:52.253 | INFO     | src.policies:train:157 - Total loss: 1.0004184246063232\n",
      "2021-08-25 11:22:52.256 | INFO     | src.policies:train:103 - Epoch 767 / 800\n",
      "2021-08-25 11:22:52.256 | INFO     | src.policies:train:109 - Episode 2686\n",
      "2021-08-25 11:22:52.312 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:52.314 | INFO     | src.policies:train:121 - Mean episode return: 165.0\n",
      "2021-08-25 11:22:52.315 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.92\n",
      "2021-08-25 11:22:52.315 | INFO     | src.policies:train:109 - Episode 2687\n",
      "2021-08-25 11:22:52.369 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:52.370 | INFO     | src.policies:train:121 - Mean episode return: 153.0\n",
      "2021-08-25 11:22:52.371 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.45\n",
      "2021-08-25 11:22:52.372 | WARNING  | src.policies:train:131 - The actual batch size is 318, instead of 200\n",
      "2021-08-25 11:22:52.378 | INFO     | src.policies:train:157 - Total loss: 1.002297282218933\n",
      "2021-08-25 11:22:52.381 | INFO     | src.policies:train:103 - Epoch 768 / 800\n",
      "2021-08-25 11:22:52.382 | INFO     | src.policies:train:109 - Episode 2688\n",
      "2021-08-25 11:22:52.449 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:52.451 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:52.452 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.45\n",
      "2021-08-25 11:22:52.457 | INFO     | src.policies:train:157 - Total loss: 1.0004026889801025\n",
      "2021-08-25 11:22:52.460 | INFO     | src.policies:train:103 - Epoch 769 / 800\n",
      "2021-08-25 11:22:52.461 | INFO     | src.policies:train:109 - Episode 2689\n",
      "2021-08-25 11:22:52.519 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:52.520 | INFO     | src.policies:train:121 - Mean episode return: 170.0\n",
      "2021-08-25 11:22:52.521 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.15\n",
      "2021-08-25 11:22:52.522 | INFO     | src.policies:train:109 - Episode 2690\n",
      "2021-08-25 11:22:52.569 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:52.571 | INFO     | src.policies:train:121 - Mean episode return: 137.0\n",
      "2021-08-25 11:22:52.572 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 171.52\n",
      "2021-08-25 11:22:52.573 | WARNING  | src.policies:train:131 - The actual batch size is 307, instead of 200\n",
      "2021-08-25 11:22:52.579 | INFO     | src.policies:train:157 - Total loss: 1.0020358562469482\n",
      "2021-08-25 11:22:52.582 | INFO     | src.policies:train:103 - Epoch 770 / 800\n",
      "2021-08-25 11:22:52.583 | INFO     | src.policies:train:109 - Episode 2691\n",
      "2021-08-25 11:22:52.633 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:52.635 | INFO     | src.policies:train:121 - Mean episode return: 152.0\n",
      "2021-08-25 11:22:52.636 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 171.54\n",
      "2021-08-25 11:22:52.636 | INFO     | src.policies:train:109 - Episode 2692\n",
      "2021-08-25 11:22:52.705 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:52.706 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:52.707 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 171.89\n",
      "2021-08-25 11:22:52.708 | WARNING  | src.policies:train:131 - The actual batch size is 352, instead of 200\n",
      "2021-08-25 11:22:52.714 | INFO     | src.policies:train:157 - Total loss: 1.0026572942733765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:22:52.717 | INFO     | src.policies:train:103 - Epoch 771 / 800\n",
      "2021-08-25 11:22:52.718 | INFO     | src.policies:train:109 - Episode 2693\n",
      "2021-08-25 11:22:52.776 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:52.777 | INFO     | src.policies:train:121 - Mean episode return: 164.0\n",
      "2021-08-25 11:22:52.779 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.11\n",
      "2021-08-25 11:22:52.779 | INFO     | src.policies:train:109 - Episode 2694\n",
      "2021-08-25 11:22:52.846 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:52.847 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:52.848 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.11\n",
      "2021-08-25 11:22:52.849 | WARNING  | src.policies:train:131 - The actual batch size is 364, instead of 200\n",
      "2021-08-25 11:22:52.855 | INFO     | src.policies:train:157 - Total loss: 1.0027358531951904\n",
      "2021-08-25 11:22:52.858 | INFO     | src.policies:train:103 - Epoch 772 / 800\n",
      "2021-08-25 11:22:52.859 | INFO     | src.policies:train:109 - Episode 2695\n",
      "2021-08-25 11:22:52.926 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:52.927 | INFO     | src.policies:train:121 - Mean episode return: 194.0\n",
      "2021-08-25 11:22:52.928 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.33\n",
      "2021-08-25 11:22:52.929 | INFO     | src.policies:train:109 - Episode 2696\n",
      "2021-08-25 11:22:52.989 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:52.991 | INFO     | src.policies:train:121 - Mean episode return: 181.0\n",
      "2021-08-25 11:22:52.992 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.37\n",
      "2021-08-25 11:22:52.993 | WARNING  | src.policies:train:131 - The actual batch size is 375, instead of 200\n",
      "2021-08-25 11:22:52.999 | INFO     | src.policies:train:157 - Total loss: 1.002853274345398\n",
      "2021-08-25 11:22:53.002 | INFO     | src.policies:train:103 - Epoch 773 / 800\n",
      "2021-08-25 11:22:53.003 | INFO     | src.policies:train:109 - Episode 2697\n",
      "2021-08-25 11:22:53.071 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:53.073 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:53.074 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.93\n",
      "2021-08-25 11:22:53.078 | INFO     | src.policies:train:157 - Total loss: 1.0003361701965332\n",
      "2021-08-25 11:22:53.081 | INFO     | src.policies:train:103 - Epoch 774 / 800\n",
      "2021-08-25 11:22:53.082 | INFO     | src.policies:train:109 - Episode 2698\n",
      "2021-08-25 11:22:53.127 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:53.129 | INFO     | src.policies:train:121 - Mean episode return: 138.0\n",
      "2021-08-25 11:22:53.130 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.68\n",
      "2021-08-25 11:22:53.131 | INFO     | src.policies:train:109 - Episode 2699\n",
      "2021-08-25 11:22:53.190 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:53.191 | INFO     | src.policies:train:121 - Mean episode return: 166.0\n",
      "2021-08-25 11:22:53.192 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.34\n",
      "2021-08-25 11:22:53.193 | WARNING  | src.policies:train:131 - The actual batch size is 304, instead of 200\n",
      "2021-08-25 11:22:53.200 | INFO     | src.policies:train:157 - Total loss: 1.0020968914031982\n",
      "2021-08-25 11:22:53.203 | INFO     | src.policies:train:103 - Epoch 775 / 800\n",
      "2021-08-25 11:22:53.204 | INFO     | src.policies:train:109 - Episode 2700\n",
      "2021-08-25 11:22:53.250 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:53.251 | INFO     | src.policies:train:121 - Mean episode return: 137.0\n",
      "2021-08-25 11:22:53.252 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 171.71\n",
      "2021-08-25 11:22:53.253 | INFO     | src.policies:train:109 - Episode 2701\n",
      "2021-08-25 11:22:53.322 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:53.323 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:53.324 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.23\n",
      "2021-08-25 11:22:53.325 | WARNING  | src.policies:train:131 - The actual batch size is 337, instead of 200\n",
      "2021-08-25 11:22:53.332 | INFO     | src.policies:train:157 - Total loss: 1.0023027658462524\n",
      "2021-08-25 11:22:53.335 | INFO     | src.policies:train:103 - Epoch 776 / 800\n",
      "2021-08-25 11:22:53.336 | INFO     | src.policies:train:109 - Episode 2702\n",
      "2021-08-25 11:22:53.406 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:53.408 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:53.409 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.23\n",
      "2021-08-25 11:22:53.414 | INFO     | src.policies:train:157 - Total loss: 1.000163197517395\n",
      "2021-08-25 11:22:53.417 | INFO     | src.policies:train:103 - Epoch 777 / 800\n",
      "2021-08-25 11:22:53.417 | INFO     | src.policies:train:109 - Episode 2703\n",
      "2021-08-25 11:22:53.485 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:53.487 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:53.488 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.23\n",
      "2021-08-25 11:22:53.493 | INFO     | src.policies:train:157 - Total loss: 1.0003031492233276\n",
      "2021-08-25 11:22:53.496 | INFO     | src.policies:train:103 - Epoch 778 / 800\n",
      "2021-08-25 11:22:53.497 | INFO     | src.policies:train:109 - Episode 2704\n",
      "2021-08-25 11:22:53.563 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:53.564 | INFO     | src.policies:train:121 - Mean episode return: 190.0\n",
      "2021-08-25 11:22:53.565 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.3\n",
      "2021-08-25 11:22:53.566 | INFO     | src.policies:train:109 - Episode 2705\n",
      "2021-08-25 11:22:53.634 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:53.636 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:53.636 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.3\n",
      "2021-08-25 11:22:53.637 | WARNING  | src.policies:train:131 - The actual batch size is 390, instead of 200\n",
      "2021-08-25 11:22:53.644 | INFO     | src.policies:train:157 - Total loss: 1.0027554035186768\n",
      "2021-08-25 11:22:53.647 | INFO     | src.policies:train:103 - Epoch 779 / 800\n",
      "2021-08-25 11:22:53.648 | INFO     | src.policies:train:109 - Episode 2706\n",
      "2021-08-25 11:22:53.698 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:53.700 | INFO     | src.policies:train:121 - Mean episode return: 141.0\n",
      "2021-08-25 11:22:53.700 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.37\n",
      "2021-08-25 11:22:53.701 | INFO     | src.policies:train:109 - Episode 2707\n",
      "2021-08-25 11:22:53.755 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:53.756 | INFO     | src.policies:train:121 - Mean episode return: 151.0\n",
      "2021-08-25 11:22:53.757 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 171.88\n",
      "2021-08-25 11:22:53.758 | WARNING  | src.policies:train:131 - The actual batch size is 292, instead of 200\n",
      "2021-08-25 11:22:53.763 | INFO     | src.policies:train:157 - Total loss: 1.0019186735153198\n",
      "2021-08-25 11:22:53.767 | INFO     | src.policies:train:103 - Epoch 780 / 800\n",
      "2021-08-25 11:22:53.768 | INFO     | src.policies:train:109 - Episode 2708\n",
      "2021-08-25 11:22:53.818 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:53.819 | INFO     | src.policies:train:121 - Mean episode return: 150.0\n",
      "2021-08-25 11:22:53.820 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.05\n",
      "2021-08-25 11:22:53.821 | INFO     | src.policies:train:109 - Episode 2709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:22:53.891 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:53.892 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:53.893 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.05\n",
      "2021-08-25 11:22:53.893 | WARNING  | src.policies:train:131 - The actual batch size is 350, instead of 200\n",
      "2021-08-25 11:22:53.900 | INFO     | src.policies:train:157 - Total loss: 1.0025460720062256\n",
      "2021-08-25 11:22:53.903 | INFO     | src.policies:train:103 - Epoch 781 / 800\n",
      "2021-08-25 11:22:53.904 | INFO     | src.policies:train:109 - Episode 2710\n",
      "2021-08-25 11:22:53.963 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:53.964 | INFO     | src.policies:train:121 - Mean episode return: 181.0\n",
      "2021-08-25 11:22:53.965 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.42\n",
      "2021-08-25 11:22:53.966 | INFO     | src.policies:train:109 - Episode 2711\n",
      "2021-08-25 11:22:54.030 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:54.032 | INFO     | src.policies:train:121 - Mean episode return: 187.0\n",
      "2021-08-25 11:22:54.032 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.71\n",
      "2021-08-25 11:22:54.033 | WARNING  | src.policies:train:131 - The actual batch size is 368, instead of 200\n",
      "2021-08-25 11:22:54.040 | INFO     | src.policies:train:157 - Total loss: 1.0026729106903076\n",
      "2021-08-25 11:22:54.043 | INFO     | src.policies:train:103 - Epoch 782 / 800\n",
      "2021-08-25 11:22:54.044 | INFO     | src.policies:train:109 - Episode 2712\n",
      "2021-08-25 11:22:54.112 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:54.113 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:54.114 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.71\n",
      "2021-08-25 11:22:54.119 | INFO     | src.policies:train:157 - Total loss: 1.000397801399231\n",
      "2021-08-25 11:22:54.122 | INFO     | src.policies:train:103 - Epoch 783 / 800\n",
      "2021-08-25 11:22:54.123 | INFO     | src.policies:train:109 - Episode 2713\n",
      "2021-08-25 11:22:54.193 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:54.195 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:54.196 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 172.71\n",
      "2021-08-25 11:22:54.202 | INFO     | src.policies:train:157 - Total loss: 1.0003105401992798\n",
      "2021-08-25 11:22:54.205 | INFO     | src.policies:train:103 - Epoch 784 / 800\n",
      "2021-08-25 11:22:54.207 | INFO     | src.policies:train:109 - Episode 2714\n",
      "2021-08-25 11:22:54.279 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:54.280 | INFO     | src.policies:train:121 - Mean episode return: 191.0\n",
      "2021-08-25 11:22:54.282 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 173.31\n",
      "2021-08-25 11:22:54.282 | INFO     | src.policies:train:109 - Episode 2715\n",
      "2021-08-25 11:22:54.355 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:54.356 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:54.357 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.22\n",
      "2021-08-25 11:22:54.358 | WARNING  | src.policies:train:131 - The actual batch size is 391, instead of 200\n",
      "2021-08-25 11:22:54.364 | INFO     | src.policies:train:157 - Total loss: 1.0026743412017822\n",
      "2021-08-25 11:22:54.367 | INFO     | src.policies:train:103 - Epoch 785 / 800\n",
      "2021-08-25 11:22:54.368 | INFO     | src.policies:train:109 - Episode 2716\n",
      "2021-08-25 11:22:54.436 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:54.438 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:54.439 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.22\n",
      "2021-08-25 11:22:54.444 | INFO     | src.policies:train:157 - Total loss: 1.0004048347473145\n",
      "2021-08-25 11:22:54.447 | INFO     | src.policies:train:103 - Epoch 786 / 800\n",
      "2021-08-25 11:22:54.448 | INFO     | src.policies:train:109 - Episode 2717\n",
      "2021-08-25 11:22:54.504 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:54.505 | INFO     | src.policies:train:121 - Mean episode return: 168.0\n",
      "2021-08-25 11:22:54.506 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.28\n",
      "2021-08-25 11:22:54.507 | INFO     | src.policies:train:109 - Episode 2718\n",
      "2021-08-25 11:22:54.576 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:54.578 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:54.578 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.42\n",
      "2021-08-25 11:22:54.579 | WARNING  | src.policies:train:131 - The actual batch size is 368, instead of 200\n",
      "2021-08-25 11:22:54.585 | INFO     | src.policies:train:157 - Total loss: 1.0026761293411255\n",
      "2021-08-25 11:22:54.588 | INFO     | src.policies:train:103 - Epoch 787 / 800\n",
      "2021-08-25 11:22:54.589 | INFO     | src.policies:train:109 - Episode 2719\n",
      "2021-08-25 11:22:54.658 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:54.659 | INFO     | src.policies:train:121 - Mean episode return: 197.0\n",
      "2021-08-25 11:22:54.660 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.82\n",
      "2021-08-25 11:22:54.661 | INFO     | src.policies:train:109 - Episode 2720\n",
      "2021-08-25 11:22:54.728 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:54.729 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:54.730 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.85\n",
      "2021-08-25 11:22:54.731 | WARNING  | src.policies:train:131 - The actual batch size is 397, instead of 200\n",
      "2021-08-25 11:22:54.737 | INFO     | src.policies:train:157 - Total loss: 1.0028654336929321\n",
      "2021-08-25 11:22:54.740 | INFO     | src.policies:train:103 - Epoch 788 / 800\n",
      "2021-08-25 11:22:54.741 | INFO     | src.policies:train:109 - Episode 2721\n",
      "2021-08-25 11:22:54.807 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:54.809 | INFO     | src.policies:train:121 - Mean episode return: 195.0\n",
      "2021-08-25 11:22:54.810 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.41\n",
      "2021-08-25 11:22:54.810 | INFO     | src.policies:train:109 - Episode 2722\n",
      "2021-08-25 11:22:54.880 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:54.881 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:54.882 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.41\n",
      "2021-08-25 11:22:54.883 | WARNING  | src.policies:train:131 - The actual batch size is 395, instead of 200\n",
      "2021-08-25 11:22:54.889 | INFO     | src.policies:train:157 - Total loss: 1.0028185844421387\n",
      "2021-08-25 11:22:54.892 | INFO     | src.policies:train:103 - Epoch 789 / 800\n",
      "2021-08-25 11:22:54.893 | INFO     | src.policies:train:109 - Episode 2723\n",
      "2021-08-25 11:22:54.962 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:54.964 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:54.965 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.45\n",
      "2021-08-25 11:22:54.970 | INFO     | src.policies:train:157 - Total loss: 1.0004231929779053\n",
      "2021-08-25 11:22:54.972 | INFO     | src.policies:train:103 - Epoch 790 / 800\n",
      "2021-08-25 11:22:54.973 | INFO     | src.policies:train:109 - Episode 2724\n",
      "2021-08-25 11:22:55.041 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:55.043 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:55.044 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.66\n",
      "2021-08-25 11:22:55.049 | INFO     | src.policies:train:157 - Total loss: 1.0003411769866943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:22:55.052 | INFO     | src.policies:train:103 - Epoch 791 / 800\n",
      "2021-08-25 11:22:55.053 | INFO     | src.policies:train:109 - Episode 2725\n",
      "2021-08-25 11:22:55.121 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:55.122 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:55.123 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.66\n",
      "2021-08-25 11:22:55.128 | INFO     | src.policies:train:157 - Total loss: 1.0002570152282715\n",
      "2021-08-25 11:22:55.131 | INFO     | src.policies:train:103 - Epoch 792 / 800\n",
      "2021-08-25 11:22:55.131 | INFO     | src.policies:train:109 - Episode 2726\n",
      "2021-08-25 11:22:55.199 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:55.201 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:55.202 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.66\n",
      "2021-08-25 11:22:55.206 | INFO     | src.policies:train:157 - Total loss: 1.0001729726791382\n",
      "2021-08-25 11:22:55.209 | INFO     | src.policies:train:103 - Epoch 793 / 800\n",
      "2021-08-25 11:22:55.210 | INFO     | src.policies:train:109 - Episode 2727\n",
      "2021-08-25 11:22:55.260 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:55.261 | INFO     | src.policies:train:121 - Mean episode return: 145.0\n",
      "2021-08-25 11:22:55.262 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.45\n",
      "2021-08-25 11:22:55.263 | INFO     | src.policies:train:109 - Episode 2728\n",
      "2021-08-25 11:22:55.324 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:55.326 | INFO     | src.policies:train:121 - Mean episode return: 174.0\n",
      "2021-08-25 11:22:55.326 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.28\n",
      "2021-08-25 11:22:55.327 | WARNING  | src.policies:train:131 - The actual batch size is 319, instead of 200\n",
      "2021-08-25 11:22:55.333 | INFO     | src.policies:train:157 - Total loss: 1.0020570755004883\n",
      "2021-08-25 11:22:55.336 | INFO     | src.policies:train:103 - Epoch 794 / 800\n",
      "2021-08-25 11:22:55.337 | INFO     | src.policies:train:109 - Episode 2729\n",
      "2021-08-25 11:22:55.388 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:55.390 | INFO     | src.policies:train:121 - Mean episode return: 155.0\n",
      "2021-08-25 11:22:55.391 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.83\n",
      "2021-08-25 11:22:55.392 | INFO     | src.policies:train:109 - Episode 2730\n",
      "2021-08-25 11:22:55.443 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:55.444 | INFO     | src.policies:train:121 - Mean episode return: 144.0\n",
      "2021-08-25 11:22:55.445 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.42\n",
      "2021-08-25 11:22:55.446 | WARNING  | src.policies:train:131 - The actual batch size is 299, instead of 200\n",
      "2021-08-25 11:22:55.452 | INFO     | src.policies:train:157 - Total loss: 1.002081274986267\n",
      "2021-08-25 11:22:55.455 | INFO     | src.policies:train:103 - Epoch 795 / 800\n",
      "2021-08-25 11:22:55.456 | INFO     | src.policies:train:109 - Episode 2731\n",
      "2021-08-25 11:22:55.516 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:55.518 | INFO     | src.policies:train:121 - Mean episode return: 175.0\n",
      "2021-08-25 11:22:55.518 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.4\n",
      "2021-08-25 11:22:55.519 | INFO     | src.policies:train:109 - Episode 2732\n",
      "2021-08-25 11:22:55.588 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:55.590 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:55.590 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 174.84\n",
      "2021-08-25 11:22:55.591 | WARNING  | src.policies:train:131 - The actual batch size is 375, instead of 200\n",
      "2021-08-25 11:22:55.598 | INFO     | src.policies:train:157 - Total loss: 1.0026524066925049\n",
      "2021-08-25 11:22:55.602 | INFO     | src.policies:train:103 - Epoch 796 / 800\n",
      "2021-08-25 11:22:55.603 | INFO     | src.policies:train:109 - Episode 2733\n",
      "2021-08-25 11:22:55.665 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:55.666 | INFO     | src.policies:train:121 - Mean episode return: 177.0\n",
      "2021-08-25 11:22:55.667 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.2\n",
      "2021-08-25 11:22:55.668 | INFO     | src.policies:train:109 - Episode 2734\n",
      "2021-08-25 11:22:55.736 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:55.737 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:55.738 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.2\n",
      "2021-08-25 11:22:55.739 | WARNING  | src.policies:train:131 - The actual batch size is 377, instead of 200\n",
      "2021-08-25 11:22:55.745 | INFO     | src.policies:train:157 - Total loss: 1.0026768445968628\n",
      "2021-08-25 11:22:55.748 | INFO     | src.policies:train:103 - Epoch 797 / 800\n",
      "2021-08-25 11:22:55.749 | INFO     | src.policies:train:109 - Episode 2735\n",
      "2021-08-25 11:22:55.812 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:55.813 | INFO     | src.policies:train:121 - Mean episode return: 185.0\n",
      "2021-08-25 11:22:55.814 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.33\n",
      "2021-08-25 11:22:55.815 | INFO     | src.policies:train:109 - Episode 2736\n",
      "2021-08-25 11:22:55.884 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:55.885 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:55.886 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.33\n",
      "2021-08-25 11:22:55.887 | WARNING  | src.policies:train:131 - The actual batch size is 385, instead of 200\n",
      "2021-08-25 11:22:55.893 | INFO     | src.policies:train:157 - Total loss: 1.002722144126892\n",
      "2021-08-25 11:22:55.896 | INFO     | src.policies:train:103 - Epoch 798 / 800\n",
      "2021-08-25 11:22:55.898 | INFO     | src.policies:train:109 - Episode 2737\n",
      "2021-08-25 11:22:55.962 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:55.964 | INFO     | src.policies:train:121 - Mean episode return: 190.0\n",
      "2021-08-25 11:22:55.965 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.23\n",
      "2021-08-25 11:22:55.966 | INFO     | src.policies:train:109 - Episode 2738\n",
      "2021-08-25 11:22:56.035 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:56.036 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:56.037 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.23\n",
      "2021-08-25 11:22:56.038 | WARNING  | src.policies:train:131 - The actual batch size is 390, instead of 200\n",
      "2021-08-25 11:22:56.045 | INFO     | src.policies:train:157 - Total loss: 1.0026848316192627\n",
      "2021-08-25 11:22:56.048 | INFO     | src.policies:train:103 - Epoch 799 / 800\n",
      "2021-08-25 11:22:56.049 | INFO     | src.policies:train:109 - Episode 2739\n",
      "2021-08-25 11:22:56.120 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:56.122 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:56.123 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 175.96\n",
      "2021-08-25 11:22:56.128 | INFO     | src.policies:train:157 - Total loss: 1.0003658533096313\n",
      "2021-08-25 11:22:56.131 | INFO     | src.policies:train:103 - Epoch 800 / 800\n",
      "2021-08-25 11:22:56.132 | INFO     | src.policies:train:109 - Episode 2740\n",
      "2021-08-25 11:22:56.199 | DEBUG    | src.policies:execute_episode:267 - Early stopping, all agents done\n",
      "2021-08-25 11:22:56.200 | INFO     | src.policies:train:121 - Mean episode return: 200.0\n",
      "2021-08-25 11:22:56.201 | INFO     | src.policies:train:122 - Last 100 episodes mean return: 176.75\n",
      "2021-08-25 11:22:56.207 | INFO     | src.policies:train:157 - Total loss: 1.0004656314849854\n"
     ]
    }
   ],
   "source": [
    "ppo_policy_nn = models.MLP(observation_space_size, hidden_sizes, action_space_size)\n",
    "ppo_baseline_nn = models.MLP(observation_space_size, hidden_sizes, 1, log_softmax=False)\n",
    "ppo_policy = policies.PPOPolicy(env, ppo_policy_nn, ppo_baseline_nn, c1=c1, c2=c2, eps=eps)\n",
    "ppo_policy.train(\n",
    "    epochs,\n",
    "    steps_per_epoch,\n",
    "    enable_wandb=False\n",
    "    episodes_mean_reward=episodes_mean_reward\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
