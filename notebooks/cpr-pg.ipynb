{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5cd1f8f",
   "metadata": {},
   "source": [
    "# CPR appropriation with policy gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6b4b24",
   "metadata": {},
   "source": [
    "This notebook contains actual Harvest trainings for each implemented policy gradient method. The environment in use is a custom implementation of Harvest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28656187",
   "metadata": {},
   "source": [
    "## Pre-requisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a481935b",
   "metadata": {},
   "source": [
    "The cells down below install and import the necessary libraries to successfully run the notebook examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2583383c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f5a4d886",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -r ../init/requirements.txt\n",
    "!pip install ../src/gym_cpr_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "96a5b2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of gym_cpr_grid failed: Traceback (most recent call last):\n",
      "  File \"/Users/jobs/Github/cpr-appropriation/venv/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/Users/jobs/Github/cpr-appropriation/venv/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 394, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.5/Frameworks/Python.framework/Versions/3.9/lib/python3.9/imp.py\", line 314, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.5/Frameworks/Python.framework/Versions/3.9/lib/python3.9/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 613, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 855, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 228, in _call_with_frames_removed\n",
      "  File \"/Users/jobs/Github/cpr-appropriation/venv/lib/python3.9/site-packages/gym_cpr_grid/__init__.py\", line 3, in <module>\n",
      "    register(id=\"CPRGridEnv-v0\", entry_point=\"gym_cpr_grid.cpr_grid:CPRGridEnv\")\n",
      "  File \"/Users/jobs/Github/cpr-appropriation/venv/lib/python3.9/site-packages/gym/envs/registration.py\", line 142, in register\n",
      "    return registry.register(id, **kwargs)\n",
      "  File \"/Users/jobs/Github/cpr-appropriation/venv/lib/python3.9/site-packages/gym/envs/registration.py\", line 135, in register\n",
      "    raise error.Error('Cannot re-register id: {}'.format(id))\n",
      "gym.error.Error: Cannot re-register id: CPRGridEnv-v0\n",
      "]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "from src import memory, models, policies\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ae6b0e",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e395a5",
   "metadata": {},
   "source": [
    "The cell down below defines the environment, along with common variables to be used throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bb8048cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\n",
    "    'gym_cpr_grid:CPRGridEnv-v0', \n",
    "    n_agents=11, \n",
    "    grid_width=39, \n",
    "    grid_height=19,\n",
    "    tagging_ability=True,\n",
    "    gifting_mechanism=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "365ab924",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_space_size = env.observation_space_size()\n",
    "action_space_size = env.action_space_size()\n",
    "epochs = 4000\n",
    "steps_per_epoch = 4000\n",
    "save_every = 500\n",
    "hidden_sizes = [32, 32]\n",
    "checkpoints_path = \"../checkpoints\"\n",
    "wandb_config = {\n",
    "    \"api_key\": open(\"../wandb_api_key_file\", \"r\").read().strip(),\n",
    "    \"project\": \"cpr-appropriation\",\n",
    "    \"entity\": \"wadaboa\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c874d03",
   "metadata": {},
   "source": [
    "## VPG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4f3ac8",
   "metadata": {},
   "source": [
    "This section deals with training a set of Harvest agents using our custom Vanilla Policy Gradient implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80a7ecc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwadaboa\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.0<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">flowing-darkness-28</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/wadaboa/cpr-appropriation\" target=\"_blank\">https://wandb.ai/wadaboa/cpr-appropriation</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/wadaboa/cpr-appropriation/runs/3j96ma8r\" target=\"_blank\">https://wandb.ai/wadaboa/cpr-appropriation/runs/3j96ma8r</a><br/>\n",
       "                Run data is saved locally in <code>/Users/jobs/Github/cpr-appropriation/notebooks/wandb/run-20210825_130510-3j96ma8r</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 13:05:12.502 | INFO     | src.policies:train:103 - Epoch 1 / 4000\n",
      "2021-08-25 13:05:12.503 | INFO     | src.policies:train:110 - Episode 1\n",
      "2021-08-25 13:05:30.874 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:05:30.876 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 210.0909090909091, 'equality': 0.9288776995411495, 'sustainability': 474.1942691329546, 'peace': 756.9090909090909}\n",
      "2021-08-25 13:05:30.877 | INFO     | src.policies:train:122 - Mean episode return: 210.0909090909091\n",
      "2021-08-25 13:05:30.877 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 210.0909090909091\n",
      "2021-08-25 13:05:30.878 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:05:38.303 | INFO     | src.policies:train:159 - Total loss: 0.9996551871299744\n",
      "2021-08-25 13:05:38.304 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 210.0909090909091, 'equality': 0.9288776995411495, 'sustainability': 474.1942691329546, 'peace': 756.9090909090909}\n",
      "2021-08-25 13:05:38.348 | INFO     | src.policies:train:103 - Epoch 2 / 4000\n",
      "2021-08-25 13:05:38.348 | INFO     | src.policies:train:110 - Episode 2\n",
      "2021-08-25 13:05:56.556 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:05:56.582 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 191.0, 'equality': 0.9014322184262595, 'sustainability': 453.6478484897958, 'peace': 635.0909090909091}\n",
      "2021-08-25 13:05:56.582 | INFO     | src.policies:train:122 - Mean episode return: 191.0\n",
      "2021-08-25 13:05:56.583 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 200.54545454545456\n",
      "2021-08-25 13:05:56.583 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:06:03.974 | INFO     | src.policies:train:159 - Total loss: 0.9981196522712708\n",
      "2021-08-25 13:06:03.975 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 191.0, 'equality': 0.9014322184262595, 'sustainability': 453.6478484897958, 'peace': 635.0909090909091}\n",
      "2021-08-25 13:06:04.021 | INFO     | src.policies:train:103 - Epoch 3 / 4000\n",
      "2021-08-25 13:06:04.022 | INFO     | src.policies:train:110 - Episode 3\n",
      "2021-08-25 13:06:22.420 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:06:22.443 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 215.0, 'equality': 0.9490294061128381, 'sustainability': 492.28421692334354, 'peace': 732.0}\n",
      "2021-08-25 13:06:22.444 | INFO     | src.policies:train:122 - Mean episode return: 215.0\n",
      "2021-08-25 13:06:22.444 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.36363636363637\n",
      "2021-08-25 13:06:22.445 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:06:29.984 | INFO     | src.policies:train:159 - Total loss: 0.9983858466148376\n",
      "2021-08-25 13:06:29.985 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 215.0, 'equality': 0.9490294061128381, 'sustainability': 492.28421692334354, 'peace': 732.0}\n",
      "2021-08-25 13:06:30.032 | INFO     | src.policies:train:103 - Epoch 4 / 4000\n",
      "2021-08-25 13:06:30.032 | INFO     | src.policies:train:110 - Episode 4\n",
      "2021-08-25 13:06:48.097 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:06:48.117 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 222.27272727272728, 'equality': 0.9572411228860895, 'sustainability': 501.32197584338263, 'peace': 797.7272727272727}\n",
      "2021-08-25 13:06:48.117 | INFO     | src.policies:train:122 - Mean episode return: 222.27272727272728\n",
      "2021-08-25 13:06:48.118 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.5909090909091\n",
      "2021-08-25 13:06:48.118 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:06:55.614 | INFO     | src.policies:train:159 - Total loss: 0.9993704557418823\n",
      "2021-08-25 13:06:55.614 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 222.27272727272728, 'equality': 0.9572411228860895, 'sustainability': 501.32197584338263, 'peace': 797.7272727272727}\n",
      "2021-08-25 13:06:55.661 | INFO     | src.policies:train:103 - Epoch 5 / 4000\n",
      "2021-08-25 13:06:55.662 | INFO     | src.policies:train:110 - Episode 5\n",
      "2021-08-25 13:07:14.142 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:07:14.163 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 207.9090909090909, 'equality': 0.9367174146373431, 'sustainability': 485.28755579192364, 'peace': 720.7272727272727}\n",
      "2021-08-25 13:07:14.164 | INFO     | src.policies:train:122 - Mean episode return: 207.9090909090909\n",
      "2021-08-25 13:07:14.164 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.25454545454545\n",
      "2021-08-25 13:07:14.165 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:07:21.650 | INFO     | src.policies:train:159 - Total loss: 1.0049175024032593\n",
      "2021-08-25 13:07:21.651 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 207.9090909090909, 'equality': 0.9367174146373431, 'sustainability': 485.28755579192364, 'peace': 720.7272727272727}\n",
      "2021-08-25 13:07:21.698 | INFO     | src.policies:train:103 - Epoch 6 / 4000\n",
      "2021-08-25 13:07:21.698 | INFO     | src.policies:train:110 - Episode 6\n",
      "2021-08-25 13:07:40.709 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:07:40.728 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 217.0909090909091, 'equality': 0.9452565859611456, 'sustainability': 472.224722068058, 'peace': 708.1818181818181}\n",
      "2021-08-25 13:07:40.729 | INFO     | src.policies:train:122 - Mean episode return: 217.0909090909091\n",
      "2021-08-25 13:07:40.730 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 210.56060606060603\n",
      "2021-08-25 13:07:40.730 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:07:48.202 | INFO     | src.policies:train:159 - Total loss: 0.9995870590209961\n",
      "2021-08-25 13:07:48.203 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 217.0909090909091, 'equality': 0.9452565859611456, 'sustainability': 472.224722068058, 'peace': 708.1818181818181}\n",
      "2021-08-25 13:07:48.248 | INFO     | src.policies:train:103 - Epoch 7 / 4000\n",
      "2021-08-25 13:07:48.249 | INFO     | src.policies:train:110 - Episode 7\n",
      "2021-08-25 13:08:07.071 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:08:07.091 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 195.0909090909091, 'equality': 0.9257815809555667, 'sustainability': 488.01074216497295, 'peace': 688.8181818181819}\n",
      "2021-08-25 13:08:07.092 | INFO     | src.policies:train:122 - Mean episode return: 195.0909090909091\n",
      "2021-08-25 13:08:07.092 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.35064935064932\n",
      "2021-08-25 13:08:07.093 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:08:14.692 | INFO     | src.policies:train:159 - Total loss: 0.9931796789169312\n",
      "2021-08-25 13:08:14.693 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 195.0909090909091, 'equality': 0.9257815809555667, 'sustainability': 488.01074216497295, 'peace': 688.8181818181819}\n",
      "2021-08-25 13:08:14.741 | INFO     | src.policies:train:103 - Epoch 8 / 4000\n",
      "2021-08-25 13:08:14.742 | INFO     | src.policies:train:110 - Episode 8\n",
      "2021-08-25 13:08:33.157 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:08:33.176 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 192.0909090909091, 'equality': 0.8630985673135332, 'sustainability': 481.78660196007417, 'peace': 653.1818181818181}\n",
      "2021-08-25 13:08:33.177 | INFO     | src.policies:train:122 - Mean episode return: 192.0909090909091\n",
      "2021-08-25 13:08:33.177 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.3181818181818\n",
      "2021-08-25 13:08:33.178 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 13:08:40.733 | INFO     | src.policies:train:159 - Total loss: 0.9971657991409302\n",
      "2021-08-25 13:08:40.734 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 192.0909090909091, 'equality': 0.8630985673135332, 'sustainability': 481.78660196007417, 'peace': 653.1818181818181}\n",
      "2021-08-25 13:08:40.781 | INFO     | src.policies:train:103 - Epoch 9 / 4000\n",
      "2021-08-25 13:08:40.782 | INFO     | src.policies:train:110 - Episode 9\n",
      "2021-08-25 13:08:59.288 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:08:59.309 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 215.0, 'equality': 0.9331923890076266, 'sustainability': 505.6465004460492, 'peace': 812.8181818181819}\n",
      "2021-08-25 13:08:59.310 | INFO     | src.policies:train:122 - Mean episode return: 215.0\n",
      "2021-08-25 13:08:59.310 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.2828282828283\n",
      "2021-08-25 13:08:59.310 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:09:06.978 | INFO     | src.policies:train:159 - Total loss: 1.0036789178848267\n",
      "2021-08-25 13:09:06.979 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 215.0, 'equality': 0.9331923890076266, 'sustainability': 505.6465004460492, 'peace': 812.8181818181819}\n",
      "2021-08-25 13:09:07.028 | INFO     | src.policies:train:103 - Epoch 10 / 4000\n",
      "2021-08-25 13:09:07.028 | INFO     | src.policies:train:110 - Episode 10\n",
      "2021-08-25 13:09:25.295 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:09:25.315 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 203.1818181818182, 'equality': 0.9233679072620832, 'sustainability': 486.2241285789833, 'peace': 739.1818181818181}\n",
      "2021-08-25 13:09:25.315 | INFO     | src.policies:train:122 - Mean episode return: 203.1818181818182\n",
      "2021-08-25 13:09:25.316 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.87272727272725\n",
      "2021-08-25 13:09:25.316 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:09:32.895 | INFO     | src.policies:train:159 - Total loss: 0.9927173256874084\n",
      "2021-08-25 13:09:32.896 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 203.1818181818182, 'equality': 0.9233679072620832, 'sustainability': 486.2241285789833, 'peace': 739.1818181818181}\n",
      "2021-08-25 13:09:32.943 | INFO     | src.policies:train:103 - Epoch 11 / 4000\n",
      "2021-08-25 13:09:32.944 | INFO     | src.policies:train:110 - Episode 11\n",
      "2021-08-25 13:09:51.699 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:09:51.719 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 211.54545454545453, 'equality': 0.9136617572388628, 'sustainability': 496.0733840286897, 'peace': 754.7272727272727}\n",
      "2021-08-25 13:09:51.720 | INFO     | src.policies:train:122 - Mean episode return: 211.54545454545453\n",
      "2021-08-25 13:09:51.720 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.297520661157\n",
      "2021-08-25 13:09:51.721 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:09:59.535 | INFO     | src.policies:train:159 - Total loss: 1.0049186944961548\n",
      "2021-08-25 13:09:59.535 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 211.54545454545453, 'equality': 0.9136617572388628, 'sustainability': 496.0733840286897, 'peace': 754.7272727272727}\n",
      "2021-08-25 13:09:59.582 | INFO     | src.policies:train:103 - Epoch 12 / 4000\n",
      "2021-08-25 13:09:59.583 | INFO     | src.policies:train:110 - Episode 12\n",
      "2021-08-25 13:10:18.297 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:10:18.319 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 206.72727272727272, 'equality': 0.9130087151212719, 'sustainability': 486.2811925722452, 'peace': 723.1818181818181}\n",
      "2021-08-25 13:10:18.320 | INFO     | src.policies:train:122 - Mean episode return: 206.72727272727272\n",
      "2021-08-25 13:10:18.320 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.24999999999997\n",
      "2021-08-25 13:10:18.321 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:10:26.007 | INFO     | src.policies:train:159 - Total loss: 0.9999533295631409\n",
      "2021-08-25 13:10:26.008 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 206.72727272727272, 'equality': 0.9130087151212719, 'sustainability': 486.2811925722452, 'peace': 723.1818181818181}\n",
      "2021-08-25 13:10:26.055 | INFO     | src.policies:train:103 - Epoch 13 / 4000\n",
      "2021-08-25 13:10:26.056 | INFO     | src.policies:train:110 - Episode 13\n",
      "2021-08-25 13:10:44.421 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:10:44.440 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 221.54545454545453, 'equality': 0.9448651471640828, 'sustainability': 490.96978548581023, 'peace': 741.9090909090909}\n",
      "2021-08-25 13:10:44.441 | INFO     | src.policies:train:122 - Mean episode return: 221.54545454545453\n",
      "2021-08-25 13:10:44.441 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.34965034965032\n",
      "2021-08-25 13:10:44.442 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:10:52.216 | INFO     | src.policies:train:159 - Total loss: 0.995656430721283\n",
      "2021-08-25 13:10:52.217 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 221.54545454545453, 'equality': 0.9448651471640828, 'sustainability': 490.96978548581023, 'peace': 741.9090909090909}\n",
      "2021-08-25 13:10:52.264 | INFO     | src.policies:train:103 - Epoch 14 / 4000\n",
      "2021-08-25 13:10:52.264 | INFO     | src.policies:train:110 - Episode 14\n",
      "2021-08-25 13:11:11.652 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:11:11.671 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 227.8181818181818, 'equality': 0.960531089023425, 'sustainability': 503.6366365584386, 'peace': 783.4545454545455}\n",
      "2021-08-25 13:11:11.672 | INFO     | src.policies:train:122 - Mean episode return: 227.8181818181818\n",
      "2021-08-25 13:11:11.672 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.74025974025972\n",
      "2021-08-25 13:11:11.673 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:11:19.450 | INFO     | src.policies:train:159 - Total loss: 1.0035055875778198\n",
      "2021-08-25 13:11:19.452 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 227.8181818181818, 'equality': 0.960531089023425, 'sustainability': 503.6366365584386, 'peace': 783.4545454545455}\n",
      "2021-08-25 13:11:19.499 | INFO     | src.policies:train:103 - Epoch 15 / 4000\n",
      "2021-08-25 13:11:19.499 | INFO     | src.policies:train:110 - Episode 15\n",
      "2021-08-25 13:11:37.761 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:11:37.782 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 210.8181818181818, 'equality': 0.9448037947401936, 'sustainability': 487.12943187128826, 'peace': 766.7272727272727}\n",
      "2021-08-25 13:11:37.782 | INFO     | src.policies:train:122 - Mean episode return: 210.8181818181818\n",
      "2021-08-25 13:11:37.783 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.8121212121212\n",
      "2021-08-25 13:11:37.783 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:11:45.634 | INFO     | src.policies:train:159 - Total loss: 1.0007202625274658\n",
      "2021-08-25 13:11:45.635 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 210.8181818181818, 'equality': 0.9448037947401936, 'sustainability': 487.12943187128826, 'peace': 766.7272727272727}\n",
      "2021-08-25 13:11:45.683 | INFO     | src.policies:train:103 - Epoch 16 / 4000\n",
      "2021-08-25 13:11:45.683 | INFO     | src.policies:train:110 - Episode 16\n",
      "2021-08-25 13:12:04.984 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:12:05.011 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 194.27272727272728, 'equality': 0.8995192921278871, 'sustainability': 478.79792458808674, 'peace': 725.3636363636364}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 13:12:05.012 | INFO     | src.policies:train:122 - Mean episode return: 194.27272727272728\n",
      "2021-08-25 13:12:05.012 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.84090909090907\n",
      "2021-08-25 13:12:05.013 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:12:13.399 | INFO     | src.policies:train:159 - Total loss: 0.9996477365493774\n",
      "2021-08-25 13:12:13.400 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 194.27272727272728, 'equality': 0.8995192921278871, 'sustainability': 478.79792458808674, 'peace': 725.3636363636364}\n",
      "2021-08-25 13:12:13.447 | INFO     | src.policies:train:103 - Epoch 17 / 4000\n",
      "2021-08-25 13:12:13.448 | INFO     | src.policies:train:110 - Episode 17\n",
      "2021-08-25 13:12:32.802 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:12:32.824 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 207.9090909090909, 'equality': 0.9270978256563362, 'sustainability': 487.7497772200393, 'peace': 669.0}\n",
      "2021-08-25 13:12:32.825 | INFO     | src.policies:train:122 - Mean episode return: 207.9090909090909\n",
      "2021-08-25 13:12:32.825 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.78609625668446\n",
      "2021-08-25 13:12:32.826 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:12:41.233 | INFO     | src.policies:train:159 - Total loss: 1.00559663772583\n",
      "2021-08-25 13:12:41.234 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 207.9090909090909, 'equality': 0.9270978256563362, 'sustainability': 487.7497772200393, 'peace': 669.0}\n",
      "2021-08-25 13:12:41.282 | INFO     | src.policies:train:103 - Epoch 18 / 4000\n",
      "2021-08-25 13:12:41.282 | INFO     | src.policies:train:110 - Episode 18\n",
      "2021-08-25 13:13:00.785 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:13:00.806 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 224.27272727272728, 'equality': 0.9431035118114917, 'sustainability': 497.49071141457466, 'peace': 728.1818181818181}\n",
      "2021-08-25 13:13:00.807 | INFO     | src.policies:train:122 - Mean episode return: 224.27272727272728\n",
      "2021-08-25 13:13:00.807 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.64646464646464\n",
      "2021-08-25 13:13:00.807 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:13:08.643 | INFO     | src.policies:train:159 - Total loss: 1.004082441329956\n",
      "2021-08-25 13:13:08.644 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 224.27272727272728, 'equality': 0.9431035118114917, 'sustainability': 497.49071141457466, 'peace': 728.1818181818181}\n",
      "2021-08-25 13:13:08.691 | INFO     | src.policies:train:103 - Epoch 19 / 4000\n",
      "2021-08-25 13:13:08.692 | INFO     | src.policies:train:110 - Episode 19\n",
      "2021-08-25 13:13:28.689 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:13:28.711 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 214.8181818181818, 'equality': 0.9659138998967816, 'sustainability': 512.5025342887893, 'peace': 758.5454545454545}\n",
      "2021-08-25 13:13:28.711 | INFO     | src.policies:train:122 - Mean episode return: 214.8181818181818\n",
      "2021-08-25 13:13:28.712 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.91866028708134\n",
      "2021-08-25 13:13:28.712 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:13:36.632 | INFO     | src.policies:train:159 - Total loss: 0.9979760050773621\n",
      "2021-08-25 13:13:36.633 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 214.8181818181818, 'equality': 0.9659138998967816, 'sustainability': 512.5025342887893, 'peace': 758.5454545454545}\n",
      "2021-08-25 13:13:36.680 | INFO     | src.policies:train:103 - Epoch 20 / 4000\n",
      "2021-08-25 13:13:36.681 | INFO     | src.policies:train:110 - Episode 20\n",
      "2021-08-25 13:13:56.474 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:13:56.495 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 216.9090909090909, 'equality': 0.9424674236085029, 'sustainability': 496.36315283217886, 'peace': 727.6363636363636}\n",
      "2021-08-25 13:13:56.496 | INFO     | src.policies:train:122 - Mean episode return: 216.9090909090909\n",
      "2021-08-25 13:13:56.497 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 210.2681818181818\n",
      "2021-08-25 13:13:56.497 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:14:04.728 | INFO     | src.policies:train:159 - Total loss: 1.0038795471191406\n",
      "2021-08-25 13:14:04.729 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 216.9090909090909, 'equality': 0.9424674236085029, 'sustainability': 496.36315283217886, 'peace': 727.6363636363636}\n",
      "2021-08-25 13:14:04.777 | INFO     | src.policies:train:103 - Epoch 21 / 4000\n",
      "2021-08-25 13:14:04.777 | INFO     | src.policies:train:110 - Episode 21\n",
      "2021-08-25 13:14:25.064 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:14:25.085 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 201.54545454545453, 'equality': 0.9329150777067102, 'sustainability': 482.74846752713694, 'peace': 694.4545454545455}\n",
      "2021-08-25 13:14:25.086 | INFO     | src.policies:train:122 - Mean episode return: 201.54545454545453\n",
      "2021-08-25 13:14:25.087 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.85281385281385\n",
      "2021-08-25 13:14:25.087 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:14:33.010 | INFO     | src.policies:train:159 - Total loss: 1.0057965517044067\n",
      "2021-08-25 13:14:33.011 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 201.54545454545453, 'equality': 0.9329150777067102, 'sustainability': 482.74846752713694, 'peace': 694.4545454545455}\n",
      "2021-08-25 13:14:33.059 | INFO     | src.policies:train:103 - Epoch 22 / 4000\n",
      "2021-08-25 13:14:33.059 | INFO     | src.policies:train:110 - Episode 22\n",
      "2021-08-25 13:14:53.507 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:14:53.530 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 213.72727272727272, 'equality': 0.9523606975764208, 'sustainability': 495.0542958192232, 'peace': 719.1818181818181}\n",
      "2021-08-25 13:14:53.530 | INFO     | src.policies:train:122 - Mean episode return: 213.72727272727272\n",
      "2021-08-25 13:14:53.531 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 210.02892561983472\n",
      "2021-08-25 13:14:53.531 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:15:01.813 | INFO     | src.policies:train:159 - Total loss: 1.0045866966247559\n",
      "2021-08-25 13:15:01.814 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 213.72727272727272, 'equality': 0.9523606975764208, 'sustainability': 495.0542958192232, 'peace': 719.1818181818181}\n",
      "2021-08-25 13:15:01.861 | INFO     | src.policies:train:103 - Epoch 23 / 4000\n",
      "2021-08-25 13:15:01.862 | INFO     | src.policies:train:110 - Episode 23\n",
      "2021-08-25 13:15:22.247 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:15:22.270 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 217.72727272727272, 'equality': 0.9109508445642256, 'sustainability': 494.7693931559598, 'peace': 822.2727272727273}\n",
      "2021-08-25 13:15:22.271 | INFO     | src.policies:train:122 - Mean episode return: 217.72727272727272\n",
      "2021-08-25 13:15:22.272 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 210.3636363636364\n",
      "2021-08-25 13:15:22.272 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:15:30.619 | INFO     | src.policies:train:159 - Total loss: 1.0022664070129395\n",
      "2021-08-25 13:15:30.620 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 217.72727272727272, 'equality': 0.9109508445642256, 'sustainability': 494.7693931559598, 'peace': 822.2727272727273}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 13:15:30.666 | INFO     | src.policies:train:103 - Epoch 24 / 4000\n",
      "2021-08-25 13:15:30.667 | INFO     | src.policies:train:110 - Episode 24\n",
      "2021-08-25 13:15:51.046 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:15:51.068 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 197.36363636363637, 'equality': 0.9317449018062112, 'sustainability': 493.5729859192556, 'peace': 706.1818181818181}\n",
      "2021-08-25 13:15:51.069 | INFO     | src.policies:train:122 - Mean episode return: 197.36363636363637\n",
      "2021-08-25 13:15:51.069 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.82196969696966\n",
      "2021-08-25 13:15:51.070 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:15:59.356 | INFO     | src.policies:train:159 - Total loss: 0.9995957016944885\n",
      "2021-08-25 13:15:59.356 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 197.36363636363637, 'equality': 0.9317449018062112, 'sustainability': 493.5729859192556, 'peace': 706.1818181818181}\n",
      "2021-08-25 13:15:59.404 | INFO     | src.policies:train:103 - Epoch 25 / 4000\n",
      "2021-08-25 13:15:59.405 | INFO     | src.policies:train:110 - Episode 25\n",
      "2021-08-25 13:16:19.698 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:16:19.719 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 222.27272727272728, 'equality': 0.9413273842732603, 'sustainability': 510.8915038416766, 'peace': 798.9090909090909}\n",
      "2021-08-25 13:16:19.720 | INFO     | src.policies:train:122 - Mean episode return: 222.27272727272728\n",
      "2021-08-25 13:16:19.720 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 210.31999999999996\n",
      "2021-08-25 13:16:19.721 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:16:28.012 | INFO     | src.policies:train:159 - Total loss: 1.0021605491638184\n",
      "2021-08-25 13:16:28.013 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 222.27272727272728, 'equality': 0.9413273842732603, 'sustainability': 510.8915038416766, 'peace': 798.9090909090909}\n",
      "2021-08-25 13:16:28.060 | INFO     | src.policies:train:103 - Epoch 26 / 4000\n",
      "2021-08-25 13:16:28.061 | INFO     | src.policies:train:110 - Episode 26\n",
      "2021-08-25 13:16:48.142 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:16:48.166 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 219.1818181818182, 'equality': 0.9469099958533443, 'sustainability': 495.85949477879444, 'peace': 800.3636363636364}\n",
      "2021-08-25 13:16:48.166 | INFO     | src.policies:train:122 - Mean episode return: 219.1818181818182\n",
      "2021-08-25 13:16:48.167 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 210.66083916083912\n",
      "2021-08-25 13:16:48.167 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:16:56.421 | INFO     | src.policies:train:159 - Total loss: 0.9953572750091553\n",
      "2021-08-25 13:16:56.422 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 219.1818181818182, 'equality': 0.9469099958533443, 'sustainability': 495.85949477879444, 'peace': 800.3636363636364}\n",
      "2021-08-25 13:16:56.468 | INFO     | src.policies:train:103 - Epoch 27 / 4000\n",
      "2021-08-25 13:16:56.469 | INFO     | src.policies:train:110 - Episode 27\n",
      "2021-08-25 13:17:16.890 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:17:16.915 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 199.72727272727272, 'equality': 0.912525344479817, 'sustainability': 474.8349656453242, 'peace': 688.7272727272727}\n",
      "2021-08-25 13:17:16.916 | INFO     | src.policies:train:122 - Mean episode return: 199.72727272727272\n",
      "2021-08-25 13:17:16.916 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 210.25589225589223\n",
      "2021-08-25 13:17:16.917 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:17:25.253 | INFO     | src.policies:train:159 - Total loss: 1.0006171464920044\n",
      "2021-08-25 13:17:25.254 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 199.72727272727272, 'equality': 0.912525344479817, 'sustainability': 474.8349656453242, 'peace': 688.7272727272727}\n",
      "2021-08-25 13:17:25.301 | INFO     | src.policies:train:103 - Epoch 28 / 4000\n",
      "2021-08-25 13:17:25.302 | INFO     | src.policies:train:110 - Episode 28\n",
      "2021-08-25 13:17:45.532 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:17:45.555 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 211.9090909090909, 'equality': 0.9199719199734805, 'sustainability': 482.75035269226004, 'peace': 690.5454545454545}\n",
      "2021-08-25 13:17:45.556 | INFO     | src.policies:train:122 - Mean episode return: 211.9090909090909\n",
      "2021-08-25 13:17:45.557 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 210.31493506493504\n",
      "2021-08-25 13:17:45.557 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:17:53.830 | INFO     | src.policies:train:159 - Total loss: 1.0005619525909424\n",
      "2021-08-25 13:17:53.831 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 211.9090909090909, 'equality': 0.9199719199734805, 'sustainability': 482.75035269226004, 'peace': 690.5454545454545}\n",
      "2021-08-25 13:17:53.878 | INFO     | src.policies:train:103 - Epoch 29 / 4000\n",
      "2021-08-25 13:17:53.879 | INFO     | src.policies:train:110 - Episode 29\n",
      "2021-08-25 13:18:13.262 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:18:13.284 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 208.8181818181818, 'equality': 0.9316895555481124, 'sustainability': 503.54148826512596, 'peace': 745.3636363636364}\n",
      "2021-08-25 13:18:13.285 | INFO     | src.policies:train:122 - Mean episode return: 208.8181818181818\n",
      "2021-08-25 13:18:13.285 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 210.26332288401252\n",
      "2021-08-25 13:18:13.286 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:18:21.661 | INFO     | src.policies:train:159 - Total loss: 1.0008200407028198\n",
      "2021-08-25 13:18:21.662 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 208.8181818181818, 'equality': 0.9316895555481124, 'sustainability': 503.54148826512596, 'peace': 745.3636363636364}\n",
      "2021-08-25 13:18:21.709 | INFO     | src.policies:train:103 - Epoch 30 / 4000\n",
      "2021-08-25 13:18:21.710 | INFO     | src.policies:train:110 - Episode 30\n",
      "2021-08-25 13:18:43.819 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:18:43.840 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 201.36363636363637, 'equality': 0.9230863944198012, 'sustainability': 483.4614756514786, 'peace': 705.3636363636364}\n",
      "2021-08-25 13:18:43.840 | INFO     | src.policies:train:122 - Mean episode return: 201.36363636363637\n",
      "2021-08-25 13:18:43.841 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.96666666666664\n",
      "2021-08-25 13:18:43.841 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:18:52.626 | INFO     | src.policies:train:159 - Total loss: 0.9996355175971985\n",
      "2021-08-25 13:18:52.627 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 201.36363636363637, 'equality': 0.9230863944198012, 'sustainability': 483.4614756514786, 'peace': 705.3636363636364}\n",
      "2021-08-25 13:18:52.674 | INFO     | src.policies:train:103 - Epoch 31 / 4000\n",
      "2021-08-25 13:18:52.674 | INFO     | src.policies:train:110 - Episode 31\n",
      "2021-08-25 13:19:15.131 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:19:15.154 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 201.27272727272728, 'equality': 0.9343844953614522, 'sustainability': 481.00459614865974, 'peace': 689.1818181818181}\n",
      "2021-08-25 13:19:15.155 | INFO     | src.policies:train:122 - Mean episode return: 201.27272727272728\n",
      "2021-08-25 13:19:15.155 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.68621700879763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 13:19:15.155 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:19:23.961 | INFO     | src.policies:train:159 - Total loss: 1.0068039894104004\n",
      "2021-08-25 13:19:23.961 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 201.27272727272728, 'equality': 0.9343844953614522, 'sustainability': 481.00459614865974, 'peace': 689.1818181818181}\n",
      "2021-08-25 13:19:24.008 | INFO     | src.policies:train:103 - Epoch 32 / 4000\n",
      "2021-08-25 13:19:24.008 | INFO     | src.policies:train:110 - Episode 32\n",
      "2021-08-25 13:19:45.644 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:19:45.667 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 213.0, 'equality': 0.9480076048588055, 'sustainability': 497.9819523633874, 'peace': 797.7272727272727}\n",
      "2021-08-25 13:19:45.668 | INFO     | src.policies:train:122 - Mean episode return: 213.0\n",
      "2021-08-25 13:19:45.668 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.78977272727272\n",
      "2021-08-25 13:19:45.668 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:19:54.482 | INFO     | src.policies:train:159 - Total loss: 0.9989316463470459\n",
      "2021-08-25 13:19:54.482 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 213.0, 'equality': 0.9480076048588055, 'sustainability': 497.9819523633874, 'peace': 797.7272727272727}\n",
      "2021-08-25 13:19:54.529 | INFO     | src.policies:train:103 - Epoch 33 / 4000\n",
      "2021-08-25 13:19:54.530 | INFO     | src.policies:train:110 - Episode 33\n",
      "2021-08-25 13:20:16.622 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:20:16.644 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 197.45454545454547, 'equality': 0.9434120207612713, 'sustainability': 493.57803556655364, 'peace': 763.8181818181819}\n",
      "2021-08-25 13:20:16.645 | INFO     | src.policies:train:122 - Mean episode return: 197.45454545454547\n",
      "2021-08-25 13:20:16.645 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.41597796143247\n",
      "2021-08-25 13:20:16.646 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:20:25.245 | INFO     | src.policies:train:159 - Total loss: 1.0046719312667847\n",
      "2021-08-25 13:20:25.246 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 197.45454545454547, 'equality': 0.9434120207612713, 'sustainability': 493.57803556655364, 'peace': 763.8181818181819}\n",
      "2021-08-25 13:20:25.293 | INFO     | src.policies:train:103 - Epoch 34 / 4000\n",
      "2021-08-25 13:20:25.294 | INFO     | src.policies:train:110 - Episode 34\n",
      "2021-08-25 13:20:46.651 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:20:46.673 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 210.72727272727272, 'equality': 0.9559181112252741, 'sustainability': 489.2484152947418, 'peace': 740.3636363636364}\n",
      "2021-08-25 13:20:46.674 | INFO     | src.policies:train:122 - Mean episode return: 210.72727272727272\n",
      "2021-08-25 13:20:46.674 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.45454545454544\n",
      "2021-08-25 13:20:46.675 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:20:55.293 | INFO     | src.policies:train:159 - Total loss: 1.0007920265197754\n",
      "2021-08-25 13:20:55.293 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 210.72727272727272, 'equality': 0.9559181112252741, 'sustainability': 489.2484152947418, 'peace': 740.3636363636364}\n",
      "2021-08-25 13:20:55.340 | INFO     | src.policies:train:103 - Epoch 35 / 4000\n",
      "2021-08-25 13:20:55.341 | INFO     | src.policies:train:110 - Episode 35\n",
      "2021-08-25 13:21:17.029 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:21:17.053 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 199.8181818181818, 'equality': 0.931590702292754, 'sustainability': 485.6971930074678, 'peace': 687.5454545454545}\n",
      "2021-08-25 13:21:17.053 | INFO     | src.policies:train:122 - Mean episode return: 199.8181818181818\n",
      "2021-08-25 13:21:17.054 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.17922077922077\n",
      "2021-08-25 13:21:17.054 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:21:25.886 | INFO     | src.policies:train:159 - Total loss: 1.002752423286438\n",
      "2021-08-25 13:21:25.887 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 199.8181818181818, 'equality': 0.931590702292754, 'sustainability': 485.6971930074678, 'peace': 687.5454545454545}\n",
      "2021-08-25 13:21:25.934 | INFO     | src.policies:train:103 - Epoch 36 / 4000\n",
      "2021-08-25 13:21:25.934 | INFO     | src.policies:train:110 - Episode 36\n",
      "2021-08-25 13:21:48.197 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:21:48.218 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 224.36363636363637, 'equality': 0.9440106085173123, 'sustainability': 497.78957135968415, 'peace': 804.6363636363636}\n",
      "2021-08-25 13:21:48.219 | INFO     | src.policies:train:122 - Mean episode return: 224.36363636363637\n",
      "2021-08-25 13:21:48.219 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.60101010101008\n",
      "2021-08-25 13:21:48.220 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:21:57.072 | INFO     | src.policies:train:159 - Total loss: 0.997032880783081\n",
      "2021-08-25 13:21:57.072 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 224.36363636363637, 'equality': 0.9440106085173123, 'sustainability': 497.78957135968415, 'peace': 804.6363636363636}\n",
      "2021-08-25 13:21:57.120 | INFO     | src.policies:train:103 - Epoch 37 / 4000\n",
      "2021-08-25 13:21:57.120 | INFO     | src.policies:train:110 - Episode 37\n",
      "2021-08-25 13:22:18.641 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:22:18.665 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 215.0, 'equality': 0.9699404189896225, 'sustainability': 495.7938609738674, 'peace': 794.0909090909091}\n",
      "2021-08-25 13:22:18.665 | INFO     | src.policies:train:122 - Mean episode return: 215.0\n",
      "2021-08-25 13:22:18.666 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.74692874692875\n",
      "2021-08-25 13:22:18.666 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:22:27.743 | INFO     | src.policies:train:159 - Total loss: 0.9988768696784973\n",
      "2021-08-25 13:22:27.744 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 215.0, 'equality': 0.9699404189896225, 'sustainability': 495.7938609738674, 'peace': 794.0909090909091}\n",
      "2021-08-25 13:22:27.790 | INFO     | src.policies:train:103 - Epoch 38 / 4000\n",
      "2021-08-25 13:22:27.791 | INFO     | src.policies:train:110 - Episode 38\n",
      "2021-08-25 13:22:50.030 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:22:50.054 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 215.63636363636363, 'equality': 0.9356124482612369, 'sustainability': 489.9413331392647, 'peace': 788.7272727272727}\n",
      "2021-08-25 13:22:50.054 | INFO     | src.policies:train:122 - Mean episode return: 215.63636363636363\n",
      "2021-08-25 13:22:50.055 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.90191387559807\n",
      "2021-08-25 13:22:50.055 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:22:59.088 | INFO     | src.policies:train:159 - Total loss: 1.0024000406265259\n",
      "2021-08-25 13:22:59.089 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 215.63636363636363, 'equality': 0.9356124482612369, 'sustainability': 489.9413331392647, 'peace': 788.7272727272727}\n",
      "2021-08-25 13:22:59.138 | INFO     | src.policies:train:103 - Epoch 39 / 4000\n",
      "2021-08-25 13:22:59.138 | INFO     | src.policies:train:110 - Episode 39\n",
      "2021-08-25 13:23:22.570 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 13:23:22.596 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 212.27272727272728, 'equality': 0.9247031341264415, 'sustainability': 497.69277664037327, 'peace': 649.4545454545455}\n",
      "2021-08-25 13:23:22.597 | INFO     | src.policies:train:122 - Mean episode return: 212.27272727272728\n",
      "2021-08-25 13:23:22.597 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.96270396270396\n",
      "2021-08-25 13:23:22.598 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:23:31.632 | INFO     | src.policies:train:159 - Total loss: 1.001400351524353\n",
      "2021-08-25 13:23:31.633 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 212.27272727272728, 'equality': 0.9247031341264415, 'sustainability': 497.69277664037327, 'peace': 649.4545454545455}\n",
      "2021-08-25 13:23:31.680 | INFO     | src.policies:train:103 - Epoch 40 / 4000\n",
      "2021-08-25 13:23:31.681 | INFO     | src.policies:train:110 - Episode 40\n",
      "2021-08-25 13:23:54.392 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:23:54.417 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 209.27272727272728, 'equality': 0.9448700734550022, 'sustainability': 502.9355983333528, 'peace': 734.2727272727273}\n",
      "2021-08-25 13:23:54.418 | INFO     | src.policies:train:122 - Mean episode return: 209.27272727272728\n",
      "2021-08-25 13:23:54.419 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.9454545454545\n",
      "2021-08-25 13:23:54.419 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:24:03.476 | INFO     | src.policies:train:159 - Total loss: 1.0016412734985352\n",
      "2021-08-25 13:24:03.477 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 209.27272727272728, 'equality': 0.9448700734550022, 'sustainability': 502.9355983333528, 'peace': 734.2727272727273}\n",
      "2021-08-25 13:24:03.526 | INFO     | src.policies:train:103 - Epoch 41 / 4000\n",
      "2021-08-25 13:24:03.527 | INFO     | src.policies:train:110 - Episode 41\n",
      "2021-08-25 13:24:25.794 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:24:25.816 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 218.54545454545453, 'equality': 0.9024353350494926, 'sustainability': 482.2784767589299, 'peace': 697.7272727272727}\n",
      "2021-08-25 13:24:25.817 | INFO     | src.policies:train:122 - Mean episode return: 218.54545454545453\n",
      "2021-08-25 13:24:25.817 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 210.15521064301547\n",
      "2021-08-25 13:24:25.817 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:24:34.595 | INFO     | src.policies:train:159 - Total loss: 1.0007470846176147\n",
      "2021-08-25 13:24:34.596 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 218.54545454545453, 'equality': 0.9024353350494926, 'sustainability': 482.2784767589299, 'peace': 697.7272727272727}\n",
      "2021-08-25 13:24:34.645 | INFO     | src.policies:train:103 - Epoch 42 / 4000\n",
      "2021-08-25 13:24:34.645 | INFO     | src.policies:train:110 - Episode 42\n",
      "2021-08-25 13:24:56.344 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:24:56.367 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 209.27272727272728, 'equality': 0.9541110496810261, 'sustainability': 503.18718168671, 'peace': 720.7272727272727}\n",
      "2021-08-25 13:24:56.368 | INFO     | src.policies:train:122 - Mean episode return: 209.27272727272728\n",
      "2021-08-25 13:24:56.369 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 210.1341991341991\n",
      "2021-08-25 13:24:56.369 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:25:05.169 | INFO     | src.policies:train:159 - Total loss: 0.9979462623596191\n",
      "2021-08-25 13:25:05.169 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 209.27272727272728, 'equality': 0.9541110496810261, 'sustainability': 503.18718168671, 'peace': 720.7272727272727}\n",
      "2021-08-25 13:25:05.217 | INFO     | src.policies:train:103 - Epoch 43 / 4000\n",
      "2021-08-25 13:25:05.217 | INFO     | src.policies:train:110 - Episode 43\n",
      "2021-08-25 13:25:27.125 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:25:27.148 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 203.45454545454547, 'equality': 0.9187586318970111, 'sustainability': 491.3924448186062, 'peace': 693.1818181818181}\n",
      "2021-08-25 13:25:27.149 | INFO     | src.policies:train:122 - Mean episode return: 203.45454545454547\n",
      "2021-08-25 13:25:27.149 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.97885835095136\n",
      "2021-08-25 13:25:27.150 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:25:36.138 | INFO     | src.policies:train:159 - Total loss: 0.9996159076690674\n",
      "2021-08-25 13:25:36.139 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 203.45454545454547, 'equality': 0.9187586318970111, 'sustainability': 491.3924448186062, 'peace': 693.1818181818181}\n",
      "2021-08-25 13:25:36.187 | INFO     | src.policies:train:103 - Epoch 44 / 4000\n",
      "2021-08-25 13:25:36.188 | INFO     | src.policies:train:110 - Episode 44\n",
      "2021-08-25 13:25:58.570 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:25:58.596 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 209.8181818181818, 'equality': 0.9430439577764487, 'sustainability': 499.5713546211406, 'peace': 650.1818181818181}\n",
      "2021-08-25 13:25:58.598 | INFO     | src.policies:train:122 - Mean episode return: 209.8181818181818\n",
      "2021-08-25 13:25:58.598 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.97520661157023\n",
      "2021-08-25 13:25:58.599 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:26:07.679 | INFO     | src.policies:train:159 - Total loss: 1.007609486579895\n",
      "2021-08-25 13:26:07.680 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 209.8181818181818, 'equality': 0.9430439577764487, 'sustainability': 499.5713546211406, 'peace': 650.1818181818181}\n",
      "2021-08-25 13:26:07.729 | INFO     | src.policies:train:103 - Epoch 45 / 4000\n",
      "2021-08-25 13:26:07.729 | INFO     | src.policies:train:110 - Episode 45\n",
      "2021-08-25 13:26:31.164 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:26:31.187 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 208.45454545454547, 'equality': 0.9312532212676673, 'sustainability': 500.88894334105566, 'peace': 716.3636363636364}\n",
      "2021-08-25 13:26:31.188 | INFO     | src.policies:train:122 - Mean episode return: 208.45454545454547\n",
      "2021-08-25 13:26:31.188 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.94141414141413\n",
      "2021-08-25 13:26:31.189 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:26:40.521 | INFO     | src.policies:train:159 - Total loss: 0.9974214434623718\n",
      "2021-08-25 13:26:40.522 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 208.45454545454547, 'equality': 0.9312532212676673, 'sustainability': 500.88894334105566, 'peace': 716.3636363636364}\n",
      "2021-08-25 13:26:40.571 | INFO     | src.policies:train:103 - Epoch 46 / 4000\n",
      "2021-08-25 13:26:40.572 | INFO     | src.policies:train:110 - Episode 46\n",
      "2021-08-25 13:27:03.997 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:27:04.026 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 212.27272727272728, 'equality': 0.937161767569843, 'sustainability': 497.7415083601114, 'peace': 640.7272727272727}\n",
      "2021-08-25 13:27:04.027 | INFO     | src.policies:train:122 - Mean episode return: 212.27272727272728\n",
      "2021-08-25 13:27:04.027 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.9920948616601\n",
      "2021-08-25 13:27:04.028 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:27:13.340 | INFO     | src.policies:train:159 - Total loss: 0.9988415241241455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 13:27:13.340 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 212.27272727272728, 'equality': 0.937161767569843, 'sustainability': 497.7415083601114, 'peace': 640.7272727272727}\n",
      "2021-08-25 13:27:13.391 | INFO     | src.policies:train:103 - Epoch 47 / 4000\n",
      "2021-08-25 13:27:13.391 | INFO     | src.policies:train:110 - Episode 47\n",
      "2021-08-25 13:27:35.457 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:27:35.484 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 219.9090909090909, 'equality': 0.9539253635996482, 'sustainability': 487.9896388131372, 'peace': 768.8181818181819}\n",
      "2021-08-25 13:27:35.485 | INFO     | src.policies:train:122 - Mean episode return: 219.9090909090909\n",
      "2021-08-25 13:27:35.485 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 210.20309477756285\n",
      "2021-08-25 13:27:35.486 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:27:44.547 | INFO     | src.policies:train:159 - Total loss: 1.0042535066604614\n",
      "2021-08-25 13:27:44.548 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 219.9090909090909, 'equality': 0.9539253635996482, 'sustainability': 487.9896388131372, 'peace': 768.8181818181819}\n",
      "2021-08-25 13:27:44.599 | INFO     | src.policies:train:103 - Epoch 48 / 4000\n",
      "2021-08-25 13:27:44.600 | INFO     | src.policies:train:110 - Episode 48\n",
      "2021-08-25 13:28:07.954 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:28:07.978 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 214.0, 'equality': 0.9327257279691681, 'sustainability': 514.1637524426329, 'peace': 701.7272727272727}\n",
      "2021-08-25 13:28:07.979 | INFO     | src.policies:train:122 - Mean episode return: 214.0\n",
      "2021-08-25 13:28:07.979 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 210.28219696969697\n",
      "2021-08-25 13:28:07.980 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:28:17.048 | INFO     | src.policies:train:159 - Total loss: 1.0004335641860962\n",
      "2021-08-25 13:28:17.049 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 214.0, 'equality': 0.9327257279691681, 'sustainability': 514.1637524426329, 'peace': 701.7272727272727}\n",
      "2021-08-25 13:28:17.097 | INFO     | src.policies:train:103 - Epoch 49 / 4000\n",
      "2021-08-25 13:28:17.098 | INFO     | src.policies:train:110 - Episode 49\n",
      "2021-08-25 13:28:39.068 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:28:39.091 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 208.45454545454547, 'equality': 0.9330769535754455, 'sustainability': 492.5558668943042, 'peace': 746.9090909090909}\n",
      "2021-08-25 13:28:39.092 | INFO     | src.policies:train:122 - Mean episode return: 208.45454545454547\n",
      "2021-08-25 13:28:39.092 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 210.24489795918367\n",
      "2021-08-25 13:28:39.093 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:28:48.180 | INFO     | src.policies:train:159 - Total loss: 1.000566005706787\n",
      "2021-08-25 13:28:48.181 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 208.45454545454547, 'equality': 0.9330769535754455, 'sustainability': 492.5558668943042, 'peace': 746.9090909090909}\n",
      "2021-08-25 13:28:48.230 | INFO     | src.policies:train:103 - Epoch 50 / 4000\n",
      "2021-08-25 13:28:48.231 | INFO     | src.policies:train:110 - Episode 50\n",
      "2021-08-25 13:29:11.772 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:29:11.797 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 215.1818181818182, 'equality': 0.940392518340431, 'sustainability': 486.2688817101664, 'peace': 800.6363636363636}\n",
      "2021-08-25 13:29:11.798 | INFO     | src.policies:train:122 - Mean episode return: 215.1818181818182\n",
      "2021-08-25 13:29:11.798 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 210.34363636363636\n",
      "2021-08-25 13:29:11.799 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:29:20.809 | INFO     | src.policies:train:159 - Total loss: 1.0046511888504028\n",
      "2021-08-25 13:29:20.810 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 215.1818181818182, 'equality': 0.940392518340431, 'sustainability': 486.2688817101664, 'peace': 800.6363636363636}\n",
      "2021-08-25 13:29:20.858 | INFO     | src.policies:train:103 - Epoch 51 / 4000\n",
      "2021-08-25 13:29:20.859 | INFO     | src.policies:train:110 - Episode 51\n",
      "2021-08-25 13:29:43.911 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:29:43.934 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 188.27272727272728, 'equality': 0.9158070321777839, 'sustainability': 483.023715424968, 'peace': 670.7272727272727}\n",
      "2021-08-25 13:29:43.934 | INFO     | src.policies:train:122 - Mean episode return: 188.27272727272728\n",
      "2021-08-25 13:29:43.935 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.9108734402852\n",
      "2021-08-25 13:29:43.935 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:29:52.980 | INFO     | src.policies:train:159 - Total loss: 0.9970273971557617\n",
      "2021-08-25 13:29:52.981 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 188.27272727272728, 'equality': 0.9158070321777839, 'sustainability': 483.023715424968, 'peace': 670.7272727272727}\n",
      "2021-08-25 13:29:53.030 | INFO     | src.policies:train:103 - Epoch 52 / 4000\n",
      "2021-08-25 13:29:53.030 | INFO     | src.policies:train:110 - Episode 52\n",
      "2021-08-25 13:30:15.967 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:30:15.990 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 224.8181818181818, 'equality': 0.9425798625162192, 'sustainability': 476.64773711629465, 'peace': 658.8181818181819}\n",
      "2021-08-25 13:30:15.991 | INFO     | src.policies:train:122 - Mean episode return: 224.8181818181818\n",
      "2021-08-25 13:30:15.991 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 210.19755244755245\n",
      "2021-08-25 13:30:15.992 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:30:25.027 | INFO     | src.policies:train:159 - Total loss: 0.9949914216995239\n",
      "2021-08-25 13:30:25.028 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 224.8181818181818, 'equality': 0.9425798625162192, 'sustainability': 476.64773711629465, 'peace': 658.8181818181819}\n",
      "2021-08-25 13:30:25.076 | INFO     | src.policies:train:103 - Epoch 53 / 4000\n",
      "2021-08-25 13:30:25.077 | INFO     | src.policies:train:110 - Episode 53\n",
      "2021-08-25 13:30:47.700 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:30:47.726 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 210.9090909090909, 'equality': 0.9197492163025127, 'sustainability': 480.9332435358052, 'peace': 718.9090909090909}\n",
      "2021-08-25 13:30:47.726 | INFO     | src.policies:train:122 - Mean episode return: 210.9090909090909\n",
      "2021-08-25 13:30:47.727 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 210.21097770154373\n",
      "2021-08-25 13:30:47.727 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:30:57.271 | INFO     | src.policies:train:159 - Total loss: 0.9993852376937866\n",
      "2021-08-25 13:30:57.272 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 210.9090909090909, 'equality': 0.9197492163025127, 'sustainability': 480.9332435358052, 'peace': 718.9090909090909}\n",
      "2021-08-25 13:30:57.322 | INFO     | src.policies:train:103 - Epoch 54 / 4000\n",
      "2021-08-25 13:30:57.323 | INFO     | src.policies:train:110 - Episode 54\n",
      "2021-08-25 13:31:21.828 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:31:21.856 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 217.8181818181818, 'equality': 0.9244194870252614, 'sustainability': 489.18477372369665, 'peace': 717.8181818181819}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 13:31:21.857 | INFO     | src.policies:train:122 - Mean episode return: 217.8181818181818\n",
      "2021-08-25 13:31:21.857 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 210.35185185185185\n",
      "2021-08-25 13:31:21.858 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:31:31.444 | INFO     | src.policies:train:159 - Total loss: 1.000842809677124\n",
      "2021-08-25 13:31:31.445 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 217.8181818181818, 'equality': 0.9244194870252614, 'sustainability': 489.18477372369665, 'peace': 717.8181818181819}\n",
      "2021-08-25 13:31:31.495 | INFO     | src.policies:train:103 - Epoch 55 / 4000\n",
      "2021-08-25 13:31:31.495 | INFO     | src.policies:train:110 - Episode 55\n",
      "2021-08-25 13:31:54.230 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:31:54.255 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 196.36363636363637, 'equality': 0.9030303030323437, 'sustainability': 479.37800590856585, 'peace': 659.5454545454545}\n",
      "2021-08-25 13:31:54.256 | INFO     | src.policies:train:122 - Mean episode return: 196.36363636363637\n",
      "2021-08-25 13:31:54.256 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 210.097520661157\n",
      "2021-08-25 13:31:54.257 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:32:03.295 | INFO     | src.policies:train:159 - Total loss: 0.9999598860740662\n",
      "2021-08-25 13:32:03.295 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 196.36363636363637, 'equality': 0.9030303030323437, 'sustainability': 479.37800590856585, 'peace': 659.5454545454545}\n",
      "2021-08-25 13:32:03.345 | INFO     | src.policies:train:103 - Epoch 56 / 4000\n",
      "2021-08-25 13:32:03.346 | INFO     | src.policies:train:110 - Episode 56\n",
      "2021-08-25 13:32:25.251 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:32:25.276 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 195.54545454545453, 'equality': 0.8730400236703216, 'sustainability': 466.52774818388446, 'peace': 697.5454545454545}\n",
      "2021-08-25 13:32:25.276 | INFO     | src.policies:train:122 - Mean episode return: 195.54545454545453\n",
      "2021-08-25 13:32:25.277 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.83766233766235\n",
      "2021-08-25 13:32:25.277 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:32:34.316 | INFO     | src.policies:train:159 - Total loss: 0.9981557130813599\n",
      "2021-08-25 13:32:34.317 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 195.54545454545453, 'equality': 0.8730400236703216, 'sustainability': 466.52774818388446, 'peace': 697.5454545454545}\n",
      "2021-08-25 13:32:34.366 | INFO     | src.policies:train:103 - Epoch 57 / 4000\n",
      "2021-08-25 13:32:34.367 | INFO     | src.policies:train:110 - Episode 57\n",
      "2021-08-25 13:32:55.769 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:32:55.792 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 206.8181818181818, 'equality': 0.923916083917604, 'sustainability': 496.3858530489087, 'peace': 710.1818181818181}\n",
      "2021-08-25 13:32:55.793 | INFO     | src.policies:train:122 - Mean episode return: 206.8181818181818\n",
      "2021-08-25 13:32:55.793 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.78468899521533\n",
      "2021-08-25 13:32:55.794 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:33:04.844 | INFO     | src.policies:train:159 - Total loss: 0.9995384812355042\n",
      "2021-08-25 13:33:04.845 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 206.8181818181818, 'equality': 0.923916083917604, 'sustainability': 496.3858530489087, 'peace': 710.1818181818181}\n",
      "2021-08-25 13:33:04.893 | INFO     | src.policies:train:103 - Epoch 58 / 4000\n",
      "2021-08-25 13:33:04.894 | INFO     | src.policies:train:110 - Episode 58\n",
      "2021-08-25 13:33:27.355 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:33:27.380 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 211.0, 'equality': 0.9566017782312365, 'sustainability': 496.93357105655656, 'peace': 774.1818181818181}\n",
      "2021-08-25 13:33:27.381 | INFO     | src.policies:train:122 - Mean episode return: 211.0\n",
      "2021-08-25 13:33:27.382 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.80564263322887\n",
      "2021-08-25 13:33:27.382 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:33:36.705 | INFO     | src.policies:train:159 - Total loss: 0.9960088133811951\n",
      "2021-08-25 13:33:36.706 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 211.0, 'equality': 0.9566017782312365, 'sustainability': 496.93357105655656, 'peace': 774.1818181818181}\n",
      "2021-08-25 13:33:36.755 | INFO     | src.policies:train:103 - Epoch 59 / 4000\n",
      "2021-08-25 13:33:36.756 | INFO     | src.policies:train:110 - Episode 59\n",
      "2021-08-25 13:33:58.695 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:33:58.723 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 205.0, 'equality': 0.9107438016546917, 'sustainability': 523.9582917636579, 'peace': 693.3636363636364}\n",
      "2021-08-25 13:33:58.724 | INFO     | src.policies:train:122 - Mean episode return: 205.0\n",
      "2021-08-25 13:33:58.724 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.72419106317415\n",
      "2021-08-25 13:33:58.725 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:34:08.067 | INFO     | src.policies:train:159 - Total loss: 1.0031304359436035\n",
      "2021-08-25 13:34:08.068 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 205.0, 'equality': 0.9107438016546917, 'sustainability': 523.9582917636579, 'peace': 693.3636363636364}\n",
      "2021-08-25 13:34:08.117 | INFO     | src.policies:train:103 - Epoch 60 / 4000\n",
      "2021-08-25 13:34:08.118 | INFO     | src.policies:train:110 - Episode 60\n",
      "2021-08-25 13:34:30.523 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:34:30.547 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 208.0, 'equality': 0.8801652892585791, 'sustainability': 475.0603464679218, 'peace': 743.0}\n",
      "2021-08-25 13:34:30.548 | INFO     | src.policies:train:122 - Mean episode return: 208.0\n",
      "2021-08-25 13:34:30.549 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.69545454545457\n",
      "2021-08-25 13:34:30.549 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:34:39.622 | INFO     | src.policies:train:159 - Total loss: 1.002260684967041\n",
      "2021-08-25 13:34:39.623 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 208.0, 'equality': 0.8801652892585791, 'sustainability': 475.0603464679218, 'peace': 743.0}\n",
      "2021-08-25 13:34:39.673 | INFO     | src.policies:train:103 - Epoch 61 / 4000\n",
      "2021-08-25 13:34:39.673 | INFO     | src.policies:train:110 - Episode 61\n",
      "2021-08-25 13:35:01.872 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:35:01.896 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 193.72727272727272, 'equality': 0.9249178789316813, 'sustainability': 445.1004284890915, 'peace': 694.5454545454545}\n",
      "2021-08-25 13:35:01.897 | INFO     | src.policies:train:122 - Mean episode return: 193.72727272727272\n",
      "2021-08-25 13:35:01.897 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.43368107302535\n",
      "2021-08-25 13:35:01.898 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:35:10.939 | INFO     | src.policies:train:159 - Total loss: 0.9981707334518433\n",
      "2021-08-25 13:35:10.940 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 193.72727272727272, 'equality': 0.9249178789316813, 'sustainability': 445.1004284890915, 'peace': 694.5454545454545}\n",
      "2021-08-25 13:35:10.989 | INFO     | src.policies:train:103 - Epoch 62 / 4000\n",
      "2021-08-25 13:35:10.989 | INFO     | src.policies:train:110 - Episode 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 13:35:33.107 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:35:33.132 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 202.8181818181818, 'equality': 0.8948698097083478, 'sustainability': 483.87186448110066, 'peace': 703.5454545454545}\n",
      "2021-08-25 13:35:33.132 | INFO     | src.policies:train:122 - Mean episode return: 202.8181818181818\n",
      "2021-08-25 13:35:33.133 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.32697947214078\n",
      "2021-08-25 13:35:33.133 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:35:42.191 | INFO     | src.policies:train:159 - Total loss: 1.004791021347046\n",
      "2021-08-25 13:35:42.192 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 202.8181818181818, 'equality': 0.8948698097083478, 'sustainability': 483.87186448110066, 'peace': 703.5454545454545}\n",
      "2021-08-25 13:35:42.240 | INFO     | src.policies:train:103 - Epoch 63 / 4000\n",
      "2021-08-25 13:35:42.241 | INFO     | src.policies:train:110 - Episode 63\n",
      "2021-08-25 13:36:04.774 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:36:04.797 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 198.0, 'equality': 0.9104265798499368, 'sustainability': 495.9052504513218, 'peace': 641.2727272727273}\n",
      "2021-08-25 13:36:04.797 | INFO     | src.policies:train:122 - Mean episode return: 198.0\n",
      "2021-08-25 13:36:04.798 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.14718614718615\n",
      "2021-08-25 13:36:04.798 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:36:13.922 | INFO     | src.policies:train:159 - Total loss: 1.00167977809906\n",
      "2021-08-25 13:36:13.923 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 198.0, 'equality': 0.9104265798499368, 'sustainability': 495.9052504513218, 'peace': 641.2727272727273}\n",
      "2021-08-25 13:36:13.972 | INFO     | src.policies:train:103 - Epoch 64 / 4000\n",
      "2021-08-25 13:36:13.973 | INFO     | src.policies:train:110 - Episode 64\n",
      "2021-08-25 13:36:35.684 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:36:35.709 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 220.9090909090909, 'equality': 0.944930789376264, 'sustainability': 490.36772751002775, 'peace': 736.6363636363636}\n",
      "2021-08-25 13:36:35.710 | INFO     | src.policies:train:122 - Mean episode return: 220.9090909090909\n",
      "2021-08-25 13:36:35.711 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.3309659090909\n",
      "2021-08-25 13:36:35.711 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:36:44.792 | INFO     | src.policies:train:159 - Total loss: 1.0086371898651123\n",
      "2021-08-25 13:36:44.793 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 220.9090909090909, 'equality': 0.944930789376264, 'sustainability': 490.36772751002775, 'peace': 736.6363636363636}\n",
      "2021-08-25 13:36:44.842 | INFO     | src.policies:train:103 - Epoch 65 / 4000\n",
      "2021-08-25 13:36:44.842 | INFO     | src.policies:train:110 - Episode 65\n",
      "2021-08-25 13:37:08.068 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:37:08.092 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 197.36363636363637, 'equality': 0.913403961309966, 'sustainability': 501.5943823641979, 'peace': 663.1818181818181}\n",
      "2021-08-25 13:37:08.093 | INFO     | src.policies:train:122 - Mean episode return: 197.36363636363637\n",
      "2021-08-25 13:37:08.093 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.14685314685315\n",
      "2021-08-25 13:37:08.094 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:37:17.271 | INFO     | src.policies:train:159 - Total loss: 0.996584951877594\n",
      "2021-08-25 13:37:17.272 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 197.36363636363637, 'equality': 0.913403961309966, 'sustainability': 501.5943823641979, 'peace': 663.1818181818181}\n",
      "2021-08-25 13:37:17.320 | INFO     | src.policies:train:103 - Epoch 66 / 4000\n",
      "2021-08-25 13:37:17.321 | INFO     | src.policies:train:110 - Episode 66\n",
      "2021-08-25 13:37:39.346 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:37:39.371 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 208.54545454545453, 'equality': 0.9220099865276609, 'sustainability': 490.56078407160953, 'peace': 659.0909090909091}\n",
      "2021-08-25 13:37:39.372 | INFO     | src.policies:train:122 - Mean episode return: 208.54545454545453\n",
      "2021-08-25 13:37:39.372 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.13774104683193\n",
      "2021-08-25 13:37:39.373 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:37:48.454 | INFO     | src.policies:train:159 - Total loss: 1.000347375869751\n",
      "2021-08-25 13:37:48.455 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 208.54545454545453, 'equality': 0.9220099865276609, 'sustainability': 490.56078407160953, 'peace': 659.0909090909091}\n",
      "2021-08-25 13:37:48.505 | INFO     | src.policies:train:103 - Epoch 67 / 4000\n",
      "2021-08-25 13:37:48.505 | INFO     | src.policies:train:110 - Episode 67\n",
      "2021-08-25 13:38:10.741 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:38:10.763 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 190.63636363636363, 'equality': 0.9257814193452598, 'sustainability': 490.2483973450971, 'peace': 673.9090909090909}\n",
      "2021-08-25 13:38:10.764 | INFO     | src.policies:train:122 - Mean episode return: 190.63636363636363\n",
      "2021-08-25 13:38:10.765 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.86160108548168\n",
      "2021-08-25 13:38:10.765 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:38:19.836 | INFO     | src.policies:train:159 - Total loss: 0.9960511922836304\n",
      "2021-08-25 13:38:19.836 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 190.63636363636363, 'equality': 0.9257814193452598, 'sustainability': 490.2483973450971, 'peace': 673.9090909090909}\n",
      "2021-08-25 13:38:19.885 | INFO     | src.policies:train:103 - Epoch 68 / 4000\n",
      "2021-08-25 13:38:19.886 | INFO     | src.policies:train:110 - Episode 68\n",
      "2021-08-25 13:38:42.416 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:38:42.438 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 189.36363636363637, 'equality': 0.9097455592914558, 'sustainability': 485.22114847047266, 'peace': 707.6363636363636}\n",
      "2021-08-25 13:38:42.438 | INFO     | src.policies:train:122 - Mean episode return: 189.36363636363637\n",
      "2021-08-25 13:38:42.439 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.57486631016042\n",
      "2021-08-25 13:38:42.440 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:38:51.763 | INFO     | src.policies:train:159 - Total loss: 0.99872887134552\n",
      "2021-08-25 13:38:51.764 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 189.36363636363637, 'equality': 0.9097455592914558, 'sustainability': 485.22114847047266, 'peace': 707.6363636363636}\n",
      "2021-08-25 13:38:51.814 | INFO     | src.policies:train:103 - Epoch 69 / 4000\n",
      "2021-08-25 13:38:51.815 | INFO     | src.policies:train:110 - Episode 69\n",
      "2021-08-25 13:39:14.462 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:39:14.485 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 199.8181818181818, 'equality': 0.9262966333045269, 'sustainability': 466.8555455640329, 'peace': 701.5454545454545}\n",
      "2021-08-25 13:39:14.486 | INFO     | src.policies:train:122 - Mean episode return: 199.8181818181818\n",
      "2021-08-25 13:39:14.486 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.4479578392622\n",
      "2021-08-25 13:39:14.487 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 13:39:23.815 | INFO     | src.policies:train:159 - Total loss: 1.0009381771087646\n",
      "2021-08-25 13:39:23.815 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 199.8181818181818, 'equality': 0.9262966333045269, 'sustainability': 466.8555455640329, 'peace': 701.5454545454545}\n",
      "2021-08-25 13:39:23.865 | INFO     | src.policies:train:103 - Epoch 70 / 4000\n",
      "2021-08-25 13:39:23.866 | INFO     | src.policies:train:110 - Episode 70\n",
      "2021-08-25 13:39:46.689 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:39:46.717 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 213.45454545454547, 'equality': 0.9468019203974988, 'sustainability': 494.0652500967135, 'peace': 763.9090909090909}\n",
      "2021-08-25 13:39:46.718 | INFO     | src.policies:train:122 - Mean episode return: 213.45454545454547\n",
      "2021-08-25 13:39:46.718 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.5194805194805\n",
      "2021-08-25 13:39:46.719 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:39:55.714 | INFO     | src.policies:train:159 - Total loss: 0.9917696118354797\n",
      "2021-08-25 13:39:55.715 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 213.45454545454547, 'equality': 0.9468019203974988, 'sustainability': 494.0652500967135, 'peace': 763.9090909090909}\n",
      "2021-08-25 13:39:55.764 | INFO     | src.policies:train:103 - Epoch 71 / 4000\n",
      "2021-08-25 13:39:55.764 | INFO     | src.policies:train:110 - Episode 71\n",
      "2021-08-25 13:40:17.447 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:40:17.469 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 190.54545454545453, 'equality': 0.9443095072878143, 'sustainability': 465.80393850295036, 'peace': 670.8181818181819}\n",
      "2021-08-25 13:40:17.470 | INFO     | src.policies:train:122 - Mean episode return: 190.54545454545453\n",
      "2021-08-25 13:40:17.471 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.2663252240717\n",
      "2021-08-25 13:40:17.471 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:40:26.346 | INFO     | src.policies:train:159 - Total loss: 1.0002104043960571\n",
      "2021-08-25 13:40:26.346 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 190.54545454545453, 'equality': 0.9443095072878143, 'sustainability': 465.80393850295036, 'peace': 670.8181818181819}\n",
      "2021-08-25 13:40:26.394 | INFO     | src.policies:train:103 - Epoch 72 / 4000\n",
      "2021-08-25 13:40:26.395 | INFO     | src.policies:train:110 - Episode 72\n",
      "2021-08-25 13:40:47.867 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:40:47.890 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 197.63636363636363, 'equality': 0.9074182487265322, 'sustainability': 515.0265055095552, 'peace': 742.3636363636364}\n",
      "2021-08-25 13:40:47.891 | INFO     | src.policies:train:122 - Mean episode return: 197.63636363636363\n",
      "2021-08-25 13:40:47.891 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.11868686868686\n",
      "2021-08-25 13:40:47.892 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:40:56.711 | INFO     | src.policies:train:159 - Total loss: 0.9977312088012695\n",
      "2021-08-25 13:40:56.712 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 197.63636363636363, 'equality': 0.9074182487265322, 'sustainability': 515.0265055095552, 'peace': 742.3636363636364}\n",
      "2021-08-25 13:40:56.759 | INFO     | src.policies:train:103 - Epoch 73 / 4000\n",
      "2021-08-25 13:40:56.760 | INFO     | src.policies:train:110 - Episode 73\n",
      "2021-08-25 13:41:19.522 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:41:19.548 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 200.54545454545453, 'equality': 0.8976345504018455, 'sustainability': 481.45001896664945, 'peace': 725.3636363636364}\n",
      "2021-08-25 13:41:19.548 | INFO     | src.policies:train:122 - Mean episode return: 200.54545454545453\n",
      "2021-08-25 13:41:19.549 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.01494396014942\n",
      "2021-08-25 13:41:19.549 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:41:28.891 | INFO     | src.policies:train:159 - Total loss: 0.9989869594573975\n",
      "2021-08-25 13:41:28.892 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 200.54545454545453, 'equality': 0.8976345504018455, 'sustainability': 481.45001896664945, 'peace': 725.3636363636364}\n",
      "2021-08-25 13:41:28.944 | INFO     | src.policies:train:103 - Epoch 74 / 4000\n",
      "2021-08-25 13:41:28.944 | INFO     | src.policies:train:110 - Episode 74\n",
      "2021-08-25 13:41:52.140 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:41:52.165 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 213.8181818181818, 'equality': 0.9394712430438414, 'sustainability': 493.6436946469378, 'peace': 772.2727272727273}\n",
      "2021-08-25 13:41:52.166 | INFO     | src.policies:train:122 - Mean episode return: 213.8181818181818\n",
      "2021-08-25 13:41:52.166 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.0933660933661\n",
      "2021-08-25 13:41:52.167 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:42:01.439 | INFO     | src.policies:train:159 - Total loss: 1.0007433891296387\n",
      "2021-08-25 13:42:01.440 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 213.8181818181818, 'equality': 0.9394712430438414, 'sustainability': 493.6436946469378, 'peace': 772.2727272727273}\n",
      "2021-08-25 13:42:01.490 | INFO     | src.policies:train:103 - Epoch 75 / 4000\n",
      "2021-08-25 13:42:01.490 | INFO     | src.policies:train:110 - Episode 75\n",
      "2021-08-25 13:42:24.675 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:42:24.697 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 212.27272727272728, 'equality': 0.9268833949790367, 'sustainability': 484.44530123822483, 'peace': 705.4545454545455}\n",
      "2021-08-25 13:42:24.697 | INFO     | src.policies:train:122 - Mean episode return: 212.27272727272728\n",
      "2021-08-25 13:42:24.698 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.14909090909092\n",
      "2021-08-25 13:42:24.698 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:42:34.019 | INFO     | src.policies:train:159 - Total loss: 1.0006242990493774\n",
      "2021-08-25 13:42:34.020 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 212.27272727272728, 'equality': 0.9268833949790367, 'sustainability': 484.44530123822483, 'peace': 705.4545454545455}\n",
      "2021-08-25 13:42:34.071 | INFO     | src.policies:train:103 - Epoch 76 / 4000\n",
      "2021-08-25 13:42:34.072 | INFO     | src.policies:train:110 - Episode 76\n",
      "2021-08-25 13:42:56.844 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:42:56.869 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 209.54545454545453, 'equality': 0.9533819759425481, 'sustainability': 482.2692068461342, 'peace': 735.2727272727273}\n",
      "2021-08-25 13:42:56.870 | INFO     | src.policies:train:122 - Mean episode return: 209.54545454545453\n",
      "2021-08-25 13:42:56.871 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.16746411483254\n",
      "2021-08-25 13:42:56.871 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:43:05.966 | INFO     | src.policies:train:159 - Total loss: 0.9966504573822021\n",
      "2021-08-25 13:43:05.966 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 209.54545454545453, 'equality': 0.9533819759425481, 'sustainability': 482.2692068461342, 'peace': 735.2727272727273}\n",
      "2021-08-25 13:43:06.017 | INFO     | src.policies:train:103 - Epoch 77 / 4000\n",
      "2021-08-25 13:43:06.018 | INFO     | src.policies:train:110 - Episode 77\n",
      "2021-08-25 13:43:28.345 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:43:28.369 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 198.27272727272728, 'equality': 0.9363928139732318, 'sustainability': 470.1142073718709, 'peace': 700.6363636363636}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 13:43:28.370 | INFO     | src.policies:train:122 - Mean episode return: 198.27272727272728\n",
      "2021-08-25 13:43:28.370 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.03896103896105\n",
      "2021-08-25 13:43:28.371 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:43:37.445 | INFO     | src.policies:train:159 - Total loss: 0.9987347722053528\n",
      "2021-08-25 13:43:37.446 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 198.27272727272728, 'equality': 0.9363928139732318, 'sustainability': 470.1142073718709, 'peace': 700.6363636363636}\n",
      "2021-08-25 13:43:37.495 | INFO     | src.policies:train:103 - Epoch 78 / 4000\n",
      "2021-08-25 13:43:37.496 | INFO     | src.policies:train:110 - Episode 78\n",
      "2021-08-25 13:43:59.854 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:43:59.877 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 201.45454545454547, 'equality': 0.9405973088295743, 'sustainability': 476.0885174774863, 'peace': 720.2727272727273}\n",
      "2021-08-25 13:43:59.877 | INFO     | src.policies:train:122 - Mean episode return: 201.45454545454547\n",
      "2021-08-25 13:43:59.878 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.95454545454547\n",
      "2021-08-25 13:43:59.878 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:44:08.728 | INFO     | src.policies:train:159 - Total loss: 0.9959748387336731\n",
      "2021-08-25 13:44:08.729 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 201.45454545454547, 'equality': 0.9405973088295743, 'sustainability': 476.0885174774863, 'peace': 720.2727272727273}\n",
      "2021-08-25 13:44:08.779 | INFO     | src.policies:train:103 - Epoch 79 / 4000\n",
      "2021-08-25 13:44:08.779 | INFO     | src.policies:train:110 - Episode 79\n",
      "2021-08-25 13:44:29.898 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:44:29.919 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 229.1818181818182, 'equality': 0.9390573726165833, 'sustainability': 471.6513722242713, 'peace': 769.8181818181819}\n",
      "2021-08-25 13:44:29.920 | INFO     | src.policies:train:122 - Mean episode return: 229.1818181818182\n",
      "2021-08-25 13:44:29.921 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.22324510932106\n",
      "2021-08-25 13:44:29.921 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:44:38.751 | INFO     | src.policies:train:159 - Total loss: 0.9979003667831421\n",
      "2021-08-25 13:44:38.752 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 229.1818181818182, 'equality': 0.9390573726165833, 'sustainability': 471.6513722242713, 'peace': 769.8181818181819}\n",
      "2021-08-25 13:44:38.802 | INFO     | src.policies:train:103 - Epoch 80 / 4000\n",
      "2021-08-25 13:44:38.803 | INFO     | src.policies:train:110 - Episode 80\n",
      "2021-08-25 13:45:00.884 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:45:00.911 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 205.8181818181818, 'equality': 0.9424991969173125, 'sustainability': 483.861797375196, 'peace': 744.3636363636364}\n",
      "2021-08-25 13:45:00.911 | INFO     | src.policies:train:122 - Mean episode return: 205.8181818181818\n",
      "2021-08-25 13:45:00.912 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.1931818181818\n",
      "2021-08-25 13:45:00.912 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:45:10.130 | INFO     | src.policies:train:159 - Total loss: 0.9985126256942749\n",
      "2021-08-25 13:45:10.131 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 205.8181818181818, 'equality': 0.9424991969173125, 'sustainability': 483.861797375196, 'peace': 744.3636363636364}\n",
      "2021-08-25 13:45:10.185 | INFO     | src.policies:train:103 - Epoch 81 / 4000\n",
      "2021-08-25 13:45:10.185 | INFO     | src.policies:train:110 - Episode 81\n",
      "2021-08-25 13:45:32.912 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:45:32.935 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 207.0, 'equality': 0.9465005789127141, 'sustainability': 475.44147145503035, 'peace': 653.2727272727273}\n",
      "2021-08-25 13:45:32.936 | INFO     | src.policies:train:122 - Mean episode return: 207.0\n",
      "2021-08-25 13:45:32.937 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.17845117845116\n",
      "2021-08-25 13:45:32.937 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:45:42.247 | INFO     | src.policies:train:159 - Total loss: 1.000834345817566\n",
      "2021-08-25 13:45:42.248 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 207.0, 'equality': 0.9465005789127141, 'sustainability': 475.44147145503035, 'peace': 653.2727272727273}\n",
      "2021-08-25 13:45:42.298 | INFO     | src.policies:train:103 - Epoch 82 / 4000\n",
      "2021-08-25 13:45:42.299 | INFO     | src.policies:train:110 - Episode 82\n",
      "2021-08-25 13:46:05.115 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:46:05.137 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 222.45454545454547, 'equality': 0.9361741650270057, 'sustainability': 487.46527645680004, 'peace': 706.1818181818181}\n",
      "2021-08-25 13:46:05.137 | INFO     | src.policies:train:122 - Mean episode return: 222.45454545454547\n",
      "2021-08-25 13:46:05.138 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.35254988913522\n",
      "2021-08-25 13:46:05.138 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:46:14.219 | INFO     | src.policies:train:159 - Total loss: 1.0019911527633667\n",
      "2021-08-25 13:46:14.220 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 222.45454545454547, 'equality': 0.9361741650270057, 'sustainability': 487.46527645680004, 'peace': 706.1818181818181}\n",
      "2021-08-25 13:46:14.269 | INFO     | src.policies:train:103 - Epoch 83 / 4000\n",
      "2021-08-25 13:46:14.269 | INFO     | src.policies:train:110 - Episode 83\n",
      "2021-08-25 13:46:36.164 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:46:36.186 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 184.27272727272728, 'equality': 0.9016011122594609, 'sustainability': 475.2176619126736, 'peace': 607.0}\n",
      "2021-08-25 13:46:36.187 | INFO     | src.policies:train:122 - Mean episode return: 184.27272727272728\n",
      "2021-08-25 13:46:36.187 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.06243154435924\n",
      "2021-08-25 13:46:36.188 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:46:45.283 | INFO     | src.policies:train:159 - Total loss: 1.0056734085083008\n",
      "2021-08-25 13:46:45.284 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 184.27272727272728, 'equality': 0.9016011122594609, 'sustainability': 475.2176619126736, 'peace': 607.0}\n",
      "2021-08-25 13:46:45.333 | INFO     | src.policies:train:103 - Epoch 84 / 4000\n",
      "2021-08-25 13:46:45.333 | INFO     | src.policies:train:110 - Episode 84\n",
      "2021-08-25 13:47:07.107 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:47:07.133 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 214.27272727272728, 'equality': 0.912600763684333, 'sustainability': 496.41652984227784, 'peace': 759.5454545454545}\n",
      "2021-08-25 13:47:07.133 | INFO     | src.policies:train:122 - Mean episode return: 214.27272727272728\n",
      "2021-08-25 13:47:07.134 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.13636363636363\n",
      "2021-08-25 13:47:07.134 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:47:15.936 | INFO     | src.policies:train:159 - Total loss: 1.0028316974639893\n",
      "2021-08-25 13:47:15.937 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 214.27272727272728, 'equality': 0.912600763684333, 'sustainability': 496.41652984227784, 'peace': 759.5454545454545}\n",
      "2021-08-25 13:47:15.989 | INFO     | src.policies:train:103 - Epoch 85 / 4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 13:47:15.990 | INFO     | src.policies:train:110 - Episode 85\n",
      "2021-08-25 13:47:37.701 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:47:37.725 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 194.0909090909091, 'equality': 0.9129657228036414, 'sustainability': 502.9879926180079, 'peace': 766.0}\n",
      "2021-08-25 13:47:37.725 | INFO     | src.policies:train:122 - Mean episode return: 194.0909090909091\n",
      "2021-08-25 13:47:37.726 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.97112299465238\n",
      "2021-08-25 13:47:37.726 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:47:46.830 | INFO     | src.policies:train:159 - Total loss: 1.0055216550827026\n",
      "2021-08-25 13:47:46.831 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 194.0909090909091, 'equality': 0.9129657228036414, 'sustainability': 502.9879926180079, 'peace': 766.0}\n",
      "2021-08-25 13:47:46.882 | INFO     | src.policies:train:103 - Epoch 86 / 4000\n",
      "2021-08-25 13:47:46.882 | INFO     | src.policies:train:110 - Episode 86\n",
      "2021-08-25 13:48:10.145 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:48:10.168 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 199.0909090909091, 'equality': 0.9285180572866643, 'sustainability': 482.0455924502832, 'peace': 724.0}\n",
      "2021-08-25 13:48:10.168 | INFO     | src.policies:train:122 - Mean episode return: 199.0909090909091\n",
      "2021-08-25 13:48:10.169 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.86786469344605\n",
      "2021-08-25 13:48:10.169 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:48:19.552 | INFO     | src.policies:train:159 - Total loss: 1.001051425933838\n",
      "2021-08-25 13:48:19.553 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 199.0909090909091, 'equality': 0.9285180572866643, 'sustainability': 482.0455924502832, 'peace': 724.0}\n",
      "2021-08-25 13:48:19.607 | INFO     | src.policies:train:103 - Epoch 87 / 4000\n",
      "2021-08-25 13:48:19.608 | INFO     | src.policies:train:110 - Episode 87\n",
      "2021-08-25 13:48:42.500 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:48:42.524 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 204.63636363636363, 'equality': 0.9060619522655373, 'sustainability': 489.67314184671227, 'peace': 693.0}\n",
      "2021-08-25 13:48:42.525 | INFO     | src.policies:train:122 - Mean episode return: 204.63636363636363\n",
      "2021-08-25 13:48:42.525 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.83072100313476\n",
      "2021-08-25 13:48:42.526 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:48:51.913 | INFO     | src.policies:train:159 - Total loss: 0.9971688389778137\n",
      "2021-08-25 13:48:51.914 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 204.63636363636363, 'equality': 0.9060619522655373, 'sustainability': 489.67314184671227, 'peace': 693.0}\n",
      "2021-08-25 13:48:51.964 | INFO     | src.policies:train:103 - Epoch 88 / 4000\n",
      "2021-08-25 13:48:51.965 | INFO     | src.policies:train:110 - Episode 88\n",
      "2021-08-25 13:49:14.557 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:49:14.580 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 198.1818181818182, 'equality': 0.8739783152653466, 'sustainability': 481.16832134236387, 'peace': 744.6363636363636}\n",
      "2021-08-25 13:49:14.581 | INFO     | src.policies:train:122 - Mean episode return: 198.1818181818182\n",
      "2021-08-25 13:49:14.581 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.72107438016528\n",
      "2021-08-25 13:49:14.582 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:49:23.670 | INFO     | src.policies:train:159 - Total loss: 1.0002379417419434\n",
      "2021-08-25 13:49:23.671 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 198.1818181818182, 'equality': 0.8739783152653466, 'sustainability': 481.16832134236387, 'peace': 744.6363636363636}\n",
      "2021-08-25 13:49:23.720 | INFO     | src.policies:train:103 - Epoch 89 / 4000\n",
      "2021-08-25 13:49:23.721 | INFO     | src.policies:train:110 - Episode 89\n",
      "2021-08-25 13:49:46.303 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:49:46.327 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 216.1818181818182, 'equality': 0.9598593164622704, 'sustainability': 491.31182313633695, 'peace': 799.9090909090909}\n",
      "2021-08-25 13:49:46.327 | INFO     | src.policies:train:122 - Mean episode return: 216.1818181818182\n",
      "2021-08-25 13:49:46.328 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.81613891726252\n",
      "2021-08-25 13:49:46.328 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:49:55.391 | INFO     | src.policies:train:159 - Total loss: 0.997453510761261\n",
      "2021-08-25 13:49:55.392 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 216.1818181818182, 'equality': 0.9598593164622704, 'sustainability': 491.31182313633695, 'peace': 799.9090909090909}\n",
      "2021-08-25 13:49:55.441 | INFO     | src.policies:train:103 - Epoch 90 / 4000\n",
      "2021-08-25 13:49:55.442 | INFO     | src.policies:train:110 - Episode 90\n",
      "2021-08-25 13:50:17.358 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:50:17.379 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 204.0, 'equality': 0.9369632150393582, 'sustainability': 487.28127802893874, 'peace': 752.0}\n",
      "2021-08-25 13:50:17.380 | INFO     | src.policies:train:122 - Mean episode return: 204.0\n",
      "2021-08-25 13:50:17.380 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.7737373737374\n",
      "2021-08-25 13:50:17.381 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:50:26.445 | INFO     | src.policies:train:159 - Total loss: 1.000418782234192\n",
      "2021-08-25 13:50:26.445 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 204.0, 'equality': 0.9369632150393582, 'sustainability': 487.28127802893874, 'peace': 752.0}\n",
      "2021-08-25 13:50:26.496 | INFO     | src.policies:train:103 - Epoch 91 / 4000\n",
      "2021-08-25 13:50:26.497 | INFO     | src.policies:train:110 - Episode 91\n",
      "2021-08-25 13:50:49.852 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:50:49.874 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 207.63636363636363, 'equality': 0.9078968317165281, 'sustainability': 498.3116352123585, 'peace': 731.5454545454545}\n",
      "2021-08-25 13:50:49.875 | INFO     | src.policies:train:122 - Mean episode return: 207.63636363636363\n",
      "2021-08-25 13:50:49.875 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.77222777222778\n",
      "2021-08-25 13:50:49.876 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:50:58.944 | INFO     | src.policies:train:159 - Total loss: 1.0101032257080078\n",
      "2021-08-25 13:50:58.945 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 207.63636363636363, 'equality': 0.9078968317165281, 'sustainability': 498.3116352123585, 'peace': 731.5454545454545}\n",
      "2021-08-25 13:50:58.994 | INFO     | src.policies:train:103 - Epoch 92 / 4000\n",
      "2021-08-25 13:50:58.995 | INFO     | src.policies:train:110 - Episode 92\n",
      "2021-08-25 13:51:22.705 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:51:22.736 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 218.63636363636363, 'equality': 0.9092799092816239, 'sustainability': 510.7701598743622, 'peace': 743.8181818181819}\n",
      "2021-08-25 13:51:22.737 | INFO     | src.policies:train:122 - Mean episode return: 218.63636363636363\n",
      "2021-08-25 13:51:22.737 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.8903162055336\n",
      "2021-08-25 13:51:22.738 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:51:32.718 | INFO     | src.policies:train:159 - Total loss: 1.0048973560333252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 13:51:32.719 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 218.63636363636363, 'equality': 0.9092799092816239, 'sustainability': 510.7701598743622, 'peace': 743.8181818181819}\n",
      "2021-08-25 13:51:32.775 | INFO     | src.policies:train:103 - Epoch 93 / 4000\n",
      "2021-08-25 13:51:32.776 | INFO     | src.policies:train:110 - Episode 93\n",
      "2021-08-25 13:51:58.501 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:51:58.528 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 200.36363636363637, 'equality': 0.9674146180504988, 'sustainability': 470.52826071218317, 'peace': 734.0909090909091}\n",
      "2021-08-25 13:51:58.529 | INFO     | src.policies:train:122 - Mean episode return: 200.36363636363637\n",
      "2021-08-25 13:51:58.530 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.80938416422288\n",
      "2021-08-25 13:51:58.531 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:52:09.545 | INFO     | src.policies:train:159 - Total loss: 1.0045057535171509\n",
      "2021-08-25 13:52:09.546 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 200.36363636363637, 'equality': 0.9674146180504988, 'sustainability': 470.52826071218317, 'peace': 734.0909090909091}\n",
      "2021-08-25 13:52:09.608 | INFO     | src.policies:train:103 - Epoch 94 / 4000\n",
      "2021-08-25 13:52:09.609 | INFO     | src.policies:train:110 - Episode 94\n",
      "2021-08-25 13:52:35.312 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:52:35.337 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 206.9090909090909, 'equality': 0.9319380092680153, 'sustainability': 477.0862378980426, 'peace': 703.5454545454545}\n",
      "2021-08-25 13:52:35.338 | INFO     | src.policies:train:122 - Mean episode return: 206.9090909090909\n",
      "2021-08-25 13:52:35.338 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.79980657640235\n",
      "2021-08-25 13:52:35.339 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:52:45.252 | INFO     | src.policies:train:159 - Total loss: 1.0020177364349365\n",
      "2021-08-25 13:52:45.252 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 206.9090909090909, 'equality': 0.9319380092680153, 'sustainability': 477.0862378980426, 'peace': 703.5454545454545}\n",
      "2021-08-25 13:52:45.306 | INFO     | src.policies:train:103 - Epoch 95 / 4000\n",
      "2021-08-25 13:52:45.306 | INFO     | src.policies:train:110 - Episode 95\n",
      "2021-08-25 13:53:07.262 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:53:07.287 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 186.63636363636363, 'equality': 0.8847805871698893, 'sustainability': 495.2311076269423, 'peace': 631.0909090909091}\n",
      "2021-08-25 13:53:07.287 | INFO     | src.policies:train:122 - Mean episode return: 186.63636363636363\n",
      "2021-08-25 13:53:07.288 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.57703349282298\n",
      "2021-08-25 13:53:07.288 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:53:16.372 | INFO     | src.policies:train:159 - Total loss: 0.999157726764679\n",
      "2021-08-25 13:53:16.373 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 186.63636363636363, 'equality': 0.8847805871698893, 'sustainability': 495.2311076269423, 'peace': 631.0909090909091}\n",
      "2021-08-25 13:53:16.422 | INFO     | src.policies:train:103 - Epoch 96 / 4000\n",
      "2021-08-25 13:53:16.423 | INFO     | src.policies:train:110 - Episode 96\n",
      "2021-08-25 13:53:39.034 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:53:39.055 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 214.9090909090909, 'equality': 0.93016459006441, 'sustainability': 497.48764944467183, 'peace': 825.1818181818181}\n",
      "2021-08-25 13:53:39.056 | INFO     | src.policies:train:122 - Mean episode return: 214.9090909090909\n",
      "2021-08-25 13:53:39.057 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.6534090909091\n",
      "2021-08-25 13:53:39.057 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:53:47.888 | INFO     | src.policies:train:159 - Total loss: 0.9989537000656128\n",
      "2021-08-25 13:53:47.888 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 214.9090909090909, 'equality': 0.93016459006441, 'sustainability': 497.48764944467183, 'peace': 825.1818181818181}\n",
      "2021-08-25 13:53:47.934 | INFO     | src.policies:train:103 - Epoch 97 / 4000\n",
      "2021-08-25 13:53:47.935 | INFO     | src.policies:train:110 - Episode 97\n",
      "2021-08-25 13:54:09.658 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:54:09.681 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 186.54545454545453, 'equality': 0.8684210526344935, 'sustainability': 519.3082218283238, 'peace': 670.0}\n",
      "2021-08-25 13:54:09.681 | INFO     | src.policies:train:122 - Mean episode return: 186.54545454545453\n",
      "2021-08-25 13:54:09.682 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.43580131208998\n",
      "2021-08-25 13:54:09.682 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:54:18.441 | INFO     | src.policies:train:159 - Total loss: 0.9994451999664307\n",
      "2021-08-25 13:54:18.441 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 186.54545454545453, 'equality': 0.8684210526344935, 'sustainability': 519.3082218283238, 'peace': 670.0}\n",
      "2021-08-25 13:54:18.488 | INFO     | src.policies:train:103 - Epoch 98 / 4000\n",
      "2021-08-25 13:54:18.489 | INFO     | src.policies:train:110 - Episode 98\n",
      "2021-08-25 13:54:40.331 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:54:40.354 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 205.72727272727272, 'equality': 0.897240188006724, 'sustainability': 472.2818159434983, 'peace': 659.1818181818181}\n",
      "2021-08-25 13:54:40.355 | INFO     | src.policies:train:122 - Mean episode return: 205.72727272727272\n",
      "2021-08-25 13:54:40.355 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.41836734693877\n",
      "2021-08-25 13:54:40.356 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:54:49.414 | INFO     | src.policies:train:159 - Total loss: 1.002662181854248\n",
      "2021-08-25 13:54:49.415 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 205.72727272727272, 'equality': 0.897240188006724, 'sustainability': 472.2818159434983, 'peace': 659.1818181818181}\n",
      "2021-08-25 13:54:49.462 | INFO     | src.policies:train:103 - Epoch 99 / 4000\n",
      "2021-08-25 13:54:49.463 | INFO     | src.policies:train:110 - Episode 99\n",
      "2021-08-25 13:55:12.429 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:55:12.455 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 195.27272727272728, 'equality': 0.9434569155251512, 'sustainability': 494.84844407220595, 'peace': 671.9090909090909}\n",
      "2021-08-25 13:55:12.456 | INFO     | src.policies:train:122 - Mean episode return: 195.27272727272728\n",
      "2021-08-25 13:55:12.456 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.29568411386595\n",
      "2021-08-25 13:55:12.457 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:55:21.699 | INFO     | src.policies:train:159 - Total loss: 0.9979420304298401\n",
      "2021-08-25 13:55:21.700 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 195.27272727272728, 'equality': 0.9434569155251512, 'sustainability': 494.84844407220595, 'peace': 671.9090909090909}\n",
      "2021-08-25 13:55:21.752 | INFO     | src.policies:train:103 - Epoch 100 / 4000\n",
      "2021-08-25 13:55:21.753 | INFO     | src.policies:train:110 - Episode 100\n",
      "2021-08-25 13:55:44.650 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:55:44.679 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 184.63636363636363, 'equality': 0.9287408799980139, 'sustainability': 443.5497396882569, 'peace': 595.9090909090909}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 13:55:44.680 | INFO     | src.policies:train:122 - Mean episode return: 184.63636363636363\n",
      "2021-08-25 13:55:44.681 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.06909090909093\n",
      "2021-08-25 13:55:44.681 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:55:54.212 | INFO     | src.policies:train:159 - Total loss: 1.0026956796646118\n",
      "2021-08-25 13:55:54.213 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 184.63636363636363, 'equality': 0.9287408799980139, 'sustainability': 443.5497396882569, 'peace': 595.9090909090909}\n",
      "2021-08-25 13:55:54.264 | INFO     | src.policies:train:103 - Epoch 101 / 4000\n",
      "2021-08-25 13:55:54.265 | INFO     | src.policies:train:110 - Episode 101\n",
      "2021-08-25 13:56:19.664 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:56:19.690 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 213.54545454545453, 'equality': 0.9232942451348098, 'sustainability': 503.95696799951696, 'peace': 785.1818181818181}\n",
      "2021-08-25 13:56:19.691 | INFO     | src.policies:train:122 - Mean episode return: 213.54545454545453\n",
      "2021-08-25 13:56:19.691 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.10363636363635\n",
      "2021-08-25 13:56:19.692 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:56:29.794 | INFO     | src.policies:train:159 - Total loss: 1.0028811693191528\n",
      "2021-08-25 13:56:29.795 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 213.54545454545453, 'equality': 0.9232942451348098, 'sustainability': 503.95696799951696, 'peace': 785.1818181818181}\n",
      "2021-08-25 13:56:29.850 | INFO     | src.policies:train:103 - Epoch 102 / 4000\n",
      "2021-08-25 13:56:29.851 | INFO     | src.policies:train:110 - Episode 102\n",
      "2021-08-25 13:56:53.018 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:56:53.045 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 220.1818181818182, 'equality': 0.9352150739446135, 'sustainability': 486.12881072593154, 'peace': 777.5454545454545}\n",
      "2021-08-25 13:56:53.046 | INFO     | src.policies:train:122 - Mean episode return: 220.1818181818182\n",
      "2021-08-25 13:56:53.047 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.39545454545456\n",
      "2021-08-25 13:56:53.047 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:57:02.419 | INFO     | src.policies:train:159 - Total loss: 1.0022740364074707\n",
      "2021-08-25 13:57:02.420 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 220.1818181818182, 'equality': 0.9352150739446135, 'sustainability': 486.12881072593154, 'peace': 777.5454545454545}\n",
      "2021-08-25 13:57:02.475 | INFO     | src.policies:train:103 - Epoch 103 / 4000\n",
      "2021-08-25 13:57:02.475 | INFO     | src.policies:train:110 - Episode 103\n",
      "2021-08-25 13:57:26.393 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:57:26.420 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 193.0, 'equality': 0.9032244251294647, 'sustainability': 483.9537902904285, 'peace': 687.2727272727273}\n",
      "2021-08-25 13:57:26.421 | INFO     | src.policies:train:122 - Mean episode return: 193.0\n",
      "2021-08-25 13:57:26.421 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.17545454545456\n",
      "2021-08-25 13:57:26.422 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:57:36.360 | INFO     | src.policies:train:159 - Total loss: 0.9955764412879944\n",
      "2021-08-25 13:57:36.361 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 193.0, 'equality': 0.9032244251294647, 'sustainability': 483.9537902904285, 'peace': 687.2727272727273}\n",
      "2021-08-25 13:57:36.414 | INFO     | src.policies:train:103 - Epoch 104 / 4000\n",
      "2021-08-25 13:57:36.415 | INFO     | src.policies:train:110 - Episode 104\n",
      "2021-08-25 13:58:02.060 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:58:02.087 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 203.8181818181818, 'equality': 0.9398264536546138, 'sustainability': 470.2061726924752, 'peace': 689.0909090909091}\n",
      "2021-08-25 13:58:02.088 | INFO     | src.policies:train:122 - Mean episode return: 203.8181818181818\n",
      "2021-08-25 13:58:02.088 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.99090909090913\n",
      "2021-08-25 13:58:02.089 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:58:12.309 | INFO     | src.policies:train:159 - Total loss: 1.0042299032211304\n",
      "2021-08-25 13:58:12.310 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 203.8181818181818, 'equality': 0.9398264536546138, 'sustainability': 470.2061726924752, 'peace': 689.0909090909091}\n",
      "2021-08-25 13:58:12.364 | INFO     | src.policies:train:103 - Epoch 105 / 4000\n",
      "2021-08-25 13:58:12.364 | INFO     | src.policies:train:110 - Episode 105\n",
      "2021-08-25 13:58:38.209 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:58:38.238 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 189.9090909090909, 'equality': 0.9130510466096642, 'sustainability': 486.97498718210403, 'peace': 709.7272727272727}\n",
      "2021-08-25 13:58:38.238 | INFO     | src.policies:train:122 - Mean episode return: 189.9090909090909\n",
      "2021-08-25 13:58:38.239 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.8109090909091\n",
      "2021-08-25 13:58:38.240 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:58:48.524 | INFO     | src.policies:train:159 - Total loss: 0.9985531568527222\n",
      "2021-08-25 13:58:48.525 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 189.9090909090909, 'equality': 0.9130510466096642, 'sustainability': 486.97498718210403, 'peace': 709.7272727272727}\n",
      "2021-08-25 13:58:48.581 | INFO     | src.policies:train:103 - Epoch 106 / 4000\n",
      "2021-08-25 13:58:48.581 | INFO     | src.policies:train:110 - Episode 106\n",
      "2021-08-25 13:59:12.832 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:59:12.858 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 203.45454545454547, 'equality': 0.9325696644745193, 'sustainability': 474.98010334986157, 'peace': 693.8181818181819}\n",
      "2021-08-25 13:59:12.858 | INFO     | src.policies:train:122 - Mean episode return: 203.45454545454547\n",
      "2021-08-25 13:59:12.859 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.67454545454544\n",
      "2021-08-25 13:59:12.859 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:59:22.252 | INFO     | src.policies:train:159 - Total loss: 0.9973518252372742\n",
      "2021-08-25 13:59:22.253 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 203.45454545454547, 'equality': 0.9325696644745193, 'sustainability': 474.98010334986157, 'peace': 693.8181818181819}\n",
      "2021-08-25 13:59:22.307 | INFO     | src.policies:train:103 - Epoch 107 / 4000\n",
      "2021-08-25 13:59:22.308 | INFO     | src.policies:train:110 - Episode 107\n",
      "2021-08-25 13:59:45.513 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:59:45.539 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 210.0, 'equality': 0.9323101141296279, 'sustainability': 493.38126209461313, 'peace': 680.6363636363636}\n",
      "2021-08-25 13:59:45.539 | INFO     | src.policies:train:122 - Mean episode return: 210.0\n",
      "2021-08-25 13:59:45.540 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.82363636363633\n",
      "2021-08-25 13:59:45.540 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:59:54.917 | INFO     | src.policies:train:159 - Total loss: 1.0017929077148438\n",
      "2021-08-25 13:59:54.918 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 210.0, 'equality': 0.9323101141296279, 'sustainability': 493.38126209461313, 'peace': 680.6363636363636}\n",
      "2021-08-25 13:59:54.972 | INFO     | src.policies:train:103 - Epoch 108 / 4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 13:59:54.972 | INFO     | src.policies:train:110 - Episode 108\n",
      "2021-08-25 14:00:18.262 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:00:18.286 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 199.54545454545453, 'equality': 0.9006833713004622, 'sustainability': 465.8076161078238, 'peace': 721.6363636363636}\n",
      "2021-08-25 14:00:18.286 | INFO     | src.policies:train:122 - Mean episode return: 199.54545454545453\n",
      "2021-08-25 14:00:18.287 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.89818181818183\n",
      "2021-08-25 14:00:18.287 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:00:27.957 | INFO     | src.policies:train:159 - Total loss: 0.9994522929191589\n",
      "2021-08-25 14:00:27.957 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 199.54545454545453, 'equality': 0.9006833713004622, 'sustainability': 465.8076161078238, 'peace': 721.6363636363636}\n",
      "2021-08-25 14:00:28.012 | INFO     | src.policies:train:103 - Epoch 109 / 4000\n",
      "2021-08-25 14:00:28.013 | INFO     | src.policies:train:110 - Episode 109\n",
      "2021-08-25 14:00:52.840 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:00:52.866 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 210.0, 'equality': 0.9409681227874662, 'sustainability': 513.3422047521916, 'peace': 661.3636363636364}\n",
      "2021-08-25 14:00:52.867 | INFO     | src.policies:train:122 - Mean episode return: 210.0\n",
      "2021-08-25 14:00:52.867 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.84818181818184\n",
      "2021-08-25 14:00:52.868 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:01:02.563 | INFO     | src.policies:train:159 - Total loss: 0.9951536655426025\n",
      "2021-08-25 14:01:02.564 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 210.0, 'equality': 0.9409681227874662, 'sustainability': 513.3422047521916, 'peace': 661.3636363636364}\n",
      "2021-08-25 14:01:02.618 | INFO     | src.policies:train:103 - Epoch 110 / 4000\n",
      "2021-08-25 14:01:02.619 | INFO     | src.policies:train:110 - Episode 110\n",
      "2021-08-25 14:01:26.866 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:01:26.890 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 213.9090909090909, 'equality': 0.9456786307625531, 'sustainability': 490.72511481054676, 'peace': 748.8181818181819}\n",
      "2021-08-25 14:01:26.891 | INFO     | src.policies:train:122 - Mean episode return: 213.9090909090909\n",
      "2021-08-25 14:01:26.891 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.95545454545456\n",
      "2021-08-25 14:01:26.892 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:01:36.284 | INFO     | src.policies:train:159 - Total loss: 0.9943355917930603\n",
      "2021-08-25 14:01:36.285 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 213.9090909090909, 'equality': 0.9456786307625531, 'sustainability': 490.72511481054676, 'peace': 748.8181818181819}\n",
      "2021-08-25 14:01:36.338 | INFO     | src.policies:train:103 - Epoch 111 / 4000\n",
      "2021-08-25 14:01:36.338 | INFO     | src.policies:train:110 - Episode 111\n",
      "2021-08-25 14:01:59.700 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:01:59.725 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 198.9090909090909, 'equality': 0.9423300648175518, 'sustainability': 496.65131094450356, 'peace': 685.2727272727273}\n",
      "2021-08-25 14:01:59.726 | INFO     | src.policies:train:122 - Mean episode return: 198.9090909090909\n",
      "2021-08-25 14:01:59.726 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.82909090909095\n",
      "2021-08-25 14:01:59.727 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:02:09.578 | INFO     | src.policies:train:159 - Total loss: 0.9995763301849365\n",
      "2021-08-25 14:02:09.578 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 198.9090909090909, 'equality': 0.9423300648175518, 'sustainability': 496.65131094450356, 'peace': 685.2727272727273}\n",
      "2021-08-25 14:02:09.634 | INFO     | src.policies:train:103 - Epoch 112 / 4000\n",
      "2021-08-25 14:02:09.635 | INFO     | src.policies:train:110 - Episode 112\n",
      "2021-08-25 14:02:35.990 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:02:36.019 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 217.1818181818182, 'equality': 0.9125537501443632, 'sustainability': 508.26749196126184, 'peace': 730.4545454545455}\n",
      "2021-08-25 14:02:36.020 | INFO     | src.policies:train:122 - Mean episode return: 217.1818181818182\n",
      "2021-08-25 14:02:36.020 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.93363636363642\n",
      "2021-08-25 14:02:36.021 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:02:46.735 | INFO     | src.policies:train:159 - Total loss: 1.0023915767669678\n",
      "2021-08-25 14:02:46.736 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 217.1818181818182, 'equality': 0.9125537501443632, 'sustainability': 508.26749196126184, 'peace': 730.4545454545455}\n",
      "2021-08-25 14:02:46.795 | INFO     | src.policies:train:103 - Epoch 113 / 4000\n",
      "2021-08-25 14:02:46.796 | INFO     | src.policies:train:110 - Episode 113\n",
      "2021-08-25 14:03:13.291 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:03:13.321 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 185.36363636363637, 'equality': 0.9065495563799868, 'sustainability': 498.08799020998043, 'peace': 627.2727272727273}\n",
      "2021-08-25 14:03:13.322 | INFO     | src.policies:train:122 - Mean episode return: 185.36363636363637\n",
      "2021-08-25 14:03:13.323 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.57181818181823\n",
      "2021-08-25 14:03:13.323 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:03:24.348 | INFO     | src.policies:train:159 - Total loss: 0.9944605827331543\n",
      "2021-08-25 14:03:24.349 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 185.36363636363637, 'equality': 0.9065495563799868, 'sustainability': 498.08799020998043, 'peace': 627.2727272727273}\n",
      "2021-08-25 14:03:24.409 | INFO     | src.policies:train:103 - Epoch 114 / 4000\n",
      "2021-08-25 14:03:24.410 | INFO     | src.policies:train:110 - Episode 114\n",
      "2021-08-25 14:03:51.146 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:03:51.180 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 218.8181818181818, 'equality': 0.9441024285239245, 'sustainability': 481.9726190845531, 'peace': 823.2727272727273}\n",
      "2021-08-25 14:03:51.181 | INFO     | src.policies:train:122 - Mean episode return: 218.8181818181818\n",
      "2021-08-25 14:03:51.181 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.48181818181817\n",
      "2021-08-25 14:03:51.182 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:04:01.719 | INFO     | src.policies:train:159 - Total loss: 1.0022835731506348\n",
      "2021-08-25 14:04:01.719 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 218.8181818181818, 'equality': 0.9441024285239245, 'sustainability': 481.9726190845531, 'peace': 823.2727272727273}\n",
      "2021-08-25 14:04:01.781 | INFO     | src.policies:train:103 - Epoch 115 / 4000\n",
      "2021-08-25 14:04:01.781 | INFO     | src.policies:train:110 - Episode 115\n",
      "2021-08-25 14:04:29.469 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:04:29.498 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 208.9090909090909, 'equality': 0.9355170504008324, 'sustainability': 509.1051252571682, 'peace': 742.2727272727273}\n",
      "2021-08-25 14:04:29.499 | INFO     | src.policies:train:122 - Mean episode return: 208.9090909090909\n",
      "2021-08-25 14:04:29.500 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.46272727272728\n",
      "2021-08-25 14:04:29.500 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 14:04:40.656 | INFO     | src.policies:train:159 - Total loss: 0.9985252618789673\n",
      "2021-08-25 14:04:40.657 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 208.9090909090909, 'equality': 0.9355170504008324, 'sustainability': 509.1051252571682, 'peace': 742.2727272727273}\n",
      "2021-08-25 14:04:40.711 | INFO     | src.policies:train:103 - Epoch 116 / 4000\n",
      "2021-08-25 14:04:40.712 | INFO     | src.policies:train:110 - Episode 116\n",
      "2021-08-25 14:05:07.004 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:05:07.032 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 199.27272727272728, 'equality': 0.9255142667566872, 'sustainability': 490.7914187613911, 'peace': 764.9090909090909}\n",
      "2021-08-25 14:05:07.032 | INFO     | src.policies:train:122 - Mean episode return: 199.27272727272728\n",
      "2021-08-25 14:05:07.033 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.5127272727273\n",
      "2021-08-25 14:05:07.033 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:05:17.332 | INFO     | src.policies:train:159 - Total loss: 1.0054728984832764\n",
      "2021-08-25 14:05:17.333 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 199.27272727272728, 'equality': 0.9255142667566872, 'sustainability': 490.7914187613911, 'peace': 764.9090909090909}\n",
      "2021-08-25 14:05:17.391 | INFO     | src.policies:train:103 - Epoch 117 / 4000\n",
      "2021-08-25 14:05:17.392 | INFO     | src.policies:train:110 - Episode 117\n",
      "2021-08-25 14:05:42.868 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:05:42.896 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 209.45454545454547, 'equality': 0.916429924244073, 'sustainability': 482.7063449515692, 'peace': 760.5454545454545}\n",
      "2021-08-25 14:05:42.897 | INFO     | src.policies:train:122 - Mean episode return: 209.45454545454547\n",
      "2021-08-25 14:05:42.898 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.52818181818185\n",
      "2021-08-25 14:05:42.898 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:05:53.671 | INFO     | src.policies:train:159 - Total loss: 0.9999741911888123\n",
      "2021-08-25 14:05:53.672 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 209.45454545454547, 'equality': 0.916429924244073, 'sustainability': 482.7063449515692, 'peace': 760.5454545454545}\n",
      "2021-08-25 14:05:53.732 | INFO     | src.policies:train:103 - Epoch 118 / 4000\n",
      "2021-08-25 14:05:53.733 | INFO     | src.policies:train:110 - Episode 118\n",
      "2021-08-25 14:06:19.706 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:06:19.733 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 184.36363636363637, 'equality': 0.8503675811401656, 'sustainability': 470.3175229077265, 'peace': 632.1818181818181}\n",
      "2021-08-25 14:06:19.734 | INFO     | src.policies:train:122 - Mean episode return: 184.36363636363637\n",
      "2021-08-25 14:06:19.734 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.1290909090909\n",
      "2021-08-25 14:06:19.735 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:06:29.847 | INFO     | src.policies:train:159 - Total loss: 1.0040570497512817\n",
      "2021-08-25 14:06:29.848 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 184.36363636363637, 'equality': 0.8503675811401656, 'sustainability': 470.3175229077265, 'peace': 632.1818181818181}\n",
      "2021-08-25 14:06:29.904 | INFO     | src.policies:train:103 - Epoch 119 / 4000\n",
      "2021-08-25 14:06:29.905 | INFO     | src.policies:train:110 - Episode 119\n",
      "2021-08-25 14:06:53.938 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:06:53.962 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 214.36363636363637, 'equality': 0.9467962063392167, 'sustainability': 486.2770642475561, 'peace': 718.7272727272727}\n",
      "2021-08-25 14:06:53.962 | INFO     | src.policies:train:122 - Mean episode return: 214.36363636363637\n",
      "2021-08-25 14:06:53.963 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.12454545454545\n",
      "2021-08-25 14:06:53.964 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:07:03.461 | INFO     | src.policies:train:159 - Total loss: 0.999955952167511\n",
      "2021-08-25 14:07:03.462 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 214.36363636363637, 'equality': 0.9467962063392167, 'sustainability': 486.2770642475561, 'peace': 718.7272727272727}\n",
      "2021-08-25 14:07:03.519 | INFO     | src.policies:train:103 - Epoch 120 / 4000\n",
      "2021-08-25 14:07:03.519 | INFO     | src.policies:train:110 - Episode 120\n",
      "2021-08-25 14:07:26.541 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:07:26.567 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 193.36363636363637, 'equality': 0.9264863016641773, 'sustainability': 474.150853067977, 'peace': 722.6363636363636}\n",
      "2021-08-25 14:07:26.568 | INFO     | src.policies:train:122 - Mean episode return: 193.36363636363637\n",
      "2021-08-25 14:07:26.568 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.8890909090909\n",
      "2021-08-25 14:07:26.569 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:07:36.534 | INFO     | src.policies:train:159 - Total loss: 0.9961875677108765\n",
      "2021-08-25 14:07:36.535 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 193.36363636363637, 'equality': 0.9264863016641773, 'sustainability': 474.150853067977, 'peace': 722.6363636363636}\n",
      "2021-08-25 14:07:36.599 | INFO     | src.policies:train:103 - Epoch 121 / 4000\n",
      "2021-08-25 14:07:36.600 | INFO     | src.policies:train:110 - Episode 121\n",
      "2021-08-25 14:08:07.207 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:08:07.237 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 214.1818181818182, 'equality': 0.9288470442983322, 'sustainability': 466.92349588883013, 'peace': 719.2727272727273}\n",
      "2021-08-25 14:08:07.238 | INFO     | src.policies:train:122 - Mean episode return: 214.1818181818182\n",
      "2021-08-25 14:08:07.239 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.01545454545456\n",
      "2021-08-25 14:08:07.240 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:08:19.322 | INFO     | src.policies:train:159 - Total loss: 1.0015188455581665\n",
      "2021-08-25 14:08:19.323 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 214.1818181818182, 'equality': 0.9288470442983322, 'sustainability': 466.92349588883013, 'peace': 719.2727272727273}\n",
      "2021-08-25 14:08:19.384 | INFO     | src.policies:train:103 - Epoch 122 / 4000\n",
      "2021-08-25 14:08:19.385 | INFO     | src.policies:train:110 - Episode 122\n",
      "2021-08-25 14:08:46.400 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:08:46.427 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 197.63636363636363, 'equality': 0.9355189428799967, 'sustainability': 502.76469588704737, 'peace': 690.3636363636364}\n",
      "2021-08-25 14:08:46.427 | INFO     | src.policies:train:122 - Mean episode return: 197.63636363636363\n",
      "2021-08-25 14:08:46.428 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.85454545454544\n",
      "2021-08-25 14:08:46.428 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:08:56.415 | INFO     | src.policies:train:159 - Total loss: 0.9964160323143005\n",
      "2021-08-25 14:08:56.416 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 197.63636363636363, 'equality': 0.9355189428799967, 'sustainability': 502.76469588704737, 'peace': 690.3636363636364}\n",
      "2021-08-25 14:08:56.466 | INFO     | src.policies:train:103 - Epoch 123 / 4000\n",
      "2021-08-25 14:08:56.467 | INFO     | src.policies:train:110 - Episode 123\n",
      "2021-08-25 14:09:20.975 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:09:21.001 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 207.9090909090909, 'equality': 0.9100846682849687, 'sustainability': 477.1056953834955, 'peace': 675.6363636363636}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 14:09:21.001 | INFO     | src.policies:train:122 - Mean episode return: 207.9090909090909\n",
      "2021-08-25 14:09:21.002 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.7563636363637\n",
      "2021-08-25 14:09:21.002 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:09:30.323 | INFO     | src.policies:train:159 - Total loss: 0.9974158406257629\n",
      "2021-08-25 14:09:30.324 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 207.9090909090909, 'equality': 0.9100846682849687, 'sustainability': 477.1056953834955, 'peace': 675.6363636363636}\n",
      "2021-08-25 14:09:30.374 | INFO     | src.policies:train:103 - Epoch 124 / 4000\n",
      "2021-08-25 14:09:30.374 | INFO     | src.policies:train:110 - Episode 124\n",
      "2021-08-25 14:09:53.591 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:09:53.616 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 211.27272727272728, 'equality': 0.9343608199042724, 'sustainability': 487.49962352414934, 'peace': 774.2727272727273}\n",
      "2021-08-25 14:09:53.616 | INFO     | src.policies:train:122 - Mean episode return: 211.27272727272728\n",
      "2021-08-25 14:09:53.617 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.89545454545458\n",
      "2021-08-25 14:09:53.618 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:10:03.174 | INFO     | src.policies:train:159 - Total loss: 0.9999392032623291\n",
      "2021-08-25 14:10:03.174 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 211.27272727272728, 'equality': 0.9343608199042724, 'sustainability': 487.49962352414934, 'peace': 774.2727272727273}\n",
      "2021-08-25 14:10:03.228 | INFO     | src.policies:train:103 - Epoch 125 / 4000\n",
      "2021-08-25 14:10:03.229 | INFO     | src.policies:train:110 - Episode 125\n",
      "2021-08-25 14:10:29.463 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:10:29.494 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 212.36363636363637, 'equality': 0.943103985057147, 'sustainability': 485.9958167556928, 'peace': 751.4545454545455}\n",
      "2021-08-25 14:10:29.495 | INFO     | src.policies:train:122 - Mean episode return: 212.36363636363637\n",
      "2021-08-25 14:10:29.495 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.79636363636365\n",
      "2021-08-25 14:10:29.496 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:10:39.708 | INFO     | src.policies:train:159 - Total loss: 1.0002102851867676\n",
      "2021-08-25 14:10:39.709 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 212.36363636363637, 'equality': 0.943103985057147, 'sustainability': 485.9958167556928, 'peace': 751.4545454545455}\n",
      "2021-08-25 14:10:39.764 | INFO     | src.policies:train:103 - Epoch 126 / 4000\n",
      "2021-08-25 14:10:39.765 | INFO     | src.policies:train:110 - Episode 126\n",
      "2021-08-25 14:11:06.471 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:11:06.497 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 215.9090909090909, 'equality': 0.9570526315797694, 'sustainability': 492.1268024953983, 'peace': 826.2727272727273}\n",
      "2021-08-25 14:11:06.498 | INFO     | src.policies:train:122 - Mean episode return: 215.9090909090909\n",
      "2021-08-25 14:11:06.499 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.76363636363635\n",
      "2021-08-25 14:11:06.499 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:11:16.758 | INFO     | src.policies:train:159 - Total loss: 0.9989409446716309\n",
      "2021-08-25 14:11:16.759 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 215.9090909090909, 'equality': 0.9570526315797694, 'sustainability': 492.1268024953983, 'peace': 826.2727272727273}\n",
      "2021-08-25 14:11:16.814 | INFO     | src.policies:train:103 - Epoch 127 / 4000\n",
      "2021-08-25 14:11:16.815 | INFO     | src.policies:train:110 - Episode 127\n",
      "2021-08-25 14:11:44.075 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:11:44.103 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 196.0, 'equality': 0.9521841794579148, 'sustainability': 503.12649392067794, 'peace': 701.4545454545455}\n",
      "2021-08-25 14:11:44.104 | INFO     | src.policies:train:122 - Mean episode return: 196.0\n",
      "2021-08-25 14:11:44.104 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.72636363636363\n",
      "2021-08-25 14:11:44.105 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:11:55.003 | INFO     | src.policies:train:159 - Total loss: 0.9960848689079285\n",
      "2021-08-25 14:11:55.004 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 196.0, 'equality': 0.9521841794579148, 'sustainability': 503.12649392067794, 'peace': 701.4545454545455}\n",
      "2021-08-25 14:11:55.062 | INFO     | src.policies:train:103 - Epoch 128 / 4000\n",
      "2021-08-25 14:11:55.063 | INFO     | src.policies:train:110 - Episode 128\n",
      "2021-08-25 14:12:23.071 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:12:23.099 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 220.54545454545453, 'equality': 0.9232556396626835, 'sustainability': 479.63882759538905, 'peace': 765.0909090909091}\n",
      "2021-08-25 14:12:23.100 | INFO     | src.policies:train:122 - Mean episode return: 220.54545454545453\n",
      "2021-08-25 14:12:23.101 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.81272727272727\n",
      "2021-08-25 14:12:23.101 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:12:33.353 | INFO     | src.policies:train:159 - Total loss: 0.9986109137535095\n",
      "2021-08-25 14:12:33.354 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 220.54545454545453, 'equality': 0.9232556396626835, 'sustainability': 479.63882759538905, 'peace': 765.0909090909091}\n",
      "2021-08-25 14:12:33.407 | INFO     | src.policies:train:103 - Epoch 129 / 4000\n",
      "2021-08-25 14:12:33.408 | INFO     | src.policies:train:110 - Episode 129\n",
      "2021-08-25 14:12:57.326 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:12:57.349 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 219.8181818181818, 'equality': 0.9551094067231538, 'sustainability': 478.45935267727987, 'peace': 729.9090909090909}\n",
      "2021-08-25 14:12:57.349 | INFO     | src.policies:train:122 - Mean episode return: 219.8181818181818\n",
      "2021-08-25 14:12:57.350 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.9227272727273\n",
      "2021-08-25 14:12:57.350 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:13:06.631 | INFO     | src.policies:train:159 - Total loss: 1.0031211376190186\n",
      "2021-08-25 14:13:06.632 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 219.8181818181818, 'equality': 0.9551094067231538, 'sustainability': 478.45935267727987, 'peace': 729.9090909090909}\n",
      "2021-08-25 14:13:06.682 | INFO     | src.policies:train:103 - Epoch 130 / 4000\n",
      "2021-08-25 14:13:06.683 | INFO     | src.policies:train:110 - Episode 130\n",
      "2021-08-25 14:13:29.126 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:13:29.153 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 192.36363636363637, 'equality': 0.8768688778167024, 'sustainability': 484.5817210729016, 'peace': 682.9090909090909}\n",
      "2021-08-25 14:13:29.154 | INFO     | src.policies:train:122 - Mean episode return: 192.36363636363637\n",
      "2021-08-25 14:13:29.155 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.83272727272728\n",
      "2021-08-25 14:13:29.155 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:13:38.498 | INFO     | src.policies:train:159 - Total loss: 0.9978609085083008\n",
      "2021-08-25 14:13:38.498 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 192.36363636363637, 'equality': 0.8768688778167024, 'sustainability': 484.5817210729016, 'peace': 682.9090909090909}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 14:13:38.547 | INFO     | src.policies:train:103 - Epoch 131 / 4000\n",
      "2021-08-25 14:13:38.548 | INFO     | src.policies:train:110 - Episode 131\n",
      "2021-08-25 14:14:02.012 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:14:02.038 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 221.36363636363637, 'equality': 0.9255553481440069, 'sustainability': 471.8954606985578, 'peace': 731.4545454545455}\n",
      "2021-08-25 14:14:02.038 | INFO     | src.policies:train:122 - Mean episode return: 221.36363636363637\n",
      "2021-08-25 14:14:02.039 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.03363636363636\n",
      "2021-08-25 14:14:02.039 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:14:12.011 | INFO     | src.policies:train:159 - Total loss: 1.002609133720398\n",
      "2021-08-25 14:14:12.012 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 221.36363636363637, 'equality': 0.9255553481440069, 'sustainability': 471.8954606985578, 'peace': 731.4545454545455}\n",
      "2021-08-25 14:14:12.068 | INFO     | src.policies:train:103 - Epoch 132 / 4000\n",
      "2021-08-25 14:14:12.068 | INFO     | src.policies:train:110 - Episode 132\n",
      "2021-08-25 14:14:39.228 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:14:39.259 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 193.72727272727272, 'equality': 0.9520498272268237, 'sustainability': 478.42844539214514, 'peace': 679.7272727272727}\n",
      "2021-08-25 14:14:39.260 | INFO     | src.policies:train:122 - Mean episode return: 193.72727272727272\n",
      "2021-08-25 14:14:39.260 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.8409090909091\n",
      "2021-08-25 14:14:39.261 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:14:50.282 | INFO     | src.policies:train:159 - Total loss: 1.0044028759002686\n",
      "2021-08-25 14:14:50.284 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 193.72727272727272, 'equality': 0.9520498272268237, 'sustainability': 478.42844539214514, 'peace': 679.7272727272727}\n",
      "2021-08-25 14:14:50.341 | INFO     | src.policies:train:103 - Epoch 133 / 4000\n",
      "2021-08-25 14:14:50.341 | INFO     | src.policies:train:110 - Episode 133\n",
      "2021-08-25 14:15:17.631 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:15:17.662 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 222.9090909090909, 'equality': 0.9638884769397174, 'sustainability': 487.04065818500163, 'peace': 753.5454545454545}\n",
      "2021-08-25 14:15:17.662 | INFO     | src.policies:train:122 - Mean episode return: 222.9090909090909\n",
      "2021-08-25 14:15:17.663 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.09545454545457\n",
      "2021-08-25 14:15:17.664 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:15:28.055 | INFO     | src.policies:train:159 - Total loss: 1.001605749130249\n",
      "2021-08-25 14:15:28.056 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 222.9090909090909, 'equality': 0.9638884769397174, 'sustainability': 487.04065818500163, 'peace': 753.5454545454545}\n",
      "2021-08-25 14:15:28.112 | INFO     | src.policies:train:103 - Epoch 134 / 4000\n",
      "2021-08-25 14:15:28.112 | INFO     | src.policies:train:110 - Episode 134\n",
      "2021-08-25 14:15:52.933 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:15:52.960 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 167.9090909090909, 'equality': 0.8797066496067405, 'sustainability': 470.0853059561838, 'peace': 557.3636363636364}\n",
      "2021-08-25 14:15:52.961 | INFO     | src.policies:train:122 - Mean episode return: 167.9090909090909\n",
      "2021-08-25 14:15:52.961 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.66727272727275\n",
      "2021-08-25 14:15:52.962 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:16:02.936 | INFO     | src.policies:train:159 - Total loss: 0.999060869216919\n",
      "2021-08-25 14:16:02.937 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 167.9090909090909, 'equality': 0.8797066496067405, 'sustainability': 470.0853059561838, 'peace': 557.3636363636364}\n",
      "2021-08-25 14:16:02.991 | INFO     | src.policies:train:103 - Epoch 135 / 4000\n",
      "2021-08-25 14:16:02.992 | INFO     | src.policies:train:110 - Episode 135\n",
      "2021-08-25 14:16:27.556 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:16:27.582 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 194.72727272727272, 'equality': 0.9197860962583867, 'sustainability': 485.2010928536693, 'peace': 654.5454545454545}\n",
      "2021-08-25 14:16:27.583 | INFO     | src.policies:train:122 - Mean episode return: 194.72727272727272\n",
      "2021-08-25 14:16:27.583 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.61636363636367\n",
      "2021-08-25 14:16:27.584 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:16:37.771 | INFO     | src.policies:train:159 - Total loss: 1.004799723625183\n",
      "2021-08-25 14:16:37.772 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 194.72727272727272, 'equality': 0.9197860962583867, 'sustainability': 485.2010928536693, 'peace': 654.5454545454545}\n",
      "2021-08-25 14:16:37.826 | INFO     | src.policies:train:103 - Epoch 136 / 4000\n",
      "2021-08-25 14:16:37.827 | INFO     | src.policies:train:110 - Episode 136\n",
      "2021-08-25 14:17:03.672 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:17:03.698 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 205.72727272727272, 'equality': 0.9325111477135638, 'sustainability': 462.9950567496064, 'peace': 693.7272727272727}\n",
      "2021-08-25 14:17:03.699 | INFO     | src.policies:train:122 - Mean episode return: 205.72727272727272\n",
      "2021-08-25 14:17:03.700 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.43\n",
      "2021-08-25 14:17:03.701 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:17:14.291 | INFO     | src.policies:train:159 - Total loss: 1.0019729137420654\n",
      "2021-08-25 14:17:14.292 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 205.72727272727272, 'equality': 0.9325111477135638, 'sustainability': 462.9950567496064, 'peace': 693.7272727272727}\n",
      "2021-08-25 14:17:14.347 | INFO     | src.policies:train:103 - Epoch 137 / 4000\n",
      "2021-08-25 14:17:14.348 | INFO     | src.policies:train:110 - Episode 137\n",
      "2021-08-25 14:17:41.173 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:17:41.204 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 191.54545454545453, 'equality': 0.9044742632803108, 'sustainability': 482.39821417658766, 'peace': 697.0}\n",
      "2021-08-25 14:17:41.204 | INFO     | src.policies:train:122 - Mean episode return: 191.54545454545453\n",
      "2021-08-25 14:17:41.205 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.1954545454546\n",
      "2021-08-25 14:17:41.206 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:17:51.824 | INFO     | src.policies:train:159 - Total loss: 0.9974876046180725\n",
      "2021-08-25 14:17:51.825 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 191.54545454545453, 'equality': 0.9044742632803108, 'sustainability': 482.39821417658766, 'peace': 697.0}\n",
      "2021-08-25 14:17:51.886 | INFO     | src.policies:train:103 - Epoch 138 / 4000\n",
      "2021-08-25 14:17:51.886 | INFO     | src.policies:train:110 - Episode 138\n",
      "2021-08-25 14:18:19.667 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:18:19.697 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 217.0909090909091, 'equality': 0.9615501751187462, 'sustainability': 493.8885265814053, 'peace': 794.4545454545455}\n",
      "2021-08-25 14:18:19.698 | INFO     | src.policies:train:122 - Mean episode return: 217.0909090909091\n",
      "2021-08-25 14:18:19.698 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 14:18:19.699 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:18:30.135 | INFO     | src.policies:train:159 - Total loss: 1.0050582885742188\n",
      "2021-08-25 14:18:30.136 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 217.0909090909091, 'equality': 0.9615501751187462, 'sustainability': 493.8885265814053, 'peace': 794.4545454545455}\n",
      "2021-08-25 14:18:30.190 | INFO     | src.policies:train:103 - Epoch 139 / 4000\n",
      "2021-08-25 14:18:30.191 | INFO     | src.policies:train:110 - Episode 139\n",
      "2021-08-25 14:18:55.485 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:18:55.512 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 207.36363636363637, 'equality': 0.9320074927278306, 'sustainability': 471.05786822758404, 'peace': 729.4545454545455}\n",
      "2021-08-25 14:18:55.513 | INFO     | src.policies:train:122 - Mean episode return: 207.36363636363637\n",
      "2021-08-25 14:18:55.514 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.16090909090912\n",
      "2021-08-25 14:18:55.514 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:19:05.775 | INFO     | src.policies:train:159 - Total loss: 1.0010007619857788\n",
      "2021-08-25 14:19:05.776 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 207.36363636363637, 'equality': 0.9320074927278306, 'sustainability': 471.05786822758404, 'peace': 729.4545454545455}\n",
      "2021-08-25 14:19:05.830 | INFO     | src.policies:train:103 - Epoch 140 / 4000\n",
      "2021-08-25 14:19:05.831 | INFO     | src.policies:train:110 - Episode 140\n",
      "2021-08-25 14:19:31.084 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:19:31.112 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 222.63636363636363, 'equality': 0.9454322729138901, 'sustainability': 508.8787132343525, 'peace': 792.1818181818181}\n",
      "2021-08-25 14:19:31.113 | INFO     | src.policies:train:122 - Mean episode return: 222.63636363636363\n",
      "2021-08-25 14:19:31.113 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.29454545454547\n",
      "2021-08-25 14:19:31.114 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:19:40.768 | INFO     | src.policies:train:159 - Total loss: 0.9966182708740234\n",
      "2021-08-25 14:19:40.768 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 222.63636363636363, 'equality': 0.9454322729138901, 'sustainability': 508.8787132343525, 'peace': 792.1818181818181}\n",
      "2021-08-25 14:19:40.819 | INFO     | src.policies:train:103 - Epoch 141 / 4000\n",
      "2021-08-25 14:19:40.820 | INFO     | src.policies:train:110 - Episode 141\n",
      "2021-08-25 14:20:03.452 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:20:03.478 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 216.36363636363637, 'equality': 0.9599694423231481, 'sustainability': 495.22400004979716, 'peace': 769.0}\n",
      "2021-08-25 14:20:03.479 | INFO     | src.policies:train:122 - Mean episode return: 216.36363636363637\n",
      "2021-08-25 14:20:03.479 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.27272727272728\n",
      "2021-08-25 14:20:03.480 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:20:12.795 | INFO     | src.policies:train:159 - Total loss: 1.0040620565414429\n",
      "2021-08-25 14:20:12.796 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 216.36363636363637, 'equality': 0.9599694423231481, 'sustainability': 495.22400004979716, 'peace': 769.0}\n",
      "2021-08-25 14:20:12.844 | INFO     | src.policies:train:103 - Epoch 142 / 4000\n",
      "2021-08-25 14:20:12.845 | INFO     | src.policies:train:110 - Episode 142\n",
      "2021-08-25 14:20:35.549 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:20:35.578 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 228.27272727272728, 'equality': 0.9488070670875637, 'sustainability': 495.5736306640316, 'peace': 818.6363636363636}\n",
      "2021-08-25 14:20:35.579 | INFO     | src.policies:train:122 - Mean episode return: 228.27272727272728\n",
      "2021-08-25 14:20:35.579 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.46272727272728\n",
      "2021-08-25 14:20:35.580 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:20:45.113 | INFO     | src.policies:train:159 - Total loss: 0.9965884685516357\n",
      "2021-08-25 14:20:45.113 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 228.27272727272728, 'equality': 0.9488070670875637, 'sustainability': 495.5736306640316, 'peace': 818.6363636363636}\n",
      "2021-08-25 14:20:45.166 | INFO     | src.policies:train:103 - Epoch 143 / 4000\n",
      "2021-08-25 14:20:45.167 | INFO     | src.policies:train:110 - Episode 143\n",
      "2021-08-25 14:21:08.835 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:21:08.864 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 201.54545454545453, 'equality': 0.9414442120814073, 'sustainability': 473.4512605634658, 'peace': 658.2727272727273}\n",
      "2021-08-25 14:21:08.865 | INFO     | src.policies:train:122 - Mean episode return: 201.54545454545453\n",
      "2021-08-25 14:21:08.865 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.4436363636364\n",
      "2021-08-25 14:21:08.866 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:21:18.806 | INFO     | src.policies:train:159 - Total loss: 1.0007319450378418\n",
      "2021-08-25 14:21:18.807 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 201.54545454545453, 'equality': 0.9414442120814073, 'sustainability': 473.4512605634658, 'peace': 658.2727272727273}\n",
      "2021-08-25 14:21:18.860 | INFO     | src.policies:train:103 - Epoch 144 / 4000\n",
      "2021-08-25 14:21:18.860 | INFO     | src.policies:train:110 - Episode 144\n",
      "2021-08-25 14:21:42.966 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:21:42.996 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 197.54545454545453, 'equality': 0.9305526502963948, 'sustainability': 497.89353010909093, 'peace': 743.0}\n",
      "2021-08-25 14:21:42.997 | INFO     | src.policies:train:122 - Mean episode return: 197.54545454545453\n",
      "2021-08-25 14:21:42.998 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.32090909090908\n",
      "2021-08-25 14:21:42.998 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:21:53.035 | INFO     | src.policies:train:159 - Total loss: 1.0035070180892944\n",
      "2021-08-25 14:21:53.036 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 197.54545454545453, 'equality': 0.9305526502963948, 'sustainability': 497.89353010909093, 'peace': 743.0}\n",
      "2021-08-25 14:21:53.090 | INFO     | src.policies:train:103 - Epoch 145 / 4000\n",
      "2021-08-25 14:21:53.091 | INFO     | src.policies:train:110 - Episode 145\n",
      "2021-08-25 14:22:19.384 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:22:19.413 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 200.54545454545453, 'equality': 0.9249979395053779, 'sustainability': 474.411980880905, 'peace': 696.6363636363636}\n",
      "2021-08-25 14:22:19.414 | INFO     | src.policies:train:122 - Mean episode return: 200.54545454545453\n",
      "2021-08-25 14:22:19.414 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.24181818181825\n",
      "2021-08-25 14:22:19.415 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:22:30.401 | INFO     | src.policies:train:159 - Total loss: 1.001346468925476\n",
      "2021-08-25 14:22:30.401 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 200.54545454545453, 'equality': 0.9249979395053779, 'sustainability': 474.411980880905, 'peace': 696.6363636363636}\n",
      "2021-08-25 14:22:30.461 | INFO     | src.policies:train:103 - Epoch 146 / 4000\n",
      "2021-08-25 14:22:30.461 | INFO     | src.policies:train:110 - Episode 146\n",
      "2021-08-25 14:22:57.804 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 14:22:57.836 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 199.36363636363637, 'equality': 0.916594121794209, 'sustainability': 476.41264874360405, 'peace': 659.4545454545455}\n",
      "2021-08-25 14:22:57.837 | INFO     | src.policies:train:122 - Mean episode return: 199.36363636363637\n",
      "2021-08-25 14:22:57.838 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.1127272727273\n",
      "2021-08-25 14:22:57.838 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:23:08.737 | INFO     | src.policies:train:159 - Total loss: 1.003564476966858\n",
      "2021-08-25 14:23:08.738 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 199.36363636363637, 'equality': 0.916594121794209, 'sustainability': 476.41264874360405, 'peace': 659.4545454545455}\n",
      "2021-08-25 14:23:08.801 | INFO     | src.policies:train:103 - Epoch 147 / 4000\n",
      "2021-08-25 14:23:08.802 | INFO     | src.policies:train:110 - Episode 147\n",
      "2021-08-25 14:23:34.859 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:23:34.887 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 214.1818181818182, 'equality': 0.9153418737475818, 'sustainability': 495.9541745147859, 'peace': 801.0}\n",
      "2021-08-25 14:23:34.887 | INFO     | src.policies:train:122 - Mean episode return: 214.1818181818182\n",
      "2021-08-25 14:23:34.888 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.05545454545455\n",
      "2021-08-25 14:23:34.889 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:23:45.155 | INFO     | src.policies:train:159 - Total loss: 1.0002074241638184\n",
      "2021-08-25 14:23:45.156 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 214.1818181818182, 'equality': 0.9153418737475818, 'sustainability': 495.9541745147859, 'peace': 801.0}\n",
      "2021-08-25 14:23:45.210 | INFO     | src.policies:train:103 - Epoch 148 / 4000\n",
      "2021-08-25 14:23:45.211 | INFO     | src.policies:train:110 - Episode 148\n",
      "2021-08-25 14:24:10.697 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:24:10.722 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 202.1818181818182, 'equality': 0.9158763897989725, 'sustainability': 496.3336543694049, 'peace': 689.3636363636364}\n",
      "2021-08-25 14:24:10.722 | INFO     | src.policies:train:122 - Mean episode return: 202.1818181818182\n",
      "2021-08-25 14:24:10.723 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 204.93727272727276\n",
      "2021-08-25 14:24:10.723 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:24:20.932 | INFO     | src.policies:train:159 - Total loss: 0.9952569007873535\n",
      "2021-08-25 14:24:20.933 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 202.1818181818182, 'equality': 0.9158763897989725, 'sustainability': 496.3336543694049, 'peace': 689.3636363636364}\n",
      "2021-08-25 14:24:20.985 | INFO     | src.policies:train:103 - Epoch 149 / 4000\n",
      "2021-08-25 14:24:20.985 | INFO     | src.policies:train:110 - Episode 149\n",
      "2021-08-25 14:24:45.806 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:24:45.829 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 212.0909090909091, 'equality': 0.924950317579298, 'sustainability': 501.8143900256238, 'peace': 807.5454545454545}\n",
      "2021-08-25 14:24:45.830 | INFO     | src.policies:train:122 - Mean episode return: 212.0909090909091\n",
      "2021-08-25 14:24:45.830 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 204.9736363636364\n",
      "2021-08-25 14:24:45.831 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:24:55.394 | INFO     | src.policies:train:159 - Total loss: 0.9985991716384888\n",
      "2021-08-25 14:24:55.395 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 212.0909090909091, 'equality': 0.924950317579298, 'sustainability': 501.8143900256238, 'peace': 807.5454545454545}\n",
      "2021-08-25 14:24:55.444 | INFO     | src.policies:train:103 - Epoch 150 / 4000\n",
      "2021-08-25 14:24:55.445 | INFO     | src.policies:train:110 - Episode 150\n",
      "2021-08-25 14:25:19.290 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:25:19.319 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 209.0, 'equality': 0.9264502352816155, 'sustainability': 478.6091275791412, 'peace': 717.3636363636364}\n",
      "2021-08-25 14:25:19.320 | INFO     | src.policies:train:122 - Mean episode return: 209.0\n",
      "2021-08-25 14:25:19.320 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 204.9118181818182\n",
      "2021-08-25 14:25:19.321 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:25:30.520 | INFO     | src.policies:train:159 - Total loss: 0.9976646900177002\n",
      "2021-08-25 14:25:30.521 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 209.0, 'equality': 0.9264502352816155, 'sustainability': 478.6091275791412, 'peace': 717.3636363636364}\n",
      "2021-08-25 14:25:30.579 | INFO     | src.policies:train:103 - Epoch 151 / 4000\n",
      "2021-08-25 14:25:30.580 | INFO     | src.policies:train:110 - Episode 151\n",
      "2021-08-25 14:25:58.786 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:25:58.817 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 211.63636363636363, 'equality': 0.9408778506728195, 'sustainability': 508.4952160077684, 'peace': 776.8181818181819}\n",
      "2021-08-25 14:25:58.818 | INFO     | src.policies:train:122 - Mean episode return: 211.63636363636363\n",
      "2021-08-25 14:25:58.819 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.14545454545456\n",
      "2021-08-25 14:25:58.820 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:26:10.129 | INFO     | src.policies:train:159 - Total loss: 1.004783034324646\n",
      "2021-08-25 14:26:10.130 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 211.63636363636363, 'equality': 0.9408778506728195, 'sustainability': 508.4952160077684, 'peace': 776.8181818181819}\n",
      "2021-08-25 14:26:10.185 | INFO     | src.policies:train:103 - Epoch 152 / 4000\n",
      "2021-08-25 14:26:10.186 | INFO     | src.policies:train:110 - Episode 152\n",
      "2021-08-25 14:26:35.927 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:26:35.953 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 204.45454545454547, 'equality': 0.9150329439363953, 'sustainability': 471.80141837731065, 'peace': 721.9090909090909}\n",
      "2021-08-25 14:26:35.954 | INFO     | src.policies:train:122 - Mean episode return: 204.45454545454547\n",
      "2021-08-25 14:26:35.954 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 204.94181818181815\n",
      "2021-08-25 14:26:35.955 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:26:45.553 | INFO     | src.policies:train:159 - Total loss: 1.0014967918395996\n",
      "2021-08-25 14:26:45.554 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 204.45454545454547, 'equality': 0.9150329439363953, 'sustainability': 471.80141837731065, 'peace': 721.9090909090909}\n",
      "2021-08-25 14:26:45.605 | INFO     | src.policies:train:103 - Epoch 153 / 4000\n",
      "2021-08-25 14:26:45.606 | INFO     | src.policies:train:110 - Episode 153\n",
      "2021-08-25 14:27:09.418 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:27:09.446 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 213.45454545454547, 'equality': 0.9138144649234587, 'sustainability': 500.09487223631004, 'peace': 721.9090909090909}\n",
      "2021-08-25 14:27:09.446 | INFO     | src.policies:train:122 - Mean episode return: 213.45454545454547\n",
      "2021-08-25 14:27:09.447 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 204.96727272727273\n",
      "2021-08-25 14:27:09.448 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:27:19.685 | INFO     | src.policies:train:159 - Total loss: 1.0023081302642822\n",
      "2021-08-25 14:27:19.685 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 213.45454545454547, 'equality': 0.9138144649234587, 'sustainability': 500.09487223631004, 'peace': 721.9090909090909}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 14:27:19.743 | INFO     | src.policies:train:103 - Epoch 154 / 4000\n",
      "2021-08-25 14:27:19.743 | INFO     | src.policies:train:110 - Episode 154\n",
      "2021-08-25 14:27:45.590 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:27:45.617 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 206.72727272727272, 'equality': 0.927240745184152, 'sustainability': 498.0924375206096, 'peace': 742.4545454545455}\n",
      "2021-08-25 14:27:45.618 | INFO     | src.policies:train:122 - Mean episode return: 206.72727272727272\n",
      "2021-08-25 14:27:45.618 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 204.85636363636365\n",
      "2021-08-25 14:27:45.619 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:27:55.839 | INFO     | src.policies:train:159 - Total loss: 0.9998180270195007\n",
      "2021-08-25 14:27:55.840 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 206.72727272727272, 'equality': 0.927240745184152, 'sustainability': 498.0924375206096, 'peace': 742.4545454545455}\n",
      "2021-08-25 14:27:55.894 | INFO     | src.policies:train:103 - Epoch 155 / 4000\n",
      "2021-08-25 14:27:55.895 | INFO     | src.policies:train:110 - Episode 155\n",
      "2021-08-25 14:28:21.119 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:28:21.148 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 194.0909090909091, 'equality': 0.8914200553567933, 'sustainability': 483.5181954198144, 'peace': 689.3636363636364}\n",
      "2021-08-25 14:28:21.149 | INFO     | src.policies:train:122 - Mean episode return: 194.0909090909091\n",
      "2021-08-25 14:28:21.150 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 204.83363636363637\n",
      "2021-08-25 14:28:21.150 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n"
     ]
    }
   ],
   "source": [
    "vpg_policy_nn = models.MLP(observation_space_size, hidden_sizes, action_space_size)\n",
    "vpg_baseline_nn = models.MLP(observation_space_size, hidden_sizes, 1, log_softmax=False)\n",
    "vpg_policy = policies.VPGPolicy(env, vpg_policy_nn, baseline_nn=vpg_baseline_nn)\n",
    "vpg_policy.train(\n",
    "    epochs,\n",
    "    steps_per_epoch,\n",
    "    enable_wandb=True,\n",
    "    wandb_config={**wandb_config, \"group\": \"VPG\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f59524a",
   "metadata": {},
   "source": [
    "## TRPO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25b5599",
   "metadata": {},
   "source": [
    "This section deals with training a set of Harvest agents using our custom Trust Region Policy Optimization implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae9b78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 1.0\n",
    "kl_target = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df45fd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trpo_policy_nn = models.MLP(observation_space_size, hidden_sizes, action_space_size)\n",
    "trpo_baseline_nn = models.MLP(observation_space_size, hidden_sizes, 1, log_softmax=False)\n",
    "trpo_policy = policies.TRPOPolicy(env, trpo_policy_nn, trpo_baseline_nn, beta=beta, kl_target=kl_target)\n",
    "trpo_policy.train(\n",
    "    epochs,\n",
    "    steps_per_epoch,\n",
    "    enable_wandb=True,\n",
    "    wandb_config={**wandb_config, \"group\": \"TRPO\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70837d5",
   "metadata": {},
   "source": [
    "## PPO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ef0f7b",
   "metadata": {},
   "source": [
    "This section deals with training a set of Harvest agents using our custom Proximal Policy Optimization implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36d0b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1=1.0\n",
    "c2=0.01\n",
    "eps=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3878aeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_policy_nn = models.MLP(observation_space_size, hidden_sizes, action_space_size)\n",
    "ppo_baseline_nn = models.MLP(observation_space_size, hidden_sizes, 1, log_softmax=False)\n",
    "ppo_policy = policies.PPOPolicy(env, ppo_policy_nn, ppo_baseline_nn, c1=c1, c2=c2, eps=eps)\n",
    "ppo_policy.train(\n",
    "    epochs,\n",
    "    steps_per_epoch,\n",
    "    enable_wandb=True,\n",
    "    wandb_config={**wandb_config, \"group\": \"PPO\"}\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
