{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ddf1b9a",
   "metadata": {},
   "source": [
    "# CPR appropriation with policy gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36690845",
   "metadata": {},
   "source": [
    "This notebook contains actual Harvest trainings for each implemented policy gradient method. The environment in use is a custom implementation of Harvest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66552cde",
   "metadata": {},
   "source": [
    "## Pre-requisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebd241f",
   "metadata": {},
   "source": [
    "The cells down below install and import the necessary libraries to successfully run the notebook examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae0ed66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3caa94d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -r init/requirements.txt\n",
    "!pip install src/gym_cpr_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96a5b2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "from src import memory\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227a3d29",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05c7770",
   "metadata": {},
   "source": [
    "The cell down below defines the environment, along with common variables to be used throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bb8048cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\n",
    "    'gym_cpr_grid:CPRGridEnv-v0', \n",
    "    n_agents=11, \n",
    "    grid_width=39, \n",
    "    grid_height=19,\n",
    "    tagging_ability=True,\n",
    "    gifting_mechanism=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "365ab924",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_space_size = env.observation_space_size()\n",
    "action_space_size = env.action_space_size()\n",
    "epochs = 4000\n",
    "steps_per_epoch = 4000\n",
    "save_every = 500\n",
    "hidden_sizes = [32, 32]\n",
    "checkpoints_path = \"./checkpoints\"\n",
    "wandb_config = {\n",
    "    \"api_key\": open(\"./wandb_api_key_file\", \"r\").read().strip(),\n",
    "    \"project\": \"cpr-appropriation\",\n",
    "    \"entity\": \"wadaboa\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cac70c5",
   "metadata": {},
   "source": [
    "## VPG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202d6efd",
   "metadata": {},
   "source": [
    "This section deals with training a set of Harvest agents using our custom Vanilla Policy Gradient implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c869c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vpg_policy_nn = models.MLP(observation_space_size, hidden_sizes, action_space_size)\n",
    "vpg_baseline_nn = models.MLP(observation_space_size, hidden_sizes, action_space_size, log_softmax=False)\n",
    "vpg_policy = policies.VPGPolicy(env, vpg_policy_nn, baseline_nn=vpg_baseline_nn)\n",
    "vpg_policy.train(\n",
    "    epochs,\n",
    "    steps_per_epoch,\n",
    "    enable_wandb=True,\n",
    "    wandb_config={**wandb_config, \"group\": \"VPG\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06d59db",
   "metadata": {},
   "source": [
    "## TRPO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71021fe4",
   "metadata": {},
   "source": [
    "This section deals with training a set of Harvest agents using our custom Trust Region Policy Optimization implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c24f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 1.0\n",
    "kl_target = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee1239b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trpo_policy_nn = models.MLP(observation_space_size, hidden_sizes, action_space_size)\n",
    "trpo_baseline_nn = models.MLP(observation_space_size, hidden_sizes, action_space_size, log_softmax=False)\n",
    "trpo_policy = policies.TRPOPolicy(env, trpo_policy_nn, trpo_baseline_nn, beta=beta, kl_target=kl_target)\n",
    "trpo_policy.train(\n",
    "    epochs,\n",
    "    steps_per_epoch,\n",
    "    enable_wandb=True,\n",
    "    wandb_config={**wandb_config, \"group\": \"TRPO\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1109e2e5",
   "metadata": {},
   "source": [
    "## PPO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2630e1",
   "metadata": {},
   "source": [
    "This section deals with training a set of Harvest agents using our custom Proximal Policy Optimization implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c6dae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1=1.0\n",
    "c2=0.01\n",
    "eps=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc213ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_policy_nn = models.MLP(observation_space_size, hidden_sizes, action_space_size)\n",
    "ppo_baseline_nn = models.MLP(observation_space_size, hidden_sizes, action_space_size, log_softmax=False)\n",
    "ppo_policy = policies.PPOPolicy(env, ppo_policy_nn, ppo_baseline_nn, c1=c1, c2=c2, eps=eps)\n",
    "ppo_policy.train(\n",
    "    epochs,\n",
    "    steps_per_epoch,\n",
    "    enable_wandb=True,\n",
    "    wandb_config={**wandb_config, \"group\": \"PPO\"}\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
