{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24f90518",
   "metadata": {},
   "source": [
    "# CPR appropriation with policy gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd8eb71",
   "metadata": {},
   "source": [
    "This notebook contains actual Harvest trainings for each implemented policy gradient method. The environment in use is a custom implementation of Harvest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90af7b1",
   "metadata": {},
   "source": [
    "## Pre-requisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce46cf5f",
   "metadata": {},
   "source": [
    "The cells down below install and import the necessary libraries to successfully run the notebook examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d6f211a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "83194756",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -r ../init/requirements.txt\n",
    "!pip install ../src/gym_cpr_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "96a5b2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "from src import memory, models, policies\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6081a14",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6674369",
   "metadata": {},
   "source": [
    "The cell down below defines the environment, along with common variables to be used throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bb8048cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\n",
    "    'gym_cpr_grid:CPRGridEnv-v0', \n",
    "    n_agents=11, \n",
    "    grid_width=39, \n",
    "    grid_height=19,\n",
    "    tagging_ability=True,\n",
    "    gifting_mechanism=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "365ab924",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_space_size = env.observation_space_size()\n",
    "action_space_size = env.action_space_size()\n",
    "epochs = 4000\n",
    "steps_per_epoch = 4000\n",
    "save_every = 100\n",
    "hidden_sizes = [32, 32]\n",
    "checkpoints_path = \"../checkpoints\"\n",
    "render_every = 100\n",
    "wandb_config = {\n",
    "    \"api_key\": open(\"../wandb_api_key_file\", \"r\").read().strip(),\n",
    "    \"project\": \"cpr-appropriation\",\n",
    "    \"entity\": \"wadaboa\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee053691",
   "metadata": {},
   "source": [
    "## VPG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487b7639",
   "metadata": {},
   "source": [
    "This section deals with training a set of Harvest agents using our custom Vanilla Policy Gradient implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "85d84dcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwadaboa\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.0<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">flowing-darkness-28</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/wadaboa/cpr-appropriation\" target=\"_blank\">https://wandb.ai/wadaboa/cpr-appropriation</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/wadaboa/cpr-appropriation/runs/3j96ma8r\" target=\"_blank\">https://wandb.ai/wadaboa/cpr-appropriation/runs/3j96ma8r</a><br/>\n",
       "                Run data is saved locally in <code>/Users/jobs/Github/cpr-appropriation/notebooks/wandb/run-20210825_130510-3j96ma8r</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 13:05:12.502 | INFO     | src.policies:train:103 - Epoch 1 / 4000\n",
      "2021-08-25 13:05:12.503 | INFO     | src.policies:train:110 - Episode 1\n",
      "2021-08-25 13:05:30.874 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:05:30.876 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 210.0909090909091, 'equality': 0.9288776995411495, 'sustainability': 474.1942691329546, 'peace': 756.9090909090909}\n",
      "2021-08-25 13:05:30.877 | INFO     | src.policies:train:122 - Mean episode return: 210.0909090909091\n",
      "2021-08-25 13:05:30.877 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 210.0909090909091\n",
      "2021-08-25 13:05:30.878 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:05:38.303 | INFO     | src.policies:train:159 - Total loss: 0.9996551871299744\n",
      "2021-08-25 13:05:38.304 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 210.0909090909091, 'equality': 0.9288776995411495, 'sustainability': 474.1942691329546, 'peace': 756.9090909090909}\n",
      "2021-08-25 13:05:38.348 | INFO     | src.policies:train:103 - Epoch 2 / 4000\n",
      "2021-08-25 13:05:38.348 | INFO     | src.policies:train:110 - Episode 2\n",
      "2021-08-25 13:05:56.556 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:05:56.582 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 191.0, 'equality': 0.9014322184262595, 'sustainability': 453.6478484897958, 'peace': 635.0909090909091}\n",
      "2021-08-25 13:05:56.582 | INFO     | src.policies:train:122 - Mean episode return: 191.0\n",
      "2021-08-25 13:05:56.583 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 200.54545454545456\n",
      "2021-08-25 13:05:56.583 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:06:03.974 | INFO     | src.policies:train:159 - Total loss: 0.9981196522712708\n",
      "2021-08-25 13:06:03.975 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 191.0, 'equality': 0.9014322184262595, 'sustainability': 453.6478484897958, 'peace': 635.0909090909091}\n",
      "2021-08-25 13:06:04.021 | INFO     | src.policies:train:103 - Epoch 3 / 4000\n",
      "2021-08-25 13:06:04.022 | INFO     | src.policies:train:110 - Episode 3\n",
      "2021-08-25 13:06:22.420 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:06:22.443 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 215.0, 'equality': 0.9490294061128381, 'sustainability': 492.28421692334354, 'peace': 732.0}\n",
      "2021-08-25 13:06:22.444 | INFO     | src.policies:train:122 - Mean episode return: 215.0\n",
      "2021-08-25 13:06:22.444 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.36363636363637\n",
      "2021-08-25 13:06:22.445 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:06:29.984 | INFO     | src.policies:train:159 - Total loss: 0.9983858466148376\n",
      "2021-08-25 13:06:29.985 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 215.0, 'equality': 0.9490294061128381, 'sustainability': 492.28421692334354, 'peace': 732.0}\n",
      "2021-08-25 13:06:30.032 | INFO     | src.policies:train:103 - Epoch 4 / 4000\n",
      "2021-08-25 13:06:30.032 | INFO     | src.policies:train:110 - Episode 4\n",
      "2021-08-25 13:06:48.097 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:06:48.117 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 222.27272727272728, 'equality': 0.9572411228860895, 'sustainability': 501.32197584338263, 'peace': 797.7272727272727}\n",
      "2021-08-25 13:06:48.117 | INFO     | src.policies:train:122 - Mean episode return: 222.27272727272728\n",
      "2021-08-25 13:06:48.118 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.5909090909091\n",
      "2021-08-25 13:06:48.118 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:06:55.614 | INFO     | src.policies:train:159 - Total loss: 0.9993704557418823\n",
      "2021-08-25 13:06:55.614 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 222.27272727272728, 'equality': 0.9572411228860895, 'sustainability': 501.32197584338263, 'peace': 797.7272727272727}\n",
      "2021-08-25 13:06:55.661 | INFO     | src.policies:train:103 - Epoch 5 / 4000\n",
      "2021-08-25 13:06:55.662 | INFO     | src.policies:train:110 - Episode 5\n",
      "2021-08-25 13:07:14.142 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:07:14.163 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 207.9090909090909, 'equality': 0.9367174146373431, 'sustainability': 485.28755579192364, 'peace': 720.7272727272727}\n",
      "2021-08-25 13:07:14.164 | INFO     | src.policies:train:122 - Mean episode return: 207.9090909090909\n",
      "2021-08-25 13:07:14.164 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.25454545454545\n",
      "2021-08-25 13:07:14.165 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:07:21.650 | INFO     | src.policies:train:159 - Total loss: 1.0049175024032593\n",
      "2021-08-25 13:07:21.651 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 207.9090909090909, 'equality': 0.9367174146373431, 'sustainability': 485.28755579192364, 'peace': 720.7272727272727}\n",
      "2021-08-25 13:07:21.698 | INFO     | src.policies:train:103 - Epoch 6 / 4000\n",
      "2021-08-25 13:07:21.698 | INFO     | src.policies:train:110 - Episode 6\n",
      "2021-08-25 13:07:40.709 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:07:40.728 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 217.0909090909091, 'equality': 0.9452565859611456, 'sustainability': 472.224722068058, 'peace': 708.1818181818181}\n",
      "2021-08-25 13:07:40.729 | INFO     | src.policies:train:122 - Mean episode return: 217.0909090909091\n",
      "2021-08-25 13:07:40.730 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 210.56060606060603\n",
      "2021-08-25 13:07:40.730 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:07:48.202 | INFO     | src.policies:train:159 - Total loss: 0.9995870590209961\n",
      "2021-08-25 13:07:48.203 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 217.0909090909091, 'equality': 0.9452565859611456, 'sustainability': 472.224722068058, 'peace': 708.1818181818181}\n",
      "2021-08-25 13:07:48.248 | INFO     | src.policies:train:103 - Epoch 7 / 4000\n",
      "2021-08-25 13:07:48.249 | INFO     | src.policies:train:110 - Episode 7\n",
      "2021-08-25 13:08:07.071 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:08:07.091 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 195.0909090909091, 'equality': 0.9257815809555667, 'sustainability': 488.01074216497295, 'peace': 688.8181818181819}\n",
      "2021-08-25 13:08:07.092 | INFO     | src.policies:train:122 - Mean episode return: 195.0909090909091\n",
      "2021-08-25 13:08:07.092 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.35064935064932\n",
      "2021-08-25 13:08:07.093 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:08:14.692 | INFO     | src.policies:train:159 - Total loss: 0.9931796789169312\n",
      "2021-08-25 13:08:14.693 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 195.0909090909091, 'equality': 0.9257815809555667, 'sustainability': 488.01074216497295, 'peace': 688.8181818181819}\n",
      "2021-08-25 13:08:14.741 | INFO     | src.policies:train:103 - Epoch 8 / 4000\n",
      "2021-08-25 13:08:14.742 | INFO     | src.policies:train:110 - Episode 8\n",
      "2021-08-25 13:08:33.157 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:08:33.176 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 192.0909090909091, 'equality': 0.8630985673135332, 'sustainability': 481.78660196007417, 'peace': 653.1818181818181}\n",
      "2021-08-25 13:08:33.177 | INFO     | src.policies:train:122 - Mean episode return: 192.0909090909091\n",
      "2021-08-25 13:08:33.177 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.3181818181818\n",
      "2021-08-25 13:08:33.178 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 13:08:40.733 | INFO     | src.policies:train:159 - Total loss: 0.9971657991409302\n",
      "2021-08-25 13:08:40.734 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 192.0909090909091, 'equality': 0.8630985673135332, 'sustainability': 481.78660196007417, 'peace': 653.1818181818181}\n",
      "2021-08-25 13:08:40.781 | INFO     | src.policies:train:103 - Epoch 9 / 4000\n",
      "2021-08-25 13:08:40.782 | INFO     | src.policies:train:110 - Episode 9\n",
      "2021-08-25 13:08:59.288 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:08:59.309 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 215.0, 'equality': 0.9331923890076266, 'sustainability': 505.6465004460492, 'peace': 812.8181818181819}\n",
      "2021-08-25 13:08:59.310 | INFO     | src.policies:train:122 - Mean episode return: 215.0\n",
      "2021-08-25 13:08:59.310 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.2828282828283\n",
      "2021-08-25 13:08:59.310 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:09:06.978 | INFO     | src.policies:train:159 - Total loss: 1.0036789178848267\n",
      "2021-08-25 13:09:06.979 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 215.0, 'equality': 0.9331923890076266, 'sustainability': 505.6465004460492, 'peace': 812.8181818181819}\n",
      "2021-08-25 13:09:07.028 | INFO     | src.policies:train:103 - Epoch 10 / 4000\n",
      "2021-08-25 13:09:07.028 | INFO     | src.policies:train:110 - Episode 10\n",
      "2021-08-25 13:09:25.295 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:09:25.315 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 203.1818181818182, 'equality': 0.9233679072620832, 'sustainability': 486.2241285789833, 'peace': 739.1818181818181}\n",
      "2021-08-25 13:09:25.315 | INFO     | src.policies:train:122 - Mean episode return: 203.1818181818182\n",
      "2021-08-25 13:09:25.316 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.87272727272725\n",
      "2021-08-25 13:09:25.316 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:09:32.895 | INFO     | src.policies:train:159 - Total loss: 0.9927173256874084\n",
      "2021-08-25 13:09:32.896 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 203.1818181818182, 'equality': 0.9233679072620832, 'sustainability': 486.2241285789833, 'peace': 739.1818181818181}\n",
      "2021-08-25 13:09:32.943 | INFO     | src.policies:train:103 - Epoch 11 / 4000\n",
      "2021-08-25 13:09:32.944 | INFO     | src.policies:train:110 - Episode 11\n",
      "2021-08-25 13:09:51.699 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:09:51.719 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 211.54545454545453, 'equality': 0.9136617572388628, 'sustainability': 496.0733840286897, 'peace': 754.7272727272727}\n",
      "2021-08-25 13:09:51.720 | INFO     | src.policies:train:122 - Mean episode return: 211.54545454545453\n",
      "2021-08-25 13:09:51.720 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.297520661157\n",
      "2021-08-25 13:09:51.721 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:09:59.535 | INFO     | src.policies:train:159 - Total loss: 1.0049186944961548\n",
      "2021-08-25 13:09:59.535 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 211.54545454545453, 'equality': 0.9136617572388628, 'sustainability': 496.0733840286897, 'peace': 754.7272727272727}\n",
      "2021-08-25 13:09:59.582 | INFO     | src.policies:train:103 - Epoch 12 / 4000\n",
      "2021-08-25 13:09:59.583 | INFO     | src.policies:train:110 - Episode 12\n",
      "2021-08-25 13:10:18.297 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:10:18.319 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 206.72727272727272, 'equality': 0.9130087151212719, 'sustainability': 486.2811925722452, 'peace': 723.1818181818181}\n",
      "2021-08-25 13:10:18.320 | INFO     | src.policies:train:122 - Mean episode return: 206.72727272727272\n",
      "2021-08-25 13:10:18.320 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.24999999999997\n",
      "2021-08-25 13:10:18.321 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:10:26.007 | INFO     | src.policies:train:159 - Total loss: 0.9999533295631409\n",
      "2021-08-25 13:10:26.008 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 206.72727272727272, 'equality': 0.9130087151212719, 'sustainability': 486.2811925722452, 'peace': 723.1818181818181}\n",
      "2021-08-25 13:10:26.055 | INFO     | src.policies:train:103 - Epoch 13 / 4000\n",
      "2021-08-25 13:10:26.056 | INFO     | src.policies:train:110 - Episode 13\n",
      "2021-08-25 13:10:44.421 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:10:44.440 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 221.54545454545453, 'equality': 0.9448651471640828, 'sustainability': 490.96978548581023, 'peace': 741.9090909090909}\n",
      "2021-08-25 13:10:44.441 | INFO     | src.policies:train:122 - Mean episode return: 221.54545454545453\n",
      "2021-08-25 13:10:44.441 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.34965034965032\n",
      "2021-08-25 13:10:44.442 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:10:52.216 | INFO     | src.policies:train:159 - Total loss: 0.995656430721283\n",
      "2021-08-25 13:10:52.217 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 221.54545454545453, 'equality': 0.9448651471640828, 'sustainability': 490.96978548581023, 'peace': 741.9090909090909}\n",
      "2021-08-25 13:10:52.264 | INFO     | src.policies:train:103 - Epoch 14 / 4000\n",
      "2021-08-25 13:10:52.264 | INFO     | src.policies:train:110 - Episode 14\n",
      "2021-08-25 13:11:11.652 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:11:11.671 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 227.8181818181818, 'equality': 0.960531089023425, 'sustainability': 503.6366365584386, 'peace': 783.4545454545455}\n",
      "2021-08-25 13:11:11.672 | INFO     | src.policies:train:122 - Mean episode return: 227.8181818181818\n",
      "2021-08-25 13:11:11.672 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.74025974025972\n",
      "2021-08-25 13:11:11.673 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:11:19.450 | INFO     | src.policies:train:159 - Total loss: 1.0035055875778198\n",
      "2021-08-25 13:11:19.452 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 227.8181818181818, 'equality': 0.960531089023425, 'sustainability': 503.6366365584386, 'peace': 783.4545454545455}\n",
      "2021-08-25 13:11:19.499 | INFO     | src.policies:train:103 - Epoch 15 / 4000\n",
      "2021-08-25 13:11:19.499 | INFO     | src.policies:train:110 - Episode 15\n",
      "2021-08-25 13:11:37.761 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:11:37.782 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 210.8181818181818, 'equality': 0.9448037947401936, 'sustainability': 487.12943187128826, 'peace': 766.7272727272727}\n",
      "2021-08-25 13:11:37.782 | INFO     | src.policies:train:122 - Mean episode return: 210.8181818181818\n",
      "2021-08-25 13:11:37.783 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.8121212121212\n",
      "2021-08-25 13:11:37.783 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:11:45.634 | INFO     | src.policies:train:159 - Total loss: 1.0007202625274658\n",
      "2021-08-25 13:11:45.635 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 210.8181818181818, 'equality': 0.9448037947401936, 'sustainability': 487.12943187128826, 'peace': 766.7272727272727}\n",
      "2021-08-25 13:11:45.683 | INFO     | src.policies:train:103 - Epoch 16 / 4000\n",
      "2021-08-25 13:11:45.683 | INFO     | src.policies:train:110 - Episode 16\n",
      "2021-08-25 13:12:04.984 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:12:05.011 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 194.27272727272728, 'equality': 0.8995192921278871, 'sustainability': 478.79792458808674, 'peace': 725.3636363636364}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 13:12:05.012 | INFO     | src.policies:train:122 - Mean episode return: 194.27272727272728\n",
      "2021-08-25 13:12:05.012 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.84090909090907\n",
      "2021-08-25 13:12:05.013 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:12:13.399 | INFO     | src.policies:train:159 - Total loss: 0.9996477365493774\n",
      "2021-08-25 13:12:13.400 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 194.27272727272728, 'equality': 0.8995192921278871, 'sustainability': 478.79792458808674, 'peace': 725.3636363636364}\n",
      "2021-08-25 13:12:13.447 | INFO     | src.policies:train:103 - Epoch 17 / 4000\n",
      "2021-08-25 13:12:13.448 | INFO     | src.policies:train:110 - Episode 17\n",
      "2021-08-25 13:12:32.802 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:12:32.824 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 207.9090909090909, 'equality': 0.9270978256563362, 'sustainability': 487.7497772200393, 'peace': 669.0}\n",
      "2021-08-25 13:12:32.825 | INFO     | src.policies:train:122 - Mean episode return: 207.9090909090909\n",
      "2021-08-25 13:12:32.825 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.78609625668446\n",
      "2021-08-25 13:12:32.826 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:12:41.233 | INFO     | src.policies:train:159 - Total loss: 1.00559663772583\n",
      "2021-08-25 13:12:41.234 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 207.9090909090909, 'equality': 0.9270978256563362, 'sustainability': 487.7497772200393, 'peace': 669.0}\n",
      "2021-08-25 13:12:41.282 | INFO     | src.policies:train:103 - Epoch 18 / 4000\n",
      "2021-08-25 13:12:41.282 | INFO     | src.policies:train:110 - Episode 18\n",
      "2021-08-25 13:13:00.785 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:13:00.806 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 224.27272727272728, 'equality': 0.9431035118114917, 'sustainability': 497.49071141457466, 'peace': 728.1818181818181}\n",
      "2021-08-25 13:13:00.807 | INFO     | src.policies:train:122 - Mean episode return: 224.27272727272728\n",
      "2021-08-25 13:13:00.807 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.64646464646464\n",
      "2021-08-25 13:13:00.807 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:13:08.643 | INFO     | src.policies:train:159 - Total loss: 1.004082441329956\n",
      "2021-08-25 13:13:08.644 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 224.27272727272728, 'equality': 0.9431035118114917, 'sustainability': 497.49071141457466, 'peace': 728.1818181818181}\n",
      "2021-08-25 13:13:08.691 | INFO     | src.policies:train:103 - Epoch 19 / 4000\n",
      "2021-08-25 13:13:08.692 | INFO     | src.policies:train:110 - Episode 19\n",
      "2021-08-25 13:13:28.689 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:13:28.711 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 214.8181818181818, 'equality': 0.9659138998967816, 'sustainability': 512.5025342887893, 'peace': 758.5454545454545}\n",
      "2021-08-25 13:13:28.711 | INFO     | src.policies:train:122 - Mean episode return: 214.8181818181818\n",
      "2021-08-25 13:13:28.712 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.91866028708134\n",
      "2021-08-25 13:13:28.712 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:13:36.632 | INFO     | src.policies:train:159 - Total loss: 0.9979760050773621\n",
      "2021-08-25 13:13:36.633 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 214.8181818181818, 'equality': 0.9659138998967816, 'sustainability': 512.5025342887893, 'peace': 758.5454545454545}\n",
      "2021-08-25 13:13:36.680 | INFO     | src.policies:train:103 - Epoch 20 / 4000\n",
      "2021-08-25 13:13:36.681 | INFO     | src.policies:train:110 - Episode 20\n",
      "2021-08-25 13:13:56.474 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:13:56.495 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 216.9090909090909, 'equality': 0.9424674236085029, 'sustainability': 496.36315283217886, 'peace': 727.6363636363636}\n",
      "2021-08-25 13:13:56.496 | INFO     | src.policies:train:122 - Mean episode return: 216.9090909090909\n",
      "2021-08-25 13:13:56.497 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 210.2681818181818\n",
      "2021-08-25 13:13:56.497 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:14:04.728 | INFO     | src.policies:train:159 - Total loss: 1.0038795471191406\n",
      "2021-08-25 13:14:04.729 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 216.9090909090909, 'equality': 0.9424674236085029, 'sustainability': 496.36315283217886, 'peace': 727.6363636363636}\n",
      "2021-08-25 13:14:04.777 | INFO     | src.policies:train:103 - Epoch 21 / 4000\n",
      "2021-08-25 13:14:04.777 | INFO     | src.policies:train:110 - Episode 21\n",
      "2021-08-25 13:14:25.064 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:14:25.085 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 201.54545454545453, 'equality': 0.9329150777067102, 'sustainability': 482.74846752713694, 'peace': 694.4545454545455}\n",
      "2021-08-25 13:14:25.086 | INFO     | src.policies:train:122 - Mean episode return: 201.54545454545453\n",
      "2021-08-25 13:14:25.087 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.85281385281385\n",
      "2021-08-25 13:14:25.087 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:14:33.010 | INFO     | src.policies:train:159 - Total loss: 1.0057965517044067\n",
      "2021-08-25 13:14:33.011 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 201.54545454545453, 'equality': 0.9329150777067102, 'sustainability': 482.74846752713694, 'peace': 694.4545454545455}\n",
      "2021-08-25 13:14:33.059 | INFO     | src.policies:train:103 - Epoch 22 / 4000\n",
      "2021-08-25 13:14:33.059 | INFO     | src.policies:train:110 - Episode 22\n",
      "2021-08-25 13:14:53.507 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:14:53.530 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 213.72727272727272, 'equality': 0.9523606975764208, 'sustainability': 495.0542958192232, 'peace': 719.1818181818181}\n",
      "2021-08-25 13:14:53.530 | INFO     | src.policies:train:122 - Mean episode return: 213.72727272727272\n",
      "2021-08-25 13:14:53.531 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 210.02892561983472\n",
      "2021-08-25 13:14:53.531 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:15:01.813 | INFO     | src.policies:train:159 - Total loss: 1.0045866966247559\n",
      "2021-08-25 13:15:01.814 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 213.72727272727272, 'equality': 0.9523606975764208, 'sustainability': 495.0542958192232, 'peace': 719.1818181818181}\n",
      "2021-08-25 13:15:01.861 | INFO     | src.policies:train:103 - Epoch 23 / 4000\n",
      "2021-08-25 13:15:01.862 | INFO     | src.policies:train:110 - Episode 23\n",
      "2021-08-25 13:15:22.247 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:15:22.270 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 217.72727272727272, 'equality': 0.9109508445642256, 'sustainability': 494.7693931559598, 'peace': 822.2727272727273}\n",
      "2021-08-25 13:15:22.271 | INFO     | src.policies:train:122 - Mean episode return: 217.72727272727272\n",
      "2021-08-25 13:15:22.272 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 210.3636363636364\n",
      "2021-08-25 13:15:22.272 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:15:30.619 | INFO     | src.policies:train:159 - Total loss: 1.0022664070129395\n",
      "2021-08-25 13:15:30.620 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 217.72727272727272, 'equality': 0.9109508445642256, 'sustainability': 494.7693931559598, 'peace': 822.2727272727273}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 13:15:30.666 | INFO     | src.policies:train:103 - Epoch 24 / 4000\n",
      "2021-08-25 13:15:30.667 | INFO     | src.policies:train:110 - Episode 24\n",
      "2021-08-25 13:15:51.046 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:15:51.068 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 197.36363636363637, 'equality': 0.9317449018062112, 'sustainability': 493.5729859192556, 'peace': 706.1818181818181}\n",
      "2021-08-25 13:15:51.069 | INFO     | src.policies:train:122 - Mean episode return: 197.36363636363637\n",
      "2021-08-25 13:15:51.069 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.82196969696966\n",
      "2021-08-25 13:15:51.070 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:15:59.356 | INFO     | src.policies:train:159 - Total loss: 0.9995957016944885\n",
      "2021-08-25 13:15:59.356 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 197.36363636363637, 'equality': 0.9317449018062112, 'sustainability': 493.5729859192556, 'peace': 706.1818181818181}\n",
      "2021-08-25 13:15:59.404 | INFO     | src.policies:train:103 - Epoch 25 / 4000\n",
      "2021-08-25 13:15:59.405 | INFO     | src.policies:train:110 - Episode 25\n",
      "2021-08-25 13:16:19.698 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:16:19.719 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 222.27272727272728, 'equality': 0.9413273842732603, 'sustainability': 510.8915038416766, 'peace': 798.9090909090909}\n",
      "2021-08-25 13:16:19.720 | INFO     | src.policies:train:122 - Mean episode return: 222.27272727272728\n",
      "2021-08-25 13:16:19.720 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 210.31999999999996\n",
      "2021-08-25 13:16:19.721 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:16:28.012 | INFO     | src.policies:train:159 - Total loss: 1.0021605491638184\n",
      "2021-08-25 13:16:28.013 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 222.27272727272728, 'equality': 0.9413273842732603, 'sustainability': 510.8915038416766, 'peace': 798.9090909090909}\n",
      "2021-08-25 13:16:28.060 | INFO     | src.policies:train:103 - Epoch 26 / 4000\n",
      "2021-08-25 13:16:28.061 | INFO     | src.policies:train:110 - Episode 26\n",
      "2021-08-25 13:16:48.142 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:16:48.166 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 219.1818181818182, 'equality': 0.9469099958533443, 'sustainability': 495.85949477879444, 'peace': 800.3636363636364}\n",
      "2021-08-25 13:16:48.166 | INFO     | src.policies:train:122 - Mean episode return: 219.1818181818182\n",
      "2021-08-25 13:16:48.167 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 210.66083916083912\n",
      "2021-08-25 13:16:48.167 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:16:56.421 | INFO     | src.policies:train:159 - Total loss: 0.9953572750091553\n",
      "2021-08-25 13:16:56.422 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 219.1818181818182, 'equality': 0.9469099958533443, 'sustainability': 495.85949477879444, 'peace': 800.3636363636364}\n",
      "2021-08-25 13:16:56.468 | INFO     | src.policies:train:103 - Epoch 27 / 4000\n",
      "2021-08-25 13:16:56.469 | INFO     | src.policies:train:110 - Episode 27\n",
      "2021-08-25 13:17:16.890 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:17:16.915 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 199.72727272727272, 'equality': 0.912525344479817, 'sustainability': 474.8349656453242, 'peace': 688.7272727272727}\n",
      "2021-08-25 13:17:16.916 | INFO     | src.policies:train:122 - Mean episode return: 199.72727272727272\n",
      "2021-08-25 13:17:16.916 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 210.25589225589223\n",
      "2021-08-25 13:17:16.917 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:17:25.253 | INFO     | src.policies:train:159 - Total loss: 1.0006171464920044\n",
      "2021-08-25 13:17:25.254 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 199.72727272727272, 'equality': 0.912525344479817, 'sustainability': 474.8349656453242, 'peace': 688.7272727272727}\n",
      "2021-08-25 13:17:25.301 | INFO     | src.policies:train:103 - Epoch 28 / 4000\n",
      "2021-08-25 13:17:25.302 | INFO     | src.policies:train:110 - Episode 28\n",
      "2021-08-25 13:17:45.532 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:17:45.555 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 211.9090909090909, 'equality': 0.9199719199734805, 'sustainability': 482.75035269226004, 'peace': 690.5454545454545}\n",
      "2021-08-25 13:17:45.556 | INFO     | src.policies:train:122 - Mean episode return: 211.9090909090909\n",
      "2021-08-25 13:17:45.557 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 210.31493506493504\n",
      "2021-08-25 13:17:45.557 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:17:53.830 | INFO     | src.policies:train:159 - Total loss: 1.0005619525909424\n",
      "2021-08-25 13:17:53.831 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 211.9090909090909, 'equality': 0.9199719199734805, 'sustainability': 482.75035269226004, 'peace': 690.5454545454545}\n",
      "2021-08-25 13:17:53.878 | INFO     | src.policies:train:103 - Epoch 29 / 4000\n",
      "2021-08-25 13:17:53.879 | INFO     | src.policies:train:110 - Episode 29\n",
      "2021-08-25 13:18:13.262 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:18:13.284 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 208.8181818181818, 'equality': 0.9316895555481124, 'sustainability': 503.54148826512596, 'peace': 745.3636363636364}\n",
      "2021-08-25 13:18:13.285 | INFO     | src.policies:train:122 - Mean episode return: 208.8181818181818\n",
      "2021-08-25 13:18:13.285 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 210.26332288401252\n",
      "2021-08-25 13:18:13.286 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:18:21.661 | INFO     | src.policies:train:159 - Total loss: 1.0008200407028198\n",
      "2021-08-25 13:18:21.662 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 208.8181818181818, 'equality': 0.9316895555481124, 'sustainability': 503.54148826512596, 'peace': 745.3636363636364}\n",
      "2021-08-25 13:18:21.709 | INFO     | src.policies:train:103 - Epoch 30 / 4000\n",
      "2021-08-25 13:18:21.710 | INFO     | src.policies:train:110 - Episode 30\n",
      "2021-08-25 13:18:43.819 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:18:43.840 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 201.36363636363637, 'equality': 0.9230863944198012, 'sustainability': 483.4614756514786, 'peace': 705.3636363636364}\n",
      "2021-08-25 13:18:43.840 | INFO     | src.policies:train:122 - Mean episode return: 201.36363636363637\n",
      "2021-08-25 13:18:43.841 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.96666666666664\n",
      "2021-08-25 13:18:43.841 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:18:52.626 | INFO     | src.policies:train:159 - Total loss: 0.9996355175971985\n",
      "2021-08-25 13:18:52.627 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 201.36363636363637, 'equality': 0.9230863944198012, 'sustainability': 483.4614756514786, 'peace': 705.3636363636364}\n",
      "2021-08-25 13:18:52.674 | INFO     | src.policies:train:103 - Epoch 31 / 4000\n",
      "2021-08-25 13:18:52.674 | INFO     | src.policies:train:110 - Episode 31\n",
      "2021-08-25 13:19:15.131 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:19:15.154 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 201.27272727272728, 'equality': 0.9343844953614522, 'sustainability': 481.00459614865974, 'peace': 689.1818181818181}\n",
      "2021-08-25 13:19:15.155 | INFO     | src.policies:train:122 - Mean episode return: 201.27272727272728\n",
      "2021-08-25 13:19:15.155 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.68621700879763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 13:19:15.155 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:19:23.961 | INFO     | src.policies:train:159 - Total loss: 1.0068039894104004\n",
      "2021-08-25 13:19:23.961 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 201.27272727272728, 'equality': 0.9343844953614522, 'sustainability': 481.00459614865974, 'peace': 689.1818181818181}\n",
      "2021-08-25 13:19:24.008 | INFO     | src.policies:train:103 - Epoch 32 / 4000\n",
      "2021-08-25 13:19:24.008 | INFO     | src.policies:train:110 - Episode 32\n",
      "2021-08-25 13:19:45.644 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:19:45.667 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 213.0, 'equality': 0.9480076048588055, 'sustainability': 497.9819523633874, 'peace': 797.7272727272727}\n",
      "2021-08-25 13:19:45.668 | INFO     | src.policies:train:122 - Mean episode return: 213.0\n",
      "2021-08-25 13:19:45.668 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.78977272727272\n",
      "2021-08-25 13:19:45.668 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:19:54.482 | INFO     | src.policies:train:159 - Total loss: 0.9989316463470459\n",
      "2021-08-25 13:19:54.482 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 213.0, 'equality': 0.9480076048588055, 'sustainability': 497.9819523633874, 'peace': 797.7272727272727}\n",
      "2021-08-25 13:19:54.529 | INFO     | src.policies:train:103 - Epoch 33 / 4000\n",
      "2021-08-25 13:19:54.530 | INFO     | src.policies:train:110 - Episode 33\n",
      "2021-08-25 13:20:16.622 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:20:16.644 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 197.45454545454547, 'equality': 0.9434120207612713, 'sustainability': 493.57803556655364, 'peace': 763.8181818181819}\n",
      "2021-08-25 13:20:16.645 | INFO     | src.policies:train:122 - Mean episode return: 197.45454545454547\n",
      "2021-08-25 13:20:16.645 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.41597796143247\n",
      "2021-08-25 13:20:16.646 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:20:25.245 | INFO     | src.policies:train:159 - Total loss: 1.0046719312667847\n",
      "2021-08-25 13:20:25.246 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 197.45454545454547, 'equality': 0.9434120207612713, 'sustainability': 493.57803556655364, 'peace': 763.8181818181819}\n",
      "2021-08-25 13:20:25.293 | INFO     | src.policies:train:103 - Epoch 34 / 4000\n",
      "2021-08-25 13:20:25.294 | INFO     | src.policies:train:110 - Episode 34\n",
      "2021-08-25 13:20:46.651 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:20:46.673 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 210.72727272727272, 'equality': 0.9559181112252741, 'sustainability': 489.2484152947418, 'peace': 740.3636363636364}\n",
      "2021-08-25 13:20:46.674 | INFO     | src.policies:train:122 - Mean episode return: 210.72727272727272\n",
      "2021-08-25 13:20:46.674 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.45454545454544\n",
      "2021-08-25 13:20:46.675 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:20:55.293 | INFO     | src.policies:train:159 - Total loss: 1.0007920265197754\n",
      "2021-08-25 13:20:55.293 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 210.72727272727272, 'equality': 0.9559181112252741, 'sustainability': 489.2484152947418, 'peace': 740.3636363636364}\n",
      "2021-08-25 13:20:55.340 | INFO     | src.policies:train:103 - Epoch 35 / 4000\n",
      "2021-08-25 13:20:55.341 | INFO     | src.policies:train:110 - Episode 35\n",
      "2021-08-25 13:21:17.029 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:21:17.053 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 199.8181818181818, 'equality': 0.931590702292754, 'sustainability': 485.6971930074678, 'peace': 687.5454545454545}\n",
      "2021-08-25 13:21:17.053 | INFO     | src.policies:train:122 - Mean episode return: 199.8181818181818\n",
      "2021-08-25 13:21:17.054 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.17922077922077\n",
      "2021-08-25 13:21:17.054 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:21:25.886 | INFO     | src.policies:train:159 - Total loss: 1.002752423286438\n",
      "2021-08-25 13:21:25.887 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 199.8181818181818, 'equality': 0.931590702292754, 'sustainability': 485.6971930074678, 'peace': 687.5454545454545}\n",
      "2021-08-25 13:21:25.934 | INFO     | src.policies:train:103 - Epoch 36 / 4000\n",
      "2021-08-25 13:21:25.934 | INFO     | src.policies:train:110 - Episode 36\n",
      "2021-08-25 13:21:48.197 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:21:48.218 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 224.36363636363637, 'equality': 0.9440106085173123, 'sustainability': 497.78957135968415, 'peace': 804.6363636363636}\n",
      "2021-08-25 13:21:48.219 | INFO     | src.policies:train:122 - Mean episode return: 224.36363636363637\n",
      "2021-08-25 13:21:48.219 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.60101010101008\n",
      "2021-08-25 13:21:48.220 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:21:57.072 | INFO     | src.policies:train:159 - Total loss: 0.997032880783081\n",
      "2021-08-25 13:21:57.072 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 224.36363636363637, 'equality': 0.9440106085173123, 'sustainability': 497.78957135968415, 'peace': 804.6363636363636}\n",
      "2021-08-25 13:21:57.120 | INFO     | src.policies:train:103 - Epoch 37 / 4000\n",
      "2021-08-25 13:21:57.120 | INFO     | src.policies:train:110 - Episode 37\n",
      "2021-08-25 13:22:18.641 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:22:18.665 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 215.0, 'equality': 0.9699404189896225, 'sustainability': 495.7938609738674, 'peace': 794.0909090909091}\n",
      "2021-08-25 13:22:18.665 | INFO     | src.policies:train:122 - Mean episode return: 215.0\n",
      "2021-08-25 13:22:18.666 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.74692874692875\n",
      "2021-08-25 13:22:18.666 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:22:27.743 | INFO     | src.policies:train:159 - Total loss: 0.9988768696784973\n",
      "2021-08-25 13:22:27.744 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 215.0, 'equality': 0.9699404189896225, 'sustainability': 495.7938609738674, 'peace': 794.0909090909091}\n",
      "2021-08-25 13:22:27.790 | INFO     | src.policies:train:103 - Epoch 38 / 4000\n",
      "2021-08-25 13:22:27.791 | INFO     | src.policies:train:110 - Episode 38\n",
      "2021-08-25 13:22:50.030 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:22:50.054 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 215.63636363636363, 'equality': 0.9356124482612369, 'sustainability': 489.9413331392647, 'peace': 788.7272727272727}\n",
      "2021-08-25 13:22:50.054 | INFO     | src.policies:train:122 - Mean episode return: 215.63636363636363\n",
      "2021-08-25 13:22:50.055 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.90191387559807\n",
      "2021-08-25 13:22:50.055 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:22:59.088 | INFO     | src.policies:train:159 - Total loss: 1.0024000406265259\n",
      "2021-08-25 13:22:59.089 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 215.63636363636363, 'equality': 0.9356124482612369, 'sustainability': 489.9413331392647, 'peace': 788.7272727272727}\n",
      "2021-08-25 13:22:59.138 | INFO     | src.policies:train:103 - Epoch 39 / 4000\n",
      "2021-08-25 13:22:59.138 | INFO     | src.policies:train:110 - Episode 39\n",
      "2021-08-25 13:23:22.570 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 13:23:22.596 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 212.27272727272728, 'equality': 0.9247031341264415, 'sustainability': 497.69277664037327, 'peace': 649.4545454545455}\n",
      "2021-08-25 13:23:22.597 | INFO     | src.policies:train:122 - Mean episode return: 212.27272727272728\n",
      "2021-08-25 13:23:22.597 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.96270396270396\n",
      "2021-08-25 13:23:22.598 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:23:31.632 | INFO     | src.policies:train:159 - Total loss: 1.001400351524353\n",
      "2021-08-25 13:23:31.633 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 212.27272727272728, 'equality': 0.9247031341264415, 'sustainability': 497.69277664037327, 'peace': 649.4545454545455}\n",
      "2021-08-25 13:23:31.680 | INFO     | src.policies:train:103 - Epoch 40 / 4000\n",
      "2021-08-25 13:23:31.681 | INFO     | src.policies:train:110 - Episode 40\n",
      "2021-08-25 13:23:54.392 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:23:54.417 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 209.27272727272728, 'equality': 0.9448700734550022, 'sustainability': 502.9355983333528, 'peace': 734.2727272727273}\n",
      "2021-08-25 13:23:54.418 | INFO     | src.policies:train:122 - Mean episode return: 209.27272727272728\n",
      "2021-08-25 13:23:54.419 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.9454545454545\n",
      "2021-08-25 13:23:54.419 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:24:03.476 | INFO     | src.policies:train:159 - Total loss: 1.0016412734985352\n",
      "2021-08-25 13:24:03.477 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 209.27272727272728, 'equality': 0.9448700734550022, 'sustainability': 502.9355983333528, 'peace': 734.2727272727273}\n",
      "2021-08-25 13:24:03.526 | INFO     | src.policies:train:103 - Epoch 41 / 4000\n",
      "2021-08-25 13:24:03.527 | INFO     | src.policies:train:110 - Episode 41\n",
      "2021-08-25 13:24:25.794 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:24:25.816 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 218.54545454545453, 'equality': 0.9024353350494926, 'sustainability': 482.2784767589299, 'peace': 697.7272727272727}\n",
      "2021-08-25 13:24:25.817 | INFO     | src.policies:train:122 - Mean episode return: 218.54545454545453\n",
      "2021-08-25 13:24:25.817 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 210.15521064301547\n",
      "2021-08-25 13:24:25.817 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:24:34.595 | INFO     | src.policies:train:159 - Total loss: 1.0007470846176147\n",
      "2021-08-25 13:24:34.596 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 218.54545454545453, 'equality': 0.9024353350494926, 'sustainability': 482.2784767589299, 'peace': 697.7272727272727}\n",
      "2021-08-25 13:24:34.645 | INFO     | src.policies:train:103 - Epoch 42 / 4000\n",
      "2021-08-25 13:24:34.645 | INFO     | src.policies:train:110 - Episode 42\n",
      "2021-08-25 13:24:56.344 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:24:56.367 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 209.27272727272728, 'equality': 0.9541110496810261, 'sustainability': 503.18718168671, 'peace': 720.7272727272727}\n",
      "2021-08-25 13:24:56.368 | INFO     | src.policies:train:122 - Mean episode return: 209.27272727272728\n",
      "2021-08-25 13:24:56.369 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 210.1341991341991\n",
      "2021-08-25 13:24:56.369 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:25:05.169 | INFO     | src.policies:train:159 - Total loss: 0.9979462623596191\n",
      "2021-08-25 13:25:05.169 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 209.27272727272728, 'equality': 0.9541110496810261, 'sustainability': 503.18718168671, 'peace': 720.7272727272727}\n",
      "2021-08-25 13:25:05.217 | INFO     | src.policies:train:103 - Epoch 43 / 4000\n",
      "2021-08-25 13:25:05.217 | INFO     | src.policies:train:110 - Episode 43\n",
      "2021-08-25 13:25:27.125 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:25:27.148 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 203.45454545454547, 'equality': 0.9187586318970111, 'sustainability': 491.3924448186062, 'peace': 693.1818181818181}\n",
      "2021-08-25 13:25:27.149 | INFO     | src.policies:train:122 - Mean episode return: 203.45454545454547\n",
      "2021-08-25 13:25:27.149 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.97885835095136\n",
      "2021-08-25 13:25:27.150 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:25:36.138 | INFO     | src.policies:train:159 - Total loss: 0.9996159076690674\n",
      "2021-08-25 13:25:36.139 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 203.45454545454547, 'equality': 0.9187586318970111, 'sustainability': 491.3924448186062, 'peace': 693.1818181818181}\n",
      "2021-08-25 13:25:36.187 | INFO     | src.policies:train:103 - Epoch 44 / 4000\n",
      "2021-08-25 13:25:36.188 | INFO     | src.policies:train:110 - Episode 44\n",
      "2021-08-25 13:25:58.570 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:25:58.596 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 209.8181818181818, 'equality': 0.9430439577764487, 'sustainability': 499.5713546211406, 'peace': 650.1818181818181}\n",
      "2021-08-25 13:25:58.598 | INFO     | src.policies:train:122 - Mean episode return: 209.8181818181818\n",
      "2021-08-25 13:25:58.598 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.97520661157023\n",
      "2021-08-25 13:25:58.599 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:26:07.679 | INFO     | src.policies:train:159 - Total loss: 1.007609486579895\n",
      "2021-08-25 13:26:07.680 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 209.8181818181818, 'equality': 0.9430439577764487, 'sustainability': 499.5713546211406, 'peace': 650.1818181818181}\n",
      "2021-08-25 13:26:07.729 | INFO     | src.policies:train:103 - Epoch 45 / 4000\n",
      "2021-08-25 13:26:07.729 | INFO     | src.policies:train:110 - Episode 45\n",
      "2021-08-25 13:26:31.164 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:26:31.187 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 208.45454545454547, 'equality': 0.9312532212676673, 'sustainability': 500.88894334105566, 'peace': 716.3636363636364}\n",
      "2021-08-25 13:26:31.188 | INFO     | src.policies:train:122 - Mean episode return: 208.45454545454547\n",
      "2021-08-25 13:26:31.188 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.94141414141413\n",
      "2021-08-25 13:26:31.189 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:26:40.521 | INFO     | src.policies:train:159 - Total loss: 0.9974214434623718\n",
      "2021-08-25 13:26:40.522 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 208.45454545454547, 'equality': 0.9312532212676673, 'sustainability': 500.88894334105566, 'peace': 716.3636363636364}\n",
      "2021-08-25 13:26:40.571 | INFO     | src.policies:train:103 - Epoch 46 / 4000\n",
      "2021-08-25 13:26:40.572 | INFO     | src.policies:train:110 - Episode 46\n",
      "2021-08-25 13:27:03.997 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:27:04.026 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 212.27272727272728, 'equality': 0.937161767569843, 'sustainability': 497.7415083601114, 'peace': 640.7272727272727}\n",
      "2021-08-25 13:27:04.027 | INFO     | src.policies:train:122 - Mean episode return: 212.27272727272728\n",
      "2021-08-25 13:27:04.027 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.9920948616601\n",
      "2021-08-25 13:27:04.028 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:27:13.340 | INFO     | src.policies:train:159 - Total loss: 0.9988415241241455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 13:27:13.340 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 212.27272727272728, 'equality': 0.937161767569843, 'sustainability': 497.7415083601114, 'peace': 640.7272727272727}\n",
      "2021-08-25 13:27:13.391 | INFO     | src.policies:train:103 - Epoch 47 / 4000\n",
      "2021-08-25 13:27:13.391 | INFO     | src.policies:train:110 - Episode 47\n",
      "2021-08-25 13:27:35.457 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:27:35.484 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 219.9090909090909, 'equality': 0.9539253635996482, 'sustainability': 487.9896388131372, 'peace': 768.8181818181819}\n",
      "2021-08-25 13:27:35.485 | INFO     | src.policies:train:122 - Mean episode return: 219.9090909090909\n",
      "2021-08-25 13:27:35.485 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 210.20309477756285\n",
      "2021-08-25 13:27:35.486 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:27:44.547 | INFO     | src.policies:train:159 - Total loss: 1.0042535066604614\n",
      "2021-08-25 13:27:44.548 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 219.9090909090909, 'equality': 0.9539253635996482, 'sustainability': 487.9896388131372, 'peace': 768.8181818181819}\n",
      "2021-08-25 13:27:44.599 | INFO     | src.policies:train:103 - Epoch 48 / 4000\n",
      "2021-08-25 13:27:44.600 | INFO     | src.policies:train:110 - Episode 48\n",
      "2021-08-25 13:28:07.954 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:28:07.978 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 214.0, 'equality': 0.9327257279691681, 'sustainability': 514.1637524426329, 'peace': 701.7272727272727}\n",
      "2021-08-25 13:28:07.979 | INFO     | src.policies:train:122 - Mean episode return: 214.0\n",
      "2021-08-25 13:28:07.979 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 210.28219696969697\n",
      "2021-08-25 13:28:07.980 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:28:17.048 | INFO     | src.policies:train:159 - Total loss: 1.0004335641860962\n",
      "2021-08-25 13:28:17.049 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 214.0, 'equality': 0.9327257279691681, 'sustainability': 514.1637524426329, 'peace': 701.7272727272727}\n",
      "2021-08-25 13:28:17.097 | INFO     | src.policies:train:103 - Epoch 49 / 4000\n",
      "2021-08-25 13:28:17.098 | INFO     | src.policies:train:110 - Episode 49\n",
      "2021-08-25 13:28:39.068 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:28:39.091 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 208.45454545454547, 'equality': 0.9330769535754455, 'sustainability': 492.5558668943042, 'peace': 746.9090909090909}\n",
      "2021-08-25 13:28:39.092 | INFO     | src.policies:train:122 - Mean episode return: 208.45454545454547\n",
      "2021-08-25 13:28:39.092 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 210.24489795918367\n",
      "2021-08-25 13:28:39.093 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:28:48.180 | INFO     | src.policies:train:159 - Total loss: 1.000566005706787\n",
      "2021-08-25 13:28:48.181 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 208.45454545454547, 'equality': 0.9330769535754455, 'sustainability': 492.5558668943042, 'peace': 746.9090909090909}\n",
      "2021-08-25 13:28:48.230 | INFO     | src.policies:train:103 - Epoch 50 / 4000\n",
      "2021-08-25 13:28:48.231 | INFO     | src.policies:train:110 - Episode 50\n",
      "2021-08-25 13:29:11.772 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:29:11.797 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 215.1818181818182, 'equality': 0.940392518340431, 'sustainability': 486.2688817101664, 'peace': 800.6363636363636}\n",
      "2021-08-25 13:29:11.798 | INFO     | src.policies:train:122 - Mean episode return: 215.1818181818182\n",
      "2021-08-25 13:29:11.798 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 210.34363636363636\n",
      "2021-08-25 13:29:11.799 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:29:20.809 | INFO     | src.policies:train:159 - Total loss: 1.0046511888504028\n",
      "2021-08-25 13:29:20.810 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 215.1818181818182, 'equality': 0.940392518340431, 'sustainability': 486.2688817101664, 'peace': 800.6363636363636}\n",
      "2021-08-25 13:29:20.858 | INFO     | src.policies:train:103 - Epoch 51 / 4000\n",
      "2021-08-25 13:29:20.859 | INFO     | src.policies:train:110 - Episode 51\n",
      "2021-08-25 13:29:43.911 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:29:43.934 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 188.27272727272728, 'equality': 0.9158070321777839, 'sustainability': 483.023715424968, 'peace': 670.7272727272727}\n",
      "2021-08-25 13:29:43.934 | INFO     | src.policies:train:122 - Mean episode return: 188.27272727272728\n",
      "2021-08-25 13:29:43.935 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.9108734402852\n",
      "2021-08-25 13:29:43.935 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:29:52.980 | INFO     | src.policies:train:159 - Total loss: 0.9970273971557617\n",
      "2021-08-25 13:29:52.981 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 188.27272727272728, 'equality': 0.9158070321777839, 'sustainability': 483.023715424968, 'peace': 670.7272727272727}\n",
      "2021-08-25 13:29:53.030 | INFO     | src.policies:train:103 - Epoch 52 / 4000\n",
      "2021-08-25 13:29:53.030 | INFO     | src.policies:train:110 - Episode 52\n",
      "2021-08-25 13:30:15.967 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:30:15.990 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 224.8181818181818, 'equality': 0.9425798625162192, 'sustainability': 476.64773711629465, 'peace': 658.8181818181819}\n",
      "2021-08-25 13:30:15.991 | INFO     | src.policies:train:122 - Mean episode return: 224.8181818181818\n",
      "2021-08-25 13:30:15.991 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 210.19755244755245\n",
      "2021-08-25 13:30:15.992 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:30:25.027 | INFO     | src.policies:train:159 - Total loss: 0.9949914216995239\n",
      "2021-08-25 13:30:25.028 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 224.8181818181818, 'equality': 0.9425798625162192, 'sustainability': 476.64773711629465, 'peace': 658.8181818181819}\n",
      "2021-08-25 13:30:25.076 | INFO     | src.policies:train:103 - Epoch 53 / 4000\n",
      "2021-08-25 13:30:25.077 | INFO     | src.policies:train:110 - Episode 53\n",
      "2021-08-25 13:30:47.700 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:30:47.726 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 210.9090909090909, 'equality': 0.9197492163025127, 'sustainability': 480.9332435358052, 'peace': 718.9090909090909}\n",
      "2021-08-25 13:30:47.726 | INFO     | src.policies:train:122 - Mean episode return: 210.9090909090909\n",
      "2021-08-25 13:30:47.727 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 210.21097770154373\n",
      "2021-08-25 13:30:47.727 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:30:57.271 | INFO     | src.policies:train:159 - Total loss: 0.9993852376937866\n",
      "2021-08-25 13:30:57.272 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 210.9090909090909, 'equality': 0.9197492163025127, 'sustainability': 480.9332435358052, 'peace': 718.9090909090909}\n",
      "2021-08-25 13:30:57.322 | INFO     | src.policies:train:103 - Epoch 54 / 4000\n",
      "2021-08-25 13:30:57.323 | INFO     | src.policies:train:110 - Episode 54\n",
      "2021-08-25 13:31:21.828 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:31:21.856 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 217.8181818181818, 'equality': 0.9244194870252614, 'sustainability': 489.18477372369665, 'peace': 717.8181818181819}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 13:31:21.857 | INFO     | src.policies:train:122 - Mean episode return: 217.8181818181818\n",
      "2021-08-25 13:31:21.857 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 210.35185185185185\n",
      "2021-08-25 13:31:21.858 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:31:31.444 | INFO     | src.policies:train:159 - Total loss: 1.000842809677124\n",
      "2021-08-25 13:31:31.445 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 217.8181818181818, 'equality': 0.9244194870252614, 'sustainability': 489.18477372369665, 'peace': 717.8181818181819}\n",
      "2021-08-25 13:31:31.495 | INFO     | src.policies:train:103 - Epoch 55 / 4000\n",
      "2021-08-25 13:31:31.495 | INFO     | src.policies:train:110 - Episode 55\n",
      "2021-08-25 13:31:54.230 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:31:54.255 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 196.36363636363637, 'equality': 0.9030303030323437, 'sustainability': 479.37800590856585, 'peace': 659.5454545454545}\n",
      "2021-08-25 13:31:54.256 | INFO     | src.policies:train:122 - Mean episode return: 196.36363636363637\n",
      "2021-08-25 13:31:54.256 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 210.097520661157\n",
      "2021-08-25 13:31:54.257 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:32:03.295 | INFO     | src.policies:train:159 - Total loss: 0.9999598860740662\n",
      "2021-08-25 13:32:03.295 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 196.36363636363637, 'equality': 0.9030303030323437, 'sustainability': 479.37800590856585, 'peace': 659.5454545454545}\n",
      "2021-08-25 13:32:03.345 | INFO     | src.policies:train:103 - Epoch 56 / 4000\n",
      "2021-08-25 13:32:03.346 | INFO     | src.policies:train:110 - Episode 56\n",
      "2021-08-25 13:32:25.251 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:32:25.276 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 195.54545454545453, 'equality': 0.8730400236703216, 'sustainability': 466.52774818388446, 'peace': 697.5454545454545}\n",
      "2021-08-25 13:32:25.276 | INFO     | src.policies:train:122 - Mean episode return: 195.54545454545453\n",
      "2021-08-25 13:32:25.277 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.83766233766235\n",
      "2021-08-25 13:32:25.277 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:32:34.316 | INFO     | src.policies:train:159 - Total loss: 0.9981557130813599\n",
      "2021-08-25 13:32:34.317 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 195.54545454545453, 'equality': 0.8730400236703216, 'sustainability': 466.52774818388446, 'peace': 697.5454545454545}\n",
      "2021-08-25 13:32:34.366 | INFO     | src.policies:train:103 - Epoch 57 / 4000\n",
      "2021-08-25 13:32:34.367 | INFO     | src.policies:train:110 - Episode 57\n",
      "2021-08-25 13:32:55.769 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:32:55.792 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 206.8181818181818, 'equality': 0.923916083917604, 'sustainability': 496.3858530489087, 'peace': 710.1818181818181}\n",
      "2021-08-25 13:32:55.793 | INFO     | src.policies:train:122 - Mean episode return: 206.8181818181818\n",
      "2021-08-25 13:32:55.793 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.78468899521533\n",
      "2021-08-25 13:32:55.794 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:33:04.844 | INFO     | src.policies:train:159 - Total loss: 0.9995384812355042\n",
      "2021-08-25 13:33:04.845 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 206.8181818181818, 'equality': 0.923916083917604, 'sustainability': 496.3858530489087, 'peace': 710.1818181818181}\n",
      "2021-08-25 13:33:04.893 | INFO     | src.policies:train:103 - Epoch 58 / 4000\n",
      "2021-08-25 13:33:04.894 | INFO     | src.policies:train:110 - Episode 58\n",
      "2021-08-25 13:33:27.355 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:33:27.380 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 211.0, 'equality': 0.9566017782312365, 'sustainability': 496.93357105655656, 'peace': 774.1818181818181}\n",
      "2021-08-25 13:33:27.381 | INFO     | src.policies:train:122 - Mean episode return: 211.0\n",
      "2021-08-25 13:33:27.382 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.80564263322887\n",
      "2021-08-25 13:33:27.382 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:33:36.705 | INFO     | src.policies:train:159 - Total loss: 0.9960088133811951\n",
      "2021-08-25 13:33:36.706 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 211.0, 'equality': 0.9566017782312365, 'sustainability': 496.93357105655656, 'peace': 774.1818181818181}\n",
      "2021-08-25 13:33:36.755 | INFO     | src.policies:train:103 - Epoch 59 / 4000\n",
      "2021-08-25 13:33:36.756 | INFO     | src.policies:train:110 - Episode 59\n",
      "2021-08-25 13:33:58.695 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:33:58.723 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 205.0, 'equality': 0.9107438016546917, 'sustainability': 523.9582917636579, 'peace': 693.3636363636364}\n",
      "2021-08-25 13:33:58.724 | INFO     | src.policies:train:122 - Mean episode return: 205.0\n",
      "2021-08-25 13:33:58.724 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.72419106317415\n",
      "2021-08-25 13:33:58.725 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:34:08.067 | INFO     | src.policies:train:159 - Total loss: 1.0031304359436035\n",
      "2021-08-25 13:34:08.068 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 205.0, 'equality': 0.9107438016546917, 'sustainability': 523.9582917636579, 'peace': 693.3636363636364}\n",
      "2021-08-25 13:34:08.117 | INFO     | src.policies:train:103 - Epoch 60 / 4000\n",
      "2021-08-25 13:34:08.118 | INFO     | src.policies:train:110 - Episode 60\n",
      "2021-08-25 13:34:30.523 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:34:30.547 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 208.0, 'equality': 0.8801652892585791, 'sustainability': 475.0603464679218, 'peace': 743.0}\n",
      "2021-08-25 13:34:30.548 | INFO     | src.policies:train:122 - Mean episode return: 208.0\n",
      "2021-08-25 13:34:30.549 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.69545454545457\n",
      "2021-08-25 13:34:30.549 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:34:39.622 | INFO     | src.policies:train:159 - Total loss: 1.002260684967041\n",
      "2021-08-25 13:34:39.623 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 208.0, 'equality': 0.8801652892585791, 'sustainability': 475.0603464679218, 'peace': 743.0}\n",
      "2021-08-25 13:34:39.673 | INFO     | src.policies:train:103 - Epoch 61 / 4000\n",
      "2021-08-25 13:34:39.673 | INFO     | src.policies:train:110 - Episode 61\n",
      "2021-08-25 13:35:01.872 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:35:01.896 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 193.72727272727272, 'equality': 0.9249178789316813, 'sustainability': 445.1004284890915, 'peace': 694.5454545454545}\n",
      "2021-08-25 13:35:01.897 | INFO     | src.policies:train:122 - Mean episode return: 193.72727272727272\n",
      "2021-08-25 13:35:01.897 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.43368107302535\n",
      "2021-08-25 13:35:01.898 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:35:10.939 | INFO     | src.policies:train:159 - Total loss: 0.9981707334518433\n",
      "2021-08-25 13:35:10.940 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 193.72727272727272, 'equality': 0.9249178789316813, 'sustainability': 445.1004284890915, 'peace': 694.5454545454545}\n",
      "2021-08-25 13:35:10.989 | INFO     | src.policies:train:103 - Epoch 62 / 4000\n",
      "2021-08-25 13:35:10.989 | INFO     | src.policies:train:110 - Episode 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 13:35:33.107 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:35:33.132 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 202.8181818181818, 'equality': 0.8948698097083478, 'sustainability': 483.87186448110066, 'peace': 703.5454545454545}\n",
      "2021-08-25 13:35:33.132 | INFO     | src.policies:train:122 - Mean episode return: 202.8181818181818\n",
      "2021-08-25 13:35:33.133 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.32697947214078\n",
      "2021-08-25 13:35:33.133 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:35:42.191 | INFO     | src.policies:train:159 - Total loss: 1.004791021347046\n",
      "2021-08-25 13:35:42.192 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 202.8181818181818, 'equality': 0.8948698097083478, 'sustainability': 483.87186448110066, 'peace': 703.5454545454545}\n",
      "2021-08-25 13:35:42.240 | INFO     | src.policies:train:103 - Epoch 63 / 4000\n",
      "2021-08-25 13:35:42.241 | INFO     | src.policies:train:110 - Episode 63\n",
      "2021-08-25 13:36:04.774 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:36:04.797 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 198.0, 'equality': 0.9104265798499368, 'sustainability': 495.9052504513218, 'peace': 641.2727272727273}\n",
      "2021-08-25 13:36:04.797 | INFO     | src.policies:train:122 - Mean episode return: 198.0\n",
      "2021-08-25 13:36:04.798 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.14718614718615\n",
      "2021-08-25 13:36:04.798 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:36:13.922 | INFO     | src.policies:train:159 - Total loss: 1.00167977809906\n",
      "2021-08-25 13:36:13.923 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 198.0, 'equality': 0.9104265798499368, 'sustainability': 495.9052504513218, 'peace': 641.2727272727273}\n",
      "2021-08-25 13:36:13.972 | INFO     | src.policies:train:103 - Epoch 64 / 4000\n",
      "2021-08-25 13:36:13.973 | INFO     | src.policies:train:110 - Episode 64\n",
      "2021-08-25 13:36:35.684 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:36:35.709 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 220.9090909090909, 'equality': 0.944930789376264, 'sustainability': 490.36772751002775, 'peace': 736.6363636363636}\n",
      "2021-08-25 13:36:35.710 | INFO     | src.policies:train:122 - Mean episode return: 220.9090909090909\n",
      "2021-08-25 13:36:35.711 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.3309659090909\n",
      "2021-08-25 13:36:35.711 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:36:44.792 | INFO     | src.policies:train:159 - Total loss: 1.0086371898651123\n",
      "2021-08-25 13:36:44.793 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 220.9090909090909, 'equality': 0.944930789376264, 'sustainability': 490.36772751002775, 'peace': 736.6363636363636}\n",
      "2021-08-25 13:36:44.842 | INFO     | src.policies:train:103 - Epoch 65 / 4000\n",
      "2021-08-25 13:36:44.842 | INFO     | src.policies:train:110 - Episode 65\n",
      "2021-08-25 13:37:08.068 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:37:08.092 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 197.36363636363637, 'equality': 0.913403961309966, 'sustainability': 501.5943823641979, 'peace': 663.1818181818181}\n",
      "2021-08-25 13:37:08.093 | INFO     | src.policies:train:122 - Mean episode return: 197.36363636363637\n",
      "2021-08-25 13:37:08.093 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.14685314685315\n",
      "2021-08-25 13:37:08.094 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:37:17.271 | INFO     | src.policies:train:159 - Total loss: 0.996584951877594\n",
      "2021-08-25 13:37:17.272 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 197.36363636363637, 'equality': 0.913403961309966, 'sustainability': 501.5943823641979, 'peace': 663.1818181818181}\n",
      "2021-08-25 13:37:17.320 | INFO     | src.policies:train:103 - Epoch 66 / 4000\n",
      "2021-08-25 13:37:17.321 | INFO     | src.policies:train:110 - Episode 66\n",
      "2021-08-25 13:37:39.346 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:37:39.371 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 208.54545454545453, 'equality': 0.9220099865276609, 'sustainability': 490.56078407160953, 'peace': 659.0909090909091}\n",
      "2021-08-25 13:37:39.372 | INFO     | src.policies:train:122 - Mean episode return: 208.54545454545453\n",
      "2021-08-25 13:37:39.372 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 209.13774104683193\n",
      "2021-08-25 13:37:39.373 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:37:48.454 | INFO     | src.policies:train:159 - Total loss: 1.000347375869751\n",
      "2021-08-25 13:37:48.455 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 208.54545454545453, 'equality': 0.9220099865276609, 'sustainability': 490.56078407160953, 'peace': 659.0909090909091}\n",
      "2021-08-25 13:37:48.505 | INFO     | src.policies:train:103 - Epoch 67 / 4000\n",
      "2021-08-25 13:37:48.505 | INFO     | src.policies:train:110 - Episode 67\n",
      "2021-08-25 13:38:10.741 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:38:10.763 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 190.63636363636363, 'equality': 0.9257814193452598, 'sustainability': 490.2483973450971, 'peace': 673.9090909090909}\n",
      "2021-08-25 13:38:10.764 | INFO     | src.policies:train:122 - Mean episode return: 190.63636363636363\n",
      "2021-08-25 13:38:10.765 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.86160108548168\n",
      "2021-08-25 13:38:10.765 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:38:19.836 | INFO     | src.policies:train:159 - Total loss: 0.9960511922836304\n",
      "2021-08-25 13:38:19.836 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 190.63636363636363, 'equality': 0.9257814193452598, 'sustainability': 490.2483973450971, 'peace': 673.9090909090909}\n",
      "2021-08-25 13:38:19.885 | INFO     | src.policies:train:103 - Epoch 68 / 4000\n",
      "2021-08-25 13:38:19.886 | INFO     | src.policies:train:110 - Episode 68\n",
      "2021-08-25 13:38:42.416 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:38:42.438 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 189.36363636363637, 'equality': 0.9097455592914558, 'sustainability': 485.22114847047266, 'peace': 707.6363636363636}\n",
      "2021-08-25 13:38:42.438 | INFO     | src.policies:train:122 - Mean episode return: 189.36363636363637\n",
      "2021-08-25 13:38:42.439 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.57486631016042\n",
      "2021-08-25 13:38:42.440 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:38:51.763 | INFO     | src.policies:train:159 - Total loss: 0.99872887134552\n",
      "2021-08-25 13:38:51.764 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 189.36363636363637, 'equality': 0.9097455592914558, 'sustainability': 485.22114847047266, 'peace': 707.6363636363636}\n",
      "2021-08-25 13:38:51.814 | INFO     | src.policies:train:103 - Epoch 69 / 4000\n",
      "2021-08-25 13:38:51.815 | INFO     | src.policies:train:110 - Episode 69\n",
      "2021-08-25 13:39:14.462 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:39:14.485 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 199.8181818181818, 'equality': 0.9262966333045269, 'sustainability': 466.8555455640329, 'peace': 701.5454545454545}\n",
      "2021-08-25 13:39:14.486 | INFO     | src.policies:train:122 - Mean episode return: 199.8181818181818\n",
      "2021-08-25 13:39:14.486 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.4479578392622\n",
      "2021-08-25 13:39:14.487 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 13:39:23.815 | INFO     | src.policies:train:159 - Total loss: 1.0009381771087646\n",
      "2021-08-25 13:39:23.815 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 199.8181818181818, 'equality': 0.9262966333045269, 'sustainability': 466.8555455640329, 'peace': 701.5454545454545}\n",
      "2021-08-25 13:39:23.865 | INFO     | src.policies:train:103 - Epoch 70 / 4000\n",
      "2021-08-25 13:39:23.866 | INFO     | src.policies:train:110 - Episode 70\n",
      "2021-08-25 13:39:46.689 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:39:46.717 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 213.45454545454547, 'equality': 0.9468019203974988, 'sustainability': 494.0652500967135, 'peace': 763.9090909090909}\n",
      "2021-08-25 13:39:46.718 | INFO     | src.policies:train:122 - Mean episode return: 213.45454545454547\n",
      "2021-08-25 13:39:46.718 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.5194805194805\n",
      "2021-08-25 13:39:46.719 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:39:55.714 | INFO     | src.policies:train:159 - Total loss: 0.9917696118354797\n",
      "2021-08-25 13:39:55.715 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 213.45454545454547, 'equality': 0.9468019203974988, 'sustainability': 494.0652500967135, 'peace': 763.9090909090909}\n",
      "2021-08-25 13:39:55.764 | INFO     | src.policies:train:103 - Epoch 71 / 4000\n",
      "2021-08-25 13:39:55.764 | INFO     | src.policies:train:110 - Episode 71\n",
      "2021-08-25 13:40:17.447 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:40:17.469 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 190.54545454545453, 'equality': 0.9443095072878143, 'sustainability': 465.80393850295036, 'peace': 670.8181818181819}\n",
      "2021-08-25 13:40:17.470 | INFO     | src.policies:train:122 - Mean episode return: 190.54545454545453\n",
      "2021-08-25 13:40:17.471 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.2663252240717\n",
      "2021-08-25 13:40:17.471 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:40:26.346 | INFO     | src.policies:train:159 - Total loss: 1.0002104043960571\n",
      "2021-08-25 13:40:26.346 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 190.54545454545453, 'equality': 0.9443095072878143, 'sustainability': 465.80393850295036, 'peace': 670.8181818181819}\n",
      "2021-08-25 13:40:26.394 | INFO     | src.policies:train:103 - Epoch 72 / 4000\n",
      "2021-08-25 13:40:26.395 | INFO     | src.policies:train:110 - Episode 72\n",
      "2021-08-25 13:40:47.867 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:40:47.890 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 197.63636363636363, 'equality': 0.9074182487265322, 'sustainability': 515.0265055095552, 'peace': 742.3636363636364}\n",
      "2021-08-25 13:40:47.891 | INFO     | src.policies:train:122 - Mean episode return: 197.63636363636363\n",
      "2021-08-25 13:40:47.891 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.11868686868686\n",
      "2021-08-25 13:40:47.892 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:40:56.711 | INFO     | src.policies:train:159 - Total loss: 0.9977312088012695\n",
      "2021-08-25 13:40:56.712 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 197.63636363636363, 'equality': 0.9074182487265322, 'sustainability': 515.0265055095552, 'peace': 742.3636363636364}\n",
      "2021-08-25 13:40:56.759 | INFO     | src.policies:train:103 - Epoch 73 / 4000\n",
      "2021-08-25 13:40:56.760 | INFO     | src.policies:train:110 - Episode 73\n",
      "2021-08-25 13:41:19.522 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:41:19.548 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 200.54545454545453, 'equality': 0.8976345504018455, 'sustainability': 481.45001896664945, 'peace': 725.3636363636364}\n",
      "2021-08-25 13:41:19.548 | INFO     | src.policies:train:122 - Mean episode return: 200.54545454545453\n",
      "2021-08-25 13:41:19.549 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.01494396014942\n",
      "2021-08-25 13:41:19.549 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:41:28.891 | INFO     | src.policies:train:159 - Total loss: 0.9989869594573975\n",
      "2021-08-25 13:41:28.892 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 200.54545454545453, 'equality': 0.8976345504018455, 'sustainability': 481.45001896664945, 'peace': 725.3636363636364}\n",
      "2021-08-25 13:41:28.944 | INFO     | src.policies:train:103 - Epoch 74 / 4000\n",
      "2021-08-25 13:41:28.944 | INFO     | src.policies:train:110 - Episode 74\n",
      "2021-08-25 13:41:52.140 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:41:52.165 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 213.8181818181818, 'equality': 0.9394712430438414, 'sustainability': 493.6436946469378, 'peace': 772.2727272727273}\n",
      "2021-08-25 13:41:52.166 | INFO     | src.policies:train:122 - Mean episode return: 213.8181818181818\n",
      "2021-08-25 13:41:52.166 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.0933660933661\n",
      "2021-08-25 13:41:52.167 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:42:01.439 | INFO     | src.policies:train:159 - Total loss: 1.0007433891296387\n",
      "2021-08-25 13:42:01.440 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 213.8181818181818, 'equality': 0.9394712430438414, 'sustainability': 493.6436946469378, 'peace': 772.2727272727273}\n",
      "2021-08-25 13:42:01.490 | INFO     | src.policies:train:103 - Epoch 75 / 4000\n",
      "2021-08-25 13:42:01.490 | INFO     | src.policies:train:110 - Episode 75\n",
      "2021-08-25 13:42:24.675 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:42:24.697 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 212.27272727272728, 'equality': 0.9268833949790367, 'sustainability': 484.44530123822483, 'peace': 705.4545454545455}\n",
      "2021-08-25 13:42:24.697 | INFO     | src.policies:train:122 - Mean episode return: 212.27272727272728\n",
      "2021-08-25 13:42:24.698 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.14909090909092\n",
      "2021-08-25 13:42:24.698 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:42:34.019 | INFO     | src.policies:train:159 - Total loss: 1.0006242990493774\n",
      "2021-08-25 13:42:34.020 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 212.27272727272728, 'equality': 0.9268833949790367, 'sustainability': 484.44530123822483, 'peace': 705.4545454545455}\n",
      "2021-08-25 13:42:34.071 | INFO     | src.policies:train:103 - Epoch 76 / 4000\n",
      "2021-08-25 13:42:34.072 | INFO     | src.policies:train:110 - Episode 76\n",
      "2021-08-25 13:42:56.844 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:42:56.869 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 209.54545454545453, 'equality': 0.9533819759425481, 'sustainability': 482.2692068461342, 'peace': 735.2727272727273}\n",
      "2021-08-25 13:42:56.870 | INFO     | src.policies:train:122 - Mean episode return: 209.54545454545453\n",
      "2021-08-25 13:42:56.871 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.16746411483254\n",
      "2021-08-25 13:42:56.871 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:43:05.966 | INFO     | src.policies:train:159 - Total loss: 0.9966504573822021\n",
      "2021-08-25 13:43:05.966 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 209.54545454545453, 'equality': 0.9533819759425481, 'sustainability': 482.2692068461342, 'peace': 735.2727272727273}\n",
      "2021-08-25 13:43:06.017 | INFO     | src.policies:train:103 - Epoch 77 / 4000\n",
      "2021-08-25 13:43:06.018 | INFO     | src.policies:train:110 - Episode 77\n",
      "2021-08-25 13:43:28.345 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:43:28.369 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 198.27272727272728, 'equality': 0.9363928139732318, 'sustainability': 470.1142073718709, 'peace': 700.6363636363636}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 13:43:28.370 | INFO     | src.policies:train:122 - Mean episode return: 198.27272727272728\n",
      "2021-08-25 13:43:28.370 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.03896103896105\n",
      "2021-08-25 13:43:28.371 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:43:37.445 | INFO     | src.policies:train:159 - Total loss: 0.9987347722053528\n",
      "2021-08-25 13:43:37.446 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 198.27272727272728, 'equality': 0.9363928139732318, 'sustainability': 470.1142073718709, 'peace': 700.6363636363636}\n",
      "2021-08-25 13:43:37.495 | INFO     | src.policies:train:103 - Epoch 78 / 4000\n",
      "2021-08-25 13:43:37.496 | INFO     | src.policies:train:110 - Episode 78\n",
      "2021-08-25 13:43:59.854 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:43:59.877 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 201.45454545454547, 'equality': 0.9405973088295743, 'sustainability': 476.0885174774863, 'peace': 720.2727272727273}\n",
      "2021-08-25 13:43:59.877 | INFO     | src.policies:train:122 - Mean episode return: 201.45454545454547\n",
      "2021-08-25 13:43:59.878 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.95454545454547\n",
      "2021-08-25 13:43:59.878 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:44:08.728 | INFO     | src.policies:train:159 - Total loss: 0.9959748387336731\n",
      "2021-08-25 13:44:08.729 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 201.45454545454547, 'equality': 0.9405973088295743, 'sustainability': 476.0885174774863, 'peace': 720.2727272727273}\n",
      "2021-08-25 13:44:08.779 | INFO     | src.policies:train:103 - Epoch 79 / 4000\n",
      "2021-08-25 13:44:08.779 | INFO     | src.policies:train:110 - Episode 79\n",
      "2021-08-25 13:44:29.898 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:44:29.919 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 229.1818181818182, 'equality': 0.9390573726165833, 'sustainability': 471.6513722242713, 'peace': 769.8181818181819}\n",
      "2021-08-25 13:44:29.920 | INFO     | src.policies:train:122 - Mean episode return: 229.1818181818182\n",
      "2021-08-25 13:44:29.921 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.22324510932106\n",
      "2021-08-25 13:44:29.921 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:44:38.751 | INFO     | src.policies:train:159 - Total loss: 0.9979003667831421\n",
      "2021-08-25 13:44:38.752 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 229.1818181818182, 'equality': 0.9390573726165833, 'sustainability': 471.6513722242713, 'peace': 769.8181818181819}\n",
      "2021-08-25 13:44:38.802 | INFO     | src.policies:train:103 - Epoch 80 / 4000\n",
      "2021-08-25 13:44:38.803 | INFO     | src.policies:train:110 - Episode 80\n",
      "2021-08-25 13:45:00.884 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:45:00.911 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 205.8181818181818, 'equality': 0.9424991969173125, 'sustainability': 483.861797375196, 'peace': 744.3636363636364}\n",
      "2021-08-25 13:45:00.911 | INFO     | src.policies:train:122 - Mean episode return: 205.8181818181818\n",
      "2021-08-25 13:45:00.912 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.1931818181818\n",
      "2021-08-25 13:45:00.912 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:45:10.130 | INFO     | src.policies:train:159 - Total loss: 0.9985126256942749\n",
      "2021-08-25 13:45:10.131 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 205.8181818181818, 'equality': 0.9424991969173125, 'sustainability': 483.861797375196, 'peace': 744.3636363636364}\n",
      "2021-08-25 13:45:10.185 | INFO     | src.policies:train:103 - Epoch 81 / 4000\n",
      "2021-08-25 13:45:10.185 | INFO     | src.policies:train:110 - Episode 81\n",
      "2021-08-25 13:45:32.912 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:45:32.935 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 207.0, 'equality': 0.9465005789127141, 'sustainability': 475.44147145503035, 'peace': 653.2727272727273}\n",
      "2021-08-25 13:45:32.936 | INFO     | src.policies:train:122 - Mean episode return: 207.0\n",
      "2021-08-25 13:45:32.937 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.17845117845116\n",
      "2021-08-25 13:45:32.937 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:45:42.247 | INFO     | src.policies:train:159 - Total loss: 1.000834345817566\n",
      "2021-08-25 13:45:42.248 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 207.0, 'equality': 0.9465005789127141, 'sustainability': 475.44147145503035, 'peace': 653.2727272727273}\n",
      "2021-08-25 13:45:42.298 | INFO     | src.policies:train:103 - Epoch 82 / 4000\n",
      "2021-08-25 13:45:42.299 | INFO     | src.policies:train:110 - Episode 82\n",
      "2021-08-25 13:46:05.115 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:46:05.137 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 222.45454545454547, 'equality': 0.9361741650270057, 'sustainability': 487.46527645680004, 'peace': 706.1818181818181}\n",
      "2021-08-25 13:46:05.137 | INFO     | src.policies:train:122 - Mean episode return: 222.45454545454547\n",
      "2021-08-25 13:46:05.138 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.35254988913522\n",
      "2021-08-25 13:46:05.138 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:46:14.219 | INFO     | src.policies:train:159 - Total loss: 1.0019911527633667\n",
      "2021-08-25 13:46:14.220 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 222.45454545454547, 'equality': 0.9361741650270057, 'sustainability': 487.46527645680004, 'peace': 706.1818181818181}\n",
      "2021-08-25 13:46:14.269 | INFO     | src.policies:train:103 - Epoch 83 / 4000\n",
      "2021-08-25 13:46:14.269 | INFO     | src.policies:train:110 - Episode 83\n",
      "2021-08-25 13:46:36.164 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:46:36.186 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 184.27272727272728, 'equality': 0.9016011122594609, 'sustainability': 475.2176619126736, 'peace': 607.0}\n",
      "2021-08-25 13:46:36.187 | INFO     | src.policies:train:122 - Mean episode return: 184.27272727272728\n",
      "2021-08-25 13:46:36.187 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.06243154435924\n",
      "2021-08-25 13:46:36.188 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:46:45.283 | INFO     | src.policies:train:159 - Total loss: 1.0056734085083008\n",
      "2021-08-25 13:46:45.284 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 184.27272727272728, 'equality': 0.9016011122594609, 'sustainability': 475.2176619126736, 'peace': 607.0}\n",
      "2021-08-25 13:46:45.333 | INFO     | src.policies:train:103 - Epoch 84 / 4000\n",
      "2021-08-25 13:46:45.333 | INFO     | src.policies:train:110 - Episode 84\n",
      "2021-08-25 13:47:07.107 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:47:07.133 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 214.27272727272728, 'equality': 0.912600763684333, 'sustainability': 496.41652984227784, 'peace': 759.5454545454545}\n",
      "2021-08-25 13:47:07.133 | INFO     | src.policies:train:122 - Mean episode return: 214.27272727272728\n",
      "2021-08-25 13:47:07.134 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.13636363636363\n",
      "2021-08-25 13:47:07.134 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:47:15.936 | INFO     | src.policies:train:159 - Total loss: 1.0028316974639893\n",
      "2021-08-25 13:47:15.937 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 214.27272727272728, 'equality': 0.912600763684333, 'sustainability': 496.41652984227784, 'peace': 759.5454545454545}\n",
      "2021-08-25 13:47:15.989 | INFO     | src.policies:train:103 - Epoch 85 / 4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 13:47:15.990 | INFO     | src.policies:train:110 - Episode 85\n",
      "2021-08-25 13:47:37.701 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:47:37.725 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 194.0909090909091, 'equality': 0.9129657228036414, 'sustainability': 502.9879926180079, 'peace': 766.0}\n",
      "2021-08-25 13:47:37.725 | INFO     | src.policies:train:122 - Mean episode return: 194.0909090909091\n",
      "2021-08-25 13:47:37.726 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.97112299465238\n",
      "2021-08-25 13:47:37.726 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:47:46.830 | INFO     | src.policies:train:159 - Total loss: 1.0055216550827026\n",
      "2021-08-25 13:47:46.831 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 194.0909090909091, 'equality': 0.9129657228036414, 'sustainability': 502.9879926180079, 'peace': 766.0}\n",
      "2021-08-25 13:47:46.882 | INFO     | src.policies:train:103 - Epoch 86 / 4000\n",
      "2021-08-25 13:47:46.882 | INFO     | src.policies:train:110 - Episode 86\n",
      "2021-08-25 13:48:10.145 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:48:10.168 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 199.0909090909091, 'equality': 0.9285180572866643, 'sustainability': 482.0455924502832, 'peace': 724.0}\n",
      "2021-08-25 13:48:10.168 | INFO     | src.policies:train:122 - Mean episode return: 199.0909090909091\n",
      "2021-08-25 13:48:10.169 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.86786469344605\n",
      "2021-08-25 13:48:10.169 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:48:19.552 | INFO     | src.policies:train:159 - Total loss: 1.001051425933838\n",
      "2021-08-25 13:48:19.553 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 199.0909090909091, 'equality': 0.9285180572866643, 'sustainability': 482.0455924502832, 'peace': 724.0}\n",
      "2021-08-25 13:48:19.607 | INFO     | src.policies:train:103 - Epoch 87 / 4000\n",
      "2021-08-25 13:48:19.608 | INFO     | src.policies:train:110 - Episode 87\n",
      "2021-08-25 13:48:42.500 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:48:42.524 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 204.63636363636363, 'equality': 0.9060619522655373, 'sustainability': 489.67314184671227, 'peace': 693.0}\n",
      "2021-08-25 13:48:42.525 | INFO     | src.policies:train:122 - Mean episode return: 204.63636363636363\n",
      "2021-08-25 13:48:42.525 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.83072100313476\n",
      "2021-08-25 13:48:42.526 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:48:51.913 | INFO     | src.policies:train:159 - Total loss: 0.9971688389778137\n",
      "2021-08-25 13:48:51.914 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 204.63636363636363, 'equality': 0.9060619522655373, 'sustainability': 489.67314184671227, 'peace': 693.0}\n",
      "2021-08-25 13:48:51.964 | INFO     | src.policies:train:103 - Epoch 88 / 4000\n",
      "2021-08-25 13:48:51.965 | INFO     | src.policies:train:110 - Episode 88\n",
      "2021-08-25 13:49:14.557 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:49:14.580 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 198.1818181818182, 'equality': 0.8739783152653466, 'sustainability': 481.16832134236387, 'peace': 744.6363636363636}\n",
      "2021-08-25 13:49:14.581 | INFO     | src.policies:train:122 - Mean episode return: 198.1818181818182\n",
      "2021-08-25 13:49:14.581 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.72107438016528\n",
      "2021-08-25 13:49:14.582 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:49:23.670 | INFO     | src.policies:train:159 - Total loss: 1.0002379417419434\n",
      "2021-08-25 13:49:23.671 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 198.1818181818182, 'equality': 0.8739783152653466, 'sustainability': 481.16832134236387, 'peace': 744.6363636363636}\n",
      "2021-08-25 13:49:23.720 | INFO     | src.policies:train:103 - Epoch 89 / 4000\n",
      "2021-08-25 13:49:23.721 | INFO     | src.policies:train:110 - Episode 89\n",
      "2021-08-25 13:49:46.303 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:49:46.327 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 216.1818181818182, 'equality': 0.9598593164622704, 'sustainability': 491.31182313633695, 'peace': 799.9090909090909}\n",
      "2021-08-25 13:49:46.327 | INFO     | src.policies:train:122 - Mean episode return: 216.1818181818182\n",
      "2021-08-25 13:49:46.328 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.81613891726252\n",
      "2021-08-25 13:49:46.328 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:49:55.391 | INFO     | src.policies:train:159 - Total loss: 0.997453510761261\n",
      "2021-08-25 13:49:55.392 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 216.1818181818182, 'equality': 0.9598593164622704, 'sustainability': 491.31182313633695, 'peace': 799.9090909090909}\n",
      "2021-08-25 13:49:55.441 | INFO     | src.policies:train:103 - Epoch 90 / 4000\n",
      "2021-08-25 13:49:55.442 | INFO     | src.policies:train:110 - Episode 90\n",
      "2021-08-25 13:50:17.358 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:50:17.379 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 204.0, 'equality': 0.9369632150393582, 'sustainability': 487.28127802893874, 'peace': 752.0}\n",
      "2021-08-25 13:50:17.380 | INFO     | src.policies:train:122 - Mean episode return: 204.0\n",
      "2021-08-25 13:50:17.380 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.7737373737374\n",
      "2021-08-25 13:50:17.381 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:50:26.445 | INFO     | src.policies:train:159 - Total loss: 1.000418782234192\n",
      "2021-08-25 13:50:26.445 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 204.0, 'equality': 0.9369632150393582, 'sustainability': 487.28127802893874, 'peace': 752.0}\n",
      "2021-08-25 13:50:26.496 | INFO     | src.policies:train:103 - Epoch 91 / 4000\n",
      "2021-08-25 13:50:26.497 | INFO     | src.policies:train:110 - Episode 91\n",
      "2021-08-25 13:50:49.852 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:50:49.874 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 207.63636363636363, 'equality': 0.9078968317165281, 'sustainability': 498.3116352123585, 'peace': 731.5454545454545}\n",
      "2021-08-25 13:50:49.875 | INFO     | src.policies:train:122 - Mean episode return: 207.63636363636363\n",
      "2021-08-25 13:50:49.875 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.77222777222778\n",
      "2021-08-25 13:50:49.876 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:50:58.944 | INFO     | src.policies:train:159 - Total loss: 1.0101032257080078\n",
      "2021-08-25 13:50:58.945 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 207.63636363636363, 'equality': 0.9078968317165281, 'sustainability': 498.3116352123585, 'peace': 731.5454545454545}\n",
      "2021-08-25 13:50:58.994 | INFO     | src.policies:train:103 - Epoch 92 / 4000\n",
      "2021-08-25 13:50:58.995 | INFO     | src.policies:train:110 - Episode 92\n",
      "2021-08-25 13:51:22.705 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:51:22.736 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 218.63636363636363, 'equality': 0.9092799092816239, 'sustainability': 510.7701598743622, 'peace': 743.8181818181819}\n",
      "2021-08-25 13:51:22.737 | INFO     | src.policies:train:122 - Mean episode return: 218.63636363636363\n",
      "2021-08-25 13:51:22.737 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.8903162055336\n",
      "2021-08-25 13:51:22.738 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:51:32.718 | INFO     | src.policies:train:159 - Total loss: 1.0048973560333252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 13:51:32.719 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 218.63636363636363, 'equality': 0.9092799092816239, 'sustainability': 510.7701598743622, 'peace': 743.8181818181819}\n",
      "2021-08-25 13:51:32.775 | INFO     | src.policies:train:103 - Epoch 93 / 4000\n",
      "2021-08-25 13:51:32.776 | INFO     | src.policies:train:110 - Episode 93\n",
      "2021-08-25 13:51:58.501 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:51:58.528 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 200.36363636363637, 'equality': 0.9674146180504988, 'sustainability': 470.52826071218317, 'peace': 734.0909090909091}\n",
      "2021-08-25 13:51:58.529 | INFO     | src.policies:train:122 - Mean episode return: 200.36363636363637\n",
      "2021-08-25 13:51:58.530 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.80938416422288\n",
      "2021-08-25 13:51:58.531 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:52:09.545 | INFO     | src.policies:train:159 - Total loss: 1.0045057535171509\n",
      "2021-08-25 13:52:09.546 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 200.36363636363637, 'equality': 0.9674146180504988, 'sustainability': 470.52826071218317, 'peace': 734.0909090909091}\n",
      "2021-08-25 13:52:09.608 | INFO     | src.policies:train:103 - Epoch 94 / 4000\n",
      "2021-08-25 13:52:09.609 | INFO     | src.policies:train:110 - Episode 94\n",
      "2021-08-25 13:52:35.312 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:52:35.337 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 206.9090909090909, 'equality': 0.9319380092680153, 'sustainability': 477.0862378980426, 'peace': 703.5454545454545}\n",
      "2021-08-25 13:52:35.338 | INFO     | src.policies:train:122 - Mean episode return: 206.9090909090909\n",
      "2021-08-25 13:52:35.338 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.79980657640235\n",
      "2021-08-25 13:52:35.339 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:52:45.252 | INFO     | src.policies:train:159 - Total loss: 1.0020177364349365\n",
      "2021-08-25 13:52:45.252 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 206.9090909090909, 'equality': 0.9319380092680153, 'sustainability': 477.0862378980426, 'peace': 703.5454545454545}\n",
      "2021-08-25 13:52:45.306 | INFO     | src.policies:train:103 - Epoch 95 / 4000\n",
      "2021-08-25 13:52:45.306 | INFO     | src.policies:train:110 - Episode 95\n",
      "2021-08-25 13:53:07.262 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:53:07.287 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 186.63636363636363, 'equality': 0.8847805871698893, 'sustainability': 495.2311076269423, 'peace': 631.0909090909091}\n",
      "2021-08-25 13:53:07.287 | INFO     | src.policies:train:122 - Mean episode return: 186.63636363636363\n",
      "2021-08-25 13:53:07.288 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.57703349282298\n",
      "2021-08-25 13:53:07.288 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:53:16.372 | INFO     | src.policies:train:159 - Total loss: 0.999157726764679\n",
      "2021-08-25 13:53:16.373 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 186.63636363636363, 'equality': 0.8847805871698893, 'sustainability': 495.2311076269423, 'peace': 631.0909090909091}\n",
      "2021-08-25 13:53:16.422 | INFO     | src.policies:train:103 - Epoch 96 / 4000\n",
      "2021-08-25 13:53:16.423 | INFO     | src.policies:train:110 - Episode 96\n",
      "2021-08-25 13:53:39.034 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:53:39.055 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 214.9090909090909, 'equality': 0.93016459006441, 'sustainability': 497.48764944467183, 'peace': 825.1818181818181}\n",
      "2021-08-25 13:53:39.056 | INFO     | src.policies:train:122 - Mean episode return: 214.9090909090909\n",
      "2021-08-25 13:53:39.057 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.6534090909091\n",
      "2021-08-25 13:53:39.057 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:53:47.888 | INFO     | src.policies:train:159 - Total loss: 0.9989537000656128\n",
      "2021-08-25 13:53:47.888 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 214.9090909090909, 'equality': 0.93016459006441, 'sustainability': 497.48764944467183, 'peace': 825.1818181818181}\n",
      "2021-08-25 13:53:47.934 | INFO     | src.policies:train:103 - Epoch 97 / 4000\n",
      "2021-08-25 13:53:47.935 | INFO     | src.policies:train:110 - Episode 97\n",
      "2021-08-25 13:54:09.658 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:54:09.681 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 186.54545454545453, 'equality': 0.8684210526344935, 'sustainability': 519.3082218283238, 'peace': 670.0}\n",
      "2021-08-25 13:54:09.681 | INFO     | src.policies:train:122 - Mean episode return: 186.54545454545453\n",
      "2021-08-25 13:54:09.682 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.43580131208998\n",
      "2021-08-25 13:54:09.682 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:54:18.441 | INFO     | src.policies:train:159 - Total loss: 0.9994451999664307\n",
      "2021-08-25 13:54:18.441 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 186.54545454545453, 'equality': 0.8684210526344935, 'sustainability': 519.3082218283238, 'peace': 670.0}\n",
      "2021-08-25 13:54:18.488 | INFO     | src.policies:train:103 - Epoch 98 / 4000\n",
      "2021-08-25 13:54:18.489 | INFO     | src.policies:train:110 - Episode 98\n",
      "2021-08-25 13:54:40.331 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:54:40.354 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 205.72727272727272, 'equality': 0.897240188006724, 'sustainability': 472.2818159434983, 'peace': 659.1818181818181}\n",
      "2021-08-25 13:54:40.355 | INFO     | src.policies:train:122 - Mean episode return: 205.72727272727272\n",
      "2021-08-25 13:54:40.355 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.41836734693877\n",
      "2021-08-25 13:54:40.356 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:54:49.414 | INFO     | src.policies:train:159 - Total loss: 1.002662181854248\n",
      "2021-08-25 13:54:49.415 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 205.72727272727272, 'equality': 0.897240188006724, 'sustainability': 472.2818159434983, 'peace': 659.1818181818181}\n",
      "2021-08-25 13:54:49.462 | INFO     | src.policies:train:103 - Epoch 99 / 4000\n",
      "2021-08-25 13:54:49.463 | INFO     | src.policies:train:110 - Episode 99\n",
      "2021-08-25 13:55:12.429 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:55:12.455 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 195.27272727272728, 'equality': 0.9434569155251512, 'sustainability': 494.84844407220595, 'peace': 671.9090909090909}\n",
      "2021-08-25 13:55:12.456 | INFO     | src.policies:train:122 - Mean episode return: 195.27272727272728\n",
      "2021-08-25 13:55:12.456 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.29568411386595\n",
      "2021-08-25 13:55:12.457 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:55:21.699 | INFO     | src.policies:train:159 - Total loss: 0.9979420304298401\n",
      "2021-08-25 13:55:21.700 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 195.27272727272728, 'equality': 0.9434569155251512, 'sustainability': 494.84844407220595, 'peace': 671.9090909090909}\n",
      "2021-08-25 13:55:21.752 | INFO     | src.policies:train:103 - Epoch 100 / 4000\n",
      "2021-08-25 13:55:21.753 | INFO     | src.policies:train:110 - Episode 100\n",
      "2021-08-25 13:55:44.650 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:55:44.679 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 184.63636363636363, 'equality': 0.9287408799980139, 'sustainability': 443.5497396882569, 'peace': 595.9090909090909}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 13:55:44.680 | INFO     | src.policies:train:122 - Mean episode return: 184.63636363636363\n",
      "2021-08-25 13:55:44.681 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.06909090909093\n",
      "2021-08-25 13:55:44.681 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:55:54.212 | INFO     | src.policies:train:159 - Total loss: 1.0026956796646118\n",
      "2021-08-25 13:55:54.213 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 184.63636363636363, 'equality': 0.9287408799980139, 'sustainability': 443.5497396882569, 'peace': 595.9090909090909}\n",
      "2021-08-25 13:55:54.264 | INFO     | src.policies:train:103 - Epoch 101 / 4000\n",
      "2021-08-25 13:55:54.265 | INFO     | src.policies:train:110 - Episode 101\n",
      "2021-08-25 13:56:19.664 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:56:19.690 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 213.54545454545453, 'equality': 0.9232942451348098, 'sustainability': 503.95696799951696, 'peace': 785.1818181818181}\n",
      "2021-08-25 13:56:19.691 | INFO     | src.policies:train:122 - Mean episode return: 213.54545454545453\n",
      "2021-08-25 13:56:19.691 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.10363636363635\n",
      "2021-08-25 13:56:19.692 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:56:29.794 | INFO     | src.policies:train:159 - Total loss: 1.0028811693191528\n",
      "2021-08-25 13:56:29.795 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 213.54545454545453, 'equality': 0.9232942451348098, 'sustainability': 503.95696799951696, 'peace': 785.1818181818181}\n",
      "2021-08-25 13:56:29.850 | INFO     | src.policies:train:103 - Epoch 102 / 4000\n",
      "2021-08-25 13:56:29.851 | INFO     | src.policies:train:110 - Episode 102\n",
      "2021-08-25 13:56:53.018 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:56:53.045 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 220.1818181818182, 'equality': 0.9352150739446135, 'sustainability': 486.12881072593154, 'peace': 777.5454545454545}\n",
      "2021-08-25 13:56:53.046 | INFO     | src.policies:train:122 - Mean episode return: 220.1818181818182\n",
      "2021-08-25 13:56:53.047 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.39545454545456\n",
      "2021-08-25 13:56:53.047 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:57:02.419 | INFO     | src.policies:train:159 - Total loss: 1.0022740364074707\n",
      "2021-08-25 13:57:02.420 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 220.1818181818182, 'equality': 0.9352150739446135, 'sustainability': 486.12881072593154, 'peace': 777.5454545454545}\n",
      "2021-08-25 13:57:02.475 | INFO     | src.policies:train:103 - Epoch 103 / 4000\n",
      "2021-08-25 13:57:02.475 | INFO     | src.policies:train:110 - Episode 103\n",
      "2021-08-25 13:57:26.393 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:57:26.420 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 193.0, 'equality': 0.9032244251294647, 'sustainability': 483.9537902904285, 'peace': 687.2727272727273}\n",
      "2021-08-25 13:57:26.421 | INFO     | src.policies:train:122 - Mean episode return: 193.0\n",
      "2021-08-25 13:57:26.421 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.17545454545456\n",
      "2021-08-25 13:57:26.422 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:57:36.360 | INFO     | src.policies:train:159 - Total loss: 0.9955764412879944\n",
      "2021-08-25 13:57:36.361 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 193.0, 'equality': 0.9032244251294647, 'sustainability': 483.9537902904285, 'peace': 687.2727272727273}\n",
      "2021-08-25 13:57:36.414 | INFO     | src.policies:train:103 - Epoch 104 / 4000\n",
      "2021-08-25 13:57:36.415 | INFO     | src.policies:train:110 - Episode 104\n",
      "2021-08-25 13:58:02.060 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:58:02.087 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 203.8181818181818, 'equality': 0.9398264536546138, 'sustainability': 470.2061726924752, 'peace': 689.0909090909091}\n",
      "2021-08-25 13:58:02.088 | INFO     | src.policies:train:122 - Mean episode return: 203.8181818181818\n",
      "2021-08-25 13:58:02.088 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.99090909090913\n",
      "2021-08-25 13:58:02.089 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:58:12.309 | INFO     | src.policies:train:159 - Total loss: 1.0042299032211304\n",
      "2021-08-25 13:58:12.310 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 203.8181818181818, 'equality': 0.9398264536546138, 'sustainability': 470.2061726924752, 'peace': 689.0909090909091}\n",
      "2021-08-25 13:58:12.364 | INFO     | src.policies:train:103 - Epoch 105 / 4000\n",
      "2021-08-25 13:58:12.364 | INFO     | src.policies:train:110 - Episode 105\n",
      "2021-08-25 13:58:38.209 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:58:38.238 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 189.9090909090909, 'equality': 0.9130510466096642, 'sustainability': 486.97498718210403, 'peace': 709.7272727272727}\n",
      "2021-08-25 13:58:38.238 | INFO     | src.policies:train:122 - Mean episode return: 189.9090909090909\n",
      "2021-08-25 13:58:38.239 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.8109090909091\n",
      "2021-08-25 13:58:38.240 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:58:48.524 | INFO     | src.policies:train:159 - Total loss: 0.9985531568527222\n",
      "2021-08-25 13:58:48.525 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 189.9090909090909, 'equality': 0.9130510466096642, 'sustainability': 486.97498718210403, 'peace': 709.7272727272727}\n",
      "2021-08-25 13:58:48.581 | INFO     | src.policies:train:103 - Epoch 106 / 4000\n",
      "2021-08-25 13:58:48.581 | INFO     | src.policies:train:110 - Episode 106\n",
      "2021-08-25 13:59:12.832 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:59:12.858 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 203.45454545454547, 'equality': 0.9325696644745193, 'sustainability': 474.98010334986157, 'peace': 693.8181818181819}\n",
      "2021-08-25 13:59:12.858 | INFO     | src.policies:train:122 - Mean episode return: 203.45454545454547\n",
      "2021-08-25 13:59:12.859 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.67454545454544\n",
      "2021-08-25 13:59:12.859 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:59:22.252 | INFO     | src.policies:train:159 - Total loss: 0.9973518252372742\n",
      "2021-08-25 13:59:22.253 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 203.45454545454547, 'equality': 0.9325696644745193, 'sustainability': 474.98010334986157, 'peace': 693.8181818181819}\n",
      "2021-08-25 13:59:22.307 | INFO     | src.policies:train:103 - Epoch 107 / 4000\n",
      "2021-08-25 13:59:22.308 | INFO     | src.policies:train:110 - Episode 107\n",
      "2021-08-25 13:59:45.513 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 13:59:45.539 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 210.0, 'equality': 0.9323101141296279, 'sustainability': 493.38126209461313, 'peace': 680.6363636363636}\n",
      "2021-08-25 13:59:45.539 | INFO     | src.policies:train:122 - Mean episode return: 210.0\n",
      "2021-08-25 13:59:45.540 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.82363636363633\n",
      "2021-08-25 13:59:45.540 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 13:59:54.917 | INFO     | src.policies:train:159 - Total loss: 1.0017929077148438\n",
      "2021-08-25 13:59:54.918 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 210.0, 'equality': 0.9323101141296279, 'sustainability': 493.38126209461313, 'peace': 680.6363636363636}\n",
      "2021-08-25 13:59:54.972 | INFO     | src.policies:train:103 - Epoch 108 / 4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 13:59:54.972 | INFO     | src.policies:train:110 - Episode 108\n",
      "2021-08-25 14:00:18.262 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:00:18.286 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 199.54545454545453, 'equality': 0.9006833713004622, 'sustainability': 465.8076161078238, 'peace': 721.6363636363636}\n",
      "2021-08-25 14:00:18.286 | INFO     | src.policies:train:122 - Mean episode return: 199.54545454545453\n",
      "2021-08-25 14:00:18.287 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.89818181818183\n",
      "2021-08-25 14:00:18.287 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:00:27.957 | INFO     | src.policies:train:159 - Total loss: 0.9994522929191589\n",
      "2021-08-25 14:00:27.957 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 199.54545454545453, 'equality': 0.9006833713004622, 'sustainability': 465.8076161078238, 'peace': 721.6363636363636}\n",
      "2021-08-25 14:00:28.012 | INFO     | src.policies:train:103 - Epoch 109 / 4000\n",
      "2021-08-25 14:00:28.013 | INFO     | src.policies:train:110 - Episode 109\n",
      "2021-08-25 14:00:52.840 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:00:52.866 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 210.0, 'equality': 0.9409681227874662, 'sustainability': 513.3422047521916, 'peace': 661.3636363636364}\n",
      "2021-08-25 14:00:52.867 | INFO     | src.policies:train:122 - Mean episode return: 210.0\n",
      "2021-08-25 14:00:52.867 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.84818181818184\n",
      "2021-08-25 14:00:52.868 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:01:02.563 | INFO     | src.policies:train:159 - Total loss: 0.9951536655426025\n",
      "2021-08-25 14:01:02.564 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 210.0, 'equality': 0.9409681227874662, 'sustainability': 513.3422047521916, 'peace': 661.3636363636364}\n",
      "2021-08-25 14:01:02.618 | INFO     | src.policies:train:103 - Epoch 110 / 4000\n",
      "2021-08-25 14:01:02.619 | INFO     | src.policies:train:110 - Episode 110\n",
      "2021-08-25 14:01:26.866 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:01:26.890 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 213.9090909090909, 'equality': 0.9456786307625531, 'sustainability': 490.72511481054676, 'peace': 748.8181818181819}\n",
      "2021-08-25 14:01:26.891 | INFO     | src.policies:train:122 - Mean episode return: 213.9090909090909\n",
      "2021-08-25 14:01:26.891 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.95545454545456\n",
      "2021-08-25 14:01:26.892 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:01:36.284 | INFO     | src.policies:train:159 - Total loss: 0.9943355917930603\n",
      "2021-08-25 14:01:36.285 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 213.9090909090909, 'equality': 0.9456786307625531, 'sustainability': 490.72511481054676, 'peace': 748.8181818181819}\n",
      "2021-08-25 14:01:36.338 | INFO     | src.policies:train:103 - Epoch 111 / 4000\n",
      "2021-08-25 14:01:36.338 | INFO     | src.policies:train:110 - Episode 111\n",
      "2021-08-25 14:01:59.700 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:01:59.725 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 198.9090909090909, 'equality': 0.9423300648175518, 'sustainability': 496.65131094450356, 'peace': 685.2727272727273}\n",
      "2021-08-25 14:01:59.726 | INFO     | src.policies:train:122 - Mean episode return: 198.9090909090909\n",
      "2021-08-25 14:01:59.726 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.82909090909095\n",
      "2021-08-25 14:01:59.727 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:02:09.578 | INFO     | src.policies:train:159 - Total loss: 0.9995763301849365\n",
      "2021-08-25 14:02:09.578 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 198.9090909090909, 'equality': 0.9423300648175518, 'sustainability': 496.65131094450356, 'peace': 685.2727272727273}\n",
      "2021-08-25 14:02:09.634 | INFO     | src.policies:train:103 - Epoch 112 / 4000\n",
      "2021-08-25 14:02:09.635 | INFO     | src.policies:train:110 - Episode 112\n",
      "2021-08-25 14:02:35.990 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:02:36.019 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 217.1818181818182, 'equality': 0.9125537501443632, 'sustainability': 508.26749196126184, 'peace': 730.4545454545455}\n",
      "2021-08-25 14:02:36.020 | INFO     | src.policies:train:122 - Mean episode return: 217.1818181818182\n",
      "2021-08-25 14:02:36.020 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.93363636363642\n",
      "2021-08-25 14:02:36.021 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:02:46.735 | INFO     | src.policies:train:159 - Total loss: 1.0023915767669678\n",
      "2021-08-25 14:02:46.736 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 217.1818181818182, 'equality': 0.9125537501443632, 'sustainability': 508.26749196126184, 'peace': 730.4545454545455}\n",
      "2021-08-25 14:02:46.795 | INFO     | src.policies:train:103 - Epoch 113 / 4000\n",
      "2021-08-25 14:02:46.796 | INFO     | src.policies:train:110 - Episode 113\n",
      "2021-08-25 14:03:13.291 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:03:13.321 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 185.36363636363637, 'equality': 0.9065495563799868, 'sustainability': 498.08799020998043, 'peace': 627.2727272727273}\n",
      "2021-08-25 14:03:13.322 | INFO     | src.policies:train:122 - Mean episode return: 185.36363636363637\n",
      "2021-08-25 14:03:13.323 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.57181818181823\n",
      "2021-08-25 14:03:13.323 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:03:24.348 | INFO     | src.policies:train:159 - Total loss: 0.9944605827331543\n",
      "2021-08-25 14:03:24.349 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 185.36363636363637, 'equality': 0.9065495563799868, 'sustainability': 498.08799020998043, 'peace': 627.2727272727273}\n",
      "2021-08-25 14:03:24.409 | INFO     | src.policies:train:103 - Epoch 114 / 4000\n",
      "2021-08-25 14:03:24.410 | INFO     | src.policies:train:110 - Episode 114\n",
      "2021-08-25 14:03:51.146 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:03:51.180 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 218.8181818181818, 'equality': 0.9441024285239245, 'sustainability': 481.9726190845531, 'peace': 823.2727272727273}\n",
      "2021-08-25 14:03:51.181 | INFO     | src.policies:train:122 - Mean episode return: 218.8181818181818\n",
      "2021-08-25 14:03:51.181 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.48181818181817\n",
      "2021-08-25 14:03:51.182 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:04:01.719 | INFO     | src.policies:train:159 - Total loss: 1.0022835731506348\n",
      "2021-08-25 14:04:01.719 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 218.8181818181818, 'equality': 0.9441024285239245, 'sustainability': 481.9726190845531, 'peace': 823.2727272727273}\n",
      "2021-08-25 14:04:01.781 | INFO     | src.policies:train:103 - Epoch 115 / 4000\n",
      "2021-08-25 14:04:01.781 | INFO     | src.policies:train:110 - Episode 115\n",
      "2021-08-25 14:04:29.469 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:04:29.498 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 208.9090909090909, 'equality': 0.9355170504008324, 'sustainability': 509.1051252571682, 'peace': 742.2727272727273}\n",
      "2021-08-25 14:04:29.499 | INFO     | src.policies:train:122 - Mean episode return: 208.9090909090909\n",
      "2021-08-25 14:04:29.500 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.46272727272728\n",
      "2021-08-25 14:04:29.500 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 14:04:40.656 | INFO     | src.policies:train:159 - Total loss: 0.9985252618789673\n",
      "2021-08-25 14:04:40.657 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 208.9090909090909, 'equality': 0.9355170504008324, 'sustainability': 509.1051252571682, 'peace': 742.2727272727273}\n",
      "2021-08-25 14:04:40.711 | INFO     | src.policies:train:103 - Epoch 116 / 4000\n",
      "2021-08-25 14:04:40.712 | INFO     | src.policies:train:110 - Episode 116\n",
      "2021-08-25 14:05:07.004 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:05:07.032 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 199.27272727272728, 'equality': 0.9255142667566872, 'sustainability': 490.7914187613911, 'peace': 764.9090909090909}\n",
      "2021-08-25 14:05:07.032 | INFO     | src.policies:train:122 - Mean episode return: 199.27272727272728\n",
      "2021-08-25 14:05:07.033 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.5127272727273\n",
      "2021-08-25 14:05:07.033 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:05:17.332 | INFO     | src.policies:train:159 - Total loss: 1.0054728984832764\n",
      "2021-08-25 14:05:17.333 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 199.27272727272728, 'equality': 0.9255142667566872, 'sustainability': 490.7914187613911, 'peace': 764.9090909090909}\n",
      "2021-08-25 14:05:17.391 | INFO     | src.policies:train:103 - Epoch 117 / 4000\n",
      "2021-08-25 14:05:17.392 | INFO     | src.policies:train:110 - Episode 117\n",
      "2021-08-25 14:05:42.868 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:05:42.896 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 209.45454545454547, 'equality': 0.916429924244073, 'sustainability': 482.7063449515692, 'peace': 760.5454545454545}\n",
      "2021-08-25 14:05:42.897 | INFO     | src.policies:train:122 - Mean episode return: 209.45454545454547\n",
      "2021-08-25 14:05:42.898 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.52818181818185\n",
      "2021-08-25 14:05:42.898 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:05:53.671 | INFO     | src.policies:train:159 - Total loss: 0.9999741911888123\n",
      "2021-08-25 14:05:53.672 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 209.45454545454547, 'equality': 0.916429924244073, 'sustainability': 482.7063449515692, 'peace': 760.5454545454545}\n",
      "2021-08-25 14:05:53.732 | INFO     | src.policies:train:103 - Epoch 118 / 4000\n",
      "2021-08-25 14:05:53.733 | INFO     | src.policies:train:110 - Episode 118\n",
      "2021-08-25 14:06:19.706 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:06:19.733 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 184.36363636363637, 'equality': 0.8503675811401656, 'sustainability': 470.3175229077265, 'peace': 632.1818181818181}\n",
      "2021-08-25 14:06:19.734 | INFO     | src.policies:train:122 - Mean episode return: 184.36363636363637\n",
      "2021-08-25 14:06:19.734 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.1290909090909\n",
      "2021-08-25 14:06:19.735 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:06:29.847 | INFO     | src.policies:train:159 - Total loss: 1.0040570497512817\n",
      "2021-08-25 14:06:29.848 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 184.36363636363637, 'equality': 0.8503675811401656, 'sustainability': 470.3175229077265, 'peace': 632.1818181818181}\n",
      "2021-08-25 14:06:29.904 | INFO     | src.policies:train:103 - Epoch 119 / 4000\n",
      "2021-08-25 14:06:29.905 | INFO     | src.policies:train:110 - Episode 119\n",
      "2021-08-25 14:06:53.938 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:06:53.962 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 214.36363636363637, 'equality': 0.9467962063392167, 'sustainability': 486.2770642475561, 'peace': 718.7272727272727}\n",
      "2021-08-25 14:06:53.962 | INFO     | src.policies:train:122 - Mean episode return: 214.36363636363637\n",
      "2021-08-25 14:06:53.963 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.12454545454545\n",
      "2021-08-25 14:06:53.964 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:07:03.461 | INFO     | src.policies:train:159 - Total loss: 0.999955952167511\n",
      "2021-08-25 14:07:03.462 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 214.36363636363637, 'equality': 0.9467962063392167, 'sustainability': 486.2770642475561, 'peace': 718.7272727272727}\n",
      "2021-08-25 14:07:03.519 | INFO     | src.policies:train:103 - Epoch 120 / 4000\n",
      "2021-08-25 14:07:03.519 | INFO     | src.policies:train:110 - Episode 120\n",
      "2021-08-25 14:07:26.541 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:07:26.567 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 193.36363636363637, 'equality': 0.9264863016641773, 'sustainability': 474.150853067977, 'peace': 722.6363636363636}\n",
      "2021-08-25 14:07:26.568 | INFO     | src.policies:train:122 - Mean episode return: 193.36363636363637\n",
      "2021-08-25 14:07:26.568 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.8890909090909\n",
      "2021-08-25 14:07:26.569 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:07:36.534 | INFO     | src.policies:train:159 - Total loss: 0.9961875677108765\n",
      "2021-08-25 14:07:36.535 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 193.36363636363637, 'equality': 0.9264863016641773, 'sustainability': 474.150853067977, 'peace': 722.6363636363636}\n",
      "2021-08-25 14:07:36.599 | INFO     | src.policies:train:103 - Epoch 121 / 4000\n",
      "2021-08-25 14:07:36.600 | INFO     | src.policies:train:110 - Episode 121\n",
      "2021-08-25 14:08:07.207 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:08:07.237 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 214.1818181818182, 'equality': 0.9288470442983322, 'sustainability': 466.92349588883013, 'peace': 719.2727272727273}\n",
      "2021-08-25 14:08:07.238 | INFO     | src.policies:train:122 - Mean episode return: 214.1818181818182\n",
      "2021-08-25 14:08:07.239 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.01545454545456\n",
      "2021-08-25 14:08:07.240 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:08:19.322 | INFO     | src.policies:train:159 - Total loss: 1.0015188455581665\n",
      "2021-08-25 14:08:19.323 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 214.1818181818182, 'equality': 0.9288470442983322, 'sustainability': 466.92349588883013, 'peace': 719.2727272727273}\n",
      "2021-08-25 14:08:19.384 | INFO     | src.policies:train:103 - Epoch 122 / 4000\n",
      "2021-08-25 14:08:19.385 | INFO     | src.policies:train:110 - Episode 122\n",
      "2021-08-25 14:08:46.400 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:08:46.427 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 197.63636363636363, 'equality': 0.9355189428799967, 'sustainability': 502.76469588704737, 'peace': 690.3636363636364}\n",
      "2021-08-25 14:08:46.427 | INFO     | src.policies:train:122 - Mean episode return: 197.63636363636363\n",
      "2021-08-25 14:08:46.428 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.85454545454544\n",
      "2021-08-25 14:08:46.428 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:08:56.415 | INFO     | src.policies:train:159 - Total loss: 0.9964160323143005\n",
      "2021-08-25 14:08:56.416 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 197.63636363636363, 'equality': 0.9355189428799967, 'sustainability': 502.76469588704737, 'peace': 690.3636363636364}\n",
      "2021-08-25 14:08:56.466 | INFO     | src.policies:train:103 - Epoch 123 / 4000\n",
      "2021-08-25 14:08:56.467 | INFO     | src.policies:train:110 - Episode 123\n",
      "2021-08-25 14:09:20.975 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:09:21.001 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 207.9090909090909, 'equality': 0.9100846682849687, 'sustainability': 477.1056953834955, 'peace': 675.6363636363636}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 14:09:21.001 | INFO     | src.policies:train:122 - Mean episode return: 207.9090909090909\n",
      "2021-08-25 14:09:21.002 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.7563636363637\n",
      "2021-08-25 14:09:21.002 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:09:30.323 | INFO     | src.policies:train:159 - Total loss: 0.9974158406257629\n",
      "2021-08-25 14:09:30.324 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 207.9090909090909, 'equality': 0.9100846682849687, 'sustainability': 477.1056953834955, 'peace': 675.6363636363636}\n",
      "2021-08-25 14:09:30.374 | INFO     | src.policies:train:103 - Epoch 124 / 4000\n",
      "2021-08-25 14:09:30.374 | INFO     | src.policies:train:110 - Episode 124\n",
      "2021-08-25 14:09:53.591 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:09:53.616 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 211.27272727272728, 'equality': 0.9343608199042724, 'sustainability': 487.49962352414934, 'peace': 774.2727272727273}\n",
      "2021-08-25 14:09:53.616 | INFO     | src.policies:train:122 - Mean episode return: 211.27272727272728\n",
      "2021-08-25 14:09:53.617 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.89545454545458\n",
      "2021-08-25 14:09:53.618 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:10:03.174 | INFO     | src.policies:train:159 - Total loss: 0.9999392032623291\n",
      "2021-08-25 14:10:03.174 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 211.27272727272728, 'equality': 0.9343608199042724, 'sustainability': 487.49962352414934, 'peace': 774.2727272727273}\n",
      "2021-08-25 14:10:03.228 | INFO     | src.policies:train:103 - Epoch 125 / 4000\n",
      "2021-08-25 14:10:03.229 | INFO     | src.policies:train:110 - Episode 125\n",
      "2021-08-25 14:10:29.463 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:10:29.494 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 212.36363636363637, 'equality': 0.943103985057147, 'sustainability': 485.9958167556928, 'peace': 751.4545454545455}\n",
      "2021-08-25 14:10:29.495 | INFO     | src.policies:train:122 - Mean episode return: 212.36363636363637\n",
      "2021-08-25 14:10:29.495 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.79636363636365\n",
      "2021-08-25 14:10:29.496 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:10:39.708 | INFO     | src.policies:train:159 - Total loss: 1.0002102851867676\n",
      "2021-08-25 14:10:39.709 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 212.36363636363637, 'equality': 0.943103985057147, 'sustainability': 485.9958167556928, 'peace': 751.4545454545455}\n",
      "2021-08-25 14:10:39.764 | INFO     | src.policies:train:103 - Epoch 126 / 4000\n",
      "2021-08-25 14:10:39.765 | INFO     | src.policies:train:110 - Episode 126\n",
      "2021-08-25 14:11:06.471 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:11:06.497 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 215.9090909090909, 'equality': 0.9570526315797694, 'sustainability': 492.1268024953983, 'peace': 826.2727272727273}\n",
      "2021-08-25 14:11:06.498 | INFO     | src.policies:train:122 - Mean episode return: 215.9090909090909\n",
      "2021-08-25 14:11:06.499 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.76363636363635\n",
      "2021-08-25 14:11:06.499 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:11:16.758 | INFO     | src.policies:train:159 - Total loss: 0.9989409446716309\n",
      "2021-08-25 14:11:16.759 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 215.9090909090909, 'equality': 0.9570526315797694, 'sustainability': 492.1268024953983, 'peace': 826.2727272727273}\n",
      "2021-08-25 14:11:16.814 | INFO     | src.policies:train:103 - Epoch 127 / 4000\n",
      "2021-08-25 14:11:16.815 | INFO     | src.policies:train:110 - Episode 127\n",
      "2021-08-25 14:11:44.075 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:11:44.103 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 196.0, 'equality': 0.9521841794579148, 'sustainability': 503.12649392067794, 'peace': 701.4545454545455}\n",
      "2021-08-25 14:11:44.104 | INFO     | src.policies:train:122 - Mean episode return: 196.0\n",
      "2021-08-25 14:11:44.104 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.72636363636363\n",
      "2021-08-25 14:11:44.105 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:11:55.003 | INFO     | src.policies:train:159 - Total loss: 0.9960848689079285\n",
      "2021-08-25 14:11:55.004 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 196.0, 'equality': 0.9521841794579148, 'sustainability': 503.12649392067794, 'peace': 701.4545454545455}\n",
      "2021-08-25 14:11:55.062 | INFO     | src.policies:train:103 - Epoch 128 / 4000\n",
      "2021-08-25 14:11:55.063 | INFO     | src.policies:train:110 - Episode 128\n",
      "2021-08-25 14:12:23.071 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:12:23.099 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 220.54545454545453, 'equality': 0.9232556396626835, 'sustainability': 479.63882759538905, 'peace': 765.0909090909091}\n",
      "2021-08-25 14:12:23.100 | INFO     | src.policies:train:122 - Mean episode return: 220.54545454545453\n",
      "2021-08-25 14:12:23.101 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.81272727272727\n",
      "2021-08-25 14:12:23.101 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:12:33.353 | INFO     | src.policies:train:159 - Total loss: 0.9986109137535095\n",
      "2021-08-25 14:12:33.354 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 220.54545454545453, 'equality': 0.9232556396626835, 'sustainability': 479.63882759538905, 'peace': 765.0909090909091}\n",
      "2021-08-25 14:12:33.407 | INFO     | src.policies:train:103 - Epoch 129 / 4000\n",
      "2021-08-25 14:12:33.408 | INFO     | src.policies:train:110 - Episode 129\n",
      "2021-08-25 14:12:57.326 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:12:57.349 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 219.8181818181818, 'equality': 0.9551094067231538, 'sustainability': 478.45935267727987, 'peace': 729.9090909090909}\n",
      "2021-08-25 14:12:57.349 | INFO     | src.policies:train:122 - Mean episode return: 219.8181818181818\n",
      "2021-08-25 14:12:57.350 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.9227272727273\n",
      "2021-08-25 14:12:57.350 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:13:06.631 | INFO     | src.policies:train:159 - Total loss: 1.0031211376190186\n",
      "2021-08-25 14:13:06.632 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 219.8181818181818, 'equality': 0.9551094067231538, 'sustainability': 478.45935267727987, 'peace': 729.9090909090909}\n",
      "2021-08-25 14:13:06.682 | INFO     | src.policies:train:103 - Epoch 130 / 4000\n",
      "2021-08-25 14:13:06.683 | INFO     | src.policies:train:110 - Episode 130\n",
      "2021-08-25 14:13:29.126 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:13:29.153 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 192.36363636363637, 'equality': 0.8768688778167024, 'sustainability': 484.5817210729016, 'peace': 682.9090909090909}\n",
      "2021-08-25 14:13:29.154 | INFO     | src.policies:train:122 - Mean episode return: 192.36363636363637\n",
      "2021-08-25 14:13:29.155 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.83272727272728\n",
      "2021-08-25 14:13:29.155 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:13:38.498 | INFO     | src.policies:train:159 - Total loss: 0.9978609085083008\n",
      "2021-08-25 14:13:38.498 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 192.36363636363637, 'equality': 0.8768688778167024, 'sustainability': 484.5817210729016, 'peace': 682.9090909090909}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 14:13:38.547 | INFO     | src.policies:train:103 - Epoch 131 / 4000\n",
      "2021-08-25 14:13:38.548 | INFO     | src.policies:train:110 - Episode 131\n",
      "2021-08-25 14:14:02.012 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:14:02.038 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 221.36363636363637, 'equality': 0.9255553481440069, 'sustainability': 471.8954606985578, 'peace': 731.4545454545455}\n",
      "2021-08-25 14:14:02.038 | INFO     | src.policies:train:122 - Mean episode return: 221.36363636363637\n",
      "2021-08-25 14:14:02.039 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.03363636363636\n",
      "2021-08-25 14:14:02.039 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:14:12.011 | INFO     | src.policies:train:159 - Total loss: 1.002609133720398\n",
      "2021-08-25 14:14:12.012 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 221.36363636363637, 'equality': 0.9255553481440069, 'sustainability': 471.8954606985578, 'peace': 731.4545454545455}\n",
      "2021-08-25 14:14:12.068 | INFO     | src.policies:train:103 - Epoch 132 / 4000\n",
      "2021-08-25 14:14:12.068 | INFO     | src.policies:train:110 - Episode 132\n",
      "2021-08-25 14:14:39.228 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:14:39.259 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 193.72727272727272, 'equality': 0.9520498272268237, 'sustainability': 478.42844539214514, 'peace': 679.7272727272727}\n",
      "2021-08-25 14:14:39.260 | INFO     | src.policies:train:122 - Mean episode return: 193.72727272727272\n",
      "2021-08-25 14:14:39.260 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.8409090909091\n",
      "2021-08-25 14:14:39.261 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:14:50.282 | INFO     | src.policies:train:159 - Total loss: 1.0044028759002686\n",
      "2021-08-25 14:14:50.284 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 193.72727272727272, 'equality': 0.9520498272268237, 'sustainability': 478.42844539214514, 'peace': 679.7272727272727}\n",
      "2021-08-25 14:14:50.341 | INFO     | src.policies:train:103 - Epoch 133 / 4000\n",
      "2021-08-25 14:14:50.341 | INFO     | src.policies:train:110 - Episode 133\n",
      "2021-08-25 14:15:17.631 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:15:17.662 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 222.9090909090909, 'equality': 0.9638884769397174, 'sustainability': 487.04065818500163, 'peace': 753.5454545454545}\n",
      "2021-08-25 14:15:17.662 | INFO     | src.policies:train:122 - Mean episode return: 222.9090909090909\n",
      "2021-08-25 14:15:17.663 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.09545454545457\n",
      "2021-08-25 14:15:17.664 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:15:28.055 | INFO     | src.policies:train:159 - Total loss: 1.001605749130249\n",
      "2021-08-25 14:15:28.056 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 222.9090909090909, 'equality': 0.9638884769397174, 'sustainability': 487.04065818500163, 'peace': 753.5454545454545}\n",
      "2021-08-25 14:15:28.112 | INFO     | src.policies:train:103 - Epoch 134 / 4000\n",
      "2021-08-25 14:15:28.112 | INFO     | src.policies:train:110 - Episode 134\n",
      "2021-08-25 14:15:52.933 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:15:52.960 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 167.9090909090909, 'equality': 0.8797066496067405, 'sustainability': 470.0853059561838, 'peace': 557.3636363636364}\n",
      "2021-08-25 14:15:52.961 | INFO     | src.policies:train:122 - Mean episode return: 167.9090909090909\n",
      "2021-08-25 14:15:52.961 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.66727272727275\n",
      "2021-08-25 14:15:52.962 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:16:02.936 | INFO     | src.policies:train:159 - Total loss: 0.999060869216919\n",
      "2021-08-25 14:16:02.937 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 167.9090909090909, 'equality': 0.8797066496067405, 'sustainability': 470.0853059561838, 'peace': 557.3636363636364}\n",
      "2021-08-25 14:16:02.991 | INFO     | src.policies:train:103 - Epoch 135 / 4000\n",
      "2021-08-25 14:16:02.992 | INFO     | src.policies:train:110 - Episode 135\n",
      "2021-08-25 14:16:27.556 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:16:27.582 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 194.72727272727272, 'equality': 0.9197860962583867, 'sustainability': 485.2010928536693, 'peace': 654.5454545454545}\n",
      "2021-08-25 14:16:27.583 | INFO     | src.policies:train:122 - Mean episode return: 194.72727272727272\n",
      "2021-08-25 14:16:27.583 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.61636363636367\n",
      "2021-08-25 14:16:27.584 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:16:37.771 | INFO     | src.policies:train:159 - Total loss: 1.004799723625183\n",
      "2021-08-25 14:16:37.772 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 194.72727272727272, 'equality': 0.9197860962583867, 'sustainability': 485.2010928536693, 'peace': 654.5454545454545}\n",
      "2021-08-25 14:16:37.826 | INFO     | src.policies:train:103 - Epoch 136 / 4000\n",
      "2021-08-25 14:16:37.827 | INFO     | src.policies:train:110 - Episode 136\n",
      "2021-08-25 14:17:03.672 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:17:03.698 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 205.72727272727272, 'equality': 0.9325111477135638, 'sustainability': 462.9950567496064, 'peace': 693.7272727272727}\n",
      "2021-08-25 14:17:03.699 | INFO     | src.policies:train:122 - Mean episode return: 205.72727272727272\n",
      "2021-08-25 14:17:03.700 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.43\n",
      "2021-08-25 14:17:03.701 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:17:14.291 | INFO     | src.policies:train:159 - Total loss: 1.0019729137420654\n",
      "2021-08-25 14:17:14.292 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 205.72727272727272, 'equality': 0.9325111477135638, 'sustainability': 462.9950567496064, 'peace': 693.7272727272727}\n",
      "2021-08-25 14:17:14.347 | INFO     | src.policies:train:103 - Epoch 137 / 4000\n",
      "2021-08-25 14:17:14.348 | INFO     | src.policies:train:110 - Episode 137\n",
      "2021-08-25 14:17:41.173 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:17:41.204 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 191.54545454545453, 'equality': 0.9044742632803108, 'sustainability': 482.39821417658766, 'peace': 697.0}\n",
      "2021-08-25 14:17:41.204 | INFO     | src.policies:train:122 - Mean episode return: 191.54545454545453\n",
      "2021-08-25 14:17:41.205 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.1954545454546\n",
      "2021-08-25 14:17:41.206 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:17:51.824 | INFO     | src.policies:train:159 - Total loss: 0.9974876046180725\n",
      "2021-08-25 14:17:51.825 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 191.54545454545453, 'equality': 0.9044742632803108, 'sustainability': 482.39821417658766, 'peace': 697.0}\n",
      "2021-08-25 14:17:51.886 | INFO     | src.policies:train:103 - Epoch 138 / 4000\n",
      "2021-08-25 14:17:51.886 | INFO     | src.policies:train:110 - Episode 138\n",
      "2021-08-25 14:18:19.667 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:18:19.697 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 217.0909090909091, 'equality': 0.9615501751187462, 'sustainability': 493.8885265814053, 'peace': 794.4545454545455}\n",
      "2021-08-25 14:18:19.698 | INFO     | src.policies:train:122 - Mean episode return: 217.0909090909091\n",
      "2021-08-25 14:18:19.698 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 14:18:19.699 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:18:30.135 | INFO     | src.policies:train:159 - Total loss: 1.0050582885742188\n",
      "2021-08-25 14:18:30.136 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 217.0909090909091, 'equality': 0.9615501751187462, 'sustainability': 493.8885265814053, 'peace': 794.4545454545455}\n",
      "2021-08-25 14:18:30.190 | INFO     | src.policies:train:103 - Epoch 139 / 4000\n",
      "2021-08-25 14:18:30.191 | INFO     | src.policies:train:110 - Episode 139\n",
      "2021-08-25 14:18:55.485 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:18:55.512 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 207.36363636363637, 'equality': 0.9320074927278306, 'sustainability': 471.05786822758404, 'peace': 729.4545454545455}\n",
      "2021-08-25 14:18:55.513 | INFO     | src.policies:train:122 - Mean episode return: 207.36363636363637\n",
      "2021-08-25 14:18:55.514 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.16090909090912\n",
      "2021-08-25 14:18:55.514 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:19:05.775 | INFO     | src.policies:train:159 - Total loss: 1.0010007619857788\n",
      "2021-08-25 14:19:05.776 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 207.36363636363637, 'equality': 0.9320074927278306, 'sustainability': 471.05786822758404, 'peace': 729.4545454545455}\n",
      "2021-08-25 14:19:05.830 | INFO     | src.policies:train:103 - Epoch 140 / 4000\n",
      "2021-08-25 14:19:05.831 | INFO     | src.policies:train:110 - Episode 140\n",
      "2021-08-25 14:19:31.084 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:19:31.112 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 222.63636363636363, 'equality': 0.9454322729138901, 'sustainability': 508.8787132343525, 'peace': 792.1818181818181}\n",
      "2021-08-25 14:19:31.113 | INFO     | src.policies:train:122 - Mean episode return: 222.63636363636363\n",
      "2021-08-25 14:19:31.113 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.29454545454547\n",
      "2021-08-25 14:19:31.114 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:19:40.768 | INFO     | src.policies:train:159 - Total loss: 0.9966182708740234\n",
      "2021-08-25 14:19:40.768 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 222.63636363636363, 'equality': 0.9454322729138901, 'sustainability': 508.8787132343525, 'peace': 792.1818181818181}\n",
      "2021-08-25 14:19:40.819 | INFO     | src.policies:train:103 - Epoch 141 / 4000\n",
      "2021-08-25 14:19:40.820 | INFO     | src.policies:train:110 - Episode 141\n",
      "2021-08-25 14:20:03.452 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:20:03.478 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 216.36363636363637, 'equality': 0.9599694423231481, 'sustainability': 495.22400004979716, 'peace': 769.0}\n",
      "2021-08-25 14:20:03.479 | INFO     | src.policies:train:122 - Mean episode return: 216.36363636363637\n",
      "2021-08-25 14:20:03.479 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.27272727272728\n",
      "2021-08-25 14:20:03.480 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:20:12.795 | INFO     | src.policies:train:159 - Total loss: 1.0040620565414429\n",
      "2021-08-25 14:20:12.796 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 216.36363636363637, 'equality': 0.9599694423231481, 'sustainability': 495.22400004979716, 'peace': 769.0}\n",
      "2021-08-25 14:20:12.844 | INFO     | src.policies:train:103 - Epoch 142 / 4000\n",
      "2021-08-25 14:20:12.845 | INFO     | src.policies:train:110 - Episode 142\n",
      "2021-08-25 14:20:35.549 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:20:35.578 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 228.27272727272728, 'equality': 0.9488070670875637, 'sustainability': 495.5736306640316, 'peace': 818.6363636363636}\n",
      "2021-08-25 14:20:35.579 | INFO     | src.policies:train:122 - Mean episode return: 228.27272727272728\n",
      "2021-08-25 14:20:35.579 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.46272727272728\n",
      "2021-08-25 14:20:35.580 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:20:45.113 | INFO     | src.policies:train:159 - Total loss: 0.9965884685516357\n",
      "2021-08-25 14:20:45.113 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 228.27272727272728, 'equality': 0.9488070670875637, 'sustainability': 495.5736306640316, 'peace': 818.6363636363636}\n",
      "2021-08-25 14:20:45.166 | INFO     | src.policies:train:103 - Epoch 143 / 4000\n",
      "2021-08-25 14:20:45.167 | INFO     | src.policies:train:110 - Episode 143\n",
      "2021-08-25 14:21:08.835 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:21:08.864 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 201.54545454545453, 'equality': 0.9414442120814073, 'sustainability': 473.4512605634658, 'peace': 658.2727272727273}\n",
      "2021-08-25 14:21:08.865 | INFO     | src.policies:train:122 - Mean episode return: 201.54545454545453\n",
      "2021-08-25 14:21:08.865 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.4436363636364\n",
      "2021-08-25 14:21:08.866 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:21:18.806 | INFO     | src.policies:train:159 - Total loss: 1.0007319450378418\n",
      "2021-08-25 14:21:18.807 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 201.54545454545453, 'equality': 0.9414442120814073, 'sustainability': 473.4512605634658, 'peace': 658.2727272727273}\n",
      "2021-08-25 14:21:18.860 | INFO     | src.policies:train:103 - Epoch 144 / 4000\n",
      "2021-08-25 14:21:18.860 | INFO     | src.policies:train:110 - Episode 144\n",
      "2021-08-25 14:21:42.966 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:21:42.996 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 197.54545454545453, 'equality': 0.9305526502963948, 'sustainability': 497.89353010909093, 'peace': 743.0}\n",
      "2021-08-25 14:21:42.997 | INFO     | src.policies:train:122 - Mean episode return: 197.54545454545453\n",
      "2021-08-25 14:21:42.998 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.32090909090908\n",
      "2021-08-25 14:21:42.998 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:21:53.035 | INFO     | src.policies:train:159 - Total loss: 1.0035070180892944\n",
      "2021-08-25 14:21:53.036 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 197.54545454545453, 'equality': 0.9305526502963948, 'sustainability': 497.89353010909093, 'peace': 743.0}\n",
      "2021-08-25 14:21:53.090 | INFO     | src.policies:train:103 - Epoch 145 / 4000\n",
      "2021-08-25 14:21:53.091 | INFO     | src.policies:train:110 - Episode 145\n",
      "2021-08-25 14:22:19.384 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:22:19.413 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 200.54545454545453, 'equality': 0.9249979395053779, 'sustainability': 474.411980880905, 'peace': 696.6363636363636}\n",
      "2021-08-25 14:22:19.414 | INFO     | src.policies:train:122 - Mean episode return: 200.54545454545453\n",
      "2021-08-25 14:22:19.414 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.24181818181825\n",
      "2021-08-25 14:22:19.415 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:22:30.401 | INFO     | src.policies:train:159 - Total loss: 1.001346468925476\n",
      "2021-08-25 14:22:30.401 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 200.54545454545453, 'equality': 0.9249979395053779, 'sustainability': 474.411980880905, 'peace': 696.6363636363636}\n",
      "2021-08-25 14:22:30.461 | INFO     | src.policies:train:103 - Epoch 146 / 4000\n",
      "2021-08-25 14:22:30.461 | INFO     | src.policies:train:110 - Episode 146\n",
      "2021-08-25 14:22:57.804 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 14:22:57.836 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 199.36363636363637, 'equality': 0.916594121794209, 'sustainability': 476.41264874360405, 'peace': 659.4545454545455}\n",
      "2021-08-25 14:22:57.837 | INFO     | src.policies:train:122 - Mean episode return: 199.36363636363637\n",
      "2021-08-25 14:22:57.838 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.1127272727273\n",
      "2021-08-25 14:22:57.838 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:23:08.737 | INFO     | src.policies:train:159 - Total loss: 1.003564476966858\n",
      "2021-08-25 14:23:08.738 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 199.36363636363637, 'equality': 0.916594121794209, 'sustainability': 476.41264874360405, 'peace': 659.4545454545455}\n",
      "2021-08-25 14:23:08.801 | INFO     | src.policies:train:103 - Epoch 147 / 4000\n",
      "2021-08-25 14:23:08.802 | INFO     | src.policies:train:110 - Episode 147\n",
      "2021-08-25 14:23:34.859 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:23:34.887 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 214.1818181818182, 'equality': 0.9153418737475818, 'sustainability': 495.9541745147859, 'peace': 801.0}\n",
      "2021-08-25 14:23:34.887 | INFO     | src.policies:train:122 - Mean episode return: 214.1818181818182\n",
      "2021-08-25 14:23:34.888 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.05545454545455\n",
      "2021-08-25 14:23:34.889 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:23:45.155 | INFO     | src.policies:train:159 - Total loss: 1.0002074241638184\n",
      "2021-08-25 14:23:45.156 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 214.1818181818182, 'equality': 0.9153418737475818, 'sustainability': 495.9541745147859, 'peace': 801.0}\n",
      "2021-08-25 14:23:45.210 | INFO     | src.policies:train:103 - Epoch 148 / 4000\n",
      "2021-08-25 14:23:45.211 | INFO     | src.policies:train:110 - Episode 148\n",
      "2021-08-25 14:24:10.697 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:24:10.722 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 202.1818181818182, 'equality': 0.9158763897989725, 'sustainability': 496.3336543694049, 'peace': 689.3636363636364}\n",
      "2021-08-25 14:24:10.722 | INFO     | src.policies:train:122 - Mean episode return: 202.1818181818182\n",
      "2021-08-25 14:24:10.723 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 204.93727272727276\n",
      "2021-08-25 14:24:10.723 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:24:20.932 | INFO     | src.policies:train:159 - Total loss: 0.9952569007873535\n",
      "2021-08-25 14:24:20.933 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 202.1818181818182, 'equality': 0.9158763897989725, 'sustainability': 496.3336543694049, 'peace': 689.3636363636364}\n",
      "2021-08-25 14:24:20.985 | INFO     | src.policies:train:103 - Epoch 149 / 4000\n",
      "2021-08-25 14:24:20.985 | INFO     | src.policies:train:110 - Episode 149\n",
      "2021-08-25 14:24:45.806 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:24:45.829 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 212.0909090909091, 'equality': 0.924950317579298, 'sustainability': 501.8143900256238, 'peace': 807.5454545454545}\n",
      "2021-08-25 14:24:45.830 | INFO     | src.policies:train:122 - Mean episode return: 212.0909090909091\n",
      "2021-08-25 14:24:45.830 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 204.9736363636364\n",
      "2021-08-25 14:24:45.831 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:24:55.394 | INFO     | src.policies:train:159 - Total loss: 0.9985991716384888\n",
      "2021-08-25 14:24:55.395 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 212.0909090909091, 'equality': 0.924950317579298, 'sustainability': 501.8143900256238, 'peace': 807.5454545454545}\n",
      "2021-08-25 14:24:55.444 | INFO     | src.policies:train:103 - Epoch 150 / 4000\n",
      "2021-08-25 14:24:55.445 | INFO     | src.policies:train:110 - Episode 150\n",
      "2021-08-25 14:25:19.290 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:25:19.319 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 209.0, 'equality': 0.9264502352816155, 'sustainability': 478.6091275791412, 'peace': 717.3636363636364}\n",
      "2021-08-25 14:25:19.320 | INFO     | src.policies:train:122 - Mean episode return: 209.0\n",
      "2021-08-25 14:25:19.320 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 204.9118181818182\n",
      "2021-08-25 14:25:19.321 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:25:30.520 | INFO     | src.policies:train:159 - Total loss: 0.9976646900177002\n",
      "2021-08-25 14:25:30.521 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 209.0, 'equality': 0.9264502352816155, 'sustainability': 478.6091275791412, 'peace': 717.3636363636364}\n",
      "2021-08-25 14:25:30.579 | INFO     | src.policies:train:103 - Epoch 151 / 4000\n",
      "2021-08-25 14:25:30.580 | INFO     | src.policies:train:110 - Episode 151\n",
      "2021-08-25 14:25:58.786 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:25:58.817 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 211.63636363636363, 'equality': 0.9408778506728195, 'sustainability': 508.4952160077684, 'peace': 776.8181818181819}\n",
      "2021-08-25 14:25:58.818 | INFO     | src.policies:train:122 - Mean episode return: 211.63636363636363\n",
      "2021-08-25 14:25:58.819 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.14545454545456\n",
      "2021-08-25 14:25:58.820 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:26:10.129 | INFO     | src.policies:train:159 - Total loss: 1.004783034324646\n",
      "2021-08-25 14:26:10.130 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 211.63636363636363, 'equality': 0.9408778506728195, 'sustainability': 508.4952160077684, 'peace': 776.8181818181819}\n",
      "2021-08-25 14:26:10.185 | INFO     | src.policies:train:103 - Epoch 152 / 4000\n",
      "2021-08-25 14:26:10.186 | INFO     | src.policies:train:110 - Episode 152\n",
      "2021-08-25 14:26:35.927 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:26:35.953 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 204.45454545454547, 'equality': 0.9150329439363953, 'sustainability': 471.80141837731065, 'peace': 721.9090909090909}\n",
      "2021-08-25 14:26:35.954 | INFO     | src.policies:train:122 - Mean episode return: 204.45454545454547\n",
      "2021-08-25 14:26:35.954 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 204.94181818181815\n",
      "2021-08-25 14:26:35.955 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:26:45.553 | INFO     | src.policies:train:159 - Total loss: 1.0014967918395996\n",
      "2021-08-25 14:26:45.554 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 204.45454545454547, 'equality': 0.9150329439363953, 'sustainability': 471.80141837731065, 'peace': 721.9090909090909}\n",
      "2021-08-25 14:26:45.605 | INFO     | src.policies:train:103 - Epoch 153 / 4000\n",
      "2021-08-25 14:26:45.606 | INFO     | src.policies:train:110 - Episode 153\n",
      "2021-08-25 14:27:09.418 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:27:09.446 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 213.45454545454547, 'equality': 0.9138144649234587, 'sustainability': 500.09487223631004, 'peace': 721.9090909090909}\n",
      "2021-08-25 14:27:09.446 | INFO     | src.policies:train:122 - Mean episode return: 213.45454545454547\n",
      "2021-08-25 14:27:09.447 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 204.96727272727273\n",
      "2021-08-25 14:27:09.448 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:27:19.685 | INFO     | src.policies:train:159 - Total loss: 1.0023081302642822\n",
      "2021-08-25 14:27:19.685 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 213.45454545454547, 'equality': 0.9138144649234587, 'sustainability': 500.09487223631004, 'peace': 721.9090909090909}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 14:27:19.743 | INFO     | src.policies:train:103 - Epoch 154 / 4000\n",
      "2021-08-25 14:27:19.743 | INFO     | src.policies:train:110 - Episode 154\n",
      "2021-08-25 14:27:45.590 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:27:45.617 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 206.72727272727272, 'equality': 0.927240745184152, 'sustainability': 498.0924375206096, 'peace': 742.4545454545455}\n",
      "2021-08-25 14:27:45.618 | INFO     | src.policies:train:122 - Mean episode return: 206.72727272727272\n",
      "2021-08-25 14:27:45.618 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 204.85636363636365\n",
      "2021-08-25 14:27:45.619 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:27:55.839 | INFO     | src.policies:train:159 - Total loss: 0.9998180270195007\n",
      "2021-08-25 14:27:55.840 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 206.72727272727272, 'equality': 0.927240745184152, 'sustainability': 498.0924375206096, 'peace': 742.4545454545455}\n",
      "2021-08-25 14:27:55.894 | INFO     | src.policies:train:103 - Epoch 155 / 4000\n",
      "2021-08-25 14:27:55.895 | INFO     | src.policies:train:110 - Episode 155\n",
      "2021-08-25 14:28:21.119 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:28:21.148 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 194.0909090909091, 'equality': 0.8914200553567933, 'sustainability': 483.5181954198144, 'peace': 689.3636363636364}\n",
      "2021-08-25 14:28:21.149 | INFO     | src.policies:train:122 - Mean episode return: 194.0909090909091\n",
      "2021-08-25 14:28:21.150 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 204.83363636363637\n",
      "2021-08-25 14:28:21.150 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:28:31.891 | INFO     | src.policies:train:159 - Total loss: 1.0004698038101196\n",
      "2021-08-25 14:28:31.891 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 194.0909090909091, 'equality': 0.8914200553567933, 'sustainability': 483.5181954198144, 'peace': 689.3636363636364}\n",
      "2021-08-25 14:28:31.952 | INFO     | src.policies:train:103 - Epoch 156 / 4000\n",
      "2021-08-25 14:28:31.952 | INFO     | src.policies:train:110 - Episode 156\n",
      "2021-08-25 14:28:59.618 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:28:59.646 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 194.8181818181818, 'equality': 0.9258473677528136, 'sustainability': 485.3560917691962, 'peace': 671.9090909090909}\n",
      "2021-08-25 14:28:59.647 | INFO     | src.policies:train:122 - Mean episode return: 194.8181818181818\n",
      "2021-08-25 14:28:59.647 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 204.8263636363636\n",
      "2021-08-25 14:28:59.648 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:29:10.623 | INFO     | src.policies:train:159 - Total loss: 0.9988174438476562\n",
      "2021-08-25 14:29:10.624 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 194.8181818181818, 'equality': 0.9258473677528136, 'sustainability': 485.3560917691962, 'peace': 671.9090909090909}\n",
      "2021-08-25 14:29:10.682 | INFO     | src.policies:train:103 - Epoch 157 / 4000\n",
      "2021-08-25 14:29:10.683 | INFO     | src.policies:train:110 - Episode 157\n",
      "2021-08-25 14:29:37.211 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:29:37.240 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 207.36363636363637, 'equality': 0.9407755769012639, 'sustainability': 484.59618172520806, 'peace': 683.2727272727273}\n",
      "2021-08-25 14:29:37.241 | INFO     | src.policies:train:122 - Mean episode return: 207.36363636363637\n",
      "2021-08-25 14:29:37.241 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 204.83181818181816\n",
      "2021-08-25 14:29:37.242 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:29:47.841 | INFO     | src.policies:train:159 - Total loss: 1.0034383535385132\n",
      "2021-08-25 14:29:47.842 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 207.36363636363637, 'equality': 0.9407755769012639, 'sustainability': 484.59618172520806, 'peace': 683.2727272727273}\n",
      "2021-08-25 14:29:47.897 | INFO     | src.policies:train:103 - Epoch 158 / 4000\n",
      "2021-08-25 14:29:47.898 | INFO     | src.policies:train:110 - Episode 158\n",
      "2021-08-25 14:30:12.546 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:30:12.575 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 211.54545454545453, 'equality': 0.9316326131981945, 'sustainability': 487.4834870882071, 'peace': 729.9090909090909}\n",
      "2021-08-25 14:30:12.575 | INFO     | src.policies:train:122 - Mean episode return: 211.54545454545453\n",
      "2021-08-25 14:30:12.576 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 204.83727272727276\n",
      "2021-08-25 14:30:12.576 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:30:22.547 | INFO     | src.policies:train:159 - Total loss: 1.0046782493591309\n",
      "2021-08-25 14:30:22.548 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 211.54545454545453, 'equality': 0.9316326131981945, 'sustainability': 487.4834870882071, 'peace': 729.9090909090909}\n",
      "2021-08-25 14:30:22.603 | INFO     | src.policies:train:103 - Epoch 159 / 4000\n",
      "2021-08-25 14:30:22.604 | INFO     | src.policies:train:110 - Episode 159\n",
      "2021-08-25 14:30:48.865 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:30:48.892 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 220.27272727272728, 'equality': 0.9384684650895121, 'sustainability': 485.89405034215906, 'peace': 693.7272727272727}\n",
      "2021-08-25 14:30:48.893 | INFO     | src.policies:train:122 - Mean episode return: 220.27272727272728\n",
      "2021-08-25 14:30:48.893 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 204.99\n",
      "2021-08-25 14:30:48.894 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:30:59.703 | INFO     | src.policies:train:159 - Total loss: 1.0076624155044556\n",
      "2021-08-25 14:30:59.703 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 220.27272727272728, 'equality': 0.9384684650895121, 'sustainability': 485.89405034215906, 'peace': 693.7272727272727}\n",
      "2021-08-25 14:30:59.760 | INFO     | src.policies:train:103 - Epoch 160 / 4000\n",
      "2021-08-25 14:30:59.761 | INFO     | src.policies:train:110 - Episode 160\n",
      "2021-08-25 14:31:27.621 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:31:27.650 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 219.9090909090909, 'equality': 0.9474613852465809, 'sustainability': 491.7005375258836, 'peace': 746.3636363636364}\n",
      "2021-08-25 14:31:27.651 | INFO     | src.policies:train:122 - Mean episode return: 219.9090909090909\n",
      "2021-08-25 14:31:27.652 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.10909090909095\n",
      "2021-08-25 14:31:27.653 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:31:38.577 | INFO     | src.policies:train:159 - Total loss: 0.9992325901985168\n",
      "2021-08-25 14:31:38.578 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 219.9090909090909, 'equality': 0.9474613852465809, 'sustainability': 491.7005375258836, 'peace': 746.3636363636364}\n",
      "2021-08-25 14:31:38.636 | INFO     | src.policies:train:103 - Epoch 161 / 4000\n",
      "2021-08-25 14:31:38.636 | INFO     | src.policies:train:110 - Episode 161\n",
      "2021-08-25 14:32:04.545 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:32:04.570 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 198.1818181818182, 'equality': 0.9045037531295975, 'sustainability': 481.2017994650568, 'peace': 692.8181818181819}\n",
      "2021-08-25 14:32:04.571 | INFO     | src.policies:train:122 - Mean episode return: 198.1818181818182\n",
      "2021-08-25 14:32:04.571 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.1536363636364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 14:32:04.572 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:32:14.494 | INFO     | src.policies:train:159 - Total loss: 1.003471851348877\n",
      "2021-08-25 14:32:14.495 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 198.1818181818182, 'equality': 0.9045037531295975, 'sustainability': 481.2017994650568, 'peace': 692.8181818181819}\n",
      "2021-08-25 14:32:14.548 | INFO     | src.policies:train:103 - Epoch 162 / 4000\n",
      "2021-08-25 14:32:14.548 | INFO     | src.policies:train:110 - Episode 162\n",
      "2021-08-25 14:32:38.652 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:32:38.676 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 222.0909090909091, 'equality': 0.931232091691824, 'sustainability': 505.56914786191487, 'peace': 809.2727272727273}\n",
      "2021-08-25 14:32:38.677 | INFO     | src.policies:train:122 - Mean episode return: 222.0909090909091\n",
      "2021-08-25 14:32:38.677 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.34636363636366\n",
      "2021-08-25 14:32:38.678 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:32:48.343 | INFO     | src.policies:train:159 - Total loss: 1.0060209035873413\n",
      "2021-08-25 14:32:48.344 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 222.0909090909091, 'equality': 0.931232091691824, 'sustainability': 505.56914786191487, 'peace': 809.2727272727273}\n",
      "2021-08-25 14:32:48.396 | INFO     | src.policies:train:103 - Epoch 163 / 4000\n",
      "2021-08-25 14:32:48.397 | INFO     | src.policies:train:110 - Episode 163\n",
      "2021-08-25 14:33:12.405 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:33:12.432 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 193.36363636363637, 'equality': 0.943753472668638, 'sustainability': 450.01040901068967, 'peace': 648.5454545454545}\n",
      "2021-08-25 14:33:12.433 | INFO     | src.policies:train:122 - Mean episode return: 193.36363636363637\n",
      "2021-08-25 14:33:12.433 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.3\n",
      "2021-08-25 14:33:12.434 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:33:22.706 | INFO     | src.policies:train:159 - Total loss: 0.999360978603363\n",
      "2021-08-25 14:33:22.707 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 193.36363636363637, 'equality': 0.943753472668638, 'sustainability': 450.01040901068967, 'peace': 648.5454545454545}\n",
      "2021-08-25 14:33:22.761 | INFO     | src.policies:train:103 - Epoch 164 / 4000\n",
      "2021-08-25 14:33:22.762 | INFO     | src.policies:train:110 - Episode 164\n",
      "2021-08-25 14:33:49.069 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:33:49.094 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 206.9090909090909, 'equality': 0.9189966448330604, 'sustainability': 472.5706339132448, 'peace': 672.5454545454545}\n",
      "2021-08-25 14:33:49.096 | INFO     | src.policies:train:122 - Mean episode return: 206.9090909090909\n",
      "2021-08-25 14:33:49.096 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.16000000000003\n",
      "2021-08-25 14:33:49.097 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:33:59.664 | INFO     | src.policies:train:159 - Total loss: 1.0008262395858765\n",
      "2021-08-25 14:33:59.665 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 206.9090909090909, 'equality': 0.9189966448330604, 'sustainability': 472.5706339132448, 'peace': 672.5454545454545}\n",
      "2021-08-25 14:33:59.720 | INFO     | src.policies:train:103 - Epoch 165 / 4000\n",
      "2021-08-25 14:33:59.720 | INFO     | src.policies:train:110 - Episode 165\n",
      "2021-08-25 14:34:26.081 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:34:26.109 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 211.36363636363637, 'equality': 0.9350928641263911, 'sustainability': 497.8237705248408, 'peace': 733.6363636363636}\n",
      "2021-08-25 14:34:26.110 | INFO     | src.policies:train:122 - Mean episode return: 211.36363636363637\n",
      "2021-08-25 14:34:26.111 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.3\n",
      "2021-08-25 14:34:26.111 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:34:36.676 | INFO     | src.policies:train:159 - Total loss: 1.0026381015777588\n",
      "2021-08-25 14:34:36.677 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 211.36363636363637, 'equality': 0.9350928641263911, 'sustainability': 497.8237705248408, 'peace': 733.6363636363636}\n",
      "2021-08-25 14:34:36.730 | INFO     | src.policies:train:103 - Epoch 166 / 4000\n",
      "2021-08-25 14:34:36.731 | INFO     | src.policies:train:110 - Episode 166\n",
      "2021-08-25 14:35:03.364 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:35:03.392 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 197.45454545454547, 'equality': 0.9056587979259656, 'sustainability': 479.8702481555131, 'peace': 727.6363636363636}\n",
      "2021-08-25 14:35:03.393 | INFO     | src.policies:train:122 - Mean episode return: 197.45454545454547\n",
      "2021-08-25 14:35:03.393 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.1890909090909\n",
      "2021-08-25 14:35:03.394 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:35:13.639 | INFO     | src.policies:train:159 - Total loss: 1.008531928062439\n",
      "2021-08-25 14:35:13.640 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 197.45454545454547, 'equality': 0.9056587979259656, 'sustainability': 479.8702481555131, 'peace': 727.6363636363636}\n",
      "2021-08-25 14:35:13.693 | INFO     | src.policies:train:103 - Epoch 167 / 4000\n",
      "2021-08-25 14:35:13.694 | INFO     | src.policies:train:110 - Episode 167\n",
      "2021-08-25 14:35:39.647 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:35:39.673 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 210.9090909090909, 'equality': 0.9239028213181053, 'sustainability': 479.67835649476496, 'peace': 737.0909090909091}\n",
      "2021-08-25 14:35:39.674 | INFO     | src.policies:train:122 - Mean episode return: 210.9090909090909\n",
      "2021-08-25 14:35:39.674 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.3918181818182\n",
      "2021-08-25 14:35:39.675 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:35:49.258 | INFO     | src.policies:train:159 - Total loss: 1.0031830072402954\n",
      "2021-08-25 14:35:49.259 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 210.9090909090909, 'equality': 0.9239028213181053, 'sustainability': 479.67835649476496, 'peace': 737.0909090909091}\n",
      "2021-08-25 14:35:49.313 | INFO     | src.policies:train:103 - Epoch 168 / 4000\n",
      "2021-08-25 14:35:49.314 | INFO     | src.policies:train:110 - Episode 168\n",
      "2021-08-25 14:36:14.431 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:36:14.457 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 206.36363636363637, 'equality': 0.9174209050877569, 'sustainability': 498.42378353763957, 'peace': 683.0}\n",
      "2021-08-25 14:36:14.457 | INFO     | src.policies:train:122 - Mean episode return: 206.36363636363637\n",
      "2021-08-25 14:36:14.458 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.5618181818182\n",
      "2021-08-25 14:36:14.458 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:36:24.060 | INFO     | src.policies:train:159 - Total loss: 1.0023772716522217\n",
      "2021-08-25 14:36:24.061 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 206.36363636363637, 'equality': 0.9174209050877569, 'sustainability': 498.42378353763957, 'peace': 683.0}\n",
      "2021-08-25 14:36:24.111 | INFO     | src.policies:train:103 - Epoch 169 / 4000\n",
      "2021-08-25 14:36:24.112 | INFO     | src.policies:train:110 - Episode 169\n",
      "2021-08-25 14:36:48.707 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 14:36:48.734 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 214.54545454545453, 'equality': 0.946456086287626, 'sustainability': 489.45420894759667, 'peace': 804.8181818181819}\n",
      "2021-08-25 14:36:48.735 | INFO     | src.policies:train:122 - Mean episode return: 214.54545454545453\n",
      "2021-08-25 14:36:48.735 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.70909090909092\n",
      "2021-08-25 14:36:48.736 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:36:58.986 | INFO     | src.policies:train:159 - Total loss: 0.9986152052879333\n",
      "2021-08-25 14:36:58.987 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 214.54545454545453, 'equality': 0.946456086287626, 'sustainability': 489.45420894759667, 'peace': 804.8181818181819}\n",
      "2021-08-25 14:36:59.044 | INFO     | src.policies:train:103 - Epoch 170 / 4000\n",
      "2021-08-25 14:36:59.045 | INFO     | src.policies:train:110 - Episode 170\n",
      "2021-08-25 14:37:25.906 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:37:25.933 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 198.0909090909091, 'equality': 0.9309942008441947, 'sustainability': 484.26069465077484, 'peace': 714.2727272727273}\n",
      "2021-08-25 14:37:25.934 | INFO     | src.policies:train:122 - Mean episode return: 198.0909090909091\n",
      "2021-08-25 14:37:25.935 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.5554545454546\n",
      "2021-08-25 14:37:25.935 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:37:36.534 | INFO     | src.policies:train:159 - Total loss: 1.0015122890472412\n",
      "2021-08-25 14:37:36.535 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 198.0909090909091, 'equality': 0.9309942008441947, 'sustainability': 484.26069465077484, 'peace': 714.2727272727273}\n",
      "2021-08-25 14:37:36.594 | INFO     | src.policies:train:103 - Epoch 171 / 4000\n",
      "2021-08-25 14:37:36.595 | INFO     | src.policies:train:110 - Episode 171\n",
      "2021-08-25 14:38:04.195 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:38:04.229 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 213.0, 'equality': 0.9475420013202277, 'sustainability': 502.0559626645618, 'peace': 763.6363636363636}\n",
      "2021-08-25 14:38:04.230 | INFO     | src.policies:train:122 - Mean episode return: 213.0\n",
      "2021-08-25 14:38:04.231 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.78\n",
      "2021-08-25 14:38:04.232 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:38:15.184 | INFO     | src.policies:train:159 - Total loss: 1.0060029029846191\n",
      "2021-08-25 14:38:15.185 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 213.0, 'equality': 0.9475420013202277, 'sustainability': 502.0559626645618, 'peace': 763.6363636363636}\n",
      "2021-08-25 14:38:15.245 | INFO     | src.policies:train:103 - Epoch 172 / 4000\n",
      "2021-08-25 14:38:15.245 | INFO     | src.policies:train:110 - Episode 172\n",
      "2021-08-25 14:38:42.226 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:38:42.255 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 201.9090909090909, 'equality': 0.8851459211680827, 'sustainability': 470.0007072887151, 'peace': 688.3636363636364}\n",
      "2021-08-25 14:38:42.256 | INFO     | src.policies:train:122 - Mean episode return: 201.9090909090909\n",
      "2021-08-25 14:38:42.256 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.82272727272732\n",
      "2021-08-25 14:38:42.257 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:38:52.501 | INFO     | src.policies:train:159 - Total loss: 1.0019097328186035\n",
      "2021-08-25 14:38:52.501 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 201.9090909090909, 'equality': 0.8851459211680827, 'sustainability': 470.0007072887151, 'peace': 688.3636363636364}\n",
      "2021-08-25 14:38:52.558 | INFO     | src.policies:train:103 - Epoch 173 / 4000\n",
      "2021-08-25 14:38:52.559 | INFO     | src.policies:train:110 - Episode 173\n",
      "2021-08-25 14:39:19.642 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:39:19.675 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 203.0, 'equality': 0.9404795831140236, 'sustainability': 495.30339348693093, 'peace': 666.2727272727273}\n",
      "2021-08-25 14:39:19.676 | INFO     | src.policies:train:122 - Mean episode return: 203.0\n",
      "2021-08-25 14:39:19.676 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.84727272727272\n",
      "2021-08-25 14:39:19.677 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:39:31.498 | INFO     | src.policies:train:159 - Total loss: 0.9947860240936279\n",
      "2021-08-25 14:39:31.499 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 203.0, 'equality': 0.9404795831140236, 'sustainability': 495.30339348693093, 'peace': 666.2727272727273}\n",
      "2021-08-25 14:39:31.564 | INFO     | src.policies:train:103 - Epoch 174 / 4000\n",
      "2021-08-25 14:39:31.565 | INFO     | src.policies:train:110 - Episode 174\n",
      "2021-08-25 14:40:00.341 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:40:00.372 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 217.63636363636363, 'equality': 0.9328624591795234, 'sustainability': 478.6561312656773, 'peace': 771.0}\n",
      "2021-08-25 14:40:00.373 | INFO     | src.policies:train:122 - Mean episode return: 217.63636363636363\n",
      "2021-08-25 14:40:00.374 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.88545454545456\n",
      "2021-08-25 14:40:00.374 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:40:10.892 | INFO     | src.policies:train:159 - Total loss: 1.00156831741333\n",
      "2021-08-25 14:40:10.893 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 217.63636363636363, 'equality': 0.9328624591795234, 'sustainability': 478.6561312656773, 'peace': 771.0}\n",
      "2021-08-25 14:40:10.946 | INFO     | src.policies:train:103 - Epoch 175 / 4000\n",
      "2021-08-25 14:40:10.947 | INFO     | src.policies:train:110 - Episode 175\n",
      "2021-08-25 14:40:35.157 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:40:35.182 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 182.27272727272728, 'equality': 0.908138744051051, 'sustainability': 461.42519590626904, 'peace': 710.7272727272727}\n",
      "2021-08-25 14:40:35.183 | INFO     | src.policies:train:122 - Mean episode return: 182.27272727272728\n",
      "2021-08-25 14:40:35.184 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.58545454545455\n",
      "2021-08-25 14:40:35.184 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:40:44.801 | INFO     | src.policies:train:159 - Total loss: 0.9998959898948669\n",
      "2021-08-25 14:40:44.802 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 182.27272727272728, 'equality': 0.908138744051051, 'sustainability': 461.42519590626904, 'peace': 710.7272727272727}\n",
      "2021-08-25 14:40:44.858 | INFO     | src.policies:train:103 - Epoch 176 / 4000\n",
      "2021-08-25 14:40:44.859 | INFO     | src.policies:train:110 - Episode 176\n",
      "2021-08-25 14:41:08.534 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:41:08.560 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 198.9090909090909, 'equality': 0.919062655810224, 'sustainability': 478.0724995966738, 'peace': 653.1818181818181}\n",
      "2021-08-25 14:41:08.561 | INFO     | src.policies:train:122 - Mean episode return: 198.9090909090909\n",
      "2021-08-25 14:41:08.562 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.47909090909096\n",
      "2021-08-25 14:41:08.562 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:41:19.007 | INFO     | src.policies:train:159 - Total loss: 1.0014151334762573\n",
      "2021-08-25 14:41:19.008 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 198.9090909090909, 'equality': 0.919062655810224, 'sustainability': 478.0724995966738, 'peace': 653.1818181818181}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 14:41:19.064 | INFO     | src.policies:train:103 - Epoch 177 / 4000\n",
      "2021-08-25 14:41:19.065 | INFO     | src.policies:train:110 - Episode 177\n",
      "2021-08-25 14:41:46.706 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:41:46.735 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 208.1818181818182, 'equality': 0.947121873760478, 'sustainability': 491.33049439048494, 'peace': 745.3636363636364}\n",
      "2021-08-25 14:41:46.735 | INFO     | src.policies:train:122 - Mean episode return: 208.1818181818182\n",
      "2021-08-25 14:41:46.736 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.57818181818186\n",
      "2021-08-25 14:41:46.737 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:41:57.745 | INFO     | src.policies:train:159 - Total loss: 0.9979227781295776\n",
      "2021-08-25 14:41:57.746 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 208.1818181818182, 'equality': 0.947121873760478, 'sustainability': 491.33049439048494, 'peace': 745.3636363636364}\n",
      "2021-08-25 14:41:57.809 | INFO     | src.policies:train:103 - Epoch 178 / 4000\n",
      "2021-08-25 14:41:57.810 | INFO     | src.policies:train:110 - Episode 178\n",
      "2021-08-25 14:42:24.494 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:42:24.522 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 207.0909090909091, 'equality': 0.9652007342971266, 'sustainability': 485.1734994307149, 'peace': 796.2727272727273}\n",
      "2021-08-25 14:42:24.523 | INFO     | src.policies:train:122 - Mean episode return: 207.0909090909091\n",
      "2021-08-25 14:42:24.523 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.63454545454547\n",
      "2021-08-25 14:42:24.524 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:42:35.511 | INFO     | src.policies:train:159 - Total loss: 0.9999309778213501\n",
      "2021-08-25 14:42:35.512 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 207.0909090909091, 'equality': 0.9652007342971266, 'sustainability': 485.1734994307149, 'peace': 796.2727272727273}\n",
      "2021-08-25 14:42:35.566 | INFO     | src.policies:train:103 - Epoch 179 / 4000\n",
      "2021-08-25 14:42:35.566 | INFO     | src.policies:train:110 - Episode 179\n",
      "2021-08-25 14:43:01.944 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:43:01.967 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 203.36363636363637, 'equality': 0.8981590604320283, 'sustainability': 492.6231502836801, 'peace': 671.0909090909091}\n",
      "2021-08-25 14:43:01.968 | INFO     | src.policies:train:122 - Mean episode return: 203.36363636363637\n",
      "2021-08-25 14:43:01.968 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.37636363636366\n",
      "2021-08-25 14:43:01.969 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:43:12.209 | INFO     | src.policies:train:159 - Total loss: 1.0024892091751099\n",
      "2021-08-25 14:43:12.209 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 203.36363636363637, 'equality': 0.8981590604320283, 'sustainability': 492.6231502836801, 'peace': 671.0909090909091}\n",
      "2021-08-25 14:43:12.264 | INFO     | src.policies:train:103 - Epoch 180 / 4000\n",
      "2021-08-25 14:43:12.265 | INFO     | src.policies:train:110 - Episode 180\n",
      "2021-08-25 14:43:37.453 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:43:37.483 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 208.8181818181818, 'equality': 0.954248624689234, 'sustainability': 476.0137124125133, 'peace': 672.7272727272727}\n",
      "2021-08-25 14:43:37.483 | INFO     | src.policies:train:122 - Mean episode return: 208.8181818181818\n",
      "2021-08-25 14:43:37.484 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.40636363636364\n",
      "2021-08-25 14:43:37.484 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:43:47.749 | INFO     | src.policies:train:159 - Total loss: 1.005611538887024\n",
      "2021-08-25 14:43:47.750 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 208.8181818181818, 'equality': 0.954248624689234, 'sustainability': 476.0137124125133, 'peace': 672.7272727272727}\n",
      "2021-08-25 14:43:47.805 | INFO     | src.policies:train:103 - Epoch 181 / 4000\n",
      "2021-08-25 14:43:47.806 | INFO     | src.policies:train:110 - Episode 181\n",
      "2021-08-25 14:44:14.636 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:44:14.661 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 198.63636363636363, 'equality': 0.903141252342352, 'sustainability': 515.207679355279, 'peace': 750.4545454545455}\n",
      "2021-08-25 14:44:14.662 | INFO     | src.policies:train:122 - Mean episode return: 198.63636363636363\n",
      "2021-08-25 14:44:14.663 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.3227272727273\n",
      "2021-08-25 14:44:14.663 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:44:25.253 | INFO     | src.policies:train:159 - Total loss: 0.9959661364555359\n",
      "2021-08-25 14:44:25.254 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 198.63636363636363, 'equality': 0.903141252342352, 'sustainability': 515.207679355279, 'peace': 750.4545454545455}\n",
      "2021-08-25 14:44:25.308 | INFO     | src.policies:train:103 - Epoch 182 / 4000\n",
      "2021-08-25 14:44:25.309 | INFO     | src.policies:train:110 - Episode 182\n",
      "2021-08-25 14:44:51.993 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:44:52.024 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 207.36363636363637, 'equality': 0.9316089434472199, 'sustainability': 480.498050848034, 'peace': 725.6363636363636}\n",
      "2021-08-25 14:44:52.025 | INFO     | src.policies:train:122 - Mean episode return: 207.36363636363637\n",
      "2021-08-25 14:44:52.026 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.17181818181817\n",
      "2021-08-25 14:44:52.026 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:45:02.738 | INFO     | src.policies:train:159 - Total loss: 0.9950942397117615\n",
      "2021-08-25 14:45:02.739 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 207.36363636363637, 'equality': 0.9316089434472199, 'sustainability': 480.498050848034, 'peace': 725.6363636363636}\n",
      "2021-08-25 14:45:02.798 | INFO     | src.policies:train:103 - Epoch 183 / 4000\n",
      "2021-08-25 14:45:02.799 | INFO     | src.policies:train:110 - Episode 183\n",
      "2021-08-25 14:45:29.296 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:45:29.327 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 212.72727272727272, 'equality': 0.9459207459217964, 'sustainability': 503.1077562090954, 'peace': 761.5454545454545}\n",
      "2021-08-25 14:45:29.328 | INFO     | src.policies:train:122 - Mean episode return: 212.72727272727272\n",
      "2021-08-25 14:45:29.328 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.45636363636365\n",
      "2021-08-25 14:45:29.329 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:45:39.934 | INFO     | src.policies:train:159 - Total loss: 0.9983581900596619\n",
      "2021-08-25 14:45:39.935 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 212.72727272727272, 'equality': 0.9459207459217964, 'sustainability': 503.1077562090954, 'peace': 761.5454545454545}\n",
      "2021-08-25 14:45:39.989 | INFO     | src.policies:train:103 - Epoch 184 / 4000\n",
      "2021-08-25 14:45:39.990 | INFO     | src.policies:train:110 - Episode 184\n",
      "2021-08-25 14:46:06.518 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:46:06.544 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 205.1818181818182, 'equality': 0.9266121561218308, 'sustainability': 509.5150748403839, 'peace': 718.1818181818181}\n",
      "2021-08-25 14:46:06.545 | INFO     | src.policies:train:122 - Mean episode return: 205.1818181818182\n",
      "2021-08-25 14:46:06.545 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.36545454545455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 14:46:06.546 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:46:17.212 | INFO     | src.policies:train:159 - Total loss: 1.0010466575622559\n",
      "2021-08-25 14:46:17.213 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 205.1818181818182, 'equality': 0.9266121561218308, 'sustainability': 509.5150748403839, 'peace': 718.1818181818181}\n",
      "2021-08-25 14:46:17.271 | INFO     | src.policies:train:103 - Epoch 185 / 4000\n",
      "2021-08-25 14:46:17.271 | INFO     | src.policies:train:110 - Episode 185\n",
      "2021-08-25 14:46:44.930 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:46:44.958 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 207.63636363636363, 'equality': 0.9359974526362045, 'sustainability': 495.58513055400476, 'peace': 735.8181818181819}\n",
      "2021-08-25 14:46:44.958 | INFO     | src.policies:train:122 - Mean episode return: 207.63636363636363\n",
      "2021-08-25 14:46:44.959 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.5009090909091\n",
      "2021-08-25 14:46:44.959 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:46:55.229 | INFO     | src.policies:train:159 - Total loss: 1.000104308128357\n",
      "2021-08-25 14:46:55.230 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 207.63636363636363, 'equality': 0.9359974526362045, 'sustainability': 495.58513055400476, 'peace': 735.8181818181819}\n",
      "2021-08-25 14:46:55.286 | INFO     | src.policies:train:103 - Epoch 186 / 4000\n",
      "2021-08-25 14:46:55.287 | INFO     | src.policies:train:110 - Episode 186\n",
      "2021-08-25 14:47:19.662 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:47:19.687 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 204.72727272727272, 'equality': 0.8905215565983666, 'sustainability': 460.5191923746115, 'peace': 671.0909090909091}\n",
      "2021-08-25 14:47:19.688 | INFO     | src.policies:train:122 - Mean episode return: 204.72727272727272\n",
      "2021-08-25 14:47:19.689 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.55727272727273\n",
      "2021-08-25 14:47:19.689 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:47:29.375 | INFO     | src.policies:train:159 - Total loss: 0.9979332685470581\n",
      "2021-08-25 14:47:29.376 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 204.72727272727272, 'equality': 0.8905215565983666, 'sustainability': 460.5191923746115, 'peace': 671.0909090909091}\n",
      "2021-08-25 14:47:29.427 | INFO     | src.policies:train:103 - Epoch 187 / 4000\n",
      "2021-08-25 14:47:29.428 | INFO     | src.policies:train:110 - Episode 187\n",
      "2021-08-25 14:47:55.824 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:47:55.853 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 216.63636363636363, 'equality': 0.9456758097137742, 'sustainability': 493.1657130257814, 'peace': 748.6363636363636}\n",
      "2021-08-25 14:47:55.854 | INFO     | src.policies:train:122 - Mean episode return: 216.63636363636363\n",
      "2021-08-25 14:47:55.855 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.67727272727276\n",
      "2021-08-25 14:47:55.856 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:48:07.320 | INFO     | src.policies:train:159 - Total loss: 0.9947400093078613\n",
      "2021-08-25 14:48:07.321 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 216.63636363636363, 'equality': 0.9456758097137742, 'sustainability': 493.1657130257814, 'peace': 748.6363636363636}\n",
      "2021-08-25 14:48:07.383 | INFO     | src.policies:train:103 - Epoch 188 / 4000\n",
      "2021-08-25 14:48:07.384 | INFO     | src.policies:train:110 - Episode 188\n",
      "2021-08-25 14:48:35.174 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:48:35.201 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 203.0, 'equality': 0.9282660912769558, 'sustainability': 468.8340864340855, 'peace': 618.8181818181819}\n",
      "2021-08-25 14:48:35.202 | INFO     | src.policies:train:122 - Mean episode return: 203.0\n",
      "2021-08-25 14:48:35.202 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.7254545454545\n",
      "2021-08-25 14:48:35.203 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:48:45.909 | INFO     | src.policies:train:159 - Total loss: 0.9923365116119385\n",
      "2021-08-25 14:48:45.910 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 203.0, 'equality': 0.9282660912769558, 'sustainability': 468.8340864340855, 'peace': 618.8181818181819}\n",
      "2021-08-25 14:48:45.969 | INFO     | src.policies:train:103 - Epoch 189 / 4000\n",
      "2021-08-25 14:48:45.970 | INFO     | src.policies:train:110 - Episode 189\n",
      "2021-08-25 14:49:12.095 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:49:12.124 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 198.9090909090909, 'equality': 0.9235499418330657, 'sustainability': 461.591976411352, 'peace': 700.2727272727273}\n",
      "2021-08-25 14:49:12.125 | INFO     | src.policies:train:122 - Mean episode return: 198.9090909090909\n",
      "2021-08-25 14:49:12.125 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.55272727272728\n",
      "2021-08-25 14:49:12.126 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:49:22.715 | INFO     | src.policies:train:159 - Total loss: 1.0026967525482178\n",
      "2021-08-25 14:49:22.716 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 198.9090909090909, 'equality': 0.9235499418330657, 'sustainability': 461.591976411352, 'peace': 700.2727272727273}\n",
      "2021-08-25 14:49:22.771 | INFO     | src.policies:train:103 - Epoch 190 / 4000\n",
      "2021-08-25 14:49:22.772 | INFO     | src.policies:train:110 - Episode 190\n",
      "2021-08-25 14:49:47.074 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:49:47.098 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 201.27272727272728, 'equality': 0.9274041225275642, 'sustainability': 487.6695124020264, 'peace': 765.7272727272727}\n",
      "2021-08-25 14:49:47.099 | INFO     | src.policies:train:122 - Mean episode return: 201.27272727272728\n",
      "2021-08-25 14:49:47.099 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.52545454545455\n",
      "2021-08-25 14:49:47.100 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:49:56.543 | INFO     | src.policies:train:159 - Total loss: 0.9983911514282227\n",
      "2021-08-25 14:49:56.544 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 201.27272727272728, 'equality': 0.9274041225275642, 'sustainability': 487.6695124020264, 'peace': 765.7272727272727}\n",
      "2021-08-25 14:49:56.592 | INFO     | src.policies:train:103 - Epoch 191 / 4000\n",
      "2021-08-25 14:49:56.593 | INFO     | src.policies:train:110 - Episode 191\n",
      "2021-08-25 14:50:20.195 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:50:20.221 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 220.27272727272728, 'equality': 0.9511499643576492, 'sustainability': 497.35383240939484, 'peace': 796.5454545454545}\n",
      "2021-08-25 14:50:20.222 | INFO     | src.policies:train:122 - Mean episode return: 220.27272727272728\n",
      "2021-08-25 14:50:20.222 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.6518181818182\n",
      "2021-08-25 14:50:20.223 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:50:29.774 | INFO     | src.policies:train:159 - Total loss: 1.002326250076294\n",
      "2021-08-25 14:50:29.774 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 220.27272727272728, 'equality': 0.9511499643576492, 'sustainability': 497.35383240939484, 'peace': 796.5454545454545}\n",
      "2021-08-25 14:50:29.826 | INFO     | src.policies:train:103 - Epoch 192 / 4000\n",
      "2021-08-25 14:50:29.827 | INFO     | src.policies:train:110 - Episode 192\n",
      "2021-08-25 14:50:54.225 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 14:50:54.251 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 224.63636363636363, 'equality': 0.9416504175721708, 'sustainability': 487.15878192360566, 'peace': 778.5454545454545}\n",
      "2021-08-25 14:50:54.252 | INFO     | src.policies:train:122 - Mean episode return: 224.63636363636363\n",
      "2021-08-25 14:50:54.252 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.71181818181816\n",
      "2021-08-25 14:50:54.253 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:51:04.164 | INFO     | src.policies:train:159 - Total loss: 1.0041038990020752\n",
      "2021-08-25 14:51:04.165 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 224.63636363636363, 'equality': 0.9416504175721708, 'sustainability': 487.15878192360566, 'peace': 778.5454545454545}\n",
      "2021-08-25 14:51:04.217 | INFO     | src.policies:train:103 - Epoch 193 / 4000\n",
      "2021-08-25 14:51:04.218 | INFO     | src.policies:train:110 - Episode 193\n",
      "2021-08-25 14:51:28.869 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:51:28.898 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 218.63636363636363, 'equality': 0.9395955395966813, 'sustainability': 476.02829157122846, 'peace': 685.7272727272727}\n",
      "2021-08-25 14:51:28.899 | INFO     | src.policies:train:122 - Mean episode return: 218.63636363636363\n",
      "2021-08-25 14:51:28.900 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.89454545454547\n",
      "2021-08-25 14:51:28.900 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:51:38.859 | INFO     | src.policies:train:159 - Total loss: 0.9976562261581421\n",
      "2021-08-25 14:51:38.859 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 218.63636363636363, 'equality': 0.9395955395966813, 'sustainability': 476.02829157122846, 'peace': 685.7272727272727}\n",
      "2021-08-25 14:51:38.914 | INFO     | src.policies:train:103 - Epoch 194 / 4000\n",
      "2021-08-25 14:51:38.915 | INFO     | src.policies:train:110 - Episode 194\n",
      "2021-08-25 14:52:03.618 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:52:03.647 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 208.45454545454547, 'equality': 0.9326011973212425, 'sustainability': 495.4737470523747, 'peace': 724.4545454545455}\n",
      "2021-08-25 14:52:03.648 | INFO     | src.policies:train:122 - Mean episode return: 208.45454545454547\n",
      "2021-08-25 14:52:03.648 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.91\n",
      "2021-08-25 14:52:03.649 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:52:13.899 | INFO     | src.policies:train:159 - Total loss: 1.0047333240509033\n",
      "2021-08-25 14:52:13.900 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 208.45454545454547, 'equality': 0.9326011973212425, 'sustainability': 495.4737470523747, 'peace': 724.4545454545455}\n",
      "2021-08-25 14:52:13.957 | INFO     | src.policies:train:103 - Epoch 195 / 4000\n",
      "2021-08-25 14:52:13.957 | INFO     | src.policies:train:110 - Episode 195\n",
      "2021-08-25 14:52:40.254 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:52:40.280 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 214.54545454545453, 'equality': 0.9513867488453123, 'sustainability': 519.4374726761984, 'peace': 800.6363636363636}\n",
      "2021-08-25 14:52:40.280 | INFO     | src.policies:train:122 - Mean episode return: 214.54545454545453\n",
      "2021-08-25 14:52:40.281 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.18909090909096\n",
      "2021-08-25 14:52:40.281 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:52:50.923 | INFO     | src.policies:train:159 - Total loss: 0.9976277351379395\n",
      "2021-08-25 14:52:50.924 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 214.54545454545453, 'equality': 0.9513867488453123, 'sustainability': 519.4374726761984, 'peace': 800.6363636363636}\n",
      "2021-08-25 14:52:50.985 | INFO     | src.policies:train:103 - Epoch 196 / 4000\n",
      "2021-08-25 14:52:50.986 | INFO     | src.policies:train:110 - Episode 196\n",
      "2021-08-25 14:53:18.057 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:53:18.086 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 206.0909090909091, 'equality': 0.9474676183994172, 'sustainability': 494.99767729144367, 'peace': 744.4545454545455}\n",
      "2021-08-25 14:53:18.087 | INFO     | src.policies:train:122 - Mean episode return: 206.0909090909091\n",
      "2021-08-25 14:53:18.088 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.10090909090906\n",
      "2021-08-25 14:53:18.089 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:53:29.237 | INFO     | src.policies:train:159 - Total loss: 1.0032637119293213\n",
      "2021-08-25 14:53:29.238 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 206.0909090909091, 'equality': 0.9474676183994172, 'sustainability': 494.99767729144367, 'peace': 744.4545454545455}\n",
      "2021-08-25 14:53:29.300 | INFO     | src.policies:train:103 - Epoch 197 / 4000\n",
      "2021-08-25 14:53:29.301 | INFO     | src.policies:train:110 - Episode 197\n",
      "2021-08-25 14:53:57.923 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:53:57.952 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 209.36363636363637, 'equality': 0.9247621679247471, 'sustainability': 495.55548958172693, 'peace': 640.0909090909091}\n",
      "2021-08-25 14:53:57.953 | INFO     | src.policies:train:122 - Mean episode return: 209.36363636363637\n",
      "2021-08-25 14:53:57.954 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.3290909090909\n",
      "2021-08-25 14:53:57.955 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:54:09.044 | INFO     | src.policies:train:159 - Total loss: 1.000516414642334\n",
      "2021-08-25 14:54:09.045 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 209.36363636363637, 'equality': 0.9247621679247471, 'sustainability': 495.55548958172693, 'peace': 640.0909090909091}\n",
      "2021-08-25 14:54:09.105 | INFO     | src.policies:train:103 - Epoch 198 / 4000\n",
      "2021-08-25 14:54:09.105 | INFO     | src.policies:train:110 - Episode 198\n",
      "2021-08-25 14:54:35.006 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:54:35.032 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 207.0, 'equality': 0.9258194594177782, 'sustainability': 485.71721402880394, 'peace': 680.6363636363636}\n",
      "2021-08-25 14:54:35.033 | INFO     | src.policies:train:122 - Mean episode return: 207.0\n",
      "2021-08-25 14:54:35.034 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.34181818181816\n",
      "2021-08-25 14:54:35.034 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:54:45.003 | INFO     | src.policies:train:159 - Total loss: 0.9987344741821289\n",
      "2021-08-25 14:54:45.004 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 207.0, 'equality': 0.9258194594177782, 'sustainability': 485.71721402880394, 'peace': 680.6363636363636}\n",
      "2021-08-25 14:54:45.057 | INFO     | src.policies:train:103 - Epoch 199 / 4000\n",
      "2021-08-25 14:54:45.057 | INFO     | src.policies:train:110 - Episode 199\n",
      "2021-08-25 14:55:09.578 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:55:09.601 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 221.63636363636363, 'equality': 0.9295249459331507, 'sustainability': 474.3807650481449, 'peace': 727.9090909090909}\n",
      "2021-08-25 14:55:09.601 | INFO     | src.policies:train:122 - Mean episode return: 221.63636363636363\n",
      "2021-08-25 14:55:09.602 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.60545454545456\n",
      "2021-08-25 14:55:09.602 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:55:19.185 | INFO     | src.policies:train:159 - Total loss: 1.0007497072219849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 14:55:19.186 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 221.63636363636363, 'equality': 0.9295249459331507, 'sustainability': 474.3807650481449, 'peace': 727.9090909090909}\n",
      "2021-08-25 14:55:19.238 | INFO     | src.policies:train:103 - Epoch 200 / 4000\n",
      "2021-08-25 14:55:19.239 | INFO     | src.policies:train:110 - Episode 200\n",
      "2021-08-25 14:55:42.727 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:55:42.754 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 202.0909090909091, 'equality': 0.9567333251552624, 'sustainability': 485.59020120034506, 'peace': 722.9090909090909}\n",
      "2021-08-25 14:55:42.755 | INFO     | src.policies:train:122 - Mean episode return: 202.0909090909091\n",
      "2021-08-25 14:55:42.755 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.77999999999997\n",
      "2021-08-25 14:55:42.755 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:55:52.843 | INFO     | src.policies:train:159 - Total loss: 1.0034147500991821\n",
      "2021-08-25 14:55:52.844 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 202.0909090909091, 'equality': 0.9567333251552624, 'sustainability': 485.59020120034506, 'peace': 722.9090909090909}\n",
      "2021-08-25 14:55:52.901 | INFO     | src.policies:train:103 - Epoch 201 / 4000\n",
      "2021-08-25 14:55:52.902 | INFO     | src.policies:train:110 - Episode 201\n",
      "2021-08-25 14:56:19.092 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:56:19.116 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 207.27272727272728, 'equality': 0.897448165871263, 'sustainability': 482.2528967463834, 'peace': 708.7272727272727}\n",
      "2021-08-25 14:56:19.117 | INFO     | src.policies:train:122 - Mean episode return: 207.27272727272728\n",
      "2021-08-25 14:56:19.117 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.71727272727273\n",
      "2021-08-25 14:56:19.118 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:56:29.658 | INFO     | src.policies:train:159 - Total loss: 1.0016237497329712\n",
      "2021-08-25 14:56:29.659 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 207.27272727272728, 'equality': 0.897448165871263, 'sustainability': 482.2528967463834, 'peace': 708.7272727272727}\n",
      "2021-08-25 14:56:29.716 | INFO     | src.policies:train:103 - Epoch 202 / 4000\n",
      "2021-08-25 14:56:29.717 | INFO     | src.policies:train:110 - Episode 202\n",
      "2021-08-25 14:56:57.120 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:56:57.150 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 199.8181818181818, 'equality': 0.9381255687000967, 'sustainability': 514.7982255425223, 'peace': 698.0909090909091}\n",
      "2021-08-25 14:56:57.151 | INFO     | src.policies:train:122 - Mean episode return: 199.8181818181818\n",
      "2021-08-25 14:56:57.152 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.51363636363632\n",
      "2021-08-25 14:56:57.152 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:57:08.151 | INFO     | src.policies:train:159 - Total loss: 0.9996528029441833\n",
      "2021-08-25 14:57:08.152 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 199.8181818181818, 'equality': 0.9381255687000967, 'sustainability': 514.7982255425223, 'peace': 698.0909090909091}\n",
      "2021-08-25 14:57:08.211 | INFO     | src.policies:train:103 - Epoch 203 / 4000\n",
      "2021-08-25 14:57:08.212 | INFO     | src.policies:train:110 - Episode 203\n",
      "2021-08-25 14:57:35.592 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:57:35.619 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 193.0909090909091, 'equality': 0.9066940592384289, 'sustainability': 484.5420330659055, 'peace': 649.5454545454545}\n",
      "2021-08-25 14:57:35.620 | INFO     | src.policies:train:122 - Mean episode return: 193.0909090909091\n",
      "2021-08-25 14:57:35.620 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.51454545454544\n",
      "2021-08-25 14:57:35.621 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:57:45.949 | INFO     | src.policies:train:159 - Total loss: 0.9985889792442322\n",
      "2021-08-25 14:57:45.950 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 193.0909090909091, 'equality': 0.9066940592384289, 'sustainability': 484.5420330659055, 'peace': 649.5454545454545}\n",
      "2021-08-25 14:57:46.008 | INFO     | src.policies:train:103 - Epoch 204 / 4000\n",
      "2021-08-25 14:57:46.008 | INFO     | src.policies:train:110 - Episode 204\n",
      "2021-08-25 14:58:10.502 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:58:10.528 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 230.9090909090909, 'equality': 0.9577666428067687, 'sustainability': 502.85664539286915, 'peace': 783.9090909090909}\n",
      "2021-08-25 14:58:10.529 | INFO     | src.policies:train:122 - Mean episode return: 230.9090909090909\n",
      "2021-08-25 14:58:10.529 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.7854545454545\n",
      "2021-08-25 14:58:10.530 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:58:20.182 | INFO     | src.policies:train:159 - Total loss: 0.9998175501823425\n",
      "2021-08-25 14:58:20.183 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 230.9090909090909, 'equality': 0.9577666428067687, 'sustainability': 502.85664539286915, 'peace': 783.9090909090909}\n",
      "2021-08-25 14:58:20.238 | INFO     | src.policies:train:103 - Epoch 205 / 4000\n",
      "2021-08-25 14:58:20.239 | INFO     | src.policies:train:110 - Episode 205\n",
      "2021-08-25 14:58:43.921 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:58:43.947 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 210.63636363636363, 'equality': 0.924824420294173, 'sustainability': 495.5867995525752, 'peace': 659.8181818181819}\n",
      "2021-08-25 14:58:43.947 | INFO     | src.policies:train:122 - Mean episode return: 210.63636363636363\n",
      "2021-08-25 14:58:43.948 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.99272727272728\n",
      "2021-08-25 14:58:43.948 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:58:53.577 | INFO     | src.policies:train:159 - Total loss: 1.0027176141738892\n",
      "2021-08-25 14:58:53.578 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 210.63636363636363, 'equality': 0.924824420294173, 'sustainability': 495.5867995525752, 'peace': 659.8181818181819}\n",
      "2021-08-25 14:58:53.629 | INFO     | src.policies:train:103 - Epoch 206 / 4000\n",
      "2021-08-25 14:58:53.629 | INFO     | src.policies:train:110 - Episode 206\n",
      "2021-08-25 14:59:18.345 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:59:18.373 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 212.72727272727272, 'equality': 0.9372960372972553, 'sustainability': 488.69796980548125, 'peace': 738.5454545454545}\n",
      "2021-08-25 14:59:18.373 | INFO     | src.policies:train:122 - Mean episode return: 212.72727272727272\n",
      "2021-08-25 14:59:18.374 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.08545454545452\n",
      "2021-08-25 14:59:18.375 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 14:59:28.883 | INFO     | src.policies:train:159 - Total loss: 1.00479257106781\n",
      "2021-08-25 14:59:28.884 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 212.72727272727272, 'equality': 0.9372960372972553, 'sustainability': 488.69796980548125, 'peace': 738.5454545454545}\n",
      "2021-08-25 14:59:28.942 | INFO     | src.policies:train:103 - Epoch 207 / 4000\n",
      "2021-08-25 14:59:28.943 | INFO     | src.policies:train:110 - Episode 207\n",
      "2021-08-25 14:59:56.752 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 14:59:56.784 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 221.27272727272728, 'equality': 0.9313513109746143, 'sustainability': 500.098585497859, 'peace': 746.1818181818181}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 14:59:56.784 | INFO     | src.policies:train:122 - Mean episode return: 221.27272727272728\n",
      "2021-08-25 14:59:56.785 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.19818181818184\n",
      "2021-08-25 14:59:56.788 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:00:08.584 | INFO     | src.policies:train:159 - Total loss: 0.9984179139137268\n",
      "2021-08-25 15:00:08.585 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 221.27272727272728, 'equality': 0.9313513109746143, 'sustainability': 500.098585497859, 'peace': 746.1818181818181}\n",
      "2021-08-25 15:00:08.647 | INFO     | src.policies:train:103 - Epoch 208 / 4000\n",
      "2021-08-25 15:00:08.648 | INFO     | src.policies:train:110 - Episode 208\n",
      "2021-08-25 15:00:33.604 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:00:33.629 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 202.72727272727272, 'equality': 0.891642886263929, 'sustainability': 480.5284666882954, 'peace': 679.8181818181819}\n",
      "2021-08-25 15:00:33.630 | INFO     | src.policies:train:122 - Mean episode return: 202.72727272727272\n",
      "2021-08-25 15:00:33.630 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.23\n",
      "2021-08-25 15:00:33.631 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:00:43.099 | INFO     | src.policies:train:159 - Total loss: 1.0006057024002075\n",
      "2021-08-25 15:00:43.100 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 202.72727272727272, 'equality': 0.891642886263929, 'sustainability': 480.5284666882954, 'peace': 679.8181818181819}\n",
      "2021-08-25 15:00:43.150 | INFO     | src.policies:train:103 - Epoch 209 / 4000\n",
      "2021-08-25 15:00:43.151 | INFO     | src.policies:train:110 - Episode 209\n",
      "2021-08-25 15:01:05.630 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:01:05.654 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 203.27272727272728, 'equality': 0.9125060985543888, 'sustainability': 481.70164358733143, 'peace': 731.9090909090909}\n",
      "2021-08-25 15:01:05.655 | INFO     | src.policies:train:122 - Mean episode return: 203.27272727272728\n",
      "2021-08-25 15:01:05.655 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.16272727272727\n",
      "2021-08-25 15:01:05.656 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:01:14.697 | INFO     | src.policies:train:159 - Total loss: 0.9963791966438293\n",
      "2021-08-25 15:01:14.698 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 203.27272727272728, 'equality': 0.9125060985543888, 'sustainability': 481.70164358733143, 'peace': 731.9090909090909}\n",
      "2021-08-25 15:01:14.745 | INFO     | src.policies:train:103 - Epoch 210 / 4000\n",
      "2021-08-25 15:01:14.746 | INFO     | src.policies:train:110 - Episode 210\n",
      "2021-08-25 15:01:37.001 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:01:37.027 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 200.63636363636363, 'equality': 0.9318696708833079, 'sustainability': 486.1183687401475, 'peace': 663.9090909090909}\n",
      "2021-08-25 15:01:37.028 | INFO     | src.policies:train:122 - Mean episode return: 200.63636363636363\n",
      "2021-08-25 15:01:37.029 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.03000000000003\n",
      "2021-08-25 15:01:37.029 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:01:46.312 | INFO     | src.policies:train:159 - Total loss: 1.0056769847869873\n",
      "2021-08-25 15:01:46.313 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 200.63636363636363, 'equality': 0.9318696708833079, 'sustainability': 486.1183687401475, 'peace': 663.9090909090909}\n",
      "2021-08-25 15:01:46.364 | INFO     | src.policies:train:103 - Epoch 211 / 4000\n",
      "2021-08-25 15:01:46.364 | INFO     | src.policies:train:110 - Episode 211\n",
      "2021-08-25 15:02:10.975 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:02:11.004 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 196.9090909090909, 'equality': 0.9351129018732663, 'sustainability': 475.8610728374852, 'peace': 708.4545454545455}\n",
      "2021-08-25 15:02:11.005 | INFO     | src.policies:train:122 - Mean episode return: 196.9090909090909\n",
      "2021-08-25 15:02:11.005 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.01\n",
      "2021-08-25 15:02:11.006 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:02:21.254 | INFO     | src.policies:train:159 - Total loss: 0.9989038705825806\n",
      "2021-08-25 15:02:21.255 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 196.9090909090909, 'equality': 0.9351129018732663, 'sustainability': 475.8610728374852, 'peace': 708.4545454545455}\n",
      "2021-08-25 15:02:21.310 | INFO     | src.policies:train:103 - Epoch 212 / 4000\n",
      "2021-08-25 15:02:21.311 | INFO     | src.policies:train:110 - Episode 212\n",
      "2021-08-25 15:02:47.272 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:02:47.299 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 205.8181818181818, 'equality': 0.929087696756965, 'sustainability': 481.6812906216633, 'peace': 706.6363636363636}\n",
      "2021-08-25 15:02:47.300 | INFO     | src.policies:train:122 - Mean episode return: 205.8181818181818\n",
      "2021-08-25 15:02:47.301 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.89636363636365\n",
      "2021-08-25 15:02:47.301 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:02:57.540 | INFO     | src.policies:train:159 - Total loss: 0.9986189603805542\n",
      "2021-08-25 15:02:57.540 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 205.8181818181818, 'equality': 0.929087696756965, 'sustainability': 481.6812906216633, 'peace': 706.6363636363636}\n",
      "2021-08-25 15:02:57.596 | INFO     | src.policies:train:103 - Epoch 213 / 4000\n",
      "2021-08-25 15:02:57.596 | INFO     | src.policies:train:110 - Episode 213\n",
      "2021-08-25 15:03:22.140 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:03:22.165 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 196.9090909090909, 'equality': 0.9270544783025465, 'sustainability': 492.8159324430946, 'peace': 737.6363636363636}\n",
      "2021-08-25 15:03:22.166 | INFO     | src.policies:train:122 - Mean episode return: 196.9090909090909\n",
      "2021-08-25 15:03:22.166 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.0118181818182\n",
      "2021-08-25 15:03:22.167 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:03:32.445 | INFO     | src.policies:train:159 - Total loss: 0.9978780746459961\n",
      "2021-08-25 15:03:32.446 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 196.9090909090909, 'equality': 0.9270544783025465, 'sustainability': 492.8159324430946, 'peace': 737.6363636363636}\n",
      "2021-08-25 15:03:32.502 | INFO     | src.policies:train:103 - Epoch 214 / 4000\n",
      "2021-08-25 15:03:32.502 | INFO     | src.policies:train:110 - Episode 214\n",
      "2021-08-25 15:03:58.021 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:03:58.047 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 187.54545454545453, 'equality': 0.8996166218679853, 'sustainability': 509.82727210346343, 'peace': 684.3636363636364}\n",
      "2021-08-25 15:03:58.049 | INFO     | src.policies:train:122 - Mean episode return: 187.54545454545453\n",
      "2021-08-25 15:03:58.049 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.69909090909093\n",
      "2021-08-25 15:03:58.050 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:04:08.156 | INFO     | src.policies:train:159 - Total loss: 1.001534342765808\n",
      "2021-08-25 15:04:08.157 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 187.54545454545453, 'equality': 0.8996166218679853, 'sustainability': 509.82727210346343, 'peace': 684.3636363636364}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 15:04:08.211 | INFO     | src.policies:train:103 - Epoch 215 / 4000\n",
      "2021-08-25 15:04:08.211 | INFO     | src.policies:train:110 - Episode 215\n",
      "2021-08-25 15:04:33.287 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:04:33.311 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 209.1818181818182, 'equality': 0.9356011220430722, 'sustainability': 486.6440744913134, 'peace': 747.7272727272727}\n",
      "2021-08-25 15:04:33.312 | INFO     | src.policies:train:122 - Mean episode return: 209.1818181818182\n",
      "2021-08-25 15:04:33.312 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.7018181818182\n",
      "2021-08-25 15:04:33.313 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:04:42.917 | INFO     | src.policies:train:159 - Total loss: 1.0021817684173584\n",
      "2021-08-25 15:04:42.918 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 209.1818181818182, 'equality': 0.9356011220430722, 'sustainability': 486.6440744913134, 'peace': 747.7272727272727}\n",
      "2021-08-25 15:04:42.968 | INFO     | src.policies:train:103 - Epoch 216 / 4000\n",
      "2021-08-25 15:04:42.969 | INFO     | src.policies:train:110 - Episode 216\n",
      "2021-08-25 15:05:07.294 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:05:07.319 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 221.63636363636363, 'equality': 0.9442911477376335, 'sustainability': 496.79709932024997, 'peace': 714.0}\n",
      "2021-08-25 15:05:07.320 | INFO     | src.policies:train:122 - Mean episode return: 221.63636363636363\n",
      "2021-08-25 15:05:07.320 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.92545454545458\n",
      "2021-08-25 15:05:07.321 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:05:16.921 | INFO     | src.policies:train:159 - Total loss: 1.006545066833496\n",
      "2021-08-25 15:05:16.922 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 221.63636363636363, 'equality': 0.9442911477376335, 'sustainability': 496.79709932024997, 'peace': 714.0}\n",
      "2021-08-25 15:05:16.972 | INFO     | src.policies:train:103 - Epoch 217 / 4000\n",
      "2021-08-25 15:05:16.973 | INFO     | src.policies:train:110 - Episode 217\n",
      "2021-08-25 15:05:40.616 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:05:40.638 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 215.8181818181818, 'equality': 0.932067090450868, 'sustainability': 485.0053578084086, 'peace': 741.2727272727273}\n",
      "2021-08-25 15:05:40.638 | INFO     | src.policies:train:122 - Mean episode return: 215.8181818181818\n",
      "2021-08-25 15:05:40.639 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.98909090909092\n",
      "2021-08-25 15:05:40.639 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:05:49.990 | INFO     | src.policies:train:159 - Total loss: 1.0023393630981445\n",
      "2021-08-25 15:05:49.991 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 215.8181818181818, 'equality': 0.932067090450868, 'sustainability': 485.0053578084086, 'peace': 741.2727272727273}\n",
      "2021-08-25 15:05:50.040 | INFO     | src.policies:train:103 - Epoch 218 / 4000\n",
      "2021-08-25 15:05:50.040 | INFO     | src.policies:train:110 - Episode 218\n",
      "2021-08-25 15:06:12.136 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:06:12.160 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 193.45454545454547, 'equality': 0.8998632946022757, 'sustainability': 472.96619731850456, 'peace': 672.4545454545455}\n",
      "2021-08-25 15:06:12.161 | INFO     | src.policies:train:122 - Mean episode return: 193.45454545454547\n",
      "2021-08-25 15:06:12.161 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.08\n",
      "2021-08-25 15:06:12.161 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:06:21.241 | INFO     | src.policies:train:159 - Total loss: 1.0041553974151611\n",
      "2021-08-25 15:06:21.242 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 193.45454545454547, 'equality': 0.8998632946022757, 'sustainability': 472.96619731850456, 'peace': 672.4545454545455}\n",
      "2021-08-25 15:06:21.291 | INFO     | src.policies:train:103 - Epoch 219 / 4000\n",
      "2021-08-25 15:06:21.292 | INFO     | src.policies:train:110 - Episode 219\n",
      "2021-08-25 15:06:45.270 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:06:45.300 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 208.45454545454547, 'equality': 0.9169012409325437, 'sustainability': 489.80444448399845, 'peace': 771.0909090909091}\n",
      "2021-08-25 15:06:45.301 | INFO     | src.policies:train:122 - Mean episode return: 208.45454545454547\n",
      "2021-08-25 15:06:45.301 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.02090909090904\n",
      "2021-08-25 15:06:45.302 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:06:55.534 | INFO     | src.policies:train:159 - Total loss: 0.9971526265144348\n",
      "2021-08-25 15:06:55.535 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 208.45454545454547, 'equality': 0.9169012409325437, 'sustainability': 489.80444448399845, 'peace': 771.0909090909091}\n",
      "2021-08-25 15:06:55.589 | INFO     | src.policies:train:103 - Epoch 220 / 4000\n",
      "2021-08-25 15:06:55.589 | INFO     | src.policies:train:110 - Episode 220\n",
      "2021-08-25 15:07:20.867 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:07:20.894 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 218.8181818181818, 'equality': 0.9502964837415436, 'sustainability': 482.3152836246829, 'peace': 697.8181818181819}\n",
      "2021-08-25 15:07:20.894 | INFO     | src.policies:train:122 - Mean episode return: 218.8181818181818\n",
      "2021-08-25 15:07:20.895 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.2754545454545\n",
      "2021-08-25 15:07:20.896 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:07:31.136 | INFO     | src.policies:train:159 - Total loss: 1.0017609596252441\n",
      "2021-08-25 15:07:31.136 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 218.8181818181818, 'equality': 0.9502964837415436, 'sustainability': 482.3152836246829, 'peace': 697.8181818181819}\n",
      "2021-08-25 15:07:31.190 | INFO     | src.policies:train:103 - Epoch 221 / 4000\n",
      "2021-08-25 15:07:31.191 | INFO     | src.policies:train:110 - Episode 221\n",
      "2021-08-25 15:07:57.527 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:07:57.554 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 203.8181818181818, 'equality': 0.9382045251816924, 'sustainability': 494.81629972277454, 'peace': 717.9090909090909}\n",
      "2021-08-25 15:07:57.555 | INFO     | src.policies:train:122 - Mean episode return: 203.8181818181818\n",
      "2021-08-25 15:07:57.556 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.17181818181814\n",
      "2021-08-25 15:07:57.556 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:08:07.941 | INFO     | src.policies:train:159 - Total loss: 1.001432180404663\n",
      "2021-08-25 15:08:07.942 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 203.8181818181818, 'equality': 0.9382045251816924, 'sustainability': 494.81629972277454, 'peace': 717.9090909090909}\n",
      "2021-08-25 15:08:07.998 | INFO     | src.policies:train:103 - Epoch 222 / 4000\n",
      "2021-08-25 15:08:07.999 | INFO     | src.policies:train:110 - Episode 222\n",
      "2021-08-25 15:08:33.667 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:08:33.692 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 226.27272727272728, 'equality': 0.9363015449808922, 'sustainability': 480.4049378109557, 'peace': 755.8181818181819}\n",
      "2021-08-25 15:08:33.693 | INFO     | src.policies:train:122 - Mean episode return: 226.27272727272728\n",
      "2021-08-25 15:08:33.694 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.45818181818177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 15:08:33.695 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:08:43.996 | INFO     | src.policies:train:159 - Total loss: 1.0047566890716553\n",
      "2021-08-25 15:08:43.997 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 226.27272727272728, 'equality': 0.9363015449808922, 'sustainability': 480.4049378109557, 'peace': 755.8181818181819}\n",
      "2021-08-25 15:08:44.053 | INFO     | src.policies:train:103 - Epoch 223 / 4000\n",
      "2021-08-25 15:08:44.054 | INFO     | src.policies:train:110 - Episode 223\n",
      "2021-08-25 15:09:09.678 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:09:09.704 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 197.8181818181818, 'equality': 0.9258021390389831, 'sustainability': 476.0016012852038, 'peace': 736.0}\n",
      "2021-08-25 15:09:09.705 | INFO     | src.policies:train:122 - Mean episode return: 197.8181818181818\n",
      "2021-08-25 15:09:09.706 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.3572727272727\n",
      "2021-08-25 15:09:09.706 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:09:20.330 | INFO     | src.policies:train:159 - Total loss: 1.00225830078125\n",
      "2021-08-25 15:09:20.331 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 197.8181818181818, 'equality': 0.9258021390389831, 'sustainability': 476.0016012852038, 'peace': 736.0}\n",
      "2021-08-25 15:09:20.387 | INFO     | src.policies:train:103 - Epoch 224 / 4000\n",
      "2021-08-25 15:09:20.388 | INFO     | src.policies:train:110 - Episode 224\n",
      "2021-08-25 15:09:46.130 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:09:46.157 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 204.9090909090909, 'equality': 0.9111881906930873, 'sustainability': 477.14042333140765, 'peace': 737.1818181818181}\n",
      "2021-08-25 15:09:46.158 | INFO     | src.policies:train:122 - Mean episode return: 204.9090909090909\n",
      "2021-08-25 15:09:46.158 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.29363636363635\n",
      "2021-08-25 15:09:46.159 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:09:56.407 | INFO     | src.policies:train:159 - Total loss: 1.0036836862564087\n",
      "2021-08-25 15:09:56.408 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 204.9090909090909, 'equality': 0.9111881906930873, 'sustainability': 477.14042333140765, 'peace': 737.1818181818181}\n",
      "2021-08-25 15:09:56.463 | INFO     | src.policies:train:103 - Epoch 225 / 4000\n",
      "2021-08-25 15:09:56.464 | INFO     | src.policies:train:110 - Episode 225\n",
      "2021-08-25 15:10:21.530 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:10:21.556 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 205.8181818181818, 'equality': 0.9318181818195507, 'sustainability': 497.10475138428103, 'peace': 783.6363636363636}\n",
      "2021-08-25 15:10:21.557 | INFO     | src.policies:train:122 - Mean episode return: 205.8181818181818\n",
      "2021-08-25 15:10:21.557 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.2281818181818\n",
      "2021-08-25 15:10:21.558 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:10:31.845 | INFO     | src.policies:train:159 - Total loss: 0.9995956420898438\n",
      "2021-08-25 15:10:31.846 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 205.8181818181818, 'equality': 0.9318181818195507, 'sustainability': 497.10475138428103, 'peace': 783.6363636363636}\n",
      "2021-08-25 15:10:31.903 | INFO     | src.policies:train:103 - Epoch 226 / 4000\n",
      "2021-08-25 15:10:31.904 | INFO     | src.policies:train:110 - Episode 226\n",
      "2021-08-25 15:10:56.581 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:10:56.608 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 214.45454545454547, 'equality': 0.9523681066716951, 'sustainability': 491.3353572945484, 'peace': 670.5454545454545}\n",
      "2021-08-25 15:10:56.609 | INFO     | src.policies:train:122 - Mean episode return: 214.45454545454547\n",
      "2021-08-25 15:10:56.610 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.2136363636363\n",
      "2021-08-25 15:10:56.610 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:11:06.608 | INFO     | src.policies:train:159 - Total loss: 1.0067170858383179\n",
      "2021-08-25 15:11:06.609 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 214.45454545454547, 'equality': 0.9523681066716951, 'sustainability': 491.3353572945484, 'peace': 670.5454545454545}\n",
      "2021-08-25 15:11:06.662 | INFO     | src.policies:train:103 - Epoch 227 / 4000\n",
      "2021-08-25 15:11:06.663 | INFO     | src.policies:train:110 - Episode 227\n",
      "2021-08-25 15:11:32.590 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:11:32.619 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 198.36363636363637, 'equality': 0.8921756520312437, 'sustainability': 476.032725794289, 'peace': 669.5454545454545}\n",
      "2021-08-25 15:11:32.620 | INFO     | src.policies:train:122 - Mean episode return: 198.36363636363637\n",
      "2021-08-25 15:11:32.621 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.2372727272727\n",
      "2021-08-25 15:11:32.621 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:11:42.585 | INFO     | src.policies:train:159 - Total loss: 1.0074173212051392\n",
      "2021-08-25 15:11:42.586 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 198.36363636363637, 'equality': 0.8921756520312437, 'sustainability': 476.032725794289, 'peace': 669.5454545454545}\n",
      "2021-08-25 15:11:42.639 | INFO     | src.policies:train:103 - Epoch 228 / 4000\n",
      "2021-08-25 15:11:42.639 | INFO     | src.policies:train:110 - Episode 228\n",
      "2021-08-25 15:12:07.076 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:12:07.100 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 221.45454545454547, 'equality': 0.9300641886861833, 'sustainability': 498.8645810721691, 'peace': 760.8181818181819}\n",
      "2021-08-25 15:12:07.100 | INFO     | src.policies:train:122 - Mean episode return: 221.45454545454547\n",
      "2021-08-25 15:12:07.101 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.2463636363636\n",
      "2021-08-25 15:12:07.102 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:12:17.091 | INFO     | src.policies:train:159 - Total loss: 1.0044474601745605\n",
      "2021-08-25 15:12:17.092 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 221.45454545454547, 'equality': 0.9300641886861833, 'sustainability': 498.8645810721691, 'peace': 760.8181818181819}\n",
      "2021-08-25 15:12:17.146 | INFO     | src.policies:train:103 - Epoch 229 / 4000\n",
      "2021-08-25 15:12:17.146 | INFO     | src.policies:train:110 - Episode 229\n",
      "2021-08-25 15:12:42.778 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:12:42.816 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 204.0909090909091, 'equality': 0.9237092528867441, 'sustainability': 487.52052003422375, 'peace': 699.0}\n",
      "2021-08-25 15:12:42.818 | INFO     | src.policies:train:122 - Mean episode return: 204.0909090909091\n",
      "2021-08-25 15:12:42.819 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.08909090909088\n",
      "2021-08-25 15:12:42.819 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:12:54.635 | INFO     | src.policies:train:159 - Total loss: 1.00340735912323\n",
      "2021-08-25 15:12:54.635 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 204.0909090909091, 'equality': 0.9237092528867441, 'sustainability': 487.52052003422375, 'peace': 699.0}\n",
      "2021-08-25 15:12:54.699 | INFO     | src.policies:train:103 - Epoch 230 / 4000\n",
      "2021-08-25 15:12:54.700 | INFO     | src.policies:train:110 - Episode 230\n",
      "2021-08-25 15:13:26.878 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 15:13:26.910 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 186.0, 'equality': 0.8958499955590542, 'sustainability': 472.0381053232267, 'peace': 584.3636363636364}\n",
      "2021-08-25 15:13:26.911 | INFO     | src.policies:train:122 - Mean episode return: 186.0\n",
      "2021-08-25 15:13:26.911 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.02545454545452\n",
      "2021-08-25 15:13:26.912 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:13:38.845 | INFO     | src.policies:train:159 - Total loss: 0.9978119134902954\n",
      "2021-08-25 15:13:38.846 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 186.0, 'equality': 0.8958499955590542, 'sustainability': 472.0381053232267, 'peace': 584.3636363636364}\n",
      "2021-08-25 15:13:38.906 | INFO     | src.policies:train:103 - Epoch 231 / 4000\n",
      "2021-08-25 15:13:38.907 | INFO     | src.policies:train:110 - Episode 231\n",
      "2021-08-25 15:14:05.114 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:14:05.141 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 194.45454545454547, 'equality': 0.896298185220445, 'sustainability': 490.5956504506139, 'peace': 616.4545454545455}\n",
      "2021-08-25 15:14:05.141 | INFO     | src.policies:train:122 - Mean episode return: 194.45454545454547\n",
      "2021-08-25 15:14:05.142 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.7563636363636\n",
      "2021-08-25 15:14:05.143 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:14:15.376 | INFO     | src.policies:train:159 - Total loss: 0.9994552135467529\n",
      "2021-08-25 15:14:15.377 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 194.45454545454547, 'equality': 0.896298185220445, 'sustainability': 490.5956504506139, 'peace': 616.4545454545455}\n",
      "2021-08-25 15:14:15.432 | INFO     | src.policies:train:103 - Epoch 232 / 4000\n",
      "2021-08-25 15:14:15.433 | INFO     | src.policies:train:110 - Episode 232\n",
      "2021-08-25 15:14:41.914 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:14:41.946 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 194.1818181818182, 'equality': 0.9014300306456113, 'sustainability': 472.31727582952897, 'peace': 644.5454545454545}\n",
      "2021-08-25 15:14:41.946 | INFO     | src.policies:train:122 - Mean episode return: 194.1818181818182\n",
      "2021-08-25 15:14:41.947 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.76090909090908\n",
      "2021-08-25 15:14:41.948 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:14:52.898 | INFO     | src.policies:train:159 - Total loss: 1.00687837600708\n",
      "2021-08-25 15:14:52.899 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 194.1818181818182, 'equality': 0.9014300306456113, 'sustainability': 472.31727582952897, 'peace': 644.5454545454545}\n",
      "2021-08-25 15:14:52.957 | INFO     | src.policies:train:103 - Epoch 233 / 4000\n",
      "2021-08-25 15:14:52.958 | INFO     | src.policies:train:110 - Episode 233\n",
      "2021-08-25 15:15:20.580 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:15:20.612 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 209.1818181818182, 'equality': 0.901386748846324, 'sustainability': 499.76833210616513, 'peace': 820.6363636363636}\n",
      "2021-08-25 15:15:20.613 | INFO     | src.policies:train:122 - Mean episode return: 209.1818181818182\n",
      "2021-08-25 15:15:20.613 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.6236363636364\n",
      "2021-08-25 15:15:20.614 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:15:31.516 | INFO     | src.policies:train:159 - Total loss: 0.9997598528862\n",
      "2021-08-25 15:15:31.517 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 209.1818181818182, 'equality': 0.901386748846324, 'sustainability': 499.76833210616513, 'peace': 820.6363636363636}\n",
      "2021-08-25 15:15:31.575 | INFO     | src.policies:train:103 - Epoch 234 / 4000\n",
      "2021-08-25 15:15:31.576 | INFO     | src.policies:train:110 - Episode 234\n",
      "2021-08-25 15:15:56.977 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:15:57.007 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 216.54545454545453, 'equality': 0.9455766735374098, 'sustainability': 502.12026816702286, 'peace': 821.8181818181819}\n",
      "2021-08-25 15:15:57.008 | INFO     | src.policies:train:122 - Mean episode return: 216.54545454545453\n",
      "2021-08-25 15:15:57.009 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.11000000000004\n",
      "2021-08-25 15:15:57.009 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:16:06.917 | INFO     | src.policies:train:159 - Total loss: 1.001168966293335\n",
      "2021-08-25 15:16:06.918 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 216.54545454545453, 'equality': 0.9455766735374098, 'sustainability': 502.12026816702286, 'peace': 821.8181818181819}\n",
      "2021-08-25 15:16:06.972 | INFO     | src.policies:train:103 - Epoch 235 / 4000\n",
      "2021-08-25 15:16:06.972 | INFO     | src.policies:train:110 - Episode 235\n",
      "2021-08-25 15:16:32.075 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:16:32.102 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 198.1818181818182, 'equality': 0.9453711426199881, 'sustainability': 480.4094206227233, 'peace': 694.0}\n",
      "2021-08-25 15:16:32.102 | INFO     | src.policies:train:122 - Mean episode return: 198.1818181818182\n",
      "2021-08-25 15:16:32.103 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.14454545454555\n",
      "2021-08-25 15:16:32.103 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:16:42.071 | INFO     | src.policies:train:159 - Total loss: 0.9996057748794556\n",
      "2021-08-25 15:16:42.072 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 198.1818181818182, 'equality': 0.9453711426199881, 'sustainability': 480.4094206227233, 'peace': 694.0}\n",
      "2021-08-25 15:16:42.126 | INFO     | src.policies:train:103 - Epoch 236 / 4000\n",
      "2021-08-25 15:16:42.127 | INFO     | src.policies:train:110 - Episode 236\n",
      "2021-08-25 15:17:07.035 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:17:07.061 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 209.0909090909091, 'equality': 0.930988142293854, 'sustainability': 477.76725678515027, 'peace': 706.3636363636364}\n",
      "2021-08-25 15:17:07.062 | INFO     | src.policies:train:122 - Mean episode return: 209.0909090909091\n",
      "2021-08-25 15:17:07.063 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.17818181818188\n",
      "2021-08-25 15:17:07.063 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:17:17.287 | INFO     | src.policies:train:159 - Total loss: 1.0041159391403198\n",
      "2021-08-25 15:17:17.288 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 209.0909090909091, 'equality': 0.930988142293854, 'sustainability': 477.76725678515027, 'peace': 706.3636363636364}\n",
      "2021-08-25 15:17:17.341 | INFO     | src.policies:train:103 - Epoch 237 / 4000\n",
      "2021-08-25 15:17:17.342 | INFO     | src.policies:train:110 - Episode 237\n",
      "2021-08-25 15:17:42.581 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:17:42.609 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 193.1818181818182, 'equality': 0.9385668449211002, 'sustainability': 505.7986488697499, 'peace': 721.9090909090909}\n",
      "2021-08-25 15:17:42.610 | INFO     | src.policies:train:122 - Mean episode return: 193.1818181818182\n",
      "2021-08-25 15:17:42.610 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.1945454545455\n",
      "2021-08-25 15:17:42.611 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:17:53.507 | INFO     | src.policies:train:159 - Total loss: 1.0012930631637573\n",
      "2021-08-25 15:17:53.508 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 193.1818181818182, 'equality': 0.9385668449211002, 'sustainability': 505.7986488697499, 'peace': 721.9090909090909}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 15:17:53.570 | INFO     | src.policies:train:103 - Epoch 238 / 4000\n",
      "2021-08-25 15:17:53.571 | INFO     | src.policies:train:110 - Episode 238\n",
      "2021-08-25 15:18:23.330 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:18:23.359 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 205.54545454545453, 'equality': 0.9152426520864613, 'sustainability': 447.0805781034421, 'peace': 648.2727272727273}\n",
      "2021-08-25 15:18:23.360 | INFO     | src.policies:train:122 - Mean episode return: 205.54545454545453\n",
      "2021-08-25 15:18:23.361 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.07909090909092\n",
      "2021-08-25 15:18:23.362 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:18:35.010 | INFO     | src.policies:train:159 - Total loss: 0.9999114871025085\n",
      "2021-08-25 15:18:35.011 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 205.54545454545453, 'equality': 0.9152426520864613, 'sustainability': 447.0805781034421, 'peace': 648.2727272727273}\n",
      "2021-08-25 15:18:35.082 | INFO     | src.policies:train:103 - Epoch 239 / 4000\n",
      "2021-08-25 15:18:35.083 | INFO     | src.policies:train:110 - Episode 239\n",
      "2021-08-25 15:19:02.206 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:19:02.232 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 202.72727272727272, 'equality': 0.9443946188352141, 'sustainability': 500.2623136079068, 'peace': 793.9090909090909}\n",
      "2021-08-25 15:19:02.233 | INFO     | src.policies:train:122 - Mean episode return: 202.72727272727272\n",
      "2021-08-25 15:19:02.234 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.03272727272727\n",
      "2021-08-25 15:19:02.234 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:19:13.167 | INFO     | src.policies:train:159 - Total loss: 0.9988970756530762\n",
      "2021-08-25 15:19:13.168 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 202.72727272727272, 'equality': 0.9443946188352141, 'sustainability': 500.2623136079068, 'peace': 793.9090909090909}\n",
      "2021-08-25 15:19:13.226 | INFO     | src.policies:train:103 - Epoch 240 / 4000\n",
      "2021-08-25 15:19:13.227 | INFO     | src.policies:train:110 - Episode 240\n",
      "2021-08-25 15:19:39.416 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:19:39.444 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 189.27272727272728, 'equality': 0.8924984717515392, 'sustainability': 491.0492824363301, 'peace': 654.5454545454545}\n",
      "2021-08-25 15:19:39.444 | INFO     | src.policies:train:122 - Mean episode return: 189.27272727272728\n",
      "2021-08-25 15:19:39.445 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.69909090909093\n",
      "2021-08-25 15:19:39.445 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:19:49.685 | INFO     | src.policies:train:159 - Total loss: 1.0003067255020142\n",
      "2021-08-25 15:19:49.686 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 189.27272727272728, 'equality': 0.8924984717515392, 'sustainability': 491.0492824363301, 'peace': 654.5454545454545}\n",
      "2021-08-25 15:19:49.743 | INFO     | src.policies:train:103 - Epoch 241 / 4000\n",
      "2021-08-25 15:19:49.744 | INFO     | src.policies:train:110 - Episode 241\n",
      "2021-08-25 15:20:15.660 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:20:15.688 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 216.63636363636363, 'equality': 0.9585701751047463, 'sustainability': 505.0411841904017, 'peace': 788.5454545454545}\n",
      "2021-08-25 15:20:15.689 | INFO     | src.policies:train:122 - Mean episode return: 216.63636363636363\n",
      "2021-08-25 15:20:15.690 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.7018181818182\n",
      "2021-08-25 15:20:15.690 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:20:26.032 | INFO     | src.policies:train:159 - Total loss: 0.9974673390388489\n",
      "2021-08-25 15:20:26.033 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 216.63636363636363, 'equality': 0.9585701751047463, 'sustainability': 505.0411841904017, 'peace': 788.5454545454545}\n",
      "2021-08-25 15:20:26.088 | INFO     | src.policies:train:103 - Epoch 242 / 4000\n",
      "2021-08-25 15:20:26.089 | INFO     | src.policies:train:110 - Episode 242\n",
      "2021-08-25 15:20:51.341 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:20:51.368 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 199.72727272727272, 'equality': 0.9217941821508298, 'sustainability': 461.51874141968534, 'peace': 649.5454545454545}\n",
      "2021-08-25 15:20:51.369 | INFO     | src.policies:train:122 - Mean episode return: 199.72727272727272\n",
      "2021-08-25 15:20:51.369 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.41636363636363\n",
      "2021-08-25 15:20:51.370 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:21:01.621 | INFO     | src.policies:train:159 - Total loss: 0.9972900152206421\n",
      "2021-08-25 15:21:01.622 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 199.72727272727272, 'equality': 0.9217941821508298, 'sustainability': 461.51874141968534, 'peace': 649.5454545454545}\n",
      "2021-08-25 15:21:01.677 | INFO     | src.policies:train:103 - Epoch 243 / 4000\n",
      "2021-08-25 15:21:01.678 | INFO     | src.policies:train:110 - Episode 243\n",
      "2021-08-25 15:21:27.590 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:21:27.616 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 218.0909090909091, 'equality': 0.9402781461984108, 'sustainability': 479.64294134902633, 'peace': 729.2727272727273}\n",
      "2021-08-25 15:21:27.617 | INFO     | src.policies:train:122 - Mean episode return: 218.0909090909091\n",
      "2021-08-25 15:21:27.618 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.58181818181816\n",
      "2021-08-25 15:21:27.619 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:21:37.857 | INFO     | src.policies:train:159 - Total loss: 1.0071709156036377\n",
      "2021-08-25 15:21:37.858 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 218.0909090909091, 'equality': 0.9402781461984108, 'sustainability': 479.64294134902633, 'peace': 729.2727272727273}\n",
      "2021-08-25 15:21:37.911 | INFO     | src.policies:train:103 - Epoch 244 / 4000\n",
      "2021-08-25 15:21:37.912 | INFO     | src.policies:train:110 - Episode 244\n",
      "2021-08-25 15:22:03.662 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:22:03.691 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 221.8181818181818, 'equality': 0.9468703427729719, 'sustainability': 510.0460743944263, 'peace': 838.8181818181819}\n",
      "2021-08-25 15:22:03.692 | INFO     | src.policies:train:122 - Mean episode return: 221.8181818181818\n",
      "2021-08-25 15:22:03.693 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.82454545454544\n",
      "2021-08-25 15:22:03.694 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:22:14.223 | INFO     | src.policies:train:159 - Total loss: 0.9976719617843628\n",
      "2021-08-25 15:22:14.225 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 221.8181818181818, 'equality': 0.9468703427729719, 'sustainability': 510.0460743944263, 'peace': 838.8181818181819}\n",
      "2021-08-25 15:22:14.288 | INFO     | src.policies:train:103 - Epoch 245 / 4000\n",
      "2021-08-25 15:22:14.289 | INFO     | src.policies:train:110 - Episode 245\n",
      "2021-08-25 15:22:41.576 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:22:41.604 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 214.1818181818182, 'equality': 0.9503781447763857, 'sustainability': 475.3867803480223, 'peace': 716.0}\n",
      "2021-08-25 15:22:41.605 | INFO     | src.policies:train:122 - Mean episode return: 214.1818181818182\n",
      "2021-08-25 15:22:41.606 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.96090909090907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 15:22:41.606 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:22:52.616 | INFO     | src.policies:train:159 - Total loss: 1.0047941207885742\n",
      "2021-08-25 15:22:52.616 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 214.1818181818182, 'equality': 0.9503781447763857, 'sustainability': 475.3867803480223, 'peace': 716.0}\n",
      "2021-08-25 15:22:52.675 | INFO     | src.policies:train:103 - Epoch 246 / 4000\n",
      "2021-08-25 15:22:52.676 | INFO     | src.policies:train:110 - Episode 246\n",
      "2021-08-25 15:23:19.206 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:23:19.238 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 209.45454545454547, 'equality': 0.937500000001233, 'sustainability': 489.21100306028126, 'peace': 756.0}\n",
      "2021-08-25 15:23:19.239 | INFO     | src.policies:train:122 - Mean episode return: 209.45454545454547\n",
      "2021-08-25 15:23:19.240 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.06181818181813\n",
      "2021-08-25 15:23:19.241 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:23:29.954 | INFO     | src.policies:train:159 - Total loss: 1.0007983446121216\n",
      "2021-08-25 15:23:29.955 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 209.45454545454547, 'equality': 0.937500000001233, 'sustainability': 489.21100306028126, 'peace': 756.0}\n",
      "2021-08-25 15:23:30.013 | INFO     | src.policies:train:103 - Epoch 247 / 4000\n",
      "2021-08-25 15:23:30.013 | INFO     | src.policies:train:110 - Episode 247\n",
      "2021-08-25 15:23:56.688 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:23:56.715 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 206.54545454545453, 'equality': 0.9117317541630976, 'sustainability': 490.88261048833243, 'peace': 756.3636363636364}\n",
      "2021-08-25 15:23:56.715 | INFO     | src.policies:train:122 - Mean episode return: 206.54545454545453\n",
      "2021-08-25 15:23:56.716 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.98545454545453\n",
      "2021-08-25 15:23:56.716 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:24:06.982 | INFO     | src.policies:train:159 - Total loss: 1.0004866123199463\n",
      "2021-08-25 15:24:06.983 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 206.54545454545453, 'equality': 0.9117317541630976, 'sustainability': 490.88261048833243, 'peace': 756.3636363636364}\n",
      "2021-08-25 15:24:07.038 | INFO     | src.policies:train:103 - Epoch 248 / 4000\n",
      "2021-08-25 15:24:07.039 | INFO     | src.policies:train:110 - Episode 248\n",
      "2021-08-25 15:24:33.865 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:24:33.894 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 198.45454545454547, 'equality': 0.8727356015518108, 'sustainability': 494.8395192191059, 'peace': 733.6363636363636}\n",
      "2021-08-25 15:24:33.895 | INFO     | src.policies:train:122 - Mean episode return: 198.45454545454547\n",
      "2021-08-25 15:24:33.896 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.9481818181818\n",
      "2021-08-25 15:24:33.896 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:24:44.746 | INFO     | src.policies:train:159 - Total loss: 1.0033574104309082\n",
      "2021-08-25 15:24:44.747 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 198.45454545454547, 'equality': 0.8727356015518108, 'sustainability': 494.8395192191059, 'peace': 733.6363636363636}\n",
      "2021-08-25 15:24:44.808 | INFO     | src.policies:train:103 - Epoch 249 / 4000\n",
      "2021-08-25 15:24:44.809 | INFO     | src.policies:train:110 - Episode 249\n",
      "2021-08-25 15:25:12.960 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:25:12.989 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 188.27272727272728, 'equality': 0.9182652210193085, 'sustainability': 494.88622276902765, 'peace': 657.4545454545455}\n",
      "2021-08-25 15:25:12.990 | INFO     | src.policies:train:122 - Mean episode return: 188.27272727272728\n",
      "2021-08-25 15:25:12.991 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.70999999999995\n",
      "2021-08-25 15:25:12.992 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:25:23.953 | INFO     | src.policies:train:159 - Total loss: 1.0035948753356934\n",
      "2021-08-25 15:25:23.954 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 188.27272727272728, 'equality': 0.9182652210193085, 'sustainability': 494.88622276902765, 'peace': 657.4545454545455}\n",
      "2021-08-25 15:25:24.011 | INFO     | src.policies:train:103 - Epoch 250 / 4000\n",
      "2021-08-25 15:25:24.011 | INFO     | src.policies:train:110 - Episode 250\n",
      "2021-08-25 15:25:51.004 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:25:51.031 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 200.45454545454547, 'equality': 0.9322201607929866, 'sustainability': 504.37372627946894, 'peace': 742.7272727272727}\n",
      "2021-08-25 15:25:51.032 | INFO     | src.policies:train:122 - Mean episode return: 200.45454545454547\n",
      "2021-08-25 15:25:51.032 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.62454545454545\n",
      "2021-08-25 15:25:51.033 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:26:01.294 | INFO     | src.policies:train:159 - Total loss: 1.0023441314697266\n",
      "2021-08-25 15:26:01.294 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 200.45454545454547, 'equality': 0.9322201607929866, 'sustainability': 504.37372627946894, 'peace': 742.7272727272727}\n",
      "2021-08-25 15:26:01.350 | INFO     | src.policies:train:103 - Epoch 251 / 4000\n",
      "2021-08-25 15:26:01.351 | INFO     | src.policies:train:110 - Episode 251\n",
      "2021-08-25 15:26:27.475 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:26:27.505 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 197.8181818181818, 'equality': 0.9708389037439247, 'sustainability': 500.5596541761704, 'peace': 705.7272727272727}\n",
      "2021-08-25 15:26:27.506 | INFO     | src.policies:train:122 - Mean episode return: 197.8181818181818\n",
      "2021-08-25 15:26:27.507 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.48636363636356\n",
      "2021-08-25 15:26:27.507 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:26:38.941 | INFO     | src.policies:train:159 - Total loss: 0.9937655329704285\n",
      "2021-08-25 15:26:38.942 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 197.8181818181818, 'equality': 0.9708389037439247, 'sustainability': 500.5596541761704, 'peace': 705.7272727272727}\n",
      "2021-08-25 15:26:39.003 | INFO     | src.policies:train:103 - Epoch 252 / 4000\n",
      "2021-08-25 15:26:39.004 | INFO     | src.policies:train:110 - Episode 252\n",
      "2021-08-25 15:27:08.015 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:27:08.043 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 190.27272727272728, 'equality': 0.9078312991376486, 'sustainability': 473.3094662338833, 'peace': 659.0}\n",
      "2021-08-25 15:27:08.044 | INFO     | src.policies:train:122 - Mean episode return: 190.27272727272728\n",
      "2021-08-25 15:27:08.045 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.3445454545454\n",
      "2021-08-25 15:27:08.045 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:27:18.949 | INFO     | src.policies:train:159 - Total loss: 0.9997878074645996\n",
      "2021-08-25 15:27:18.950 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 190.27272727272728, 'equality': 0.9078312991376486, 'sustainability': 473.3094662338833, 'peace': 659.0}\n",
      "2021-08-25 15:27:19.003 | INFO     | src.policies:train:103 - Epoch 253 / 4000\n",
      "2021-08-25 15:27:19.004 | INFO     | src.policies:train:110 - Episode 253\n",
      "2021-08-25 15:27:43.534 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 15:27:43.557 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 200.54545454545453, 'equality': 0.8660677491167463, 'sustainability': 453.40920089074785, 'peace': 674.4545454545455}\n",
      "2021-08-25 15:27:43.558 | INFO     | src.policies:train:122 - Mean episode return: 200.54545454545453\n",
      "2021-08-25 15:27:43.559 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.21545454545452\n",
      "2021-08-25 15:27:43.559 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:27:53.142 | INFO     | src.policies:train:159 - Total loss: 1.0043574571609497\n",
      "2021-08-25 15:27:53.143 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 200.54545454545453, 'equality': 0.8660677491167463, 'sustainability': 453.40920089074785, 'peace': 674.4545454545455}\n",
      "2021-08-25 15:27:53.194 | INFO     | src.policies:train:103 - Epoch 254 / 4000\n",
      "2021-08-25 15:27:53.195 | INFO     | src.policies:train:110 - Episode 254\n",
      "2021-08-25 15:28:18.215 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:28:18.241 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 211.63636363636363, 'equality': 0.9143236488614042, 'sustainability': 487.7253509979884, 'peace': 651.8181818181819}\n",
      "2021-08-25 15:28:18.242 | INFO     | src.policies:train:122 - Mean episode return: 211.63636363636363\n",
      "2021-08-25 15:28:18.243 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.26454545454544\n",
      "2021-08-25 15:28:18.243 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:28:28.586 | INFO     | src.policies:train:159 - Total loss: 1.000618815422058\n",
      "2021-08-25 15:28:28.587 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 211.63636363636363, 'equality': 0.9143236488614042, 'sustainability': 487.7253509979884, 'peace': 651.8181818181819}\n",
      "2021-08-25 15:28:28.644 | INFO     | src.policies:train:103 - Epoch 255 / 4000\n",
      "2021-08-25 15:28:28.645 | INFO     | src.policies:train:110 - Episode 255\n",
      "2021-08-25 15:28:55.947 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:28:55.974 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 203.8181818181818, 'equality': 0.9134701159696401, 'sustainability': 463.2967936369624, 'peace': 672.3636363636364}\n",
      "2021-08-25 15:28:55.975 | INFO     | src.policies:train:122 - Mean episode return: 203.8181818181818\n",
      "2021-08-25 15:28:55.976 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.36181818181817\n",
      "2021-08-25 15:28:55.976 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:29:06.967 | INFO     | src.policies:train:159 - Total loss: 1.002200961112976\n",
      "2021-08-25 15:29:06.968 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 203.8181818181818, 'equality': 0.9134701159696401, 'sustainability': 463.2967936369624, 'peace': 672.3636363636364}\n",
      "2021-08-25 15:29:07.029 | INFO     | src.policies:train:103 - Epoch 256 / 4000\n",
      "2021-08-25 15:29:07.030 | INFO     | src.policies:train:110 - Episode 256\n",
      "2021-08-25 15:29:34.435 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:29:34.460 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 185.63636363636363, 'equality': 0.8464072656075503, 'sustainability': 484.2872094186027, 'peace': 637.2727272727273}\n",
      "2021-08-25 15:29:34.461 | INFO     | src.policies:train:122 - Mean episode return: 185.63636363636363\n",
      "2021-08-25 15:29:34.462 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.27000000000004\n",
      "2021-08-25 15:29:34.462 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:29:45.386 | INFO     | src.policies:train:159 - Total loss: 1.0016024112701416\n",
      "2021-08-25 15:29:45.387 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 185.63636363636363, 'equality': 0.8464072656075503, 'sustainability': 484.2872094186027, 'peace': 637.2727272727273}\n",
      "2021-08-25 15:29:45.444 | INFO     | src.policies:train:103 - Epoch 257 / 4000\n",
      "2021-08-25 15:29:45.445 | INFO     | src.policies:train:110 - Episode 257\n",
      "2021-08-25 15:30:11.138 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:30:11.164 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 218.72727272727272, 'equality': 0.9246580518415201, 'sustainability': 490.52622934429274, 'peace': 687.3636363636364}\n",
      "2021-08-25 15:30:11.165 | INFO     | src.policies:train:122 - Mean episode return: 218.72727272727272\n",
      "2021-08-25 15:30:11.165 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.38363636363636\n",
      "2021-08-25 15:30:11.166 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:30:21.295 | INFO     | src.policies:train:159 - Total loss: 1.0052869319915771\n",
      "2021-08-25 15:30:21.296 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 218.72727272727272, 'equality': 0.9246580518415201, 'sustainability': 490.52622934429274, 'peace': 687.3636363636364}\n",
      "2021-08-25 15:30:21.351 | INFO     | src.policies:train:103 - Epoch 258 / 4000\n",
      "2021-08-25 15:30:21.351 | INFO     | src.policies:train:110 - Episode 258\n",
      "2021-08-25 15:30:46.157 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:30:46.182 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 217.72727272727272, 'equality': 0.9552097172147427, 'sustainability': 482.31173323362896, 'peace': 711.6363636363636}\n",
      "2021-08-25 15:30:46.183 | INFO     | src.policies:train:122 - Mean episode return: 217.72727272727272\n",
      "2021-08-25 15:30:46.184 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.4454545454545\n",
      "2021-08-25 15:30:46.184 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:30:56.087 | INFO     | src.policies:train:159 - Total loss: 1.0032646656036377\n",
      "2021-08-25 15:30:56.088 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 217.72727272727272, 'equality': 0.9552097172147427, 'sustainability': 482.31173323362896, 'peace': 711.6363636363636}\n",
      "2021-08-25 15:30:56.141 | INFO     | src.policies:train:103 - Epoch 259 / 4000\n",
      "2021-08-25 15:30:56.142 | INFO     | src.policies:train:110 - Episode 259\n",
      "2021-08-25 15:31:20.345 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:31:20.370 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 199.1818181818182, 'equality': 0.9376789344853392, 'sustainability': 478.8300598225542, 'peace': 627.2727272727273}\n",
      "2021-08-25 15:31:20.371 | INFO     | src.policies:train:122 - Mean episode return: 199.1818181818182\n",
      "2021-08-25 15:31:20.371 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.23454545454544\n",
      "2021-08-25 15:31:20.372 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:31:30.307 | INFO     | src.policies:train:159 - Total loss: 0.9972081780433655\n",
      "2021-08-25 15:31:30.308 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 199.1818181818182, 'equality': 0.9376789344853392, 'sustainability': 478.8300598225542, 'peace': 627.2727272727273}\n",
      "2021-08-25 15:31:30.360 | INFO     | src.policies:train:103 - Epoch 260 / 4000\n",
      "2021-08-25 15:31:30.361 | INFO     | src.policies:train:110 - Episode 260\n",
      "2021-08-25 15:31:55.948 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:31:55.976 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 210.8181818181818, 'equality': 0.9489591908748097, 'sustainability': 476.81395197122634, 'peace': 718.4545454545455}\n",
      "2021-08-25 15:31:55.977 | INFO     | src.policies:train:122 - Mean episode return: 210.8181818181818\n",
      "2021-08-25 15:31:55.978 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.14363636363635\n",
      "2021-08-25 15:31:55.978 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:32:06.224 | INFO     | src.policies:train:159 - Total loss: 1.0037248134613037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 15:32:06.225 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 210.8181818181818, 'equality': 0.9489591908748097, 'sustainability': 476.81395197122634, 'peace': 718.4545454545455}\n",
      "2021-08-25 15:32:06.281 | INFO     | src.policies:train:103 - Epoch 261 / 4000\n",
      "2021-08-25 15:32:06.282 | INFO     | src.policies:train:110 - Episode 261\n",
      "2021-08-25 15:32:32.559 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:32:32.587 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 210.45454545454547, 'equality': 0.9255448655031309, 'sustainability': 500.97081130162223, 'peace': 706.5454545454545}\n",
      "2021-08-25 15:32:32.588 | INFO     | src.policies:train:122 - Mean episode return: 210.45454545454547\n",
      "2021-08-25 15:32:32.588 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.2663636363636\n",
      "2021-08-25 15:32:32.589 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:32:42.853 | INFO     | src.policies:train:159 - Total loss: 0.9965837597846985\n",
      "2021-08-25 15:32:42.854 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 210.45454545454547, 'equality': 0.9255448655031309, 'sustainability': 500.97081130162223, 'peace': 706.5454545454545}\n",
      "2021-08-25 15:32:42.909 | INFO     | src.policies:train:103 - Epoch 262 / 4000\n",
      "2021-08-25 15:32:42.910 | INFO     | src.policies:train:110 - Episode 262\n",
      "2021-08-25 15:33:08.079 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:33:08.106 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 209.36363636363637, 'equality': 0.940472900960398, 'sustainability': 491.3846383522035, 'peace': 705.5454545454545}\n",
      "2021-08-25 15:33:08.107 | INFO     | src.policies:train:122 - Mean episode return: 209.36363636363637\n",
      "2021-08-25 15:33:08.107 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.13909090909092\n",
      "2021-08-25 15:33:08.108 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:33:18.354 | INFO     | src.policies:train:159 - Total loss: 1.0042705535888672\n",
      "2021-08-25 15:33:18.355 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 209.36363636363637, 'equality': 0.940472900960398, 'sustainability': 491.3846383522035, 'peace': 705.5454545454545}\n",
      "2021-08-25 15:33:18.410 | INFO     | src.policies:train:103 - Epoch 263 / 4000\n",
      "2021-08-25 15:33:18.411 | INFO     | src.policies:train:110 - Episode 263\n",
      "2021-08-25 15:33:43.851 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:33:43.877 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 196.0, 'equality': 0.8964412211187291, 'sustainability': 460.01144757372043, 'peace': 621.5454545454545}\n",
      "2021-08-25 15:33:43.878 | INFO     | src.policies:train:122 - Mean episode return: 196.0\n",
      "2021-08-25 15:33:43.879 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.16545454545448\n",
      "2021-08-25 15:33:43.879 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:33:54.099 | INFO     | src.policies:train:159 - Total loss: 1.000391960144043\n",
      "2021-08-25 15:33:54.100 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 196.0, 'equality': 0.8964412211187291, 'sustainability': 460.01144757372043, 'peace': 621.5454545454545}\n",
      "2021-08-25 15:33:54.153 | INFO     | src.policies:train:103 - Epoch 264 / 4000\n",
      "2021-08-25 15:33:54.154 | INFO     | src.policies:train:110 - Episode 264\n",
      "2021-08-25 15:34:19.713 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:34:19.741 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 214.9090909090909, 'equality': 0.9589293954784085, 'sustainability': 480.5328302495225, 'peace': 674.8181818181819}\n",
      "2021-08-25 15:34:19.741 | INFO     | src.policies:train:122 - Mean episode return: 214.9090909090909\n",
      "2021-08-25 15:34:19.742 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.24545454545455\n",
      "2021-08-25 15:34:19.743 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:34:29.959 | INFO     | src.policies:train:159 - Total loss: 0.9982218146324158\n",
      "2021-08-25 15:34:29.960 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 214.9090909090909, 'equality': 0.9589293954784085, 'sustainability': 480.5328302495225, 'peace': 674.8181818181819}\n",
      "2021-08-25 15:34:30.014 | INFO     | src.policies:train:103 - Epoch 265 / 4000\n",
      "2021-08-25 15:34:30.015 | INFO     | src.policies:train:110 - Episode 265\n",
      "2021-08-25 15:34:54.803 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:34:54.829 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 209.63636363636363, 'equality': 0.9248600488858145, 'sustainability': 501.03320888833235, 'peace': 752.5454545454545}\n",
      "2021-08-25 15:34:54.830 | INFO     | src.policies:train:122 - Mean episode return: 209.63636363636363\n",
      "2021-08-25 15:34:54.830 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.2281818181818\n",
      "2021-08-25 15:34:54.831 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:35:04.415 | INFO     | src.policies:train:159 - Total loss: 1.0007829666137695\n",
      "2021-08-25 15:35:04.416 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 209.63636363636363, 'equality': 0.9248600488858145, 'sustainability': 501.03320888833235, 'peace': 752.5454545454545}\n",
      "2021-08-25 15:35:04.466 | INFO     | src.policies:train:103 - Epoch 266 / 4000\n",
      "2021-08-25 15:35:04.467 | INFO     | src.policies:train:110 - Episode 266\n",
      "2021-08-25 15:35:28.056 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:35:28.082 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 209.54545454545453, 'equality': 0.9106290672468818, 'sustainability': 468.1799549386955, 'peace': 721.3636363636364}\n",
      "2021-08-25 15:35:28.083 | INFO     | src.policies:train:122 - Mean episode return: 209.54545454545453\n",
      "2021-08-25 15:35:28.084 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.34909090909096\n",
      "2021-08-25 15:35:28.084 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:35:38.063 | INFO     | src.policies:train:159 - Total loss: 1.002334475517273\n",
      "2021-08-25 15:35:38.064 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 209.54545454545453, 'equality': 0.9106290672468818, 'sustainability': 468.1799549386955, 'peace': 721.3636363636364}\n",
      "2021-08-25 15:35:38.118 | INFO     | src.policies:train:103 - Epoch 267 / 4000\n",
      "2021-08-25 15:35:38.119 | INFO     | src.policies:train:110 - Episode 267\n",
      "2021-08-25 15:36:03.540 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:36:03.567 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 202.72727272727272, 'equality': 0.9077863840214475, 'sustainability': 494.45061770199186, 'peace': 759.8181818181819}\n",
      "2021-08-25 15:36:03.567 | INFO     | src.policies:train:122 - Mean episode return: 202.72727272727272\n",
      "2021-08-25 15:36:03.568 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.2672727272727\n",
      "2021-08-25 15:36:03.569 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:36:13.839 | INFO     | src.policies:train:159 - Total loss: 0.9998325109481812\n",
      "2021-08-25 15:36:13.839 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 202.72727272727272, 'equality': 0.9077863840214475, 'sustainability': 494.45061770199186, 'peace': 759.8181818181819}\n",
      "2021-08-25 15:36:13.893 | INFO     | src.policies:train:103 - Epoch 268 / 4000\n",
      "2021-08-25 15:36:13.894 | INFO     | src.policies:train:110 - Episode 268\n",
      "2021-08-25 15:36:38.468 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:36:38.493 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 184.8181818181818, 'equality': 0.9001028484572708, 'sustainability': 470.2970257137829, 'peace': 631.8181818181819}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 15:36:38.493 | INFO     | src.policies:train:122 - Mean episode return: 184.8181818181818\n",
      "2021-08-25 15:36:38.494 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.05181818181816\n",
      "2021-08-25 15:36:38.494 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:36:48.041 | INFO     | src.policies:train:159 - Total loss: 0.9994921684265137\n",
      "2021-08-25 15:36:48.042 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 184.8181818181818, 'equality': 0.9001028484572708, 'sustainability': 470.2970257137829, 'peace': 631.8181818181819}\n",
      "2021-08-25 15:36:48.091 | INFO     | src.policies:train:103 - Epoch 269 / 4000\n",
      "2021-08-25 15:36:48.091 | INFO     | src.policies:train:110 - Episode 269\n",
      "2021-08-25 15:37:11.673 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:37:11.698 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 226.1818181818182, 'equality': 0.9394182987441644, 'sustainability': 498.86067704833874, 'peace': 667.4545454545455}\n",
      "2021-08-25 15:37:11.699 | INFO     | src.policies:train:122 - Mean episode return: 226.1818181818182\n",
      "2021-08-25 15:37:11.699 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.16818181818184\n",
      "2021-08-25 15:37:11.700 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:37:21.047 | INFO     | src.policies:train:159 - Total loss: 0.996786892414093\n",
      "2021-08-25 15:37:21.048 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 226.1818181818182, 'equality': 0.9394182987441644, 'sustainability': 498.86067704833874, 'peace': 667.4545454545455}\n",
      "2021-08-25 15:37:21.098 | INFO     | src.policies:train:103 - Epoch 270 / 4000\n",
      "2021-08-25 15:37:21.099 | INFO     | src.policies:train:110 - Episode 270\n",
      "2021-08-25 15:37:44.734 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:37:44.761 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 208.8181818181818, 'equality': 0.936280524004902, 'sustainability': 476.01761582034413, 'peace': 742.3636363636364}\n",
      "2021-08-25 15:37:44.761 | INFO     | src.policies:train:122 - Mean episode return: 208.8181818181818\n",
      "2021-08-25 15:37:44.762 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.27545454545452\n",
      "2021-08-25 15:37:44.762 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:37:54.699 | INFO     | src.policies:train:159 - Total loss: 0.9963064193725586\n",
      "2021-08-25 15:37:54.700 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 208.8181818181818, 'equality': 0.936280524004902, 'sustainability': 476.01761582034413, 'peace': 742.3636363636364}\n",
      "2021-08-25 15:37:54.752 | INFO     | src.policies:train:103 - Epoch 271 / 4000\n",
      "2021-08-25 15:37:54.753 | INFO     | src.policies:train:110 - Episode 271\n",
      "2021-08-25 15:38:19.300 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:38:19.322 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 217.54545454545453, 'equality': 0.9424837594510033, 'sustainability': 500.9980591126898, 'peace': 746.8181818181819}\n",
      "2021-08-25 15:38:19.322 | INFO     | src.policies:train:122 - Mean episode return: 217.54545454545453\n",
      "2021-08-25 15:38:19.323 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.32090909090908\n",
      "2021-08-25 15:38:19.323 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:38:29.266 | INFO     | src.policies:train:159 - Total loss: 0.9980345964431763\n",
      "2021-08-25 15:38:29.267 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 217.54545454545453, 'equality': 0.9424837594510033, 'sustainability': 500.9980591126898, 'peace': 746.8181818181819}\n",
      "2021-08-25 15:38:29.321 | INFO     | src.policies:train:103 - Epoch 272 / 4000\n",
      "2021-08-25 15:38:29.322 | INFO     | src.policies:train:110 - Episode 272\n",
      "2021-08-25 15:38:53.345 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:38:53.370 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 195.45454545454547, 'equality': 0.9319238900648642, 'sustainability': 481.216113781686, 'peace': 638.2727272727273}\n",
      "2021-08-25 15:38:53.371 | INFO     | src.policies:train:122 - Mean episode return: 195.45454545454547\n",
      "2021-08-25 15:38:53.371 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.2563636363636\n",
      "2021-08-25 15:38:53.372 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:39:02.696 | INFO     | src.policies:train:159 - Total loss: 1.0009121894836426\n",
      "2021-08-25 15:39:02.697 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 195.45454545454547, 'equality': 0.9319238900648642, 'sustainability': 481.216113781686, 'peace': 638.2727272727273}\n",
      "2021-08-25 15:39:02.748 | INFO     | src.policies:train:103 - Epoch 273 / 4000\n",
      "2021-08-25 15:39:02.749 | INFO     | src.policies:train:110 - Episode 273\n",
      "2021-08-25 15:39:26.194 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:39:26.219 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 205.72727272727272, 'equality': 0.8899288956756934, 'sustainability': 488.8624814118866, 'peace': 702.8181818181819}\n",
      "2021-08-25 15:39:26.220 | INFO     | src.policies:train:122 - Mean episode return: 205.72727272727272\n",
      "2021-08-25 15:39:26.220 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.28363636363636\n",
      "2021-08-25 15:39:26.221 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:39:35.577 | INFO     | src.policies:train:159 - Total loss: 1.0030964612960815\n",
      "2021-08-25 15:39:35.578 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 205.72727272727272, 'equality': 0.8899288956756934, 'sustainability': 488.8624814118866, 'peace': 702.8181818181819}\n",
      "2021-08-25 15:39:35.628 | INFO     | src.policies:train:103 - Epoch 274 / 4000\n",
      "2021-08-25 15:39:35.628 | INFO     | src.policies:train:110 - Episode 274\n",
      "2021-08-25 15:39:58.755 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:39:58.778 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 208.72727272727272, 'equality': 0.9038644282565754, 'sustainability': 498.56096686935786, 'peace': 785.1818181818181}\n",
      "2021-08-25 15:39:58.779 | INFO     | src.policies:train:122 - Mean episode return: 208.72727272727272\n",
      "2021-08-25 15:39:58.779 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.19454545454545\n",
      "2021-08-25 15:39:58.780 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:40:08.143 | INFO     | src.policies:train:159 - Total loss: 0.9941250085830688\n",
      "2021-08-25 15:40:08.144 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 208.72727272727272, 'equality': 0.9038644282565754, 'sustainability': 498.56096686935786, 'peace': 785.1818181818181}\n",
      "2021-08-25 15:40:08.195 | INFO     | src.policies:train:103 - Epoch 275 / 4000\n",
      "2021-08-25 15:40:08.195 | INFO     | src.policies:train:110 - Episode 275\n",
      "2021-08-25 15:40:31.585 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:40:31.613 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 192.54545454545453, 'equality': 0.9222250836998407, 'sustainability': 455.58221950188874, 'peace': 723.1818181818181}\n",
      "2021-08-25 15:40:31.614 | INFO     | src.policies:train:122 - Mean episode return: 192.54545454545453\n",
      "2021-08-25 15:40:31.614 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.2972727272727\n",
      "2021-08-25 15:40:31.615 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:40:41.030 | INFO     | src.policies:train:159 - Total loss: 1.0004887580871582\n",
      "2021-08-25 15:40:41.031 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 192.54545454545453, 'equality': 0.9222250836998407, 'sustainability': 455.58221950188874, 'peace': 723.1818181818181}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 15:40:41.083 | INFO     | src.policies:train:103 - Epoch 276 / 4000\n",
      "2021-08-25 15:40:41.083 | INFO     | src.policies:train:110 - Episode 276\n",
      "2021-08-25 15:41:05.777 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:41:05.801 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 200.36363636363637, 'equality': 0.9276522026083226, 'sustainability': 485.40339366649965, 'peace': 723.0909090909091}\n",
      "2021-08-25 15:41:05.802 | INFO     | src.policies:train:122 - Mean episode return: 200.36363636363637\n",
      "2021-08-25 15:41:05.803 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.31181818181815\n",
      "2021-08-25 15:41:05.803 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:41:15.705 | INFO     | src.policies:train:159 - Total loss: 1.0018130540847778\n",
      "2021-08-25 15:41:15.706 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 200.36363636363637, 'equality': 0.9276522026083226, 'sustainability': 485.40339366649965, 'peace': 723.0909090909091}\n",
      "2021-08-25 15:41:15.760 | INFO     | src.policies:train:103 - Epoch 277 / 4000\n",
      "2021-08-25 15:41:15.761 | INFO     | src.policies:train:110 - Episode 277\n",
      "2021-08-25 15:41:39.687 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:41:39.712 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 192.1818181818182, 'equality': 0.9065967145457428, 'sustainability': 481.1399518239579, 'peace': 636.6363636363636}\n",
      "2021-08-25 15:41:39.712 | INFO     | src.policies:train:122 - Mean episode return: 192.1818181818182\n",
      "2021-08-25 15:41:39.713 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.1518181818182\n",
      "2021-08-25 15:41:39.714 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:41:49.646 | INFO     | src.policies:train:159 - Total loss: 0.9963142275810242\n",
      "2021-08-25 15:41:49.647 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 192.1818181818182, 'equality': 0.9065967145457428, 'sustainability': 481.1399518239579, 'peace': 636.6363636363636}\n",
      "2021-08-25 15:41:49.699 | INFO     | src.policies:train:103 - Epoch 278 / 4000\n",
      "2021-08-25 15:41:49.700 | INFO     | src.policies:train:110 - Episode 278\n",
      "2021-08-25 15:42:14.013 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:42:14.039 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 216.8181818181818, 'equality': 0.9456451305518269, 'sustainability': 508.2673926685078, 'peace': 803.6363636363636}\n",
      "2021-08-25 15:42:14.040 | INFO     | src.policies:train:122 - Mean episode return: 216.8181818181818\n",
      "2021-08-25 15:42:14.040 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.2490909090909\n",
      "2021-08-25 15:42:14.041 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:42:23.518 | INFO     | src.policies:train:159 - Total loss: 1.00510835647583\n",
      "2021-08-25 15:42:23.519 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 216.8181818181818, 'equality': 0.9456451305518269, 'sustainability': 508.2673926685078, 'peace': 803.6363636363636}\n",
      "2021-08-25 15:42:23.568 | INFO     | src.policies:train:103 - Epoch 279 / 4000\n",
      "2021-08-25 15:42:23.569 | INFO     | src.policies:train:110 - Episode 279\n",
      "2021-08-25 15:42:46.053 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:42:46.079 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 175.45454545454547, 'equality': 0.8806406029232068, 'sustainability': 470.95534285784146, 'peace': 629.6363636363636}\n",
      "2021-08-25 15:42:46.079 | INFO     | src.policies:train:122 - Mean episode return: 175.45454545454547\n",
      "2021-08-25 15:42:46.080 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.96999999999997\n",
      "2021-08-25 15:42:46.080 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:42:55.419 | INFO     | src.policies:train:159 - Total loss: 0.9960282444953918\n",
      "2021-08-25 15:42:55.420 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 175.45454545454547, 'equality': 0.8806406029232068, 'sustainability': 470.95534285784146, 'peace': 629.6363636363636}\n",
      "2021-08-25 15:42:55.469 | INFO     | src.policies:train:103 - Epoch 280 / 4000\n",
      "2021-08-25 15:42:55.469 | INFO     | src.policies:train:110 - Episode 280\n",
      "2021-08-25 15:43:19.321 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:43:19.347 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 215.0, 'equality': 0.940418989045927, 'sustainability': 494.2645375199641, 'peace': 751.1818181818181}\n",
      "2021-08-25 15:43:19.348 | INFO     | src.policies:train:122 - Mean episode return: 215.0\n",
      "2021-08-25 15:43:19.348 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.03181818181815\n",
      "2021-08-25 15:43:19.349 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:43:28.708 | INFO     | src.policies:train:159 - Total loss: 1.0042186975479126\n",
      "2021-08-25 15:43:28.709 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 215.0, 'equality': 0.940418989045927, 'sustainability': 494.2645375199641, 'peace': 751.1818181818181}\n",
      "2021-08-25 15:43:28.761 | INFO     | src.policies:train:103 - Epoch 281 / 4000\n",
      "2021-08-25 15:43:28.762 | INFO     | src.policies:train:110 - Episode 281\n",
      "2021-08-25 15:43:51.228 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:43:51.252 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 191.1818181818182, 'equality': 0.8978947823477739, 'sustainability': 474.54892373731803, 'peace': 704.5454545454545}\n",
      "2021-08-25 15:43:51.253 | INFO     | src.policies:train:122 - Mean episode return: 191.1818181818182\n",
      "2021-08-25 15:43:51.253 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.9572727272727\n",
      "2021-08-25 15:43:51.254 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:44:00.615 | INFO     | src.policies:train:159 - Total loss: 1.0068284273147583\n",
      "2021-08-25 15:44:00.615 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 191.1818181818182, 'equality': 0.8978947823477739, 'sustainability': 474.54892373731803, 'peace': 704.5454545454545}\n",
      "2021-08-25 15:44:00.665 | INFO     | src.policies:train:103 - Epoch 282 / 4000\n",
      "2021-08-25 15:44:00.666 | INFO     | src.policies:train:110 - Episode 282\n",
      "2021-08-25 15:44:24.402 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:44:24.428 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 193.72727272727272, 'equality': 0.9239793524183273, 'sustainability': 501.1221588674525, 'peace': 669.7272727272727}\n",
      "2021-08-25 15:44:24.429 | INFO     | src.policies:train:122 - Mean episode return: 193.72727272727272\n",
      "2021-08-25 15:44:24.429 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.82090909090908\n",
      "2021-08-25 15:44:24.430 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:44:34.060 | INFO     | src.policies:train:159 - Total loss: 1.0029830932617188\n",
      "2021-08-25 15:44:34.061 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 193.72727272727272, 'equality': 0.9239793524183273, 'sustainability': 501.1221588674525, 'peace': 669.7272727272727}\n",
      "2021-08-25 15:44:34.112 | INFO     | src.policies:train:103 - Epoch 283 / 4000\n",
      "2021-08-25 15:44:34.113 | INFO     | src.policies:train:110 - Episode 283\n",
      "2021-08-25 15:44:57.368 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:44:57.394 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 203.63636363636363, 'equality': 0.9086850649369179, 'sustainability': 476.89596476138826, 'peace': 603.0909090909091}\n",
      "2021-08-25 15:44:57.395 | INFO     | src.policies:train:122 - Mean episode return: 203.63636363636363\n",
      "2021-08-25 15:44:57.395 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 15:44:57.396 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:45:07.019 | INFO     | src.policies:train:159 - Total loss: 1.0008656978607178\n",
      "2021-08-25 15:45:07.019 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 203.63636363636363, 'equality': 0.9086850649369179, 'sustainability': 476.89596476138826, 'peace': 603.0909090909091}\n",
      "2021-08-25 15:45:07.070 | INFO     | src.policies:train:103 - Epoch 284 / 4000\n",
      "2021-08-25 15:45:07.070 | INFO     | src.policies:train:110 - Episode 284\n",
      "2021-08-25 15:45:31.360 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:45:31.383 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 217.63636363636363, 'equality': 0.9691653375869757, 'sustainability': 503.6884296178568, 'peace': 747.7272727272727}\n",
      "2021-08-25 15:45:31.384 | INFO     | src.policies:train:122 - Mean episode return: 217.63636363636363\n",
      "2021-08-25 15:45:31.385 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.85454545454547\n",
      "2021-08-25 15:45:31.385 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:45:40.672 | INFO     | src.policies:train:159 - Total loss: 0.9986860752105713\n",
      "2021-08-25 15:45:40.673 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 217.63636363636363, 'equality': 0.9691653375869757, 'sustainability': 503.6884296178568, 'peace': 747.7272727272727}\n",
      "2021-08-25 15:45:40.723 | INFO     | src.policies:train:103 - Epoch 285 / 4000\n",
      "2021-08-25 15:45:40.724 | INFO     | src.policies:train:110 - Episode 285\n",
      "2021-08-25 15:46:04.302 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:46:04.327 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 219.0, 'equality': 0.9226385901369365, 'sustainability': 488.32763976837305, 'peace': 736.3636363636364}\n",
      "2021-08-25 15:46:04.328 | INFO     | src.policies:train:122 - Mean episode return: 219.0\n",
      "2021-08-25 15:46:04.329 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.9681818181818\n",
      "2021-08-25 15:46:04.329 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:46:13.654 | INFO     | src.policies:train:159 - Total loss: 0.9996278882026672\n",
      "2021-08-25 15:46:13.655 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 219.0, 'equality': 0.9226385901369365, 'sustainability': 488.32763976837305, 'peace': 736.3636363636364}\n",
      "2021-08-25 15:46:13.704 | INFO     | src.policies:train:103 - Epoch 286 / 4000\n",
      "2021-08-25 15:46:13.705 | INFO     | src.policies:train:110 - Episode 286\n",
      "2021-08-25 15:46:37.457 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:46:37.482 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 214.54545454545453, 'equality': 0.9324345146392058, 'sustainability': 467.8375311598458, 'peace': 705.9090909090909}\n",
      "2021-08-25 15:46:37.483 | INFO     | src.policies:train:122 - Mean episode return: 214.54545454545453\n",
      "2021-08-25 15:46:37.483 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.06636363636363\n",
      "2021-08-25 15:46:37.484 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:46:46.815 | INFO     | src.policies:train:159 - Total loss: 1.006248116493225\n",
      "2021-08-25 15:46:46.816 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 214.54545454545453, 'equality': 0.9324345146392058, 'sustainability': 467.8375311598458, 'peace': 705.9090909090909}\n",
      "2021-08-25 15:46:46.865 | INFO     | src.policies:train:103 - Epoch 287 / 4000\n",
      "2021-08-25 15:46:46.866 | INFO     | src.policies:train:110 - Episode 287\n",
      "2021-08-25 15:47:10.145 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:47:10.171 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 210.9090909090909, 'equality': 0.9170846395000571, 'sustainability': 464.8262261897834, 'peace': 721.0909090909091}\n",
      "2021-08-25 15:47:10.171 | INFO     | src.policies:train:122 - Mean episode return: 210.9090909090909\n",
      "2021-08-25 15:47:10.172 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.00909090909093\n",
      "2021-08-25 15:47:10.172 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:47:19.763 | INFO     | src.policies:train:159 - Total loss: 1.0019973516464233\n",
      "2021-08-25 15:47:19.764 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 210.9090909090909, 'equality': 0.9170846395000571, 'sustainability': 464.8262261897834, 'peace': 721.0909090909091}\n",
      "2021-08-25 15:47:19.816 | INFO     | src.policies:train:103 - Epoch 288 / 4000\n",
      "2021-08-25 15:47:19.816 | INFO     | src.policies:train:110 - Episode 288\n",
      "2021-08-25 15:47:44.185 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:47:44.208 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 212.8181818181818, 'equality': 0.9225661139388264, 'sustainability': 485.1271978824964, 'peace': 781.2727272727273}\n",
      "2021-08-25 15:47:44.209 | INFO     | src.policies:train:122 - Mean episode return: 212.8181818181818\n",
      "2021-08-25 15:47:44.209 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.10727272727271\n",
      "2021-08-25 15:47:44.210 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:47:53.840 | INFO     | src.policies:train:159 - Total loss: 0.9989444017410278\n",
      "2021-08-25 15:47:53.841 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 212.8181818181818, 'equality': 0.9225661139388264, 'sustainability': 485.1271978824964, 'peace': 781.2727272727273}\n",
      "2021-08-25 15:47:53.892 | INFO     | src.policies:train:103 - Epoch 289 / 4000\n",
      "2021-08-25 15:47:53.892 | INFO     | src.policies:train:110 - Episode 289\n",
      "2021-08-25 15:48:17.811 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:48:17.836 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 191.36363636363637, 'equality': 0.8847765061566665, 'sustainability': 479.49404426676324, 'peace': 665.0909090909091}\n",
      "2021-08-25 15:48:17.837 | INFO     | src.policies:train:122 - Mean episode return: 191.36363636363637\n",
      "2021-08-25 15:48:17.838 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.0318181818182\n",
      "2021-08-25 15:48:17.838 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:48:27.487 | INFO     | src.policies:train:159 - Total loss: 0.997656524181366\n",
      "2021-08-25 15:48:27.488 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 191.36363636363637, 'equality': 0.8847765061566665, 'sustainability': 479.49404426676324, 'peace': 665.0909090909091}\n",
      "2021-08-25 15:48:27.540 | INFO     | src.policies:train:103 - Epoch 290 / 4000\n",
      "2021-08-25 15:48:27.541 | INFO     | src.policies:train:110 - Episode 290\n",
      "2021-08-25 15:48:52.147 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:48:52.174 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 222.0, 'equality': 0.9385004839561741, 'sustainability': 506.26233877957236, 'peace': 731.6363636363636}\n",
      "2021-08-25 15:48:52.175 | INFO     | src.policies:train:122 - Mean episode return: 222.0\n",
      "2021-08-25 15:48:52.176 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.2390909090909\n",
      "2021-08-25 15:48:52.176 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:49:02.075 | INFO     | src.policies:train:159 - Total loss: 1.0006707906723022\n",
      "2021-08-25 15:49:02.076 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 222.0, 'equality': 0.9385004839561741, 'sustainability': 506.26233877957236, 'peace': 731.6363636363636}\n",
      "2021-08-25 15:49:02.131 | INFO     | src.policies:train:103 - Epoch 291 / 4000\n",
      "2021-08-25 15:49:02.131 | INFO     | src.policies:train:110 - Episode 291\n",
      "2021-08-25 15:49:26.882 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 15:49:26.908 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 185.27272727272728, 'equality': 0.917477027390546, 'sustainability': 470.42485744614754, 'peace': 617.6363636363636}\n",
      "2021-08-25 15:49:26.909 | INFO     | src.policies:train:122 - Mean episode return: 185.27272727272728\n",
      "2021-08-25 15:49:26.909 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.8890909090909\n",
      "2021-08-25 15:49:26.910 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:49:36.524 | INFO     | src.policies:train:159 - Total loss: 0.9987404346466064\n",
      "2021-08-25 15:49:36.525 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 185.27272727272728, 'equality': 0.917477027390546, 'sustainability': 470.42485744614754, 'peace': 617.6363636363636}\n",
      "2021-08-25 15:49:36.576 | INFO     | src.policies:train:103 - Epoch 292 / 4000\n",
      "2021-08-25 15:49:36.576 | INFO     | src.policies:train:110 - Episode 292\n",
      "2021-08-25 15:49:59.945 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:49:59.969 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 207.54545454545453, 'equality': 0.9296778560918711, 'sustainability': 504.1258229330906, 'peace': 695.4545454545455}\n",
      "2021-08-25 15:49:59.970 | INFO     | src.policies:train:122 - Mean episode return: 207.54545454545453\n",
      "2021-08-25 15:49:59.970 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.7181818181818\n",
      "2021-08-25 15:49:59.971 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:50:09.303 | INFO     | src.policies:train:159 - Total loss: 0.9991708397865295\n",
      "2021-08-25 15:50:09.304 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 207.54545454545453, 'equality': 0.9296778560918711, 'sustainability': 504.1258229330906, 'peace': 695.4545454545455}\n",
      "2021-08-25 15:50:09.353 | INFO     | src.policies:train:103 - Epoch 293 / 4000\n",
      "2021-08-25 15:50:09.353 | INFO     | src.policies:train:110 - Episode 293\n",
      "2021-08-25 15:50:31.574 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:50:31.602 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 203.36363636363637, 'equality': 0.9217295891428917, 'sustainability': 496.3422764487913, 'peace': 748.8181818181819}\n",
      "2021-08-25 15:50:31.602 | INFO     | src.policies:train:122 - Mean episode return: 203.36363636363637\n",
      "2021-08-25 15:50:31.603 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.5654545454546\n",
      "2021-08-25 15:50:31.604 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:50:40.955 | INFO     | src.policies:train:159 - Total loss: 0.9989013671875\n",
      "2021-08-25 15:50:40.956 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 203.36363636363637, 'equality': 0.9217295891428917, 'sustainability': 496.3422764487913, 'peace': 748.8181818181819}\n",
      "2021-08-25 15:50:41.006 | INFO     | src.policies:train:103 - Epoch 294 / 4000\n",
      "2021-08-25 15:50:41.006 | INFO     | src.policies:train:110 - Episode 294\n",
      "2021-08-25 15:51:04.264 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:51:04.288 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 216.9090909090909, 'equality': 0.9269221976696083, 'sustainability': 500.27990029960796, 'peace': 781.3636363636364}\n",
      "2021-08-25 15:51:04.289 | INFO     | src.policies:train:122 - Mean episode return: 216.9090909090909\n",
      "2021-08-25 15:51:04.290 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.65\n",
      "2021-08-25 15:51:04.290 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:51:13.612 | INFO     | src.policies:train:159 - Total loss: 1.003367304801941\n",
      "2021-08-25 15:51:13.613 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 216.9090909090909, 'equality': 0.9269221976696083, 'sustainability': 500.27990029960796, 'peace': 781.3636363636364}\n",
      "2021-08-25 15:51:13.662 | INFO     | src.policies:train:103 - Epoch 295 / 4000\n",
      "2021-08-25 15:51:13.663 | INFO     | src.policies:train:110 - Episode 295\n",
      "2021-08-25 15:51:37.577 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:51:37.602 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 201.27272727272728, 'equality': 0.8920095261580847, 'sustainability': 482.09307604357895, 'peace': 765.3636363636364}\n",
      "2021-08-25 15:51:37.602 | INFO     | src.policies:train:122 - Mean episode return: 201.27272727272728\n",
      "2021-08-25 15:51:37.603 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.51727272727277\n",
      "2021-08-25 15:51:37.604 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:51:46.910 | INFO     | src.policies:train:159 - Total loss: 1.0056029558181763\n",
      "2021-08-25 15:51:46.911 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 201.27272727272728, 'equality': 0.8920095261580847, 'sustainability': 482.09307604357895, 'peace': 765.3636363636364}\n",
      "2021-08-25 15:51:46.961 | INFO     | src.policies:train:103 - Epoch 296 / 4000\n",
      "2021-08-25 15:51:46.961 | INFO     | src.policies:train:110 - Episode 296\n",
      "2021-08-25 15:52:10.835 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:52:10.860 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 220.1818181818182, 'equality': 0.9632910442165886, 'sustainability': 501.3758994602203, 'peace': 836.3636363636364}\n",
      "2021-08-25 15:52:10.861 | INFO     | src.policies:train:122 - Mean episode return: 220.1818181818182\n",
      "2021-08-25 15:52:10.861 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.65818181818187\n",
      "2021-08-25 15:52:10.862 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:52:20.225 | INFO     | src.policies:train:159 - Total loss: 1.002158522605896\n",
      "2021-08-25 15:52:20.225 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 220.1818181818182, 'equality': 0.9632910442165886, 'sustainability': 501.3758994602203, 'peace': 836.3636363636364}\n",
      "2021-08-25 15:52:20.274 | INFO     | src.policies:train:103 - Epoch 297 / 4000\n",
      "2021-08-25 15:52:20.274 | INFO     | src.policies:train:110 - Episode 297\n",
      "2021-08-25 15:52:43.544 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:52:43.570 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 208.72727272727272, 'equality': 0.91225847323582, 'sustainability': 464.77875795111834, 'peace': 686.0}\n",
      "2021-08-25 15:52:43.571 | INFO     | src.policies:train:122 - Mean episode return: 208.72727272727272\n",
      "2021-08-25 15:52:43.572 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.65181818181824\n",
      "2021-08-25 15:52:43.572 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:52:53.175 | INFO     | src.policies:train:159 - Total loss: 1.0019261837005615\n",
      "2021-08-25 15:52:53.176 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 208.72727272727272, 'equality': 0.91225847323582, 'sustainability': 464.77875795111834, 'peace': 686.0}\n",
      "2021-08-25 15:52:53.227 | INFO     | src.policies:train:103 - Epoch 298 / 4000\n",
      "2021-08-25 15:52:53.228 | INFO     | src.policies:train:110 - Episode 298\n",
      "2021-08-25 15:53:17.606 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:53:17.631 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 208.0909090909091, 'equality': 0.9250963104188987, 'sustainability': 495.3781557221297, 'peace': 741.2727272727273}\n",
      "2021-08-25 15:53:17.632 | INFO     | src.policies:train:122 - Mean episode return: 208.0909090909091\n",
      "2021-08-25 15:53:17.633 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.66272727272727\n",
      "2021-08-25 15:53:17.633 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:53:27.210 | INFO     | src.policies:train:159 - Total loss: 1.001599907875061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 15:53:27.211 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 208.0909090909091, 'equality': 0.9250963104188987, 'sustainability': 495.3781557221297, 'peace': 741.2727272727273}\n",
      "2021-08-25 15:53:27.261 | INFO     | src.policies:train:103 - Epoch 299 / 4000\n",
      "2021-08-25 15:53:27.262 | INFO     | src.policies:train:110 - Episode 299\n",
      "2021-08-25 15:53:51.439 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:53:51.461 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 229.0, 'equality': 0.9324407232319384, 'sustainability': 501.4908628747795, 'peace': 740.8181818181819}\n",
      "2021-08-25 15:53:51.462 | INFO     | src.policies:train:122 - Mean episode return: 229.0\n",
      "2021-08-25 15:53:51.462 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.7363636363636\n",
      "2021-08-25 15:53:51.463 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:54:01.078 | INFO     | src.policies:train:159 - Total loss: 0.9986935257911682\n",
      "2021-08-25 15:54:01.079 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 229.0, 'equality': 0.9324407232319384, 'sustainability': 501.4908628747795, 'peace': 740.8181818181819}\n",
      "2021-08-25 15:54:01.128 | INFO     | src.policies:train:103 - Epoch 300 / 4000\n",
      "2021-08-25 15:54:01.129 | INFO     | src.policies:train:110 - Episode 300\n",
      "2021-08-25 15:54:24.966 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:54:24.989 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 207.0, 'equality': 0.9419491356261838, 'sustainability': 466.7975506456536, 'peace': 684.9090909090909}\n",
      "2021-08-25 15:54:24.990 | INFO     | src.policies:train:122 - Mean episode return: 207.0\n",
      "2021-08-25 15:54:24.990 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.7854545454545\n",
      "2021-08-25 15:54:24.990 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:54:34.325 | INFO     | src.policies:train:159 - Total loss: 1.0015504360198975\n",
      "2021-08-25 15:54:34.326 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 207.0, 'equality': 0.9419491356261838, 'sustainability': 466.7975506456536, 'peace': 684.9090909090909}\n",
      "2021-08-25 15:54:34.376 | INFO     | src.policies:train:103 - Epoch 301 / 4000\n",
      "2021-08-25 15:54:34.377 | INFO     | src.policies:train:110 - Episode 301\n",
      "2021-08-25 15:54:57.493 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:54:57.516 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 185.54545454545453, 'equality': 0.8908734577548689, 'sustainability': 477.85141517165533, 'peace': 668.4545454545455}\n",
      "2021-08-25 15:54:57.516 | INFO     | src.policies:train:122 - Mean episode return: 185.54545454545453\n",
      "2021-08-25 15:54:57.517 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.56818181818184\n",
      "2021-08-25 15:54:57.517 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:55:06.869 | INFO     | src.policies:train:159 - Total loss: 0.9992932081222534\n",
      "2021-08-25 15:55:06.870 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 185.54545454545453, 'equality': 0.8908734577548689, 'sustainability': 477.85141517165533, 'peace': 668.4545454545455}\n",
      "2021-08-25 15:55:06.919 | INFO     | src.policies:train:103 - Epoch 302 / 4000\n",
      "2021-08-25 15:55:06.919 | INFO     | src.policies:train:110 - Episode 302\n",
      "2021-08-25 15:55:29.194 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:55:29.218 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 196.27272727272728, 'equality': 0.917975493706725, 'sustainability': 480.68455607417764, 'peace': 674.9090909090909}\n",
      "2021-08-25 15:55:29.219 | INFO     | src.policies:train:122 - Mean episode return: 196.27272727272728\n",
      "2021-08-25 15:55:29.220 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.53272727272727\n",
      "2021-08-25 15:55:29.221 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:55:38.520 | INFO     | src.policies:train:159 - Total loss: 0.9992587566375732\n",
      "2021-08-25 15:55:38.521 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 196.27272727272728, 'equality': 0.917975493706725, 'sustainability': 480.68455607417764, 'peace': 674.9090909090909}\n",
      "2021-08-25 15:55:38.570 | INFO     | src.policies:train:103 - Epoch 303 / 4000\n",
      "2021-08-25 15:55:38.571 | INFO     | src.policies:train:110 - Episode 303\n",
      "2021-08-25 15:56:01.552 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:56:01.577 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 209.54545454545453, 'equality': 0.9379215144954068, 'sustainability': 493.5651794699866, 'peace': 776.1818181818181}\n",
      "2021-08-25 15:56:01.578 | INFO     | src.policies:train:122 - Mean episode return: 209.54545454545453\n",
      "2021-08-25 15:56:01.578 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.6972727272728\n",
      "2021-08-25 15:56:01.578 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:56:10.883 | INFO     | src.policies:train:159 - Total loss: 0.9999074339866638\n",
      "2021-08-25 15:56:10.884 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 209.54545454545453, 'equality': 0.9379215144954068, 'sustainability': 493.5651794699866, 'peace': 776.1818181818181}\n",
      "2021-08-25 15:56:10.933 | INFO     | src.policies:train:103 - Epoch 304 / 4000\n",
      "2021-08-25 15:56:10.934 | INFO     | src.policies:train:110 - Episode 304\n",
      "2021-08-25 15:56:34.182 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:56:34.210 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 208.63636363636363, 'equality': 0.9229946524079423, 'sustainability': 490.8972298099557, 'peace': 732.5454545454545}\n",
      "2021-08-25 15:56:34.211 | INFO     | src.policies:train:122 - Mean episode return: 208.63636363636363\n",
      "2021-08-25 15:56:34.212 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.47454545454548\n",
      "2021-08-25 15:56:34.212 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:56:43.797 | INFO     | src.policies:train:159 - Total loss: 1.00190269947052\n",
      "2021-08-25 15:56:43.798 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 208.63636363636363, 'equality': 0.9229946524079423, 'sustainability': 490.8972298099557, 'peace': 732.5454545454545}\n",
      "2021-08-25 15:56:43.848 | INFO     | src.policies:train:103 - Epoch 305 / 4000\n",
      "2021-08-25 15:56:43.848 | INFO     | src.policies:train:110 - Episode 305\n",
      "2021-08-25 15:57:08.281 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:57:08.306 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 232.54545454545453, 'equality': 0.9362428033275954, 'sustainability': 499.6211101538673, 'peace': 770.9090909090909}\n",
      "2021-08-25 15:57:08.306 | INFO     | src.policies:train:122 - Mean episode return: 232.54545454545453\n",
      "2021-08-25 15:57:08.307 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.69363636363644\n",
      "2021-08-25 15:57:08.307 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:57:17.894 | INFO     | src.policies:train:159 - Total loss: 0.9983305931091309\n",
      "2021-08-25 15:57:17.894 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 232.54545454545453, 'equality': 0.9362428033275954, 'sustainability': 499.6211101538673, 'peace': 770.9090909090909}\n",
      "2021-08-25 15:57:17.946 | INFO     | src.policies:train:103 - Epoch 306 / 4000\n",
      "2021-08-25 15:57:17.947 | INFO     | src.policies:train:110 - Episode 306\n",
      "2021-08-25 15:57:42.322 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:57:42.347 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 204.36363636363637, 'equality': 0.9054513102574925, 'sustainability': 482.29919815820284, 'peace': 746.3636363636364}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 15:57:42.348 | INFO     | src.policies:train:122 - Mean episode return: 204.36363636363637\n",
      "2021-08-25 15:57:42.348 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.61000000000004\n",
      "2021-08-25 15:57:42.349 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:57:51.945 | INFO     | src.policies:train:159 - Total loss: 1.0019819736480713\n",
      "2021-08-25 15:57:51.946 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 204.36363636363637, 'equality': 0.9054513102574925, 'sustainability': 482.29919815820284, 'peace': 746.3636363636364}\n",
      "2021-08-25 15:57:51.996 | INFO     | src.policies:train:103 - Epoch 307 / 4000\n",
      "2021-08-25 15:57:51.996 | INFO     | src.policies:train:110 - Episode 307\n",
      "2021-08-25 15:58:15.199 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:58:15.223 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 229.72727272727272, 'equality': 0.9537360146786751, 'sustainability': 508.4250799943256, 'peace': 770.4545454545455}\n",
      "2021-08-25 15:58:15.224 | INFO     | src.policies:train:122 - Mean episode return: 229.72727272727272\n",
      "2021-08-25 15:58:15.225 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.69454545454548\n",
      "2021-08-25 15:58:15.225 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:58:24.490 | INFO     | src.policies:train:159 - Total loss: 0.9973589181900024\n",
      "2021-08-25 15:58:24.491 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 229.72727272727272, 'equality': 0.9537360146786751, 'sustainability': 508.4250799943256, 'peace': 770.4545454545455}\n",
      "2021-08-25 15:58:24.540 | INFO     | src.policies:train:103 - Epoch 308 / 4000\n",
      "2021-08-25 15:58:24.541 | INFO     | src.policies:train:110 - Episode 308\n",
      "2021-08-25 15:58:47.227 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:58:47.252 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 212.36363636363637, 'equality': 0.9233343711098355, 'sustainability': 510.78337581562226, 'peace': 737.8181818181819}\n",
      "2021-08-25 15:58:47.253 | INFO     | src.policies:train:122 - Mean episode return: 212.36363636363637\n",
      "2021-08-25 15:58:47.253 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.7909090909091\n",
      "2021-08-25 15:58:47.254 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:58:56.574 | INFO     | src.policies:train:159 - Total loss: 1.0005497932434082\n",
      "2021-08-25 15:58:56.575 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 212.36363636363637, 'equality': 0.9233343711098355, 'sustainability': 510.78337581562226, 'peace': 737.8181818181819}\n",
      "2021-08-25 15:58:56.624 | INFO     | src.policies:train:103 - Epoch 309 / 4000\n",
      "2021-08-25 15:58:56.625 | INFO     | src.policies:train:110 - Episode 309\n",
      "2021-08-25 15:59:20.029 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:59:20.055 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 181.8181818181818, 'equality': 0.9168181818200724, 'sustainability': 469.26108129865503, 'peace': 631.3636363636364}\n",
      "2021-08-25 15:59:20.056 | INFO     | src.policies:train:122 - Mean episode return: 181.8181818181818\n",
      "2021-08-25 15:59:20.056 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.57636363636365\n",
      "2021-08-25 15:59:20.057 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 15:59:29.442 | INFO     | src.policies:train:159 - Total loss: 1.005259394645691\n",
      "2021-08-25 15:59:29.442 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 181.8181818181818, 'equality': 0.9168181818200724, 'sustainability': 469.26108129865503, 'peace': 631.3636363636364}\n",
      "2021-08-25 15:59:29.493 | INFO     | src.policies:train:103 - Epoch 310 / 4000\n",
      "2021-08-25 15:59:29.493 | INFO     | src.policies:train:110 - Episode 310\n",
      "2021-08-25 15:59:53.111 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 15:59:53.136 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 215.8181818181818, 'equality': 0.9369686758072879, 'sustainability': 481.5024231980857, 'peace': 765.8181818181819}\n",
      "2021-08-25 15:59:53.137 | INFO     | src.policies:train:122 - Mean episode return: 215.8181818181818\n",
      "2021-08-25 15:59:53.137 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.7281818181818\n",
      "2021-08-25 15:59:53.138 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:00:02.746 | INFO     | src.policies:train:159 - Total loss: 0.999556839466095\n",
      "2021-08-25 16:00:02.746 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 215.8181818181818, 'equality': 0.9369686758072879, 'sustainability': 481.5024231980857, 'peace': 765.8181818181819}\n",
      "2021-08-25 16:00:02.796 | INFO     | src.policies:train:103 - Epoch 311 / 4000\n",
      "2021-08-25 16:00:02.797 | INFO     | src.policies:train:110 - Episode 311\n",
      "2021-08-25 16:00:27.998 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:00:28.027 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 210.1818181818182, 'equality': 0.9476250393215707, 'sustainability': 474.3790715761239, 'peace': 727.7272727272727}\n",
      "2021-08-25 16:00:28.028 | INFO     | src.policies:train:122 - Mean episode return: 210.1818181818182\n",
      "2021-08-25 16:00:28.029 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.86090909090905\n",
      "2021-08-25 16:00:28.029 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:00:37.703 | INFO     | src.policies:train:159 - Total loss: 1.0009340047836304\n",
      "2021-08-25 16:00:37.703 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 210.1818181818182, 'equality': 0.9476250393215707, 'sustainability': 474.3790715761239, 'peace': 727.7272727272727}\n",
      "2021-08-25 16:00:37.752 | INFO     | src.policies:train:103 - Epoch 312 / 4000\n",
      "2021-08-25 16:00:37.752 | INFO     | src.policies:train:110 - Episode 312\n",
      "2021-08-25 16:01:01.489 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:01:01.513 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 225.63636363636363, 'equality': 0.960515713135292, 'sustainability': 497.3048842202543, 'peace': 727.2727272727273}\n",
      "2021-08-25 16:01:01.514 | INFO     | src.policies:train:122 - Mean episode return: 225.63636363636363\n",
      "2021-08-25 16:01:01.514 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.05909090909088\n",
      "2021-08-25 16:01:01.515 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:01:10.847 | INFO     | src.policies:train:159 - Total loss: 0.9986622333526611\n",
      "2021-08-25 16:01:10.848 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 225.63636363636363, 'equality': 0.960515713135292, 'sustainability': 497.3048842202543, 'peace': 727.2727272727273}\n",
      "2021-08-25 16:01:10.900 | INFO     | src.policies:train:103 - Epoch 313 / 4000\n",
      "2021-08-25 16:01:10.900 | INFO     | src.policies:train:110 - Episode 313\n",
      "2021-08-25 16:01:34.226 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:01:34.250 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 202.72727272727272, 'equality': 0.9163473298019497, 'sustainability': 477.25099433346475, 'peace': 661.8181818181819}\n",
      "2021-08-25 16:01:34.251 | INFO     | src.policies:train:122 - Mean episode return: 202.72727272727272\n",
      "2021-08-25 16:01:34.251 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.11727272727273\n",
      "2021-08-25 16:01:34.252 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:01:43.577 | INFO     | src.policies:train:159 - Total loss: 1.0009739398956299\n",
      "2021-08-25 16:01:43.578 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 202.72727272727272, 'equality': 0.9163473298019497, 'sustainability': 477.25099433346475, 'peace': 661.8181818181819}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 16:01:43.628 | INFO     | src.policies:train:103 - Epoch 314 / 4000\n",
      "2021-08-25 16:01:43.629 | INFO     | src.policies:train:110 - Episode 314\n",
      "2021-08-25 16:02:05.974 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:02:05.996 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 189.8181818181818, 'equality': 0.8912399860699399, 'sustainability': 470.1360844368368, 'peace': 655.9090909090909}\n",
      "2021-08-25 16:02:05.998 | INFO     | src.policies:train:122 - Mean episode return: 189.8181818181818\n",
      "2021-08-25 16:02:05.998 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.14\n",
      "2021-08-25 16:02:05.999 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:02:15.356 | INFO     | src.policies:train:159 - Total loss: 1.0017091035842896\n",
      "2021-08-25 16:02:15.357 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 189.8181818181818, 'equality': 0.8912399860699399, 'sustainability': 470.1360844368368, 'peace': 655.9090909090909}\n",
      "2021-08-25 16:02:15.408 | INFO     | src.policies:train:103 - Epoch 315 / 4000\n",
      "2021-08-25 16:02:15.408 | INFO     | src.policies:train:110 - Episode 315\n",
      "2021-08-25 16:02:38.745 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:02:38.771 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 201.9090909090909, 'equality': 0.9536654250756484, 'sustainability': 505.9231397995611, 'peace': 724.1818181818181}\n",
      "2021-08-25 16:02:38.771 | INFO     | src.policies:train:122 - Mean episode return: 201.9090909090909\n",
      "2021-08-25 16:02:38.772 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.0672727272727\n",
      "2021-08-25 16:02:38.772 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:02:48.167 | INFO     | src.policies:train:159 - Total loss: 1.0063599348068237\n",
      "2021-08-25 16:02:48.168 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 201.9090909090909, 'equality': 0.9536654250756484, 'sustainability': 505.9231397995611, 'peace': 724.1818181818181}\n",
      "2021-08-25 16:02:48.217 | INFO     | src.policies:train:103 - Epoch 316 / 4000\n",
      "2021-08-25 16:02:48.218 | INFO     | src.policies:train:110 - Episode 316\n",
      "2021-08-25 16:03:12.234 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:03:12.258 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 216.63636363636363, 'equality': 0.9273642848981924, 'sustainability': 503.8732453252456, 'peace': 771.0909090909091}\n",
      "2021-08-25 16:03:12.259 | INFO     | src.policies:train:122 - Mean episode return: 216.63636363636363\n",
      "2021-08-25 16:03:12.260 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.0172727272727\n",
      "2021-08-25 16:03:12.260 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:03:21.581 | INFO     | src.policies:train:159 - Total loss: 0.9973801374435425\n",
      "2021-08-25 16:03:21.582 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 216.63636363636363, 'equality': 0.9273642848981924, 'sustainability': 503.8732453252456, 'peace': 771.0909090909091}\n",
      "2021-08-25 16:03:21.630 | INFO     | src.policies:train:103 - Epoch 317 / 4000\n",
      "2021-08-25 16:03:21.631 | INFO     | src.policies:train:110 - Episode 317\n",
      "2021-08-25 16:03:44.177 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:03:44.202 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 193.0909090909091, 'equality': 0.8659476117131923, 'sustainability': 485.44841385523563, 'peace': 692.7272727272727}\n",
      "2021-08-25 16:03:44.202 | INFO     | src.policies:train:122 - Mean episode return: 193.0909090909091\n",
      "2021-08-25 16:03:44.203 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.79\n",
      "2021-08-25 16:03:44.203 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:03:53.763 | INFO     | src.policies:train:159 - Total loss: 1.004467487335205\n",
      "2021-08-25 16:03:53.763 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 193.0909090909091, 'equality': 0.8659476117131923, 'sustainability': 485.44841385523563, 'peace': 692.7272727272727}\n",
      "2021-08-25 16:03:53.813 | INFO     | src.policies:train:103 - Epoch 318 / 4000\n",
      "2021-08-25 16:03:53.814 | INFO     | src.policies:train:110 - Episode 318\n",
      "2021-08-25 16:04:17.896 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:04:17.923 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 212.27272727272728, 'equality': 0.9296865875038021, 'sustainability': 486.5144005616736, 'peace': 720.9090909090909}\n",
      "2021-08-25 16:04:17.923 | INFO     | src.policies:train:122 - Mean episode return: 212.27272727272728\n",
      "2021-08-25 16:04:17.924 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.9781818181818\n",
      "2021-08-25 16:04:17.924 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:04:27.546 | INFO     | src.policies:train:159 - Total loss: 1.0020039081573486\n",
      "2021-08-25 16:04:27.547 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 212.27272727272728, 'equality': 0.9296865875038021, 'sustainability': 486.5144005616736, 'peace': 720.9090909090909}\n",
      "2021-08-25 16:04:27.596 | INFO     | src.policies:train:103 - Epoch 319 / 4000\n",
      "2021-08-25 16:04:27.597 | INFO     | src.policies:train:110 - Episode 319\n",
      "2021-08-25 16:04:50.704 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:04:50.730 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 176.63636363636363, 'equality': 0.8177139381505237, 'sustainability': 473.795923756398, 'peace': 604.0}\n",
      "2021-08-25 16:04:50.731 | INFO     | src.policies:train:122 - Mean episode return: 176.63636363636363\n",
      "2021-08-25 16:04:50.731 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.66\n",
      "2021-08-25 16:04:50.732 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:05:00.123 | INFO     | src.policies:train:159 - Total loss: 1.0038560628890991\n",
      "2021-08-25 16:05:00.124 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 176.63636363636363, 'equality': 0.8177139381505237, 'sustainability': 473.795923756398, 'peace': 604.0}\n",
      "2021-08-25 16:05:00.174 | INFO     | src.policies:train:103 - Epoch 320 / 4000\n",
      "2021-08-25 16:05:00.175 | INFO     | src.policies:train:110 - Episode 320\n",
      "2021-08-25 16:05:24.320 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:05:24.345 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 226.0, 'equality': 0.9534849703804307, 'sustainability': 479.17052483674615, 'peace': 740.3636363636364}\n",
      "2021-08-25 16:05:24.346 | INFO     | src.policies:train:122 - Mean episode return: 226.0\n",
      "2021-08-25 16:05:24.346 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.73181818181817\n",
      "2021-08-25 16:05:24.347 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:05:33.682 | INFO     | src.policies:train:159 - Total loss: 1.0033961534500122\n",
      "2021-08-25 16:05:33.683 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 226.0, 'equality': 0.9534849703804307, 'sustainability': 479.17052483674615, 'peace': 740.3636363636364}\n",
      "2021-08-25 16:05:33.734 | INFO     | src.policies:train:103 - Epoch 321 / 4000\n",
      "2021-08-25 16:05:33.734 | INFO     | src.policies:train:110 - Episode 321\n",
      "2021-08-25 16:05:57.704 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:05:57.728 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 200.45454545454547, 'equality': 0.9215007215023397, 'sustainability': 512.2696829330854, 'peace': 714.9090909090909}\n",
      "2021-08-25 16:05:57.728 | INFO     | src.policies:train:122 - Mean episode return: 200.45454545454547\n",
      "2021-08-25 16:05:57.729 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.6981818181818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 16:05:57.729 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:06:07.045 | INFO     | src.policies:train:159 - Total loss: 0.9965023398399353\n",
      "2021-08-25 16:06:07.046 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 200.45454545454547, 'equality': 0.9215007215023397, 'sustainability': 512.2696829330854, 'peace': 714.9090909090909}\n",
      "2021-08-25 16:06:07.095 | INFO     | src.policies:train:103 - Epoch 322 / 4000\n",
      "2021-08-25 16:06:07.096 | INFO     | src.policies:train:110 - Episode 322\n",
      "2021-08-25 16:06:30.786 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:06:30.809 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 201.27272727272728, 'equality': 0.8906955736246469, 'sustainability': 473.2305487800431, 'peace': 647.4545454545455}\n",
      "2021-08-25 16:06:30.809 | INFO     | src.policies:train:122 - Mean episode return: 201.27272727272728\n",
      "2021-08-25 16:06:30.810 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.4481818181818\n",
      "2021-08-25 16:06:30.810 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:06:40.109 | INFO     | src.policies:train:159 - Total loss: 1.0071017742156982\n",
      "2021-08-25 16:06:40.110 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 201.27272727272728, 'equality': 0.8906955736246469, 'sustainability': 473.2305487800431, 'peace': 647.4545454545455}\n",
      "2021-08-25 16:06:40.159 | INFO     | src.policies:train:103 - Epoch 323 / 4000\n",
      "2021-08-25 16:06:40.160 | INFO     | src.policies:train:110 - Episode 323\n",
      "2021-08-25 16:07:02.830 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:07:02.854 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 211.0909090909091, 'equality': 0.9058022081296335, 'sustainability': 472.86968510950834, 'peace': 718.0909090909091}\n",
      "2021-08-25 16:07:02.855 | INFO     | src.policies:train:122 - Mean episode return: 211.0909090909091\n",
      "2021-08-25 16:07:02.856 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.58090909090907\n",
      "2021-08-25 16:07:02.856 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:07:12.240 | INFO     | src.policies:train:159 - Total loss: 0.9995850920677185\n",
      "2021-08-25 16:07:12.241 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 211.0909090909091, 'equality': 0.9058022081296335, 'sustainability': 472.86968510950834, 'peace': 718.0909090909091}\n",
      "2021-08-25 16:07:12.294 | INFO     | src.policies:train:103 - Epoch 324 / 4000\n",
      "2021-08-25 16:07:12.295 | INFO     | src.policies:train:110 - Episode 324\n",
      "2021-08-25 16:07:35.965 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:07:35.990 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 208.8181818181818, 'equality': 0.9473621720040495, 'sustainability': 487.11789487141374, 'peace': 695.2727272727273}\n",
      "2021-08-25 16:07:35.990 | INFO     | src.policies:train:122 - Mean episode return: 208.8181818181818\n",
      "2021-08-25 16:07:35.991 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.61999999999998\n",
      "2021-08-25 16:07:35.991 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:07:45.577 | INFO     | src.policies:train:159 - Total loss: 1.0016779899597168\n",
      "2021-08-25 16:07:45.578 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 208.8181818181818, 'equality': 0.9473621720040495, 'sustainability': 487.11789487141374, 'peace': 695.2727272727273}\n",
      "2021-08-25 16:07:45.629 | INFO     | src.policies:train:103 - Epoch 325 / 4000\n",
      "2021-08-25 16:07:45.630 | INFO     | src.policies:train:110 - Episode 325\n",
      "2021-08-25 16:08:10.192 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:08:10.217 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 207.72727272727272, 'equality': 0.914541476031141, 'sustainability': 504.7045434405445, 'peace': 750.9090909090909}\n",
      "2021-08-25 16:08:10.218 | INFO     | src.policies:train:122 - Mean episode return: 207.72727272727272\n",
      "2021-08-25 16:08:10.219 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.6390909090909\n",
      "2021-08-25 16:08:10.219 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:08:19.843 | INFO     | src.policies:train:159 - Total loss: 1.0000759363174438\n",
      "2021-08-25 16:08:19.844 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 207.72727272727272, 'equality': 0.914541476031141, 'sustainability': 504.7045434405445, 'peace': 750.9090909090909}\n",
      "2021-08-25 16:08:19.894 | INFO     | src.policies:train:103 - Epoch 326 / 4000\n",
      "2021-08-25 16:08:19.895 | INFO     | src.policies:train:110 - Episode 326\n",
      "2021-08-25 16:08:43.537 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:08:43.563 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 224.0, 'equality': 0.9718122786309804, 'sustainability': 485.3151488533178, 'peace': 781.2727272727273}\n",
      "2021-08-25 16:08:43.564 | INFO     | src.policies:train:122 - Mean episode return: 224.0\n",
      "2021-08-25 16:08:43.564 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.73454545454544\n",
      "2021-08-25 16:08:43.565 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:08:52.938 | INFO     | src.policies:train:159 - Total loss: 0.9951235055923462\n",
      "2021-08-25 16:08:52.938 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 224.0, 'equality': 0.9718122786309804, 'sustainability': 485.3151488533178, 'peace': 781.2727272727273}\n",
      "2021-08-25 16:08:52.987 | INFO     | src.policies:train:103 - Epoch 327 / 4000\n",
      "2021-08-25 16:08:52.988 | INFO     | src.policies:train:110 - Episode 327\n",
      "2021-08-25 16:09:15.874 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:09:15.899 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 227.0909090909091, 'equality': 0.9326006259565361, 'sustainability': 506.170898187638, 'peace': 780.2727272727273}\n",
      "2021-08-25 16:09:15.901 | INFO     | src.policies:train:122 - Mean episode return: 227.0909090909091\n",
      "2021-08-25 16:09:15.901 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.02181818181816\n",
      "2021-08-25 16:09:15.902 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:09:25.216 | INFO     | src.policies:train:159 - Total loss: 0.9983170628547668\n",
      "2021-08-25 16:09:25.216 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 227.0909090909091, 'equality': 0.9326006259565361, 'sustainability': 506.170898187638, 'peace': 780.2727272727273}\n",
      "2021-08-25 16:09:25.267 | INFO     | src.policies:train:103 - Epoch 328 / 4000\n",
      "2021-08-25 16:09:25.268 | INFO     | src.policies:train:110 - Episode 328\n",
      "2021-08-25 16:09:48.293 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:09:48.318 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 178.45454545454547, 'equality': 0.9077478812599512, 'sustainability': 443.94510707260855, 'peace': 580.4545454545455}\n",
      "2021-08-25 16:09:48.319 | INFO     | src.policies:train:122 - Mean episode return: 178.45454545454547\n",
      "2021-08-25 16:09:48.319 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.59181818181816\n",
      "2021-08-25 16:09:48.320 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:09:57.649 | INFO     | src.policies:train:159 - Total loss: 0.9997251629829407\n",
      "2021-08-25 16:09:57.650 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 178.45454545454547, 'equality': 0.9077478812599512, 'sustainability': 443.94510707260855, 'peace': 580.4545454545455}\n",
      "2021-08-25 16:09:57.699 | INFO     | src.policies:train:103 - Epoch 329 / 4000\n",
      "2021-08-25 16:09:57.700 | INFO     | src.policies:train:110 - Episode 329\n",
      "2021-08-25 16:10:20.503 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 16:10:20.527 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 202.54545454545453, 'equality': 0.9298188346676632, 'sustainability': 488.26826452530526, 'peace': 634.8181818181819}\n",
      "2021-08-25 16:10:20.528 | INFO     | src.policies:train:122 - Mean episode return: 202.54545454545453\n",
      "2021-08-25 16:10:20.528 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.57636363636365\n",
      "2021-08-25 16:10:20.529 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:10:29.882 | INFO     | src.policies:train:159 - Total loss: 1.0008634328842163\n",
      "2021-08-25 16:10:29.882 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 202.54545454545453, 'equality': 0.9298188346676632, 'sustainability': 488.26826452530526, 'peace': 634.8181818181819}\n",
      "2021-08-25 16:10:29.933 | INFO     | src.policies:train:103 - Epoch 330 / 4000\n",
      "2021-08-25 16:10:29.934 | INFO     | src.policies:train:110 - Episode 330\n",
      "2021-08-25 16:10:52.659 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:10:52.684 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 183.72727272727272, 'equality': 0.8565966443287167, 'sustainability': 488.786483506852, 'peace': 696.8181818181819}\n",
      "2021-08-25 16:10:52.684 | INFO     | src.policies:train:122 - Mean episode return: 183.72727272727272\n",
      "2021-08-25 16:10:52.685 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.55363636363637\n",
      "2021-08-25 16:10:52.685 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:11:02.025 | INFO     | src.policies:train:159 - Total loss: 1.0022155046463013\n",
      "2021-08-25 16:11:02.025 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 183.72727272727272, 'equality': 0.8565966443287167, 'sustainability': 488.786483506852, 'peace': 696.8181818181819}\n",
      "2021-08-25 16:11:02.075 | INFO     | src.policies:train:103 - Epoch 331 / 4000\n",
      "2021-08-25 16:11:02.076 | INFO     | src.policies:train:110 - Episode 331\n",
      "2021-08-25 16:11:25.487 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:11:25.513 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 214.54545454545453, 'equality': 0.9456856702629876, 'sustainability': 497.86881888537505, 'peace': 736.5454545454545}\n",
      "2021-08-25 16:11:25.514 | INFO     | src.policies:train:122 - Mean episode return: 214.54545454545453\n",
      "2021-08-25 16:11:25.515 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.75454545454545\n",
      "2021-08-25 16:11:25.515 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:11:35.161 | INFO     | src.policies:train:159 - Total loss: 1.0001267194747925\n",
      "2021-08-25 16:11:35.162 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 214.54545454545453, 'equality': 0.9456856702629876, 'sustainability': 497.86881888537505, 'peace': 736.5454545454545}\n",
      "2021-08-25 16:11:35.213 | INFO     | src.policies:train:103 - Epoch 332 / 4000\n",
      "2021-08-25 16:11:35.214 | INFO     | src.policies:train:110 - Episode 332\n",
      "2021-08-25 16:11:58.174 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:11:58.199 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 207.63636363636363, 'equality': 0.9088520936174802, 'sustainability': 479.35778721758146, 'peace': 702.5454545454545}\n",
      "2021-08-25 16:11:58.199 | INFO     | src.policies:train:122 - Mean episode return: 207.63636363636363\n",
      "2021-08-25 16:11:58.200 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.88909090909092\n",
      "2021-08-25 16:11:58.200 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:12:07.821 | INFO     | src.policies:train:159 - Total loss: 0.9939230680465698\n",
      "2021-08-25 16:12:07.822 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 207.63636363636363, 'equality': 0.9088520936174802, 'sustainability': 479.35778721758146, 'peace': 702.5454545454545}\n",
      "2021-08-25 16:12:07.873 | INFO     | src.policies:train:103 - Epoch 333 / 4000\n",
      "2021-08-25 16:12:07.874 | INFO     | src.policies:train:110 - Episode 333\n",
      "2021-08-25 16:12:32.139 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:12:32.166 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 229.63636363636363, 'equality': 0.9630029511271323, 'sustainability': 489.1199990730507, 'peace': 793.0}\n",
      "2021-08-25 16:12:32.166 | INFO     | src.policies:train:122 - Mean episode return: 229.63636363636363\n",
      "2021-08-25 16:12:32.167 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.0936363636364\n",
      "2021-08-25 16:12:32.168 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:12:41.803 | INFO     | src.policies:train:159 - Total loss: 1.0032979249954224\n",
      "2021-08-25 16:12:41.804 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 229.63636363636363, 'equality': 0.9630029511271323, 'sustainability': 489.1199990730507, 'peace': 793.0}\n",
      "2021-08-25 16:12:41.854 | INFO     | src.policies:train:103 - Epoch 334 / 4000\n",
      "2021-08-25 16:12:41.854 | INFO     | src.policies:train:110 - Episode 334\n",
      "2021-08-25 16:13:05.298 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:13:05.322 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 219.36363636363637, 'equality': 0.9408506950996336, 'sustainability': 483.42577595191943, 'peace': 787.4545454545455}\n",
      "2021-08-25 16:13:05.323 | INFO     | src.policies:train:122 - Mean episode return: 219.36363636363637\n",
      "2021-08-25 16:13:05.324 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.12181818181818\n",
      "2021-08-25 16:13:05.324 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:13:14.618 | INFO     | src.policies:train:159 - Total loss: 1.0056511163711548\n",
      "2021-08-25 16:13:14.619 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 219.36363636363637, 'equality': 0.9408506950996336, 'sustainability': 483.42577595191943, 'peace': 787.4545454545455}\n",
      "2021-08-25 16:13:14.667 | INFO     | src.policies:train:103 - Epoch 335 / 4000\n",
      "2021-08-25 16:13:14.668 | INFO     | src.policies:train:110 - Episode 335\n",
      "2021-08-25 16:13:37.521 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:13:37.547 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 193.45454545454547, 'equality': 0.9047334244723015, 'sustainability': 467.6991086316562, 'peace': 694.1818181818181}\n",
      "2021-08-25 16:13:37.547 | INFO     | src.policies:train:122 - Mean episode return: 193.45454545454547\n",
      "2021-08-25 16:13:37.548 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.07454545454544\n",
      "2021-08-25 16:13:37.548 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:13:46.896 | INFO     | src.policies:train:159 - Total loss: 1.0008876323699951\n",
      "2021-08-25 16:13:46.896 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 193.45454545454547, 'equality': 0.9047334244723015, 'sustainability': 467.6991086316562, 'peace': 694.1818181818181}\n",
      "2021-08-25 16:13:46.946 | INFO     | src.policies:train:103 - Epoch 336 / 4000\n",
      "2021-08-25 16:13:46.947 | INFO     | src.policies:train:110 - Episode 336\n",
      "2021-08-25 16:14:09.411 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:14:09.437 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 200.72727272727272, 'equality': 0.921607378130731, 'sustainability': 505.5755852168917, 'peace': 708.7272727272727}\n",
      "2021-08-25 16:14:09.438 | INFO     | src.policies:train:122 - Mean episode return: 200.72727272727272\n",
      "2021-08-25 16:14:09.438 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.99090909090904\n",
      "2021-08-25 16:14:09.439 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:14:18.736 | INFO     | src.policies:train:159 - Total loss: 1.0006524324417114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 16:14:18.737 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 200.72727272727272, 'equality': 0.921607378130731, 'sustainability': 505.5755852168917, 'peace': 708.7272727272727}\n",
      "2021-08-25 16:14:18.786 | INFO     | src.policies:train:103 - Epoch 337 / 4000\n",
      "2021-08-25 16:14:18.787 | INFO     | src.policies:train:110 - Episode 337\n",
      "2021-08-25 16:14:42.756 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:14:42.781 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 199.1818181818182, 'equality': 0.9410812829355404, 'sustainability': 500.1308971295854, 'peace': 687.4545454545455}\n",
      "2021-08-25 16:14:42.782 | INFO     | src.policies:train:122 - Mean episode return: 199.1818181818182\n",
      "2021-08-25 16:14:42.782 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.05090909090904\n",
      "2021-08-25 16:14:42.783 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:14:52.695 | INFO     | src.policies:train:159 - Total loss: 0.999764084815979\n",
      "2021-08-25 16:14:52.696 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 199.1818181818182, 'equality': 0.9410812829355404, 'sustainability': 500.1308971295854, 'peace': 687.4545454545455}\n",
      "2021-08-25 16:14:52.748 | INFO     | src.policies:train:103 - Epoch 338 / 4000\n",
      "2021-08-25 16:14:52.749 | INFO     | src.policies:train:110 - Episode 338\n",
      "2021-08-25 16:15:17.549 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:15:17.575 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 206.0, 'equality': 0.9243360346641191, 'sustainability': 483.3261582876111, 'peace': 748.4545454545455}\n",
      "2021-08-25 16:15:17.576 | INFO     | src.policies:train:122 - Mean episode return: 206.0\n",
      "2021-08-25 16:15:17.576 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.05545454545452\n",
      "2021-08-25 16:15:17.577 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:15:27.467 | INFO     | src.policies:train:159 - Total loss: 1.0013737678527832\n",
      "2021-08-25 16:15:27.468 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 206.0, 'equality': 0.9243360346641191, 'sustainability': 483.3261582876111, 'peace': 748.4545454545455}\n",
      "2021-08-25 16:15:27.518 | INFO     | src.policies:train:103 - Epoch 339 / 4000\n",
      "2021-08-25 16:15:27.518 | INFO     | src.policies:train:110 - Episode 339\n",
      "2021-08-25 16:15:50.448 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:15:50.474 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 209.27272727272728, 'equality': 0.9474765026469576, 'sustainability': 493.5029813057991, 'peace': 712.1818181818181}\n",
      "2021-08-25 16:15:50.474 | INFO     | src.policies:train:122 - Mean episode return: 209.27272727272728\n",
      "2021-08-25 16:15:50.475 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.1209090909091\n",
      "2021-08-25 16:15:50.475 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:15:59.814 | INFO     | src.policies:train:159 - Total loss: 0.9965177774429321\n",
      "2021-08-25 16:15:59.815 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 209.27272727272728, 'equality': 0.9474765026469576, 'sustainability': 493.5029813057991, 'peace': 712.1818181818181}\n",
      "2021-08-25 16:15:59.863 | INFO     | src.policies:train:103 - Epoch 340 / 4000\n",
      "2021-08-25 16:15:59.864 | INFO     | src.policies:train:110 - Episode 340\n",
      "2021-08-25 16:16:23.604 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:16:23.627 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 213.36363636363637, 'equality': 0.9360886237762698, 'sustainability': 501.3602634840799, 'peace': 772.0}\n",
      "2021-08-25 16:16:23.627 | INFO     | src.policies:train:122 - Mean episode return: 213.36363636363637\n",
      "2021-08-25 16:16:23.628 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.3618181818182\n",
      "2021-08-25 16:16:23.628 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:16:32.987 | INFO     | src.policies:train:159 - Total loss: 1.000140905380249\n",
      "2021-08-25 16:16:32.988 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 213.36363636363637, 'equality': 0.9360886237762698, 'sustainability': 501.3602634840799, 'peace': 772.0}\n",
      "2021-08-25 16:16:33.040 | INFO     | src.policies:train:103 - Epoch 341 / 4000\n",
      "2021-08-25 16:16:33.040 | INFO     | src.policies:train:110 - Episode 341\n",
      "2021-08-25 16:16:55.790 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:16:55.816 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 211.36363636363637, 'equality': 0.9451026392972609, 'sustainability': 490.83568489803764, 'peace': 708.3636363636364}\n",
      "2021-08-25 16:16:55.817 | INFO     | src.policies:train:122 - Mean episode return: 211.36363636363637\n",
      "2021-08-25 16:16:55.817 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.30909090909088\n",
      "2021-08-25 16:16:55.818 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:17:05.167 | INFO     | src.policies:train:159 - Total loss: 1.0015931129455566\n",
      "2021-08-25 16:17:05.168 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 211.36363636363637, 'equality': 0.9451026392972609, 'sustainability': 490.83568489803764, 'peace': 708.3636363636364}\n",
      "2021-08-25 16:17:05.221 | INFO     | src.policies:train:103 - Epoch 342 / 4000\n",
      "2021-08-25 16:17:05.221 | INFO     | src.policies:train:110 - Episode 342\n",
      "2021-08-25 16:17:27.722 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:17:27.745 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 206.0, 'equality': 0.9216881970648783, 'sustainability': 482.974019775377, 'peace': 708.4545454545455}\n",
      "2021-08-25 16:17:27.745 | INFO     | src.policies:train:122 - Mean episode return: 206.0\n",
      "2021-08-25 16:17:27.746 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.37181818181816\n",
      "2021-08-25 16:17:27.746 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:17:37.116 | INFO     | src.policies:train:159 - Total loss: 0.9981207251548767\n",
      "2021-08-25 16:17:37.117 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 206.0, 'equality': 0.9216881970648783, 'sustainability': 482.974019775377, 'peace': 708.4545454545455}\n",
      "2021-08-25 16:17:37.170 | INFO     | src.policies:train:103 - Epoch 343 / 4000\n",
      "2021-08-25 16:17:37.171 | INFO     | src.policies:train:110 - Episode 343\n",
      "2021-08-25 16:18:00.515 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:18:00.540 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 186.27272727272728, 'equality': 0.8877501220132271, 'sustainability': 473.04395156546144, 'peace': 711.1818181818181}\n",
      "2021-08-25 16:18:00.541 | INFO     | src.policies:train:122 - Mean episode return: 186.27272727272728\n",
      "2021-08-25 16:18:00.542 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.05363636363637\n",
      "2021-08-25 16:18:00.542 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:18:09.880 | INFO     | src.policies:train:159 - Total loss: 1.003862738609314\n",
      "2021-08-25 16:18:09.881 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 186.27272727272728, 'equality': 0.8877501220132271, 'sustainability': 473.04395156546144, 'peace': 711.1818181818181}\n",
      "2021-08-25 16:18:09.930 | INFO     | src.policies:train:103 - Epoch 344 / 4000\n",
      "2021-08-25 16:18:09.931 | INFO     | src.policies:train:110 - Episode 344\n",
      "2021-08-25 16:18:34.392 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:18:34.417 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 207.72727272727272, 'equality': 0.9459717525373788, 'sustainability': 496.63421895499266, 'peace': 728.1818181818181}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 16:18:34.418 | INFO     | src.policies:train:122 - Mean episode return: 207.72727272727272\n",
      "2021-08-25 16:18:34.419 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.91272727272724\n",
      "2021-08-25 16:18:34.420 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:18:44.008 | INFO     | src.policies:train:159 - Total loss: 0.9997689127922058\n",
      "2021-08-25 16:18:44.009 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 207.72727272727272, 'equality': 0.9459717525373788, 'sustainability': 496.63421895499266, 'peace': 728.1818181818181}\n",
      "2021-08-25 16:18:44.060 | INFO     | src.policies:train:103 - Epoch 345 / 4000\n",
      "2021-08-25 16:18:44.061 | INFO     | src.policies:train:110 - Episode 345\n",
      "2021-08-25 16:19:07.939 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:19:07.965 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 215.27272727272728, 'equality': 0.9097051597068929, 'sustainability': 492.2969224462307, 'peace': 749.3636363636364}\n",
      "2021-08-25 16:19:07.966 | INFO     | src.policies:train:122 - Mean episode return: 215.27272727272728\n",
      "2021-08-25 16:19:07.966 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.92363636363635\n",
      "2021-08-25 16:19:07.967 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:19:17.580 | INFO     | src.policies:train:159 - Total loss: 0.9979227781295776\n",
      "2021-08-25 16:19:17.581 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 215.27272727272728, 'equality': 0.9097051597068929, 'sustainability': 492.2969224462307, 'peace': 749.3636363636364}\n",
      "2021-08-25 16:19:17.632 | INFO     | src.policies:train:103 - Epoch 346 / 4000\n",
      "2021-08-25 16:19:17.632 | INFO     | src.policies:train:110 - Episode 346\n",
      "2021-08-25 16:19:42.133 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:19:42.160 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 203.36363636363637, 'equality': 0.9095379363614107, 'sustainability': 480.4020435716306, 'peace': 697.3636363636364}\n",
      "2021-08-25 16:19:42.161 | INFO     | src.policies:train:122 - Mean episode return: 203.36363636363637\n",
      "2021-08-25 16:19:42.162 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.86272727272726\n",
      "2021-08-25 16:19:42.162 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:19:51.447 | INFO     | src.policies:train:159 - Total loss: 1.0023729801177979\n",
      "2021-08-25 16:19:51.448 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 203.36363636363637, 'equality': 0.9095379363614107, 'sustainability': 480.4020435716306, 'peace': 697.3636363636364}\n",
      "2021-08-25 16:19:51.499 | INFO     | src.policies:train:103 - Epoch 347 / 4000\n",
      "2021-08-25 16:19:51.499 | INFO     | src.policies:train:110 - Episode 347\n",
      "2021-08-25 16:20:14.682 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:20:14.705 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 205.45454545454547, 'equality': 0.9427192276761319, 'sustainability': 486.2685961174868, 'peace': 714.7272727272727}\n",
      "2021-08-25 16:20:14.706 | INFO     | src.policies:train:122 - Mean episode return: 205.45454545454547\n",
      "2021-08-25 16:20:14.708 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 205.85181818181817\n",
      "2021-08-25 16:20:14.708 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:20:24.068 | INFO     | src.policies:train:159 - Total loss: 1.0020737648010254\n",
      "2021-08-25 16:20:24.069 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 205.45454545454547, 'equality': 0.9427192276761319, 'sustainability': 486.2685961174868, 'peace': 714.7272727272727}\n",
      "2021-08-25 16:20:24.123 | INFO     | src.policies:train:103 - Epoch 348 / 4000\n",
      "2021-08-25 16:20:24.123 | INFO     | src.policies:train:110 - Episode 348\n",
      "2021-08-25 16:20:48.121 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:20:48.147 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 225.45454545454547, 'equality': 0.9612170087983648, 'sustainability': 494.7471967959675, 'peace': 811.3636363636364}\n",
      "2021-08-25 16:20:48.148 | INFO     | src.policies:train:122 - Mean episode return: 225.45454545454547\n",
      "2021-08-25 16:20:48.148 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.12181818181813\n",
      "2021-08-25 16:20:48.149 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:20:58.125 | INFO     | src.policies:train:159 - Total loss: 0.9995351433753967\n",
      "2021-08-25 16:20:58.125 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 225.45454545454547, 'equality': 0.9612170087983648, 'sustainability': 494.7471967959675, 'peace': 811.3636363636364}\n",
      "2021-08-25 16:20:58.180 | INFO     | src.policies:train:103 - Epoch 349 / 4000\n",
      "2021-08-25 16:20:58.181 | INFO     | src.policies:train:110 - Episode 349\n",
      "2021-08-25 16:21:24.169 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:21:24.196 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 213.0909090909091, 'equality': 0.9356965560049701, 'sustainability': 495.4431207090647, 'peace': 679.4545454545455}\n",
      "2021-08-25 16:21:24.197 | INFO     | src.policies:train:122 - Mean episode return: 213.0909090909091\n",
      "2021-08-25 16:21:24.197 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.36999999999992\n",
      "2021-08-25 16:21:24.198 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:21:34.410 | INFO     | src.policies:train:159 - Total loss: 1.0062161684036255\n",
      "2021-08-25 16:21:34.411 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 213.0909090909091, 'equality': 0.9356965560049701, 'sustainability': 495.4431207090647, 'peace': 679.4545454545455}\n",
      "2021-08-25 16:21:34.465 | INFO     | src.policies:train:103 - Epoch 350 / 4000\n",
      "2021-08-25 16:21:34.465 | INFO     | src.policies:train:110 - Episode 350\n",
      "2021-08-25 16:22:00.225 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:22:00.251 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 219.1818181818182, 'equality': 0.9360506768233465, 'sustainability': 498.9673189330604, 'peace': 705.3636363636364}\n",
      "2021-08-25 16:22:00.252 | INFO     | src.policies:train:122 - Mean episode return: 219.1818181818182\n",
      "2021-08-25 16:22:00.253 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.55727272727273\n",
      "2021-08-25 16:22:00.253 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:22:10.519 | INFO     | src.policies:train:159 - Total loss: 0.9992497563362122\n",
      "2021-08-25 16:22:10.520 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 219.1818181818182, 'equality': 0.9360506768233465, 'sustainability': 498.9673189330604, 'peace': 705.3636363636364}\n",
      "2021-08-25 16:22:10.582 | INFO     | src.policies:train:103 - Epoch 351 / 4000\n",
      "2021-08-25 16:22:10.583 | INFO     | src.policies:train:110 - Episode 351\n",
      "2021-08-25 16:22:36.321 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:22:36.347 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 190.36363636363637, 'equality': 0.9249804636640405, 'sustainability': 497.2345135091324, 'peace': 686.0909090909091}\n",
      "2021-08-25 16:22:36.348 | INFO     | src.policies:train:122 - Mean episode return: 190.36363636363637\n",
      "2021-08-25 16:22:36.348 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.48272727272723\n",
      "2021-08-25 16:22:36.349 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:22:46.613 | INFO     | src.policies:train:159 - Total loss: 0.9987924695014954\n",
      "2021-08-25 16:22:46.614 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 190.36363636363637, 'equality': 0.9249804636640405, 'sustainability': 497.2345135091324, 'peace': 686.0909090909091}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 16:22:46.667 | INFO     | src.policies:train:103 - Epoch 352 / 4000\n",
      "2021-08-25 16:22:46.668 | INFO     | src.policies:train:110 - Episode 352\n",
      "2021-08-25 16:23:12.195 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:23:12.223 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 209.8181818181818, 'equality': 0.9216165117393726, 'sustainability': 487.31368803654, 'peace': 759.5454545454545}\n",
      "2021-08-25 16:23:12.224 | INFO     | src.policies:train:122 - Mean episode return: 209.8181818181818\n",
      "2021-08-25 16:23:12.224 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.6781818181818\n",
      "2021-08-25 16:23:12.225 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:23:22.435 | INFO     | src.policies:train:159 - Total loss: 0.998066782951355\n",
      "2021-08-25 16:23:22.436 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 209.8181818181818, 'equality': 0.9216165117393726, 'sustainability': 487.31368803654, 'peace': 759.5454545454545}\n",
      "2021-08-25 16:23:22.487 | INFO     | src.policies:train:103 - Epoch 353 / 4000\n",
      "2021-08-25 16:23:22.488 | INFO     | src.policies:train:110 - Episode 353\n",
      "2021-08-25 16:23:48.763 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:23:48.796 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 211.8181818181818, 'equality': 0.9529457666805902, 'sustainability': 499.3137456673216, 'peace': 690.2727272727273}\n",
      "2021-08-25 16:23:48.797 | INFO     | src.policies:train:122 - Mean episode return: 211.8181818181818\n",
      "2021-08-25 16:23:48.798 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.79090909090905\n",
      "2021-08-25 16:23:48.798 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:23:59.023 | INFO     | src.policies:train:159 - Total loss: 0.9990686774253845\n",
      "2021-08-25 16:23:59.023 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 211.8181818181818, 'equality': 0.9529457666805902, 'sustainability': 499.3137456673216, 'peace': 690.2727272727273}\n",
      "2021-08-25 16:23:59.078 | INFO     | src.policies:train:103 - Epoch 354 / 4000\n",
      "2021-08-25 16:23:59.079 | INFO     | src.policies:train:110 - Episode 354\n",
      "2021-08-25 16:24:24.656 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:24:24.683 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 210.72727272727272, 'equality': 0.9460349831369904, 'sustainability': 501.47356542046003, 'peace': 681.8181818181819}\n",
      "2021-08-25 16:24:24.683 | INFO     | src.policies:train:122 - Mean episode return: 210.72727272727272\n",
      "2021-08-25 16:24:24.684 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.78181818181812\n",
      "2021-08-25 16:24:24.684 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:24:34.604 | INFO     | src.policies:train:159 - Total loss: 1.0011019706726074\n",
      "2021-08-25 16:24:34.605 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 210.72727272727272, 'equality': 0.9460349831369904, 'sustainability': 501.47356542046003, 'peace': 681.8181818181819}\n",
      "2021-08-25 16:24:34.657 | INFO     | src.policies:train:103 - Epoch 355 / 4000\n",
      "2021-08-25 16:24:34.658 | INFO     | src.policies:train:110 - Episode 355\n",
      "2021-08-25 16:24:59.553 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:24:59.578 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 219.54545454545453, 'equality': 0.954677206851973, 'sustainability': 479.8300135529149, 'peace': 741.5454545454545}\n",
      "2021-08-25 16:24:59.579 | INFO     | src.policies:train:122 - Mean episode return: 219.54545454545453\n",
      "2021-08-25 16:24:59.580 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.93909090909088\n",
      "2021-08-25 16:24:59.580 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:25:09.470 | INFO     | src.policies:train:159 - Total loss: 1.0031911134719849\n",
      "2021-08-25 16:25:09.471 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 219.54545454545453, 'equality': 0.954677206851973, 'sustainability': 479.8300135529149, 'peace': 741.5454545454545}\n",
      "2021-08-25 16:25:09.523 | INFO     | src.policies:train:103 - Epoch 356 / 4000\n",
      "2021-08-25 16:25:09.524 | INFO     | src.policies:train:110 - Episode 356\n",
      "2021-08-25 16:25:34.245 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:25:34.270 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 198.36363636363637, 'equality': 0.8906757770208592, 'sustainability': 470.4244358034728, 'peace': 703.7272727272727}\n",
      "2021-08-25 16:25:34.271 | INFO     | src.policies:train:122 - Mean episode return: 198.36363636363637\n",
      "2021-08-25 16:25:34.271 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.0663636363636\n",
      "2021-08-25 16:25:34.272 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:25:44.530 | INFO     | src.policies:train:159 - Total loss: 0.9994356632232666\n",
      "2021-08-25 16:25:44.531 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 198.36363636363637, 'equality': 0.8906757770208592, 'sustainability': 470.4244358034728, 'peace': 703.7272727272727}\n",
      "2021-08-25 16:25:44.585 | INFO     | src.policies:train:103 - Epoch 357 / 4000\n",
      "2021-08-25 16:25:44.586 | INFO     | src.policies:train:110 - Episode 357\n",
      "2021-08-25 16:26:11.374 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:26:11.400 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 198.27272727272728, 'equality': 0.8646992622261536, 'sustainability': 476.79773734957564, 'peace': 679.3636363636364}\n",
      "2021-08-25 16:26:11.401 | INFO     | src.policies:train:122 - Mean episode return: 198.27272727272728\n",
      "2021-08-25 16:26:11.402 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.8618181818182\n",
      "2021-08-25 16:26:11.402 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:26:21.754 | INFO     | src.policies:train:159 - Total loss: 1.0015082359313965\n",
      "2021-08-25 16:26:21.755 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 198.27272727272728, 'equality': 0.8646992622261536, 'sustainability': 476.79773734957564, 'peace': 679.3636363636364}\n",
      "2021-08-25 16:26:21.807 | INFO     | src.policies:train:103 - Epoch 358 / 4000\n",
      "2021-08-25 16:26:21.807 | INFO     | src.policies:train:110 - Episode 358\n",
      "2021-08-25 16:26:47.359 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:26:47.384 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 214.0909090909091, 'equality': 0.9280447790015819, 'sustainability': 494.13357832827364, 'peace': 712.7272727272727}\n",
      "2021-08-25 16:26:47.385 | INFO     | src.policies:train:122 - Mean episode return: 214.0909090909091\n",
      "2021-08-25 16:26:47.385 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.82545454545456\n",
      "2021-08-25 16:26:47.386 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:26:56.987 | INFO     | src.policies:train:159 - Total loss: 0.9982202053070068\n",
      "2021-08-25 16:26:56.987 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 214.0909090909091, 'equality': 0.9280447790015819, 'sustainability': 494.13357832827364, 'peace': 712.7272727272727}\n",
      "2021-08-25 16:26:57.037 | INFO     | src.policies:train:103 - Epoch 359 / 4000\n",
      "2021-08-25 16:26:57.038 | INFO     | src.policies:train:110 - Episode 359\n",
      "2021-08-25 16:27:20.154 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:27:20.176 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 202.27272727272728, 'equality': 0.9141164453541549, 'sustainability': 488.8432280931396, 'peace': 679.9090909090909}\n",
      "2021-08-25 16:27:20.177 | INFO     | src.policies:train:122 - Mean episode return: 202.27272727272728\n",
      "2021-08-25 16:27:20.178 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.8563636363636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 16:27:20.178 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:27:29.506 | INFO     | src.policies:train:159 - Total loss: 0.9946997761726379\n",
      "2021-08-25 16:27:29.507 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 202.27272727272728, 'equality': 0.9141164453541549, 'sustainability': 488.8432280931396, 'peace': 679.9090909090909}\n",
      "2021-08-25 16:27:29.557 | INFO     | src.policies:train:103 - Epoch 360 / 4000\n",
      "2021-08-25 16:27:29.557 | INFO     | src.policies:train:110 - Episode 360\n",
      "2021-08-25 16:27:52.956 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:27:52.978 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 210.0909090909091, 'equality': 0.9195153613170309, 'sustainability': 488.383878248964, 'peace': 735.0}\n",
      "2021-08-25 16:27:52.979 | INFO     | src.policies:train:122 - Mean episode return: 210.0909090909091\n",
      "2021-08-25 16:27:52.980 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.84909090909088\n",
      "2021-08-25 16:27:52.980 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:28:02.288 | INFO     | src.policies:train:159 - Total loss: 1.0053596496582031\n",
      "2021-08-25 16:28:02.289 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 210.0909090909091, 'equality': 0.9195153613170309, 'sustainability': 488.383878248964, 'peace': 735.0}\n",
      "2021-08-25 16:28:02.336 | INFO     | src.policies:train:103 - Epoch 361 / 4000\n",
      "2021-08-25 16:28:02.337 | INFO     | src.policies:train:110 - Episode 361\n",
      "2021-08-25 16:28:27.160 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:28:27.185 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 209.36363636363637, 'equality': 0.9144199265796704, 'sustainability': 508.81124150791305, 'peace': 697.7272727272727}\n",
      "2021-08-25 16:28:27.186 | INFO     | src.policies:train:122 - Mean episode return: 209.36363636363637\n",
      "2021-08-25 16:28:27.187 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.8381818181818\n",
      "2021-08-25 16:28:27.187 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:28:36.826 | INFO     | src.policies:train:159 - Total loss: 0.9989141821861267\n",
      "2021-08-25 16:28:36.827 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 209.36363636363637, 'equality': 0.9144199265796704, 'sustainability': 508.81124150791305, 'peace': 697.7272727272727}\n",
      "2021-08-25 16:28:36.877 | INFO     | src.policies:train:103 - Epoch 362 / 4000\n",
      "2021-08-25 16:28:36.878 | INFO     | src.policies:train:110 - Episode 362\n",
      "2021-08-25 16:29:01.085 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:29:01.108 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 217.9090909090909, 'equality': 0.946903326128363, 'sustainability': 493.8225512809513, 'peace': 794.7272727272727}\n",
      "2021-08-25 16:29:01.109 | INFO     | src.policies:train:122 - Mean episode return: 217.9090909090909\n",
      "2021-08-25 16:29:01.110 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.92363636363635\n",
      "2021-08-25 16:29:01.110 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:29:10.720 | INFO     | src.policies:train:159 - Total loss: 1.0005396604537964\n",
      "2021-08-25 16:29:10.721 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 217.9090909090909, 'equality': 0.946903326128363, 'sustainability': 493.8225512809513, 'peace': 794.7272727272727}\n",
      "2021-08-25 16:29:10.771 | INFO     | src.policies:train:103 - Epoch 363 / 4000\n",
      "2021-08-25 16:29:10.772 | INFO     | src.policies:train:110 - Episode 363\n",
      "2021-08-25 16:29:34.689 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:29:34.717 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 209.45454545454547, 'equality': 0.9306344696983382, 'sustainability': 479.0632992744802, 'peace': 748.6363636363636}\n",
      "2021-08-25 16:29:34.717 | INFO     | src.policies:train:122 - Mean episode return: 209.45454545454547\n",
      "2021-08-25 16:29:34.718 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.0581818181818\n",
      "2021-08-25 16:29:34.718 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:29:44.303 | INFO     | src.policies:train:159 - Total loss: 0.9970093965530396\n",
      "2021-08-25 16:29:44.304 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 209.45454545454547, 'equality': 0.9306344696983382, 'sustainability': 479.0632992744802, 'peace': 748.6363636363636}\n",
      "2021-08-25 16:29:44.353 | INFO     | src.policies:train:103 - Epoch 364 / 4000\n",
      "2021-08-25 16:29:44.354 | INFO     | src.policies:train:110 - Episode 364\n",
      "2021-08-25 16:30:07.908 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:30:07.934 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 211.0, 'equality': 0.9521366182297573, 'sustainability': 497.1493175508536, 'peace': 696.9090909090909}\n",
      "2021-08-25 16:30:07.934 | INFO     | src.policies:train:122 - Mean episode return: 211.0\n",
      "2021-08-25 16:30:07.935 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.0190909090909\n",
      "2021-08-25 16:30:07.935 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:30:17.479 | INFO     | src.policies:train:159 - Total loss: 1.00301992893219\n",
      "2021-08-25 16:30:17.480 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 211.0, 'equality': 0.9521366182297573, 'sustainability': 497.1493175508536, 'peace': 696.9090909090909}\n",
      "2021-08-25 16:30:17.528 | INFO     | src.policies:train:103 - Epoch 365 / 4000\n",
      "2021-08-25 16:30:17.529 | INFO     | src.policies:train:110 - Episode 365\n",
      "2021-08-25 16:30:41.119 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:30:41.144 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 197.63636363636363, 'equality': 0.9039056619573491, 'sustainability': 453.8474170332601, 'peace': 682.2727272727273}\n",
      "2021-08-25 16:30:41.145 | INFO     | src.policies:train:122 - Mean episode return: 197.63636363636363\n",
      "2021-08-25 16:30:41.145 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.8990909090909\n",
      "2021-08-25 16:30:41.146 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:30:50.756 | INFO     | src.policies:train:159 - Total loss: 1.0025311708450317\n",
      "2021-08-25 16:30:50.757 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 197.63636363636363, 'equality': 0.9039056619573491, 'sustainability': 453.8474170332601, 'peace': 682.2727272727273}\n",
      "2021-08-25 16:30:50.807 | INFO     | src.policies:train:103 - Epoch 366 / 4000\n",
      "2021-08-25 16:30:50.808 | INFO     | src.policies:train:110 - Episode 366\n",
      "2021-08-25 16:31:14.816 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:31:14.840 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 199.27272727272728, 'equality': 0.920122760452884, 'sustainability': 484.91217911797963, 'peace': 642.8181818181819}\n",
      "2021-08-25 16:31:14.840 | INFO     | src.policies:train:122 - Mean episode return: 199.27272727272728\n",
      "2021-08-25 16:31:14.841 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.79636363636365\n",
      "2021-08-25 16:31:14.841 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:31:24.436 | INFO     | src.policies:train:159 - Total loss: 0.9961978793144226\n",
      "2021-08-25 16:31:24.437 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 199.27272727272728, 'equality': 0.920122760452884, 'sustainability': 484.91217911797963, 'peace': 642.8181818181819}\n",
      "2021-08-25 16:31:24.488 | INFO     | src.policies:train:103 - Epoch 367 / 4000\n",
      "2021-08-25 16:31:24.488 | INFO     | src.policies:train:110 - Episode 367\n",
      "2021-08-25 16:31:49.162 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 16:31:49.184 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 217.54545454545453, 'equality': 0.9475743646250888, 'sustainability': 504.96602063847945, 'peace': 729.3636363636364}\n",
      "2021-08-25 16:31:49.185 | INFO     | src.policies:train:122 - Mean episode return: 217.54545454545453\n",
      "2021-08-25 16:31:49.186 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.94454545454548\n",
      "2021-08-25 16:31:49.186 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:31:58.828 | INFO     | src.policies:train:159 - Total loss: 0.9983823299407959\n",
      "2021-08-25 16:31:58.829 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 217.54545454545453, 'equality': 0.9475743646250888, 'sustainability': 504.96602063847945, 'peace': 729.3636363636364}\n",
      "2021-08-25 16:31:58.879 | INFO     | src.policies:train:103 - Epoch 368 / 4000\n",
      "2021-08-25 16:31:58.879 | INFO     | src.policies:train:110 - Episode 368\n",
      "2021-08-25 16:32:22.309 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:32:22.332 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 186.36363636363637, 'equality': 0.8891352549913717, 'sustainability': 460.2736576008363, 'peace': 599.6363636363636}\n",
      "2021-08-25 16:32:22.333 | INFO     | src.policies:train:122 - Mean episode return: 186.36363636363637\n",
      "2021-08-25 16:32:22.333 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.96\n",
      "2021-08-25 16:32:22.334 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:32:32.369 | INFO     | src.policies:train:159 - Total loss: 1.0076375007629395\n",
      "2021-08-25 16:32:32.370 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 186.36363636363637, 'equality': 0.8891352549913717, 'sustainability': 460.2736576008363, 'peace': 599.6363636363636}\n",
      "2021-08-25 16:32:32.424 | INFO     | src.policies:train:103 - Epoch 369 / 4000\n",
      "2021-08-25 16:32:32.425 | INFO     | src.policies:train:110 - Episode 369\n",
      "2021-08-25 16:32:58.162 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:32:58.188 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 218.36363636363637, 'equality': 0.9341457876024876, 'sustainability': 497.1292344933434, 'peace': 706.5454545454545}\n",
      "2021-08-25 16:32:58.189 | INFO     | src.policies:train:122 - Mean episode return: 218.36363636363637\n",
      "2021-08-25 16:32:58.189 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.88181818181818\n",
      "2021-08-25 16:32:58.190 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:33:08.383 | INFO     | src.policies:train:159 - Total loss: 1.0053510665893555\n",
      "2021-08-25 16:33:08.384 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 218.36363636363637, 'equality': 0.9341457876024876, 'sustainability': 497.1292344933434, 'peace': 706.5454545454545}\n",
      "2021-08-25 16:33:08.437 | INFO     | src.policies:train:103 - Epoch 370 / 4000\n",
      "2021-08-25 16:33:08.438 | INFO     | src.policies:train:110 - Episode 370\n",
      "2021-08-25 16:33:33.879 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:33:33.905 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 211.0909090909091, 'equality': 0.9345391903544252, 'sustainability': 479.7420205474557, 'peace': 666.2727272727273}\n",
      "2021-08-25 16:33:33.906 | INFO     | src.policies:train:122 - Mean episode return: 211.0909090909091\n",
      "2021-08-25 16:33:33.906 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.90454545454548\n",
      "2021-08-25 16:33:33.907 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:33:44.153 | INFO     | src.policies:train:159 - Total loss: 1.0036159753799438\n",
      "2021-08-25 16:33:44.154 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 211.0909090909091, 'equality': 0.9345391903544252, 'sustainability': 479.7420205474557, 'peace': 666.2727272727273}\n",
      "2021-08-25 16:33:44.208 | INFO     | src.policies:train:103 - Epoch 371 / 4000\n",
      "2021-08-25 16:33:44.208 | INFO     | src.policies:train:110 - Episode 371\n",
      "2021-08-25 16:34:10.723 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:34:10.751 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 219.9090909090909, 'equality': 0.9303994888960427, 'sustainability': 485.94815018622035, 'peace': 727.5454545454545}\n",
      "2021-08-25 16:34:10.751 | INFO     | src.policies:train:122 - Mean episode return: 219.9090909090909\n",
      "2021-08-25 16:34:10.752 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.9281818181818\n",
      "2021-08-25 16:34:10.752 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:34:21.313 | INFO     | src.policies:train:159 - Total loss: 0.9985294938087463\n",
      "2021-08-25 16:34:21.314 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 219.9090909090909, 'equality': 0.9303994888960427, 'sustainability': 485.94815018622035, 'peace': 727.5454545454545}\n",
      "2021-08-25 16:34:21.369 | INFO     | src.policies:train:103 - Epoch 372 / 4000\n",
      "2021-08-25 16:34:21.370 | INFO     | src.policies:train:110 - Episode 372\n",
      "2021-08-25 16:34:48.933 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:34:48.960 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 218.63636363636363, 'equality': 0.9328671328684017, 'sustainability': 494.73299720695616, 'peace': 728.9090909090909}\n",
      "2021-08-25 16:34:48.961 | INFO     | src.policies:train:122 - Mean episode return: 218.63636363636363\n",
      "2021-08-25 16:34:48.962 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.16\n",
      "2021-08-25 16:34:48.962 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:34:59.628 | INFO     | src.policies:train:159 - Total loss: 0.997762143611908\n",
      "2021-08-25 16:34:59.629 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 218.63636363636363, 'equality': 0.9328671328684017, 'sustainability': 494.73299720695616, 'peace': 728.9090909090909}\n",
      "2021-08-25 16:34:59.687 | INFO     | src.policies:train:103 - Epoch 373 / 4000\n",
      "2021-08-25 16:34:59.688 | INFO     | src.policies:train:110 - Episode 373\n",
      "2021-08-25 16:35:26.709 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:35:26.736 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 217.72727272727272, 'equality': 0.9441260201187298, 'sustainability': 494.7935650556865, 'peace': 714.3636363636364}\n",
      "2021-08-25 16:35:26.737 | INFO     | src.policies:train:122 - Mean episode return: 217.72727272727272\n",
      "2021-08-25 16:35:26.738 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.27999999999997\n",
      "2021-08-25 16:35:26.738 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:35:38.402 | INFO     | src.policies:train:159 - Total loss: 1.0008419752120972\n",
      "2021-08-25 16:35:38.403 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 217.72727272727272, 'equality': 0.9441260201187298, 'sustainability': 494.7935650556865, 'peace': 714.3636363636364}\n",
      "2021-08-25 16:35:38.463 | INFO     | src.policies:train:103 - Epoch 374 / 4000\n",
      "2021-08-25 16:35:38.464 | INFO     | src.policies:train:110 - Episode 374\n",
      "2021-08-25 16:36:06.501 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:36:06.529 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 198.9090909090909, 'equality': 0.9398371281381952, 'sustainability': 477.8405902564451, 'peace': 710.0909090909091}\n",
      "2021-08-25 16:36:06.530 | INFO     | src.policies:train:122 - Mean episode return: 198.9090909090909\n",
      "2021-08-25 16:36:06.531 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.1818181818182\n",
      "2021-08-25 16:36:06.531 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:36:17.052 | INFO     | src.policies:train:159 - Total loss: 1.0041158199310303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 16:36:17.053 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 198.9090909090909, 'equality': 0.9398371281381952, 'sustainability': 477.8405902564451, 'peace': 710.0909090909091}\n",
      "2021-08-25 16:36:17.107 | INFO     | src.policies:train:103 - Epoch 375 / 4000\n",
      "2021-08-25 16:36:17.108 | INFO     | src.policies:train:110 - Episode 375\n",
      "2021-08-25 16:36:43.255 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:36:43.279 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 230.0, 'equality': 0.9458857348195133, 'sustainability': 494.88911944142825, 'peace': 746.0}\n",
      "2021-08-25 16:36:43.280 | INFO     | src.policies:train:122 - Mean episode return: 230.0\n",
      "2021-08-25 16:36:43.281 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.55636363636364\n",
      "2021-08-25 16:36:43.281 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:36:52.878 | INFO     | src.policies:train:159 - Total loss: 0.9985874891281128\n",
      "2021-08-25 16:36:52.879 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 230.0, 'equality': 0.9458857348195133, 'sustainability': 494.88911944142825, 'peace': 746.0}\n",
      "2021-08-25 16:36:52.931 | INFO     | src.policies:train:103 - Epoch 376 / 4000\n",
      "2021-08-25 16:36:52.932 | INFO     | src.policies:train:110 - Episode 376\n",
      "2021-08-25 16:37:16.575 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:37:16.598 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 204.8181818181818, 'equality': 0.9402009441968244, 'sustainability': 478.3270014831473, 'peace': 669.0909090909091}\n",
      "2021-08-25 16:37:16.599 | INFO     | src.policies:train:122 - Mean episode return: 204.8181818181818\n",
      "2021-08-25 16:37:16.600 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.60090909090908\n",
      "2021-08-25 16:37:16.600 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:37:26.180 | INFO     | src.policies:train:159 - Total loss: 0.9988436102867126\n",
      "2021-08-25 16:37:26.181 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 204.8181818181818, 'equality': 0.9402009441968244, 'sustainability': 478.3270014831473, 'peace': 669.0909090909091}\n",
      "2021-08-25 16:37:26.232 | INFO     | src.policies:train:103 - Epoch 377 / 4000\n",
      "2021-08-25 16:37:26.232 | INFO     | src.policies:train:110 - Episode 377\n",
      "2021-08-25 16:37:51.137 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:37:51.163 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 207.72727272727272, 'equality': 0.9267157350322913, 'sustainability': 480.35745613245655, 'peace': 730.9090909090909}\n",
      "2021-08-25 16:37:51.164 | INFO     | src.policies:train:122 - Mean episode return: 207.72727272727272\n",
      "2021-08-25 16:37:51.164 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.7563636363636\n",
      "2021-08-25 16:37:51.164 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:38:00.764 | INFO     | src.policies:train:159 - Total loss: 1.0005265474319458\n",
      "2021-08-25 16:38:00.765 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 207.72727272727272, 'equality': 0.9267157350322913, 'sustainability': 480.35745613245655, 'peace': 730.9090909090909}\n",
      "2021-08-25 16:38:00.816 | INFO     | src.policies:train:103 - Epoch 378 / 4000\n",
      "2021-08-25 16:38:00.817 | INFO     | src.policies:train:110 - Episode 378\n",
      "2021-08-25 16:38:26.050 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:38:26.074 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 206.0, 'equality': 0.9390194977144544, 'sustainability': 517.391992242365, 'peace': 721.1818181818181}\n",
      "2021-08-25 16:38:26.075 | INFO     | src.policies:train:122 - Mean episode return: 206.0\n",
      "2021-08-25 16:38:26.076 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.6481818181818\n",
      "2021-08-25 16:38:26.076 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:38:35.856 | INFO     | src.policies:train:159 - Total loss: 1.000372290611267\n",
      "2021-08-25 16:38:35.857 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 206.0, 'equality': 0.9390194977144544, 'sustainability': 517.391992242365, 'peace': 721.1818181818181}\n",
      "2021-08-25 16:38:35.908 | INFO     | src.policies:train:103 - Epoch 379 / 4000\n",
      "2021-08-25 16:38:35.909 | INFO     | src.policies:train:110 - Episode 379\n",
      "2021-08-25 16:39:00.047 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:39:00.070 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 210.0, 'equality': 0.905234159781479, 'sustainability': 498.65455102409794, 'peace': 724.6363636363636}\n",
      "2021-08-25 16:39:00.071 | INFO     | src.policies:train:122 - Mean episode return: 210.0\n",
      "2021-08-25 16:39:00.071 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.99363636363637\n",
      "2021-08-25 16:39:00.072 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:39:09.361 | INFO     | src.policies:train:159 - Total loss: 1.011091947555542\n",
      "2021-08-25 16:39:09.362 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 210.0, 'equality': 0.905234159781479, 'sustainability': 498.65455102409794, 'peace': 724.6363636363636}\n",
      "2021-08-25 16:39:09.411 | INFO     | src.policies:train:103 - Epoch 380 / 4000\n",
      "2021-08-25 16:39:09.411 | INFO     | src.policies:train:110 - Episode 380\n",
      "2021-08-25 16:39:31.195 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:39:31.217 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 207.27272727272728, 'equality': 0.9159489633190601, 'sustainability': 493.9146329617493, 'peace': 780.4545454545455}\n",
      "2021-08-25 16:39:31.218 | INFO     | src.policies:train:122 - Mean episode return: 207.27272727272728\n",
      "2021-08-25 16:39:31.218 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.91636363636363\n",
      "2021-08-25 16:39:31.218 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:39:39.997 | INFO     | src.policies:train:159 - Total loss: 0.9979215860366821\n",
      "2021-08-25 16:39:39.998 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 207.27272727272728, 'equality': 0.9159489633190601, 'sustainability': 493.9146329617493, 'peace': 780.4545454545455}\n",
      "2021-08-25 16:39:40.047 | INFO     | src.policies:train:103 - Epoch 381 / 4000\n",
      "2021-08-25 16:39:40.047 | INFO     | src.policies:train:110 - Episode 381\n",
      "2021-08-25 16:40:01.992 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:40:02.015 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 205.36363636363637, 'equality': 0.9325526178129391, 'sustainability': 463.1148582059752, 'peace': 686.4545454545455}\n",
      "2021-08-25 16:40:02.015 | INFO     | src.policies:train:122 - Mean episode return: 205.36363636363637\n",
      "2021-08-25 16:40:02.016 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.05818181818185\n",
      "2021-08-25 16:40:02.016 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:40:10.835 | INFO     | src.policies:train:159 - Total loss: 0.9998571872711182\n",
      "2021-08-25 16:40:10.836 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 205.36363636363637, 'equality': 0.9325526178129391, 'sustainability': 463.1148582059752, 'peace': 686.4545454545455}\n",
      "2021-08-25 16:40:10.883 | INFO     | src.policies:train:103 - Epoch 382 / 4000\n",
      "2021-08-25 16:40:10.883 | INFO     | src.policies:train:110 - Episode 382\n",
      "2021-08-25 16:40:32.187 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:40:32.217 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 200.36363636363637, 'equality': 0.9240224385430618, 'sustainability': 477.4693446089714, 'peace': 716.5454545454545}\n",
      "2021-08-25 16:40:32.217 | INFO     | src.policies:train:122 - Mean episode return: 200.36363636363637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 16:40:32.218 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.12454545454548\n",
      "2021-08-25 16:40:32.218 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:40:41.053 | INFO     | src.policies:train:159 - Total loss: 1.0026084184646606\n",
      "2021-08-25 16:40:41.054 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 200.36363636363637, 'equality': 0.9240224385430618, 'sustainability': 477.4693446089714, 'peace': 716.5454545454545}\n",
      "2021-08-25 16:40:41.106 | INFO     | src.policies:train:103 - Epoch 383 / 4000\n",
      "2021-08-25 16:40:41.107 | INFO     | src.policies:train:110 - Episode 383\n",
      "2021-08-25 16:41:04.754 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:41:04.779 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 194.27272727272728, 'equality': 0.8904156208812181, 'sustainability': 497.466122590218, 'peace': 696.7272727272727}\n",
      "2021-08-25 16:41:04.780 | INFO     | src.policies:train:122 - Mean episode return: 194.27272727272728\n",
      "2021-08-25 16:41:04.781 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.03090909090912\n",
      "2021-08-25 16:41:04.781 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:41:14.236 | INFO     | src.policies:train:159 - Total loss: 0.9912996292114258\n",
      "2021-08-25 16:41:14.237 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 194.27272727272728, 'equality': 0.8904156208812181, 'sustainability': 497.466122590218, 'peace': 696.7272727272727}\n",
      "2021-08-25 16:41:14.289 | INFO     | src.policies:train:103 - Epoch 384 / 4000\n",
      "2021-08-25 16:41:14.289 | INFO     | src.policies:train:110 - Episode 384\n",
      "2021-08-25 16:41:37.893 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:41:37.919 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 209.8181818181818, 'equality': 0.9239010556183256, 'sustainability': 470.20087629915855, 'peace': 700.1818181818181}\n",
      "2021-08-25 16:41:37.919 | INFO     | src.policies:train:122 - Mean episode return: 209.8181818181818\n",
      "2021-08-25 16:41:37.920 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.95272727272723\n",
      "2021-08-25 16:41:37.920 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:41:47.317 | INFO     | src.policies:train:159 - Total loss: 1.0010960102081299\n",
      "2021-08-25 16:41:47.318 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 209.8181818181818, 'equality': 0.9239010556183256, 'sustainability': 470.20087629915855, 'peace': 700.1818181818181}\n",
      "2021-08-25 16:41:47.369 | INFO     | src.policies:train:103 - Epoch 385 / 4000\n",
      "2021-08-25 16:41:47.370 | INFO     | src.policies:train:110 - Episode 385\n",
      "2021-08-25 16:42:11.585 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:42:11.610 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 206.72727272727272, 'equality': 0.8889421923744915, 'sustainability': 472.3784309674023, 'peace': 662.0}\n",
      "2021-08-25 16:42:11.611 | INFO     | src.policies:train:122 - Mean episode return: 206.72727272727272\n",
      "2021-08-25 16:42:11.612 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.83\n",
      "2021-08-25 16:42:11.612 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:42:21.367 | INFO     | src.policies:train:159 - Total loss: 1.0022449493408203\n",
      "2021-08-25 16:42:21.368 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 206.72727272727272, 'equality': 0.8889421923744915, 'sustainability': 472.3784309674023, 'peace': 662.0}\n",
      "2021-08-25 16:42:21.422 | INFO     | src.policies:train:103 - Epoch 386 / 4000\n",
      "2021-08-25 16:42:21.422 | INFO     | src.policies:train:110 - Episode 386\n",
      "2021-08-25 16:42:44.713 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:42:44.734 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 221.72727272727272, 'equality': 0.9265719929940257, 'sustainability': 500.98833036005703, 'peace': 813.4545454545455}\n",
      "2021-08-25 16:42:44.735 | INFO     | src.policies:train:122 - Mean episode return: 221.72727272727272\n",
      "2021-08-25 16:42:44.736 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.90181818181816\n",
      "2021-08-25 16:42:44.736 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:42:53.415 | INFO     | src.policies:train:159 - Total loss: 1.0022399425506592\n",
      "2021-08-25 16:42:53.415 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 221.72727272727272, 'equality': 0.9265719929940257, 'sustainability': 500.98833036005703, 'peace': 813.4545454545455}\n",
      "2021-08-25 16:42:53.462 | INFO     | src.policies:train:103 - Epoch 387 / 4000\n",
      "2021-08-25 16:42:53.463 | INFO     | src.policies:train:110 - Episode 387\n",
      "2021-08-25 16:43:13.720 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:43:13.744 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 207.54545454545453, 'equality': 0.9261736949005261, 'sustainability': 492.4143153971438, 'peace': 732.5454545454545}\n",
      "2021-08-25 16:43:13.744 | INFO     | src.policies:train:122 - Mean episode return: 207.54545454545453\n",
      "2021-08-25 16:43:13.745 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.8681818181818\n",
      "2021-08-25 16:43:13.745 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:43:22.194 | INFO     | src.policies:train:159 - Total loss: 0.9961262345314026\n",
      "2021-08-25 16:43:22.195 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 207.54545454545453, 'equality': 0.9261736949005261, 'sustainability': 492.4143153971438, 'peace': 732.5454545454545}\n",
      "2021-08-25 16:43:22.240 | INFO     | src.policies:train:103 - Epoch 388 / 4000\n",
      "2021-08-25 16:43:22.241 | INFO     | src.policies:train:110 - Episode 388\n",
      "2021-08-25 16:43:43.066 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:43:43.090 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 206.54545454545453, 'equality': 0.9122119078122557, 'sustainability': 471.0390061479988, 'peace': 668.4545454545455}\n",
      "2021-08-25 16:43:43.090 | INFO     | src.policies:train:122 - Mean episode return: 206.54545454545453\n",
      "2021-08-25 16:43:43.091 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.80545454545455\n",
      "2021-08-25 16:43:43.091 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:43:51.480 | INFO     | src.policies:train:159 - Total loss: 1.0053373575210571\n",
      "2021-08-25 16:43:51.481 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 206.54545454545453, 'equality': 0.9122119078122557, 'sustainability': 471.0390061479988, 'peace': 668.4545454545455}\n",
      "2021-08-25 16:43:51.531 | INFO     | src.policies:train:103 - Epoch 389 / 4000\n",
      "2021-08-25 16:43:51.531 | INFO     | src.policies:train:110 - Episode 389\n",
      "2021-08-25 16:44:12.043 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:44:12.065 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 220.0909090909091, 'equality': 0.8997409034602579, 'sustainability': 491.93234414776435, 'peace': 736.2727272727273}\n",
      "2021-08-25 16:44:12.066 | INFO     | src.policies:train:122 - Mean episode return: 220.0909090909091\n",
      "2021-08-25 16:44:12.067 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.09272727272727\n",
      "2021-08-25 16:44:12.067 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:44:20.442 | INFO     | src.policies:train:159 - Total loss: 1.0004351139068604\n",
      "2021-08-25 16:44:20.442 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 220.0909090909091, 'equality': 0.8997409034602579, 'sustainability': 491.93234414776435, 'peace': 736.2727272727273}\n",
      "2021-08-25 16:44:20.489 | INFO     | src.policies:train:103 - Epoch 390 / 4000\n",
      "2021-08-25 16:44:20.490 | INFO     | src.policies:train:110 - Episode 390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 16:44:41.276 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:44:41.298 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 211.27272727272728, 'equality': 0.9112814895964778, 'sustainability': 486.9548381510411, 'peace': 714.1818181818181}\n",
      "2021-08-25 16:44:41.299 | INFO     | src.policies:train:122 - Mean episode return: 211.27272727272728\n",
      "2021-08-25 16:44:41.300 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.98545454545456\n",
      "2021-08-25 16:44:41.300 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:44:49.801 | INFO     | src.policies:train:159 - Total loss: 1.0043658018112183\n",
      "2021-08-25 16:44:49.802 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 211.27272727272728, 'equality': 0.9112814895964778, 'sustainability': 486.9548381510411, 'peace': 714.1818181818181}\n",
      "2021-08-25 16:44:49.847 | INFO     | src.policies:train:103 - Epoch 391 / 4000\n",
      "2021-08-25 16:44:49.848 | INFO     | src.policies:train:110 - Episode 391\n",
      "2021-08-25 16:45:10.303 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:45:10.325 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 202.36363636363637, 'equality': 0.883851997061916, 'sustainability': 450.3916922353563, 'peace': 612.9090909090909}\n",
      "2021-08-25 16:45:10.326 | INFO     | src.policies:train:122 - Mean episode return: 202.36363636363637\n",
      "2021-08-25 16:45:10.327 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.15636363636364\n",
      "2021-08-25 16:45:10.327 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:45:18.792 | INFO     | src.policies:train:159 - Total loss: 0.9984099268913269\n",
      "2021-08-25 16:45:18.792 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 202.36363636363637, 'equality': 0.883851997061916, 'sustainability': 450.3916922353563, 'peace': 612.9090909090909}\n",
      "2021-08-25 16:45:18.841 | INFO     | src.policies:train:103 - Epoch 392 / 4000\n",
      "2021-08-25 16:45:18.841 | INFO     | src.policies:train:110 - Episode 392\n",
      "2021-08-25 16:45:40.942 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:45:40.965 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 201.8181818181818, 'equality': 0.918099918101595, 'sustainability': 478.7841971715743, 'peace': 721.6363636363636}\n",
      "2021-08-25 16:45:40.965 | INFO     | src.policies:train:122 - Mean episode return: 201.8181818181818\n",
      "2021-08-25 16:45:40.966 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.09909090909088\n",
      "2021-08-25 16:45:40.966 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:45:49.475 | INFO     | src.policies:train:159 - Total loss: 0.9947540163993835\n",
      "2021-08-25 16:45:49.476 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 201.8181818181818, 'equality': 0.918099918101595, 'sustainability': 478.7841971715743, 'peace': 721.6363636363636}\n",
      "2021-08-25 16:45:49.529 | INFO     | src.policies:train:103 - Epoch 393 / 4000\n",
      "2021-08-25 16:45:49.529 | INFO     | src.policies:train:110 - Episode 393\n",
      "2021-08-25 16:46:10.886 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:46:10.911 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 207.0, 'equality': 0.9593564099501066, 'sustainability': 487.4095503072589, 'peace': 697.7272727272727}\n",
      "2021-08-25 16:46:10.911 | INFO     | src.policies:train:122 - Mean episode return: 207.0\n",
      "2021-08-25 16:46:10.912 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.13545454545454\n",
      "2021-08-25 16:46:10.912 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:46:19.333 | INFO     | src.policies:train:159 - Total loss: 1.0005985498428345\n",
      "2021-08-25 16:46:19.333 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 207.0, 'equality': 0.9593564099501066, 'sustainability': 487.4095503072589, 'peace': 697.7272727272727}\n",
      "2021-08-25 16:46:19.381 | INFO     | src.policies:train:103 - Epoch 394 / 4000\n",
      "2021-08-25 16:46:19.382 | INFO     | src.policies:train:110 - Episode 394\n",
      "2021-08-25 16:46:39.675 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:46:39.695 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 198.8181818181818, 'equality': 0.8651535935514579, 'sustainability': 477.2525083600323, 'peace': 721.9090909090909}\n",
      "2021-08-25 16:46:39.696 | INFO     | src.policies:train:122 - Mean episode return: 198.8181818181818\n",
      "2021-08-25 16:46:39.696 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.9545454545454\n",
      "2021-08-25 16:46:39.697 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:46:48.084 | INFO     | src.policies:train:159 - Total loss: 1.0043977499008179\n",
      "2021-08-25 16:46:48.084 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 198.8181818181818, 'equality': 0.8651535935514579, 'sustainability': 477.2525083600323, 'peace': 721.9090909090909}\n",
      "2021-08-25 16:46:48.132 | INFO     | src.policies:train:103 - Epoch 395 / 4000\n",
      "2021-08-25 16:46:48.132 | INFO     | src.policies:train:110 - Episode 395\n",
      "2021-08-25 16:47:09.065 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:47:09.085 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 202.9090909090909, 'equality': 0.9160149885973441, 'sustainability': 483.51790062626316, 'peace': 756.1818181818181}\n",
      "2021-08-25 16:47:09.086 | INFO     | src.policies:train:122 - Mean episode return: 202.9090909090909\n",
      "2021-08-25 16:47:09.087 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.9709090909091\n",
      "2021-08-25 16:47:09.087 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:47:17.545 | INFO     | src.policies:train:159 - Total loss: 1.001139760017395\n",
      "2021-08-25 16:47:17.546 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 202.9090909090909, 'equality': 0.9160149885973441, 'sustainability': 483.51790062626316, 'peace': 756.1818181818181}\n",
      "2021-08-25 16:47:17.590 | INFO     | src.policies:train:103 - Epoch 396 / 4000\n",
      "2021-08-25 16:47:17.591 | INFO     | src.policies:train:110 - Episode 396\n",
      "2021-08-25 16:47:38.589 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:47:38.615 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 206.72727272727272, 'equality': 0.8839849684200051, 'sustainability': 476.29414373819435, 'peace': 707.1818181818181}\n",
      "2021-08-25 16:47:38.616 | INFO     | src.policies:train:122 - Mean episode return: 206.72727272727272\n",
      "2021-08-25 16:47:38.616 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.83636363636361\n",
      "2021-08-25 16:47:38.617 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:47:47.033 | INFO     | src.policies:train:159 - Total loss: 1.002779483795166\n",
      "2021-08-25 16:47:47.034 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 206.72727272727272, 'equality': 0.8839849684200051, 'sustainability': 476.29414373819435, 'peace': 707.1818181818181}\n",
      "2021-08-25 16:47:47.080 | INFO     | src.policies:train:103 - Epoch 397 / 4000\n",
      "2021-08-25 16:47:47.080 | INFO     | src.policies:train:110 - Episode 397\n",
      "2021-08-25 16:48:08.253 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:48:08.275 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 212.9090909090909, 'equality': 0.9470538001718218, 'sustainability': 502.32502450448214, 'peace': 746.2727272727273}\n",
      "2021-08-25 16:48:08.276 | INFO     | src.policies:train:122 - Mean episode return: 212.9090909090909\n",
      "2021-08-25 16:48:08.276 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.87818181818182\n",
      "2021-08-25 16:48:08.277 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 16:48:16.852 | INFO     | src.policies:train:159 - Total loss: 0.9996019601821899\n",
      "2021-08-25 16:48:16.853 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 212.9090909090909, 'equality': 0.9470538001718218, 'sustainability': 502.32502450448214, 'peace': 746.2727272727273}\n",
      "2021-08-25 16:48:16.901 | INFO     | src.policies:train:103 - Epoch 398 / 4000\n",
      "2021-08-25 16:48:16.901 | INFO     | src.policies:train:110 - Episode 398\n",
      "2021-08-25 16:48:38.078 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:48:38.102 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 187.63636363636363, 'equality': 0.8816067653303029, 'sustainability': 465.1264923501723, 'peace': 696.0909090909091}\n",
      "2021-08-25 16:48:38.102 | INFO     | src.policies:train:122 - Mean episode return: 187.63636363636363\n",
      "2021-08-25 16:48:38.103 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.67363636363635\n",
      "2021-08-25 16:48:38.103 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:48:46.461 | INFO     | src.policies:train:159 - Total loss: 1.003524661064148\n",
      "2021-08-25 16:48:46.461 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 187.63636363636363, 'equality': 0.8816067653303029, 'sustainability': 465.1264923501723, 'peace': 696.0909090909091}\n",
      "2021-08-25 16:48:46.509 | INFO     | src.policies:train:103 - Epoch 399 / 4000\n",
      "2021-08-25 16:48:46.510 | INFO     | src.policies:train:110 - Episode 399\n",
      "2021-08-25 16:49:07.684 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:49:07.709 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 227.0, 'equality': 0.9492481887364974, 'sustainability': 501.9530308584492, 'peace': 746.2727272727273}\n",
      "2021-08-25 16:49:07.710 | INFO     | src.policies:train:122 - Mean episode return: 227.0\n",
      "2021-08-25 16:49:07.711 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.6536363636364\n",
      "2021-08-25 16:49:07.711 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:49:16.287 | INFO     | src.policies:train:159 - Total loss: 0.9951976537704468\n",
      "2021-08-25 16:49:16.289 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 227.0, 'equality': 0.9492481887364974, 'sustainability': 501.9530308584492, 'peace': 746.2727272727273}\n",
      "2021-08-25 16:49:16.356 | INFO     | src.policies:train:103 - Epoch 400 / 4000\n",
      "2021-08-25 16:49:16.357 | INFO     | src.policies:train:110 - Episode 400\n",
      "2021-08-25 16:49:37.298 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:49:37.319 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 201.1818181818182, 'equality': 0.9348478001903042, 'sustainability': 495.4535762544146, 'peace': 697.0909090909091}\n",
      "2021-08-25 16:49:37.319 | INFO     | src.policies:train:122 - Mean episode return: 201.1818181818182\n",
      "2021-08-25 16:49:37.320 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.5954545454546\n",
      "2021-08-25 16:49:37.320 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:49:45.605 | INFO     | src.policies:train:159 - Total loss: 0.9941492080688477\n",
      "2021-08-25 16:49:45.606 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 201.1818181818182, 'equality': 0.9348478001903042, 'sustainability': 495.4535762544146, 'peace': 697.0909090909091}\n",
      "2021-08-25 16:49:45.652 | INFO     | src.policies:train:103 - Epoch 401 / 4000\n",
      "2021-08-25 16:49:45.653 | INFO     | src.policies:train:110 - Episode 401\n",
      "2021-08-25 16:50:06.570 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:50:06.595 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 199.8181818181818, 'equality': 0.9247249565736471, 'sustainability': 494.1140274276673, 'peace': 680.7272727272727}\n",
      "2021-08-25 16:50:06.595 | INFO     | src.policies:train:122 - Mean episode return: 199.8181818181818\n",
      "2021-08-25 16:50:06.596 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.7381818181818\n",
      "2021-08-25 16:50:06.596 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:50:14.352 | INFO     | src.policies:train:159 - Total loss: 0.999282717704773\n",
      "2021-08-25 16:50:14.353 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 199.8181818181818, 'equality': 0.9247249565736471, 'sustainability': 494.1140274276673, 'peace': 680.7272727272727}\n",
      "2021-08-25 16:50:14.398 | INFO     | src.policies:train:103 - Epoch 402 / 4000\n",
      "2021-08-25 16:50:14.398 | INFO     | src.policies:train:110 - Episode 402\n",
      "2021-08-25 16:50:35.254 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:50:35.274 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 212.9090909090909, 'equality': 0.9332349972841154, 'sustainability': 535.4572314656124, 'peace': 802.3636363636364}\n",
      "2021-08-25 16:50:35.275 | INFO     | src.policies:train:122 - Mean episode return: 212.9090909090909\n",
      "2021-08-25 16:50:35.276 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.90454545454548\n",
      "2021-08-25 16:50:35.276 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:50:43.685 | INFO     | src.policies:train:159 - Total loss: 1.001948595046997\n",
      "2021-08-25 16:50:43.686 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 212.9090909090909, 'equality': 0.9332349972841154, 'sustainability': 535.4572314656124, 'peace': 802.3636363636364}\n",
      "2021-08-25 16:50:43.731 | INFO     | src.policies:train:103 - Epoch 403 / 4000\n",
      "2021-08-25 16:50:43.732 | INFO     | src.policies:train:110 - Episode 403\n",
      "2021-08-25 16:51:03.834 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:51:03.856 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 210.54545454545453, 'equality': 0.931543413410042, 'sustainability': 491.4359115786583, 'peace': 736.8181818181819}\n",
      "2021-08-25 16:51:03.857 | INFO     | src.policies:train:122 - Mean episode return: 210.54545454545453\n",
      "2021-08-25 16:51:03.857 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.91454545454548\n",
      "2021-08-25 16:51:03.858 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:51:12.044 | INFO     | src.policies:train:159 - Total loss: 1.001702070236206\n",
      "2021-08-25 16:51:12.045 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 210.54545454545453, 'equality': 0.931543413410042, 'sustainability': 491.4359115786583, 'peace': 736.8181818181819}\n",
      "2021-08-25 16:51:12.089 | INFO     | src.policies:train:103 - Epoch 404 / 4000\n",
      "2021-08-25 16:51:12.090 | INFO     | src.policies:train:110 - Episode 404\n",
      "2021-08-25 16:51:30.966 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:51:30.989 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 193.36363636363637, 'equality': 0.8775911441663976, 'sustainability': 476.6151101163064, 'peace': 656.5454545454545}\n",
      "2021-08-25 16:51:30.990 | INFO     | src.policies:train:122 - Mean episode return: 193.36363636363637\n",
      "2021-08-25 16:51:30.991 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.76181818181817\n",
      "2021-08-25 16:51:30.991 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:51:38.635 | INFO     | src.policies:train:159 - Total loss: 0.9982868432998657\n",
      "2021-08-25 16:51:38.636 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 193.36363636363637, 'equality': 0.8775911441663976, 'sustainability': 476.6151101163064, 'peace': 656.5454545454545}\n",
      "2021-08-25 16:51:38.681 | INFO     | src.policies:train:103 - Epoch 405 / 4000\n",
      "2021-08-25 16:51:38.681 | INFO     | src.policies:train:110 - Episode 405\n",
      "2021-08-25 16:52:00.084 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:52:00.107 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 220.8181818181818, 'equality': 0.9484262135568616, 'sustainability': 489.91286999509737, 'peace': 783.4545454545455}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 16:52:00.108 | INFO     | src.policies:train:122 - Mean episode return: 220.8181818181818\n",
      "2021-08-25 16:52:00.109 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.64454545454547\n",
      "2021-08-25 16:52:00.109 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:52:08.694 | INFO     | src.policies:train:159 - Total loss: 1.0016230344772339\n",
      "2021-08-25 16:52:08.695 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 220.8181818181818, 'equality': 0.9484262135568616, 'sustainability': 489.91286999509737, 'peace': 783.4545454545455}\n",
      "2021-08-25 16:52:08.744 | INFO     | src.policies:train:103 - Epoch 406 / 4000\n",
      "2021-08-25 16:52:08.745 | INFO     | src.policies:train:110 - Episode 406\n",
      "2021-08-25 16:52:29.409 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:52:29.433 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 202.27272727272728, 'equality': 0.921144024516422, 'sustainability': 482.3733103547447, 'peace': 706.1818181818181}\n",
      "2021-08-25 16:52:29.434 | INFO     | src.policies:train:122 - Mean episode return: 202.27272727272728\n",
      "2021-08-25 16:52:29.435 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.62363636363636\n",
      "2021-08-25 16:52:29.435 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:52:37.918 | INFO     | src.policies:train:159 - Total loss: 1.0021411180496216\n",
      "2021-08-25 16:52:37.919 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 202.27272727272728, 'equality': 0.921144024516422, 'sustainability': 482.3733103547447, 'peace': 706.1818181818181}\n",
      "2021-08-25 16:52:37.967 | INFO     | src.policies:train:103 - Epoch 407 / 4000\n",
      "2021-08-25 16:52:37.968 | INFO     | src.policies:train:110 - Episode 407\n",
      "2021-08-25 16:52:58.168 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:52:58.191 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 214.45454545454547, 'equality': 0.9428108983016145, 'sustainability': 477.3754631828601, 'peace': 690.8181818181819}\n",
      "2021-08-25 16:52:58.191 | INFO     | src.policies:train:122 - Mean episode return: 214.45454545454547\n",
      "2021-08-25 16:52:58.192 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.47090909090903\n",
      "2021-08-25 16:52:58.192 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:53:06.424 | INFO     | src.policies:train:159 - Total loss: 0.9952706098556519\n",
      "2021-08-25 16:53:06.425 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 214.45454545454547, 'equality': 0.9428108983016145, 'sustainability': 477.3754631828601, 'peace': 690.8181818181819}\n",
      "2021-08-25 16:53:06.471 | INFO     | src.policies:train:103 - Epoch 408 / 4000\n",
      "2021-08-25 16:53:06.471 | INFO     | src.policies:train:110 - Episode 408\n",
      "2021-08-25 16:53:26.394 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:53:26.416 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 206.45454545454547, 'equality': 0.932989071695829, 'sustainability': 480.9145960476975, 'peace': 717.0909090909091}\n",
      "2021-08-25 16:53:26.417 | INFO     | src.policies:train:122 - Mean episode return: 206.45454545454547\n",
      "2021-08-25 16:53:26.417 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.41181818181812\n",
      "2021-08-25 16:53:26.418 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:53:34.567 | INFO     | src.policies:train:159 - Total loss: 1.0028725862503052\n",
      "2021-08-25 16:53:34.567 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 206.45454545454547, 'equality': 0.932989071695829, 'sustainability': 480.9145960476975, 'peace': 717.0909090909091}\n",
      "2021-08-25 16:53:34.617 | INFO     | src.policies:train:103 - Epoch 409 / 4000\n",
      "2021-08-25 16:53:34.617 | INFO     | src.policies:train:110 - Episode 409\n",
      "2021-08-25 16:53:55.714 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:53:55.738 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 199.0, 'equality': 0.9006603264275788, 'sustainability': 478.25160546788817, 'peace': 695.7272727272727}\n",
      "2021-08-25 16:53:55.738 | INFO     | src.policies:train:122 - Mean episode return: 199.0\n",
      "2021-08-25 16:53:55.739 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.58363636363632\n",
      "2021-08-25 16:53:55.739 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:54:04.416 | INFO     | src.policies:train:159 - Total loss: 1.000038743019104\n",
      "2021-08-25 16:54:04.417 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 199.0, 'equality': 0.9006603264275788, 'sustainability': 478.25160546788817, 'peace': 695.7272727272727}\n",
      "2021-08-25 16:54:04.466 | INFO     | src.policies:train:103 - Epoch 410 / 4000\n",
      "2021-08-25 16:54:04.467 | INFO     | src.policies:train:110 - Episode 410\n",
      "2021-08-25 16:54:29.880 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:54:29.908 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 221.9090909090909, 'equality': 0.9445085844112974, 'sustainability': 491.11579409737647, 'peace': 734.0}\n",
      "2021-08-25 16:54:29.909 | INFO     | src.policies:train:122 - Mean episode return: 221.9090909090909\n",
      "2021-08-25 16:54:29.909 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.64454545454544\n",
      "2021-08-25 16:54:29.910 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:54:40.794 | INFO     | src.policies:train:159 - Total loss: 1.002855896949768\n",
      "2021-08-25 16:54:40.795 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 221.9090909090909, 'equality': 0.9445085844112974, 'sustainability': 491.11579409737647, 'peace': 734.0}\n",
      "2021-08-25 16:54:40.854 | INFO     | src.policies:train:103 - Epoch 411 / 4000\n",
      "2021-08-25 16:54:40.855 | INFO     | src.policies:train:110 - Episode 411\n",
      "2021-08-25 16:55:08.354 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:55:08.383 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 211.72727272727272, 'equality': 0.9357508099469973, 'sustainability': 484.2049296860648, 'peace': 752.5454545454545}\n",
      "2021-08-25 16:55:08.384 | INFO     | src.policies:train:122 - Mean episode return: 211.72727272727272\n",
      "2021-08-25 16:55:08.384 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.66\n",
      "2021-08-25 16:55:08.385 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:55:18.657 | INFO     | src.policies:train:159 - Total loss: 1.0011911392211914\n",
      "2021-08-25 16:55:18.657 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 211.72727272727272, 'equality': 0.9357508099469973, 'sustainability': 484.2049296860648, 'peace': 752.5454545454545}\n",
      "2021-08-25 16:55:18.713 | INFO     | src.policies:train:103 - Epoch 412 / 4000\n",
      "2021-08-25 16:55:18.713 | INFO     | src.policies:train:110 - Episode 412\n",
      "2021-08-25 16:55:45.035 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:55:45.062 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 228.8181818181818, 'equality': 0.9443059919828023, 'sustainability': 492.8702435795027, 'peace': 728.4545454545455}\n",
      "2021-08-25 16:55:45.063 | INFO     | src.policies:train:122 - Mean episode return: 228.8181818181818\n",
      "2021-08-25 16:55:45.064 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.69181818181815\n",
      "2021-08-25 16:55:45.064 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:55:54.618 | INFO     | src.policies:train:159 - Total loss: 1.000799536705017\n",
      "2021-08-25 16:55:54.619 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 228.8181818181818, 'equality': 0.9443059919828023, 'sustainability': 492.8702435795027, 'peace': 728.4545454545455}\n",
      "2021-08-25 16:55:54.669 | INFO     | src.policies:train:103 - Epoch 413 / 4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 16:55:54.669 | INFO     | src.policies:train:110 - Episode 413\n",
      "2021-08-25 16:56:16.841 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:56:16.863 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 210.36363636363637, 'equality': 0.9266912862432881, 'sustainability': 486.3670301768071, 'peace': 694.8181818181819}\n",
      "2021-08-25 16:56:16.863 | INFO     | src.policies:train:122 - Mean episode return: 210.36363636363637\n",
      "2021-08-25 16:56:16.864 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.7681818181818\n",
      "2021-08-25 16:56:16.864 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:56:25.464 | INFO     | src.policies:train:159 - Total loss: 1.0011311769485474\n",
      "2021-08-25 16:56:25.465 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 210.36363636363637, 'equality': 0.9266912862432881, 'sustainability': 486.3670301768071, 'peace': 694.8181818181819}\n",
      "2021-08-25 16:56:25.514 | INFO     | src.policies:train:103 - Epoch 414 / 4000\n",
      "2021-08-25 16:56:25.514 | INFO     | src.policies:train:110 - Episode 414\n",
      "2021-08-25 16:56:48.804 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:56:48.829 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 211.36363636363637, 'equality': 0.9408797653970502, 'sustainability': 514.1926666138036, 'peace': 700.1818181818181}\n",
      "2021-08-25 16:56:48.829 | INFO     | src.policies:train:122 - Mean episode return: 211.36363636363637\n",
      "2021-08-25 16:56:48.830 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.98363636363632\n",
      "2021-08-25 16:56:48.830 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:56:58.247 | INFO     | src.policies:train:159 - Total loss: 0.9908360242843628\n",
      "2021-08-25 16:56:58.248 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 211.36363636363637, 'equality': 0.9408797653970502, 'sustainability': 514.1926666138036, 'peace': 700.1818181818181}\n",
      "2021-08-25 16:56:58.300 | INFO     | src.policies:train:103 - Epoch 415 / 4000\n",
      "2021-08-25 16:56:58.300 | INFO     | src.policies:train:110 - Episode 415\n",
      "2021-08-25 16:57:20.667 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:57:20.687 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 210.54545454545453, 'equality': 0.9053226566198516, 'sustainability': 487.3417129790371, 'peace': 724.4545454545455}\n",
      "2021-08-25 16:57:20.687 | INFO     | src.policies:train:122 - Mean episode return: 210.54545454545453\n",
      "2021-08-25 16:57:20.688 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.07\n",
      "2021-08-25 16:57:20.688 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:57:29.079 | INFO     | src.policies:train:159 - Total loss: 1.0007164478302002\n",
      "2021-08-25 16:57:29.080 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 210.54545454545453, 'equality': 0.9053226566198516, 'sustainability': 487.3417129790371, 'peace': 724.4545454545455}\n",
      "2021-08-25 16:57:29.133 | INFO     | src.policies:train:103 - Epoch 416 / 4000\n",
      "2021-08-25 16:57:29.134 | INFO     | src.policies:train:110 - Episode 416\n",
      "2021-08-25 16:57:48.623 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:57:48.646 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 210.63636363636363, 'equality': 0.926079962335189, 'sustainability': 468.7209643101019, 'peace': 692.2727272727273}\n",
      "2021-08-25 16:57:48.646 | INFO     | src.policies:train:122 - Mean episode return: 210.63636363636363\n",
      "2021-08-25 16:57:48.647 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.01\n",
      "2021-08-25 16:57:48.647 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:57:56.297 | INFO     | src.policies:train:159 - Total loss: 1.005346417427063\n",
      "2021-08-25 16:57:56.298 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 210.63636363636363, 'equality': 0.926079962335189, 'sustainability': 468.7209643101019, 'peace': 692.2727272727273}\n",
      "2021-08-25 16:57:56.345 | INFO     | src.policies:train:103 - Epoch 417 / 4000\n",
      "2021-08-25 16:57:56.345 | INFO     | src.policies:train:110 - Episode 417\n",
      "2021-08-25 16:58:16.050 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:58:16.072 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 202.1818181818182, 'equality': 0.9287933289746404, 'sustainability': 481.78159353549086, 'peace': 724.1818181818181}\n",
      "2021-08-25 16:58:16.072 | INFO     | src.policies:train:122 - Mean episode return: 202.1818181818182\n",
      "2021-08-25 16:58:16.073 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.10090909090914\n",
      "2021-08-25 16:58:16.073 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:58:24.463 | INFO     | src.policies:train:159 - Total loss: 0.9985368847846985\n",
      "2021-08-25 16:58:24.464 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 202.1818181818182, 'equality': 0.9287933289746404, 'sustainability': 481.78159353549086, 'peace': 724.1818181818181}\n",
      "2021-08-25 16:58:24.512 | INFO     | src.policies:train:103 - Epoch 418 / 4000\n",
      "2021-08-25 16:58:24.513 | INFO     | src.policies:train:110 - Episode 418\n",
      "2021-08-25 16:58:44.937 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:58:44.962 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 211.45454545454547, 'equality': 0.9239427812099597, 'sustainability': 488.66860977261746, 'peace': 715.7272727272727}\n",
      "2021-08-25 16:58:44.962 | INFO     | src.policies:train:122 - Mean episode return: 211.45454545454547\n",
      "2021-08-25 16:58:44.963 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.09272727272727\n",
      "2021-08-25 16:58:44.963 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:58:52.612 | INFO     | src.policies:train:159 - Total loss: 1.0057902336120605\n",
      "2021-08-25 16:58:52.613 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 211.45454545454547, 'equality': 0.9239427812099597, 'sustainability': 488.66860977261746, 'peace': 715.7272727272727}\n",
      "2021-08-25 16:58:52.660 | INFO     | src.policies:train:103 - Epoch 419 / 4000\n",
      "2021-08-25 16:58:52.661 | INFO     | src.policies:train:110 - Episode 419\n",
      "2021-08-25 16:59:12.247 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:59:12.267 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 201.36363636363637, 'equality': 0.9393392160898966, 'sustainability': 485.21378864398264, 'peace': 700.3636363636364}\n",
      "2021-08-25 16:59:12.268 | INFO     | src.policies:train:122 - Mean episode return: 201.36363636363637\n",
      "2021-08-25 16:59:12.268 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.34\n",
      "2021-08-25 16:59:12.269 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 16:59:19.737 | INFO     | src.policies:train:159 - Total loss: 1.0062618255615234\n",
      "2021-08-25 16:59:19.738 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 201.36363636363637, 'equality': 0.9393392160898966, 'sustainability': 485.21378864398264, 'peace': 700.3636363636364}\n",
      "2021-08-25 16:59:19.783 | INFO     | src.policies:train:103 - Epoch 420 / 4000\n",
      "2021-08-25 16:59:19.784 | INFO     | src.policies:train:110 - Episode 420\n",
      "2021-08-25 16:59:39.173 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 16:59:39.193 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 217.8181818181818, 'equality': 0.9102291698302051, 'sustainability': 481.82976579858826, 'peace': 758.2727272727273}\n",
      "2021-08-25 16:59:39.194 | INFO     | src.policies:train:122 - Mean episode return: 217.8181818181818\n",
      "2021-08-25 16:59:39.194 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.2581818181818\n",
      "2021-08-25 16:59:39.194 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 16:59:46.755 | INFO     | src.policies:train:159 - Total loss: 1.000838041305542\n",
      "2021-08-25 16:59:46.756 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 217.8181818181818, 'equality': 0.9102291698302051, 'sustainability': 481.82976579858826, 'peace': 758.2727272727273}\n",
      "2021-08-25 16:59:46.802 | INFO     | src.policies:train:103 - Epoch 421 / 4000\n",
      "2021-08-25 16:59:46.802 | INFO     | src.policies:train:110 - Episode 421\n",
      "2021-08-25 17:00:07.456 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:00:07.476 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 202.0909090909091, 'equality': 0.9197644460818761, 'sustainability': 481.3401972909041, 'peace': 755.1818181818181}\n",
      "2021-08-25 17:00:07.477 | INFO     | src.policies:train:122 - Mean episode return: 202.0909090909091\n",
      "2021-08-25 17:00:07.477 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.2745454545454\n",
      "2021-08-25 17:00:07.478 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:00:15.273 | INFO     | src.policies:train:159 - Total loss: 1.0052781105041504\n",
      "2021-08-25 17:00:15.273 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 202.0909090909091, 'equality': 0.9197644460818761, 'sustainability': 481.3401972909041, 'peace': 755.1818181818181}\n",
      "2021-08-25 17:00:15.322 | INFO     | src.policies:train:103 - Epoch 422 / 4000\n",
      "2021-08-25 17:00:15.322 | INFO     | src.policies:train:110 - Episode 422\n",
      "2021-08-25 17:00:35.892 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:00:35.915 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 200.63636363636363, 'equality': 0.9653169666769923, 'sustainability': 475.54786448745705, 'peace': 698.6363636363636}\n",
      "2021-08-25 17:00:35.916 | INFO     | src.policies:train:122 - Mean episode return: 200.63636363636363\n",
      "2021-08-25 17:00:35.916 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.2681818181818\n",
      "2021-08-25 17:00:35.917 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:00:44.142 | INFO     | src.policies:train:159 - Total loss: 0.9996342062950134\n",
      "2021-08-25 17:00:44.143 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 200.63636363636363, 'equality': 0.9653169666769923, 'sustainability': 475.54786448745705, 'peace': 698.6363636363636}\n",
      "2021-08-25 17:00:44.190 | INFO     | src.policies:train:103 - Epoch 423 / 4000\n",
      "2021-08-25 17:00:44.190 | INFO     | src.policies:train:110 - Episode 423\n",
      "2021-08-25 17:01:02.632 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:01:02.654 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 191.27272727272728, 'equality': 0.9444348427250165, 'sustainability': 505.24128694535733, 'peace': 652.7272727272727}\n",
      "2021-08-25 17:01:02.655 | INFO     | src.policies:train:122 - Mean episode return: 191.27272727272728\n",
      "2021-08-25 17:01:02.655 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.06999999999996\n",
      "2021-08-25 17:01:02.656 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:01:10.906 | INFO     | src.policies:train:159 - Total loss: 1.0002409219741821\n",
      "2021-08-25 17:01:10.907 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 191.27272727272728, 'equality': 0.9444348427250165, 'sustainability': 505.24128694535733, 'peace': 652.7272727272727}\n",
      "2021-08-25 17:01:10.957 | INFO     | src.policies:train:103 - Epoch 424 / 4000\n",
      "2021-08-25 17:01:10.957 | INFO     | src.policies:train:110 - Episode 424\n",
      "2021-08-25 17:01:30.271 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:01:30.293 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 215.9090909090909, 'equality': 0.9453397129197064, 'sustainability': 497.09418349837983, 'peace': 777.8181818181819}\n",
      "2021-08-25 17:01:30.294 | INFO     | src.policies:train:122 - Mean episode return: 215.9090909090909\n",
      "2021-08-25 17:01:30.294 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.1409090909091\n",
      "2021-08-25 17:01:30.295 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:01:38.047 | INFO     | src.policies:train:159 - Total loss: 1.003903865814209\n",
      "2021-08-25 17:01:38.048 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 215.9090909090909, 'equality': 0.9453397129197064, 'sustainability': 497.09418349837983, 'peace': 777.8181818181819}\n",
      "2021-08-25 17:01:38.094 | INFO     | src.policies:train:103 - Epoch 425 / 4000\n",
      "2021-08-25 17:01:38.095 | INFO     | src.policies:train:110 - Episode 425\n",
      "2021-08-25 17:01:57.889 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:01:57.911 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 206.8181818181818, 'equality': 0.9696303696309764, 'sustainability': 496.26242397816037, 'peace': 649.9090909090909}\n",
      "2021-08-25 17:01:57.911 | INFO     | src.policies:train:122 - Mean episode return: 206.8181818181818\n",
      "2021-08-25 17:01:57.912 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.1318181818182\n",
      "2021-08-25 17:01:57.912 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:02:05.818 | INFO     | src.policies:train:159 - Total loss: 1.00050950050354\n",
      "2021-08-25 17:02:05.819 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 206.8181818181818, 'equality': 0.9696303696309764, 'sustainability': 496.26242397816037, 'peace': 649.9090909090909}\n",
      "2021-08-25 17:02:05.866 | INFO     | src.policies:train:103 - Epoch 426 / 4000\n",
      "2021-08-25 17:02:05.867 | INFO     | src.policies:train:110 - Episode 426\n",
      "2021-08-25 17:02:25.543 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:02:25.566 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 198.0, 'equality': 0.8995742549482516, 'sustainability': 477.2052221161385, 'peace': 662.1818181818181}\n",
      "2021-08-25 17:02:25.567 | INFO     | src.policies:train:122 - Mean episode return: 198.0\n",
      "2021-08-25 17:02:25.567 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.87181818181818\n",
      "2021-08-25 17:02:25.568 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:02:33.314 | INFO     | src.policies:train:159 - Total loss: 0.9962367415428162\n",
      "2021-08-25 17:02:33.315 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 198.0, 'equality': 0.8995742549482516, 'sustainability': 477.2052221161385, 'peace': 662.1818181818181}\n",
      "2021-08-25 17:02:33.361 | INFO     | src.policies:train:103 - Epoch 427 / 4000\n",
      "2021-08-25 17:02:33.362 | INFO     | src.policies:train:110 - Episode 427\n",
      "2021-08-25 17:02:52.215 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:02:52.235 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 226.72727272727272, 'equality': 0.9381059998553236, 'sustainability': 502.35001281738283, 'peace': 774.1818181818181}\n",
      "2021-08-25 17:02:52.236 | INFO     | src.policies:train:122 - Mean episode return: 226.72727272727272\n",
      "2021-08-25 17:02:52.236 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.8681818181818\n",
      "2021-08-25 17:02:52.236 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:02:59.837 | INFO     | src.policies:train:159 - Total loss: 1.0002548694610596\n",
      "2021-08-25 17:02:59.838 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 226.72727272727272, 'equality': 0.9381059998553236, 'sustainability': 502.35001281738283, 'peace': 774.1818181818181}\n",
      "2021-08-25 17:02:59.882 | INFO     | src.policies:train:103 - Epoch 428 / 4000\n",
      "2021-08-25 17:02:59.882 | INFO     | src.policies:train:110 - Episode 428\n",
      "2021-08-25 17:03:19.140 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:03:19.162 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 204.72727272727272, 'equality': 0.9139350880043207, 'sustainability': 470.3312917863063, 'peace': 726.7272727272727}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 17:03:19.163 | INFO     | src.policies:train:122 - Mean episode return: 204.72727272727272\n",
      "2021-08-25 17:03:19.163 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.13090909090909\n",
      "2021-08-25 17:03:19.164 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:03:27.316 | INFO     | src.policies:train:159 - Total loss: 1.0023552179336548\n",
      "2021-08-25 17:03:27.317 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 204.72727272727272, 'equality': 0.9139350880043207, 'sustainability': 470.3312917863063, 'peace': 726.7272727272727}\n",
      "2021-08-25 17:03:27.362 | INFO     | src.policies:train:103 - Epoch 429 / 4000\n",
      "2021-08-25 17:03:27.362 | INFO     | src.policies:train:110 - Episode 429\n",
      "2021-08-25 17:03:49.068 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:03:49.133 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 199.54545454545453, 'equality': 0.8955477324519456, 'sustainability': 498.3027846010424, 'peace': 691.8181818181819}\n",
      "2021-08-25 17:03:49.133 | INFO     | src.policies:train:122 - Mean episode return: 199.54545454545453\n",
      "2021-08-25 17:03:49.134 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.1009090909091\n",
      "2021-08-25 17:03:49.135 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:04:00.307 | INFO     | src.policies:train:159 - Total loss: 1.0024583339691162\n",
      "2021-08-25 17:04:00.308 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 199.54545454545453, 'equality': 0.8955477324519456, 'sustainability': 498.3027846010424, 'peace': 691.8181818181819}\n",
      "2021-08-25 17:04:00.361 | INFO     | src.policies:train:103 - Epoch 430 / 4000\n",
      "2021-08-25 17:04:00.361 | INFO     | src.policies:train:110 - Episode 430\n",
      "2021-08-25 17:04:22.769 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:04:22.791 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 211.8181818181818, 'equality': 0.9344518142814192, 'sustainability': 496.18937597445233, 'peace': 725.2727272727273}\n",
      "2021-08-25 17:04:22.791 | INFO     | src.policies:train:122 - Mean episode return: 211.8181818181818\n",
      "2021-08-25 17:04:22.792 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.3818181818182\n",
      "2021-08-25 17:04:22.792 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:04:31.207 | INFO     | src.policies:train:159 - Total loss: 1.0024514198303223\n",
      "2021-08-25 17:04:31.208 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 211.8181818181818, 'equality': 0.9344518142814192, 'sustainability': 496.18937597445233, 'peace': 725.2727272727273}\n",
      "2021-08-25 17:04:31.256 | INFO     | src.policies:train:103 - Epoch 431 / 4000\n",
      "2021-08-25 17:04:31.256 | INFO     | src.policies:train:110 - Episode 431\n",
      "2021-08-25 17:04:51.116 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:04:51.138 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 210.63636363636363, 'equality': 0.9303958881011811, 'sustainability': 470.11478301670707, 'peace': 690.3636363636364}\n",
      "2021-08-25 17:04:51.139 | INFO     | src.policies:train:122 - Mean episode return: 210.63636363636363\n",
      "2021-08-25 17:04:51.139 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.34272727272727\n",
      "2021-08-25 17:04:51.139 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:04:58.804 | INFO     | src.policies:train:159 - Total loss: 1.0019912719726562\n",
      "2021-08-25 17:04:58.805 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 210.63636363636363, 'equality': 0.9303958881011811, 'sustainability': 470.11478301670707, 'peace': 690.3636363636364}\n",
      "2021-08-25 17:04:58.853 | INFO     | src.policies:train:103 - Epoch 432 / 4000\n",
      "2021-08-25 17:04:58.854 | INFO     | src.policies:train:110 - Episode 432\n",
      "2021-08-25 17:05:18.047 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:05:18.066 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 190.8181818181818, 'equality': 0.9139850145109363, 'sustainability': 483.0273895744467, 'peace': 626.6363636363636}\n",
      "2021-08-25 17:05:18.066 | INFO     | src.policies:train:122 - Mean episode return: 190.8181818181818\n",
      "2021-08-25 17:05:18.067 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.17454545454544\n",
      "2021-08-25 17:05:18.067 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:05:26.090 | INFO     | src.policies:train:159 - Total loss: 0.9993668794631958\n",
      "2021-08-25 17:05:26.091 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 190.8181818181818, 'equality': 0.9139850145109363, 'sustainability': 483.0273895744467, 'peace': 626.6363636363636}\n",
      "2021-08-25 17:05:26.138 | INFO     | src.policies:train:103 - Epoch 433 / 4000\n",
      "2021-08-25 17:05:26.139 | INFO     | src.policies:train:110 - Episode 433\n",
      "2021-08-25 17:05:44.423 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:05:44.444 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 198.9090909090909, 'equality': 0.8843277380778559, 'sustainability': 471.60811729677795, 'peace': 671.1818181818181}\n",
      "2021-08-25 17:05:44.444 | INFO     | src.policies:train:122 - Mean episode return: 198.9090909090909\n",
      "2021-08-25 17:05:44.445 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.86727272727273\n",
      "2021-08-25 17:05:44.445 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:05:52.209 | INFO     | src.policies:train:159 - Total loss: 0.9927347898483276\n",
      "2021-08-25 17:05:52.209 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 198.9090909090909, 'equality': 0.8843277380778559, 'sustainability': 471.60811729677795, 'peace': 671.1818181818181}\n",
      "2021-08-25 17:05:52.259 | INFO     | src.policies:train:103 - Epoch 434 / 4000\n",
      "2021-08-25 17:05:52.259 | INFO     | src.policies:train:110 - Episode 434\n",
      "2021-08-25 17:06:10.864 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:06:10.887 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 212.36363636363637, 'equality': 0.9639632627653338, 'sustainability': 487.7833297940944, 'peace': 627.0}\n",
      "2021-08-25 17:06:10.887 | INFO     | src.policies:train:122 - Mean episode return: 212.36363636363637\n",
      "2021-08-25 17:06:10.888 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.7972727272727\n",
      "2021-08-25 17:06:10.888 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:06:18.393 | INFO     | src.policies:train:159 - Total loss: 1.0004956722259521\n",
      "2021-08-25 17:06:18.394 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 212.36363636363637, 'equality': 0.9639632627653338, 'sustainability': 487.7833297940944, 'peace': 627.0}\n",
      "2021-08-25 17:06:18.440 | INFO     | src.policies:train:103 - Epoch 435 / 4000\n",
      "2021-08-25 17:06:18.441 | INFO     | src.policies:train:110 - Episode 435\n",
      "2021-08-25 17:06:37.290 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:06:37.311 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 210.36363636363637, 'equality': 0.8974620884753386, 'sustainability': 502.7926486603424, 'peace': 723.0}\n",
      "2021-08-25 17:06:37.311 | INFO     | src.policies:train:122 - Mean episode return: 210.36363636363637\n",
      "2021-08-25 17:06:37.312 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.9663636363636\n",
      "2021-08-25 17:06:37.312 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:06:45.360 | INFO     | src.policies:train:159 - Total loss: 1.0016642808914185\n",
      "2021-08-25 17:06:45.361 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 210.36363636363637, 'equality': 0.8974620884753386, 'sustainability': 502.7926486603424, 'peace': 723.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 17:06:45.407 | INFO     | src.policies:train:103 - Epoch 436 / 4000\n",
      "2021-08-25 17:06:45.408 | INFO     | src.policies:train:110 - Episode 436\n",
      "2021-08-25 17:07:05.206 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:07:05.227 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 205.36363636363637, 'equality': 0.9267576160021176, 'sustainability': 487.6090440613702, 'peace': 724.0}\n",
      "2021-08-25 17:07:05.227 | INFO     | src.policies:train:122 - Mean episode return: 205.36363636363637\n",
      "2021-08-25 17:07:05.228 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.0127272727273\n",
      "2021-08-25 17:07:05.228 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:07:12.937 | INFO     | src.policies:train:159 - Total loss: 0.9978480935096741\n",
      "2021-08-25 17:07:12.938 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 205.36363636363637, 'equality': 0.9267576160021176, 'sustainability': 487.6090440613702, 'peace': 724.0}\n",
      "2021-08-25 17:07:12.987 | INFO     | src.policies:train:103 - Epoch 437 / 4000\n",
      "2021-08-25 17:07:12.987 | INFO     | src.policies:train:110 - Episode 437\n",
      "2021-08-25 17:07:31.395 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:07:31.416 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 191.0, 'equality': 0.8572973908559279, 'sustainability': 469.59707070284566, 'peace': 606.2727272727273}\n",
      "2021-08-25 17:07:31.417 | INFO     | src.policies:train:122 - Mean episode return: 191.0\n",
      "2021-08-25 17:07:31.417 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.93090909090907\n",
      "2021-08-25 17:07:31.418 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:07:38.983 | INFO     | src.policies:train:159 - Total loss: 1.0065109729766846\n",
      "2021-08-25 17:07:38.983 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 191.0, 'equality': 0.8572973908559279, 'sustainability': 469.59707070284566, 'peace': 606.2727272727273}\n",
      "2021-08-25 17:07:39.030 | INFO     | src.policies:train:103 - Epoch 438 / 4000\n",
      "2021-08-25 17:07:39.031 | INFO     | src.policies:train:110 - Episode 438\n",
      "2021-08-25 17:07:58.653 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:07:58.674 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 202.9090909090909, 'equality': 0.9381720430120118, 'sustainability': 499.8711954313912, 'peace': 706.9090909090909}\n",
      "2021-08-25 17:07:58.675 | INFO     | src.policies:train:122 - Mean episode return: 202.9090909090909\n",
      "2021-08-25 17:07:58.675 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.90000000000003\n",
      "2021-08-25 17:07:58.676 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:08:06.334 | INFO     | src.policies:train:159 - Total loss: 1.0031764507293701\n",
      "2021-08-25 17:08:06.334 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 202.9090909090909, 'equality': 0.9381720430120118, 'sustainability': 499.8711954313912, 'peace': 706.9090909090909}\n",
      "2021-08-25 17:08:06.381 | INFO     | src.policies:train:103 - Epoch 439 / 4000\n",
      "2021-08-25 17:08:06.382 | INFO     | src.policies:train:110 - Episode 439\n",
      "2021-08-25 17:08:25.494 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:08:25.518 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 216.63636363636363, 'equality': 0.9392667760283205, 'sustainability': 481.670583094382, 'peace': 689.7272727272727}\n",
      "2021-08-25 17:08:25.518 | INFO     | src.policies:train:122 - Mean episode return: 216.63636363636363\n",
      "2021-08-25 17:08:25.519 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.97363636363636\n",
      "2021-08-25 17:08:25.519 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:08:33.286 | INFO     | src.policies:train:159 - Total loss: 0.998186469078064\n",
      "2021-08-25 17:08:33.287 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 216.63636363636363, 'equality': 0.9392667760283205, 'sustainability': 481.670583094382, 'peace': 689.7272727272727}\n",
      "2021-08-25 17:08:33.335 | INFO     | src.policies:train:103 - Epoch 440 / 4000\n",
      "2021-08-25 17:08:33.336 | INFO     | src.policies:train:110 - Episode 440\n",
      "2021-08-25 17:08:51.350 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:08:51.372 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 191.0, 'equality': 0.8590281684077057, 'sustainability': 498.92927815901277, 'peace': 662.3636363636364}\n",
      "2021-08-25 17:08:51.372 | INFO     | src.policies:train:122 - Mean episode return: 191.0\n",
      "2021-08-25 17:08:51.373 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.75000000000003\n",
      "2021-08-25 17:08:51.373 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:08:59.544 | INFO     | src.policies:train:159 - Total loss: 0.9981685280799866\n",
      "2021-08-25 17:08:59.545 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 191.0, 'equality': 0.8590281684077057, 'sustainability': 498.92927815901277, 'peace': 662.3636363636364}\n",
      "2021-08-25 17:08:59.592 | INFO     | src.policies:train:103 - Epoch 441 / 4000\n",
      "2021-08-25 17:08:59.593 | INFO     | src.policies:train:110 - Episode 441\n",
      "2021-08-25 17:09:19.057 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:09:19.076 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 210.72727272727272, 'equality': 0.9211702878672607, 'sustainability': 464.13542206130865, 'peace': 680.9090909090909}\n",
      "2021-08-25 17:09:19.077 | INFO     | src.policies:train:122 - Mean episode return: 210.72727272727272\n",
      "2021-08-25 17:09:19.077 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.7436363636364\n",
      "2021-08-25 17:09:19.078 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:09:26.831 | INFO     | src.policies:train:159 - Total loss: 1.000859260559082\n",
      "2021-08-25 17:09:26.832 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 210.72727272727272, 'equality': 0.9211702878672607, 'sustainability': 464.13542206130865, 'peace': 680.9090909090909}\n",
      "2021-08-25 17:09:26.883 | INFO     | src.policies:train:103 - Epoch 442 / 4000\n",
      "2021-08-25 17:09:26.883 | INFO     | src.policies:train:110 - Episode 442\n",
      "2021-08-25 17:09:46.904 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:09:46.930 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 203.45454545454547, 'equality': 0.9129904947616989, 'sustainability': 468.2678589073073, 'peace': 684.1818181818181}\n",
      "2021-08-25 17:09:46.930 | INFO     | src.policies:train:122 - Mean episode return: 203.45454545454547\n",
      "2021-08-25 17:09:46.931 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.7181818181818\n",
      "2021-08-25 17:09:46.931 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:09:54.625 | INFO     | src.policies:train:159 - Total loss: 0.9953644871711731\n",
      "2021-08-25 17:09:54.626 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 203.45454545454547, 'equality': 0.9129904947616989, 'sustainability': 468.2678589073073, 'peace': 684.1818181818181}\n",
      "2021-08-25 17:09:54.675 | INFO     | src.policies:train:103 - Epoch 443 / 4000\n",
      "2021-08-25 17:09:54.676 | INFO     | src.policies:train:110 - Episode 443\n",
      "2021-08-25 17:10:14.001 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:10:14.022 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 201.36363636363637, 'equality': 0.9059306382124783, 'sustainability': 497.1208653638523, 'peace': 656.0}\n",
      "2021-08-25 17:10:14.022 | INFO     | src.policies:train:122 - Mean episode return: 201.36363636363637\n",
      "2021-08-25 17:10:14.023 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.8690909090909\n",
      "2021-08-25 17:10:14.023 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 17:10:21.634 | INFO     | src.policies:train:159 - Total loss: 1.002406120300293\n",
      "2021-08-25 17:10:21.635 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 201.36363636363637, 'equality': 0.9059306382124783, 'sustainability': 497.1208653638523, 'peace': 656.0}\n",
      "2021-08-25 17:10:21.681 | INFO     | src.policies:train:103 - Epoch 444 / 4000\n",
      "2021-08-25 17:10:21.682 | INFO     | src.policies:train:110 - Episode 444\n",
      "2021-08-25 17:10:40.672 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:10:40.693 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 191.72727272727272, 'equality': 0.9258588732288923, 'sustainability': 489.50254141548925, 'peace': 716.7272727272727}\n",
      "2021-08-25 17:10:40.694 | INFO     | src.policies:train:122 - Mean episode return: 191.72727272727272\n",
      "2021-08-25 17:10:40.695 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.7090909090909\n",
      "2021-08-25 17:10:40.695 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:10:48.370 | INFO     | src.policies:train:159 - Total loss: 1.006112813949585\n",
      "2021-08-25 17:10:48.371 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 191.72727272727272, 'equality': 0.9258588732288923, 'sustainability': 489.50254141548925, 'peace': 716.7272727272727}\n",
      "2021-08-25 17:10:48.419 | INFO     | src.policies:train:103 - Epoch 445 / 4000\n",
      "2021-08-25 17:10:48.420 | INFO     | src.policies:train:110 - Episode 445\n",
      "2021-08-25 17:11:07.669 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:11:07.692 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 209.36363636363637, 'equality': 0.9279201042133202, 'sustainability': 504.4156445974993, 'peace': 768.7272727272727}\n",
      "2021-08-25 17:11:07.693 | INFO     | src.policies:train:122 - Mean episode return: 209.36363636363637\n",
      "2021-08-25 17:11:07.693 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.65\n",
      "2021-08-25 17:11:07.694 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:11:15.285 | INFO     | src.policies:train:159 - Total loss: 0.9934258460998535\n",
      "2021-08-25 17:11:15.286 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 209.36363636363637, 'equality': 0.9279201042133202, 'sustainability': 504.4156445974993, 'peace': 768.7272727272727}\n",
      "2021-08-25 17:11:15.336 | INFO     | src.policies:train:103 - Epoch 446 / 4000\n",
      "2021-08-25 17:11:15.336 | INFO     | src.policies:train:110 - Episode 446\n",
      "2021-08-25 17:11:34.270 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:11:34.291 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 187.9090909090909, 'equality': 0.9258477371701226, 'sustainability': 487.50514505888447, 'peace': 668.5454545454545}\n",
      "2021-08-25 17:11:34.292 | INFO     | src.policies:train:122 - Mean episode return: 187.9090909090909\n",
      "2021-08-25 17:11:34.292 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.49545454545455\n",
      "2021-08-25 17:11:34.293 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:11:42.028 | INFO     | src.policies:train:159 - Total loss: 1.0047099590301514\n",
      "2021-08-25 17:11:42.028 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 187.9090909090909, 'equality': 0.9258477371701226, 'sustainability': 487.50514505888447, 'peace': 668.5454545454545}\n",
      "2021-08-25 17:11:42.078 | INFO     | src.policies:train:103 - Epoch 447 / 4000\n",
      "2021-08-25 17:11:42.079 | INFO     | src.policies:train:110 - Episode 447\n",
      "2021-08-25 17:12:01.302 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:12:01.320 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 213.27272727272728, 'equality': 0.9269162210352841, 'sustainability': 494.23801638915046, 'peace': 727.9090909090909}\n",
      "2021-08-25 17:12:01.321 | INFO     | src.policies:train:122 - Mean episode return: 213.27272727272728\n",
      "2021-08-25 17:12:01.322 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.57363636363635\n",
      "2021-08-25 17:12:01.322 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:12:09.508 | INFO     | src.policies:train:159 - Total loss: 1.0061525106430054\n",
      "2021-08-25 17:12:09.509 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 213.27272727272728, 'equality': 0.9269162210352841, 'sustainability': 494.23801638915046, 'peace': 727.9090909090909}\n",
      "2021-08-25 17:12:09.558 | INFO     | src.policies:train:103 - Epoch 448 / 4000\n",
      "2021-08-25 17:12:09.559 | INFO     | src.policies:train:110 - Episode 448\n",
      "2021-08-25 17:12:29.443 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:12:29.468 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 186.54545454545453, 'equality': 0.8904837852230533, 'sustainability': 469.31118826843306, 'peace': 686.0909090909091}\n",
      "2021-08-25 17:12:29.468 | INFO     | src.policies:train:122 - Mean episode return: 186.54545454545453\n",
      "2021-08-25 17:12:29.469 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.18454545454549\n",
      "2021-08-25 17:12:29.469 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:12:37.052 | INFO     | src.policies:train:159 - Total loss: 0.9961411952972412\n",
      "2021-08-25 17:12:37.053 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 186.54545454545453, 'equality': 0.8904837852230533, 'sustainability': 469.31118826843306, 'peace': 686.0909090909091}\n",
      "2021-08-25 17:12:37.100 | INFO     | src.policies:train:103 - Epoch 449 / 4000\n",
      "2021-08-25 17:12:37.101 | INFO     | src.policies:train:110 - Episode 449\n",
      "2021-08-25 17:12:55.693 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:12:55.713 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 205.36363636363637, 'equality': 0.9123505976113254, 'sustainability': 470.7236212312027, 'peace': 748.6363636363636}\n",
      "2021-08-25 17:12:55.713 | INFO     | src.policies:train:122 - Mean episode return: 205.36363636363637\n",
      "2021-08-25 17:12:55.714 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.10727272727274\n",
      "2021-08-25 17:12:55.714 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:13:03.388 | INFO     | src.policies:train:159 - Total loss: 1.0007710456848145\n",
      "2021-08-25 17:13:03.388 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 205.36363636363637, 'equality': 0.9123505976113254, 'sustainability': 470.7236212312027, 'peace': 748.6363636363636}\n",
      "2021-08-25 17:13:03.438 | INFO     | src.policies:train:103 - Epoch 450 / 4000\n",
      "2021-08-25 17:13:03.438 | INFO     | src.policies:train:110 - Episode 450\n",
      "2021-08-25 17:13:22.492 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:13:22.512 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 222.72727272727272, 'equality': 0.9553246753255041, 'sustainability': 492.3648679630162, 'peace': 771.7272727272727}\n",
      "2021-08-25 17:13:22.512 | INFO     | src.policies:train:122 - Mean episode return: 222.72727272727272\n",
      "2021-08-25 17:13:22.513 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.14272727272729\n",
      "2021-08-25 17:13:22.513 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:13:30.241 | INFO     | src.policies:train:159 - Total loss: 0.9965386390686035\n",
      "2021-08-25 17:13:30.242 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 222.72727272727272, 'equality': 0.9553246753255041, 'sustainability': 492.3648679630162, 'peace': 771.7272727272727}\n",
      "2021-08-25 17:13:30.294 | INFO     | src.policies:train:103 - Epoch 451 / 4000\n",
      "2021-08-25 17:13:30.295 | INFO     | src.policies:train:110 - Episode 451\n",
      "2021-08-25 17:13:49.951 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:13:49.978 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 214.72727272727272, 'equality': 0.9481949041654185, 'sustainability': 489.32514546848086, 'peace': 745.1818181818181}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 17:13:49.979 | INFO     | src.policies:train:122 - Mean episode return: 214.72727272727272\n",
      "2021-08-25 17:13:49.979 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.38636363636363\n",
      "2021-08-25 17:13:49.980 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:13:57.843 | INFO     | src.policies:train:159 - Total loss: 0.9981465935707092\n",
      "2021-08-25 17:13:57.844 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 214.72727272727272, 'equality': 0.9481949041654185, 'sustainability': 489.32514546848086, 'peace': 745.1818181818181}\n",
      "2021-08-25 17:13:57.895 | INFO     | src.policies:train:103 - Epoch 452 / 4000\n",
      "2021-08-25 17:13:57.896 | INFO     | src.policies:train:110 - Episode 452\n",
      "2021-08-25 17:14:17.125 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:14:17.146 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 215.9090909090909, 'equality': 0.9141818181834607, 'sustainability': 475.2605217996542, 'peace': 593.0909090909091}\n",
      "2021-08-25 17:14:17.147 | INFO     | src.policies:train:122 - Mean episode return: 215.9090909090909\n",
      "2021-08-25 17:14:17.147 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.44727272727272\n",
      "2021-08-25 17:14:17.147 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:14:24.705 | INFO     | src.policies:train:159 - Total loss: 1.0002155303955078\n",
      "2021-08-25 17:14:24.706 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 215.9090909090909, 'equality': 0.9141818181834607, 'sustainability': 475.2605217996542, 'peace': 593.0909090909091}\n",
      "2021-08-25 17:14:24.755 | INFO     | src.policies:train:103 - Epoch 453 / 4000\n",
      "2021-08-25 17:14:24.756 | INFO     | src.policies:train:110 - Episode 453\n",
      "2021-08-25 17:14:43.510 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:14:43.531 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 198.63636363636363, 'equality': 0.9055543998355408, 'sustainability': 459.34774378017903, 'peace': 653.1818181818181}\n",
      "2021-08-25 17:14:43.532 | INFO     | src.policies:train:122 - Mean episode return: 198.63636363636363\n",
      "2021-08-25 17:14:43.533 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.31545454545457\n",
      "2021-08-25 17:14:43.533 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:14:51.138 | INFO     | src.policies:train:159 - Total loss: 0.9998915791511536\n",
      "2021-08-25 17:14:51.139 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 198.63636363636363, 'equality': 0.9055543998355408, 'sustainability': 459.34774378017903, 'peace': 653.1818181818181}\n",
      "2021-08-25 17:14:51.185 | INFO     | src.policies:train:103 - Epoch 454 / 4000\n",
      "2021-08-25 17:14:51.186 | INFO     | src.policies:train:110 - Episode 454\n",
      "2021-08-25 17:15:09.904 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:15:09.923 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 203.72727272727272, 'equality': 0.9291712303774863, 'sustainability': 485.60860379345735, 'peace': 726.9090909090909}\n",
      "2021-08-25 17:15:09.923 | INFO     | src.policies:train:122 - Mean episode return: 203.72727272727272\n",
      "2021-08-25 17:15:09.924 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.24545454545452\n",
      "2021-08-25 17:15:09.924 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:15:17.579 | INFO     | src.policies:train:159 - Total loss: 0.9938907027244568\n",
      "2021-08-25 17:15:17.580 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 203.72727272727272, 'equality': 0.9291712303774863, 'sustainability': 485.60860379345735, 'peace': 726.9090909090909}\n",
      "2021-08-25 17:15:17.629 | INFO     | src.policies:train:103 - Epoch 455 / 4000\n",
      "2021-08-25 17:15:17.630 | INFO     | src.policies:train:110 - Episode 455\n",
      "2021-08-25 17:15:36.516 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:15:36.536 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 188.54545454545453, 'equality': 0.9282019812411633, 'sustainability': 488.37043383919973, 'peace': 644.0}\n",
      "2021-08-25 17:15:36.537 | INFO     | src.policies:train:122 - Mean episode return: 188.54545454545453\n",
      "2021-08-25 17:15:36.537 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 206.93545454545455\n",
      "2021-08-25 17:15:36.538 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:15:44.226 | INFO     | src.policies:train:159 - Total loss: 1.000810146331787\n",
      "2021-08-25 17:15:44.227 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 188.54545454545453, 'equality': 0.9282019812411633, 'sustainability': 488.37043383919973, 'peace': 644.0}\n",
      "2021-08-25 17:15:44.273 | INFO     | src.policies:train:103 - Epoch 456 / 4000\n",
      "2021-08-25 17:15:44.274 | INFO     | src.policies:train:110 - Episode 456\n",
      "2021-08-25 17:16:02.677 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:16:02.698 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 217.45454545454547, 'equality': 0.931134083309305, 'sustainability': 486.3658152847154, 'peace': 715.5454545454545}\n",
      "2021-08-25 17:16:02.699 | INFO     | src.policies:train:122 - Mean episode return: 217.45454545454547\n",
      "2021-08-25 17:16:02.699 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.12636363636364\n",
      "2021-08-25 17:16:02.700 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:16:10.410 | INFO     | src.policies:train:159 - Total loss: 1.0001620054244995\n",
      "2021-08-25 17:16:10.411 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 217.45454545454547, 'equality': 0.931134083309305, 'sustainability': 486.3658152847154, 'peace': 715.5454545454545}\n",
      "2021-08-25 17:16:10.457 | INFO     | src.policies:train:103 - Epoch 457 / 4000\n",
      "2021-08-25 17:16:10.458 | INFO     | src.policies:train:110 - Episode 457\n",
      "2021-08-25 17:16:29.993 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:16:30.021 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 220.27272727272728, 'equality': 0.9458972723530954, 'sustainability': 484.1740498607206, 'peace': 707.0909090909091}\n",
      "2021-08-25 17:16:30.022 | INFO     | src.policies:train:122 - Mean episode return: 220.27272727272728\n",
      "2021-08-25 17:16:30.022 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.3463636363636\n",
      "2021-08-25 17:16:30.023 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:16:37.697 | INFO     | src.policies:train:159 - Total loss: 0.9992771744728088\n",
      "2021-08-25 17:16:37.698 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 220.27272727272728, 'equality': 0.9458972723530954, 'sustainability': 484.1740498607206, 'peace': 707.0909090909091}\n",
      "2021-08-25 17:16:37.748 | INFO     | src.policies:train:103 - Epoch 458 / 4000\n",
      "2021-08-25 17:16:37.748 | INFO     | src.policies:train:110 - Episode 458\n",
      "2021-08-25 17:16:56.758 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:16:56.781 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 217.0, 'equality': 0.9273336634054283, 'sustainability': 491.32552069296196, 'peace': 664.6363636363636}\n",
      "2021-08-25 17:16:56.782 | INFO     | src.policies:train:122 - Mean episode return: 217.0\n",
      "2021-08-25 17:16:56.782 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.37545454545452\n",
      "2021-08-25 17:16:56.783 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:17:04.624 | INFO     | src.policies:train:159 - Total loss: 1.0016942024230957\n",
      "2021-08-25 17:17:04.625 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 217.0, 'equality': 0.9273336634054283, 'sustainability': 491.32552069296196, 'peace': 664.6363636363636}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 17:17:04.679 | INFO     | src.policies:train:103 - Epoch 459 / 4000\n",
      "2021-08-25 17:17:04.680 | INFO     | src.policies:train:110 - Episode 459\n",
      "2021-08-25 17:17:24.019 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:17:24.041 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 218.0, 'equality': 0.931458033210792, 'sustainability': 497.5436715045045, 'peace': 560.4545454545455}\n",
      "2021-08-25 17:17:24.041 | INFO     | src.policies:train:122 - Mean episode return: 218.0\n",
      "2021-08-25 17:17:24.042 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.53272727272727\n",
      "2021-08-25 17:17:24.042 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:17:31.750 | INFO     | src.policies:train:159 - Total loss: 1.0022579431533813\n",
      "2021-08-25 17:17:31.750 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 218.0, 'equality': 0.931458033210792, 'sustainability': 497.5436715045045, 'peace': 560.4545454545455}\n",
      "2021-08-25 17:17:31.801 | INFO     | src.policies:train:103 - Epoch 460 / 4000\n",
      "2021-08-25 17:17:31.802 | INFO     | src.policies:train:110 - Episode 460\n",
      "2021-08-25 17:17:50.710 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:17:50.730 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 195.63636363636363, 'equality': 0.9254815816169846, 'sustainability': 459.5145208257869, 'peace': 683.6363636363636}\n",
      "2021-08-25 17:17:50.731 | INFO     | src.policies:train:122 - Mean episode return: 195.63636363636363\n",
      "2021-08-25 17:17:50.731 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.3881818181818\n",
      "2021-08-25 17:17:50.732 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:17:58.732 | INFO     | src.policies:train:159 - Total loss: 1.000616431236267\n",
      "2021-08-25 17:17:58.733 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 195.63636363636363, 'equality': 0.9254815816169846, 'sustainability': 459.5145208257869, 'peace': 683.6363636363636}\n",
      "2021-08-25 17:17:58.782 | INFO     | src.policies:train:103 - Epoch 461 / 4000\n",
      "2021-08-25 17:17:58.783 | INFO     | src.policies:train:110 - Episode 461\n",
      "2021-08-25 17:18:19.983 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:18:20.005 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 207.72727272727272, 'equality': 0.9543266361656191, 'sustainability': 510.4442130795606, 'peace': 769.3636363636364}\n",
      "2021-08-25 17:18:20.005 | INFO     | src.policies:train:122 - Mean episode return: 207.72727272727272\n",
      "2021-08-25 17:18:20.006 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.37181818181816\n",
      "2021-08-25 17:18:20.006 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:18:27.976 | INFO     | src.policies:train:159 - Total loss: 0.9986048936843872\n",
      "2021-08-25 17:18:27.977 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 207.72727272727272, 'equality': 0.9543266361656191, 'sustainability': 510.4442130795606, 'peace': 769.3636363636364}\n",
      "2021-08-25 17:18:28.026 | INFO     | src.policies:train:103 - Epoch 462 / 4000\n",
      "2021-08-25 17:18:28.027 | INFO     | src.policies:train:110 - Episode 462\n",
      "2021-08-25 17:18:48.604 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:18:48.629 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 208.0, 'equality': 0.94516846789683, 'sustainability': 477.17793794673975, 'peace': 715.4545454545455}\n",
      "2021-08-25 17:18:48.629 | INFO     | src.policies:train:122 - Mean episode return: 208.0\n",
      "2021-08-25 17:18:48.630 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.27272727272725\n",
      "2021-08-25 17:18:48.630 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:18:56.340 | INFO     | src.policies:train:159 - Total loss: 0.9992414116859436\n",
      "2021-08-25 17:18:56.341 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 208.0, 'equality': 0.94516846789683, 'sustainability': 477.17793794673975, 'peace': 715.4545454545455}\n",
      "2021-08-25 17:18:56.387 | INFO     | src.policies:train:103 - Epoch 463 / 4000\n",
      "2021-08-25 17:18:56.388 | INFO     | src.policies:train:110 - Episode 463\n",
      "2021-08-25 17:19:15.909 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:19:15.929 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 210.9090909090909, 'equality': 0.9181818181834212, 'sustainability': 483.4161664089542, 'peace': 696.7272727272727}\n",
      "2021-08-25 17:19:15.930 | INFO     | src.policies:train:122 - Mean episode return: 210.9090909090909\n",
      "2021-08-25 17:19:15.931 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.28727272727272\n",
      "2021-08-25 17:19:15.931 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:19:23.637 | INFO     | src.policies:train:159 - Total loss: 0.9986222386360168\n",
      "2021-08-25 17:19:23.637 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 210.9090909090909, 'equality': 0.9181818181834212, 'sustainability': 483.4161664089542, 'peace': 696.7272727272727}\n",
      "2021-08-25 17:19:23.688 | INFO     | src.policies:train:103 - Epoch 464 / 4000\n",
      "2021-08-25 17:19:23.689 | INFO     | src.policies:train:110 - Episode 464\n",
      "2021-08-25 17:19:43.209 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:19:43.231 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 210.45454545454547, 'equality': 0.9247594737890289, 'sustainability': 470.61322148524596, 'peace': 654.2727272727273}\n",
      "2021-08-25 17:19:43.232 | INFO     | src.policies:train:122 - Mean episode return: 210.45454545454547\n",
      "2021-08-25 17:19:43.232 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.28181818181815\n",
      "2021-08-25 17:19:43.233 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:19:51.730 | INFO     | src.policies:train:159 - Total loss: 0.9987890124320984\n",
      "2021-08-25 17:19:51.731 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 210.45454545454547, 'equality': 0.9247594737890289, 'sustainability': 470.61322148524596, 'peace': 654.2727272727273}\n",
      "2021-08-25 17:19:51.780 | INFO     | src.policies:train:103 - Epoch 465 / 4000\n",
      "2021-08-25 17:19:51.780 | INFO     | src.policies:train:110 - Episode 465\n",
      "2021-08-25 17:20:11.417 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:20:11.448 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 206.54545454545453, 'equality': 0.9403809218961992, 'sustainability': 495.10269162957644, 'peace': 769.7272727272727}\n",
      "2021-08-25 17:20:11.448 | INFO     | src.policies:train:122 - Mean episode return: 206.54545454545453\n",
      "2021-08-25 17:20:11.449 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.3709090909091\n",
      "2021-08-25 17:20:11.449 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:20:20.008 | INFO     | src.policies:train:159 - Total loss: 1.0031445026397705\n",
      "2021-08-25 17:20:20.009 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 206.54545454545453, 'equality': 0.9403809218961992, 'sustainability': 495.10269162957644, 'peace': 769.7272727272727}\n",
      "2021-08-25 17:20:20.061 | INFO     | src.policies:train:103 - Epoch 466 / 4000\n",
      "2021-08-25 17:20:20.061 | INFO     | src.policies:train:110 - Episode 466\n",
      "2021-08-25 17:20:42.397 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:20:42.421 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 209.63636363636363, 'equality': 0.9035717101651113, 'sustainability': 471.49309729936516, 'peace': 748.3636363636364}\n",
      "2021-08-25 17:20:42.422 | INFO     | src.policies:train:122 - Mean episode return: 209.63636363636363\n",
      "2021-08-25 17:20:42.422 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.47454545454545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 17:20:42.423 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:20:51.095 | INFO     | src.policies:train:159 - Total loss: 1.0025179386138916\n",
      "2021-08-25 17:20:51.096 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 209.63636363636363, 'equality': 0.9035717101651113, 'sustainability': 471.49309729936516, 'peace': 748.3636363636364}\n",
      "2021-08-25 17:20:51.147 | INFO     | src.policies:train:103 - Epoch 467 / 4000\n",
      "2021-08-25 17:20:51.148 | INFO     | src.policies:train:110 - Episode 467\n",
      "2021-08-25 17:21:11.603 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:21:11.629 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 215.36363636363637, 'equality': 0.9585555854031514, 'sustainability': 469.51767296253547, 'peace': 707.7272727272727}\n",
      "2021-08-25 17:21:11.630 | INFO     | src.policies:train:122 - Mean episode return: 215.36363636363637\n",
      "2021-08-25 17:21:11.631 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.4527272727273\n",
      "2021-08-25 17:21:11.631 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:21:20.263 | INFO     | src.policies:train:159 - Total loss: 1.0003877878189087\n",
      "2021-08-25 17:21:20.263 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 215.36363636363637, 'equality': 0.9585555854031514, 'sustainability': 469.51767296253547, 'peace': 707.7272727272727}\n",
      "2021-08-25 17:21:20.313 | INFO     | src.policies:train:103 - Epoch 468 / 4000\n",
      "2021-08-25 17:21:20.313 | INFO     | src.policies:train:110 - Episode 468\n",
      "2021-08-25 17:21:42.513 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:21:42.538 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 203.0909090909091, 'equality': 0.9081142671134509, 'sustainability': 484.193796722781, 'peace': 700.1818181818181}\n",
      "2021-08-25 17:21:42.539 | INFO     | src.policies:train:122 - Mean episode return: 203.0909090909091\n",
      "2021-08-25 17:21:42.539 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.62\n",
      "2021-08-25 17:21:42.540 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:21:51.226 | INFO     | src.policies:train:159 - Total loss: 1.003191590309143\n",
      "2021-08-25 17:21:51.226 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 203.0909090909091, 'equality': 0.9081142671134509, 'sustainability': 484.193796722781, 'peace': 700.1818181818181}\n",
      "2021-08-25 17:21:51.275 | INFO     | src.policies:train:103 - Epoch 469 / 4000\n",
      "2021-08-25 17:21:51.275 | INFO     | src.policies:train:110 - Episode 469\n",
      "2021-08-25 17:22:11.793 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:22:11.816 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 224.0, 'equality': 0.9390495867779839, 'sustainability': 478.9000784341259, 'peace': 750.4545454545455}\n",
      "2021-08-25 17:22:11.817 | INFO     | src.policies:train:122 - Mean episode return: 224.0\n",
      "2021-08-25 17:22:11.817 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.67636363636365\n",
      "2021-08-25 17:22:11.818 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:22:20.447 | INFO     | src.policies:train:159 - Total loss: 0.997498095035553\n",
      "2021-08-25 17:22:20.448 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 224.0, 'equality': 0.9390495867779839, 'sustainability': 478.9000784341259, 'peace': 750.4545454545455}\n",
      "2021-08-25 17:22:20.498 | INFO     | src.policies:train:103 - Epoch 470 / 4000\n",
      "2021-08-25 17:22:20.499 | INFO     | src.policies:train:110 - Episode 470\n",
      "2021-08-25 17:22:42.865 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:22:42.891 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 216.45454545454547, 'equality': 0.9647970676956817, 'sustainability': 494.5494864810065, 'peace': 691.4545454545455}\n",
      "2021-08-25 17:22:42.892 | INFO     | src.policies:train:122 - Mean episode return: 216.45454545454547\n",
      "2021-08-25 17:22:42.893 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.73\n",
      "2021-08-25 17:22:42.893 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:22:52.085 | INFO     | src.policies:train:159 - Total loss: 1.004165530204773\n",
      "2021-08-25 17:22:52.085 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 216.45454545454547, 'equality': 0.9647970676956817, 'sustainability': 494.5494864810065, 'peace': 691.4545454545455}\n",
      "2021-08-25 17:22:52.137 | INFO     | src.policies:train:103 - Epoch 471 / 4000\n",
      "2021-08-25 17:22:52.138 | INFO     | src.policies:train:110 - Episode 471\n",
      "2021-08-25 17:23:13.357 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:23:13.380 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 210.27272727272728, 'equality': 0.9145541013262085, 'sustainability': 490.86478263623115, 'peace': 757.1818181818181}\n",
      "2021-08-25 17:23:13.381 | INFO     | src.policies:train:122 - Mean episode return: 210.27272727272728\n",
      "2021-08-25 17:23:13.381 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.63363636363636\n",
      "2021-08-25 17:23:13.382 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:23:21.635 | INFO     | src.policies:train:159 - Total loss: 0.990954577922821\n",
      "2021-08-25 17:23:21.636 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 210.27272727272728, 'equality': 0.9145541013262085, 'sustainability': 490.86478263623115, 'peace': 757.1818181818181}\n",
      "2021-08-25 17:23:21.688 | INFO     | src.policies:train:103 - Epoch 472 / 4000\n",
      "2021-08-25 17:23:21.688 | INFO     | src.policies:train:110 - Episode 472\n",
      "2021-08-25 17:23:41.312 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:23:41.334 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 193.9090909090909, 'equality': 0.901632357330656, 'sustainability': 496.7707075259379, 'peace': 727.7272727272727}\n",
      "2021-08-25 17:23:41.334 | INFO     | src.policies:train:122 - Mean episode return: 193.9090909090909\n",
      "2021-08-25 17:23:41.335 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.38636363636363\n",
      "2021-08-25 17:23:41.335 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:23:49.330 | INFO     | src.policies:train:159 - Total loss: 1.0007840394973755\n",
      "2021-08-25 17:23:49.331 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 193.9090909090909, 'equality': 0.901632357330656, 'sustainability': 496.7707075259379, 'peace': 727.7272727272727}\n",
      "2021-08-25 17:23:49.386 | INFO     | src.policies:train:103 - Epoch 473 / 4000\n",
      "2021-08-25 17:23:49.387 | INFO     | src.policies:train:110 - Episode 473\n",
      "2021-08-25 17:24:08.355 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:24:08.375 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 214.36363636363637, 'equality': 0.8969080114138155, 'sustainability': 485.330126159593, 'peace': 609.5454545454545}\n",
      "2021-08-25 17:24:08.376 | INFO     | src.policies:train:122 - Mean episode return: 214.36363636363637\n",
      "2021-08-25 17:24:08.376 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.35272727272724\n",
      "2021-08-25 17:24:08.377 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:24:16.367 | INFO     | src.policies:train:159 - Total loss: 1.0025707483291626\n",
      "2021-08-25 17:24:16.368 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 214.36363636363637, 'equality': 0.8969080114138155, 'sustainability': 485.330126159593, 'peace': 609.5454545454545}\n",
      "2021-08-25 17:24:16.418 | INFO     | src.policies:train:103 - Epoch 474 / 4000\n",
      "2021-08-25 17:24:16.418 | INFO     | src.policies:train:110 - Episode 474\n",
      "2021-08-25 17:24:35.663 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 17:24:35.681 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 214.0, 'equality': 0.9050745346430626, 'sustainability': 489.2240399955357, 'peace': 747.0909090909091}\n",
      "2021-08-25 17:24:35.681 | INFO     | src.policies:train:122 - Mean episode return: 214.0\n",
      "2021-08-25 17:24:35.682 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.5036363636364\n",
      "2021-08-25 17:24:35.682 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:24:43.355 | INFO     | src.policies:train:159 - Total loss: 0.9998958706855774\n",
      "2021-08-25 17:24:43.356 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 214.0, 'equality': 0.9050745346430626, 'sustainability': 489.2240399955357, 'peace': 747.0909090909091}\n",
      "2021-08-25 17:24:43.410 | INFO     | src.policies:train:103 - Epoch 475 / 4000\n",
      "2021-08-25 17:24:43.410 | INFO     | src.policies:train:110 - Episode 475\n",
      "2021-08-25 17:25:03.614 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:25:03.636 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 199.45454545454547, 'equality': 0.9259136487957671, 'sustainability': 479.2579274656129, 'peace': 713.8181818181819}\n",
      "2021-08-25 17:25:03.636 | INFO     | src.policies:train:122 - Mean episode return: 199.45454545454547\n",
      "2021-08-25 17:25:03.637 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.1981818181818\n",
      "2021-08-25 17:25:03.637 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:25:11.339 | INFO     | src.policies:train:159 - Total loss: 1.0001299381256104\n",
      "2021-08-25 17:25:11.340 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 199.45454545454547, 'equality': 0.9259136487957671, 'sustainability': 479.2579274656129, 'peace': 713.8181818181819}\n",
      "2021-08-25 17:25:11.392 | INFO     | src.policies:train:103 - Epoch 476 / 4000\n",
      "2021-08-25 17:25:11.393 | INFO     | src.policies:train:110 - Episode 476\n",
      "2021-08-25 17:25:29.826 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:25:29.847 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 200.1818181818182, 'equality': 0.9053752786742346, 'sustainability': 468.42862054673606, 'peace': 711.1818181818181}\n",
      "2021-08-25 17:25:29.848 | INFO     | src.policies:train:122 - Mean episode return: 200.1818181818182\n",
      "2021-08-25 17:25:29.848 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.15181818181816\n",
      "2021-08-25 17:25:29.849 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:25:37.687 | INFO     | src.policies:train:159 - Total loss: 1.006219744682312\n",
      "2021-08-25 17:25:37.688 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 200.1818181818182, 'equality': 0.9053752786742346, 'sustainability': 468.42862054673606, 'peace': 711.1818181818181}\n",
      "2021-08-25 17:25:37.737 | INFO     | src.policies:train:103 - Epoch 477 / 4000\n",
      "2021-08-25 17:25:37.737 | INFO     | src.policies:train:110 - Episode 477\n",
      "2021-08-25 17:25:57.262 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:25:57.281 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 211.72727272727272, 'equality': 0.9310667863708367, 'sustainability': 489.4024310157518, 'peace': 718.8181818181819}\n",
      "2021-08-25 17:25:57.282 | INFO     | src.policies:train:122 - Mean episode return: 211.72727272727272\n",
      "2021-08-25 17:25:57.283 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.19181818181815\n",
      "2021-08-25 17:25:57.283 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:26:05.376 | INFO     | src.policies:train:159 - Total loss: 0.9986311197280884\n",
      "2021-08-25 17:26:05.377 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 211.72727272727272, 'equality': 0.9310667863708367, 'sustainability': 489.4024310157518, 'peace': 718.8181818181819}\n",
      "2021-08-25 17:26:05.427 | INFO     | src.policies:train:103 - Epoch 478 / 4000\n",
      "2021-08-25 17:26:05.428 | INFO     | src.policies:train:110 - Episode 478\n",
      "2021-08-25 17:26:25.311 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:26:25.333 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 211.0909090909091, 'equality': 0.9251429018885533, 'sustainability': 492.9736984021222, 'peace': 795.0909090909091}\n",
      "2021-08-25 17:26:25.333 | INFO     | src.policies:train:122 - Mean episode return: 211.0909090909091\n",
      "2021-08-25 17:26:25.334 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.24272727272725\n",
      "2021-08-25 17:26:25.334 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:26:33.654 | INFO     | src.policies:train:159 - Total loss: 1.0078483819961548\n",
      "2021-08-25 17:26:33.655 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 211.0909090909091, 'equality': 0.9251429018885533, 'sustainability': 492.9736984021222, 'peace': 795.0909090909091}\n",
      "2021-08-25 17:26:33.708 | INFO     | src.policies:train:103 - Epoch 479 / 4000\n",
      "2021-08-25 17:26:33.709 | INFO     | src.policies:train:110 - Episode 479\n",
      "2021-08-25 17:26:53.662 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:26:53.683 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 206.1818181818182, 'equality': 0.9307359307373189, 'sustainability': 480.35318909229335, 'peace': 651.2727272727273}\n",
      "2021-08-25 17:26:53.684 | INFO     | src.policies:train:122 - Mean episode return: 206.1818181818182\n",
      "2021-08-25 17:26:53.684 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.20454545454544\n",
      "2021-08-25 17:26:53.685 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:27:01.879 | INFO     | src.policies:train:159 - Total loss: 1.0058419704437256\n",
      "2021-08-25 17:27:01.880 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 206.1818181818182, 'equality': 0.9307359307373189, 'sustainability': 480.35318909229335, 'peace': 651.2727272727273}\n",
      "2021-08-25 17:27:01.933 | INFO     | src.policies:train:103 - Epoch 480 / 4000\n",
      "2021-08-25 17:27:01.934 | INFO     | src.policies:train:110 - Episode 480\n",
      "2021-08-25 17:27:22.153 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:27:22.178 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 226.27272727272728, 'equality': 0.9556594470222496, 'sustainability': 493.7892821808635, 'peace': 718.1818181818181}\n",
      "2021-08-25 17:27:22.178 | INFO     | src.policies:train:122 - Mean episode return: 226.27272727272728\n",
      "2021-08-25 17:27:22.179 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.39454545454544\n",
      "2021-08-25 17:27:22.179 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:27:30.257 | INFO     | src.policies:train:159 - Total loss: 1.0006558895111084\n",
      "2021-08-25 17:27:30.258 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 226.27272727272728, 'equality': 0.9556594470222496, 'sustainability': 493.7892821808635, 'peace': 718.1818181818181}\n",
      "2021-08-25 17:27:30.310 | INFO     | src.policies:train:103 - Epoch 481 / 4000\n",
      "2021-08-25 17:27:30.311 | INFO     | src.policies:train:110 - Episode 481\n",
      "2021-08-25 17:27:50.932 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:27:50.954 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 212.27272727272728, 'equality': 0.9208876776343997, 'sustainability': 481.3227532526727, 'peace': 710.6363636363636}\n",
      "2021-08-25 17:27:50.955 | INFO     | src.policies:train:122 - Mean episode return: 212.27272727272728\n",
      "2021-08-25 17:27:50.956 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.4636363636364\n",
      "2021-08-25 17:27:50.956 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:27:58.684 | INFO     | src.policies:train:159 - Total loss: 1.0033177137374878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 17:27:58.685 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 212.27272727272728, 'equality': 0.9208876776343997, 'sustainability': 481.3227532526727, 'peace': 710.6363636363636}\n",
      "2021-08-25 17:27:58.733 | INFO     | src.policies:train:103 - Epoch 482 / 4000\n",
      "2021-08-25 17:27:58.734 | INFO     | src.policies:train:110 - Episode 482\n",
      "2021-08-25 17:28:17.950 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:28:17.973 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 204.1818181818182, 'equality': 0.8737958390699871, 'sustainability': 478.41441990569837, 'peace': 701.7272727272727}\n",
      "2021-08-25 17:28:17.974 | INFO     | src.policies:train:122 - Mean episode return: 204.1818181818182\n",
      "2021-08-25 17:28:17.974 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.50181818181824\n",
      "2021-08-25 17:28:17.975 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:28:25.944 | INFO     | src.policies:train:159 - Total loss: 1.001261830329895\n",
      "2021-08-25 17:28:25.945 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 204.1818181818182, 'equality': 0.8737958390699871, 'sustainability': 478.41441990569837, 'peace': 701.7272727272727}\n",
      "2021-08-25 17:28:25.994 | INFO     | src.policies:train:103 - Epoch 483 / 4000\n",
      "2021-08-25 17:28:25.995 | INFO     | src.policies:train:110 - Episode 483\n",
      "2021-08-25 17:28:45.547 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:28:45.573 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 218.1818181818182, 'equality': 0.9321969696982538, 'sustainability': 508.8485718770044, 'peace': 797.0909090909091}\n",
      "2021-08-25 17:28:45.574 | INFO     | src.policies:train:122 - Mean episode return: 218.1818181818182\n",
      "2021-08-25 17:28:45.574 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.74090909090913\n",
      "2021-08-25 17:28:45.575 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:28:53.401 | INFO     | src.policies:train:159 - Total loss: 0.9956754446029663\n",
      "2021-08-25 17:28:53.401 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 218.1818181818182, 'equality': 0.9321969696982538, 'sustainability': 508.8485718770044, 'peace': 797.0909090909091}\n",
      "2021-08-25 17:28:53.461 | INFO     | src.policies:train:103 - Epoch 484 / 4000\n",
      "2021-08-25 17:28:53.462 | INFO     | src.policies:train:110 - Episode 484\n",
      "2021-08-25 17:29:12.797 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:29:12.815 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 215.54545454545453, 'equality': 0.9317510831652975, 'sustainability': 484.88873236300446, 'peace': 732.9090909090909}\n",
      "2021-08-25 17:29:12.815 | INFO     | src.policies:train:122 - Mean episode return: 215.54545454545453\n",
      "2021-08-25 17:29:12.816 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.79818181818183\n",
      "2021-08-25 17:29:12.816 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:29:20.499 | INFO     | src.policies:train:159 - Total loss: 0.999173104763031\n",
      "2021-08-25 17:29:20.500 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 215.54545454545453, 'equality': 0.9317510831652975, 'sustainability': 484.88873236300446, 'peace': 732.9090909090909}\n",
      "2021-08-25 17:29:20.545 | INFO     | src.policies:train:103 - Epoch 485 / 4000\n",
      "2021-08-25 17:29:20.545 | INFO     | src.policies:train:110 - Episode 485\n",
      "2021-08-25 17:29:40.033 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:29:40.055 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 225.0909090909091, 'equality': 0.9308268468216547, 'sustainability': 493.09275654276803, 'peace': 717.6363636363636}\n",
      "2021-08-25 17:29:40.056 | INFO     | src.policies:train:122 - Mean episode return: 225.0909090909091\n",
      "2021-08-25 17:29:40.057 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.9818181818182\n",
      "2021-08-25 17:29:40.057 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:29:47.708 | INFO     | src.policies:train:159 - Total loss: 0.9994487166404724\n",
      "2021-08-25 17:29:47.709 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 225.0909090909091, 'equality': 0.9308268468216547, 'sustainability': 493.09275654276803, 'peace': 717.6363636363636}\n",
      "2021-08-25 17:29:47.756 | INFO     | src.policies:train:103 - Epoch 486 / 4000\n",
      "2021-08-25 17:29:47.757 | INFO     | src.policies:train:110 - Episode 486\n",
      "2021-08-25 17:30:08.254 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:30:08.275 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 211.1818181818182, 'equality': 0.9482643916575693, 'sustainability': 476.0664804550475, 'peace': 735.3636363636364}\n",
      "2021-08-25 17:30:08.276 | INFO     | src.policies:train:122 - Mean episode return: 211.1818181818182\n",
      "2021-08-25 17:30:08.277 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.87636363636366\n",
      "2021-08-25 17:30:08.277 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:30:16.112 | INFO     | src.policies:train:159 - Total loss: 1.0005828142166138\n",
      "2021-08-25 17:30:16.113 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 211.1818181818182, 'equality': 0.9482643916575693, 'sustainability': 476.0664804550475, 'peace': 735.3636363636364}\n",
      "2021-08-25 17:30:16.160 | INFO     | src.policies:train:103 - Epoch 487 / 4000\n",
      "2021-08-25 17:30:16.161 | INFO     | src.policies:train:110 - Episode 487\n",
      "2021-08-25 17:30:35.545 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:30:35.567 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 217.27272727272728, 'equality': 0.9425637124392818, 'sustainability': 471.4098682436432, 'peace': 727.0}\n",
      "2021-08-25 17:30:35.568 | INFO     | src.policies:train:122 - Mean episode return: 217.27272727272728\n",
      "2021-08-25 17:30:35.568 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.9736363636364\n",
      "2021-08-25 17:30:35.569 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:30:43.489 | INFO     | src.policies:train:159 - Total loss: 1.004499912261963\n",
      "2021-08-25 17:30:43.490 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 217.27272727272728, 'equality': 0.9425637124392818, 'sustainability': 471.4098682436432, 'peace': 727.0}\n",
      "2021-08-25 17:30:43.539 | INFO     | src.policies:train:103 - Epoch 488 / 4000\n",
      "2021-08-25 17:30:43.539 | INFO     | src.policies:train:110 - Episode 488\n",
      "2021-08-25 17:31:04.276 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:31:04.299 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 192.9090909090909, 'equality': 0.9163739182607237, 'sustainability': 482.1892384877223, 'peace': 674.0}\n",
      "2021-08-25 17:31:04.299 | INFO     | src.policies:train:122 - Mean episode return: 192.9090909090909\n",
      "2021-08-25 17:31:04.300 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.83727272727276\n",
      "2021-08-25 17:31:04.300 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:31:12.499 | INFO     | src.policies:train:159 - Total loss: 0.99825119972229\n",
      "2021-08-25 17:31:12.500 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 192.9090909090909, 'equality': 0.9163739182607237, 'sustainability': 482.1892384877223, 'peace': 674.0}\n",
      "2021-08-25 17:31:12.550 | INFO     | src.policies:train:103 - Epoch 489 / 4000\n",
      "2021-08-25 17:31:12.551 | INFO     | src.policies:train:110 - Episode 489\n",
      "2021-08-25 17:31:32.737 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:31:32.759 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 195.9090909090909, 'equality': 0.9012866483884985, 'sustainability': 448.64522671352063, 'peace': 627.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 17:31:32.760 | INFO     | src.policies:train:122 - Mean episode return: 195.9090909090909\n",
      "2021-08-25 17:31:32.760 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.5954545454546\n",
      "2021-08-25 17:31:32.761 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:31:40.961 | INFO     | src.policies:train:159 - Total loss: 1.0029457807540894\n",
      "2021-08-25 17:31:40.962 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 195.9090909090909, 'equality': 0.9012866483884985, 'sustainability': 448.64522671352063, 'peace': 627.0}\n",
      "2021-08-25 17:31:41.013 | INFO     | src.policies:train:103 - Epoch 490 / 4000\n",
      "2021-08-25 17:31:41.014 | INFO     | src.policies:train:110 - Episode 490\n",
      "2021-08-25 17:32:01.700 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:32:01.726 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 228.1818181818182, 'equality': 0.9552336110113141, 'sustainability': 487.15975279073973, 'peace': 796.8181818181819}\n",
      "2021-08-25 17:32:01.727 | INFO     | src.policies:train:122 - Mean episode return: 228.1818181818182\n",
      "2021-08-25 17:32:01.727 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.76454545454547\n",
      "2021-08-25 17:32:01.728 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:32:09.953 | INFO     | src.policies:train:159 - Total loss: 0.9998437762260437\n",
      "2021-08-25 17:32:09.953 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 228.1818181818182, 'equality': 0.9552336110113141, 'sustainability': 487.15975279073973, 'peace': 796.8181818181819}\n",
      "2021-08-25 17:32:10.005 | INFO     | src.policies:train:103 - Epoch 491 / 4000\n",
      "2021-08-25 17:32:10.005 | INFO     | src.policies:train:110 - Episode 491\n",
      "2021-08-25 17:32:30.618 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:32:30.642 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 196.45454545454547, 'equality': 0.8602498843157577, 'sustainability': 482.68349144900697, 'peace': 687.0909090909091}\n",
      "2021-08-25 17:32:30.642 | INFO     | src.policies:train:122 - Mean episode return: 196.45454545454547\n",
      "2021-08-25 17:32:30.643 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.7054545454546\n",
      "2021-08-25 17:32:30.643 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:32:39.034 | INFO     | src.policies:train:159 - Total loss: 1.0030986070632935\n",
      "2021-08-25 17:32:39.034 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 196.45454545454547, 'equality': 0.8602498843157577, 'sustainability': 482.68349144900697, 'peace': 687.0909090909091}\n",
      "2021-08-25 17:32:39.085 | INFO     | src.policies:train:103 - Epoch 492 / 4000\n",
      "2021-08-25 17:32:39.086 | INFO     | src.policies:train:110 - Episode 492\n",
      "2021-08-25 17:33:00.173 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:33:00.198 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 202.1818181818182, 'equality': 0.8670699803820497, 'sustainability': 478.49182499224213, 'peace': 692.0}\n",
      "2021-08-25 17:33:00.198 | INFO     | src.policies:train:122 - Mean episode return: 202.1818181818182\n",
      "2021-08-25 17:33:00.199 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.70909090909092\n",
      "2021-08-25 17:33:00.200 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:33:08.339 | INFO     | src.policies:train:159 - Total loss: 1.002921462059021\n",
      "2021-08-25 17:33:08.340 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 202.1818181818182, 'equality': 0.8670699803820497, 'sustainability': 478.49182499224213, 'peace': 692.0}\n",
      "2021-08-25 17:33:08.389 | INFO     | src.policies:train:103 - Epoch 493 / 4000\n",
      "2021-08-25 17:33:08.390 | INFO     | src.policies:train:110 - Episode 493\n",
      "2021-08-25 17:33:30.052 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:33:30.075 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 215.27272727272728, 'equality': 0.9090909090926541, 'sustainability': 500.3919085351418, 'peace': 746.3636363636364}\n",
      "2021-08-25 17:33:30.076 | INFO     | src.policies:train:122 - Mean episode return: 215.27272727272728\n",
      "2021-08-25 17:33:30.077 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.7918181818182\n",
      "2021-08-25 17:33:30.077 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:33:38.705 | INFO     | src.policies:train:159 - Total loss: 0.9987732768058777\n",
      "2021-08-25 17:33:38.705 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 215.27272727272728, 'equality': 0.9090909090926541, 'sustainability': 500.3919085351418, 'peace': 746.3636363636364}\n",
      "2021-08-25 17:33:38.751 | INFO     | src.policies:train:103 - Epoch 494 / 4000\n",
      "2021-08-25 17:33:38.752 | INFO     | src.policies:train:110 - Episode 494\n",
      "2021-08-25 17:33:59.893 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:33:59.915 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 222.0909090909091, 'equality': 0.9307855468326799, 'sustainability': 495.16787092383873, 'peace': 842.3636363636364}\n",
      "2021-08-25 17:33:59.915 | INFO     | src.policies:train:122 - Mean episode return: 222.0909090909091\n",
      "2021-08-25 17:33:59.916 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.02454545454543\n",
      "2021-08-25 17:33:59.916 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:34:08.421 | INFO     | src.policies:train:159 - Total loss: 1.0034223794937134\n",
      "2021-08-25 17:34:08.422 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 222.0909090909091, 'equality': 0.9307855468326799, 'sustainability': 495.16787092383873, 'peace': 842.3636363636364}\n",
      "2021-08-25 17:34:08.472 | INFO     | src.policies:train:103 - Epoch 495 / 4000\n",
      "2021-08-25 17:34:08.473 | INFO     | src.policies:train:110 - Episode 495\n",
      "2021-08-25 17:34:29.124 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:34:29.149 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 201.63636363636363, 'equality': 0.8851545208647194, 'sustainability': 481.9893509041103, 'peace': 701.0}\n",
      "2021-08-25 17:34:29.150 | INFO     | src.policies:train:122 - Mean episode return: 201.63636363636363\n",
      "2021-08-25 17:34:29.150 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.0118181818182\n",
      "2021-08-25 17:34:29.151 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:34:37.662 | INFO     | src.policies:train:159 - Total loss: 1.004475474357605\n",
      "2021-08-25 17:34:37.663 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 201.63636363636363, 'equality': 0.8851545208647194, 'sustainability': 481.9893509041103, 'peace': 701.0}\n",
      "2021-08-25 17:34:37.713 | INFO     | src.policies:train:103 - Epoch 496 / 4000\n",
      "2021-08-25 17:34:37.713 | INFO     | src.policies:train:110 - Episode 496\n",
      "2021-08-25 17:34:57.664 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:34:57.687 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 196.1818181818182, 'equality': 0.926952565508321, 'sustainability': 476.6755695756637, 'peace': 664.0}\n",
      "2021-08-25 17:34:57.687 | INFO     | src.policies:train:122 - Mean episode return: 196.1818181818182\n",
      "2021-08-25 17:34:57.688 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.90636363636364\n",
      "2021-08-25 17:34:57.688 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:35:06.381 | INFO     | src.policies:train:159 - Total loss: 0.9970625638961792\n",
      "2021-08-25 17:35:06.382 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 196.1818181818182, 'equality': 0.926952565508321, 'sustainability': 476.6755695756637, 'peace': 664.0}\n",
      "2021-08-25 17:35:06.433 | INFO     | src.policies:train:103 - Epoch 497 / 4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 17:35:06.434 | INFO     | src.policies:train:110 - Episode 497\n",
      "2021-08-25 17:35:27.338 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:35:27.362 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 205.54545454545453, 'equality': 0.9119456395015892, 'sustainability': 487.1775688662811, 'peace': 665.7272727272727}\n",
      "2021-08-25 17:35:27.363 | INFO     | src.policies:train:122 - Mean episode return: 205.54545454545453\n",
      "2021-08-25 17:35:27.364 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.83272727272728\n",
      "2021-08-25 17:35:27.364 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:35:35.984 | INFO     | src.policies:train:159 - Total loss: 1.000747561454773\n",
      "2021-08-25 17:35:35.985 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 205.54545454545453, 'equality': 0.9119456395015892, 'sustainability': 487.1775688662811, 'peace': 665.7272727272727}\n",
      "2021-08-25 17:35:36.037 | INFO     | src.policies:train:103 - Epoch 498 / 4000\n",
      "2021-08-25 17:35:36.037 | INFO     | src.policies:train:110 - Episode 498\n",
      "2021-08-25 17:35:57.233 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:35:57.254 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 200.72727272727272, 'equality': 0.8890810276702676, 'sustainability': 484.80980929226354, 'peace': 666.0909090909091}\n",
      "2021-08-25 17:35:57.255 | INFO     | src.policies:train:122 - Mean episode return: 200.72727272727272\n",
      "2021-08-25 17:35:57.255 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.9636363636364\n",
      "2021-08-25 17:35:57.256 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:36:05.956 | INFO     | src.policies:train:159 - Total loss: 0.997306227684021\n",
      "2021-08-25 17:36:05.957 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 200.72727272727272, 'equality': 0.8890810276702676, 'sustainability': 484.80980929226354, 'peace': 666.0909090909091}\n",
      "2021-08-25 17:36:06.008 | INFO     | src.policies:train:103 - Epoch 499 / 4000\n",
      "2021-08-25 17:36:06.008 | INFO     | src.policies:train:110 - Episode 499\n",
      "2021-08-25 17:36:27.920 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:36:27.940 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 212.0, 'equality': 0.9398097614232845, 'sustainability': 489.2881248124235, 'peace': 671.9090909090909}\n",
      "2021-08-25 17:36:27.941 | INFO     | src.policies:train:122 - Mean episode return: 212.0\n",
      "2021-08-25 17:36:27.941 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.81363636363636\n",
      "2021-08-25 17:36:27.942 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:36:36.150 | INFO     | src.policies:train:159 - Total loss: 1.0007823705673218\n",
      "2021-08-25 17:36:36.151 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 212.0, 'equality': 0.9398097614232845, 'sustainability': 489.2881248124235, 'peace': 671.9090909090909}\n",
      "2021-08-25 17:36:36.198 | INFO     | src.policies:train:103 - Epoch 500 / 4000\n",
      "2021-08-25 17:36:36.198 | INFO     | src.policies:train:110 - Episode 500\n",
      "2021-08-25 17:36:57.248 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:36:57.268 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 215.0909090909091, 'equality': 0.9136248367034192, 'sustainability': 472.40262014970233, 'peace': 691.5454545454545}\n",
      "2021-08-25 17:36:57.269 | INFO     | src.policies:train:122 - Mean episode return: 215.0909090909091\n",
      "2021-08-25 17:36:57.269 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.9527272727273\n",
      "2021-08-25 17:36:57.270 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:37:05.900 | INFO     | src.policies:train:159 - Total loss: 1.002568244934082\n",
      "2021-08-25 17:37:05.901 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 215.0909090909091, 'equality': 0.9136248367034192, 'sustainability': 472.40262014970233, 'peace': 691.5454545454545}\n",
      "2021-08-25 17:37:05.949 | INFO     | src.policies:train:103 - Epoch 501 / 4000\n",
      "2021-08-25 17:37:05.950 | INFO     | src.policies:train:110 - Episode 501\n",
      "2021-08-25 17:37:26.563 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:37:26.584 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 211.54545454545453, 'equality': 0.9592921045442964, 'sustainability': 485.7245125902922, 'peace': 729.5454545454545}\n",
      "2021-08-25 17:37:26.585 | INFO     | src.policies:train:122 - Mean episode return: 211.54545454545453\n",
      "2021-08-25 17:37:26.585 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 208.07\n",
      "2021-08-25 17:37:26.586 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:37:35.299 | INFO     | src.policies:train:159 - Total loss: 0.9958000779151917\n",
      "2021-08-25 17:37:35.300 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 211.54545454545453, 'equality': 0.9592921045442964, 'sustainability': 485.7245125902922, 'peace': 729.5454545454545}\n",
      "2021-08-25 17:37:35.351 | INFO     | src.policies:train:103 - Epoch 502 / 4000\n",
      "2021-08-25 17:37:35.351 | INFO     | src.policies:train:110 - Episode 502\n",
      "2021-08-25 17:37:56.912 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:37:56.934 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 190.9090909090909, 'equality': 0.8960173160195667, 'sustainability': 446.22362862929253, 'peace': 607.1818181818181}\n",
      "2021-08-25 17:37:56.935 | INFO     | src.policies:train:122 - Mean episode return: 190.9090909090909\n",
      "2021-08-25 17:37:56.935 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.85\n",
      "2021-08-25 17:37:56.935 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:38:05.652 | INFO     | src.policies:train:159 - Total loss: 0.9983638525009155\n",
      "2021-08-25 17:38:05.653 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 190.9090909090909, 'equality': 0.8960173160195667, 'sustainability': 446.22362862929253, 'peace': 607.1818181818181}\n",
      "2021-08-25 17:38:05.703 | INFO     | src.policies:train:103 - Epoch 503 / 4000\n",
      "2021-08-25 17:38:05.703 | INFO     | src.policies:train:110 - Episode 503\n",
      "2021-08-25 17:38:27.573 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:38:27.598 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 210.0909090909091, 'equality': 0.9286416742077683, 'sustainability': 487.2406641603053, 'peace': 727.3636363636364}\n",
      "2021-08-25 17:38:27.598 | INFO     | src.policies:train:122 - Mean episode return: 210.0909090909091\n",
      "2021-08-25 17:38:27.599 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.84545454545452\n",
      "2021-08-25 17:38:27.599 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:38:36.231 | INFO     | src.policies:train:159 - Total loss: 0.9964964985847473\n",
      "2021-08-25 17:38:36.232 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 210.0909090909091, 'equality': 0.9286416742077683, 'sustainability': 487.2406641603053, 'peace': 727.3636363636364}\n",
      "2021-08-25 17:38:36.284 | INFO     | src.policies:train:103 - Epoch 504 / 4000\n",
      "2021-08-25 17:38:36.285 | INFO     | src.policies:train:110 - Episode 504\n",
      "2021-08-25 17:38:57.902 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:38:57.925 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 198.36363636363637, 'equality': 0.9232563953019903, 'sustainability': 490.92758214744697, 'peace': 647.9090909090909}\n",
      "2021-08-25 17:38:57.926 | INFO     | src.policies:train:122 - Mean episode return: 198.36363636363637\n",
      "2021-08-25 17:38:57.927 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.89545454545456\n",
      "2021-08-25 17:38:57.927 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 17:39:06.553 | INFO     | src.policies:train:159 - Total loss: 1.000697135925293\n",
      "2021-08-25 17:39:06.553 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 198.36363636363637, 'equality': 0.9232563953019903, 'sustainability': 490.92758214744697, 'peace': 647.9090909090909}\n",
      "2021-08-25 17:39:06.603 | INFO     | src.policies:train:103 - Epoch 505 / 4000\n",
      "2021-08-25 17:39:06.603 | INFO     | src.policies:train:110 - Episode 505\n",
      "2021-08-25 17:39:28.957 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:39:28.978 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 200.0909090909091, 'equality': 0.9041757878669989, 'sustainability': 495.05250537341107, 'peace': 702.1818181818181}\n",
      "2021-08-25 17:39:28.979 | INFO     | src.policies:train:122 - Mean episode return: 200.0909090909091\n",
      "2021-08-25 17:39:28.980 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.68818181818185\n",
      "2021-08-25 17:39:28.980 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:39:37.517 | INFO     | src.policies:train:159 - Total loss: 0.9965280294418335\n",
      "2021-08-25 17:39:37.517 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 200.0909090909091, 'equality': 0.9041757878669989, 'sustainability': 495.05250537341107, 'peace': 702.1818181818181}\n",
      "2021-08-25 17:39:37.565 | INFO     | src.policies:train:103 - Epoch 506 / 4000\n",
      "2021-08-25 17:39:37.566 | INFO     | src.policies:train:110 - Episode 506\n",
      "2021-08-25 17:39:58.854 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:39:58.882 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 210.54545454545453, 'equality': 0.926754592559139, 'sustainability': 496.119739134009, 'peace': 777.3636363636364}\n",
      "2021-08-25 17:39:58.882 | INFO     | src.policies:train:122 - Mean episode return: 210.54545454545453\n",
      "2021-08-25 17:39:58.883 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.77090909090907\n",
      "2021-08-25 17:39:58.883 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:40:07.502 | INFO     | src.policies:train:159 - Total loss: 1.004309058189392\n",
      "2021-08-25 17:40:07.503 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 210.54545454545453, 'equality': 0.926754592559139, 'sustainability': 496.119739134009, 'peace': 777.3636363636364}\n",
      "2021-08-25 17:40:07.551 | INFO     | src.policies:train:103 - Epoch 507 / 4000\n",
      "2021-08-25 17:40:07.552 | INFO     | src.policies:train:110 - Episode 507\n",
      "2021-08-25 17:40:28.957 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:40:28.981 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 208.0, 'equality': 0.9265734265748853, 'sustainability': 489.14669985366487, 'peace': 774.7272727272727}\n",
      "2021-08-25 17:40:28.982 | INFO     | src.policies:train:122 - Mean episode return: 208.0\n",
      "2021-08-25 17:40:28.982 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.70636363636365\n",
      "2021-08-25 17:40:28.983 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:40:37.784 | INFO     | src.policies:train:159 - Total loss: 0.9952563047409058\n",
      "2021-08-25 17:40:37.785 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 208.0, 'equality': 0.9265734265748853, 'sustainability': 489.14669985366487, 'peace': 774.7272727272727}\n",
      "2021-08-25 17:40:37.831 | INFO     | src.policies:train:103 - Epoch 508 / 4000\n",
      "2021-08-25 17:40:37.832 | INFO     | src.policies:train:110 - Episode 508\n",
      "2021-08-25 17:41:00.242 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:41:00.265 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 187.9090909090909, 'equality': 0.9042969609028391, 'sustainability': 478.6988286326874, 'peace': 625.2727272727273}\n",
      "2021-08-25 17:41:00.266 | INFO     | src.policies:train:122 - Mean episode return: 187.9090909090909\n",
      "2021-08-25 17:41:00.266 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.52090909090913\n",
      "2021-08-25 17:41:00.266 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:41:09.047 | INFO     | src.policies:train:159 - Total loss: 1.0005323886871338\n",
      "2021-08-25 17:41:09.048 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 187.9090909090909, 'equality': 0.9042969609028391, 'sustainability': 478.6988286326874, 'peace': 625.2727272727273}\n",
      "2021-08-25 17:41:09.096 | INFO     | src.policies:train:103 - Epoch 509 / 4000\n",
      "2021-08-25 17:41:09.097 | INFO     | src.policies:train:110 - Episode 509\n",
      "2021-08-25 17:41:33.179 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:41:33.213 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 211.0, 'equality': 0.9372527515581597, 'sustainability': 470.0176874559325, 'peace': 685.4545454545455}\n",
      "2021-08-25 17:41:33.214 | INFO     | src.policies:train:122 - Mean episode return: 211.0\n",
      "2021-08-25 17:41:33.214 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.64090909090908\n",
      "2021-08-25 17:41:33.215 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:41:42.964 | INFO     | src.policies:train:159 - Total loss: 0.9978744387626648\n",
      "2021-08-25 17:41:42.965 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 211.0, 'equality': 0.9372527515581597, 'sustainability': 470.0176874559325, 'peace': 685.4545454545455}\n",
      "2021-08-25 17:41:43.019 | INFO     | src.policies:train:103 - Epoch 510 / 4000\n",
      "2021-08-25 17:41:43.019 | INFO     | src.policies:train:110 - Episode 510\n",
      "2021-08-25 17:42:06.373 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:42:06.396 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 220.63636363636363, 'equality': 0.9262089373351649, 'sustainability': 508.75147946940103, 'peace': 772.3636363636364}\n",
      "2021-08-25 17:42:06.397 | INFO     | src.policies:train:122 - Mean episode return: 220.63636363636363\n",
      "2021-08-25 17:42:06.397 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.62818181818184\n",
      "2021-08-25 17:42:06.398 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:42:15.229 | INFO     | src.policies:train:159 - Total loss: 1.0017849206924438\n",
      "2021-08-25 17:42:15.230 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 220.63636363636363, 'equality': 0.9262089373351649, 'sustainability': 508.75147946940103, 'peace': 772.3636363636364}\n",
      "2021-08-25 17:42:15.279 | INFO     | src.policies:train:103 - Epoch 511 / 4000\n",
      "2021-08-25 17:42:15.280 | INFO     | src.policies:train:110 - Episode 511\n",
      "2021-08-25 17:42:38.068 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:42:38.090 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 189.9090909090909, 'equality': 0.8832847382418015, 'sustainability': 511.7555867720262, 'peace': 655.4545454545455}\n",
      "2021-08-25 17:42:38.091 | INFO     | src.policies:train:122 - Mean episode return: 189.9090909090909\n",
      "2021-08-25 17:42:38.092 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.41000000000003\n",
      "2021-08-25 17:42:38.092 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:42:47.309 | INFO     | src.policies:train:159 - Total loss: 1.005737543106079\n",
      "2021-08-25 17:42:47.310 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 189.9090909090909, 'equality': 0.8832847382418015, 'sustainability': 511.7555867720262, 'peace': 655.4545454545455}\n",
      "2021-08-25 17:42:47.363 | INFO     | src.policies:train:103 - Epoch 512 / 4000\n",
      "2021-08-25 17:42:47.364 | INFO     | src.policies:train:110 - Episode 512\n",
      "2021-08-25 17:43:09.833 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:43:09.857 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 193.0909090909091, 'equality': 0.8655196028106164, 'sustainability': 491.9531938803957, 'peace': 676.5454545454545}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 17:43:09.857 | INFO     | src.policies:train:122 - Mean episode return: 193.0909090909091\n",
      "2021-08-25 17:43:09.858 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.05272727272728\n",
      "2021-08-25 17:43:09.858 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:43:18.859 | INFO     | src.policies:train:159 - Total loss: 0.9945150017738342\n",
      "2021-08-25 17:43:18.860 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 193.0909090909091, 'equality': 0.8655196028106164, 'sustainability': 491.9531938803957, 'peace': 676.5454545454545}\n",
      "2021-08-25 17:43:18.912 | INFO     | src.policies:train:103 - Epoch 513 / 4000\n",
      "2021-08-25 17:43:18.913 | INFO     | src.policies:train:110 - Episode 513\n",
      "2021-08-25 17:43:42.312 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:43:42.335 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 228.27272727272728, 'equality': 0.9254190652053615, 'sustainability': 490.46745455773817, 'peace': 805.5454545454545}\n",
      "2021-08-25 17:43:42.336 | INFO     | src.policies:train:122 - Mean episode return: 228.27272727272728\n",
      "2021-08-25 17:43:42.336 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.23181818181817\n",
      "2021-08-25 17:43:42.337 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:43:51.418 | INFO     | src.policies:train:159 - Total loss: 1.005735993385315\n",
      "2021-08-25 17:43:51.418 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 228.27272727272728, 'equality': 0.9254190652053615, 'sustainability': 490.46745455773817, 'peace': 805.5454545454545}\n",
      "2021-08-25 17:43:51.466 | INFO     | src.policies:train:103 - Epoch 514 / 4000\n",
      "2021-08-25 17:43:51.466 | INFO     | src.policies:train:110 - Episode 514\n",
      "2021-08-25 17:44:13.597 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:44:13.621 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 216.1818181818182, 'equality': 0.9216300940453852, 'sustainability': 499.85500337545454, 'peace': 753.7272727272727}\n",
      "2021-08-25 17:44:13.622 | INFO     | src.policies:train:122 - Mean episode return: 216.1818181818182\n",
      "2021-08-25 17:44:13.622 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.28000000000003\n",
      "2021-08-25 17:44:13.623 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:44:22.534 | INFO     | src.policies:train:159 - Total loss: 1.0074325799942017\n",
      "2021-08-25 17:44:22.535 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 216.1818181818182, 'equality': 0.9216300940453852, 'sustainability': 499.85500337545454, 'peace': 753.7272727272727}\n",
      "2021-08-25 17:44:22.593 | INFO     | src.policies:train:103 - Epoch 515 / 4000\n",
      "2021-08-25 17:44:22.594 | INFO     | src.policies:train:110 - Episode 515\n",
      "2021-08-25 17:44:46.092 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:44:46.118 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 202.27272727272728, 'equality': 0.9188559754868466, 'sustainability': 498.11430984192737, 'peace': 622.0909090909091}\n",
      "2021-08-25 17:44:46.118 | INFO     | src.policies:train:122 - Mean episode return: 202.27272727272728\n",
      "2021-08-25 17:44:46.119 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.19727272727272\n",
      "2021-08-25 17:44:46.119 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:44:55.840 | INFO     | src.policies:train:159 - Total loss: 1.003420352935791\n",
      "2021-08-25 17:44:55.841 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 202.27272727272728, 'equality': 0.9188559754868466, 'sustainability': 498.11430984192737, 'peace': 622.0909090909091}\n",
      "2021-08-25 17:44:55.896 | INFO     | src.policies:train:103 - Epoch 516 / 4000\n",
      "2021-08-25 17:44:55.896 | INFO     | src.policies:train:110 - Episode 516\n",
      "2021-08-25 17:45:21.613 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:45:21.638 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 217.8181818181818, 'equality': 0.9656245257253449, 'sustainability': 489.49670936880557, 'peace': 698.0}\n",
      "2021-08-25 17:45:21.639 | INFO     | src.policies:train:122 - Mean episode return: 217.8181818181818\n",
      "2021-08-25 17:45:21.639 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.2690909090909\n",
      "2021-08-25 17:45:21.640 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:45:31.571 | INFO     | src.policies:train:159 - Total loss: 1.0058122873306274\n",
      "2021-08-25 17:45:31.571 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 217.8181818181818, 'equality': 0.9656245257253449, 'sustainability': 489.49670936880557, 'peace': 698.0}\n",
      "2021-08-25 17:45:31.627 | INFO     | src.policies:train:103 - Epoch 517 / 4000\n",
      "2021-08-25 17:45:31.628 | INFO     | src.policies:train:110 - Episode 517\n",
      "2021-08-25 17:45:56.047 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:45:56.072 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 199.1818181818182, 'equality': 0.9473880751846938, 'sustainability': 496.6856957912409, 'peace': 764.7272727272727}\n",
      "2021-08-25 17:45:56.073 | INFO     | src.policies:train:122 - Mean episode return: 199.1818181818182\n",
      "2021-08-25 17:45:56.073 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.23909090909092\n",
      "2021-08-25 17:45:56.074 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:46:05.436 | INFO     | src.policies:train:159 - Total loss: 1.0013446807861328\n",
      "2021-08-25 17:46:05.437 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 199.1818181818182, 'equality': 0.9473880751846938, 'sustainability': 496.6856957912409, 'peace': 764.7272727272727}\n",
      "2021-08-25 17:46:05.489 | INFO     | src.policies:train:103 - Epoch 518 / 4000\n",
      "2021-08-25 17:46:05.489 | INFO     | src.policies:train:110 - Episode 518\n",
      "2021-08-25 17:46:29.057 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:46:29.087 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 222.9090909090909, 'equality': 0.9266646893087894, 'sustainability': 479.2766456274732, 'peace': 840.9090909090909}\n",
      "2021-08-25 17:46:29.087 | INFO     | src.policies:train:122 - Mean episode return: 222.9090909090909\n",
      "2021-08-25 17:46:29.088 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.35363636363635\n",
      "2021-08-25 17:46:29.088 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:46:38.999 | INFO     | src.policies:train:159 - Total loss: 1.0038715600967407\n",
      "2021-08-25 17:46:39.000 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 222.9090909090909, 'equality': 0.9266646893087894, 'sustainability': 479.2766456274732, 'peace': 840.9090909090909}\n",
      "2021-08-25 17:46:39.057 | INFO     | src.policies:train:103 - Epoch 519 / 4000\n",
      "2021-08-25 17:46:39.058 | INFO     | src.policies:train:110 - Episode 519\n",
      "2021-08-25 17:47:03.912 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:47:03.938 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 205.0909090909091, 'equality': 0.894906511929906, 'sustainability': 499.14871173783246, 'peace': 700.7272727272727}\n",
      "2021-08-25 17:47:03.939 | INFO     | src.policies:train:122 - Mean episode return: 205.0909090909091\n",
      "2021-08-25 17:47:03.939 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.3909090909091\n",
      "2021-08-25 17:47:03.940 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:47:13.930 | INFO     | src.policies:train:159 - Total loss: 0.9981655478477478\n",
      "2021-08-25 17:47:13.931 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 205.0909090909091, 'equality': 0.894906511929906, 'sustainability': 499.14871173783246, 'peace': 700.7272727272727}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 17:47:13.988 | INFO     | src.policies:train:103 - Epoch 520 / 4000\n",
      "2021-08-25 17:47:13.988 | INFO     | src.policies:train:110 - Episode 520\n",
      "2021-08-25 17:47:38.669 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:47:38.694 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 192.45454545454547, 'equality': 0.9312062524169878, 'sustainability': 446.0349382458822, 'peace': 548.2727272727273}\n",
      "2021-08-25 17:47:38.694 | INFO     | src.policies:train:122 - Mean episode return: 192.45454545454547\n",
      "2021-08-25 17:47:38.695 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.13727272727274\n",
      "2021-08-25 17:47:38.695 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:47:48.645 | INFO     | src.policies:train:159 - Total loss: 0.9994122385978699\n",
      "2021-08-25 17:47:48.646 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 192.45454545454547, 'equality': 0.9312062524169878, 'sustainability': 446.0349382458822, 'peace': 548.2727272727273}\n",
      "2021-08-25 17:47:48.701 | INFO     | src.policies:train:103 - Epoch 521 / 4000\n",
      "2021-08-25 17:47:48.701 | INFO     | src.policies:train:110 - Episode 521\n",
      "2021-08-25 17:48:13.572 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:48:13.602 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 217.0909090909091, 'equality': 0.9419065022091155, 'sustainability': 497.17860525403535, 'peace': 712.6363636363636}\n",
      "2021-08-25 17:48:13.603 | INFO     | src.policies:train:122 - Mean episode return: 217.0909090909091\n",
      "2021-08-25 17:48:13.603 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.28727272727272\n",
      "2021-08-25 17:48:13.604 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:48:23.155 | INFO     | src.policies:train:159 - Total loss: 0.9989302754402161\n",
      "2021-08-25 17:48:23.156 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 217.0909090909091, 'equality': 0.9419065022091155, 'sustainability': 497.17860525403535, 'peace': 712.6363636363636}\n",
      "2021-08-25 17:48:23.207 | INFO     | src.policies:train:103 - Epoch 522 / 4000\n",
      "2021-08-25 17:48:23.208 | INFO     | src.policies:train:110 - Episode 522\n",
      "2021-08-25 17:48:49.328 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:48:49.355 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 213.63636363636363, 'equality': 0.9332301740825294, 'sustainability': 492.06333316683356, 'peace': 731.6363636363636}\n",
      "2021-08-25 17:48:49.355 | INFO     | src.policies:train:122 - Mean episode return: 213.63636363636363\n",
      "2021-08-25 17:48:49.356 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.4172727272727\n",
      "2021-08-25 17:48:49.357 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:49:00.203 | INFO     | src.policies:train:159 - Total loss: 1.0073003768920898\n",
      "2021-08-25 17:49:00.204 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 213.63636363636363, 'equality': 0.9332301740825294, 'sustainability': 492.06333316683356, 'peace': 731.6363636363636}\n",
      "2021-08-25 17:49:00.259 | INFO     | src.policies:train:103 - Epoch 523 / 4000\n",
      "2021-08-25 17:49:00.259 | INFO     | src.policies:train:110 - Episode 523\n",
      "2021-08-25 17:49:26.922 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:49:26.948 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 211.1818181818182, 'equality': 0.9475599733896694, 'sustainability': 491.50867607449504, 'peace': 715.1818181818181}\n",
      "2021-08-25 17:49:26.949 | INFO     | src.policies:train:122 - Mean episode return: 211.1818181818182\n",
      "2021-08-25 17:49:26.949 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.61636363636364\n",
      "2021-08-25 17:49:26.950 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:49:36.989 | INFO     | src.policies:train:159 - Total loss: 0.9997409582138062\n",
      "2021-08-25 17:49:36.989 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 211.1818181818182, 'equality': 0.9475599733896694, 'sustainability': 491.50867607449504, 'peace': 715.1818181818181}\n",
      "2021-08-25 17:49:37.046 | INFO     | src.policies:train:103 - Epoch 524 / 4000\n",
      "2021-08-25 17:49:37.047 | INFO     | src.policies:train:110 - Episode 524\n",
      "2021-08-25 17:50:01.201 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:50:01.229 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 209.54545454545453, 'equality': 0.893433247882204, 'sustainability': 486.16645219296186, 'peace': 733.3636363636364}\n",
      "2021-08-25 17:50:01.229 | INFO     | src.policies:train:122 - Mean episode return: 209.54545454545453\n",
      "2021-08-25 17:50:01.230 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.5527272727273\n",
      "2021-08-25 17:50:01.230 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:50:10.748 | INFO     | src.policies:train:159 - Total loss: 0.9959771633148193\n",
      "2021-08-25 17:50:10.748 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 209.54545454545453, 'equality': 0.893433247882204, 'sustainability': 486.16645219296186, 'peace': 733.3636363636364}\n",
      "2021-08-25 17:50:10.805 | INFO     | src.policies:train:103 - Epoch 525 / 4000\n",
      "2021-08-25 17:50:10.805 | INFO     | src.policies:train:110 - Episode 525\n",
      "2021-08-25 17:50:38.936 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:50:38.966 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 226.0909090909091, 'equality': 0.959132945864694, 'sustainability': 503.88650541715106, 'peace': 820.7272727272727}\n",
      "2021-08-25 17:50:38.966 | INFO     | src.policies:train:122 - Mean episode return: 226.0909090909091\n",
      "2021-08-25 17:50:38.967 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.7454545454546\n",
      "2021-08-25 17:50:38.968 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:50:49.974 | INFO     | src.policies:train:159 - Total loss: 0.9992204904556274\n",
      "2021-08-25 17:50:49.975 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 226.0909090909091, 'equality': 0.959132945864694, 'sustainability': 503.88650541715106, 'peace': 820.7272727272727}\n",
      "2021-08-25 17:50:50.039 | INFO     | src.policies:train:103 - Epoch 526 / 4000\n",
      "2021-08-25 17:50:50.039 | INFO     | src.policies:train:110 - Episode 526\n",
      "2021-08-25 17:51:17.098 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:51:17.124 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 213.36363636363637, 'equality': 0.9284967269642388, 'sustainability': 497.67640642153367, 'peace': 720.1818181818181}\n",
      "2021-08-25 17:51:17.125 | INFO     | src.policies:train:122 - Mean episode return: 213.36363636363637\n",
      "2021-08-25 17:51:17.125 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.89909090909092\n",
      "2021-08-25 17:51:17.126 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:51:27.057 | INFO     | src.policies:train:159 - Total loss: 1.0058214664459229\n",
      "2021-08-25 17:51:27.057 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 213.36363636363637, 'equality': 0.9284967269642388, 'sustainability': 497.67640642153367, 'peace': 720.1818181818181}\n",
      "2021-08-25 17:51:27.110 | INFO     | src.policies:train:103 - Epoch 527 / 4000\n",
      "2021-08-25 17:51:27.110 | INFO     | src.policies:train:110 - Episode 527\n",
      "2021-08-25 17:51:53.235 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:51:53.262 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 206.0, 'equality': 0.9477653855422498, 'sustainability': 491.0232116942009, 'peace': 624.0}\n",
      "2021-08-25 17:51:53.262 | INFO     | src.policies:train:122 - Mean episode return: 206.0\n",
      "2021-08-25 17:51:53.263 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.69181818181815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 17:51:53.263 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:52:04.468 | INFO     | src.policies:train:159 - Total loss: 1.0051045417785645\n",
      "2021-08-25 17:52:04.469 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 206.0, 'equality': 0.9477653855422498, 'sustainability': 491.0232116942009, 'peace': 624.0}\n",
      "2021-08-25 17:52:04.537 | INFO     | src.policies:train:103 - Epoch 528 / 4000\n",
      "2021-08-25 17:52:04.538 | INFO     | src.policies:train:110 - Episode 528\n",
      "2021-08-25 17:52:35.501 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:52:35.533 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 196.1818181818182, 'equality': 0.924003707137838, 'sustainability': 476.1330106341124, 'peace': 600.8181818181819}\n",
      "2021-08-25 17:52:35.534 | INFO     | src.policies:train:122 - Mean episode return: 196.1818181818182\n",
      "2021-08-25 17:52:35.534 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.60636363636365\n",
      "2021-08-25 17:52:35.535 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:52:47.346 | INFO     | src.policies:train:159 - Total loss: 1.0061562061309814\n",
      "2021-08-25 17:52:47.346 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 196.1818181818182, 'equality': 0.924003707137838, 'sustainability': 476.1330106341124, 'peace': 600.8181818181819}\n",
      "2021-08-25 17:52:47.409 | INFO     | src.policies:train:103 - Epoch 529 / 4000\n",
      "2021-08-25 17:52:47.410 | INFO     | src.policies:train:110 - Episode 529\n",
      "2021-08-25 17:53:16.634 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:53:16.663 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 213.0909090909091, 'equality': 0.9391870927718898, 'sustainability': 494.77458917056316, 'peace': 775.3636363636364}\n",
      "2021-08-25 17:53:16.664 | INFO     | src.policies:train:122 - Mean episode return: 213.0909090909091\n",
      "2021-08-25 17:53:16.665 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.7418181818182\n",
      "2021-08-25 17:53:16.665 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:53:27.259 | INFO     | src.policies:train:159 - Total loss: 1.0036733150482178\n",
      "2021-08-25 17:53:27.260 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 213.0909090909091, 'equality': 0.9391870927718898, 'sustainability': 494.77458917056316, 'peace': 775.3636363636364}\n",
      "2021-08-25 17:53:27.316 | INFO     | src.policies:train:103 - Epoch 530 / 4000\n",
      "2021-08-25 17:53:27.317 | INFO     | src.policies:train:110 - Episode 530\n",
      "2021-08-25 17:53:53.050 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:53:53.074 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 195.9090909090909, 'equality': 0.9109892427776631, 'sustainability': 478.181317729951, 'peace': 670.3636363636364}\n",
      "2021-08-25 17:53:53.076 | INFO     | src.policies:train:122 - Mean episode return: 195.9090909090909\n",
      "2021-08-25 17:53:53.076 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.5827272727273\n",
      "2021-08-25 17:53:53.077 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:54:02.225 | INFO     | src.policies:train:159 - Total loss: 1.0015448331832886\n",
      "2021-08-25 17:54:02.225 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 195.9090909090909, 'equality': 0.9109892427776631, 'sustainability': 478.181317729951, 'peace': 670.3636363636364}\n",
      "2021-08-25 17:54:02.275 | INFO     | src.policies:train:103 - Epoch 531 / 4000\n",
      "2021-08-25 17:54:02.276 | INFO     | src.policies:train:110 - Episode 531\n",
      "2021-08-25 17:54:23.841 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:54:23.871 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 189.63636363636363, 'equality': 0.9169354135815189, 'sustainability': 478.3212852968026, 'peace': 680.8181818181819}\n",
      "2021-08-25 17:54:23.871 | INFO     | src.policies:train:122 - Mean episode return: 189.63636363636363\n",
      "2021-08-25 17:54:23.872 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.37272727272727\n",
      "2021-08-25 17:54:23.872 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:54:34.053 | INFO     | src.policies:train:159 - Total loss: 1.0010451078414917\n",
      "2021-08-25 17:54:34.053 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 189.63636363636363, 'equality': 0.9169354135815189, 'sustainability': 478.3212852968026, 'peace': 680.8181818181819}\n",
      "2021-08-25 17:54:34.110 | INFO     | src.policies:train:103 - Epoch 532 / 4000\n",
      "2021-08-25 17:54:34.111 | INFO     | src.policies:train:110 - Episode 532\n",
      "2021-08-25 17:55:01.403 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:55:01.430 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 222.1818181818182, 'equality': 0.9055944055961613, 'sustainability': 481.39566379406494, 'peace': 735.1818181818181}\n",
      "2021-08-25 17:55:01.431 | INFO     | src.policies:train:122 - Mean episode return: 222.1818181818182\n",
      "2021-08-25 17:55:01.431 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.68636363636367\n",
      "2021-08-25 17:55:01.432 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:55:12.759 | INFO     | src.policies:train:159 - Total loss: 0.9987959265708923\n",
      "2021-08-25 17:55:12.760 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 222.1818181818182, 'equality': 0.9055944055961613, 'sustainability': 481.39566379406494, 'peace': 735.1818181818181}\n",
      "2021-08-25 17:55:12.815 | INFO     | src.policies:train:103 - Epoch 533 / 4000\n",
      "2021-08-25 17:55:12.816 | INFO     | src.policies:train:110 - Episode 533\n",
      "2021-08-25 17:55:39.509 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:55:39.533 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 220.0909090909091, 'equality': 0.9389433367139998, 'sustainability': 463.86106434407577, 'peace': 691.6363636363636}\n",
      "2021-08-25 17:55:39.533 | INFO     | src.policies:train:122 - Mean episode return: 220.0909090909091\n",
      "2021-08-25 17:55:39.534 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.89818181818183\n",
      "2021-08-25 17:55:39.535 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:55:49.375 | INFO     | src.policies:train:159 - Total loss: 1.0085126161575317\n",
      "2021-08-25 17:55:49.376 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 220.0909090909091, 'equality': 0.9389433367139998, 'sustainability': 463.86106434407577, 'peace': 691.6363636363636}\n",
      "2021-08-25 17:55:49.426 | INFO     | src.policies:train:103 - Epoch 534 / 4000\n",
      "2021-08-25 17:55:49.426 | INFO     | src.policies:train:110 - Episode 534\n",
      "2021-08-25 17:56:15.913 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n",
      "2021-08-25 17:56:15.941 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 200.36363636363637, 'equality': 0.9423362481450599, 'sustainability': 468.0039939980956, 'peace': 656.0909090909091}\n",
      "2021-08-25 17:56:15.942 | INFO     | src.policies:train:122 - Mean episode return: 200.36363636363637\n",
      "2021-08-25 17:56:15.943 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.77818181818185\n",
      "2021-08-25 17:56:15.943 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 17:56:27.096 | INFO     | src.policies:train:159 - Total loss: 1.0024008750915527\n",
      "2021-08-25 17:56:27.097 | INFO     | src.policies:train:164 - Epoch infos: {'efficiency': 200.36363636363637, 'equality': 0.9423362481450599, 'sustainability': 468.0039939980956, 'peace': 656.0909090909091}\n",
      "2021-08-25 17:56:27.151 | INFO     | src.policies:train:103 - Epoch 535 / 4000\n",
      "2021-08-25 17:56:27.152 | INFO     | src.policies:train:110 - Episode 535\n",
      "2021-08-25 17:56:55.894 | DEBUG    | src.policies:execute_episode:270 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 17:56:55.924 | INFO     | src.policies:train:117 - Episode infos: {'efficiency': 208.27272727272728, 'equality': 0.9004007777488909, 'sustainability': 489.5854352726565, 'peace': 648.2727272727273}\n",
      "2021-08-25 17:56:55.925 | INFO     | src.policies:train:122 - Mean episode return: 208.27272727272728\n",
      "2021-08-25 17:56:55.925 | INFO     | src.policies:train:123 - Last 100 episodes mean return: 207.75727272727275\n",
      "2021-08-25 17:56:55.926 | WARNING  | src.policies:train:133 - The actual batch size is 11000, instead of 4000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/pp/wfj1kcws58g7pxksj9k8zdhw0000gn/T/ipykernel_22958/3683872538.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mvpg_baseline_nn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMLP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation_space_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_softmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvpg_policy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVPGPolicy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvpg_policy_nn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline_nn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvpg_baseline_nn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m vpg_policy.train(\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Github/cpr-appropriation/notebooks/../src/policies.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, steps_per_epoch, policy_lr, baseline_lr, discount, save_every, checkpoints_path, enable_wandb, wandb_config, max_episodes, std_returns, episodes_mean_return)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mactual_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrajectories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_timesteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mactual_batch_size\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m                 logger.warning(\n\u001b[0m\u001b[1;32m    137\u001b[0m                     \u001b[0;34mf\"The actual batch size is {actual_batch_size}, instead of {steps_per_epoch}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m                 )\n",
      "\u001b[0;32m~/Github/cpr-appropriation/notebooks/../src/memory.py\u001b[0m in \u001b[0;36mtensorify\u001b[0;34m(self, discount)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd_to_trajectory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m         \"\"\"\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0mAdd\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mtuple\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mth\u001b[0m \u001b[0mtrajectory\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n",
      "\u001b[0;32m~/Github/cpr-appropriation/notebooks/../src/memory.py\u001b[0m in \u001b[0;36mget_next_states\u001b[0;34m(self, as_torch)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mReturn\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mrewards\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0mtrajectory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0meither\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0ma\u001b[0m \u001b[0mNumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0ma\u001b[0m \u001b[0mPyTorch\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \"\"\"\n\u001b[0m\u001b[1;32m     72\u001b[0m         return (\n\u001b[1;32m     73\u001b[0m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vpg_policy_nn = models.MLP(observation_space_size, hidden_sizes, action_space_size)\n",
    "vpg_baseline_nn = models.MLP(observation_space_size, hidden_sizes, 1, log_softmax=False)\n",
    "vpg_policy = policies.VPGPolicy(env, vpg_policy_nn, baseline_nn=vpg_baseline_nn)\n",
    "vpg_policy.train(\n",
    "    epochs,\n",
    "    steps_per_epoch,\n",
    "    enable_wandb=True,\n",
    "    wandb_config={**wandb_config, \"group\": \"VPG\"},\n",
    "    render_every=render_every\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5555b30d",
   "metadata": {},
   "source": [
    "## TRPO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a451b1",
   "metadata": {},
   "source": [
    "This section deals with training a set of Harvest agents using our custom Trust Region Policy Optimization implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "32f4162a",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 1.0\n",
    "kl_target = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf55450",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 18:03:30.853 | DEBUG    | src.policies:execute_episode:294 - Early stopping, all agents done\n",
      "2021-08-25 18:03:30.856 | INFO     | src.policies:train:124 - Episode infos: {'efficiency': 26.09090909090909, 'equality': 0.8131137155823387, 'sustainability': 443.1172088229232, 'peace': 641.9090909090909}\n",
      "2021-08-25 18:03:30.856 | INFO     | src.policies:train:129 - Mean episode return: 26.09090909090909\n",
      "2021-08-25 18:03:30.857 | INFO     | src.policies:train:130 - Last 100 episodes mean return: 26.09090909090909\n",
      "2021-08-25 18:03:30.857 | WARNING  | src.policies:train:140 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 18:03:39.446 | INFO     | src.policies:train:166 - Total loss: 1.1647214889526367\n",
      "2021-08-25 18:03:39.447 | INFO     | src.policies:train:171 - Epoch infos: {'efficiency': 26.09090909090909, 'equality': 0.8131137155823387, 'sustainability': 443.1172088229232, 'peace': 641.9090909090909}\n",
      "2021-08-25 18:03:39.489 | INFO     | src.policies:train:106 - Epoch 2 / 4000\n",
      "2021-08-25 18:03:39.489 | INFO     | src.policies:train:113 - Episode 2\n",
      "2021-08-25 18:04:02.500 | DEBUG    | src.policies:execute_episode:294 - Early stopping, all agents done\n",
      "2021-08-25 18:04:02.527 | INFO     | src.policies:train:124 - Episode infos: {'efficiency': 21.09090909090909, 'equality': 0.833072100346185, 'sustainability': 363.57891707820073, 'peace': 565.4545454545455}\n",
      "2021-08-25 18:04:02.528 | INFO     | src.policies:train:129 - Mean episode return: 21.09090909090909\n",
      "2021-08-25 18:04:02.528 | INFO     | src.policies:train:130 - Last 100 episodes mean return: 23.59090909090909\n",
      "2021-08-25 18:04:02.529 | WARNING  | src.policies:train:140 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 18:04:11.417 | INFO     | src.policies:train:166 - Total loss: 1.1492035388946533\n",
      "2021-08-25 18:04:11.418 | INFO     | src.policies:train:171 - Epoch infos: {'efficiency': 21.09090909090909, 'equality': 0.833072100346185, 'sustainability': 363.57891707820073, 'peace': 565.4545454545455}\n",
      "2021-08-25 18:04:11.466 | INFO     | src.policies:train:106 - Epoch 3 / 4000\n",
      "2021-08-25 18:04:11.467 | INFO     | src.policies:train:113 - Episode 3\n",
      "2021-08-25 18:04:34.264 | DEBUG    | src.policies:execute_episode:294 - Early stopping, all agents done\n",
      "2021-08-25 18:04:34.282 | INFO     | src.policies:train:124 - Episode infos: {'efficiency': 25.545454545454547, 'equality': 0.8453574895106184, 'sustainability': 434.588056071429, 'peace': 665.2727272727273}\n",
      "2021-08-25 18:04:34.283 | INFO     | src.policies:train:129 - Mean episode return: 25.545454545454547\n",
      "2021-08-25 18:04:34.283 | INFO     | src.policies:train:130 - Last 100 episodes mean return: 24.24242424242424\n",
      "2021-08-25 18:04:34.284 | WARNING  | src.policies:train:140 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 18:04:42.905 | INFO     | src.policies:train:166 - Total loss: 1.1363593339920044\n",
      "2021-08-25 18:04:42.905 | INFO     | src.policies:train:171 - Epoch infos: {'efficiency': 25.545454545454547, 'equality': 0.8453574895106184, 'sustainability': 434.588056071429, 'peace': 665.2727272727273}\n",
      "2021-08-25 18:04:42.952 | INFO     | src.policies:train:106 - Epoch 4 / 4000\n",
      "2021-08-25 18:04:42.953 | INFO     | src.policies:train:113 - Episode 4\n",
      "2021-08-25 18:05:04.590 | DEBUG    | src.policies:execute_episode:294 - Early stopping, all agents done\n",
      "2021-08-25 18:05:04.616 | INFO     | src.policies:train:124 - Episode infos: {'efficiency': 17.454545454545453, 'equality': 0.7528409091494221, 'sustainability': 398.0460057619148, 'peace': 597.0}\n",
      "2021-08-25 18:05:04.617 | INFO     | src.policies:train:129 - Mean episode return: 17.454545454545453\n",
      "2021-08-25 18:05:04.617 | INFO     | src.policies:train:130 - Last 100 episodes mean return: 22.545454545454543\n",
      "2021-08-25 18:05:04.618 | WARNING  | src.policies:train:140 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 18:05:14.187 | INFO     | src.policies:train:166 - Total loss: 1.122139811515808\n",
      "2021-08-25 18:05:14.188 | INFO     | src.policies:train:171 - Epoch infos: {'efficiency': 17.454545454545453, 'equality': 0.7528409091494221, 'sustainability': 398.0460057619148, 'peace': 597.0}\n",
      "2021-08-25 18:05:14.244 | INFO     | src.policies:train:106 - Epoch 5 / 4000\n",
      "2021-08-25 18:05:14.245 | INFO     | src.policies:train:113 - Episode 5\n",
      "2021-08-25 18:05:38.360 | DEBUG    | src.policies:execute_episode:294 - Early stopping, all agents done\n",
      "2021-08-25 18:05:38.384 | INFO     | src.policies:train:124 - Episode infos: {'efficiency': 28.363636363636363, 'equality': 0.740675990713771, 'sustainability': 404.011221258083, 'peace': 633.9090909090909}\n",
      "2021-08-25 18:05:38.384 | INFO     | src.policies:train:129 - Mean episode return: 28.363636363636363\n",
      "2021-08-25 18:05:38.385 | INFO     | src.policies:train:130 - Last 100 episodes mean return: 23.709090909090907\n",
      "2021-08-25 18:05:38.385 | WARNING  | src.policies:train:140 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 18:05:47.080 | INFO     | src.policies:train:166 - Total loss: 1.1029518842697144\n",
      "2021-08-25 18:05:47.080 | INFO     | src.policies:train:171 - Epoch infos: {'efficiency': 28.363636363636363, 'equality': 0.740675990713771, 'sustainability': 404.011221258083, 'peace': 633.9090909090909}\n",
      "2021-08-25 18:05:47.128 | INFO     | src.policies:train:106 - Epoch 6 / 4000\n",
      "2021-08-25 18:05:47.129 | INFO     | src.policies:train:113 - Episode 6\n",
      "2021-08-25 18:06:12.445 | DEBUG    | src.policies:execute_episode:294 - Early stopping, all agents done\n",
      "2021-08-25 18:06:12.475 | INFO     | src.policies:train:124 - Episode infos: {'efficiency': 27.0, 'equality': 0.7367615549836606, 'sustainability': 376.1376350367203, 'peace': 581.6363636363636}\n",
      "2021-08-25 18:06:12.476 | INFO     | src.policies:train:129 - Mean episode return: 27.0\n",
      "2021-08-25 18:06:12.476 | INFO     | src.policies:train:130 - Last 100 episodes mean return: 24.257575757575754\n",
      "2021-08-25 18:06:12.477 | WARNING  | src.policies:train:140 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 18:06:22.298 | INFO     | src.policies:train:166 - Total loss: 1.0881969928741455\n",
      "2021-08-25 18:06:22.298 | INFO     | src.policies:train:171 - Epoch infos: {'efficiency': 27.0, 'equality': 0.7367615549836606, 'sustainability': 376.1376350367203, 'peace': 581.6363636363636}\n",
      "2021-08-25 18:06:22.350 | INFO     | src.policies:train:106 - Epoch 7 / 4000\n",
      "2021-08-25 18:06:22.351 | INFO     | src.policies:train:113 - Episode 7\n",
      "2021-08-25 18:06:50.658 | DEBUG    | src.policies:execute_episode:294 - Early stopping, all agents done\n",
      "2021-08-25 18:06:50.685 | INFO     | src.policies:train:124 - Episode infos: {'efficiency': 16.636363636363637, 'equality': 0.7883755589199266, 'sustainability': 354.34490809798586, 'peace': 591.3636363636364}\n",
      "2021-08-25 18:06:50.686 | INFO     | src.policies:train:129 - Mean episode return: 16.636363636363637\n",
      "2021-08-25 18:06:50.686 | INFO     | src.policies:train:130 - Last 100 episodes mean return: 23.168831168831165\n",
      "2021-08-25 18:06:50.687 | WARNING  | src.policies:train:140 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 18:07:01.683 | INFO     | src.policies:train:166 - Total loss: 1.0904042720794678\n",
      "2021-08-25 18:07:01.684 | INFO     | src.policies:train:171 - Epoch infos: {'efficiency': 16.636363636363637, 'equality': 0.7883755589199266, 'sustainability': 354.34490809798586, 'peace': 591.3636363636364}\n",
      "2021-08-25 18:07:01.739 | INFO     | src.policies:train:106 - Epoch 8 / 4000\n",
      "2021-08-25 18:07:01.740 | INFO     | src.policies:train:113 - Episode 8\n",
      "2021-08-25 18:07:26.721 | DEBUG    | src.policies:execute_episode:294 - Early stopping, all agents done\n",
      "2021-08-25 18:07:26.749 | INFO     | src.policies:train:124 - Episode infos: {'efficiency': 25.818181818181817, 'equality': 0.8201024328072819, 'sustainability': 408.41192621129335, 'peace': 605.1818181818181}\n",
      "2021-08-25 18:07:26.750 | INFO     | src.policies:train:129 - Mean episode return: 25.818181818181817\n",
      "2021-08-25 18:07:26.750 | INFO     | src.policies:train:130 - Last 100 episodes mean return: 23.5\n",
      "2021-08-25 18:07:26.751 | WARNING  | src.policies:train:140 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 18:07:36.595 | INFO     | src.policies:train:166 - Total loss: 1.0589079856872559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 18:07:36.595 | INFO     | src.policies:train:171 - Epoch infos: {'efficiency': 25.818181818181817, 'equality': 0.8201024328072819, 'sustainability': 408.41192621129335, 'peace': 605.1818181818181}\n",
      "2021-08-25 18:07:36.645 | INFO     | src.policies:train:106 - Epoch 9 / 4000\n",
      "2021-08-25 18:07:36.645 | INFO     | src.policies:train:113 - Episode 9\n",
      "2021-08-25 18:07:59.038 | DEBUG    | src.policies:execute_episode:294 - Early stopping, all agents done\n",
      "2021-08-25 18:07:59.062 | INFO     | src.policies:train:124 - Episode infos: {'efficiency': 30.181818181818183, 'equality': 0.8247535597173119, 'sustainability': 460.3603476851406, 'peace': 662.2727272727273}\n",
      "2021-08-25 18:07:59.062 | INFO     | src.policies:train:129 - Mean episode return: 30.181818181818183\n",
      "2021-08-25 18:07:59.063 | INFO     | src.policies:train:130 - Last 100 episodes mean return: 24.242424242424242\n",
      "2021-08-25 18:07:59.063 | WARNING  | src.policies:train:140 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 18:08:08.462 | INFO     | src.policies:train:166 - Total loss: 1.060709834098816\n",
      "2021-08-25 18:08:08.463 | INFO     | src.policies:train:171 - Epoch infos: {'efficiency': 30.181818181818183, 'equality': 0.8247535597173119, 'sustainability': 460.3603476851406, 'peace': 662.2727272727273}\n",
      "2021-08-25 18:08:08.512 | INFO     | src.policies:train:106 - Epoch 10 / 4000\n",
      "2021-08-25 18:08:08.513 | INFO     | src.policies:train:113 - Episode 10\n",
      "2021-08-25 18:08:31.480 | DEBUG    | src.policies:execute_episode:294 - Early stopping, all agents done\n",
      "2021-08-25 18:08:31.505 | INFO     | src.policies:train:124 - Episode infos: {'efficiency': 20.545454545454547, 'equality': 0.7868061142826215, 'sustainability': 493.5765490679897, 'peace': 570.5454545454545}\n",
      "2021-08-25 18:08:31.505 | INFO     | src.policies:train:129 - Mean episode return: 20.545454545454547\n",
      "2021-08-25 18:08:31.506 | INFO     | src.policies:train:130 - Last 100 episodes mean return: 23.872727272727275\n",
      "2021-08-25 18:08:31.506 | WARNING  | src.policies:train:140 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 18:08:41.034 | INFO     | src.policies:train:166 - Total loss: 1.0503870248794556\n",
      "2021-08-25 18:08:41.035 | INFO     | src.policies:train:171 - Epoch infos: {'efficiency': 20.545454545454547, 'equality': 0.7868061142826215, 'sustainability': 493.5765490679897, 'peace': 570.5454545454545}\n",
      "2021-08-25 18:08:41.086 | INFO     | src.policies:train:106 - Epoch 11 / 4000\n",
      "2021-08-25 18:08:41.087 | INFO     | src.policies:train:113 - Episode 11\n",
      "2021-08-25 18:09:03.602 | DEBUG    | src.policies:execute_episode:294 - Early stopping, all agents done\n",
      "2021-08-25 18:09:03.630 | INFO     | src.policies:train:124 - Episode infos: {'efficiency': 33.63636363636363, 'equality': 0.8363636363837391, 'sustainability': 412.20358696858693, 'peace': 628.9090909090909}\n",
      "2021-08-25 18:09:03.630 | INFO     | src.policies:train:129 - Mean episode return: 33.63636363636363\n",
      "2021-08-25 18:09:03.631 | INFO     | src.policies:train:130 - Last 100 episodes mean return: 24.7603305785124\n",
      "2021-08-25 18:09:03.631 | WARNING  | src.policies:train:140 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 18:09:13.084 | INFO     | src.policies:train:166 - Total loss: 1.034998893737793\n",
      "2021-08-25 18:09:13.085 | INFO     | src.policies:train:171 - Epoch infos: {'efficiency': 33.63636363636363, 'equality': 0.8363636363837391, 'sustainability': 412.20358696858693, 'peace': 628.9090909090909}\n",
      "2021-08-25 18:09:13.136 | INFO     | src.policies:train:106 - Epoch 12 / 4000\n",
      "2021-08-25 18:09:13.137 | INFO     | src.policies:train:113 - Episode 12\n",
      "2021-08-25 18:09:36.952 | DEBUG    | src.policies:execute_episode:294 - Early stopping, all agents done\n",
      "2021-08-25 18:09:36.976 | INFO     | src.policies:train:124 - Episode infos: {'efficiency': 31.181818181818183, 'equality': 0.8065200106272834, 'sustainability': 412.9514910268084, 'peace': 604.4545454545455}\n",
      "2021-08-25 18:09:36.976 | INFO     | src.policies:train:129 - Mean episode return: 31.181818181818183\n",
      "2021-08-25 18:09:36.977 | INFO     | src.policies:train:130 - Last 100 episodes mean return: 25.295454545454547\n",
      "2021-08-25 18:09:36.977 | WARNING  | src.policies:train:140 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 18:09:46.271 | INFO     | src.policies:train:166 - Total loss: 1.023375391960144\n",
      "2021-08-25 18:09:46.272 | INFO     | src.policies:train:171 - Epoch infos: {'efficiency': 31.181818181818183, 'equality': 0.8065200106272834, 'sustainability': 412.9514910268084, 'peace': 604.4545454545455}\n",
      "2021-08-25 18:09:46.322 | INFO     | src.policies:train:106 - Epoch 13 / 4000\n",
      "2021-08-25 18:09:46.323 | INFO     | src.policies:train:113 - Episode 13\n",
      "2021-08-25 18:10:12.010 | DEBUG    | src.policies:execute_episode:294 - Early stopping, all agents done\n",
      "2021-08-25 18:10:12.033 | INFO     | src.policies:train:124 - Episode infos: {'efficiency': 23.818181818181817, 'equality': 0.8625954198711667, 'sustainability': 440.4119100004416, 'peace': 593.2727272727273}\n",
      "2021-08-25 18:10:12.034 | INFO     | src.policies:train:129 - Mean episode return: 23.818181818181817\n",
      "2021-08-25 18:10:12.035 | INFO     | src.policies:train:130 - Last 100 episodes mean return: 25.181818181818183\n",
      "2021-08-25 18:10:12.035 | WARNING  | src.policies:train:140 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 18:10:21.158 | INFO     | src.policies:train:166 - Total loss: 1.0213372707366943\n",
      "2021-08-25 18:10:21.159 | INFO     | src.policies:train:171 - Epoch infos: {'efficiency': 23.818181818181817, 'equality': 0.8625954198711667, 'sustainability': 440.4119100004416, 'peace': 593.2727272727273}\n",
      "2021-08-25 18:10:21.204 | INFO     | src.policies:train:106 - Epoch 14 / 4000\n",
      "2021-08-25 18:10:21.205 | INFO     | src.policies:train:113 - Episode 14\n",
      "2021-08-25 18:10:43.429 | DEBUG    | src.policies:execute_episode:294 - Early stopping, all agents done\n",
      "2021-08-25 18:10:43.451 | INFO     | src.policies:train:124 - Episode infos: {'efficiency': 25.272727272727273, 'equality': 0.862001308067037, 'sustainability': 415.3872825278952, 'peace': 608.5454545454545}\n",
      "2021-08-25 18:10:43.452 | INFO     | src.policies:train:129 - Mean episode return: 25.272727272727273\n",
      "2021-08-25 18:10:43.452 | INFO     | src.policies:train:130 - Last 100 episodes mean return: 25.18831168831169\n",
      "2021-08-25 18:10:43.453 | WARNING  | src.policies:train:140 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 18:10:52.540 | INFO     | src.policies:train:166 - Total loss: 1.0104527473449707\n",
      "2021-08-25 18:10:52.540 | INFO     | src.policies:train:171 - Epoch infos: {'efficiency': 25.272727272727273, 'equality': 0.862001308067037, 'sustainability': 415.3872825278952, 'peace': 608.5454545454545}\n",
      "2021-08-25 18:10:52.589 | INFO     | src.policies:train:106 - Epoch 15 / 4000\n",
      "2021-08-25 18:10:52.590 | INFO     | src.policies:train:113 - Episode 15\n",
      "2021-08-25 18:11:19.085 | DEBUG    | src.policies:execute_episode:294 - Early stopping, all agents done\n",
      "2021-08-25 18:11:19.127 | INFO     | src.policies:train:124 - Episode infos: {'efficiency': 22.727272727272727, 'equality': 0.7898181818563967, 'sustainability': 416.9834843656488, 'peace': 583.1818181818181}\n",
      "2021-08-25 18:11:19.128 | INFO     | src.policies:train:129 - Mean episode return: 22.727272727272727\n",
      "2021-08-25 18:11:19.129 | INFO     | src.policies:train:130 - Last 100 episodes mean return: 25.024242424242424\n",
      "2021-08-25 18:11:19.130 | WARNING  | src.policies:train:140 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 18:11:30.652 | INFO     | src.policies:train:166 - Total loss: 1.0145004987716675\n",
      "2021-08-25 18:11:30.653 | INFO     | src.policies:train:171 - Epoch infos: {'efficiency': 22.727272727272727, 'equality': 0.7898181818563967, 'sustainability': 416.9834843656488, 'peace': 583.1818181818181}\n",
      "2021-08-25 18:11:30.706 | INFO     | src.policies:train:106 - Epoch 16 / 4000\n",
      "2021-08-25 18:11:30.707 | INFO     | src.policies:train:113 - Episode 16\n",
      "2021-08-25 18:11:58.120 | DEBUG    | src.policies:execute_episode:294 - Early stopping, all agents done\n",
      "2021-08-25 18:11:58.158 | INFO     | src.policies:train:124 - Episode infos: {'efficiency': 24.818181818181817, 'equality': 0.8068598068919648, 'sustainability': 403.14813624376325, 'peace': 582.2727272727273}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 18:11:58.159 | INFO     | src.policies:train:129 - Mean episode return: 24.818181818181817\n",
      "2021-08-25 18:11:58.160 | INFO     | src.policies:train:130 - Last 100 episodes mean return: 25.011363636363633\n",
      "2021-08-25 18:11:58.160 | WARNING  | src.policies:train:140 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 18:12:07.815 | INFO     | src.policies:train:166 - Total loss: 1.0007688999176025\n",
      "2021-08-25 18:12:07.815 | INFO     | src.policies:train:171 - Epoch infos: {'efficiency': 24.818181818181817, 'equality': 0.8068598068919648, 'sustainability': 403.14813624376325, 'peace': 582.2727272727273}\n",
      "2021-08-25 18:12:07.865 | INFO     | src.policies:train:106 - Epoch 17 / 4000\n",
      "2021-08-25 18:12:07.866 | INFO     | src.policies:train:113 - Episode 17\n",
      "2021-08-25 18:12:35.220 | DEBUG    | src.policies:execute_episode:294 - Early stopping, all agents done\n",
      "2021-08-25 18:12:35.247 | INFO     | src.policies:train:124 - Episode infos: {'efficiency': 30.181818181818183, 'equality': 0.8849945235644859, 'sustainability': 410.3584748312393, 'peace': 589.0}\n",
      "2021-08-25 18:12:35.248 | INFO     | src.policies:train:129 - Mean episode return: 30.181818181818183\n",
      "2021-08-25 18:12:35.248 | INFO     | src.policies:train:130 - Last 100 episodes mean return: 25.31550802139037\n",
      "2021-08-25 18:12:35.249 | WARNING  | src.policies:train:140 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 18:12:46.528 | INFO     | src.policies:train:166 - Total loss: 1.0065324306488037\n",
      "2021-08-25 18:12:46.529 | INFO     | src.policies:train:171 - Epoch infos: {'efficiency': 30.181818181818183, 'equality': 0.8849945235644859, 'sustainability': 410.3584748312393, 'peace': 589.0}\n",
      "2021-08-25 18:12:46.581 | INFO     | src.policies:train:106 - Epoch 18 / 4000\n",
      "2021-08-25 18:12:46.581 | INFO     | src.policies:train:113 - Episode 18\n",
      "2021-08-25 18:13:14.354 | DEBUG    | src.policies:execute_episode:294 - Early stopping, all agents done\n",
      "2021-08-25 18:13:14.378 | INFO     | src.policies:train:124 - Episode infos: {'efficiency': 24.272727272727273, 'equality': 0.8072863466449972, 'sustainability': 379.7544861224806, 'peace': 610.4545454545455}\n",
      "2021-08-25 18:13:14.379 | INFO     | src.policies:train:129 - Mean episode return: 24.272727272727273\n",
      "2021-08-25 18:13:14.380 | INFO     | src.policies:train:130 - Last 100 episodes mean return: 25.257575757575754\n",
      "2021-08-25 18:13:14.380 | WARNING  | src.policies:train:140 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 18:13:23.897 | INFO     | src.policies:train:166 - Total loss: 1.005900263786316\n",
      "2021-08-25 18:13:23.897 | INFO     | src.policies:train:171 - Epoch infos: {'efficiency': 24.272727272727273, 'equality': 0.8072863466449972, 'sustainability': 379.7544861224806, 'peace': 610.4545454545455}\n",
      "2021-08-25 18:13:23.942 | INFO     | src.policies:train:106 - Epoch 19 / 4000\n",
      "2021-08-25 18:13:23.943 | INFO     | src.policies:train:113 - Episode 19\n",
      "2021-08-25 18:13:47.215 | DEBUG    | src.policies:execute_episode:294 - Early stopping, all agents done\n",
      "2021-08-25 18:13:47.236 | INFO     | src.policies:train:124 - Episode infos: {'efficiency': 23.363636363636363, 'equality': 0.7849310223231463, 'sustainability': 450.2060029688022, 'peace': 518.8181818181819}\n",
      "2021-08-25 18:13:47.237 | INFO     | src.policies:train:129 - Mean episode return: 23.363636363636363\n",
      "2021-08-25 18:13:47.237 | INFO     | src.policies:train:130 - Last 100 episodes mean return: 25.157894736842103\n",
      "2021-08-25 18:13:47.238 | WARNING  | src.policies:train:140 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 18:13:56.210 | INFO     | src.policies:train:166 - Total loss: 1.0039877891540527\n",
      "2021-08-25 18:13:56.211 | INFO     | src.policies:train:171 - Epoch infos: {'efficiency': 23.363636363636363, 'equality': 0.7849310223231463, 'sustainability': 450.2060029688022, 'peace': 518.8181818181819}\n",
      "2021-08-25 18:13:56.255 | INFO     | src.policies:train:106 - Epoch 20 / 4000\n",
      "2021-08-25 18:13:56.256 | INFO     | src.policies:train:113 - Episode 20\n",
      "2021-08-25 18:14:18.826 | DEBUG    | src.policies:execute_episode:294 - Early stopping, all agents done\n",
      "2021-08-25 18:14:18.853 | INFO     | src.policies:train:124 - Episode infos: {'efficiency': 29.636363636363637, 'equality': 0.8388176241161716, 'sustainability': 458.0257327343548, 'peace': 602.8181818181819}\n",
      "2021-08-25 18:14:18.854 | INFO     | src.policies:train:129 - Mean episode return: 29.636363636363637\n",
      "2021-08-25 18:14:18.855 | INFO     | src.policies:train:130 - Last 100 episodes mean return: 25.38181818181818\n",
      "2021-08-25 18:14:18.855 | WARNING  | src.policies:train:140 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 18:14:27.844 | INFO     | src.policies:train:166 - Total loss: 1.00147545337677\n",
      "2021-08-25 18:14:27.845 | INFO     | src.policies:train:171 - Epoch infos: {'efficiency': 29.636363636363637, 'equality': 0.8388176241161716, 'sustainability': 458.0257327343548, 'peace': 602.8181818181819}\n",
      "2021-08-25 18:14:27.889 | INFO     | src.policies:train:106 - Epoch 21 / 4000\n",
      "2021-08-25 18:14:27.890 | INFO     | src.policies:train:113 - Episode 21\n",
      "2021-08-25 18:14:52.971 | DEBUG    | src.policies:execute_episode:294 - Early stopping, all agents done\n",
      "2021-08-25 18:14:52.993 | INFO     | src.policies:train:124 - Episode infos: {'efficiency': 24.727272727272727, 'equality': 0.7713903743697543, 'sustainability': 413.6864901549506, 'peace': 575.1818181818181}\n",
      "2021-08-25 18:14:52.994 | INFO     | src.policies:train:129 - Mean episode return: 24.727272727272727\n",
      "2021-08-25 18:14:52.994 | INFO     | src.policies:train:130 - Last 100 episodes mean return: 25.350649350649345\n",
      "2021-08-25 18:14:52.995 | WARNING  | src.policies:train:140 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 18:15:02.244 | INFO     | src.policies:train:166 - Total loss: 1.0028563737869263\n",
      "2021-08-25 18:15:02.245 | INFO     | src.policies:train:171 - Epoch infos: {'efficiency': 24.727272727272727, 'equality': 0.7713903743697543, 'sustainability': 413.6864901549506, 'peace': 575.1818181818181}\n",
      "2021-08-25 18:15:02.292 | INFO     | src.policies:train:106 - Epoch 22 / 4000\n",
      "2021-08-25 18:15:02.293 | INFO     | src.policies:train:113 - Episode 22\n",
      "2021-08-25 18:15:24.908 | DEBUG    | src.policies:execute_episode:294 - Early stopping, all agents done\n",
      "2021-08-25 18:15:24.931 | INFO     | src.policies:train:124 - Episode infos: {'efficiency': 18.181818181818183, 'equality': 0.8781818182095041, 'sustainability': 464.687315835509, 'peace': 635.2727272727273}\n",
      "2021-08-25 18:15:24.931 | INFO     | src.policies:train:129 - Mean episode return: 18.181818181818183\n",
      "2021-08-25 18:15:24.932 | INFO     | src.policies:train:130 - Last 100 episodes mean return: 25.024793388429746\n",
      "2021-08-25 18:15:24.932 | WARNING  | src.policies:train:140 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 18:15:34.441 | INFO     | src.policies:train:166 - Total loss: 1.0036137104034424\n",
      "2021-08-25 18:15:34.442 | INFO     | src.policies:train:171 - Epoch infos: {'efficiency': 18.181818181818183, 'equality': 0.8781818182095041, 'sustainability': 464.687315835509, 'peace': 635.2727272727273}\n",
      "2021-08-25 18:15:34.491 | INFO     | src.policies:train:106 - Epoch 23 / 4000\n",
      "2021-08-25 18:15:34.492 | INFO     | src.policies:train:113 - Episode 23\n",
      "2021-08-25 18:15:57.109 | DEBUG    | src.policies:execute_episode:294 - Early stopping, all agents done\n",
      "2021-08-25 18:15:57.135 | INFO     | src.policies:train:124 - Episode infos: {'efficiency': 21.727272727272727, 'equality': 0.7755800685097793, 'sustainability': 414.7741873100162, 'peace': 598.2727272727273}\n",
      "2021-08-25 18:15:57.136 | INFO     | src.policies:train:129 - Mean episode return: 21.727272727272727\n",
      "2021-08-25 18:15:57.136 | INFO     | src.policies:train:130 - Last 100 episodes mean return: 24.88142292490118\n",
      "2021-08-25 18:15:57.137 | WARNING  | src.policies:train:140 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 18:16:06.950 | INFO     | src.policies:train:166 - Total loss: 1.0000221729278564\n",
      "2021-08-25 18:16:06.951 | INFO     | src.policies:train:171 - Epoch infos: {'efficiency': 21.727272727272727, 'equality': 0.7755800685097793, 'sustainability': 414.7741873100162, 'peace': 598.2727272727273}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 18:16:06.999 | INFO     | src.policies:train:106 - Epoch 24 / 4000\n",
      "2021-08-25 18:16:07.000 | INFO     | src.policies:train:113 - Episode 24\n",
      "2021-08-25 18:16:33.516 | DEBUG    | src.policies:execute_episode:294 - Early stopping, all agents done\n",
      "2021-08-25 18:16:33.541 | INFO     | src.policies:train:124 - Episode infos: {'efficiency': 28.454545454545453, 'equality': 0.8083067092930138, 'sustainability': 455.67153466838187, 'peace': 616.1818181818181}\n",
      "2021-08-25 18:16:33.542 | INFO     | src.policies:train:129 - Mean episode return: 28.454545454545453\n",
      "2021-08-25 18:16:33.543 | INFO     | src.policies:train:130 - Last 100 episodes mean return: 25.03030303030303\n",
      "2021-08-25 18:16:33.543 | WARNING  | src.policies:train:140 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 18:16:43.018 | INFO     | src.policies:train:166 - Total loss: 1.000118374824524\n",
      "2021-08-25 18:16:43.019 | INFO     | src.policies:train:171 - Epoch infos: {'efficiency': 28.454545454545453, 'equality': 0.8083067092930138, 'sustainability': 455.67153466838187, 'peace': 616.1818181818181}\n",
      "2021-08-25 18:16:43.066 | INFO     | src.policies:train:106 - Epoch 25 / 4000\n",
      "2021-08-25 18:16:43.067 | INFO     | src.policies:train:113 - Episode 25\n",
      "2021-08-25 18:17:07.396 | DEBUG    | src.policies:execute_episode:294 - Early stopping, all agents done\n",
      "2021-08-25 18:17:07.420 | INFO     | src.policies:train:124 - Episode infos: {'efficiency': 20.727272727272727, 'equality': 0.8030303030695713, 'sustainability': 392.1301643488572, 'peace': 621.3636363636364}\n",
      "2021-08-25 18:17:07.421 | INFO     | src.policies:train:129 - Mean episode return: 20.727272727272727\n",
      "2021-08-25 18:17:07.422 | INFO     | src.policies:train:130 - Last 100 episodes mean return: 24.85818181818182\n",
      "2021-08-25 18:17:07.422 | WARNING  | src.policies:train:140 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 18:17:16.904 | INFO     | src.policies:train:166 - Total loss: 1.00120210647583\n",
      "2021-08-25 18:17:16.904 | INFO     | src.policies:train:171 - Epoch infos: {'efficiency': 20.727272727272727, 'equality': 0.8030303030695713, 'sustainability': 392.1301643488572, 'peace': 621.3636363636364}\n",
      "2021-08-25 18:17:16.952 | INFO     | src.policies:train:106 - Epoch 26 / 4000\n",
      "2021-08-25 18:17:16.952 | INFO     | src.policies:train:113 - Episode 26\n",
      "2021-08-25 18:17:42.835 | DEBUG    | src.policies:execute_episode:294 - Early stopping, all agents done\n",
      "2021-08-25 18:17:42.859 | INFO     | src.policies:train:124 - Episode infos: {'efficiency': 26.636363636363637, 'equality': 0.8820974247778316, 'sustainability': 392.8325641363694, 'peace': 564.0909090909091}\n",
      "2021-08-25 18:17:42.860 | INFO     | src.policies:train:129 - Mean episode return: 26.636363636363637\n",
      "2021-08-25 18:17:42.860 | INFO     | src.policies:train:130 - Last 100 episodes mean return: 24.926573426573427\n",
      "2021-08-25 18:17:42.861 | WARNING  | src.policies:train:140 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 18:17:52.390 | INFO     | src.policies:train:166 - Total loss: 0.9999762773513794\n",
      "2021-08-25 18:17:52.391 | INFO     | src.policies:train:171 - Epoch infos: {'efficiency': 26.636363636363637, 'equality': 0.8820974247778316, 'sustainability': 392.8325641363694, 'peace': 564.0909090909091}\n",
      "2021-08-25 18:17:52.438 | INFO     | src.policies:train:106 - Epoch 27 / 4000\n",
      "2021-08-25 18:17:52.439 | INFO     | src.policies:train:113 - Episode 27\n",
      "2021-08-25 18:18:18.791 | DEBUG    | src.policies:execute_episode:294 - Early stopping, all agents done\n",
      "2021-08-25 18:18:18.825 | INFO     | src.policies:train:124 - Episode infos: {'efficiency': 21.09090909090909, 'equality': 0.8283699059897395, 'sustainability': 378.65955817286556, 'peace': 613.3636363636364}\n",
      "2021-08-25 18:18:18.826 | INFO     | src.policies:train:129 - Mean episode return: 21.09090909090909\n",
      "2021-08-25 18:18:18.826 | INFO     | src.policies:train:130 - Last 100 episodes mean return: 24.784511784511785\n",
      "2021-08-25 18:18:18.827 | WARNING  | src.policies:train:140 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 18:18:29.687 | INFO     | src.policies:train:166 - Total loss: 0.9999709129333496\n",
      "2021-08-25 18:18:29.688 | INFO     | src.policies:train:171 - Epoch infos: {'efficiency': 21.09090909090909, 'equality': 0.8283699059897395, 'sustainability': 378.65955817286556, 'peace': 613.3636363636364}\n",
      "2021-08-25 18:18:29.746 | INFO     | src.policies:train:106 - Epoch 28 / 4000\n",
      "2021-08-25 18:18:29.747 | INFO     | src.policies:train:113 - Episode 28\n",
      "2021-08-25 18:18:57.856 | DEBUG    | src.policies:execute_episode:294 - Early stopping, all agents done\n",
      "2021-08-25 18:18:57.884 | INFO     | src.policies:train:124 - Episode infos: {'efficiency': 30.545454545454547, 'equality': 0.8582251082442878, 'sustainability': 420.3880650606436, 'peace': 607.9090909090909}\n",
      "2021-08-25 18:18:57.885 | INFO     | src.policies:train:129 - Mean episode return: 30.545454545454547\n",
      "2021-08-25 18:18:57.886 | INFO     | src.policies:train:130 - Last 100 episodes mean return: 24.99025974025974\n",
      "2021-08-25 18:18:57.887 | WARNING  | src.policies:train:140 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 18:19:08.879 | INFO     | src.policies:train:166 - Total loss: 0.9999414682388306\n",
      "2021-08-25 18:19:08.880 | INFO     | src.policies:train:171 - Epoch infos: {'efficiency': 30.545454545454547, 'equality': 0.8582251082442878, 'sustainability': 420.3880650606436, 'peace': 607.9090909090909}\n",
      "2021-08-25 18:19:08.933 | INFO     | src.policies:train:106 - Epoch 29 / 4000\n",
      "2021-08-25 18:19:08.934 | INFO     | src.policies:train:113 - Episode 29\n",
      "2021-08-25 18:19:37.891 | DEBUG    | src.policies:execute_episode:294 - Early stopping, all agents done\n",
      "2021-08-25 18:19:37.922 | INFO     | src.policies:train:124 - Episode infos: {'efficiency': 28.636363636363637, 'equality': 0.7414141414514555, 'sustainability': 394.258245965829, 'peace': 642.6363636363636}\n",
      "2021-08-25 18:19:37.923 | INFO     | src.policies:train:129 - Mean episode return: 28.636363636363637\n",
      "2021-08-25 18:19:37.923 | INFO     | src.policies:train:130 - Last 100 episodes mean return: 25.11598746081505\n",
      "2021-08-25 18:19:37.924 | WARNING  | src.policies:train:140 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 18:19:51.303 | INFO     | src.policies:train:166 - Total loss: 0.9999071359634399\n",
      "2021-08-25 18:19:51.304 | INFO     | src.policies:train:171 - Epoch infos: {'efficiency': 28.636363636363637, 'equality': 0.7414141414514555, 'sustainability': 394.258245965829, 'peace': 642.6363636363636}\n",
      "2021-08-25 18:19:51.371 | INFO     | src.policies:train:106 - Epoch 30 / 4000\n",
      "2021-08-25 18:19:51.373 | INFO     | src.policies:train:113 - Episode 30\n",
      "2021-08-25 18:20:23.698 | DEBUG    | src.policies:execute_episode:294 - Early stopping, all agents done\n",
      "2021-08-25 18:20:23.725 | INFO     | src.policies:train:124 - Episode infos: {'efficiency': 24.09090909090909, 'equality': 0.7838765008947038, 'sustainability': 416.80018206809524, 'peace': 591.8181818181819}\n",
      "2021-08-25 18:20:23.726 | INFO     | src.policies:train:129 - Mean episode return: 24.09090909090909\n",
      "2021-08-25 18:20:23.727 | INFO     | src.policies:train:130 - Last 100 episodes mean return: 25.081818181818182\n",
      "2021-08-25 18:20:23.727 | WARNING  | src.policies:train:140 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 18:20:34.361 | INFO     | src.policies:train:166 - Total loss: 0.9999061226844788\n",
      "2021-08-25 18:20:34.362 | INFO     | src.policies:train:171 - Epoch infos: {'efficiency': 24.09090909090909, 'equality': 0.7838765008947038, 'sustainability': 416.80018206809524, 'peace': 591.8181818181819}\n",
      "2021-08-25 18:20:34.416 | INFO     | src.policies:train:106 - Epoch 31 / 4000\n",
      "2021-08-25 18:20:34.417 | INFO     | src.policies:train:113 - Episode 31\n",
      "2021-08-25 18:21:03.644 | DEBUG    | src.policies:execute_episode:294 - Early stopping, all agents done\n",
      "2021-08-25 18:21:03.674 | INFO     | src.policies:train:124 - Episode infos: {'efficiency': 23.181818181818183, 'equality': 0.7632798574397006, 'sustainability': 425.50709694346057, 'peace': 637.0}\n",
      "2021-08-25 18:21:03.674 | INFO     | src.policies:train:129 - Mean episode return: 23.181818181818183\n",
      "2021-08-25 18:21:03.675 | INFO     | src.policies:train:130 - Last 100 episodes mean return: 25.020527859237536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 18:21:03.676 | WARNING  | src.policies:train:140 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 18:21:14.950 | INFO     | src.policies:train:166 - Total loss: 0.9999059438705444\n",
      "2021-08-25 18:21:14.951 | INFO     | src.policies:train:171 - Epoch infos: {'efficiency': 23.181818181818183, 'equality': 0.7632798574397006, 'sustainability': 425.50709694346057, 'peace': 637.0}\n",
      "2021-08-25 18:21:15.009 | INFO     | src.policies:train:106 - Epoch 32 / 4000\n",
      "2021-08-25 18:21:15.009 | INFO     | src.policies:train:113 - Episode 32\n",
      "2021-08-25 18:21:45.739 | DEBUG    | src.policies:execute_episode:294 - Early stopping, all agents done\n",
      "2021-08-25 18:21:45.764 | INFO     | src.policies:train:124 - Episode infos: {'efficiency': 25.454545454545453, 'equality': 0.8175324675620889, 'sustainability': 437.1229949650111, 'peace': 569.9090909090909}\n",
      "2021-08-25 18:21:45.765 | INFO     | src.policies:train:129 - Mean episode return: 25.454545454545453\n",
      "2021-08-25 18:21:45.766 | INFO     | src.policies:train:130 - Last 100 episodes mean return: 25.03409090909091\n",
      "2021-08-25 18:21:45.766 | WARNING  | src.policies:train:140 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 18:21:56.204 | INFO     | src.policies:train:166 - Total loss: 0.9999066591262817\n",
      "2021-08-25 18:21:56.205 | INFO     | src.policies:train:171 - Epoch infos: {'efficiency': 25.454545454545453, 'equality': 0.8175324675620889, 'sustainability': 437.1229949650111, 'peace': 569.9090909090909}\n",
      "2021-08-25 18:21:56.257 | INFO     | src.policies:train:106 - Epoch 33 / 4000\n",
      "2021-08-25 18:21:56.258 | INFO     | src.policies:train:113 - Episode 33\n",
      "2021-08-25 18:22:24.885 | DEBUG    | src.policies:execute_episode:294 - Early stopping, all agents done\n",
      "2021-08-25 18:22:24.917 | INFO     | src.policies:train:124 - Episode infos: {'efficiency': 20.363636363636363, 'equality': 0.7045454546054088, 'sustainability': 334.0292531763824, 'peace': 635.6363636363636}\n",
      "2021-08-25 18:22:24.918 | INFO     | src.policies:train:129 - Mean episode return: 20.363636363636363\n",
      "2021-08-25 18:22:24.920 | INFO     | src.policies:train:130 - Last 100 episodes mean return: 24.892561983471076\n",
      "2021-08-25 18:22:24.921 | WARNING  | src.policies:train:140 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 18:22:36.009 | INFO     | src.policies:train:166 - Total loss: 0.9999061226844788\n",
      "2021-08-25 18:22:36.010 | INFO     | src.policies:train:171 - Epoch infos: {'efficiency': 20.363636363636363, 'equality': 0.7045454546054088, 'sustainability': 334.0292531763824, 'peace': 635.6363636363636}\n",
      "2021-08-25 18:22:36.067 | INFO     | src.policies:train:106 - Epoch 34 / 4000\n",
      "2021-08-25 18:22:36.068 | INFO     | src.policies:train:113 - Episode 34\n",
      "2021-08-25 18:23:06.034 | DEBUG    | src.policies:execute_episode:294 - Early stopping, all agents done\n",
      "2021-08-25 18:23:06.103 | INFO     | src.policies:train:124 - Episode infos: {'efficiency': 26.727272727272727, 'equality': 0.8082869511737343, 'sustainability': 393.9717887189535, 'peace': 608.7272727272727}\n",
      "2021-08-25 18:23:06.105 | INFO     | src.policies:train:129 - Mean episode return: 26.727272727272727\n",
      "2021-08-25 18:23:06.106 | INFO     | src.policies:train:130 - Last 100 episodes mean return: 24.946524064171125\n",
      "2021-08-25 18:23:06.108 | WARNING  | src.policies:train:140 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 18:23:19.458 | INFO     | src.policies:train:166 - Total loss: 0.9999064207077026\n",
      "2021-08-25 18:23:19.459 | INFO     | src.policies:train:171 - Epoch infos: {'efficiency': 26.727272727272727, 'equality': 0.8082869511737343, 'sustainability': 393.9717887189535, 'peace': 608.7272727272727}\n",
      "2021-08-25 18:23:19.522 | INFO     | src.policies:train:106 - Epoch 35 / 4000\n",
      "2021-08-25 18:23:19.523 | INFO     | src.policies:train:113 - Episode 35\n",
      "2021-08-25 18:23:57.425 | DEBUG    | src.policies:execute_episode:294 - Early stopping, all agents done\n",
      "2021-08-25 18:23:57.457 | INFO     | src.policies:train:124 - Episode infos: {'efficiency': 25.818181818181817, 'equality': 0.7624839949163758, 'sustainability': 365.31901110840505, 'peace': 602.1818181818181}\n",
      "2021-08-25 18:23:57.458 | INFO     | src.policies:train:129 - Mean episode return: 25.818181818181817\n",
      "2021-08-25 18:23:57.459 | INFO     | src.policies:train:130 - Last 100 episodes mean return: 24.971428571428575\n",
      "2021-08-25 18:23:57.459 | WARNING  | src.policies:train:140 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 18:24:11.062 | INFO     | src.policies:train:166 - Total loss: 0.9999068975448608\n",
      "2021-08-25 18:24:11.063 | INFO     | src.policies:train:171 - Epoch infos: {'efficiency': 25.818181818181817, 'equality': 0.7624839949163758, 'sustainability': 365.31901110840505, 'peace': 602.1818181818181}\n",
      "2021-08-25 18:24:11.125 | INFO     | src.policies:train:106 - Epoch 36 / 4000\n",
      "2021-08-25 18:24:11.126 | INFO     | src.policies:train:113 - Episode 36\n",
      "2021-08-25 18:24:47.633 | DEBUG    | src.policies:execute_episode:294 - Early stopping, all agents done\n",
      "2021-08-25 18:24:47.669 | INFO     | src.policies:train:124 - Episode infos: {'efficiency': 25.727272727272727, 'equality': 0.7654995181873596, 'sustainability': 441.3616674159877, 'peace': 639.0}\n",
      "2021-08-25 18:24:47.669 | INFO     | src.policies:train:129 - Mean episode return: 25.727272727272727\n",
      "2021-08-25 18:24:47.670 | INFO     | src.policies:train:130 - Last 100 episodes mean return: 24.992424242424246\n",
      "2021-08-25 18:24:47.671 | WARNING  | src.policies:train:140 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 18:24:59.804 | INFO     | src.policies:train:166 - Total loss: 0.9999064207077026\n",
      "2021-08-25 18:24:59.805 | INFO     | src.policies:train:171 - Epoch infos: {'efficiency': 25.727272727272727, 'equality': 0.7654995181873596, 'sustainability': 441.3616674159877, 'peace': 639.0}\n",
      "2021-08-25 18:24:59.868 | INFO     | src.policies:train:106 - Epoch 37 / 4000\n",
      "2021-08-25 18:24:59.869 | INFO     | src.policies:train:113 - Episode 37\n",
      "2021-08-25 18:25:38.622 | DEBUG    | src.policies:execute_episode:294 - Early stopping, all agents done\n",
      "2021-08-25 18:25:38.656 | INFO     | src.policies:train:124 - Episode infos: {'efficiency': 18.636363636363637, 'equality': 0.7809312639066671, 'sustainability': 355.37685813566424, 'peace': 622.8181818181819}\n",
      "2021-08-25 18:25:38.657 | INFO     | src.policies:train:129 - Mean episode return: 18.636363636363637\n",
      "2021-08-25 18:25:38.658 | INFO     | src.policies:train:130 - Last 100 episodes mean return: 24.820638820638823\n",
      "2021-08-25 18:25:38.659 | WARNING  | src.policies:train:140 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 18:25:52.882 | INFO     | src.policies:train:166 - Total loss: 0.9999063014984131\n",
      "2021-08-25 18:25:52.883 | INFO     | src.policies:train:171 - Epoch infos: {'efficiency': 18.636363636363637, 'equality': 0.7809312639066671, 'sustainability': 355.37685813566424, 'peace': 622.8181818181819}\n",
      "2021-08-25 18:25:52.949 | INFO     | src.policies:train:106 - Epoch 38 / 4000\n",
      "2021-08-25 18:25:52.950 | INFO     | src.policies:train:113 - Episode 38\n",
      "2021-08-25 18:26:27.570 | DEBUG    | src.policies:execute_episode:294 - Early stopping, all agents done\n",
      "2021-08-25 18:26:27.608 | INFO     | src.policies:train:124 - Episode infos: {'efficiency': 28.454545454545453, 'equality': 0.7873947139431609, 'sustainability': 471.30352760223155, 'peace': 628.8181818181819}\n",
      "2021-08-25 18:26:27.609 | INFO     | src.policies:train:129 - Mean episode return: 28.454545454545453\n",
      "2021-08-25 18:26:27.609 | INFO     | src.policies:train:130 - Last 100 episodes mean return: 24.916267942583737\n",
      "2021-08-25 18:26:27.610 | WARNING  | src.policies:train:140 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 18:26:40.198 | INFO     | src.policies:train:166 - Total loss: 0.9999064207077026\n",
      "2021-08-25 18:26:40.199 | INFO     | src.policies:train:171 - Epoch infos: {'efficiency': 28.454545454545453, 'equality': 0.7873947139431609, 'sustainability': 471.30352760223155, 'peace': 628.8181818181819}\n",
      "2021-08-25 18:26:40.263 | INFO     | src.policies:train:106 - Epoch 39 / 4000\n",
      "2021-08-25 18:26:40.264 | INFO     | src.policies:train:113 - Episode 39\n",
      "2021-08-25 18:27:14.916 | DEBUG    | src.policies:execute_episode:294 - Early stopping, all agents done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 18:27:14.951 | INFO     | src.policies:train:124 - Episode infos: {'efficiency': 24.09090909090909, 'equality': 0.683018867978899, 'sustainability': 416.72371924106375, 'peace': 561.6363636363636}\n",
      "2021-08-25 18:27:14.952 | INFO     | src.policies:train:129 - Mean episode return: 24.09090909090909\n",
      "2021-08-25 18:27:14.953 | INFO     | src.policies:train:130 - Last 100 episodes mean return: 24.8951048951049\n",
      "2021-08-25 18:27:14.953 | WARNING  | src.policies:train:140 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 18:27:27.407 | INFO     | src.policies:train:166 - Total loss: 0.999906599521637\n",
      "2021-08-25 18:27:27.408 | INFO     | src.policies:train:171 - Epoch infos: {'efficiency': 24.09090909090909, 'equality': 0.683018867978899, 'sustainability': 416.72371924106375, 'peace': 561.6363636363636}\n",
      "2021-08-25 18:27:27.470 | INFO     | src.policies:train:106 - Epoch 40 / 4000\n",
      "2021-08-25 18:27:27.471 | INFO     | src.policies:train:113 - Episode 40\n",
      "2021-08-25 18:28:03.388 | DEBUG    | src.policies:execute_episode:294 - Early stopping, all agents done\n",
      "2021-08-25 18:28:03.425 | INFO     | src.policies:train:124 - Episode infos: {'efficiency': 28.181818181818183, 'equality': 0.8451612903452843, 'sustainability': 446.2997960340912, 'peace': 589.0909090909091}\n",
      "2021-08-25 18:28:03.426 | INFO     | src.policies:train:129 - Mean episode return: 28.181818181818183\n",
      "2021-08-25 18:28:03.427 | INFO     | src.policies:train:130 - Last 100 episodes mean return: 24.977272727272727\n",
      "2021-08-25 18:28:03.428 | WARNING  | src.policies:train:140 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 18:28:17.990 | INFO     | src.policies:train:166 - Total loss: 0.999906063079834\n",
      "2021-08-25 18:28:17.991 | INFO     | src.policies:train:171 - Epoch infos: {'efficiency': 28.181818181818183, 'equality': 0.8451612903452843, 'sustainability': 446.2997960340912, 'peace': 589.0909090909091}\n",
      "2021-08-25 18:28:18.060 | INFO     | src.policies:train:106 - Epoch 41 / 4000\n",
      "2021-08-25 18:28:18.060 | INFO     | src.policies:train:113 - Episode 41\n",
      "2021-08-25 18:28:55.517 | DEBUG    | src.policies:execute_episode:294 - Early stopping, all agents done\n",
      "2021-08-25 18:28:55.552 | INFO     | src.policies:train:124 - Episode infos: {'efficiency': 27.545454545454547, 'equality': 0.8127812781558984, 'sustainability': 392.1686331926754, 'peace': 522.8181818181819}\n",
      "2021-08-25 18:28:55.552 | INFO     | src.policies:train:129 - Mean episode return: 27.545454545454547\n",
      "2021-08-25 18:28:55.553 | INFO     | src.policies:train:130 - Last 100 episodes mean return: 25.039911308203987\n",
      "2021-08-25 18:28:55.554 | WARNING  | src.policies:train:140 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 18:29:08.690 | INFO     | src.policies:train:166 - Total loss: 0.9999068379402161\n",
      "2021-08-25 18:29:08.691 | INFO     | src.policies:train:171 - Epoch infos: {'efficiency': 27.545454545454547, 'equality': 0.8127812781558984, 'sustainability': 392.1686331926754, 'peace': 522.8181818181819}\n",
      "2021-08-25 18:29:08.760 | INFO     | src.policies:train:106 - Epoch 42 / 4000\n",
      "2021-08-25 18:29:08.760 | INFO     | src.policies:train:113 - Episode 42\n",
      "2021-08-25 18:29:42.080 | DEBUG    | src.policies:execute_episode:294 - Early stopping, all agents done\n",
      "2021-08-25 18:29:42.111 | INFO     | src.policies:train:124 - Episode infos: {'efficiency': 30.818181818181817, 'equality': 0.8256905336785076, 'sustainability': 463.99208692488776, 'peace': 638.7272727272727}\n",
      "2021-08-25 18:29:42.112 | INFO     | src.policies:train:129 - Mean episode return: 30.818181818181817\n",
      "2021-08-25 18:29:42.113 | INFO     | src.policies:train:130 - Last 100 episodes mean return: 25.17748917748917\n",
      "2021-08-25 18:29:42.114 | WARNING  | src.policies:train:140 - The actual batch size is 11000, instead of 4000\n",
      "2021-08-25 18:29:55.342 | INFO     | src.policies:train:166 - Total loss: 0.9999065399169922\n",
      "2021-08-25 18:29:55.343 | INFO     | src.policies:train:171 - Epoch infos: {'efficiency': 30.818181818181817, 'equality': 0.8256905336785076, 'sustainability': 463.99208692488776, 'peace': 638.7272727272727}\n",
      "2021-08-25 18:29:55.408 | INFO     | src.policies:train:106 - Epoch 43 / 4000\n",
      "2021-08-25 18:29:55.408 | INFO     | src.policies:train:113 - Episode 43\n"
     ]
    }
   ],
   "source": [
    "trpo_policy_nn = models.MLP(observation_space_size, hidden_sizes, action_space_size)\n",
    "trpo_baseline_nn = models.MLP(observation_space_size, hidden_sizes, 1, log_softmax=False)\n",
    "trpo_policy = policies.TRPOPolicy(env, trpo_policy_nn, trpo_baseline_nn, beta=beta, kl_target=kl_target)\n",
    "trpo_policy.train(\n",
    "    epochs,\n",
    "    steps_per_epoch,\n",
    "    enable_wandb=True,\n",
    "    wandb_config={**wandb_config, \"group\": \"TRPO\"},\n",
    "    render_every=render_every\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec94b1f6",
   "metadata": {},
   "source": [
    "## PPO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22891a29",
   "metadata": {},
   "source": [
    "This section deals with training a set of Harvest agents using our custom Proximal Policy Optimization implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18325fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1=1.0\n",
    "c2=0.01\n",
    "eps=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263e5bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_policy_nn = models.MLP(observation_space_size, hidden_sizes, action_space_size)\n",
    "ppo_baseline_nn = models.MLP(observation_space_size, hidden_sizes, 1, log_softmax=False)\n",
    "ppo_policy = policies.PPOPolicy(env, ppo_policy_nn, ppo_baseline_nn, c1=c1, c2=c2, eps=eps)\n",
    "ppo_policy.train(\n",
    "    epochs,\n",
    "    steps_per_epoch,\n",
    "    enable_wandb=True,\n",
    "    wandb_config={**wandb_config, \"group\": \"PPO\"},\n",
    "    render_every=render_every\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
